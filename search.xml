<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Youtube课程CSS zero to Hero笔记]]></title>
    <url>%2F2021%2F06%2F23%2F2021%2FCSSzeroHero%2F</url>
    <content type="text"><![CDATA[course link CSS Tutorial - Zero to Hero (Complete Course) CSS cascading style sheet 添加方法：一般用link加到html的head里面 测试方法，可以直接把background设置成别的颜色运行一下试试 Selectors &amp; Propertiesselector是什么 目的：把css的文件和多个html组合起来 有很多种类 element:直接使用html里面的tag，会改变这个tag的所有要素（body,p） class:自己设定class的名字，使用html element的时候加上这个class。（.aclass） id: 前面加上#，给element设置id，然后只改变这个id的内容(#sometext) 重要概念specificity 目的：在css里面，对同样东西不同style设定的时候，override的优先级 比如同样的文字，一个设定成红色一个设定成蓝色 优先级 in-line style &gt; id &gt; class &gt; element in-line是直接在element里面写style=&quot;color: aliceblue&quot; id和class的使用区别： class会用很多次 id应该只为了一个东西存在 pseudoselectors不仅可以加到element上面，也可以加到id或者class hover 添加鼠标移动到上面时候的样式（但是不能覆盖id和inline style） 可以用在所有种类的元素上面 类似的用法可以处理a1234a:link &#123;color:green;&#125;a:visited &#123;color:green;&#125;a:hover &#123;color:red;&#125;a:active &#123;color:yellow;&#125; 点击的时候 first-child/last-child/nth-child(n) 比如一个ul里面有很多li的时候，只让第一个/最后一个/第n个改变 only-child：如果有child的元素，里面只有一个元素 li:only-child Advance Selector虽然这里的例子写的都是element的selector，但是实际上也可以和id以及class组合 h2 + a找到所有h2下面的a tag并且改变 这个方法可以和上面的pseudo一起用 textarea ~ button找到和这个area 一个perent的button 必须是在一个parent里面的，如果是加号的话只要位置挨着就行 ul &gt; li对于在ul里面的每一个 直接的li都会改变。比如如果在ul里面又加一个ol，那ol里面的li就不会变了 ul li 对于在ul里面的 所有li Attribute Selectorelement[attr=value] attr可以设置成class，src，等等element里面的任何attribute src设置的时候也可以不用绝对值用pattern ^&amp;*~加在等号前面 CSS selector的列表参考 什么是properties 修改选中的element的内容的属性 必须有冒号和分号 总体思路 可以现在html里面给所有需要的内容加上class或者id，然后再统一写 Coloring &amp; Formatting 文字的颜色：color 背景的颜色：background 用image做background 可以直接用url引用图片(在线的或者本地的都可以) background-image或者直接用background都可以实现，不加后面的比较灵活 一些常用的背景设置选项 当图片不够大的时候，他会自动repeat来填满这个地方 加图片可以不从html里面加，而直接设置一个div，然后从css里面加背景 background-repeat:no-repeat 会只显示一张图，其他的这块区域都会空着 background-size:50px 100px; 前面的是高度，后面的是宽度 background-size:cover;:会去掉图片的一部分，让他可以完整的比例正确的显示在应该在的区域 background-size:contain; 透明度 用在渐变上面比较方便 颜色：用rgba（0~1）之间 渐变 radial: background: radial-gradient(red, blue); 会从中间蔓延到周围 也可以设置各个颜色的百分比，或者设置设置形状 linear: background: linear-gradient(to right, red, blue); 前面要先设置方向:上下左右，左上等等，或者直接使用角度 然后后面可以加上喜欢的颜色，带不带透明度的都可以 unit的不同种类 绝对unit：比如英尺，厘米之类的 不管在什么硬件上面，都会显示这个尺寸 相对unit 百分比：比如width: 70%;是指占这个parent的百分之70，如果缩放现在的屏幕的话，里面的东西的大小也会跟着改变 em:和标准的字体比的倍数，比如2em就会变成大小的两倍 vw：占这个view宽度的百分比，view会比body大一点。比如width:70vw vh是高度的百分比 比较特殊的px 虽然他是一个概念上的绝对值，但是也会根据不同硬件而改变 比如如果一个400px的东西显示在一个分辨率很高的电视上，可能实际页面的一个px占电视的三四个px 其他类似的单位pc &gt; pt &gt; px 建议在高度上选择绝对的单位，但是在宽度上选择相对的单位 因为高度可以往下拉，但是宽度和硬件的长度关系非常大 chrome的inspect可以直接改变画面的尺寸 Font &amp; Text Multipulation font和text的区别 font定义了字体，大小，加粗等等 text 定义了一些什么字体都能用的东西 text具体 text-decoration 可以加一些线，比如下面加横线，删除线，上面加线，什么线都没有之类的 text-transform 全部大写，小写 text-align 把文本对齐，比如居中，向左，向右等等 justify努力让所有的文字分布均匀，让每一行一边长 Font具体 font-size em，px等等 font-weight变细加粗属性，一般是从100～800。400可能是比较普通的 font-style，普通，斜体，更斜(oblique)等等 font family 就是设置字体，选择不同的关键词设置就可以了 sans-serif,看起来比较容易 -&gt; 没有衬托线，只留下字体的主干，类似于苹果自带字体那种感觉 serif体就是类似于宋体那种感觉 font-family: &quot;Times New Roman&quot;, serif;先找第一种能不能用，不能用的话就换成第二种 一般可以多准备几种，防止因为浏览器等等的原因这个字体崩溃 找到字体的方式 google font。可以在上面自定义（最好只选自己需要的），然后直接用代码加到需要的css里面 google font都给设定好了，只需要把需要的字体加进去就行了 font-family: &quot;Merriweather&quot;, serif;google自带的代码就会帮忙设定备用的字体，这样如果连不上网的话，就会自动载入第二种字体。需要保证第二种字体所有电脑上都能载入 基础LayoutBox model 每个element都在一个box里面 content -&gt; padding -&gt; border -&gt; margin padding:不会移动content，internel border：主要是分界线的作用，可以style margin：移动，externel borderborder: 5px solid red; 三个属性，大小，style和颜色，style包括实现 soild,dotted,dashed,double是几种常用的种类，包括实线，点线，虚线和 可以根据border和content的距离看出来有没有padding padding margin padding和margin的语法 如果只给一个参数，会在各个方向加上padding padding: 3cm; 可以加上一个参数表示在哪个方向padding padding-right: 40px; padding: 100px 40px 5px 0; 上，右，下，左 margin: 80px 40px;，第一个参数是上下，第二个是左右 margin 给边缘外面加上空间 float &amp; display type inline：就像在图片旁边环绕的效果一样 -&gt; span。不会单起一个部分 float: float: right;可以把现在的东西移动到一个位置，然后其他的内容自动往上顶 相当于把图片扔到文字的群里面 display display: none;可以直接把这个元素从画面上隐藏掉，也不会占用相应的空间 display: inline-block;： 组合两种方法，虽然不会创建一个新的line，但是还是给留了一个可操作的block空间 Flexbox可以自动完成一些排版的问题。 container：一个parent的element，一般都用div item：children 创建container display:flex; direction &amp; wrap container的属性 可以改变flex分布元素的方式，行还是列，也可以reverse顺序 flex-direction: row; flex-wrap: wrap;可以让他自动换行，不会挤在一行 content alignment justify-content: flex-end; 可以让他往左，往右或者居中 space-around/around可以让他均匀的分布 align-items: center;可以让他在container里面居中（和上面的方向不一样） 具体是哪个方向取决于flex-direction strech拉长 baseline虽然大家大小不一样，但是所有都根据一个baseline为基准 itemflex item order&lt;div class=&quot;container-item&quot; style=&quot;order: 5;&quot;&gt;A&lt;/div&gt;可以直接给每个item里面设定需要出现的order，index从1开始不从0开始 grow, shrink, basis flex-basis: 100px;指定他们的宽度 flex-grow: 数字设定这个元素占据的地方占所有的地方的多少，默认的是0 flex-shrink：页面缩放的时候和其他的相比的比例。数字越大缩放的越快。如果设定成0的话就不会缩放 上面的三个属性，可以直接用一个命令flex: 1 1 100px grow，shrink，basis一条命令直接实现 item alignment 可以在css里面用text-align: center;来设定具体的alignment，然后在html里面设置单独的 align-self:flex-start;可以在html里面单独设置。但是不能用baseline和strech里面的，因为他们需要的是整体的布局 Grid也是一种layout的方式 和flex的区别 grid手动设定的东西更多，可以customized很多layout flex比较关心width上面的布局，grid width和height两方面都很关注 创建grid：只需要把display设置成grid了 template rows/columns grid-template-columns: 10px 50px 10px; grid-template-rows: 50px 250px; 设定行和列的个数，以及每个格子的大小，比如在这里设置了三列，大小分别是10，50，19。又设置了两行，分别是50和250 可以直接设置成auto，这样他就会自动帮忙排版了 justify &amp; alignment justify-content: center; 不用space between，而是用evenly align-content: center; row/column gaps column-gap: 150px; 和row-gap: 100px;，可以控制各个格子之间的距离 可以简写成grid-gap: col row row/column lines grid最好用的地方 grid-column: 1 / 3; 把现在这个项目占的地方从第一列到第三列(占1和2)，其他的项目顺延 grid-row: 1 / 3; 也可以直接用距离表示：span 2占2格子的地方 grid area：直接用一行表示上面的东西 grid-area: 2 / 1 / span 2/ span 3 顺序是 row start -&gt; column start -&gt; row end -&gt; column end Animations &amp; Transtitionstranstition 属性 transition: 300ms linear; 类似于ppt的渐变颜色等等 transform: translate(50px, 30px) 往右移动50，往下移动30 scale(倍数)缩放 rotate(30deg)旋转 skew(30deg)绕X轴，Y轴等等等转动 matrix(xscale,deg,deg,yscale,transX,transY)可以总结上面的所有的 animation 一个动画至少有两个keyframe 创建关键帧关键词from to或者百分比 12345678910111213141516@keyframes red-to-black &#123; 0% &#123; background: chocolate; transform: translate(0px, 0px); &#125; 50% &#123; background: yellow; transform: translate(10px, 10px); &#125; 100% &#123; background: black; transform: translate(20px, 20px); &#125;&#125; 增加动画 在需要增加动画的区域里加上animation-name的属性 然后再给动画加上时间animation-duration: 10s; animation-timing-function:linear控制渐变 animation-delay: -2s;可以是负值，这样的话刷新的时候就是动画运行2s的时候 animation-iteration-count: 2;重复动画 animation-direction: reverse;改变动画播放的顺序 也可以把上面的内容都写在一个animation里面 Challenge!!]]></content>
      <categories>
        <category>2021</category>
        <category>6</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些前端的基础概念]]></title>
    <url>%2F2021%2F06%2F23%2F2021%2F%E5%89%8D%E7%AB%AF%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[参考资料 目的虽然在很多模板上写了不少html和css，但是还是没有一个基础的概念。正好这次的工作要写前端的模板，所以顺势学习一下他们的基本概念 开发工具 语言 html和css不属于programming language，他们只是用来告诉电脑这个网页的组成和皮肤 只有js是programming language framework react，vue，angular VS插件 live server prettier 可以直接format html的文件 web work client向server发送request server向client发送response 里面可能包括html，html又可能包括别的图片或者媒体文件(url)，然后再次发送一个新的http请求得到相应的东西 当所有的resouce都拿到之后，就会render浏览器 chrome devtool view-developer打开，可以自定义放在左边比较方便 可以从netword窗口看到所有渲染这个页面的request 可以在chrome里面一边调整css一边给其他人看效果 ##基础 HTML基础 html对大小写不敏感，但是一般默认都写成小写的 一般的tag都有开始和结束的tag img没有结束的tag：因为图片不能拥有任何child CSS基础 命名方式： 如果前面只有一个点，那么所有带这个css的class都会附加这个效果 如果前面是比如p.username，那么只有class是username的p才会有相应的效果 类选择器 .user.login 匹配同时包含user和login的元素 &lt;div class=&#39;user login&#39;&gt;你好。这是一个 DIV 元素，class=&#39;user login&#39;。&lt;/div&gt; .user .login匹配包含user的内容下面的包含login的元素 123&lt;div class='user'&gt;你好。这是一个 DIV 元素，class='user'。 &lt;div class='login'&gt;你好。这是一个 DIV 元素，class='user login'。&lt;/div&gt; &lt;/div&gt; 测试 https://validator.w3.org/ 可以直接搜css validator ##提高部分 head section meta：提供这个webpage的信息 比如character set（ASCII，UTF-8等） viewport：让这个page可以在不同的硬件上缩放 description:在搜索的时候现实的内容 text em：可以在p里面强调信息。是在html里面的，这样搜索的时候也能搜到重要的信息 具体的style上面的东西是由css决定的 默认的是斜体 同时也有,.但是尽量别用，因为想在css里面搞 heading 有从h1-h6的不同大小的标题 不是根据大小选的！！！因为css可以决定大小 heading是用来调节级别的。是让search来理解的。每个page应该只有一个h1 entities 表示一些特殊符号，比如小于号不能直接在html里面打出来 都是&amp;开头，;结尾，比如&amp;lt;是小于号 &amp;copy;是版权的标志 &amp;nbsp;none break space hyperlinks &lt;a herf:=&quot;&quot;&gt;&lt;/a&gt; 可以在a里面加上图片，这样点图片就可以链接了 如果加上download，一点击就直接下载了 可以给页面上的不同的element加上一个id，这样就可以从页面上方跳转到下方 如果直接jump到一个井号，那就会直接跳到页面顶端 &lt;a href=&quot;#id&quot;&gt;&lt;/a&gt; 如果加上target可以让他打开一个新的窗口 可以加上mailto:直接跳转到发送邮件的页面 ###img alt的存在意义 给盲人看的时候，可以读出来 如果图片读不出来还可以知道这里应该是啥 object-fit:cover：会crop图片，让他能放下 JavaScript快速入门 每个浏览器都有javascript的引擎 Node -&gt; 把javascript从浏览器分开了，不单可以写前端，啥都能写 可以直接用node命令从terminal运行 最好把它放在html的body的最后 放在前面会花更多时间来parsing js的代码 js里面的element需要和页面上的其他元素交互 &lt;script src=&quot;index.js&quot;&gt;&lt;/script&gt;来把js的文件提取出来 console 是浏览器提供的调试接口，可以log，assert之类的 运行之后会在浏览器的consloe窗口里面看到 ##语法们 变量 最好的方法使用let来定义变量:let name = &#39;xu&#39;; 一般在js里面都是用单引号，虽然双引号也能用 和python一样，变量是灵活的 常量const insterestRate = 1; Object1234567let person = &#123; name:"xu", age:30&#125;;person.name = "xu2";person["name"] = "xu2";console.log(person); Arrays同等对标python的list，也可以存不同的type 在web里的作用 对事件作出反应&lt;button type=&quot;button&quot; onclick=&quot;alert(&#39;欢迎!&#39;)&quot;&gt;点我!&lt;/button&gt; 改变html内容,图像 12x=document.getElementById("demo"); //查找元素x.innerHTML="Hello JavaScript"; //改变内容 改变html的style 12x=document.getElementById("demo") //找到元素 x.style.color="#ff0000"; //改变样式 验证输入以上找到元素的方法基本都是靠id 常见js事件 onchange：元素改变 onclick：点击 onmouseover：在这个元素上移动 onmouseout：从这个元素移开 onkeydown：按下键盘 onload：完成页面加载]]></content>
      <categories>
        <category>2021</category>
        <category>6</category>
      </categories>
      <tags>
        <tag>HTML</tag>
        <tag>CSS</tag>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的Functional思想以及实现接口]]></title>
    <url>%2F2021%2F06%2F23%2F2021%2FFPinJava%2F</url>
    <content type="text"><![CDATA[Java的imperative表达和Declarative表达 目标：创建一个person的class，打印出来里面所有的女性 前置工作:创建person这个class1234567891011121314151617static class Person &#123; private final String name; private final Gender gender; public Person(String name, Gender gender) &#123; this.name = name; this.gender = gender; &#125; @Override public String toString() &#123; return "Person&#123;" + "name='" + name + '\'' + ", gender=" + gender + '&#125;'; &#125; &#125; enum Gender&#123; MALE,FEMALE &#125; imperative表达 需要把所有需要的东西都定义出来1234567891011121314151617181920212223public static void main(String[] args) &#123; List&lt;Person&gt; people = List.of( new Person("John",Gender.MALE), new Person("Maria",Gender.FEMALE), new Person("Aisha",Gender.FEMALE), new Person("Alex",Gender.MALE), new Person("Alice",Gender.FEMALE) ); //Imperative approach List&lt;Person&gt; females = new ArrayList&lt;&gt;(); for(Person person : people)&#123; if(Gender.FEMALE.equals(person.gender))&#123; females.add(person); &#125; &#125; for(Person female : females)&#123; System.out.println(female); &#125; &#125; declarative stream:形成一个抽象的pipe 如果想要结果是list的话需要把它转化成list 1234567//Declarative approach System.out.println("//Declarative approach"); List&lt;Person&gt; female2 = people.stream() .filter(person -&gt; Gender.FEMALE.equals(person.gender)) .collect(Collectors.toList()); female2.forEach(System.out::println); 主要，在Java的FunctionPackage里面有很多不同的类，比如consumer，predicate等 比如如果在刚才的函数里提取出filter的条件，就是一个predicate（快捷键是command+option+v） Predicate&lt;Person&gt; personPredicate = person -&gt; Gender.FEMALE.equals(person.gender); Interface们Function 目的：在用stram的时候搞明白 Function 是functional里面的一个interface，目的是写出来一个函数式的method的表达方法 Function&lt;T,R&gt;，里面的T,R表示的是input和output的类型 这里使用了apply，实际上就是call这个函数，apply里面输入的值就是这个函数的参数12345678910111213public static void main(String[] args) &#123; int increment = increment(1); System.out.println(increment); Integer increment2 = incrementByOneFunction.apply(1); System.out.println(increment2); &#125; static Function&lt;Integer,Integer&gt; incrementByOneFunction = number -&gt; number + 1; static int increment(int number)&#123; return number + 1; &#125; AndThen的用法 可以使用它组合两个functional的函数，组成一个全新的函数 比如在这个例子里，我们让这个input的数字先实行加一，再实行乘10，这样最后可以组合起来使用 也可以不组合成新的function，直接在最后apply执行123456Function&lt;Integer, Integer&gt; addBy1AndThenMultiplyBy10 = incrementByOneFunction.andThen(multiplyBy10Function);Integer result = addBy1AndThenMultiplyBy10.apply(1);System.out.println(result);static Function&lt;Integer,Integer&gt; multiplyBy10Function = number -&gt; number * 10; BiFunction 表达的意义和function基本相同，唯一的不同就是接受两个arg作为input，然后输出一个output 比如在这个例子里面，输入了两个参数，一个是需要加一的，另一个是相乘的系数 基本所有的functional里面加上Bi的都是用两个参数123static BiFunction&lt;Integer,Integer,Integer&gt; incrementByOneAndMultiplyBiFunction = (numberToAdd1, numberToMultiple) -&gt; (numberToAdd1 + 1) * numberToMultiple;System.out.println(incrementByOneAndMultiplyBiFunction.apply(1,10)); Consumer 接受一个input并且不会返回任何值 可以理解是一个void函数 这里的关键词用的apply AndThen的使用方法应该是同理 12345678910111213141516171819202122232425262728public static void main(String[] args) &#123; greetCustomer(new Customer("Maria","9999")); greetCustomerConsumer.accept(new Customer("Maria","9999")); &#125; static Consumer&lt;Customer&gt; greetCustomerConsumer = customer -&gt; System.out.println("Hello " + customer.customerName + "thanks for registering number " + customer.customerPhoneNumber); static void greetCustomer(Customer customer)&#123; System.out.println("Hello " + customer.customerName + "thanks for registering number " + customer.customerPhoneNumber); &#125; static class Customer &#123; private final String customerName; private final String customerPhoneNumber; public Customer(String customerName, String customerPhoneNumber) &#123; this.customerName = customerName; this.customerPhoneNumber = customerPhoneNumber; &#125; &#125; Bi的使用方法也应该是同理 比如在这个例子里面，我们判断了是不是要显示电话号码，要是不需要显示的话就显示星号 注意要学会一行的if的写法12345static BiConsumer&lt;Customer,Boolean&gt; greetCustomerConsumerV2 = (customer, showPhoneNumber) -&gt; System.out.println("Hello " + customer.customerName + "thanks for registering number " + (showPhoneNumber ? customer.customerPhoneNumber : "*****")); Predicate 输入一个参数，返回一个boolean 这里的参数用的test Bi的情况和上面一样 123456789101112131415161718192021public class _Predicate &#123; public static void main(String[] args) &#123; System.out.println(isPhoneNumberValid("07000000000")); System.out.println(isPhoneNumberValid("0700000000")); System.out.println(isPhoneNumberValid("08000000000")); System.out.println(isPhoneNumberValidPredicate.test("07000000000")); System.out.println(isPhoneNumberValidPredicate.test("0700000000")); System.out.println(isPhoneNumberValidPredicate.test("0800000000")); &#125; static Predicate&lt;String&gt; isPhoneNumberValidPredicate = phoneNumber -&gt; phoneNumber.startsWith("07") &amp;&amp; phoneNumber.length() == 11; static boolean isPhoneNumberValid(String phoneNumber)&#123; return phoneNumber.startsWith("07") &amp;&amp; phoneNumber.length() == 11; &#125;&#125; 也可以用and，or等的关键词，连接不同的predicate 12System.out.println(isPhoneNumberValidPredicate.and(contains3).test("07000000000")); //falseSystem.out.println(isPhoneNumberValidPredicate.and(contains3).test("07003000000")); //true Supplier 一个不需要参数，然后返回一个返回值的东西 这里的关键词用的get 虽然没有参数，但是需要在参数的地方加括号 应该没有Bi1234567891011public class _Supplier &#123; public static void main(String[] args) &#123; System.out.println(getDBConnectionUrlSupplier.get()); &#125; static Supplier&lt;String&gt; getDBConnectionUrlSupplier = () -&gt; "jdbc://localhost:5432/users"; static String getDBConnectionUrl()&#123; return "jdbc://localhost:5432/users"; &#125;&#125; Stream Stream里面的不同函数，map,filter之类的里面的内容都是上面提到的interface map：transfermation。比如下面的例子，从每个人里面取出来了性别，然后把性别组成了一个set，然后对在set里面的每一个性别都要打印出来 1234people.stream() .map(person -&gt; person.gender) //function .collect(Collectors.toSet()) .forEach(gender -&gt; System.out.println(gender)); //consumer 可以提取出来每个人的名字的长度并且打印 如果提取出来每个命令里面的变量，就会发现都是上面的interface 1234567Function&lt;Person, String&gt; personStringFunction = person -&gt; person.name;ToIntFunction&lt;String&gt; stringToIntFunction = name -&gt; name.length();IntConsumer println = System.out::println;people.stream() .map(personStringFunction) //function .mapToInt(stringToIntFunction) .forEach(println); //consumer 更多关于Stream 比如可以用anymatch,allmatch,nonematch的predicate来判断这个 集合里面是不是都是女的 或者是不是包含女的 或者是不是根本没有事PREFERNOTSAY的12345678910boolean containsOnlyFemales = people.stream().allMatch(person -&gt; FEMALE.equals(person.gender));System.out.println(containsOnlyFemales);//falseboolean containsFemales = people.stream().anyMatch(person -&gt; FEMALE.equals(person.gender));System.out.println(containsFemales);//trueboolean notNotSay = people.stream().noneMatch(person -&gt; PREFER_NOT_TO_SAY.equals(person.gender));System.out.println(notNotSay); Optional 意义：对待null pointer的方法改变了 例子: 如果是null的话就会输出默认值 不是null的话就会输出对应的值 是null的话会throw相应的exception 判断是不是有，做相应的处理1234567891011121314151617Object value = Optional.ofNullable("Hello").orElseGet(() -&gt; "default value");System.out.println(value);//HelloObject value = Optional.ofNullable(null).orElseGet(() -&gt; "default value");System.out.println(value);//default valueObject value2 = Optional.ofNullable(null).orElseThrow(()-&gt; new IllegalStateException("exception"));System.out.println(value2);//exceptionOptional.ofNullable("a@gmail.com").ifPresentOrElse( email -&gt; System.out.println("sending email to " + email), () -&gt; &#123; System.out.println("cannot send email"); &#125;); Combinator pattern 把很多函数作为参数，然后返回函数。（也就是把很多不用的函数组成一个新的接口） 主要用于验证的时候 注意： 当用and来拼接interface里面的不同方法的时候，如果没有apply是不会实现的，只会生成一个新的接口（相当于拼接好几个函数） 当apply之后才会返回相对应的值1234567891011121314151617181920212223242526272829303132333435//继承自function，接受一个customer，输出一个validationResult（是一个enum，枚举类）public interface CustomerRegistrationValidator extends Function&lt;Customer, ValidationResult&gt; &#123; //接口静态方法，可以实现 static CustomerRegistrationValidator isEmailValid()&#123; return customer -&gt; customer.getEmail().contains("@") ? SUCCESS : EMAIL_NOT_VALID; &#125; static CustomerRegistrationValidator isPhoneNumberValid()&#123; return customer -&gt; customer.getPhoneNumber().startsWith("+0") ? SUCCESS : PHONE_NUMBER_NOT_VALID; &#125; static CustomerRegistrationValidator isAdult()&#123; return customer -&gt; Period.between(customer.getDob(), LocalDate.now()).getYears() &gt; 16 ? SUCCESS : IS_NOT_AN_ADULT; &#125; //接口的默认方法 default CustomerRegistrationValidator and (CustomerRegistrationValidator other)&#123; return customer -&gt; &#123; ValidationResult result = this.apply(customer); return result.equals(SUCCESS) ? other.apply(customer) : result; &#125;; &#125; enum ValidationResult&#123; SUCCESS, PHONE_NUMBER_NOT_VALID, EMAIL_NOT_VALID, IS_NOT_AN_ADULT &#125;&#125; 1234567891011121314151617181920public class Main &#123; public static void main(String[] args) &#123; Customer customer = new Customer( "Alice", "Alice@gmail.com", "+01111111", LocalDate.of(1990,1,1) ); //Conbinator //在apply之前都不会run，只是组成一个interface ValidationResult result = isEmailValid().and(isPhoneNumberValid()).and(isAdult()).apply(customer); System.out.println(result); if (result != ValidationResult.SUCCESS) &#123; throw new IllegalStateException(result.name()); &#125; &#125;&#125; callback 可以直接用interface来实现往函数里面传一个函数作为参数，类似于js的callback功能1234567891011121314151617181920212223242526272829303132public class Main &#123; public static void main(String[] args) &#123; hello("John",null,value -&gt; &#123; System.out.println("lastName is not provided for " + value); &#125;); hello2("John",null,() -&gt; &#123; System.out.println("lastName is not provided!!"); &#125;); &#125; static void hello(String firstName, String lastName, Consumer&lt;String&gt; callback)&#123; System.out.println(firstName); if (lastName != null)&#123; System.out.println(lastName); &#125;else &#123; callback.accept(firstName); &#125; &#125; //Runnable也是一个functional static void hello2(String firstName, String lastName, Runnable callback)&#123; System.out.println(firstName); if (lastName != null)&#123; System.out.println(lastName); &#125;else &#123; callback.run(); &#125; &#125;&#125; lambdas 尽量多使用method reference（ij会给提示）12Function&lt;String,String&gt; upperCaseName = name -&gt; name.toUpperCase();Function&lt;String,String&gt; upperCaseName2 = String::toUpperCase; 1234BiFunction&lt;String,Integer, String&gt; upperCaseName3 = (name,age) -&gt; &#123; if(name.isBlank()) throw new IllegalStateException(""); return name.toUpperCase(); &#125;; 总结： function不能depend on任何state：不能在里面使用外面的变量 self contained 不能在function外面有什么side effect 如果把其他的function作为输入或者输出function，会变成higher order function]]></content>
      <categories>
        <category>2021</category>
        <category>6</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Functional</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL入门学习]]></title>
    <url>%2F2021%2F05%2F09%2F2021%2FSQL%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Youtube三小时速成SQLMySQL Tutorial for Beginners [Full Course] 什么是SQL DB里面，数据都按一定的顺序排放，大家通过DB的管理软件（database management）来访问数据库并得到结果 有两种种类 ralational:table分成不同的表，之间是有关系的 比如MySQL，Server SQL等等。MySQL是开源的，用的人最多 NoSQL：没有表，没有关系，和SQL的语法不共通 安装 本地默认端口3306，注意有的时候可能会被占用 sudo lsof -i:3306 kill （番号) Connection错误： 需要在设置里启动MySQL Server才行 创建Database 上面的小闪电：运行 会有创建database的.sql文件，使用他之后就会在schemas里面出现创建好的database database组成 Table 一般会在其他相关table里面只存储id，这样避免主体的其他地方改变 relational databases：各个表之间有关系，共享一些相同的数据（比如id） View：组合很多table Function：写具体的功能（比如找出来地方相同的人等） SELECT(以及一些基本命令) 大小写不敏感哪里都不敏感，但是一般来说要用大写来写命令。对换行不敏感，但是分开写比较容易看 USE表示访问哪个database SELECT用来访问column，也可以用星号表示所有的。 可选内容： FROM一个表。WHERE来定义具体的要求，必须这一项等于什么。ORDER BY可以设置排序。 Comment:两个横杠1234SELECT *FROM customersWHERE customer_id = 1ORDER BY first_name SELECT本身 可以在后面接任意列的名字，如果调换顺序的话显示出来的顺序也会改变 数学运算可以直接加在数字的列上面 AS可以把表头改成一个新的名字。改完之后的名字可以在后面直接用 12345SELECT last_name, first_name, points * 10 + 10 AS "discount factor"FROM customers DISTINCT可以删除重复的元素 12SELECT DISTINCT stateFROM customers WHERE 用来写条件，比如比大小 注意等于的符号是一个等号。&lt;&gt;也可以表示不等于 string的时候也需要用引号括起来。string也可以比大小，比如生日日期123SELECT *FROM customersWHERE state="VA" AND OR NOT 逻辑运算顺序，AND最先计算，然后是OR1234SELECT *FROM customersWHERE birth_date &gt; '1990-01-01' OR (points &gt; 1000 AND state = 'VA')--相当于上面加了括号的写法 IN1234567891011121314SELECT *FROM customersWHERE state = 'VA' OR state = 'GA' OR state = 'FL'-- 简化写法SELECT *FROM customersWHERE state IN ('VA','GA','FL')-- 也可以和NOT组合使用SELECT *FROM customersWHERE state NOT IN ('VA','GA','FL') BETWEEN 取中间值的写法，注意这里的写法包括了等于 同样不止包括数字，也包括string123SELECT *FROM customersWHERE points BETWEEN 1000 AND 3000 LIKE 找到b开头的名字，后面的百分号可以表示随便多少位的字母。比如%B%可以找到名字里有B的 _y只有两个character的长度，不管前面的是什么，后面的是y。可以增加下划线的长度。比如“B___Y 注意两个LIKE并列的时候需要写两遍 可以和NOT组合成not like123SELECT *FROM customersWHERE last_name LIKE 'b%' REGEXP比like更复杂的表示方法，可以有几种方式 ^field这个东西必须出现在最开头 field$必须以这个string结束 field|mac有前面或者后面的元素（中间不能有空格） [a-h]e可以随意排列组合的数字 1234567891011121314151617SELECT *FROM customersWHERE last_name REGEXP "^field|mac|rose"SELECT *FROM customersWHERE last_name REGEXP "[gim]e" -- 里面有ge ie 或者 me 也可以写 "[a-h]e"SELECT *FROM customers-- WHERE first_name REGEXP "ELKA|AMBUR"WHERE last_name REGEXP "EY$|ON$"-- WHERE last_name REGEXP "^MY|SE"-- WHERE last_name REGEXP "B[RU]" IS NULL 找到空的表格的地方，可以和NOT组合使用123SELECT *FROM customersWHERE phone IS NOT NULL ORDER BY 每个表里都有一个primary的column，会代表这个表里面每个data的unique 可以进行多重的sort，每个可以单独设置DESC降序排列。 即使是SELECT里面没有选择的列，也可以进行排序 123SELECT *FROM customersORDER BY state DESC, first_name 下面这种情况代表按first_name和last_name来排序（即SELECT里面的1，2列） 但是希望尽量避免这种写法123SELECT first_name,last_nameFROM customersORDER BY 1,2 LIMIT 不想得到所有的行，比如只想得到前三行，那就LIMIT 3 LIMIT一定是出现在最后一行的1234SELECT *FROM customersLIMIT 6,3-- 这行的意思跳过前面的6个，然后显示后面的三个 Joins(组合column)上面的都是从一个table里面选的，现在来看从不同table选 inner join基础可以把两个表根据一些相同的内容连接在一起(比如id)，这样会把两个小表组合成一个大表（分开的原因：可能有一些表容易改变，一些表不容易改变，比如用户信息和用户订单要分开） 如果想SELECT两个表里面都有的column，必须指定一个 另外，可以在FROM和JOIN后面简化database的名字。但是指定之后必须一直用指定后的，不然会报错12345678910SELECT order_id, first_name, last_nameFROM ordersJOIN customers ON orders.customer_id = customers.customer_id-- 简化版本SELECT order_id, o.customer_id, first_name, last_nameFROM orders oJOIN customers c ON o.customer_id = c.customer_id DB之间的data join 只需要在table前面加上DB的索引就可以了。需要注意现在用的是哪个DB（USE关键词）1234SELECT * FROM order_items oiJOIN sql_inventory.products p ON oi.product_id = p.product_id join itself 在例题的表里面，每个员工都会有一个对应的manager，这个manager也显示的是员工id，现在要在这个表里面找到所有员工的manager 必须给两个相同的table不同的代称，比如这里用了e表示员工，m表示manager。另外，在SELECT的时候因为列的名字都相同，需要加上不同的表的名字123456789USE sql_hr;SELECT e.employee_id, e.first_name, m.first_name AS managerFROM employees eJOIN employees m ON e.reports_to = m.employee_id join multiple table 在后面继续JOIN就可以组合多个表格，注意名字不要打错12345678910USE sql_store;SELECT o.order_id, o.order_date, c.first_name, c.last_name, os.name AS statusFROM orders oJOIN customers c ON o.customer_id = c.customer_idJOIN order_statuses os ON o.status = os.order_status_id 有条件的join之前的都用独一无二的id来join这些表格，但是有时候的表格是不一定独一无二的，需要用一些column的组合来确定 ON后面用AND来增加多个条件1234567USE sql_store;SELECT *FROM order_items oiJOIN order_item_notes oin ON oi.order_id = oin.order_id AND oi.product_id = oin.product_id outer join如果只打join就是inner的，outer需要加上关键词。outer也是可选的，只需要left和right就行了 基础12345678910USE sql_store;SELECT c.customer_id, c.first_name, o.order_idFROM customers cJOIN orders o ON c.customer_id = o.customer_idORDER BY c.customer_id 上面的是刚才inner的方法，但是这种方法有一个问题，因为不是每个customer都有订单，所以最后的结果只会显示有订单的用户 1234567891011121314151617181920SELECT c.customer_id, c.first_name, o.order_idFROM customers cLEFT JOIN orders o ON c.customer_id = o.customer_idORDER BY c.customer_id-- 或者SELECT c.customer_id, c.first_name, o.order_idFROM orders o RIGHT JOIN customers c ON c.customer_id = o.customer_idORDER BY c.customer_id 有两种方法，left join和right join。如果用了left，左边的table的所有元素（也就是FROM的那个）无论满不满足on的条件都会显示在列里，不满足条件的会用null轮空 多个表格的outer join 无论用户有没有订单，都会显示，无论订单有没有shipper，也都会显示 尽量不要用right，因为加多个表的时候容易看晕1234567891011SELECT c.customer_id, c.first_name, o.order_id, sh.nameFROM customers cLEFT JOIN orders o ON c.customer_id = o.customer_idLEFT JOIN shippers sh ON o.shipper_id = sh.shipper_idORDER BY c.customer_id self outer join 上面inner的HR例子里面，实际上是有信息丢失的，因为有一个人没有上司，所以在表里面也没显示12345678USE sql_hr;SELECT e.employee_id, e.first_name, m.first_name AS managerFROM employees eLEFT JOIN employees m ON e.reports_to = m.employee_id 小窍门USING 在数据越来越多的时候，读起来就非常困难了，这时候可以选择简化语句 但是必须保证两者的表头是一样的才可以1234567891011USE sql_store;SELECT c.customer_id, c.first_name, sh.name AS shipperFROM customers cLEFT JOIN orders o -- ON c.customer_id = o.customer_id USING (customer_id)LEFT JOIN shippers sh USING (shipper_id) 123456SELECT *FROM order_items oiJOIN order_item_notes oin -- ON oi.order_id = oin.order_id -- AND oi.product_id = oin.product_id USING (order_id, product_id) implicit join（不推荐） 也可以不用JOIN命令来写，但是这种写的方法很有可能产生不会报错的重大bug，所以不要用123SELECT *FROM orders o, customers cWHERE o.customer_id = c.customer_id natural join（不推荐） 会自动匹配名字相同的column 不是很好控制，尤其是复杂起来，别用123456USE sql_store;SELECT o.order_id, c.first_nameFROM orders oNATURAL JOIN customers c cross join 会把两个表的元素全都组合一遍，下面这个例子没有什么实际意义，如果想得到所有的排列组合的时候可以用这个命令123456789101112131415USE sql_store;SELECT c.first_name, p.name AS productFROM customers cCROSS JOIN products pORDER BY c.first_name-- 也可以这么写，效果是一样的，但是不推荐USE sql_store;SELECT c.first_name, p.name AS productFROM customers c, products pORDER BY c.first_name 对row的处理Unions 链接两个不同的query,把结果放在一个里面 必须确保两个部分选择的column数量是一样的。表头是由前一个表的名字决定的12345678910111213141516171819202122232425262728293031323334-- 例子：用年份区分是不是现在的USE sql_store;SELECT order_id, order_date, "Active" AS statusFROM ordersWHERE order_date &gt;= "2019-01-01"UNIONSELECT order_id, order_date, "Archived" AS statusFROM ordersWHERE order_date &lt; "2019-01-01"-- 例子：用积分区别等级USE sql_store;SELECT customer_id, first_name, points, "Bronze" AS typeFROM customersWHERE points &lt; 2000 UNIONSELECT customer_id, first_name, points, "Silver" AS typeFROM customersWHERE points BETWEEN 2000 AND 3000UNIONSELECT customer_id, first_name, points, "Gold" AS typeFROM customersWHERE points &gt; 3000 ORDER BY first_name 插入，修改，删除data datatype里面 varchar（50），上限是50，写多少就存多少。如果是char（50）的话就肯定占50 PK：primary key NN：not null，必须项目 AI：auto ++，一般加在PK里面 如果这个值有默认值，可以直接用default关键字添加 插入row DEFAULT可以自己选择id 可以通过自定义的项目来跳过table里面默认的部分或者以及id值,也可以改变插入的顺序1234567891011121314USE sql_store;INSERT INTO customers( first_name, last_name, birth_date, address, city, state)VALUES ("John", "Smith", "1990-01-01", "address", "city", "CA") 插入多行直接往后加就可以12345USE sql_store;INSERT INTO shippers(name)VALUES ("shipper1"), ("shipper2"), ("shipper3") 把data插入多个table 因为table之间是有关系的，会有parent和child table，也就是parent里面多了一行的话，child里面也必须多一行 LAST_INSERT_ID()得到上次插入的id 12345678USE sql_store;INSERT INTO orders(customer_id,order_date,status)VALUES(3,"2020-05-19",1);INSERT INTO order_itemsVALUES (LAST_INSERT_ID(),1,1,2.95), (LAST_INSERT_ID(),2,1,3.95) copy data123USE sql_store;CREATE TABLE orders_archived ASSELECT * FROM ordersorders_archived 注意，以上这个方法的id不会被标记成PK，也不会自己增加 1234USE sql_store;INSERT INTO orders_archivedSELECT * FROM ordersWHERE order_date &lt; "2019-01-01" 这个方法可以用INSERT INTO来只copy一部分data到新的表里面 123456789-- 创建表+JOIN+条件判断CREATE TABLE invoices_archived ASSELECT c.name, i.payment_dateFROM invoices iJOIN clients c USING (client_id)WHERE i.payment_date IS NOT NULL update数据 Update一行 123UPDATE invoicesSET payment_total = DEFAULT, payment_date = due_dateWHERE invoice_id = 1 update多行，选择多行的条件即可 123UPDATE invoicesSET payment_total = invoice_total * 0.5, payment_date = due_dateWHERE client_id IN (3,4) subquery来更新数据 比如需要从名字知道id，再从id得到需要更改的行123456789101112131415USE sql_invoicing;UPDATE invoicesSET payment_total = invoice_total * 0.5, payment_date = due_dateWHERE client_id = (SELECT client_id FROM clients WHERE name = "Myworks")-- 需要更新多个值得实惠UPDATE invoicesSET payment_total = invoice_total * 0.5, payment_date = due_dateWHERE client_id IN (SELECT client_id FROM clients WHERE state IN ("CA","NY")) 删除data 注意不加条件会全部删除的12345DELETE FROM invoicesWHERE client_id =(SELECT *FROM clientsWHERE name = "Myworks")]]></content>
      <categories>
        <category>2021</category>
        <category>5</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[page]]></title>
    <url>%2F2021%2F04%2F21%2F2021%2FGitGit%E5%8F%8A%E5%9B%A2%E9%98%9F%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Java基础复建]]></title>
    <url>%2F2021%2F04%2F21%2F2021%2FJave_BasicJava%E7%9A%84%E5%9F%BA%E7%A1%80%E5%A4%8D%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Java基础部分1 Step01VariableTestJava字符串拼接 可以用+连接，当其中有一个string的时候，其他的数据类型也会直接变成string。 注意这里其他种类都会被转换成string，即使是String s = null;也会在拼接之后变成“null” 如果都是string类型的话，可以用a.concat(b)。因为已经假设都是字符串了，所以相对的效率更高 可以考虑用StringBuffer.append()来拼接1234567StringBuffer buf=new StringBuffer()buf.append("a");if(someCondition)&#123; buf.append("b");&#125;buf.append("c");String d=buf.toString(); 再赋值 基础变量（primitive value）的再赋值不会改变之前的值，但是reference的再赋值改变的是reference，不是实际的值，所以会变 一个variable只有两个可能，是reference或者是primitive value 注意赋值的时候，需要assign到位，比如sea = sea+1而不是sea+1（太久不写Java感觉脑子不转了） ###没有assign的时候的默认情况 String的初始默认值是null，如果用了String s = &quot;&quot;则是给初始赋值了空字符 int等等数字类型的初始值都是0 boolean的初始值是false Integer是java提供的封装类，所以它在未赋值的时候初始是null，这样可以分清楚是未赋值还是赋值0的区别。 封装类：封装类里面会包含很多对基础数据类型的操作，比较方便。但是在效率上面会比primitive要低 ++a 和 a++ ++i先运算再赋值，显示出来的是计算之后的 i++先赋值再运算，显示出来的是计算之前的12System.out.println("a=i++===&gt; "+(a=i++));//1System.out.println("a=++i===&gt; "+(a=++i));//2 ###局部变量,全局变量,实例变量 定义在类里的是class variable，不需要初始化，会有默认值。静态变量（要加静态变量的static）。 可以直接通过类名来调用 定义在方法里面的是局部变量（local variable），必须初始化，出了作用域就会被销毁 实例变量instance variable:非静态变量，位于method外面，class里面 Java允许两种变量重名 局部变量的范围会覆盖全局变量。如果想调用全局变量，需要用this关键字来找 {}代表一个作用域 ###Java参数传递 值传递：调用时，参数把值传给形参，方法执行里面的primitive参数变化不会改变原本参数的值 基础数据类型，包括string123456789101112131415public class A &#123; public static void change(int i, int j) &#123; int temp = i; i = j; j = temp; &#125; public static void main(String[] args) &#123; int a = 3; int b = 4; change(a, b); System.out.println("a=" + a); //3 System.out.println("b=" + b); //4 &#125;&#125; 引用传递：调用的时候传递的是地址，所以会改变参数的值 String以外的剩余复合数据类型，包括数组，类等等 比如如果用StringBuild()而不是String来初始化新的String，那么他就可以被传递了 如果参数构造成了一个新的对象，就不是传递的那个对象了，那传递的对象就不变了123456789101112public class Test &#123; public static void add(A a) &#123; //a = new A(); //if not comment, output 0 a.i++; &#125; public static void main(String args[]) &#123; A a = new A(); add(a); System.out.println(a.i ); //output 1 &#125; &#125; 当primitive和其他数据类型同时出现在参数里面的时候，要注意谁会改变谁不会改变！！Step02IfForTest插入：List，Arraylist Array的大小固定，连续储存，删除速度很慢 List继承Collection，有两个实现类，ArrayList和LinkedList List是接口，不能直接构造list，需要List list = new ArrayList(); ArrayList可以看为可以随意增减的数组 for表达式 声明语句 类型，必须和数组的数据类型匹配 作用域就在for的括号里面 表达式：想要访问的数组名1234for(声明语句 : 表达式（数组）)&#123; //代码句子&#125; foreach用法 特点：没有储存，函数式编程 循环map,list等等 1item.forEach(元素 -&gt; 处理方法); 没有continue 要用return跳入下一个循环。 没有break的功能 可以自己设置一个flag来判断是不是要跳出循环 不可以在里面直接给变量赋值，要赋值必须使用method来处理 比如不能直接给String赋值，但是可以改成StringBuilder里面的方法 Step03DataTypeTestJava的符号优先级 括号 加减的优先级高于比大于小于 大于小于高于等于不等于 与 -&gt; 或 强制类型转换 float和double结尾可以是d/f也可以是D/F 超出范围的大数转小的会溢出，出现奇妙数字（具体变成什么要看bit上面的位） short 4bit int 8bit float 8bit double 16bit float转int（强制）的时候会舍去 ##Step05ClassTest Java里面写class public的class必须自己单独放在一个.java的文件里面 class里面的123public 类名(构造函数的参数) &#123; this.class_varibles = ...; &#125; final的用法 装饰类：final class A{}，这样被装饰的类不能被继承，final类里面的所有方法都会被认为是final的方法 装饰方法 把方法锁定，避免其他继承类修改他的意义 为了效率（现在好像已经不是很重要了） private的方法会被认为是隐式的final方法 装饰变量 如果变量是primitive，一旦初始化之后就不能被更改，可以被认为是常量 如果是引用，那么初始化之后就不能指向另一个对象了 装饰变量详解： 如果是类的变量，比如在定义或者构造器的时候初始化，初始化之后就不能再被赋值了 注意：如果像下面第二个例子一样，final修饰的指向对象的时候，就不会被优化成常量 static可以不依赖具体的对象就可以被调用1234567891011public class Test &#123; public static void main(String[] args) &#123; String a = "hello2"; final String b = "hello"; String d = "hello"; String c = b + 2; String e = d + 2; System.out.println((a == c)); //true -&gt; final的变量就直接被认为是常量了 System.out.println((a == e)); //false &#125;&#125; 12345678910111213public class Test &#123; public static void main(String[] args) &#123; String a = "hello2"; final String b = getHello(); String c = b + 2; System.out.println((a == c)); //false -&gt; &#125; public static String getHello() &#123; return "hello"; //这个是可变的 &#125;&#125; 插入：java判断两个字符串是否相等 不能用==来判断是够相同，因为String是对象类型，两个对象不一样，比较的是内存地址，所以不一样 a.equals(b) Java创建字典 关键字：HashMap&lt;Integer,String&gt; map=new HashMap&lt;Integer,String&gt;(); 添加元素 map.put(1,&quot;a&quot;); 注意：Java的map里面不能用primitive的数据类型，要改成封装类型来做 Step06ObjectOrientedTestprotected和private 如果希望被外部访问，那么一定要用public 如果希望被不同包下的子类访问，可以用protected或者public 如果要被本包下的其他类访问，可以不装饰，或者用上面两个 如果不想被任何外部类访问，那么必须用private default可以被类内部+同一包内访问（比protected少一个子类） ###抽象类（abstract）作为方法的参数和返回值 作为方法的参数传递：必须传递一个子类的对象 作为返回值传递：必须返回子类的对象 关于继承 当子类继承父类的时候，就获得了父类里面的属性和方法，子类中就不存在重复的代码，提高代码复用性 Java不能一个子类继承多个父类，但是可以多重继承（A继承B继承C）-&gt; 和c++的区别12345class 父类 &#123;&#125; class 子类 extends 父类 &#123;&#125; 继承的特性 子类可以拥有父类的非private的属性和方法 子类可以对父类的方法进行扩展 子类可以用自己的方式来实现父类的方法 关键字 implements可以变相的实现继承多个接口 1234567891011public interface A &#123;。//接口不能有自己的实例，对类的行为进行约束 public void eat(); public void sleep();&#125; public interface B &#123; public void show();&#125; public class C implements A,B &#123; //中间用逗号分隔开&#125; super可以实现对父类成员的访问（引用当前对象的父类）。this指向自己的引用。可以有和父类名字相同的函数 123456789101112131415161718192021222324class Animal &#123; void eat() &#123; System.out.println("animal : eat"); &#125;&#125; class Dog extends Animal &#123; void eat() &#123; System.out.println("dog : eat"); &#125; void eatTest() &#123; this.eat(); // this 调用自己的方法 super.eat(); // super 调用父类方法 &#125;&#125; public class Test &#123; public static void main(String[] args) &#123; Animal a = new Animal(); a.eat(); Dog d = new Dog(); d.eatTest(); &#125;&#125; 123animal : eatdog : eatanimal : eat 构造器 子类是不能继承父类的构造器（构造方法/构造函数），只是调用 如果父类构造器带参数，子类必须用super关键字来调用 如果父类构造器不带参数，子类会自动调用父类的构造器 父类new子类 父类 = new 子类，初始化为子类 调用的是子类的方法，但是子类有父类里面没有的方法不能调用 override@override：子类对父类进行重新编写 参数必须完全相同 返回值可以不同，但必须是父类的派生 如果父类里面是public，子类里面不能比public更低 final不能重写 static不能重写，但是可以被再次声明 如果子类和父类在一个包，子类可以重写所有父类的方法，除了private和final 如果不在一个包，那么只能重写public和protected 构造方法不能被重写 Interface 抽象方法的集合，一个class可以通过继承interface来继承接口的抽象方法 不能实例化 没有构造方法 必须是抽象方法 不包含成员变量，除了final和static 接口不是被类继承了，是被类实现了 接口可以继承接口，一个接口也可以继承多个借口1234567891011121314151617181920212223242526272829303132[可见度] interface 接口名称 [extends 其他的接口名] &#123; // 声明变量 // 抽象方法&#125;/* 文件名 : Animal.java */interface Animal &#123; public void eat(); public void travel();&#125;/* 文件名 : MammalInt.java */public class MammalInt implements Animal&#123; public void eat()&#123; System.out.println("Mammal eats"); &#125; public void travel()&#123; System.out.println("Mammal travels"); &#125; public int noOfLegs()&#123; return 0; &#125; public static void main(String args[])&#123; MammalInt m = new MammalInt(); m.eat(); m.travel(); &#125;&#125; interface存在的意义：把使用接口的人和实现接口的人分开，这样用的人不用关心是怎么实现的，实现的人也不用关心影不影响别人用 interface和class的类型转换：因为接口不可以实例化，但是可以将接口初始化为类 123public class B implements A&#123;&#125; A a = new B(); //引用变量a被定义为A接口类型,引用了B实例 A a = new A(); //错误,接口不允许实例化 instanceof二元操作符，测试左边是不是右边类的实例 12子类 instanceof 父类 == true父类 instanceof 子类 == false 抽象类和interface 抽象类也不能被实例化 抽象类里面可以写非抽象的实现方法，这样可以避免在子类里面复用 和普通的class相比，抽象类仅仅作为parent来使用 Step07ExceptionTestException的层次 所有异常都是从Exception继承的子类 Exception是Throwable的子类，除了Exception之外，还有一个子类是Error。Error表示的是运行环境发生的错误 Exception包括两个主要子类，IOException和RuntimeException 返回异常的信息种类 getMessage:返回详细的错误信息 getCause：返回代表异常的原因。如果是多层的会显示最底层的？ toString：返回串类的名字 printStackTrace：打印错误输出流 getStackTrace：返回包含堆栈的数组 fillInStackTrace 例子：捕捉IO的异常123456789101112131415161718192021public void test_exception_checkedException_basic() &#123; FileWriter fw = null; //需要在外面声明，不然finally里面没有反应 try &#123; fw = new FileWriter("/ssa/demo.txt"); //错误的路径 fw.write("abcdefg"); &#125; catch (IOException e)&#123; log(e.getMessage()); &#125; finally &#123; //考虑到可能在打开之后出现exception，所以最后一定要关上 try&#123; if(fw!= null)&#123; fw.close(); //创建不成功的时候，就不能关闭了，也要捕捉这个地方的异常 &#125; &#125; catch (IOException e)&#123; log(e.getMessage()); &#125; &#125; &#125; ###异常处理在处理异常的时候有两种不同的方法 抛出异常 系统自动抛出异常 throw throws 捕捉异常 throws/throw关键字 throw e，一般用于程序员主动抛出的特定种类的异常，throw new e 执行throw一定是抛出了某种异常 e.getMessage()可以得到这个异常里面的信息 throw new RuntimeException(&quot;&quot;,e) 把异常包在一个异常里面跑出，由上方解决 throws在声明方法的时候抛出的异常，出现在函数头 表示运行这个函数可能会出现异常的一种可能，并不一定会发生12345678910111213public static void function() throws NumberFormatException&#123; String s = "abc"; System.out.println(Double.parseDouble(s)); //尝试转换 &#125;public static void main(String[] args) &#123; try &#123; function(); &#125; catch (NumberFormatException e) &#123; System.err.println("非数据类型不能转换。"); //e.printStackTrace(); &#125;&#125; Java里面try和catch的用法 用处：可以捕获异常，放在异常容易发生的地方，保护代码 catch不能独立于try finally不是强制的 中间不能掺杂其他部分的代码 try后面catch和finally必须有一个 当在try的里面出现了会出现的异常的时候，catch语句会抓住上面的异常的名字（e1），并且运行catch里面的语句，比如print出来语句 1234567try&#123; // 程序代码，尝试运行的程序&#125;catch(ExceptionName e1)&#123; //Catch 块，对名字为e的异常的处理方法&#125; 也可以用多个catch来抓住不同的异常名字，使用不同的处理方法 可以在最后加上finally的分支，无论是否发生异常，finally的部分都会被执行1234567891011try&#123; // 程序代码&#125;catch(异常类型1 异常的变量名1)&#123; // 程序代码&#125;catch(异常类型2 异常的变量名2)&#123; // 程序代码&#125;catch(异常类型3 异常的变量名3)&#123; // 程序代码&#125;finally&#123; // 程序代码&#125; ####异常需要注意的点 throw只是消极的抛出了异常，并没有处理，如果可以一定要用try来处理异常 try抓到了异常之后，一定要用catch进行处理，至少print出来 如果是IO的异常，要在最后的finally里面关闭输入输出流 如果在函数体内抛出了异常，最好在函数名加上throws，交给上层函数来处理 得到错误的行号123456try &#123; //一些操作 &#125; catch (exception的种类 e) &#123; StackTraceElement stackTraceElement= e.getStackTrace()[0]; //得到首歌错误的信息 log(stackTraceElement.getLineNumber()); //打印行号 &#125; 多层exception的异常传递 需要把异常一层一层传递上去 当class一层套一层的时候，很需要每一层都把exception传递上去，不然的话会很难判断哪里出了问题 传递的时候需要在throw里面带着Throwable的参数e，不然的话不会把状况传递下去的（注意在自己定义exception class的时候也需要加上这样的方法） 自己写的可以从系统的except里面继承，然后直接super父类的方法 logger 目的：在写代码的时候，需要print出来很多需要的语句，代码改好了又要删除，logger的存在就是为了取代System.out.println() 可以设置输出样式 可以设置输出级别，比如只输出错误日志 可以被定向到文件12private static final Logger logger = LoggerFactory.getLogger(St7BasicExceptionThrower.class);logger.debug("park"); Step08Java8FunctionTest Java8的特性，允许把函数作为方法的参数 123(parameters) -&gt; expression或(parameters) -&gt;&#123; statements; &#125; 可选类型声明，可以不声明参数的类型 一个参数不需要定义圆括号，多个参数需要 如果函数体只有一个参数，不需要大括号 如果主体只有一个表达式，会自动返回返回值 1234567891011//1.() -&gt; System.out.println("Hello Lambda");//2.number1 -&gt; int a = number1 * 2;//3.(number1, number2) -&gt; int a = number1 + number2;//4.(number1, number2) -&gt; &#123; int a = number1 + number2; System.out.println(a);&#125; 变量作用域 只能用标记了final外层局部变量-&gt; 不能在lambda的函数里修改作用域之外的变量，会造成编译错误 不允许声明一个和局部变量重名的参数 函数式接口（functional interface） 有且只有一个抽象的方法的接口，和lambda配合使用，必须保证只有一个抽象方法 当目前的条件不想被锁死的时候，可以改成lambda，这样可以在使用的时候直接修改 四个最基础的函数接口 Supplier:数据提供器 提供T类型对象，没有构造器，只有get方法（相当于得到你输入参数的值，也就是得到你写在parameter里面的函数） 不接受任何参数（指前面的括号里是空的），返回一个结果 Function：数据转换器，接收T返回R，提供了apply/compose/andThen/identity的方法 apply：把function的对象运用在输入的参数上，返回计算的结果（相当于apply里给的是真正的参数，lambda里面是如何运行这个参数） Consumer：数据消费器 接收T，没有返回值，通常根据T进行处理，提供accept和andThen accept：override之后里面包括的就是实现的方法。可以不override直接定义consumer的内容Consumer&lt;String&gt; consumer1 = (s) -&gt; System.out.println(s);//lambda表达式返回的就是一个Consumer接口 Predicate：条件测试器，接收T，返回boolean]]></content>
      <categories>
        <category>编程语言</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的lru_cache装饰器，装饰器，可变参数*args]]></title>
    <url>%2F2020%2F03%2F09%2FPython-lru-cache%2F</url>
    <content type="text"><![CDATA[参考链接 Python - lru_cache和singledispatch装饰器 官方文档 今天写算法题dp的自上而下的算法的时候，看到有人用了``@functools.lru_cache这个函数。最神奇的是没用之前我的算法是超时的，用了之后居然就跑出来了 这个函数是什么？根据官方文档，这个函数的定义如下：1@functools.lru_cache(maxsize=128, typed=False) 1234567891011一个为函数提供缓存功能的装饰器，缓存 maxsize 组传入参数，在下次以相同参数调用时直接返回上一次的结果。用以节约高开销或I/O函数的调用时间。由于使用了字典存储缓存，所以该函数的固定参数和关键字参数必须是可哈希的。不同模式的参数可能被视为不同从而产生多个缓存项，例如, f(a=1, b=2) 和 f(b=2, a=1) 因其参数顺序不同，可能会被缓存两次。如果指定了 user_function，它必须是一个可调用对象。 这允许 lru_cache 装饰器被直接应用于一个用户自定义函数，让 maxsize 保持其默认值 128:如果 maxsize 设置为 None ，LRU功能将被禁用且缓存数量无上限。 maxsize 设置为2的幂时可获得最佳性能。如果 typed 设置为true，不同类型的函数参数将被分别缓存。例如， f(3) 和 f(3.0) 将被视为不同而分别缓存。 取这个函数名的意义在于，LRU叫做最久未使用算法，是一种缓存文件的置换方法。这些种方法会使用最久没有被访问的对象作为置换进去的对象。于此相对的方法还有，最近最少使用，非最近使用，先进先出等等算法。 也就是说，这个函数默认会储存128个调用结果。这个函数实现了备忘功能，会避免在传入相同函数的重复计算。超过这个条目的缓存，会根据LRU规则被丢弃掉。可以使cache_clear()来清除缓存 实现场景 比如在一些使用recursion的场景下，会重复调用很多相同参数的函数（我的雅虎网测也是因此没有通过）。使用这种方法可以很好的减少计算量 比如斐波那契的计算，计算31的时候调用函数的次数已经差出了几千倍，时间也差很多 使用的时候记得import functools12345@functools.lru_cache(None)def fib_with_cache(n): if n &lt; 2: return n return fib_with_cache(n - 2) + fib_with_cache(n - 1) 什么是装饰器既然说到了这种装饰器，我就突然发现自己还不知道什么是装饰器。 参考链接 如何理解python装饰器 Python 函数装饰器 核心思想：python万物皆对象，包括函数本身装饰器（decorators） 整体来说，装饰器的作用就是在不影响以前的函数的情况下，提供我们需要的效果。本质上来说，装饰器也是一个python的函数，他可以让其他函数实现额外的功能，而不修改本身的代码。可以用装饰器实现大量复用的功能 装饰器返回的也是函数对象。 一个例子如果现在有一个函数12def foo(): print('i am foo') 但是我想要一个需求，就是记录下来执行日志123def foo(): print('i am foo') logging.info("foo is running") 但是如果在很多个函数中都想要实现这个功能，那么我们需要修改每个函数的内容，加上log的代码。如果这个log的功能只是测试的时候用一下，那么修改的时候还需要把所有的代码再删掉。这时候最开始的想法是写一个新的函数包括这些功能，比如12345678def foo(): print("THIS is foo")def decotator(func): print("start...%s"%func) func()decotator(foo) 但是写成这样挺丑的，而且调用这个函数的时候就变成了不是调用这个函数本身，这时候就需要装饰器来工作。 面函数里面的wrapper是一个函数对象，因为修饰器的参数是函数，wrapper是来解决这个函数还有参数的问题。 这个效果也就等同于foo = Log(foo)，然后调用的时候调用foo(arg)的效果。把这个方法自动化之后就是加上@让他自动变成装饰器了 123456789def Log(func): def wrapper(*args, **kwargs): logging.warn("%s is running"%func.__name__) return func(*args) return wrapper@Logdef foo(): print("this is foo") 在装饰器调用的时候，用@来表示，避免再一次的赋值操作（本来应该是 foo = Log(foo) foo()的这种调用方法。在实现带参数的装饰器的时候，可以给装饰器再套一层。注意函数名带括号和不带括号的区别 12345678def Log(level): def decorator(func): def wrapper(*args,**kwargs): if level == "1": logging.warn("start %s"%func.__name__) return func(*args) return wrapper return decorator 其他的一些 类装饰器：如果装饰器的参数是个类，可以给类写装饰器，可以实现更多的功能 装饰器的顺序，离这个函数越近的越是 可变参数参考上面的参数里面有加了星标的，这个突然发现自己有一点理解不准确，而且这么久了感觉也没怎么用到过。就一起写在这里了总得来说，可变参数就是可以处理不同数量的参数 *args1234567def argsFunc(a, *args): print a print args &gt;&gt;&gt; argsFunc(1, 2, 3, 4)1(2, 3, 4) **kwargs 参数名字前面加两个星号，表示参数会被存放在dict里面，这时候调用这个函数的时候需要输入arg1 = value1, arg2 = value2这种形式 这种的一般会在调用sql的时候用到]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Recursion</tag>
        <tag>Cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode每日一题挑战]]></title>
    <url>%2F2020%2F03%2F05%2Fleetcode%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%E6%8C%91%E6%88%98%2F</url>
    <content type="text"><![CDATA[994 腐烂的橘子2020.3.4链接 在给定的网格中，每个单元格可以有以下三个值之一： 值 0 代表空单元格；值 1 代表新鲜橘子；值 2 代表腐烂的橘子。每分钟，任何与腐烂的橘子（在 4 个正方向上）相邻的新鲜橘子都会腐烂。 返回直到单元格中没有新鲜橘子为止所必须经过的最小分钟数。如果不可能，返回 - 1。 基本思路 刚开始看到这道题感觉像是DP，因为要求的是最短时间，乍一看感觉是找一天最快的路径。但是仔细看了一下发现因为每次传播的时候，都同时向四个方向传播，每个的传播时间也相同，所以不存在最优路径的问题。这么想来的话应该是用BFS 基本流程如下： 在所有橘子腐烂之前，把上波新被传染的橘子放进Queue 遍历Queue里面的橘子，向这个橘子周围一周传染，判断是否有格子，传染结束之后从Queue里面移除 如果所有没有新的橘子可被感染，那么循环结束 实现中的判断如下： 首先遍历所有格子，得到有多少橘子和有多少腐烂的橘子。如果腐烂的橘子总数 == 橘子数，则说明所有的都被感染。反之，循环结束的时候如果没有都被感染，返回 - 1 判断跳出循环条件：没有新的橘子被感染，设定一个counter计算被新感染的橘子数，如果等于0则说明结束了 注意点 如果想从queue里面移除元素，可以用pop。如果用remove的话，需要在for的时候复制一个新的queue，否则报错 基本代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def orangesRotting(self, grid: List[List[int]]) -&gt; int: if not grid: return -1 m, n = len(grid), len(grid[0]) rotten = [] org_num = 0 # 总数 counter = 0 # 坏了的数量 timer = 0 # 第一次遍历找到坏了的 for i in range(m): for j in range(n): if grid[i][j] == 2: rotten.append((i, j)) org_num += 1 counter += 1 elif grid[i][j] == 1: org_num += 1 # 开始扩散 while rotten: # print(rotten) this_counter = 0 for r in rotten[:]: candidate = [(r[0] - 1, r[1]), (r[0] + 1, r[1]), (r[0], r[1] - 1), (r[0], r[1] + 1)] for a in candidate[:]: if a[0] &lt; 0 or a[0] &gt;= m: candidate.remove(a) elif a[1] &lt; 0 or a[1] &gt;= n: candidate.remove(a) for a in candidate: if grid[a[0]][a[1]] == 1: grid[a[0]][a[1]] = 2 rotten.append((a[0], a[1])) counter += 1 this_counter += 1 rotten.remove(r) if this_counter &gt; 0: timer += 1 # print(rotten,timer) if counter == org_num: return timer else: return -1 希望改进的地方 remove的用法感觉有点丑陋，counter的用法也有点丑陋 可以不用while里面的那个counter，直接用queue是否为空来判断 使用pop -&gt; 但是这个不是一个一个判断而是每次会有好几个腐烂的橘子，所以pop不太好用 判断在不在格子里感觉也有点丑陋，能不能在这个格子周围加一圈？ 设定一个四个元素的list来表示这个格子的四周 最后的判断方法也优点丑陋 其实可以直接判断最后的结果里面有没有1，但是这样的话需要增加一次对整个矩阵的循环。但用个数判断也无可厚非 123456789101112131415161718192021222324252627282930313233343536373839404142def orangesRotting(self, grid: List[List[int]]) -&gt; int: if not grid: return -1 m, n = len(grid), len(grid[0]) rotten = [] org_num = 0 # 总数 counter = 0 # 坏了的数量 timer = 0 D = [[1, 0], [-1, 0], [0, 1], [0, -1]] # 找到周围的点 # 第一次遍历找到坏了的 for i in range(m): for j in range(n): if grid[i][j] == 2: rotten.append((i, j)) org_num += 1 counter += 1 elif grid[i][j] == 1: org_num += 1 # 开始扩散 while rotten: this_counter = 0 for r in rotten[:]: i, j = r[0], r[1] for d in D: mat_i, mat_j = i + d[0], j + d[1] if 0 &lt;= mat_i &lt; m and 0 &lt;= mat_j &lt; n and grid[mat_i][mat_j] == 1: grid[mat_i][mat_j] = 2 rotten.append((mat_i, mat_j)) counter += 1 this_counter += 1 rotten.remove(r) if this_counter &gt; 0: timer += 1 if counter == org_num: return timer else: return -1 1103 分糖果22020.03.05链接 排排坐，分糖果。 我们买了一些糖果 candies，打算把它们分给排好队的 n = num_people 个小朋友。 给第一个小朋友 1 颗糖果，第二个小朋友 2 颗，依此类推，直到给最后一个小朋友 n 颗糖果。 然后，我们再回到队伍的起点，给第一个小朋友 n + 1 颗糖果，第二个小朋友 n + 2 颗，依此类推，直到给最后一个小朋友 2 * n 颗糖果。 重复上述过程（每次都比上一次多给出一颗糖果，当到达队伍终点后再次从队伍起点开始），直到我们分完所有的糖果。注意，就算我们手中的剩下糖果数不够（不比前一次发出的糖果多），这些糖果也会全部发给当前的小朋友。 返回一个长度为 num_people、元素之和为 candies 的数组，以表示糖果的最终分发情况（即 ans[i] 表示第 i 个小朋友分到的糖果数）。 基本思路：遍历 while candies大于0就一直分 对每个小孩，每次需要的糖果量是 轮数 * n + 小孩的位置 如果够，分给小孩，继续给下一个 如果不够，全都给小孩，然后break 123456789101112131415161718class Solution: def distributeCandies(self, candies: int, num_people: int) -&gt; List[int]: ans = [0 for i in range(num_people)] counter = 0 while candies &gt; 0: for i in range(1, num_people + 1): candy_need = counter * num_people + i if candy_need &gt;= candies: ans[i - 1] += candies candies = 0 break elif candy_need &lt; candies: ans[i - 1] += candy_need candies -= candy_need counter += 1 return ans 面试题57-2 和为s的正整数序列2020.03.06链接 输入一个正整数 target ，输出所有和为 target 的连续正整数序列（至少含有两个数）。序列内的数字由小到大排列，不同序列按照首个数字从小到大排列。 示例 1： 输入：target = 9输出：[[2,3,4],[4,5]] 自己的思路：数学解法 从结果上来看，其实就是给等差数列求和，（首项+末项）* 项数 / 2 那么首先从2开始到target遍历项数 从数学的角度来说这个应该可以进一步缩减数量，但是为了简单我就直接遍历到target了 注意这里不是从1开始，如果从1开始的话，单个的数字也会被算进去。但是题目要求的是两个及以上的数字 如果可以整除，那么整除的结果应该是 2 首项 + 项数 - 1*。因为是连续数字 这样的话，如果里面可以给首项取整，且首项需要大于0，就能得到相对应的值了。这里我最开始写错了，首项是不需要遍历的 注意我这里的项数从2开始遍历的，所以得到的结果顺序和需要的顺序是反着的，可以从target开始遍历。 12345678910def findContinuousSequence(self, target: int) -&gt; List[List[int]]: result = [] for num_item in range(target,1,-1): if target*2%num_item == 0: new_target = int(target*2 / num_item) first = new_target + 1 - num_item if first &gt; 0 and first%2 == 0: first = int(first/2) result.append([first+i for i in range(num_item)]) return result 另一种思路：滑动窗口 滑动窗口可以来解决字符串或者数组的元素问题，他可以把循环的嵌套的时间复杂度降到单次循环。其实也可以理解成两个pointer的方法。两个pointer只能往右边移动，这样一次遍历就可以访问所有结果 窗口有几种可能： 如果现在的值比target小，右pointer向右移动 如果现在的值比target大，左pointer向右移动（减小和） 如果相等，记录这个值，左pointer向右移动12345678910111213def findContinuousSequence(self, target: int) -&gt; List[List[int]]: result = [] i,j = 1,1 while i &lt; target: temp = (i+j)*(j-i+1)/2 if temp &lt; target: j += 1 elif temp &gt; target: i += 1 elif temp == target: result.append([a for a in range(i,j+1)]) i += 1 return result 因为这里只考虑自然数，不用考虑角标，所以i和j从1开始比从0开始更方便 延伸阅读，面试题57输入一个递增排序的数组和一个数字s，在数组中查找两个数，使得它们的和正好是s。如果有多对数字的和等于s，则输出任意一对即可。链接 之前做滑动块那个做傻了，这个一次还没做出来。 基本思路1是暴力遍历，基本思路2是双指针。但是注意的是双指针需要找到这个题里面需要的规律。比如这个的里面双指针就是一前一后两个指针，不能一起在前面 如果相等，输出 如果大于，j向左移动一位 如果小于，i向右移动一位 12345678910def twoSum(self, nums: List[int], target: int) -&gt; List[int]: i,j = 0,len(nums) - 1 while i &lt; j: if nums[i] + nums[j] == target: return [nums[i],nums[j]] elif nums[i] + nums[j] &gt; target: j -= 1 elif nums[i] + nums[j] &lt; target: i += 1 return [] 面试题59-2 实现队列的最大值2020.03.07链接 请定义一个队列并实现函数 max_value 得到队列里的最大值，要求函数max_value、push_back 和 pop_front 的时间复杂度都是O(1)。 若队列为空，pop_front 和 max_value 需要返回 -1 示例 1： 输入:[“MaxQueue”,”push_back”,”push_back”,”max_value”,”pop_front”,”max_value”][[],[1],[2],[],[],[]]输出: [null,null,null,2,1,2] 分析 如果本身来说实现起来非常简单。push和pop的复杂度都可以做到O(1)，但是遍历寻找最大值的复杂度是O(n) 降低复杂度一共就那么几个思路：第一个是用一个变量来记录最大值，但是这样的话当前最大值如果被pop出去了之后，就无法确定最大值了。第二个就是用空间换时间，使用了一个deque来实现最大值的记录（自己并没有想出来） 相关参考 实现stack求最小值的操作，复杂度为1实现 这个方法也使用了构建一个辅助数组来记录最小值。但是需要注意的是，这里的stack是先进后出的，所以后面的值pop的时候对之前的最小值并没有影响。于是这道题的思路就是 push的时候如果是当前最小就push进辅助数组 -&gt; 辅助数组从上到下依次增大 pop的时候如果当前数组pop的值和辅助数组的顶端的值相同，则一起pop 此题思路 这道题和上面的stack的区别在于queue需要从前面pop出来，所以如果push 2，1。pop 2的时候，按上面一道题的方法辅助数组里面就没有东西了 所以这道题的辅助数组构建应该是从前到后依次减小 如果新push的数字大于辅助数组的最后，则把辅助数组最后一直删除，直到可以放下新的数字。比如 2，1，1，1，3的时候，辅助数组在放3之前是2，1，1，1。但是很明显可以发现，当popleft的时候，如果新的数组里有了3，则之前的2111对最大值就没有了影响。 在pop的时候，如果pop的数字和辅助数组的最左边相同，则辅助数组一起popleft 注意，pop(i)的复杂度是O(n)，包括pop(0)，所以用的时候最好还是建立一个deque然后用popleft的功能 123456789101112131415161718192021222324252627282930from collections import dequeclass MaxQueue: def __init__(self): self.queue = deque() self.assist_queue = deque() def max_value(self) -&gt; int: if not self.queue: return -1 return self.assist_queue[0] def push_back(self, value: int) -&gt; None: self.queue.append(value) while self.assist_queue and value &gt; self.assist_queue[-1]: self.assist_queue.pop() self.assist_queue.append(value) def pop_front(self) -&gt; int: if not self.queue: return -1 temp = self.queue.popleft() if temp == self.assist_queue[0]: self.assist_queue.popleft() return temp 322 零钱兑换链接 给定不同面额的硬币 coins 和一个总金额 amount。编写一个函数来计算可以凑成总金额所需的最少的硬币个数。如果没有任何一种硬币组合能组成总金额，返回 -1。 思路分析 很标准的动态规划题，直接暴力解法的话肯定会爆炸。动态规划由上至下或者由下而上都可以实现 这里的时间复杂度应该是 amout * coins，数字的总数乘以不同的额度数。另一个需要考虑到的点是因为不一定有1块的额度，所以可能拼不出来需要的数据 边缘情况：额度为0，coins为空 自下而上的思路代码 这里踩到了坑主要是我把无法组成数字的位置设定为None，但是组成的硬币枚数为0的时候也表示否，所以not None和not 0都会被判断为true 建立一个大小为amout的数组，每个位置上记录可以组成这个数字的最小枚数。对一个新的数字来说，遍历所有coin的面值，得到一个最小的面值。如果所有的面值都没法得到，则这个数字也没法得到12345678910111213141516def coinChange(self, coins: List[int], amount: int) -&gt; int: # 边缘情况：没有coins，不行。没有amount，返回0 if not coins: return -1 result = [None for i in range(amount+1)] result[0] = 0 for i in range(1,amount+1): min_coin = float("inf") for c in coins: if (i - c &gt;= 0) and (result[i-c] is not None): min_coin = min(min_coin,result[i-c]+1) if min_coin == float("inf"): result[i] = None else: result[i] = min_coin if result[amount] is not None: return result[amount] else: return -1 在上面代码的基础上，可以直接把inf和None认为成一种情况，这样代码可以进一步简化 不用判断result[i-c]是不是None了，因为如果是None，这个值等于inf，那么放在min里面比较的时候也会直接比较出来。 最后返回结果的时候也可以判断是不是inf，是inf就是不行。注意这里要用等于来判断1234567891011def coinChange(self, coins: List[int], amount: int) -&gt; int: # 边缘情况：没有coins，不行。没有amount，返回0 if not coins: return -1 result = [float("inf") for i in range(amount+1)] result[0] = 0 for i in range(1,amount+1): for c in coins: if (i - c &gt;= 0): result[i] = min(result[i],result[i-c]+1) if result[amount] != float("inf"): return result[amount] else: return -1 自上而下的算法 参考了评论区的算法，主要是return写在一行python比较占便宜 使用 functools 模块的 lur_cache 装饰器，可以缓存最多 maxsize 个此函数的调用结果，从而提高程序执行的效率，特别适合于耗时的函数，不使用的时候会超时（None为没有限制）12345678910def coinChange(self, coins: List[int], amount: int) -&gt; int: import functools @functools.lru_cache(None) def recursion(n): if n == 0: return 0 return min(recursion(n-c) if n - c &gt;= 0 else float("inf") for c in coins)+ 1 if not coins: return -1 result = recursion(amount) return result if result != float("inf") else -1 121 买卖股票的最佳时机 2020.03.09链接 给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。 如果你最多只允许完成一笔交易（即买入和卖出一支股票），设计一个算法来计算你所能获取的最大利润。 注意你不能在买入股票前卖出股票。 基本思路 只能买卖一次，所以其实求的就是这个数组里面后面的数字和前面的数字的最大的差值 第一思路，建造一个大小为n天的数组，每个位置上面记录这一天之前的最小的数字。然后用这天的数字减去最小的数字，就是这天的差值，然后在所有差值里面找最大的 进一步简化：因为之前的最小值只会随着时间而减小，而利润的最大值只会随着时间而增大，所以并不需要数组来记录这个结果，可以直接用两个变量来记录结果 12345678def maxProfit(self, prices: List[int]) -&gt; int: if not prices: return 0 MAXProfit = 0 #记录最大利润 minPrice = prices[0] #记录最小值 for i in range(1,len(prices)): #从第二天开始，因为不能当天买卖 MAXProfit = max(MAXProfit, prices[i]-minPrice) minPrice = min(minPrice,prices[i]) #这天价格*之前*的最小值 return MAXProfit 543 二叉树直径 2020.03.10链接给定一棵二叉树，你需要计算它的直径长度。一棵二叉树的直径长度是任意两个结点路径长度中的最大值。这条路径可能穿过根结点。 整体思路 在我最开始思考这道题的时候，我想的是求出两个子树的深度就可以了。但是实际上我理解错了，这个树不一定是完全二叉树。在不是完全二叉树的情况下，可能会有的点为Null，然后这个树不进行下去，所以需要找到就是最深的一条路先，即取max 关于点和路径 在这道题的计算中，要清楚是计算点还是计算线 每次计算路径的时候，线是比点少1的 每次计算深度的时候，需要计算的是两个子树的点树，在加上Root的一个点，即L+R+1，最后求出来的树的最长路径应该是d-1（点树-1） 边缘情况：当树为空的时候，路径长度为0 深度计算： def一个新的函数来计算这个root下面的深度 边缘条件：root为空的时候，长度返回0 recursive左右的子树，得到最长的深度 路径计算： 因为不一定每次的最深子树得到的都是最长的路径，所以定义了一个全局变量来记录路径 path = max(path,R+L+1)，如果现在这个点得到的最大路径大于以前的路径，则更新最大路径 代码实现12345678910111213141516def diameterOfBinaryTree(self, root: TreeNode) -&gt; int: self.d = 1 if not root: return 0 # return self.calcultateDepth(root.left) + self.calcultateDepth(root.right) self.calcultateDepth(root) return self.d - 1import functools@functools.lru_cache(None)def calcultateDepth(self,root): if not root: return 0 L = self.calcultateDepth(root.left) R = self.calcultateDepth(root.right) self.d = max(L+R+1,self.d) return max(L,R)+1 1013 数组分为和相等的三部分 2020.03.11链接给你一个整数数组 A，只有可以将其划分为三个和相等的非空部分时才返回 true，否则返回 false。 形式上，如果可以找出索引 i+1 &lt; j 且满足 (A[0] + A[1] + … + A[i] == A[i+1] + A[i+2] + … + A[j-1] == A[j] + A[j-1] + … + A[A.length - 1]) 就可以将数组三等分。 整体思路 首先，需要注意审题。需要分成三个和相等的序列，且每个部分是连续的。那么每个部分的和都应该是这个数组的和的三分之一 从最初开始遍历数组，如果前i个数字的和是这个三分之一，则继续计算第二部分。如果第二部分也是，那么这个数组符合要求 注意这里第三部分不用再求了。因为已经求出来的target就是这个数组的平均值，如果第一第二部分都符合平均值，那么第三部分则不用再求了 注意代码简洁 代码实现下面的代码写了两种方法，思路是一样的，但是comment了的那种看起来更简洁一点1234567891011121314151617181920212223242526272829303132333435363738def canThreePartsEqualSum(self, A: List[int]) -&gt; bool: if not A or len(A) &lt; 3: return False s = sum(A) if s % 3 != 0: return False target = s//3 # i,n,cur = 0,len(A),0 # while i &lt; n: # cur += A[i] # if cur == target: # break # i += 1 # if cur != target: # return False # j = i+1 # while j &lt; n-1: # cur += A[j] # if cur == 2*target: # return True # j+=1 # return False target_1 = target_2 = target i,j = None, None for a in range(len(A)): target_1 -= A[a] if target_1 == 0: i = a break if i == 0 or i: for a in range(i+1,len(A)): target_2 -= A[a] if target_2 == 0: j = a break if j and j&lt;len(A)-1: return True return False 字符串的最大公因子 2020.03.12链接 对于字符串 S 和 T，只有在 S = T + … + T（T 与自身连接 1 次或多次）时，我们才认定 “T 能除尽 S”。 返回最长字符串 X，要求满足 X 能除尽 str1 且 X 能除尽 str2。 示例 1： 输入：str1 = “ABCABC”, str2 = “ABC”输出：”ABC” 基本思路 这里需要注意，题的名字里就呆着gcd，所以求得时候也和gcd非常相似。这里需要复习一下辗转相除法求gcd。有ab两个数字，每次新输入的数字是b和a%b，如果a%b==0的时候，现在的b就是最大公因数 注意，两个str都是重复的，所以每个str都应该是被gcd填满的 先求gcd的长度，这个长度的求法就是用辗转相除两个str的长度len 其次验证结果是不是： 如果结果符合，对任意str来说，前len个位就应该是需要求的结果 如果结果符合，那么这个结果*（str总长度//gcd）长度应该就和以前的字符串相同 思路拓展 如果 str1 和 str2 拼接后等于 str2和 str1 拼接起来的字符串（注意拼接顺序不同），那么一定存在符合条件的字符串 X。 所以可以先判断有没有gcd 如果有的话，对两个str的长度求gcd，前这个位数就是结果 12345678910111213class Solution: def gcdOfStrings(self, str1: str, str2: str) -&gt; str: m,n = len(str1),len(str2) length_result = self.gcd(m,n) result = str1[:length_result] if result * (m//length_result) == str1 and result * (n//length_result) == str2: return result return "" def gcd(self,a,b): if b == 0: return a return self.gcd(b,a%b) 169 多元数组 2020.03.13链接 给定一个大小为 n 的数组，找到其中的多数元素。多数元素是指在数组中出现次数大于 ⌊ n/2 ⌋ 的元素。 你可以假设数组是非空的，并且给定的数组总是存在多数元素。 思路1（没有写代码） 排序，看中间这个是不是。 因为这道题已经确定了数组里面肯定有这个结果，在极端情况下，多数元素也应该出现在中间这位上面。所以可以直接排序 思路2 hash 如果仅仅使用遍历来求解，那么需要的时间复杂度是n2。但是可以直接用dict来一次遍历计数成功 注意求dict里面value最大时候key的值的写法，活用lambda12345678910class Solution: def majorityElement(self, nums: List[int]) -&gt; int: result = &#123;&#125; for n in nums: if n not in result: result[n] = 1 else: result[n] += 1 # max(result,key = lambda x: x[1]) return max(result,key = result.get) 扩充思路：Boyer-Moore投票算法 时间复杂度n，遍历一次。空间复杂度1，不需要额外的空间。 维护一个变量candidate和一个投票值vote 遍历一次数组 当vote等于0的时候，把当前数字赋给candidate 判断如下条件： 如果当前值等于candidate，那么vote+1 如果当前值不等于candidate，那么vote-1 遍历之后剩下的candidate就是要求的值 可以认为最后的结果的值投票的时候都投正的，非结果的值投票的时候都投反的。因为结果本身是大于一半的数字，所以留下的永远都是要求的结果。 123456789101112class Solution: def majorityElement(self, nums: List[int]) -&gt; int: candidate = nums[0] vote = 0 for n in nums: if vote == 0: candidate = n if candidate == n: vote += 1 else: vote -= 1 return candidate 300 最长上升子序列 2020.03.14链接 给定一个无序的整数数组，找到其中最长上升子序列的长度。 示例: 输入: [10,9,2,5,3,7,101,18]输出: 4解释: 最长的上升子序列是 [2,3,7,101]，它的长度是 4。 思路1，DP 时间复杂度n2，需要进行两个嵌套的遍历 最长上升子序列的定义：子序列不一定是连续的，所以不能直接用一个变量记录最长的长度 创建一个辅助数组，大小和nums相同，记录的是：以这一位结尾的时候，这个数组的LIS的最长长度。 状态转换公式 当以i位结束时，对比这一位和前面的i位的大小，如果这位比前面i位里面的j大，那么说明这位可以加到新的LIS里面去，这位截止的长度是max(length[i],length[j]+1) 如果遍历了所有他前面的位数，都没有比他小的，那么这一位只能作为一个新的LIS的起点，长度为1。由此思考辅助数组的所有位可以直接初始化为112345678910class Solution: def lengthOfLIS(self, nums: List[int]) -&gt; int: if not nums: return 0 n = len(nums) maxLength = [1 for i in range(n)] #记录以这位结尾的时候可以拥有的最大长度 for i in range(1,n): for j in range(0,i): if nums[i] &gt; nums[j]: maxLength[i] = max(maxLength[i],maxLength[j]+1) return max(maxLength) 思路2：贪心+二分查找 对于给定的字符串，还可以进行进一步的优化。考虑到贪心的策略，每次加到LIS里面的最后一个数字都要尽可能的小，这样增长的速度才可以尽可能的小 创建一个辅助数组d[i]，来记录在长度为i的时候，LIS最后一位可以保持的最小值，用len记录这个上升数组的长度 在这里需要注意的是，d[i]是对i单调递增的（可证） 遍历整个数组，更新d和len的值。如果现在的nums[i] &gt; d[len]，那么len++。否则在1到len里面寻找满足d[k-1]&lt; nums[i] &lt; d[k]的下标k，并且更新d[k] = nums[i]. 根据数组单调性，可以二分查找寻找下标，复杂度为logn 进一步解析 实际上，数组d记录的就是长度为len的时候，这个时候LIS最小的尾部元素。 在最初的时候，d的内容就只有nums里面的第一位 遍历所有数组，当当前数字比d的最后一位还大的时候，直接夹加在d的最后 当这个数字比最后一位小的时候，采用二分查找，找到一个可以塞进这个数字的地方，替换之前的数字。也就是说：在长度不变的情况下，把之前的比较大的尾部元素的值采用二分查找刷新成了更新的尾部元素的值 最后返回的值就是LIS的最大值： 即：新数比前面都大的时候，长度加一 新数小于前面的任意长度的时候，替换前面的长度。 可以直接跟尾部数字比，是因为d这个数组单调递增的特性123456789101112131415161718192021class Solution: def lengthOfLIS(self, nums: List[int]) -&gt; int: if not nums: return 0 n = len(nums) d = [nums[0]] for i in range(1,n): if nums[i] &gt; d[-1]: d.append(nums[i]) else: l,r = 0,len(d) - 1 loc = r while l &lt;= r: mid = (r+l)//2 if d[mid] &gt;= nums[i]: loc = mid r = mid-1 else: l = mid+1 d[loc] = nums[i] return len(d) 409 最长回文串给定一个包含大写字母和小写字母的字符串，找到通过这些字母构造成的最长的回文串。 在构造过程中，请注意区分大小写。比如 “Aa” 不能当做一个回文字符串。 注意:假设字符串的长度不会超过 1010。 思路： 注意这这道题是在s里面自由组合 回文的定义是正着读和反着读都一样的文字，所以根据定义可以发现，回文里面有两种情况： 所有数字出现的次数都是偶数次 只有一个数字出现的是奇数次，剩下的都是偶数次 遍历所有的字母，统计每个字母出现的次数。可以用collections.Counter来实现 对于每个字字母来说，增加的长度是这个字母出现的次数v，的v//2 * 2。即如果是偶数个的话就都加进去，如果是奇数个的话就加偶数个 当整体长度为偶数，且新的字母为奇数的时候，可以再加上一位。但是注意这个只加一次，加了之后整体的长度就是奇数位了 123456789class Solution: def longestPalindrome(self, s: str) -&gt; int: res = 0 counter = collections.Counter(s) for v in counter.values(): res += v // 2 * 2 if res % 2 == 0 and v % 2 == 1: res += 1 return res]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构算法经典汇总]]></title>
    <url>%2F2020%2F02%2F04%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%E7%BB%8F%E5%85%B8%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[最近在当数据结构和算法的TA，记录一下老师考试的重点 时间复杂度pass 经典排序看经典排序哪章，主要是merge排序和quick排序插入平常用的比较多，插入排序是前面的已经是排好序的了，后面的插入到前面里面。注意在实现排序的时候，尽量选择交换的方法来实现排序，而不是用创建新的数组的方法 选择排序123456789101112131415def SelectionSort(nums): for i in range(len(nums)): Min = float("inf") index = None for j in range(i, len(nums)): if nums[j] &lt; Min: index = j Min = nums[j] if index != i: temp = nums[i] nums[i] = nums[index] nums[index] = temp return nums 插入排序12345678910111213def InsertSort(nums): n = len(nums) for i in range(1, n): temp = nums[i] j = i while j &gt; 0 and temp &lt; nums[j - 1]: nums[j] = nums[j - 1] j -= 1 if j != i: nums[j] = temp return nums merge排序（这种实现的空间复杂度是n）12345678910111213141516171819202122def Merge(L, R): M = [] while L and R: if L[0] &lt;= R[0]: M.append(L.pop(0)) else: M.append(R.pop(0)) while L: M.append(L.pop(0)) while R: M.append(R.pop(0)) return Mdef MergeSort(nums): if len(nums) &lt; 2: return nums mid = int(len(nums) / 2) L, R = nums[:mid], nums[mid:] Merge(L, R) 快速排序(不占空间版本) 重点：最后才把piv和最前或者最后的交换，先设置一个虚拟的piv的坐标123456789101112131415161718192021def partition(nums, l, r): piv = nums[r] i = l - 1 # 相当于piv的坐标 for j in range(l, r): # 相当于把比piv小的都换到piv（i）的前面去 if nums[j] &lt;= piv: i += 1 nums[i], nums[j] = nums[j], nums[i] # i的虚拟坐标和i的真实坐标right交换，也就是把piv换到最中间 nums[i + 1], nums[r] = nums[r], nums[i + 1] return i + 1def QuickSort(nums, l, r): if l &lt; r: q = partition(nums, l, r) QuickSort(nums, l, q - 1) QuickSort(nums, q + 1, r) Heap其实也就是堆排序，子节点的数值总是小于（或者大于父节点的数值）。通过list来操作，父节点为i的时候，子节点的坐标是 2i + 1 和 2i + 2，子节点为i的时候，父节点的坐标是 floor（（i - 1）/ 2） 1234567891011121314151617181920def HeapSort(nums): for start in range(len((nums) - 2) // 2, -1, -1): MinHeap(nums, start, len(nums) - 1) for i in range(len(nums) - 1, -1, -1): nums[0], nums[i] = nums[i], nums[0] MinHeap(nums, 0, i - 1)def MinHeap(nums, start, end): dad = start child = dad * 2 + 1 while child &lt;= end: if child + 1 &lt;= end and nums[child] &gt; nums[child + 1]: child += 1 if nums[dad] &gt; nums[child]: nums[dad], nums[child] = nums[child], nums[dad] dad = child child = child * 2 + 1 HashDFS BFSKMP，BM(shift table)BM：从最末尾开始匹配，如果最后一个没匹配上，最后一个就是坏字符。 如果单词里没有坏字符，那么直接移动到坏字符后一个 如果单词里有，移动到他们俩对着的（搜索词里面出现的最后一次）12 后移位数 = 坏字符的位置(在搜索词的哪一位) - 搜索词中的上一次出现位置如果"坏字符"不包含在搜索词之中，则上一次出现位置为 -1。 如果后面几位可以匹配上，最后几位就是好后缀。(good suffix)123 后移位数 = 好后缀的位置(算到最后一位) - 搜索词中的上一次出现位置如果只出现了一次，那么这个位置是-1如果有多个好后缀，除了最长的那个，其他的必须出现在头部 在上面两个移动方法中取最大的一个 因为好后缀比较难实现，所以大也可以光用坏字符法则 生成表最牛逼的是，坏字符和好后缀都只和单词有关，和被搜索的东西无关，所以可以实现生成一张表来表示，然后再用的时候直接查 路径规划（prim，dij，krus）把所有的点都设置成未访问的，并且距离是无穷大。只有起始点是访问的，并且距离是0. visited记录已经访问过得点 distance记录这个点和起点的距离每次找不在visited里面，并且距离起点distance最小的点。放入已访问，并且relax所有和这个点连接的点（更新distance）重复这个步骤 python里面直接用字典来记录所有的数据类型就行了 在寻找未得到最优值的点中最小的值时，采用堆优化，其复杂度为O(1)，可以将整个算法的复杂度降为nlog(n) -&gt; 用堆实现的也就是优先队列 上面能够优化的时间复杂度是在“找到不在集合中的离 ss 最近的点”（每个点必须要进入集合才算更新结束，所以大循环的 O(n)O(n) 是无法减小的），我们能否通过一些排序操作，使得能够快速地找到这个点 xx 呢？这里就可以用到一个“小顶堆”的数据结构，它能够在 O(logn)O(log⁡n)（其中 nn 为堆中的元素数量）的时间复杂度内完成插入、删除最小值的操作，在 O(1)O(1) 的时间复杂度内完成取堆内最小值的操作。于是我们可以将上面的查找这一步操作放入到堆中，时间复杂度就能下降到 O(nlogn) 树（最大最小，字母树）C++和python的特点Python:面向对象，解释，通用。标准库比较多。 语法简单，数据结构不需要定义 解释性语言，跨平台的 高级语言，屏蔽了很多底层实现。比如可以自动管理内存 缺点 运行速度慢解释性语言的通病 编译语言和解释语言编译型语言源代码 -&gt; 编译器 -&gt; 最终可执行文件(.exe) -&gt; OS -&gt; CPU 一次编译之后可以无限运行 不能跨平台 可执行程序不能跨平台，同平台可能不兼容 源代码可能也不能跨平台。比如字节长度等问题 解释型语言源代码 -&gt; 解释器 -&gt; OS -&gt; CPU 执行效率低。一般计算机的底层功能都会用C或者C++实现，应用层面才会使用解释性语言 解释器可以把源代码转换成不同的机器码，所以源代码本身是可以跨平台的。解释器不能跨平台 ##C++和python C++更接近于底层，可以直接操作内存。大规模的计算 C++不仅面向对象，也面向过程 python： 快速开发应用程序java： 健壮的大型软件C++： 需求效率的软件C： 操作系统及驱动 面向对象编程的特征面向过程：就是分析出解决问题所需要的步骤，然后用函数把这些步骤一步一步实现，使用的时候一个一个依次调用就可以了。 封装 カプセル化 encapsulation隐藏了某一方法的具体运行步骤，取而代之的是通过消息传递机制发送消息给它。封装是通过限制只有特定类的对象可以访问这一特定类的成员，而它们通常利用接口实现消息的传入传出。 不用知道是怎么实现的也可以用。私有成员不会被访问。 123456789/* 一个面向过程的程序会这样写： */定义莱丝莱丝.设置音调(5)莱丝.吸气()莱丝.吐气()/* 而当狗的吠叫被封装到类中，任何人都可以简单地使用： */定义莱丝是狗莱丝.吠叫() 继承 inheritance在某种情况下，一个类会有“子类”。子类比原本的类（称为父类）要更加具体化私有成员不会被继承，protected的成员会被继承python的私有成员前面加两个下划线。保护乘员前面加一个下划线。前后都加下划线的是系统定义的名字1234类牧羊犬 : 继承狗定义莱丝是牧羊犬莱丝.吠叫() /* 注意这里调用的是狗这个类的吠叫方法。*/ 当一个类从多个父类继承时，我们称之为“多重继承”。如一只狗既是吉娃娃犬又是牧羊犬（虽然事实上并不合逻辑）。多重继承并不总是被支持的，因为它很难理解，又很难被好好使用。 多态 polymorphism指允许不同类的对象对同一消息做出响应。即同一消息可以根据发送对象的不同而采用多种不同的行为方式。很好的解决了应用程序函数同名问题。 12345678910111213141516171819202122类狗开始 公有成员: 叫() 开始 吠叫() 结束结束类鸡开始 公有成员: 叫() 开始 啼叫() 结束结束定义莱丝是狗定义鲁斯特是鸡莱丝.叫()鲁斯特.叫() overload首先说重载（overload），是发生在同一类中。与什么父类子类、继承毫无关系。标识一个函数除了函数名外，还有函数的参数（个数和类型）。也就是说，一个类中可以有两个或更多的函数，叫同一个名字而他们的参数不同。他们之间毫无关系，是不同的函数，只是可能他们的功能类似，所以才命名一样，增加可读性，仅此而已！ override覆盖(override),是发生在子类中！也就是说必须有继承的情况下才有覆盖发生。我们知道继承一个类，也就有了父类了全部方法，如果你感到哪个方法不爽，功能要变，那就把那个函数在子类中重新实现一遍。 机器学习和深度学习机器学习直接来源于早期的人工智能领域，传统的算法包括决策树、聚类、贝叶斯分类、支持向量机、EM、Adaboost等等。从学习方法上来分，机器学习算法可以分为监督学习（如分类问题）、无监督学习（如聚类问题）、半监督学习、集成学习、深度学习和强化学习。 最初的深度学习是利用深度神经网络来解决特征表达的一种学习过程。深度神经网络本身并不是一个全新的概念，可大致理解为包含多个隐含层的神经网络结构。为了提高深层神经网络的训练效果，人们对神经元的连接方法和激活函数等方面做出相应的调整。其实有不少想法早年间也曾有过，但由于当时训练数据量不足、计算能力落后，因此最终的效果不尽如人意。 深度学习需要大量的样本才能很好的解决问题，如果样本数量不够的时候，使用机器学习的方法可以更好的解决问题 机器学习的主要障碍由于以下原因，使用低功率/简单模型是优于使用高功率/复杂模型： 在我们拥有强大的处理能力之前，训练高功率模型将需要很长的时间。 在我们拥有大量数据之前，训练高功率模型会导致过度拟合问题（因为高功率模型具有丰富的参数并且可以适应广泛的数据形状，所以我们最终可能训练一个适合于特定到当前的训练数据，而不是推广到足以对未来的数据做好预测）。 然而，选择一个低功率的模型会遇到所谓的“欠拟合”的问题，模型结构太简单，如果它复杂，就无法适应训练数据。（想象一下，基础数据有一个二次方关系：y = 5 x ^ 2;你无法适应线性回归：y = a x + b，不管我们选择什么样的a和b。 为了缓解“不适合的问题”，数据科学家通常会运用他们的“领域知识”来提出“输入特征”，这与输出关系更为直接。（例如，返回二次关系y = 5 square（x），如果创建了一个特征z = x ^ 2，则可以拟合线性回归：y = a z + b，通过选择a = 5和b = 0）。 机器学习的主要障碍是特征工程这个步骤，这需要领域专家在进入训练过程之前就要找到非常重要的特征。特征工程步骤是要靠手动完成的，而且需要大量领域专业知识，因此它成为当今大多数机器学习任务的主要瓶颈。 深度学习的优点DNN的主要区别在于，你可以将原始信号（例如RGB像素值）直接输入DNN，而不需要创建任何域特定的输入功能。通过多层神经元（这就是为什么它被称为“深度”神经网络），DNN可以“自动”通过每一层产生适当的特征，最后提供一个非常好的预测。这极大地消除了寻找“特征工程”的麻烦，这是数据科学家们最喜欢看到的。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>经典</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity之旋转，欧拉角]]></title>
    <url>%2F2019%2F12%2F24%2FUnity%E4%B9%8B%E6%97%8B%E8%BD%AC%EF%BC%8C%E6%AC%A7%E6%8B%89%E8%A7%92%2F</url>
    <content type="text"><![CDATA[参考资料 如何通俗地解释欧拉角？之后为何要引入四元数？ Quaternion gimbal lock 欧拉角的死锁问题欧拉角 欧拉角的思想就是，在旋转物体的时候，不是完全使用坐标，而是使用相对每个轴的旋转角度 比如在旋转的时候，先绕世界的z轴转一定角度（和世界产生联系），然后再绕自己的坐标轴转两次 欧拉角的三个角度 pitch：俯仰 yaw：偏航 roll：翻滚 在发生着三种旋转的情况下，万向节可以通过自己的调节让中间的物体保持不变 万向节死锁万向节就是一个让物体以单一轴旋转的装置，由彼此垂直的三个平衡环组成，可以让架子里面的物体保持角度不变 在上面的三种旋转情况下，如果有两个方向的转轴重合了，就会失去一个自由度，产生死锁 Quaternion也就是中文里面的四元数（x,y,z,w） 在unity里面，一般使用quaternion来表示物体的旋转，因为使用quaternion不容易产生死锁问题 数学推导挺复杂的，一般在unity里面实际用的时候不一定用得到 注意，在unity里面，四元数的类型是Quaternion，欧拉角的类型是Vector3，注意类型的转换 常用函数性质 eulerAngles：返回这个四元数本身代表的欧拉角。从transform.ratotion里面读取出来四元数之后，可以直接这样转换成欧拉角 x,y,z,w：可以直接返回四元数的数值，但是实际用的时候作用不大 静态方法 public static float Angle(Quaternion a, Quaternion b); 如果有两个东西a和b同时绕着c转，a和c以及b和c之间都会产生角度 返回两个旋转a和b之间的角度（直接返回角度，不用访问四元数） public static Quaternion Euler(float x, float y, float z); 从绕三个周的角度，得到这个旋转的四元数 public static Quaternion Slerp(Quaternion a, Quaternion b, float t); 在a和b的两个旋转里面插入一个新的旋转 t的range是[0,1]，如果是0的话就是和a重合，是1的话就和b重合 这个可以用来作为，从开始到结束，随着时间转动 public static Quaternion FromToRotation(Vector3 fromDirection, Vector3 toDirection); 创建一个rotation，从一个vector3的方向（世界）转到另一个方向 public static Quaternion identity; identity rotation (Read Only). 也就是意味着不转！！！ 四元数的理解和我们在二次坐标系表示复数一样，四元数是一个四次元来表示complex number的概念]]></content>
      <categories>
        <category>Unity</category>
        <category>基础</category>
      </categories>
      <tags>
        <tag>欧拉角</tag>
        <tag>Quaternion</tag>
        <tag>四元数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的request库]]></title>
    <url>%2F2019%2F12%2F18%2FPython%E7%9A%84request%E5%BA%93%2F</url>
    <content type="text"><![CDATA[之前做了个日本的网测题，题目的内容是call一个web上面的api并且返回结果。之前一直不知道这道题是在干什么，这两天终于搞明白了 参考资料 快速上手request文档 GET 和 POST 到底有什么区别？ 关于HTTP协议，一篇就够了 关于request一个Python的第三方库，用于访问网络资源需要导入模块import requests 小知识：http协议（居然现在才发现我连这个都不知道） http是超文本传输协议的缩写，是从www服务器传输超文本到本地浏览器的传输协议 http协议作用于客户端-服务器架构上，浏览器作为http的客户端，通过url向http服务器端（web服务器）发送所有请求，web服务器在接到请求后，向客户端发送响应 特点 简单快捷。客户端请求的时候，只需要request method（包括GET，HEAD，POST等）和url。每种方法规定的客户和服务器的连接类型不同。因为协议简单，所以服务器的程序规模小，反应快速 灵活：允许传输任意类型的对象 无连接：限制每次连接只处理一个请求，收到客户端的应答后断开连接 无状态：对于事物的处理没有记忆能力，所以如果处理的时候需要先前的信息就需要全部重新传输 B/S（浏览器，服务器-广域网），C/S（客户端，服务器-局域网）模式 URL（Uniform Resource Locator）http://www.aspxfans.com:8080/news/index.asp?boardID=5&amp;ID=24618&amp;page=1#name一个URL包括几部分： 协议部分：http:，表示用的这个协议（https是加密的协议） 域名部分：www.aspxfans.com，也可以用IP地址作为域名 端口，用冒号分割，不是必须的 虚拟目录（endpoint），从第一个/到最后一个/，也不是必须的 文件名，从最后一个/到?为止。如果没有？就是到#。如果都没有就是到最后。如果省略的话就是默认文件名 参数部分：从？到#，不是必须的。用来搜索和查询。可以有多个参数，参数之间&amp;相隔 锚部分，从#开始到最后，不是必须的 客户端发送的request当客户端向服务器发送请求的时候，包括以下的四个部分：request line，header，empty line， request data 请求行，会说明method（比如GET），要访问的资源，http版本 请求头部：说明服务器要使用的附加信息（多行） 空行：请求头部后面需要有空行 请求数据（主体），可以为空 服务器响应的response分为状态行，消息报头，空行，和响应正文 状态行：http的版本号，状态码（200），状态消息（ok） 消息报头：客户端需要使用的附加信息 空行 html部分为响应正文 关于状态码 200 ok 成功 3xx 重定向，必须完成更进一步的操作 4xx 客户端错误，请求有语法错误或者无法实现 5xx 服务端错误，服务器未能实现 1234567200 OK //客户端请求成功400 Bad Request //客户端请求有语法错误，不能被服务器所理解401 Unauthorized //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden //服务器收到请求，但是拒绝提供服务404 Not Found //请求资源不存在，eg：输入了错误的URL500 Internal Server Error //服务器发生不可预期的错误503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常 工作原理 客户端（浏览器）连接到服务器，和服务器的http端口简历TCP连接（TCP：一种传输协议） 发送http请求 服务器接收并返回响应 释放连接TCP，可能会由服务器断线，可能会保持一段时间 客户端解析html的内容，显示 小知识：关于post和get GET请求，请求数据会附在URL后面，用？分割（比如传入参数的时候） 如果是英语或数字，原样 如果是空格换成+ 如果是中文或者其他字符，直接把字符串加密得到16进制ASCII 所以GET提交的数据会在地址栏显示出来，但是POST会把结果放在包体里面，不改变 传输数据大小： URL对数据的大小没有限制，但是有些浏览器可能会限制URL的字符长度，导致GET不行 安全性： POST的安全性更高。 但是http本身就是明文协议，所以其实哪个都安全性不高。最主要的方法是https 回到request本身发送请求我们可以使用get命令获取某个网页的信息，然后从名字为r的对象里面得到后续需要的信息我们可以用r.url来打印现在的url等1r = requests.get('https://api.github.com/events') 传递参数requests支持用params关键字来传输参数，参数设置在dict里面12payload = &#123;'key1': 'value1', 'key2': 'value2'&#125;r = requests.get("http://httpbin.org/get", params=payload) 响应内容响应的内容可以用r.text来限时，request会根据http头部的编码对文本进行解码，可以用r.encoding来查看解码类型并且改变 二进制响应内容可以用字节的方式来访问响应体r.content，会自动解码 Json响应内容内置json解码器，可以处理json数据。r.json()如果解码失败，会抛出异常401 原始响应内容r.raw 实际应用所以在一道例题中，需要调用某个网站的api，得到输入数字的hash值 http方法：GET 参数：”q”，生成hash的文字列 响应：两个key的json，分别是’n’和’hash’123456789101112import requests# the input dataparam = 'n'url = 'http://challenge-server.code-check.io'endpoint = '/api/hash'param = &#123;'q': param&#125;r = requests.get(url + endpoint, params=param)# r = requests.get(url)print(r.json())]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>Lib</category>
      </categories>
      <tags>
        <tag>Url</tag>
        <tag>Request</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于链表]]></title>
    <url>%2F2019%2F11%2F18%2F%E5%85%B3%E4%BA%8E%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[虽然链表是一种比较基础的数据结构，但是在实际应用的时候用处没有那么多 链表是一种线性的表，但是不会线性的存储数据 数组存储的时候需要连续存储 单向链表有一个头结点head，指向链表内存的首地址。链表里面的每个节点有两个成员 需要保存的数据val 指向下一个结构的指针next 特点： 查找 对各个点的查找必须从头找起，后续的地址是前节点给出来的。无论访问哪个点都必须从头来 时间复杂度n，和数组相同 插入和删除（优势） 由于链表是不连续的存储，所以在插入和删除的时候，链表不需要大量成员的位移 复杂度1 读取（劣势） 数组因为连续存储，所以可以通过寻址迅速的定位。但是链表不连续，所以必须依据指针持续的遍历 应用 由于有双向链表，单向链表的应用比较少 撤销功能：文本，图形编辑器。用到了链表的删除特性 实现图或者hashMap等高级数据结构 双向链表增加了一个prev节点，相当于多了一个指针，所以用双向链表占的内存更多比如编辑器的undo/redo操作，用双向链表就更好一点。如果是单向的话时间会是n 循环链表链表的末尾指针指向了链表开头比如分时装置 CPU处理多个用户的请求时产生抢占资源的情况，需要分时策略 每个用户代表一个节点，会给每个节点分配一定的处理时间，然后进入下一个节点。 Leetcode链表练习题141 判断单链表是否有cycle思路： in-place的方法，如果两个人一起跑步，一个快一个慢，那么总有一个时刻快的会把慢的套圈12345678910class Solution: def hasCycle(self, head: ListNode) -&gt; bool: fast = head slow = head while slow and fast and fast.next: slow = slow.next fast = fast.next.next if fast == slow: return True return False 24 交换两个相邻的node思路： 注意这个node的交换，不单和目前的部分（目前操作的两个）有关系，还和前面一个点有关系，因为前面一个点的next需要是交换之前的后一个点 注意while时候的条件判断，必须两个点都在的时候才能进行交换 注意d这个附加的点，用这个点可以快速的定位head点 123456789101112131415161718class Solution: def swapPairs(self, head: ListNode) -&gt; ListNode: counter = 0 d = ListNode(-1) d.next = head prev_node = d while head and head.next: curr = head to_swap = head.next prev_node.next = to_swap curr.next = to_swap.next to_swap.next = curr prev_node = curr head = curr.next return d.next 328 把链表的odd位都交换到前面去思路： 判断这个点如果是odd，那么上一个odd的next是现在的点，这个点的下一个指向even的开始点 如果这个点是even，那么上一个even的next是现在的点，这个点的下一个是null 死磕了一个小时的原因： 注意深拷贝和浅拷贝的问题，浅拷贝的时候，改变这个东西的同时，之前的也会改变 注意形成环的问题，一定要注意每个点的input和output的方向都确定了，该赋值0的时候赋值0 注意每次的odd点都应该指向even的起始点 在下一个点会变化的时候，记得及时保存1234567891011121314151617181920212223242526272829303132333435class Solution: def oddEvenList(self, head: ListNode) -&gt; ListNode: start = ListNode(-1) even_start = ListNode(-1) start.next = head if (not head) or (not head.next): return head prev_odd = head prev_even = head.next even_start.next = prev_even counter = 1 while head: curr = head if counter &gt;=3: temp = curr.next if counter % 2 != 0: #odd prev_odd.next = curr curr.next = even_start.next if counter == 3: even_start.next.next = None prev_odd = curr elif counter % 2 == 0:#even prev_even.next = curr prev_even = curr curr.next = None head = temp else: head = curr.next counter += 1 return start.next]]></content>
      <categories>
        <category>基础</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络]]></title>
    <url>%2F2019%2F11%2F05%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[概述网线把主机连接起来互联网把不同的网络连接起来 ISP“互联网服务供应商”从互联网管理机构获得IP地址，拥有通信线路以及路由器等联网设备，个人或机构缴纳一定的费用就可以连入互联网 主机间的通信方式 client-server：客户是服务的请求方，服务器是供应方 P2P：不区分客户和服务器 电路交换和分组交换 电路交换：电话通信系统，需要建立物理链 分组交换：每个分组有首部和尾部，包含了源地址和目的地址等。同一个传输路径上互相不受影响 时延 排队时延：路由器输入和输出队列间的等待时间，取决于通信量 处理时延：主机或路由器受到分组时的处理时间（分析首部，提取数据，进行差错检验等） 传输时延：传输所用的时间 传播时延：在信道中传播用的时间 计算机网络体系结构 五层 应用层：为特定应用提供数据传输，HTTP，DNS等协议（报文） 传输层：为进程提供通用数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。 网络层：为主机提供数据传输服务，网络层把传输层传递下来的报文段或者用户数据报封装成分组。 数据链路层：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。 物理层 OSI 表示层：数据压缩，加密，描述。不必关心各台主机数据内部格式不同的问题 会话层：建立和管理会话 TCP/IP数据链路层和物理层合并为网络接口层]]></content>
      <categories>
        <category>基础</category>
        <category>计算机网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[计算机操作系统]]></title>
    <url>%2F2019%2F11%2F05%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[概述大纲：中断，系统调用，内存管理，进程线程，调度，同步，文件系统，I/O 什么是操作系统 功能上 对用户来说，OS是控制 管理应用程序的运行 为应用程序提供服务 杀死应用程序 对下 资源分配，管理，外设管理（多个资源的协调） 承上启下的作用：层次架构 硬件之上 应用程序（比如办公软件，视频播放软件等等）之下 OS为应用软件提供服务支撑 分为两部分：shell部分，对外的接口。kernel部分，也就是OS的本身 kernel部分 CPU管理，进程线程 内存管理（物理内存，虚拟内存） 虚拟内存：给上层应用提供尽可能大的内存空间 文件系统管理 （底层相关）中断处理和设备驱动 -&gt; 直接和硬件打交道 操作系统的特征 并发concurrency：同时存在多个运行的程序，需要OS管理和调度 一段时间内，多个程序 并行parallelism：一个时间点上多个程序。一般并行的需要有多个CPU 共享：有效让资源共享给需要的应用程序 对于一个内存单元：一个时间点上只有一个程序访问一个资源 同时访问？互斥共享？ 虚拟：让每个用户都觉得有一个计算机专门为他服务 把一台机器虚拟成多台机器 异步（虽然执行的步骤不同，但是结果也相同） 不是一贯到底的，是走走停停的，向前推荐的速度不可知 但是运行环境相同，OS要保证运行的结果也相同 为什么学习OS 效率，可靠 -&gt; 算法 硬件 良好的硬件管理，合理的资源分配 硬件可以完成很多OS以前关注的问题 需要权衡 时间空间 性能和可预测 公平和性能 经典OS UNIX Linux：移动终端的占有量非常大 Windows 历史]]></content>
      <categories>
        <category>基础</category>
        <category>OS</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指offer]]></title>
    <url>%2F2019%2F11%2F05%2F%E5%89%91%E6%8C%87offer%2F</url>
    <content type="text"><![CDATA[面试的流程 能写单元测试，加分 答非所问，不懂装懂，大忌 准备几个问题 面试的三个环节行为面试 5-10分钟 性格特点 深入了解项目经历 项目介绍方法 简短的项目背景 自己完成的任务（参与 != 负责） 为了完成任务自己是怎么做的 自己的贡献，最好能用数字加以说明 追问问题： 遇到最大的问题是什么，怎么解决 学到了什么 和其他团队成员有什么冲突，怎么解决的 简短的介绍 对技能的分级 了解：只是学过，但是没有做过实际的项目 熟悉： 大部分的技能 精通 不要随便用 如果有人请教这个方面的问题有信心解决，才能用精通 为什么跳槽 NG答案 老板刻薄 同事难相处 加班频繁 工资太低 可以尝试的 对现在的工作失去了激情，需要寻找一份有挑战 技术面试 40-50分钟 基础知识 数据结构，算法，编程语言等 能写出清晰，完整的代码 能思路清晰的解决问题 简单问题-&gt; 清晰代码 复杂问题-&gt; 画图，举例等分析 能从时间空间方面优化代码 主动提问，弄清要求 沟通能力，学习能力，发散思维能力 基础 对一门编程语言的掌握 数据结构 链表，树，栈，队列，哈希表 尤其是链表和二叉树 查找，排序算法等 高质量代码 边界条件，特殊输入 简单的问题需要完整的考虑问题，考虑特殊条件 代码是不是够鲁棒 清晰的思路 举几个简单的例子让自己理解问题 图形抽象数据结构 把复杂的问题分成简单的子问题 优化效率的能力 不能放弃思考 需要知道怎么计算效率 比如斐波那契数列，用top-down就比bottom-up的重复计算多出很多 知道各种数据结构的优缺点 学习能力 最近在看什么书，学习到了什么新技术 抛出一个新概念，理解并解决相关的问题 提问环节 5-10分钟 不要问和自己职位没关系的问题 不要问薪水（指技术面试） 不要立即打听面试的结果 与应聘的职位和项目相关的问题 提前了解公司信息 注意面试时对方介绍的内容 第二章 面试的基础知识编程语言驱动C，linuxCpp，windowsC#，跨平台Java，苹果O-C，小型应用Perl，Python C++ sizeof（也就是拿着准备好的概念题） 空类型的sizeof，instance需要占据一定空间，占用多少编译器决定 给一段代码，看是否能够运行等 定义一个类型或实现类型中的成员函数 相关书籍 Effective C++（面试之前突击） C++ Primer（语法的全面了解） 深度搜索C++对象模型（了解对象内部） The C++ Programming Language（深入了解） C\ 主要会问C++和C#的区别 相关书籍 Professional C#（写给已经有其他经验的程序员） CLR Via C# 数据结构]]></content>
      <categories>
        <category>就职</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[关于docker]]></title>
    <url>%2F2019%2F11%2F05%2F%E5%85%B3%E4%BA%8Edocker%2F</url>
    <content type="text"><![CDATA[Docker Docker入门教程 通俗解释Docker是什么 解决的问题不同的机器有不同的操作系统，库和组件。把一个应用部署到多台机器上需要大量环境配置的操作 主要就是实现隔离性。但是比虚拟机的隔离性好很多 主要解决的问题 硬件性能过剩。在很多时候硬件处于闲置状态 软件冲突 但是在上面的情况下，如果使用多台电脑成本很高，所以在硬件机能过剩的情况下，硬件虚拟化的普及就提出来了 12绝大部分应用，开发者都可以通过docker build创建镜像，通过docker push上传镜像，用户通过docker pull下载镜像，用docker run运行应用。用户不需要再去关心如何搭建环境，如何安装，如何解决不同发行版的库冲突——而且通常不会需要消耗更多的硬件资源，不会明显降低性能。这就是其他答主所说的标准化、集装箱的原因所在。 Docker是对Linux容器（Linux Containers）的一种封装 docker解决的就是环境配置的问题。 对进程隔离，被隔离的进程独立于宿主系统或者其他隔离进程 可以不修改程序代码，不需要学习特定环境的技术，就能实现应用程序部署在机器上 用途 提供一次性的环境。 本地测试他人软件 持续集成时，提供单元测试和构建环境 持续集成指不断的将代码集成到主干上，这样能更快的发现错误 因为使用的时候可以隔离，随意不会对其他的产生影响 提供弹性的云服务：因为可以随开随关 组件微服务架构： 可以在本机模拟出服务器架构 与虚拟机的比较虚拟机是通过模拟硬件，在硬件上安装操作系统从而实现的 启动速度 虚拟机需要先启动虚拟机的操作系统，再启动应用 docker相当于直接启动一个进程，速度快 占用资源 一台机器只能开十几个虚拟机，是一个完整的操作系统，需要占用大量的磁盘，内存和CPU docker只需要相关应用和组件，一台机器可以开成千上万个 优势 容易迁移：打包好的应用在不同的机器上迁移 容易维护：分层和镜像，可以容易复用重复的部分。 容易扩展：可以使用基础镜像扩展得到新的镜像 镜像(imgae)和容器镜像是一种静态的结构，可以看成OOP里面的类。容器是镜像的一个instance镜像包含容器运行时候需要的代码以及组件，是一个分层结构，每一层都是只读的。构建镜像的时候会一层一层的创建，前一层是后一层的基础构建容器的时候，可以在镜像里增加writeable layer，从而保存容器在运行过程中的修改 容器文件 生成容器后，会存在容器文件和image文件。关闭容器不会删除容器文件 如果要完全终止，可以删除容器文件 image文件 docker把应用程序以及他的依赖，打包在image文件里。经过这个文件才能生成docker容器，docker根据这个文件生成容器的实例。 image是二进制文件，实际开发中，image文件一般都会继承另一个image文件，再加上一些个性化设置(image文件是通用的) 制作完成后，文件可以上传网上仓库，比如DockerHub]]></content>
      <categories>
        <category>基础</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python在遍历时删除元素]]></title>
    <url>%2F2019%2F10%2F30%2FPython%E5%9C%A8%E9%81%8D%E5%8E%86%E6%97%B6%E5%88%A0%E9%99%A4%E5%85%83%E7%B4%A0%2F</url>
    <content type="text"><![CDATA[Python语法糖——遍历列表时删除元素 Filter 之前在leetcode刷题的时候，如果用for循环删除list的元素时总会发生问题。由此来总结一下遍历删除元素的各个方法 我比较常用的——建立新的list简单直接的方法可以挺好的解决这个问题，建立一个新的list。如果结果不符合，则跳过这个元素，符合的时候把这个元素加入list。虽然这样显得比较蠢，但是遇到问题的时候比较容易想起来 延伸：遍历拷贝的list。操作原始的list123for i in lst[:]: if i == 0: lst.remove(i) 在这里，lst[:]已经是拷贝之后的结果了，也就是说对原来的lst操作不会对拷贝的结果产生影响 filter 显得比较聪明的一种方法 filter是python里面的一个函数，包括两个参数 function：用于条件判断。这个function可以是之前已经用def定义好的function，也可以是用lamnda简写的function lst：用于输入需要修改的list，参数是一个可迭代的对象1lst = filter(lambda x: x != 0, lst) 也就是说，会先判断x是否不等于0，如果返回值是true，那么保留这个元素。如果返回值是false，则删除这个元素。 列表解析也就是在1行里面写list的方法1lst = [x for x in lst if x != 0] while判断12while 0 in lst: lst.remove(0) 倒序循环 这个方法占用的空间最少 但是可读性比较差 123for i in range(len(lst)-1,-1,-1): if lst[i] == 0: del lst[i]]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>list</category>
      </categories>
      <tags>
        <tag>遍历</tag>
        <tag>删除</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Git]]></title>
    <url>%2F2019%2F10%2F27%2F%E5%85%B3%E4%BA%8EGit%2F</url>
    <content type="text"><![CDATA[Git 什么是分支 Git常用命令 集中式系统和分布式系统Git属于分布式，SVN（subversion）是集中式的系统 集中式只有在中心服务器有一份代码，分布式在每个人的电脑上都有一份代码 集中式版本控制有安全性问题（中心服务器挂了） 集中式需要联网才能工作。 分布式新建分支，合并分支的操作比较快。集中式新建分支相当于复制一份完整代码 中心服务器Github作为中心服务器用于交换每个用户的修改，没有中心服务器也能工作，倒是中心服务器24小时开启方便交流。 工作流 新建仓库之后，目前的目录就成为了工作区。工作区有一个隐藏目录.git，属于Git的版本库 在版本库里面，有一个Stage的暂存区，以及History版本库。在History里面会储存所有的分支，然后会使用HEAD指针来指向目前分区 使用 git add 会把文件添加到暂存区，也就是Stage 使用 git commit 会把暂存区的修改提交到当前的分支里面。提交之后暂存区就清空了 使用 git reset – 会使用现在的分支内容覆盖暂存区，也就是撤销最后一次add的操作 使用 git checkout – 会用Stage的内容覆盖本地内容，撤销最后一次本地修改也可以用复合命令来跳过Stage的部分 如果使用 git commit -a可以直接把文件的修改先加到暂存区，然后再提交 如果使用 git checkout HEAD – 可以取出最后一次修改，也就是对本地文件进行回滚操作 分支的实现在Git里面，使用了指针把每次的提交都连成一条线，HEAD会指向当前的指针 新建分支会在时间线上最后一个节点新建分支，并且HEAD会指向新的分支。而对新的分支的每次提交只会让当前的指针移动，其他的指针不会移动 合并的时候改变的也是Master的指针 关于Git的分支(branch)什么是分支 分支的意义：把现在的工作从主线上分离开，以免影响开发主线（这也是Git最大的优势，因为SVN开发新的分支相当于复制代码，速度非常慢） 为了不影响其他人的开发，可以在主线上建立自己的分支，工作完成后合并到主分支。每一次的提交会被保存，这样发生问题时候的定位就更加容易了 分支的应用 merge分支，为了可以随时发布release而创建的分支。通常大家会把master当成merge分支来使用 Topic分支：为了开发新功能或者修复Bug的分支，从merge里面创建，完成之后需要合并到merge里面去 分支的合并 merge（历史记录会非常复杂） 如果以前的master没有改变，可以直接合并（fast forward） 可以在合并时加上–no-ff来进行Fast forward，加上-m生成一个新的commit 如果直接fast forward可能会丢失分支信息 如果以前的有了新的更新，需要把两个分支修改的内容结合，生成一个新的提交 rebase（历史记录简单，但是可能会导致原来的内容无法正常运行） 如果使用这个方法合并，最后得到的结果会是一条线性的。如果在提交的时候X和Y发生冲突，需要修改冲突的部分 分支的冲突如果两个分支对同一个文件都进行了修改，合并的时候就会产生冲突。把不同分支的内容修改成一样的就可以解决在Git里面会用 &lt;&lt;&lt;&lt;&lt; ===== &gt;&gt;&gt;&gt;&gt;来表示 储藏 Stashing在一个分支上操作之后，如果没有提交这个分支就进行切换，那么在另一个分支上也能看到修改。因为所有的分支都公用一个工作区域。 可以使用 git stash把当前的分支修改储藏起来，这样就可以安全的切换到其他分支 比如，如果正在dev分支上开发，此时有master上面的bug需要修改，但是dev的开发还没有完成。这时候可以新建一个bug分支，并且切换到bug之前先用stash把目前dev的开发进度储存起来 SSH传输设置Git的仓库和Github的中心仓库是通过SSH进行加密的 .gitignore这个文件可以忽略以下的文件： 操作系统自动生成的文件，比如缩略图 编译生成的中间文件 自己的敏感信息。比如存放口令的配置文件 gitignore]]></content>
      <categories>
        <category>基础</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2019%2F10%2F24%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[参考资料： 读懂正则表达式就是这么简单 正则表达式 正则表达式网站 基本概念正規表現（せいきひょうげん、英: regular expression）形式言語分野用于文本内容的查找和替换（差し替える）用于其他语言或者产品软件里面在使用的时候一定要注意转义符号\，不使用这个符号的时候代表的是真实的内容，使用了才有相应的意思 正则字符元符号 被匹配的字符第一个必须和^之后的一样，最后一个必须和$之前的一样 “^”： 匹配行或字符串的起始位置 整个文档的起始位置 ＄：行或者字符串的结尾 \b：用于匹配边界，不消耗字符（Boundary） \bis\b 用来识别is的两边是否是边界 \d：匹配数字（digit） 比如0开头，五位数-&gt; ^0\d\d\d\d\d$ \w：匹配字母，数字，下划线（基本可以理解为注册用户名的要求） \s：匹配空格，\s+可以让空格重复 .：匹配除了转行符号以外的任何字符。\w的加强版，相当于w加上空格 []：匹配在空号内元素的字符，只匹配存在于括号里面的。可以写成[a-z] 反义上面的表达写成大写，如果是[]的话变成[^]，表达的意思是不包括这些的字符 量词有关量词的三个概念： 贪心 * 会首先匹配整个字符串，会选择尽可能多的内容，失败的话就backtracking（消耗最大） 懒惰 ？从起始位置开始尝试匹配，每次检查一个内容，直到检查完所有的内容（相当于遍历） 占有 + 覆盖整个字符串，然后寻找。但是就试一次 相关量词： 贪心* 会重复0次或者更多 ”aaaaa“里面匹配a* ，那么得到的是所有的字符a 重复一次或多次： ”aaaaa“，a+会取字符中所有a值，但是* 可以是0次，+不行 ? 重复零次或一次 ”aaaaa“，a?只会匹配一次，结果也是单个字符a {n}，重复n次，比如a{3}会匹配aaa {n,m} 重复n-m次，比如a{3,4}可以匹配到aaa或者aaaa {n,} 重复n次或更多次，也就是至少重复n次 懒惰限定符（大家和？的排列组合） *？ 重复任意次，但是尽可能少重复 比如 acbacb，正则 a.*?b，只会匹配acb，因为需要.重复的数量尽可能少 +？重复1次或者更多次，但是尽可能少重复 ?? 重复0次或一次，但是尽可能少重复 {n,m}重复n-m次，但是尽可能少重复。比如a{0,m}?取到的是空 {n,}？至少重复n次，尽可能少重复 进阶捕获分组如果给一部分的内容加上了括号，这部分的内容就被抓住了。然后如果后面用到了相同内容的表达式，就可以直接用一个符号代替，而不用继续写一个了。不考虑重复使用的时候，也可以单独只用于分组，分组之后的内容可以加上+ * ？等内容进行重复。但是注意嵌套层数过多会引起歧义常用写法 (exp)：匹配exp。捕获到自动命名的组里面，\1这样的 (?exp)匹配exp,捕获内容并自己命名，后面引用的时候需要 “\k“ (?:exp)：匹配exp，但是不捕获，也不给这个组分配编号 (?=exp)：匹配exp前面的位置 how are you doing，正则(?.+(?=ing))，去ing前面的字符，匹配出来的是how are you do（匹配ing之前的.+） (?&lt;=exp)：匹配后面的位置。比如(?(?&lt;=how).+)，匹配后面的位置，也就是匹配how之后的.+ (?!exp)：匹配后面不跟着exp的位置。比如\d{3}(?!\d)匹配三个数字，然后后面不再跟数字了 (?&lt;!exp)：匹配前面不是exp的位置。(?!&lt;[0-9])123，匹配123，并且123前面不能是数字 例子：分组使用比如匹配IP地址，IP地址由四部分组成，每一部分是0-255的数字。则可以分为以下的部分表示 一位数字 不以0开头的两位数 2开头，第二位是0-4的三位数 25开头，第三位是0-5的三位数1((25[0-5]|(2[0-4]\d)|(1\d&#123;2&#125;)|([1-9]\d)|(\d))\.)&#123;3&#125;(25[0-5]|(2[0-4]\d)|(1\d&#123;2&#125;)|([1-9]\d)|(\d)) 回溯引用比如匹配HTML里面的标题元素1&lt;(h[1-6])&gt;\w*?&lt;\/\1&gt; 其中，h[1-6]被分为一组，这一组的名字叫做\1，也就是说前后的两部分需要一样。h1对h1，h2对h2才能匹配上 替换（需要两个regexp）比如修改电话号码格式313-555-1234 查找的正则式(\d{3})(-)(\d{3})(-)(\d{4}) 需要替换成为的格式（$1）$3-$5。也就是说把第一个正则式中的第1，3，5个括号直接代入了后面替换的格式里面 替换之后的内容 (313)555-1234 大小写转变 \l 把后面跟随的单独的字符改成小写 \u 把单独的字符改成大写 \L 把L之后，E之前的全都变成小写 \U 把U之后，E之前的全都变成大写 \E 结束符号 如，abcd，查找(\w)(\w{2})(\w)，然后改为$1\U$2\E$3 前后查找订好了应该匹配的内容的首尾内容，但是不包括这个首尾内容。也就是前面说到的向前匹配？=和向后匹配?&lt;=.（但是js不支持向后匹配）。如果要找非的条件的时候，需要把=换成! 比如匹配邮箱的@前面的部分 (\w+|.)+(?=@)（这里加上了.，因为我的学校邮箱@前面也是有. 的） 匹配结果： **xu.r.aa**@m.titech.ac.jp 嵌入条件回溯引用判断某个表达式是否匹配，如果匹配的话继续匹配后面的条件1(\()?abc(?(1)\)) 先匹配左括号（(），？来判断左括号有0个或者1个 ？(1)是判断的表达式，也就是说能匹配到左括号的时候，再匹配右括号。 匹配结果：abc（abc）（abc 前后查找条件为首尾是否匹配，如果匹配的话继续（注意首尾不包括在匹配内容里面）1\d&#123;5&#125;(?(?=-)-\d&#123;4&#125;) 首先匹配五位数字 (?=-)表示向前查找-，也就是对-向前查找，作为条件。如果向前查找成功了，那么继续进行后面的操作，也就是匹配一个-，然后匹配一个4位数字44444-444444444-66666]]></content>
      <categories>
        <category>基础</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>正则表达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法：回溯Backtracking]]></title>
    <url>%2F2019%2F10%2F16%2F%E7%AE%97%E6%B3%95%EF%BC%9A%E5%9B%9E%E6%BA%AFBacktracking%2F</url>
    <content type="text"></content>
      <categories>
        <category>算法</category>
        <category>回溯</category>
      </categories>
      <tags>
        <tag>backtracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity练习FlappyBird]]></title>
    <url>%2F2019%2F10%2F02%2FUnity%E7%BB%83%E4%B9%A0Flappy%2F</url>
    <content type="text"><![CDATA[教程及素材源自unity官方的learning资料FlappyBird 整体思路：在游戏里物体本体是不会移动的，只有后面的背景滚轴一直在移动，然后每次在玩家视野外生成随机高度的柱子。柱子和背景一起滚动。 生成鸟的物体sprite sprite是一种半透明的texture。不会直接被用于mesh，而是会用在长方形或者正方形上 修改texture type就可以修改 与canvas render的区别：前者必须放在canvas里面，而后者可以放在hierarchy的任何地方 sprite支持网格构造，可以清除不必要的透明元素，可以一定情况下避免overdraw的问题 sorting layer 在sprite render里面会有一项叫做sorting layer，这个功能可以决定画面的前景和后景的遮挡关系。写的越靠下的越前 rigidbody + collider 需要设置刚体和碰撞关系 这里面的碰撞器设置的种类是多边形的 animator（getcomponent） 在这个游戏里，鸟的不同动作会触发不同的动画，所以需要为这个鸟构建一个动画来表现 在animation里面，可以给鸟不同的动作不同的clip。在运行状态下修改鸟在不同clip里面的renderer。 在animator里面可以设置不同动画之间切换的逻辑关系 一种是根据条件切换，需要为不同的条件设置不同的paramter（这里设定的是trigger，这个状态可以直接在script里面set，注意拼写需要一样）（正常 -按-&gt; 挥动翅膀/ 正常 -撞墙-&gt; 死亡） 一种是根据时间切换（挥动翅膀 -&gt; 正常状态） 鸟的行为逻辑 运动：本身的x轴不会运动，y轴在每次按鼠标的时候上升（addForce），不按的时候重力自由落体（对应上升动画） 碰撞：碰撞到地面或者柱子都会死亡（对应死亡动画） 在鸟死亡的时候，会对应鸟的死亡状态在controller里面的切换 UI制作 UI使用的就是普通的UI模式，注意所有text都是在canvas里面的 导入素材包字体，可以给字体加阴影 UI的分数变化在gamecontroller里面进行操作 字体锚点位置调整需要按alt/option gameControll 设定了一个static的GameControl（这是这个自建类的名字）的object，名字是instance。设定成static之后，无论在哪里的code里面想要访问这个instance，只需要callGameControl.instance就可以了 为了保证里面拥有这个instance，需要在awake的时候进行检查 1234567891011void Awake() &#123; if (instance == null) &#123; instance = this; &#125; else if(instance != this) &#123; Destroy(gameObject); &#125; &#125; 在gameControl里面设置好了游戏结束的变量，这个变量可以直接在bird的script里面访问，这样就可以直接在bird里面决定游戏结束没结束，再在现在的control里面决定分数的变化，scene的切换等 也可以在这里操作，游戏重新开始1234567void Update() &#123; if (gameOver &amp;&amp; Input.GetMouseButtonDown(0)) &#123; SceneManager.LoadScene(SceneManager.GetActiveScene().buildIndex); &#125; &#125; 地面（及背景：作为地面的子物体） 地面应该有collider，这样鸟撞到地面上才会死。需要用rd 地面应该在start开始就按照一个速度进行负移动，如果游戏结束的话，地面停止移动 地面应该复制两份，当每次第一份快要移动到头的时候，第二份移动到第一份前面去（这个距离可以直接用collider的size来决定 地面的rd应该设置成kinematic，也就是除了script让移动，其他的方法不会让他移动 障碍物 障碍物应该设置成prefab，制作好的东西直接拖进prefab文件夹就可以了。在用的时候可以直接在gamecontrol的物体里面操作这个prefab，直接拖进去就可以了 障碍物本身应该增加了一个box collider的trigger，然后在每个柱子本身里面加上了OnTriggerEnter2D(Collider2D other)，也就是在这个trigger的区域里面遇到鸟的时候，会call加分的函数 pool 生成柱子的方法，目前的方法是每次生成五个柱子，存在一个array里面，每次时间到了就随机新的柱子的位置。如果五个柱子都用完了就重头开始，也就是从index是0的柱子开始，重新定位坐标 在初始化五个柱子的时候，用了Object.Instantiate，也就是把这五个柱子在指定的位置复制了五次。其中rotation的参数设置的是Quaternion.identity，也就是没有旋转的意思 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647using System.Collections;using System.Collections.Generic;using UnityEngine;public class ColumnPool : MonoBehaviour&#123; public int ColumnSize = 5; public GameObject columnPrefab; public float SpwandRate = 4f; public float columnMin = -2f; public float columnMax = 2f; private GameObject[] columns; private Vector2 objectPoolPosition = new Vector2(-15f, -25f); private float timeSinceLastSpwand; private float spwandXPosition = 10f; private int currentColumn = 0; // Start is called before the first frame update void Start() &#123; columns = new GameObject[ColumnSize]; for (int i = 0; i &lt; ColumnSize; i++) &#123; columns[i] = (GameObject)Instantiate(columnPrefab, objectPoolPosition, Quaternion.identity); &#125; &#125; // Update is called once per frame void Update() &#123; timeSinceLastSpwand += Time.deltaTime; if (GameControl.instance.gameOver == false &amp;&amp; timeSinceLastSpwand &gt;= SpwandRate) &#123; timeSinceLastSpwand = 0; float spawnYposition = Random.Range(columnMin, columnMax); columns[currentColumn].transform.position = new Vector2(spwandXPosition, spawnYposition); currentColumn++; if(currentColumn == 4) &#123; currentColumn = 0; &#125; &#125; &#125;&#125; 以上，简易版的flappybird就制作完毕了]]></content>
      <categories>
        <category>Unity</category>
        <category>练习</category>
      </categories>
      <tags>
        <tag>Flappy Bird</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日语敬语学习]]></title>
    <url>%2F2019%2F09%2F14%2F%E6%97%A5%E8%AF%AD%E6%95%AC%E8%AF%AD%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[从头开始了解一些经常听到的用法 本日 ＝ 今日 まことに ＝ 本当に ご案内申し上げます ＝ 知らせます ただいま ＝ いま 〜におきまして ＝ で 〜でございます ＝ 〜です 来場する ＝ 会場に来る 敬语的分组 尊敬语：用来描述对方的行为，直接表示敬意 谦让语；描述自己做的事，贬低自己，间接的表示敬意 丁宁语：让整个对话的气氛都变得很丁宁，气氛比较郑重 基本常识 一般来说，礼貌程度可以分成三个阶层，分别是疯狂使用敬语的 -&gt; 使用ですます的 -&gt; 使用普通形态的朋友间的对话 一般来说，对外的人用敬语，对内的人不同敬语 比如有人打电话到了公司，问你的部长在不在，你自己说部长的时候就不用用敬语了 下面开始根据不同的场合使用敬语访问访问时候的特定用语 玄关处 ごめんください すいません 部屋に入る時 お邪魔します 失礼します 失礼いたします 部屋を出る時 失礼します 失礼いたします お／ご〜ください 〜てください的丁宁用法 masu型去masu加上后面的お，或者suru型直接加后面的ご 例子 お入りください お上りください -&gt; 请进的意思 come in おかけください -&gt; 请坐，比如沙发，椅子啥的。和打电话没有关系 日本語でお話しください ご注意ください 注意：这里没有te，不要顺便加上te，没有te，没有！！！！！ つまらないものですが… 一点小东西，不成敬意 更随意的时候可以说（给别人买了吃的的话）：美味しいので買ってきました お〜になります 〜ます的丁宁语，suru的动词不能用这个用法 也就是说一般的动词，如果不是特殊型的话，可以用这个用法代替平常直接用masu 例 この教科書は鈴木先生がお書きになります 社長、今朝の新聞をお読になりましたか 上面的尊敬语的特别变形 食べます -&gt; (🙅‍♀x)お食べになります -&gt; (●)召し上がります します -&gt; (🙅‍♀x)おしになります -&gt; (●)なさいます 見ます -&gt; (🙅‍♀x)お見になります -&gt; (●)ご覧になります 也就是说，如果是三类动词的话，后面的する直接变成なさいます 注意：特别变形如果想用ください的时候，可以直接用特别变形之后的动词加上てください、现在这里是有te的，比如おっしゃってください 请说 被动：更加简单一点的用法 使用和被动态相同的方法来表示尊敬，不用像上面的お〜になります这么麻烦，根据上下文可以推测实际的意思 例 書きます -&gt; 書かれます／ 読みます -&gt; 読まれます 出ます -&gt; 出られます します -&gt; されます／ 来ます -&gt; 来られます 注意：这种用法不能和ください一起用，不能用被动后面加ください，要用ください的话请直接用上面的那个带ください的方法 注意：被动型 不要顺嘴和させ说混 特殊敬语构成表 动词 尊敬语 谦让语 行きます いらしゃいます／おいでになります 参ります／伺います 来ます いらしゃいます／おいでになります 参ります います いらしゃいます／おいでになります おります 言います おっしゃいます （許と）申します／（意見を）申し上げます 見ます ご覧になります 拝見します 食べます／飲みます 召し上がります いただきます 知っています ご存知です 存じております／知っております／（金子部長を）存じ上げております 思います お思いになります 存じます します なさいます いたします くれます くださいます あげます さしあげます もらいます いただきます 会います お会いになります お会いします／お目にかかります 聞きます お聞きになります お聞きします／伺います あります あります ございます 寝ます お休みになります 着ます お召しになります 住んでいます お住まいです 持ちます／持っていきます／持ってきます お持ちになります お持ちします 死にました お亡くなりになりました 〜です でいらしゃいます でございます 〜ています ていらしゃいます でおります 尊敬语和谦让语的总结 句型 尊敬 お／ご〜になります お／ご〜ください 谦让 お／ご〜します 简单用法 只有尊敬语可以用被动来表示尊敬 特别型见表 注意尊敬语： 吃和穿长得差不多，但是吃喝里面不需要前面的お 说里面带促音 虽然想听起来很奇怪，但是真的是这样的 住这个词有些奇怪 死一定是过去式的 注意谦让语 来和去都可以是 参。 但是去还有伺う。同时伺う还有听的意思 存じ 在知道和想里面都可以用，注意区别。知道是te型的，所以是おります 打招呼经常使用的あいさつ 朝 おはようがざいます おはよう 会社から帰り時 それでは、お失礼にします／失礼いたします じゃ、お先に お礼 ありがどうございます -&gt; いいえ／こちらこそ／どういたしまして ありがどう -&gt; ううん／大丈夫だよ 天気 いい天気ですね／暑いですね／雨がよく降りますね -&gt; そうですね いい天気だよ／暑いね／よく降るね -&gt; そうだね 別れる時 失礼します／失礼いたします -&gt; お気をつけて／それではまた じゃあね -&gt; 気をつけてね／じゃ、また 谦让语句型 お〜します／ご〜します 例子 看见拿着东西的社长 お持ちします 说明的时候 ご説明します 我来帮你 お手伝いします 一般使用谦让语的时候都会省略“我”的主语 对于上级的人不能用 てあげる （要用さし上げる） 谦让语特别型 更多见上面的表 例子 メールを拝見しました 駅前で偶然先生にお目にかかりました 例来週の東京へのご出張のことですが、空港までお迎えにまいります／うかがいます ので、ご到着になる（到着される）時間を~存じさせてください~（お知らせください，这里的主语是对方不是自己）。空港で資料をお渡ししますので、車の中でご覧ください。ご昼食の後、会議の場所までお送りします。どうぞよろしくお願いいたします 邀请打招呼 声を掛ける -&gt; 找人帮忙的时候的搭话 部長、すみません いま、よろしいですか／ちょっとよろしでしょうか いま、お時間いただけますか 打听别人的安排 予定を聞く 日曜日、何かご予定がありますか 来週の火曜日、小林さんのご都合はいかがでしょうか 邀请 部長にもぜひ来て頂きたいですか 语气比较强的邀请 部長にもご出席いただけないかと思いまして 后面的思いまして带有表示原因的意思 よろしかったら、部長もいらしゃいませんか よろしければ、部長もいかがでしょうか もしご都合がよろしければ、部長もいかがかと思いまして お／ご〜なく（不是什么词都能用的，后面不要加te） ご心配なく ご遠慮なく お気遣いなく おかまいなく 〜ております ています的谦让语 例子 お返事をお持ちしております 当日お会いできるのを楽しみにしております 例子：邀请老师 よろしければ、先生もいらしゃいませんか／先生も来てきただきたいと思っています 先生のご都合はいかがでしょうか お返事をお持ちしております 请求打招呼 呼びかける あの、ちょっとよろしいでしょうか 今、お忙しいでしょうか お時間いただきてもよろしいでしょうか （実は）〜のですが 持ち帰って我が社のものと検討したいのですが。。。 実は使い方がよくわからないのですが。。。 いただけませんか／ご（お）〜いただけませんか 后面那种说法更好一点，中间可以直接填动词的masu型 この予告編のDVDを一枚お送っていただけませんか 注意这里没有te！！！ 继续请求 日本語訳をつけていただけないかと思いまして 日本語訳をつけていただけるとありがたいんですが。* 思いまして就表示了没说完，但是后面跟着：你能接收我的请求吗的意思 打招呼的方式 朋友 ですます 敬语 ねえ、あのね 可 不可 不可 あの- 可 可 可 悪いんだけど／悪いけど 可 不可 不可 よかったら 可 可 可 すみませんが 不可 可 可 よろしかったら 不可 不可 可 申し訳ありませんが／恐れ入りますが／恐縮ですが 不可 不可 可 文末 朋友 ですます 敬语 ~て（よ／ね） 可 不可 不可 ~てくれない 可 不可 不可 ~てくれませんか 不可 可 不可 ~てもらえませんか 不可 可 不可 ~いただけませんか 不可 可 可 ~いただけませんでしょうか 不可 可 可 ~いただきたいんですが 不可 可 可 ~いただけないかと思いまして 不可 不可 可 ~いただけるとありがたいんですが 不可 不可 可 练习句型 すみませんが、〜ていただけませんか 申し訳ないんですが、〜ていただけるとありがたいんですが 用在非常难以开口请求的郑重恳请的情况下 あのー、〜てもよろしでしょうか 写推荐信 教師の推薦状が必要なのですが、お書きいただけないでしょうか。 先生の研究室にごあいさつに伺いたいと思いまして 先生のご都合がよろしい時間をお知らせいただけるとありがたく存じます 返事をお待ちしております 拒绝 断る〜はちょっと。。。 让对方看到自己为难的样子，知道自己有困难 断る 例1：拒绝的时候说到句尾可以不说清楚 あ、コピー手伝ってくれないか 今、ロビーでお客様が待っていらっしゃるので。。。 例2：句尾用まして（ます）、でして（です）来表示原因 残念ながら今回は伺えないんです。今夜は友人と会う約束がありまして。。。 すみません。お酒はちょっと苦手でして。。。 あります -&gt; ございまして／だ -&gt; でして 謝る 拒绝了以后的道歉 被拜托了事情的时候 お役に立てなくて、申し訳ありません。 被邀请了的时候。请先说谢谢 せっかくお誘いくださいましたのに、（すみません） 拒绝了但是还要保持良好的关系 今回は伺えないんですが、また 今度／次回／次の機会 に お誘いください／ご一緒にさせてください 练习 〜はちょっと苦手でして お誘いくださいましてありがどうございます 残念ながら、その日は山田さんと会議の予定でございます。 申し訳ありませんが、参加できません せっかくのお誘いなのにすみません。 今回は伺えないですが、また今度にお誘いください 申し出る 自己主动提出申请お／ご 〜 （いた）しましょうか 使用自谦语来表示郑重的主动提出，可以让我来干这件事的意思！！没有te 例子 お荷物をお持ちしましょうか 資料をお送り致しましょうか 加藤さんには私からご連絡致しましょうか 〜させていただきます 原本是征求对方许可之后做某事，后来发展成敬语用法（させていただきいてもよろしいでしょうか） 未经许可就用的话有强加的意思 例子 会議の日は昼食を用意させていただきます 今日の午後、会議室を使わせていただきたいんですが 今日は申し訳ないんですが、早めに帰らせていただけませんか このパソコンを使わせていただいてもよろしいでしょうか 〜させてください 表达对方同意之后非常强烈的想做这件事 例子 今 度の仕事は私に担当させてください 今夜は私にごちそうをさせてください お詫びする 道歉道歉常用句 申し訳ありません（でした）／ 申し訳ございません（でした） 大変失礼いたしました ／ ご迷惑をおかけしました ／ どうかお許しください 报告自己的失误 実は、お約束の時間に伺えなくなってしまったんです 11日を21日だと聞き間違えてしまいました 传达反省的心情 以後／今後は気をつけます 二度とこのようなミスをしないように、注意／確認／徹底 いたします 别人对自己道歉的时候 轻松 あ、いえいえ、あまりお気になさらないでください 严肃 こういうのは困ります こういうことをされると困るんですよ これから気をつけてください 句子 お／ご〜してしまいまして、申し訳ございませんでした お／ご〜くださいましたのに、伺えませんで、失礼いたしました（表示的意思是你都邀请我做了，你都准备好了，之类的，但是我做不了） 或者不加o，后面加te也可以 卑微 お忙しい中、お時間を作ってくださいましたのに、時間を間違えてしまいまして申し訳ございませんでした。今後は十分注意いたしますので、お許してください。 提意见问别人的意见 これについてはどう思われますか／この点についてはいかがですか みなさんのご意見は／何かご意見はありますか 用一句话表示赞成和反对 赞成：いいと思います 反対：うーん／それはちょっと。。。／どうでしょうか。。。 开始陈述自己的意见 ちょっと、よろしいでしょうか 说自己的意见 和平的提案（一般用这种） V／Aい のではないでしょうか N／Aな なのではないでしょうか 例 予算がもっとかかってしまうのではないでしょうか 時間が足りなくて、無理なのではないでしょうか 提议 具体的方案 V たらどうかと思います（が） N がいいかと思います（が） 例 時間がかかるので、1ヶ月前から準備したらどうかと思いますが 結婚のお祝いには、二人が長く使えるコーヒーカップなどがいいと思います 归纳意见 それよりも Vた 方がいいと思います それよりももっと簡単に準備できる発表に変えた方がいいと思います 接收意见 〜はいいことだと思いますが／それもそうですが 说明理由忘年会は中華料理がいいのではないでしょうか。というのは、人数が急に増えても大丈夫ですし、若い人はたくさん食べたいという人も多いですし、料理の数も多くで、人気がありますので。。。こちらの方がいいと思います。 整体句型 よろしいでしょうか。〜（な）のはいいことだと思いますが、〜（な）のではないでしょうか。それよりも、〜た方がいいと思いますが、いかがでしょうか。 写邮件 お疲れ様です。アレクスです。 メールを拝見しました。 まず席のことですが、フランス料理はいいと思いますが、一人一人の席が離れていてみんなで話すことできないのではないでしょうか。 人数がまだ決まっていないということですが、それなら人数が変わっても大丈夫な中華料理がいいっと思います。今度のお客様はアジアからのお客様が多いと伺っておりますので、アジア料理の方が慣れていていいのではないでしょうか。 ~中華料理がいいのではないでしょうか。というのは、人数が急に増えても大丈夫し、お客様はアジア料理の方が慣れているかもしれません。~ それよりも、中華料理の方がいいと思いますが、いかがでしょうか。 接收预约〜でございます 接电话 用于说自己或者自己团体的事情 でございます和でいらしゃいます是一个意思，一个用在自己一个用在对方 承ります（うけたまわる） 接受预约 对目上的人接收预约时候的敬语 ご予約、承っております ご予約は、私、鈴木が承りました 〜でいらしゃいます 确定预约的人数或者名字 失礼ですが、田中さんでいらしゃいますか 3名様でいらしゃいますか お元気でいらしゃいますか 不能用在和对方无关的事情上 お／ご 〜 になれますか 在日语里直接问目上的人できます比较失礼，所以用这种方法的比较多。只有当有非常稀奇的技能的时候才会用できます 社長はスペイン語がお話になれますか お／ご〜いただけます ＝ 〜てもらえます（表示的是可以做的意思，没有授受的含义） この建物の中で、wifiがお使いいただけます 特急券をお求めになれば、特急にご乗車いただけます 〜はなさいますか ＝ 〜にしますか ＝ に決めます 料理はどのコースになさいますか させていただきます 再一次确认 用多了会有强迫的意思 ご注文を 繰り返させて／確認させて／復唱させて いただきます 誠に勝手ながら本日は午後七時で閉店させていただきます サービス敬語お／ご〜になりましたら 如果你决定好了的话お決まりになりましたら、お呼びください お／ご〜くださいませ 丁宁的说请求的时候 お一人一枚ずつお取りくださいませ 何かありましたら、ご相談くださいませ ご質問がおありでしたら、お答えいたします お困りでしたら、お手伝いいたします 短语 お決まりでしたら（お決まりになっていましたら）、伺います ご予約をご希望なら（ご希望になるなら）、こちらで承ります 先にお並びの方（お並びになっている方）から順にお入りください 整理券をお持ちですか（お持ちになっていらっしゃいますか） 常用服务用语 お待たせしました かしこまりました お飲み物はいかがいたしましょうか けっこうです接收商量询问别人的想法的时候 对目上询问想干什么的时候，不能用〜したい来问 先生は何を食べたいですか（X) 先生は何を召し上がりますか 先生はどのようなものがお好きですか 提案する 提建议的时候用とか不是很丁宁，変成 など ビールを召し上がるなら、銀座ホールなどはいかがでしょうか 日本文化体験なら、鎌倉のお寺で座禅をなさったらいかがでしょうか ご存知ですか ー 存じております／存じ上げております 对事物的话用前者，对人的话用后者 アスク商事の高橋部長をご存知ですか ー はい、存じ上げております（回答别人问话的时候） ご〜（漢字）です 同样表达尊敬语的意思 何かご心配ですか 明日の会議、ご出席ですか 演讲 发表开始皆まさ、おはようございます。本日は、〜についてお話しします。 对演讲时的观众说话应该用敬语在进入话题之后，比起敬语更应该用desu masu ですから ＝ だから ご存知のように／ご存知の通り 〜られております（考える／言う／評価する） 结束 以上、〜いついて紹介いたしました ご静聴ありがどうございます 面试てまいりました＝てくる 高校生の時日本語の勉強をしてまいりました 私はこれまで、通訳の仕事に田鶴わってまいりました 〜ておりますN私が研究しておりますテーマは、日本語の敬語についてです 〜次第です ＝ 〜んです 御社のビジネスは、私の研究テーマと重なっていると思い、大変興味深く感じた次第です 换种说法| 〜について面白いと思いました | 〜について興味深く感じました || すごく／とても | 大変／非常に || どんな | どのような || 〜できたらいいなと考えています | 〜できたらと考えております || 〜くれたらいいなと思います | 〜くれたらと考えております || 〜したいです | 〜できたらと思います | 自己紹介本日は面接の機会をくださいましてありがとうございます。早速ですが、自己紹介をさせていただきます。私はXXと申します。2018年来日いたしまして、現在、XXXを研究しております。どうぞよろしくお願いいたします。 被问到问题要先回答 はい，不要加那么多犹豫词不要太多的用できます 少しでもお役に立てたらと思います 例私はゲームのプログラムの開発を続けてまいりました。私が使っておりますソフトの開発を多く手がけていらっしゃる御社の事業内容を伺って、非常に興味深く感じました。さらにより良いゲームソフトを開発できたらと考えております。 接电话はい、XXXでございますいつもお世話になっております こちらこそ、お世話になっております （会社名）のXXと申しますが、XX様／役職、いらっしゃいますか名前 はただいま、XX中でございます常用语 不在的时候 XXはただいま席を外しておりまして。。。 让他一会回电 折り返しXXに電話させましょう 接收留言 よろしければ、私がご用件を承りますが。。。 承知いたしました。XXXに申し伝えます。私、XXが承りました 稍后再拨 恐れ入りますが、XX分過ぎにもう一度おかけいただけますでしょうか それでは、XX分後にこちらからおかけします 再一次请教姓名 失礼ですが、もう一度お名前を伺ってもよろしいでしょうか 挂电话 では、失礼いたします 换人接 お電話かわりました。XXです 采访〜中／ところ、ありがとうございます お忙しい中／お寒い中／雨の中、わざわざありがとうございます お急ぎのところ／お疲れのところ／お休みのところ、申し訳ありません 重复对方说的话扩展对方说的话想确认时 今、何とおっしゃいましたでしょうか。／と、おっしゃいますと その〜と言うのは、どのような意味ですか 报告有顺序的报告 まず、XXXについて報告します 以上、概要いついてご報告しました 次に、 その次に／それから 最後に とのことです ＝ そうです 转述听到别人的话请看 ことらの写真をご覧ください ご覧いただくとお分かりのように、。。。 发表感想 。。。と思います 。。。のではないでしょうか た 方がいいと思います 结束报告 以上で報告を終わります 以上、XXXについてご報告しました 何か質問はありませんか／ご質問がおありでしたらどうぞ 司会的敬语虽然是朋友，但是在很多人面前说的时候也要丁宁一点おVです ＝ おVになっていらっしゃいます 皆さんお揃いですので、 皆さんお見えですので、 そろそろ始めたいと思います常用语 大きな拍手でお迎えください 〜さんの前途を祝して／今後のご活躍とご健康を祈って、乾杯をしたいと思います 乾杯の音頭は〜先生にお願いしたいと思います お手元のグラスをお持ちください ごゆっくりお楽しみください ここで一言ご挨拶申し上げます では、〜さまにお祝いのことばをいただきたいと思います そろそろお聞きにしたいと思います 邮件 | 挨拶 | いつもお世話になっております | | お礼 | メール、ありがどうございます | | 始める | では、XXXの件ですが | | 知らせる | 次回は先生をお迎えして下記の通りお食事をすることにいたしました | | お願い | ご検討いただきますようお願いいたします／お目通しくださいますようお願い申し上げます | | 自分の希望 | お目にかかりたいと存じます／ゆっくりお話を伺いたいと存じます／一度おいでいただけたらと存じます | | 終わり | お待ちしております／よろしくお願いいたします／取り急ぎお返事申し上げます | | もとめる | 以上、ご案内／ご招待 申し上げます | | 付け加える | なお、 | 一些一些特定说法家人称呼 我 他 普通 他 敬语 父 ちち お父さん お父様 母 はは お母さん お母様 兄 あに お兄さん お兄様 姉 あね お姉さん お姉様 弟 おとうと 弟さん 弟様 妹 いもうと 妹さん 妹様 夫（おっと）／旦那／主人 ご主人 ご主人様 妻（つま）／家内（かない） 奥さん 奥様 子ども お子さん お子様 息子 息子さん ご子息（しそく） 娘 娘さん お嬢様 人称 ですます 敬語 友達 わたし わたくし わたし／僕／俺 わたしたち わたくしたち わたしたち／僕たち／俺たち 皆さん 皆様 みんな お客さん お客様 客 友人 ご友人 友達 あの人 あの方 あいつ／彼／彼女 お店の人 お店の方 店員 係の人 係の方 係 駅員さん 駅員さん 駅員 アメリカの人 アメリカの方 アメリカ人 公司，人员，学校等 自己的 他人的 弊社（へいしゃ）のXXX／うちのXXX XXX＋职位 弊社／我が社／当社 御社（おんしゃ）／貴社（きしゃ） 本校／当校 御校／貴校 本学（特指大学） 御学／貴学 常用 お／ご 词 动词 お お電話します お約束します お持ちします ご 報告 紹介 遠慮 形容词 お お好き／お嫌い お元気／お疲れ／お急ぎ ご ご健康／ご無理 ご満足／ご不快 名词 お お電話／お写真 お返事／お食事 お手紙／お荷物／お持ち物 お名前／お気持ち お金／お礼／お土産 お弁当／お風呂 お飲み物／お品物 お手洗い お見舞い／お祈り／お祝い ご ご家族／ご夫婦／ご長男 ご住所／ご印鑑／ご予算／ご意志／ご本 ご署名／ご注文／ご計画 ご予約／ご招待 ご出席／ご参加／ご登録／ご入金 ご入学／ご出発 ご結婚／ご関係 日子的说法 普通 敬语 今日 本日 昨日 昨日 さくじつ あした あす／みょうにち おととい いっさくじつ あさって みょうごにち 今年 本年 去年 昨年（さくねん） おととし 一昨年 いっさくねん 1ヶ月 ひと月 副词的转换 普通 敬语 いま ただいま さっき 先ほど 後で 後ほど（のちほど） この間 先日 その日 当日 もうすぐ 間もなく 赶紧开始 さっそく 急いて／すぐに 早急に（さっきゅう）／至急（しきゅう） すぐに ただちに 前に あらかじめ 〜たらすぐに 〜次第、 残念 あいにく ぜひ 丁寧に 丁重に だいたい 概ね（おおむね） 少し 少々（しょうしょう） 动词的转换 普通 敬语 用法 受け取る／もらう 受領する 配送物 受け取る／もらう 拝受する 配送 邮件 信 査収する 确认内容之后查收，自己不用 納める 赠品，贵重物品等 金を払う 納める 税金 送る 送付する 邮寄品，邮件 発送する 配达物 入金する 银行汇款 捺印する 盖章 使う 使用する 物品 利用する 物品，服务 ほしい／したい 希望する 売る 販売する 売り出す 発売する 買う 購入する 求める（もとめる） 読む 拝読する 邮件，信 聞く 拝聴する 意见，演讲 書く 記入する 申请用纸 書く 記す（しるす） 知らせる 通知する 頼む 依頼する 受ける 承る 考える 検討する わかる 承知する／理解する／了承する あきらめる 断念する 忘れる 失念する 帰国する 出社する／出勤する 来自己的公司 退社する／退勤する 下班回家 失礼する 帰宅する 退社／退職する 辞职 開店する 閉店する 来店する 来場する 座る かける]]></content>
      <categories>
        <category>日语</category>
        <category>敬语</category>
      </categories>
      <tags>
        <tag>敬语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构之Tree]]></title>
    <url>%2F2019%2F09%2F14%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84Tree%2F</url>
    <content type="text"><![CDATA[基本作用 树是图的一种，但是不是首尾连在一起的 树的其中一类是从 self-balanced tree BST演变出来的，包括红黑树，AVL，Splay，Treap等等（经常在面试出现但是实际不常用） 另一种大类是 Trie（字典树），能保证字典排序。前缀搜索，正则匹配，数据压缩，构建索引等等用处 二叉树，最基础的结构定义 每个数的节点最多只有两个子节点 子节点分左右，必须不能颠倒 应用环境 hash表，sets 数据库，优先队列 LDAP查找信息，在XML/HTML中进行搜索 不同分支： full binary tree：除了叶节点（也就是一个子节点都没有的点），其他的都有两个子节点 complete binary tree：除了最后一层外，其他层的节点都有两个子节点，最后一层的子节点必须是左对齐 perfect binary tree：形成完美的三角形 BST 二叉搜索树定义 两个子节点里面，左边的必须小于父节点，右边的必须大于父节点 操作 插入： 如果没有任何点，作为root 如果大放到右边的子树，小放到左边的子树 重复2直到找到空位 删除： 删除叶节点：断掉这个点和父节点的联系 删除只有一个子节点的点：把父节点对待删除点的reference改为父节点对待删除点子节点的reference 两个子节点的点：左节点不动，右边的换到父节点的位置上/右节点不同，左节点换到父节点 删除root：需要更改对root的reference 遍历 顺序：左-&gt; 中 -&gt; 右 反序：左 -&gt; 右 -&gt; 中 DFS：中 -&gt; 左 -&gt; 右 平衡二叉树 AVL树 左右两个子树的高度差不超过1 且子树本身也是平衡树 在构建平衡树的时候确保他们平衡，从而导致最差的时间复杂度也是 logN 虽然在插入或者删除的时候，可能会在旋转上花费时间，但是整体性能更加稳定 旋转 对于需要旋转的情况来说，一共有四种基本状况 对于左左或者右右：但旋转 对于左右或者右左：双旋转 红黑树 节点是红色或黑色 叶节点都是黑色的 root是黑色的 每个红节点必须有两个黑子节点，也就是说不能路径上有两个连续的红色 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点 B树定义 用来处理排序后的数据，查找，插入，删除，循序存取都在对数时间完成 对于普通的二叉树，可以有多于两个的节点 优化大块数据的读写操作，加快存取速度 在构建的时候，每一个点的存储数量是有限的，超过上限的时候，本节点分别成三部分，一个往上移动，另外两个分开B+树 只有达到叶节点才算命中，B树可以在非叶命中 更适合文件索引系统 B * 树 节点利用率从 1/2变成了 2/3 Trie树 字典树 hash树的变种，保存大量字符串 利用公共前缀减少查找时间 特点 根节点不包括字符，除了根节点都只包含一个字符 从根节点到某一节点，一路连过去就是相关的字符串 每个节点的子节点的字符都不相同 参考来源 [Data Structure] 数据结构中各种树 初学者应该了解的数据结构： Tree]]></content>
      <categories>
        <category>数据结构</category>
        <category>树</category>
      </categories>
      <tags>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity的shader]]></title>
    <url>%2F2019%2F09%2F14%2FUnity%E7%9A%84shader%2F</url>
    <content type="text"><![CDATA[参考来源这里 定义 shader，着色器，是一段负责将输入的mesh用指定的方式和输入的贴图，颜色等作用，然后输出 输入贴图或者颜色，以及对应的shader，就可以得到一个material，然后将可以把材料给到renderer来进行输出 shader如果是自己来写的话，需要新创建一个shader文件 比如在这里老师写的omniProcam的投影的shader，里面的参数就包括了fisheye相机的参数等等。这部分的参数也就是shader的输入，定义了这个shader需要的属性 需要在里面设定不同的subshader，这部分是代码的主题，在每一个里面包含不同的pass。然后运行的时候会从最优先的着色器开始找。在shader的最后需要一个fallback，也就是说所有的subshader都不能运行的时候，需要一个返回情况 代码讲解1234567891011121314151617181920212223242526Shader &quot;Custom/Diffuse Texture&quot; &#123; Properties &#123; _MainTex (&quot;Base (RGB)&quot;, 2D) = &quot;white&quot; &#123;&#125; &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 200 CGPROGRAM #pragma surface surf Lambert sampler2D _MainTex; struct Input &#123; float2 uv_MainTex; &#125;; void surf (Input IN, inout SurfaceOutput o) &#123; half4 c = tex2D (_MainTex, IN.uv_MainTex); o.Albedo = c.rgb; o.Alpha = c.a; &#125; ENDCG &#125; FallBack &quot;Diffuse&quot;&#125; 属性 Properties里面定义了这个shader的属性，这里面的所有属性将作为input提供给子着色器 _Name(&quot;Display Name&quot;, type) = defaultValue[{options}] 格式 _属性名 “display name” 显示给用户的可读的名字 type属性的类型 颜色，RGBA 2D，2的指数大小的贴图 rect，非2的指数大小的贴图 cube，立方体纹理 range，一个范围里面的数 float，任意一个浮点数 属性的默认值，比如颜色可以设定成“white” opinion项，至少需要在贴图后面加上空白的花括号，只和2d rect或者cube有关系 subshader tag：比如渲染类型，如果是非透明的物体要写在opaque里面，透明的写在transparent里面 LOD：level of detail CGPROGRAM，开始的标记，从这里开始是一段CG程序。和最后的ENDCG是对应的 #pragma surface surf Lambert一个编译指令，声明了要写一个表面的shader，指定了光照模型 sampler2D对贴图进行操作，2d的贴图模型。虽然在之前的属性里面声明过一次，但是因为这里面是cg代码，还是需要重新声明一次 需要在struct里面定义出来需要输入和输出的数据类型 uv：uv mapping指的就是把一个2d贴图上面的点按照一定规则映射到3d模型上。如果在贴图变量前边加上uv.uv_MainTex指的就是提取这个变量的uv值，也就是说二维坐标 surf函数，surf是之前定义的光照模型，有两个参数 In里面的内容是uv值，也就是说每次都会调用贴图上面的坐标点才计算输出 inout是输出值]]></content>
      <categories>
        <category>Unity</category>
        <category>入门</category>
      </categories>
      <tags>
        <tag>shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十大经典排序]]></title>
    <url>%2F2019%2F09%2F03%2F%E5%8D%81%E5%A4%A7%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[参考出自：五分钟学算法 时间复杂度 最好情况 最坏情况 空间复杂度: 需不需要开辟新的空间 排序方式：in-place还是不是in - place 排序稳定性: 也就是之前顺序的东西在排序之后是否还顺序 冒泡排序 前面一个数和后面一个比，如果前面的数比后面的大(或者小)，就交换他们两个 这样交换一次之后的最后一个数就是所有数字里面的最大数 也就相当于最大的数像冒泡一样冒出来了，第一轮过后，第二轮可以直接冒倒数第二个数，也就是说每一轮的内循环次数可以逐渐减少 需要重复n次（但是每次对越来越少的数字进行上述操作），以确保所有的交换都已经完毕了。 增加了一个flag的判断，如果在一轮里面没有任何交换产生，那就说明所有的元素都已经排序完毕了（因为如果还有数字往上冒必然会在前面有交换 这样如果是正序排列的话，可以直接跳出循环，不用进行比较，时间复杂度是n123456789101112131415def bubbleSort(num): n = len(num) for j in range(1, n): flag = True # 如果在这轮没有任何交换，就可以说明排序已经完成了 for i in range(n - j): if num[i] &gt; num[i + 1]: temp = num[i] num[i] = num[i + 1] num[i + 1] = temp flag = False if flag is True: break return num 时间复杂度： 当正序排列的时候，因为可以直接跳出循环，所以只需要遍历一次所有的数保证他们排列正常，所以时间复杂度是n 当倒序排列的时候，需要把所有都移动一遍，所以时间复杂度是 n ^ 2 平均的复杂度是n方 空间复杂度： 因为交换只需要一个额外的temp来储存临时变量，空间复杂度是1 in-place：是的 稳定性：稳定，因为一次换过来的东西就不动了，在判断大小的时候也是判断的大于而不是大于等于，也就是说前面换到后面的大数永远会在后面的数的前面 比如[0, 8, 1, 8, 2]。首先会把第一个8换到第二个8的前面，因为判断条件没有等于，所以越不过去。 选择排序 从所有元素中找到最小（或者最大）元素，然后放到数组的第一个（也就是和数组的第一个交换位置），然后这个就算是固定住了 然后从第二个到最后一个中选择现在最小的，和数组的第二个交换位置，前两个就固定住了 以此类推 12345678910111213141516def SelectSort(nums): n = len(nums) for i in range(n): Min = float("inf") index = None for j in range(i, n): if nums[j] &lt; Min: Min = nums[j] index = j if index != i: # 这样可以减少一些根本不用交换的情况，下一个位置上本来就是最小的 temp = nums[i] nums[i] = nums[index] nums[index] = temp return nums 时间复杂度： 最好情况和最坏情况都不能避免走两个循环，都是n ^ 2 空间复杂度: 1, 来储存temp的值和暂时的最大值的变量 in-place：是的，换位置就可以，不需要单拿出来 稳定： 不稳定，因为在交换位置的时候，并不知道现在的东西被交换到哪里去了 比如：[3, 3, 0, 9]，当0和3交换位置的时候，把第一个3交换到第二个3后面去了 插入排序 在第1轮，认为第1个已经排好序了，然后从第二个开始拿出来，把它放在排好序的里面的合适的位置上 从第二轮开始依次类推，所以还是两个循环 在第i轮里面，前i个元素已经是排好序的了 在插入的过程当中，需要考虑如果把所有的需要移动的数字的坐标都移动一位。这时候比较有效的考虑方法是从最右边开始往左边移动，只要右边的数比现在的temp要大，这一位（实际上这一位指的是j - 1，因为j是移动之后的坐标）就需要移动。移动之后再减1 在所有的都移动结束之后，如果j这个位置和i的位置不一样，就说明发生了插入，那么就是nums[j] = 被插入的数字temp 12345678910111213def InsertSort(nums): n = len(nums) for i in range(1, n): temp = nums[i] j = i while j &gt; 0 and temp &lt; nums[j - 1]: nums[j] = nums[j - 1] j -= 1 if j != i: nums[j] = temp return nums 时间复杂度 最好的时候，不需要插入，最大值直接放在了前面排好序的最右边，也就是没有内循环，n 最差的时候，反序，需要全都循环一遍 n2 空间复杂度 1 in-place 稳定性：稳定，因为如果是[2, 0, 0, 1]，第一个0先插入变成了[0_1, 2, 0_2, 1]，然后插入第二个0的时候因为比较的时候没有比等于，所以会变成[0_1, 0_2, 2, 1] 希尔排序 选择一个序列来对这个数组进行排序，比如如果是10个数，可以是5 2 1这样的，最后一个一定是1（设定的公式是3xn + 1不知道为什么） 然后根据这个序列把数组分成这个序列个数的组，对每组的数字进行插入排序。比如用5分成两份，那就要进行5次，两个之间的排序 一共进行的排序次数是和序列的个数有关的 123456789101112131415161718def ShellSort(nums): n = len(nums) gap = 1 while gap &lt; n / 3: gap = gap * 3 + 1 # 一个神奇的选择方法，也不知道为什么但是确实很好用 while gap &gt; 0: for i in range(gap, n): # 这里执行的是插入排序，和上面的插入排序一样，只不过每次跳gap个了 temp = nums[i] j = i while j &gt; 0 and temp &lt; nums[j - gap]: nums[j] = nums[j - gap] j -= gap if j != i: nums[j] = temp # 直接int就可以向下取整，因为加1并不影响取整效果 gap = int(gap / 3) return nums 关于增量，不同的增量对时间复杂度有不同的影响 目前应用最多的是 Knuth增量:1,4,13,40,…,(3^k - 1)/2，也就是代码里面的这个增量 这时候的复杂度是 N^（3/2） 时间复杂度： 根据不同的步长不同而有所差别，还有的步长还没计算出来复杂度 如果是原版的，也就是原长度一直除2的话 最好效果：n，也就是不需要内循环 最烂效果：n^2 空间复杂度 1 in-place 不稳定，因为很有可能因为分组的不同把两个数的顺序颠倒，比如两组的后面都是3，但是第一组的前一个是2，第二组的前一个是4，这样就把第二个3换到前面去了 归并排序 归并排序是分治法的一个典型的应用，可以把有序的子列合并，然后得到新的有序的子列 比较方法 首先比较两个子列的初始值a[i]和b[j]，把比较小的那个（比如i）放进新的list[k]里面，并且让i和k分别加一，然后继续比较i和j，然后结果放进k里。 如果有一个子列已经取完了，那么可以直接把另一个里面的剩余元素复制到新的list的最后 因为现在使用的子列已经是排好序的了，所以可以使用这种比较方法。初始状态认为每一个数字都是一个单独的子列，所以往上合并的时候都是有序的了 实现： 申请一个新的空间，大小是两个子列的大小之和 两个指针分别从初始位置开始 根据上面的方法移动指针 在实现的过程中需要用到拆分和合并两个步骤 12345678910111213141516171819202122def MergeSort(nums): n = len(nums) if n &lt; 2: return nums middle = int(n / 2) L, R = nums[:middle], nums[middle:] return merge(MergeSort(L), MergeSort(R))def merge(L, R): M = [] i, j = 0, 0 while L and R: if L[0] &lt;= R[0]: M.append(L.pop(0)) else: M.append(R.pop(0)) while L: M.append(L.pop(0)) while R: M.append(R.pop(0)) return M 在python实现中，其实并不需要用坐标表示，可以直接用pop把每次需要取的东西取出来 时间复杂度 无论最好或者最坏的情况都需要把所有东西都比较一回，一共是logn层，每层的实际内容都是n个，所以最终的复杂度是nlog(n)。这样看出来归并排序对于最好和最坏的情况比较稳定 空间复杂度： 临时数组的时间n + recursive的时候的空间logn = O(n) out of place 稳定性：稳定，因为在左边的一定是在左边 快速排序 选取数组的第一个作为标准，然后把比这个标准小的都放在左边，比标准大的都放在右边 然后再分别对左右进行快速排序 注意，在不是python的情况下，需要通过角标互换的方法得到结果 实现 选择一个基准piv 数列最左边的标记为左标记，最右边的标记是右标记 将左标记向右标记移动 如果左标记的值超过了piv的值，停止 移动右标记 当右标记小于piv的时候，停止移动 当左右标记都停止的时候，交换两个数字 然后继续移动，直到两个标记碰到一起，这时候把这个值和piv交换 12345678910111213141516def QuickSort(nums, s, e): if s &lt; e: i, j = s, e piv = nums[i] index = i while i &lt; j: while (i &lt; j) and nums[j] &gt;= piv: j -= 1 while (i &lt; j) and nums[i] &lt;= piv: i += 1 nums[i], nums[j] = nums[j], nums[i] nums[i], nums[index] = piv, nums[i] QuickSort(nums, s, i - 1) QuickSort(nums, j + 1, e) return nums 123456789101112131415161718def QuickSort_1(nums): n = len(nums) if n &lt; 2: return nums temp = nums[0] less, more, equal = [], [], [temp] for i in nums[1:]: if i &lt; temp: less.append(i) elif i &gt; temp: more.append(i) elif i == temp: equal.append(i) # less = [x for x in nums[1:] if x &lt; temp] # more = [x for x in nums[1:] if x &gt; temp] # equal = [x for x in nums if x == temp] return QuickSort(less) + equal + QuickSort(more) 1234567891011121314def QuickSort_3(nums): if len(nums) &lt; 2: return nums i, j = 0, len(nums) - 1 piv = nums[i] index = i while i &lt; j: while (i &lt; j) and nums[j] &gt;= piv: j -= 1 while (i &lt; j) and nums[i] &lt;= piv: i += 1 nums[i], nums[j] = nums[j], nums[i] nums[i], nums[index] = piv, nums[i] return QuickSort_3(nums[:i]) + [piv] + QuickSort_3(nums[i + 1:]) 第一种方法input的时候需要确定最开始和结束时候的index。看起来只有第一种方法是in-place的实现？ 时间复杂度： 最差的时候和冒泡排序是一样的（也就是排好的），这时候的复杂度是n^2 最好的时候是完全平分，这时候是 nlogn 空间复杂度：如果用第一种方法，只耗费recursive时候的空间，也就是logn in-place 不稳定，因为不知道在换的时候就把什么奇奇怪怪的东西换到前面去了 堆排序 一种类似二叉树的设计，子节点的数值总是大于或者小于父节点的数值。首先要让数据形成这样的结构 每次操作的时候，都把root的值和最后一个节点交换，交换后的最后一个节点移动出堆，然后再重新移动堆让他保持上面说的性质 一般通过一维数组来访问 父节点i的左节点：2i+1 父节点i的有节点：2i+2 子节点的父节点： floor（（i-1）/2） 12345678910111213141516171819202122232425def HeapSort(nums): # start是从最后一个父节点开始的,构建出heap for start in range((len(nums)-2)//2,-1,-1): MinHeap(nums,start,len(nums)-1) for i in range(len(nums)-1,-1,-1): nums[i],nums[0] = nums[0],nums[i] # 因为这里换到最后去的数字就已经确定是最大值了，所以再考虑的时候不用考虑他了 MinHeap(nums,0,i-1) return numsdef MinHeap(nums, start, end): dad = start child = dad * 2 + 1 # 如果子节点还在这个堆里面的话 while child &lt;= end: if child + 1 &lt;= end and nums[child] &gt; nums[child + 1]: # 比较两个子节点，选出来更小的那个 child += 1 if nums[dad] &lt; nums[child]: break else: nums[dad], nums[child] = nums[child], nums[dad] dad = child child = dad * 2 + 1 注意：如果是maxheap（即root上的数字是最大的数字的话），实际排出来的是由小到大，因为max的数字在每一次都被换到了最后面 时间复杂度：nlogn 空间复杂度：1 上面的代码可以原地完成的 in place 稳定性：不稳定，这种瞎换的很难搞清楚到底换到哪里去了 计数排序 扫描一遍整个数组，找到最大值max和最小值min，花费时间n 创建一个新的数组，大小是max-min + 1 然后用新数组里面的index来统计每个数字出现的次数，最后整理出来 123456789def CountingSort(nums): Max,Min = max(nums),min(nums) counting = [0 for i in range(Max-Min+1)] result = [] for n in nums: counting[n-Min] += 1 for n,i in enumerate(counting): result += i * [n + Min] return result 12345678910111213141516def CountingSort_2(nums): #并不创建新的数组 Max= max(nums) bucketLen = Max + 1 bucket = [0]*bucketLen sortedIndex = 0 n = len(nums) for i in range(n): # 如果现在的这个位置是空的 if not bucket[nums[i]]: bucket[nums[i]] = 0 bucket[nums[i]] += 1 for j in range(bucketLen): while bucket[j] &gt; 0: nums[sortedIndex] = j sortedIndex += 1 bucket[j] -= 1 不是比较排序，时间上来说比任何比较排序都快 没法用在排序的东西不是数字的情况下，数字差异非常大的情况会很占内存。排序的必须是整数 时间复杂度 n+k，只需要在整个数组里找出最大值和最小值，然后在k时间里面数数每个数字出现了多少次。其中k是这些整数的范围 空间复杂度 k用来储存计数的数组 稳定：为了保证数组的稳定性，需要反向填充数组（现在的方法不能保证稳定性） 桶排序 思想基于上面的计数排序，但是没有分那么多种 主要想法就是先把现在的内容分到k个不同的桶里面，再在每个桶里面分别排序 步骤 把数据分到k个桶里 每个桶的范围是 floor（（max-min+1）/ k） 放入桶的编号为 floor((数字-最小值)/每个桶的范围) 对每个不为空的桶排序 连接每个不为空的桶 时间复杂度： 最好n+k -&gt; 平均分 最差是n^2 都分到一个桶里了 空间复杂度 n+k 稳定，注意先放进桶里的要先拿出来，才能保证稳定 基数排序 radix sort 非比较的整数排序的算法。也可以用在字母上，也就是LSD和MSD 把整数按位切割成不同的数字，然后每个位的数字分别比较。需要把比较的位放进0-9的九个桶里 步骤 所有数统一到一个长度，短的话前面补0 从最低位开始，依据最低位进行排序 一直排到最高位，排序之后就是有序的了]]></content>
      <categories>
        <category>算法</category>
        <category>排序</category>
      </categories>
      <tags>
        <tag>经典排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[unity显示相机画面并在opencv处理]]></title>
    <url>%2F2019%2F08%2F22%2Funity%E6%98%BE%E7%A4%BA%E7%9B%B8%E6%9C%BA%E7%94%BB%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[打开相机显示方法首先需要明确，目前看到的显示图片有两种方法，一种是渲染到实际的gameobject上面去，另一种是draw到GUI上面去。关于gameobject在上一个显示图片里面有了大致的了解。这里主要说的内容包括 相机显示的必备步骤 关于GUI 关于renderer 相机内容显示 在unity中，有一个专门的类叫做WebCamTexture，我们需要为读取进来的相机texture创建一个新的对象。一般来说，需要三个部分，相机纹理，相机名字（string）以及相机是否打开（bool） start部分 在这部分，我们首先需要把创建的cameraTexture实例化 其次，我们需要调用StartCoroutine函数，在其中调用测试函数来确定相机是否打开 StartCoroutine 在一般的执行里面，unity是逐帧运行的，所以当操作花费时间的时候，帧率下降，就会发生卡顿 这部分开始了一个协程（Coroutine），使用yield，可以在任何部分暂停这个Coroutine的执行。如果被成功暂停，它会在下一帧恢复正常。所以这个方法在多帧运行之中非常好用。 unity会假装开辟一个新线程来执行，但是不会影响主线程的持续效果 参考 从这里的功能来说，yield会检查用户有没有授权，如果没有授权的话，运行被终止，跳到下一帧。如果授权成功了的话，运行成功，相机打开。 IEnumerator 在StartCoroutine调用的是一个IEnumerator函数，他通过yield一个bool来决定是不是继续运行这个函数 授权 在test里面需要考虑有没有用户的授权 有授权的情况下，需要把目前的WebCamTexture（注意这里不是建立的实例）的device的数据传递给WebCamDevice，包括类型，名字等等。 然后需要把包括这个相机名字，size和fps的信息传给之前cameraTexture的实例 以上都设定好之后，WebCamTexture.Play会激活这个相机，让他开始工作 然后再讲相机的texture渲染到object的表面上12345678910yield return Application.RequestUserAuthorization(UserAuthorization.WebCam); if(Application.HasUserAuthorization(UserAuthorization.WebCam)) &#123; WebCamDevice[] devices = WebCamTexture.devices; cameraName = devices[0].name; cameraTexture = new WebCamTexture(cameraName, 1024, 768, 15); cameraTexture.Play(); isOpen = true; renderer.material.mainTexture = cameraTexture; &#125; GUI GUI主要是提供了图形化的窗口，实际上显示的元素是直接显示在game画面上的，也就是说这部分是和实际相机拍摄到的画面独立的。无论相机如何移动，物体如何改变，最终GUI的画面都会显示到同样的地方 MonoBehaviour.OnGUI() 注意OnGUI函数并不需要我们自己去调用，不需要再update里面调用！ OnGUI是API里面自带的函数，我们需要在这个函数中渲染和处理GUI的event 在实际应用中，OnGUI可能每一个frame被call很多次，每次event（例如鼠标操作，键盘等等）发生的时候都会call这个函数 例如下面官方的例子，每次鼠标点击的时候，就会print出相应的话来12345678910111213using UnityEngine;using System.Collections;public class ExampleClass : MonoBehaviour&#123; void OnGUI() &#123; if (GUI.Button(new Rect(10, 10, 150, 100), "I am a button")) &#123; print("You clicked the button!"); &#125; &#125;&#125; GUI.DrawTexture 在GUI的实现中，我们需要将相机读取到的部分draw的GUI的上面，所以调用了这个函数 需要确定的参数包括：位置，需要渲染的texture，缩放比例等等 实现 代码部分参考1234567891011121314151617181920212223242526272829303132333435363738394041424344454647using System.Collections;using System.Collections.Generic;using UnityEngine;public class showCamera : MonoBehaviour&#123; protected WebCamTexture cameraTexture; protected string cameraName = ""; protected bool isOpen = false; //protected MeshRenderer renderer; // Start is called before the first frame update void Start() &#123; //renderer = this.GetComponent&lt;MeshRenderer&gt;(); cameraTexture = new WebCamTexture(); StartCoroutine(Test()); &#125; // Update is called once per frame void Update() &#123; &#125; IEnumerator Test() &#123; yield return Application.RequestUserAuthorization(UserAuthorization.WebCam); if(Application.HasUserAuthorization(UserAuthorization.WebCam)) &#123; WebCamDevice[] devices = WebCamTexture.devices; cameraName = devices[0].name; cameraTexture = new WebCamTexture(cameraName, 1024, 768, 15); cameraTexture.Play(); isOpen = true; //renderer.material.mainTexture = cameraTexture; &#125; &#125; void OnGUI() &#123; if(isOpen) &#123; GUI.DrawTexture(new Rect(0, 0, 400, 300), cameraTexture, ScaleMode.ScaleToFit); &#125; &#125;&#125; 渲染到object上面 和之前的操作类似，需要 构建MeshRenderer的object 在start里面读取出物体的MeshRenderer（getcomponent） 最后打开相机后，把相机的内容渲染到MeshRenderer上面 12345678910111213141516171819202122232425262728293031323334353637383940414243using System.Collections;using System.Collections.Generic;using UnityEngine;public class showCamera : MonoBehaviour&#123; protected WebCamTexture cameraTexture; protected string cameraName = ""; protected bool isOpen = false; protected MeshRenderer renderer; // Start is called before the first frame update void Start() &#123; renderer = this.GetComponent&lt;MeshRenderer&gt;(); //cameraTexture = new WebCamTexture(); StartCoroutine(Test()); &#125; IEnumerator Test() &#123; yield return Application.RequestUserAuthorization(UserAuthorization.WebCam); if(Application.HasUserAuthorization(UserAuthorization.WebCam)) &#123; WebCamDevice[] devices = WebCamTexture.devices; cameraName = devices[0].name; cameraTexture = new WebCamTexture(cameraName, 1024, 768, 15); cameraTexture.Play(); isOpen = true; renderer.material.mainTexture = cameraTexture; &#125; &#125; //void OnGUI() //&#123; // if(isOpen) // &#123; // GUI.DrawTexture(new Rect(0, 0, 400, 300), cameraTexture, ScaleMode.ScaleToFit); // &#125; //&#125;&#125; 将图片放入opencv来源 得到了web的texture之后，可以直接用openCV的部分把这个玩意转换成mat，然后处理 这里的问题是刚开始mat的大小莫名其妙的是16，所以需要加上一个判断条件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667using System.Collections;using System.Collections.Generic;using UnityEngine;using OpenCVForUnity.CoreModule;using OpenCVForUnity.UnityUtils;using OpenCVForUnity.ImgprocModule;public class showCamera : MonoBehaviour&#123; protected WebCamTexture cameraTexture; //protected string cameraName = ""; //protected bool isOpen = false; private Color32[] colors; private Mat rgbaMat; private Texture2D tex; // Start is called before the first frame update void Start() &#123; //renderer = this.GetComponent&lt;MeshRenderer&gt;(); //cameraTexture = new WebCamTexture(); //StartCoroutine(Test()); cameraTexture = new WebCamTexture(WebCamTexture.devices[0].name, 640, 480); cameraTexture.Play(); StartCoroutine(init()); &#125; private IEnumerator init() &#123; Debug.Log(cameraTexture.width); if (cameraTexture.width &lt;= 16) &#123; while(!cameraTexture.didUpdateThisFrame) &#123; yield return new WaitForEndOfFrame(); &#125; cameraTexture.Pause(); colors = cameraTexture.GetPixels32(); cameraTexture.Stop(); yield return new WaitForEndOfFrame(); cameraTexture.Play(); tex = new Texture2D(cameraTexture.width, cameraTexture.height, TextureFormat.RGBA32, false); rgbaMat = new Mat(cameraTexture.height, cameraTexture.width, CvType.CV_8UC4); GetComponent&lt;Renderer&gt;().material.mainTexture = tex; &#125; &#125; private void Update() &#123; Debug.Log(cameraTexture.width); if (cameraTexture.didUpdateThisFrame &amp;&amp; rgbaMat != null) &#123; Utils.webCamTextureToMat(cameraTexture, rgbaMat); //Imgproc.cvtColor(rgbaMat, rgbaMat, Imgproc.COLOR_RGB2HSV); Utils.matToTexture2D(rgbaMat, tex); tex.Apply(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Unity</category>
        <category>OpenCV</category>
      </categories>
      <tags>
        <tag>Unity</tag>
        <tag>WebCamera</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程珠玑ProgrammingPearls]]></title>
    <url>%2F2019%2F08%2F20%2F%E7%BC%96%E7%A8%8B%E7%8F%A0%E7%8E%91ProgrammingPearls%2F</url>
    <content type="text"><![CDATA[第一章问题 开始的问题是如何对文件进行排序 -&gt; merge sort 整合问题之后，问题变成了需要对7位数字进行排序，这样的话需要的时间就远小于merge sort了 另一种方法 如果在每个byte里面存一个数字，那么1MB可以存143000左右的号码（e6/7) 但是如果把每个数字表示成一个32位的int（也就是说每7位数存成一个32位的整数，那么这7位数就占4个byte），那么可以存250000左右的号码 从这个角度考虑，快排的速度比merge快 实现 从上面的问题分析来看，用bitmap或者bit vector来表示数据很常见。 比如，可以用一个20bit的string来表示{1,2,3,5,8,13} 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 在这个里面，出现在集合里的数字就表示为1，没有出现的就表示为0 在实际解决问题过程中，7位数字可以表示成一个小于千万的数。如果用一个千万的二进制串来表示，那么如果整个文件里面有现在的号码的时候，这个位才被表示为1，否则就被表示为0 分为三个阶段 关闭所有的位，即千万个位全都是0 从输入文件里面导入所有的数字，比如2897的话，就是b[2897]=1 全部输入完毕之后，再根据现有存在的数字就可以直接排序，输出了 处理原则总原则：在开始处理问题之前分析问题，才能让问题更好解决 确定正确的问题 -&gt; 最重要的一点 选择了bitmap的数据结构：选择这个数据结构是根据电话号码不会重复这个特殊条件得到的 multi-pass 时间和空间的trade off 简单设计 第二章 算法问题1： 如果有最多40亿个排好序的32位浮点数，其中有遗漏的数据，如何找到遗漏的数据。考虑内存足够的时候和内存不够的时候的情况 如果内存足够，可以像第一章说的一样，用位图来表示这些数据，然后看哪些没有 如果内存不够？ 二分查找 必须定义范围，范围里面每个数字的表示方法和探测方法 比如如果把这些数据分成两部分，比如1-10里面取中位数，因为缺数据的原因，总是会有一边的个数少，那么缺的数据就肯定在少的这边 问题2： 将具有n个元素的向量x左旋i个位置，时间上与n成正比，有十几字节的额外空间 直接方法 储存到额外数组 -&gt; 太浪费空间了 定义一个函数将数组每次移动一个位置 -&gt; 太浪费时间了（虽然时间上和n成正比） 另一个思考 把一个数组分成不同的组，每次把对应组的内容转移，直到所有内容都转移成功。比如把x[0]挪出去，x[3]诺到x[0],x[6]挪到3，然后0挪到6。然后再挪x[1]和他的对应的内容们 另一种思考方法：旋转x实际就是把ab转换成ba 如果a是前i个元素，a比b短，把b分割成b1和b2，让b2和a的长度一样 那么可以先交换a和b2 -&gt; b2 a b1 然后再集中精力交换b1和b2里的元素，也就是说这可以是一个recursive的表示方法 转置：这个看起来在写Leetcode的时候非常好用啊！！！但是注意在python里面reverse要自己写 如果把问题看成转置，实际上数组ab可以 先转置a：aTb 再转置b：aTbT 再转置整个数组：（aTbT）T = ba 也就是说，如果abcdefg想让他旋转三位，实际上可以做到的是 reverse（0，2）：cbadefg reverse（3，6）：cbagfed reverse（0，6）：defgabc 问题3 找到一个单词的变位词：比如pots和stop 解决方法 注意，找到所有的可能性是很愚蠢的，比如一个22个字母的词，所有的变位22！大概是10e21，时间爆炸了 核心思想 -&gt; 排序，排序之后的变位词就都一样了 leetcode 242,49 这个题的核心思路就是，每个单词按字母顺序排序之后的答案就是这个单词的key，如果两个单词的key一样的话这两个单词就是变位词，如果不一样的话就是新的词 在python里面直接用字典可以很好的储存变位词 第三章 数据结构数据结构的意义就是让代码可以更加简短整洁 -&gt; 比如用数组代替循环 原则：能用小程序解决的就不要用大程序 把重复性代码改写 封装复杂的结构 尽可能使用高级工具 让数据去构造程序 第四章 正确编写程序写一个完全正确的binary search吧！ 注意点 求中位数的时候是前后相加，除以二 注意跳出循环的条件是 start&gt; end 为了满足上面的循环条件，需要每次判断完mid之后，把start或者end移动一位，不然会陷入死循环 后面的9，11，14会用到程序的验证技术12345678910111213141516class Solution: def search(self, nums: List[int], target: int) -&gt; int: start = 0 end = len(nums) - 1 mid = (start + end) // 2 while start &lt;= end: if target == nums[mid]: return mid elif target &gt; nums[mid]: start = mid + 1 mid = (end + start) // 2 elif target &lt; nums[mid]: end = mid - 1 mid = (start + end) // 2 return -1 第五章 次要问题 虽然每次写完了程序，大家基本都会选择把它直接插入系统，然后强烈的希望他能运行 （哭了，写的也太真实了） 测试用例 设置极小的测试用例（比如0个，1个，2个元素等等） 设置可以自动生成的测试用例 计时，测试不同方法的时间 调试 -&gt; 引发bug是会有实际的逻辑原因的，调试的时候需要关注这些问题 第六章 性能透视在后面的三章会说到提高运行效率的三个方法，在第六章主要讲的是各个层次如何组合为一个整体 案例 一个模拟天体间受力关系，来模拟运动的程序，通过对程序的改进，在n=1000的程度下，把速度从一年提升到了不到一天，速度提升系数约为400 改进方法 算法和数据结构，把时间复杂度n2 -&gt; nlogn（二叉树） 算法优化，优化了两个粒子靠的很近的情况 数据结构重组，减少了局部计算的次数 代码优化：64位浮点数改为32位，计算时间减半。用汇编重写了某个函数，给缓慢的函数加速 硬件，提升了硬件 算法加速不一定是独立于硬件的，比如在超级计算机上，树形结构对时间的影响就很小 设计层次 问题的定义 系统结构 -&gt; 第七章，封底估计 算法和数据结构 -&gt; 2,8章 代码优化 -&gt; 9 系统软件 硬件：比如实现某个功能的专门硬件 原则 如果需要少量加速，研究最好的层次。虽然修改算法是非常常见的答案，但是在研究之前最好考虑一下所有可能的层次。比如硬件？这种的，最好能找到一个得到最大加速，又所需精力最少的层次 如果需要大量加速，需要研究多个层次。就像上面的案例一样 封底计算在处理问题之前，需要对这个问题的规模有一个大概的估计，才能更好的处理问题 帮助封底计算 两个不同方面的答案对比 量纲检测 经验法则 实践 性能估计 + 安全系数]]></content>
      <categories>
        <category>算法</category>
        <category>编程珠玑</category>
      </categories>
      <tags>
        <tag>Programming Pearls</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity与openCV显示图片]]></title>
    <url>%2F2019%2F08%2F20%2Funity%E4%B8%8EopenCV%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[关于opencv库 unity带了opencv库，但是这个库是based on java的基础上的，也就是说我继用过opencv的c++和python之后这回要用java了 OpenCV for Unity文档 注意：需要在载入opecv的asset之后，把StreamingAssets文件夹移动到Asset里面，需要操作tool--set plugin settings opencv自带了很多example，把这些加入到building setting里面就可以用了 显示图片首先明确一点，unity里面显示图片没有imshow这种东西，需要把图片的mat转化成texture格式，然后把这个texture加到object上面 在这里我建立了一个plane的object，并且调整了相机的角度，用来显示图片 这部分在start里面进行，也就是现在的图片是静态显示 var var是用来推断这个变量类型，因为var之后直接创建了变量，所以可以推断出来。但是java还是静态语言 这种样子是不行的var foo; foo = &quot;foo&quot;; 在for循环里可以 imread 基础功能和以前一样，读取一张图片，存为mat格式 路径中使用了Application.streamingAssetsPath，也就是上文中说到需要移动到asset文件夹里的opencv自带的文件夹。 Imgcodecs和Imgproc等都是以前没有接触过的库，如果需要图片正常显示，需要把格式从BGR改成RGB Texture2D 这个是处理物体表面纹理的一个class，构建新的的时候需要确定这个texture的大小 在这里需要创建一个新的texture2D，才能在之后把mat转到texture里面 Utils.matToTexture2D(dst, tex) 用于mat和纹理的转换，同样也有texture转到mat的方法 GetComponent() 得到这个gameObject的一个部分，尖括号里面的名字取决于现在这个object里面有什么 这里用的是plane，里面自带renderer的属性，并且renderer里面带有material，用来修改构成这个object的材料 总结 用unity显示图片的中心思想就是这个图片变成了object上面的texture，这个图片不能脱离object而独立存在，所以需要首先为这个图片构建object 最终结果如下 123456789101112131415161718192021222324252627using System.Collections;using System.Collections.Generic;using UnityEngine;using OpenCVForUnity;using UnityEngine.UI;using OpenCVForUnity.ImgcodecsModule;using OpenCVForUnity.ImgprocModule;using OpenCVForUnity.CoreModule;public class remove : MonoBehaviour&#123; void Start() &#123; var dst = Imgcodecs.imread(Application.streamingAssetsPath + "/image.JPG"); Imgproc.cvtColor(dst, dst, Imgproc.COLOR_BGR2RGB); //Debug.Log(dst.channels()); Texture2D tex = new Texture2D(dst.width(), dst.height(), TextureFormat.RGBA32, false); OpenCVForUnity.UnityUtils.Utils.matToTexture2D(dst, tex); gameObject.GetComponent&lt;Renderer&gt;().material.mainTexture = tex; &#125;&#125;]]></content>
      <categories>
        <category>Unity</category>
        <category>OpenCV</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OmniProcamUnity文件总结]]></title>
    <url>%2F2019%2F08%2F19%2FOmniProcamUnity%E6%96%87%E4%BB%B6%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[文件构成 Lib libOmniProCam libOmniProCamCalibration OmniProcam Projection Camera ProjectionTarget RenderTexture Shader DebugUI LibOmniProCamManager 其中，在lib里面有calibration用的接口，在里面设定好了投影仪需要的参数数量和相机需要的参数数量。在lib里面直接放了老师写好的dll，所以其实cs文件是在访问这些dll的内容 Camera 目的：初始化相机 变量 创建一个class：cameraInitializer，继承了Monobehaviour MonoBehaviour是每一个unity的script的基础类 public的gameobject，用来决定setup哪个相机，这个相机直接从unity的UI里面拽进去 protected的camera类，targetcamera projected可以在这个class以及所有继承这个class的里面被访问，但是private只能在这个class中被访问 Camera是unity里面一个表示相机的类 创建了两个float的数组，大小和之前设置好的相机参数，和投影仪参数一样 初始化三个4x4的矩阵，分别是相机的intrinsic，extrinsic以及相机的投影矩阵 Matrix4x4可以表示transformation的矩阵，包括平移旋转等等 函数 void Awake() 功能 在开始之前初始化variable或者game state，在整个stript里面只被call一次 在所有的object初始化结束之后 通常在start之前被call 效果 初始化了calibration 设定好了目标的相机，并且把这个相机setup protected void setupCamera(Camera targetCamera, int cameraIndex) 直接call了dll里面写好的功能（但是这里得到的是projector的，为什么？），得到了各种参数 关于GChandle 然后把distortion和都记录下来了，直接把translation和rotation（相机的外矩阵）赋值给了目标相机、这样目标相机就能直接移动到应该到的位置上了 另外两个函数可以返回这里目前没有用到的distortion k（4个）和c（2个） device]]></content>
      <categories>
        <category>研究室</category>
        <category>OmniProcamV2</category>
      </categories>
      <tags>
        <tag>OmniProcam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Levenshtein Distance的具体分析]]></title>
    <url>%2F2019%2F08%2F08%2FLevenshtein%2F</url>
    <content type="text"><![CDATA[编辑距离 编辑距离是衡量字符串相似度的距离 主要应用比如衡量DNA的相似性，衡量什么地方断字，文件的差异等等 基本操作 对于字符串里面的两个字母，有三种操作方法能让他们改变 插入一个新的字母 删除一个已经存在的字母 把现有的字母替换成其他字母 对于两个string，有四种基本的操作 第一种，不变 （比如ruopeng和fag） 原本的操作 ruopeng[0,6] -&gt; fag[0,2] 变换之后 ruopen[0,5] -&gt; fa[0,1] 因为最后一位相同，这个问题可以拆分成最后一个字母，和不包括最后一个字母的substring，这个问题就可以拆分了 第二种，替代 replace （比如 peng 和 zhou） 原本操作 peng[0,3] -&gt; zhou[0,3] 变换之后 pen[0,2] -&gt; zho[0,2] + replace(g -&gt; u) 其中，替换的操作是一步，替换之后最后一位的字母相同，这个问题就可以拆分成更小的问题了 第三种，插入 insert 原本操作 peng[0,3] -&gt; zhou[0,3] 变换之后 peng[0,3] -&gt; zho[0,2] + insert(u) 首先，直接把这个问题里面的zhou拆分成了更小的问题zho，然后再进行一个插入操作（一步），使zho重新变成了u 第四种，删除 deletion 原本操作 peng[0,3] -&gt; zhou[0,3] 变换之后 pen[0,2] -&gt; zhou[0,3] + delete(g) 同时也可以尝试尝试删除掉前一个string里面的最后一个字母g，不再管里面的g，把这个字符串尝试变成pen来进行比较 核心思想 首先，我们针对这两个string制作一个table 对于这个表来说，每一个位置都相当于这个位置对应的两个substring的相似程度，比如E和F对应的就是 ”RUOPE“ 和 ”F“两个substring对应的相似度 在每个单词开始之前，还有一个空白符号，对应的substring就是空白。比如空白符号这一列对应的就是”“分别和”F“，”FA“，”FAN“等元素的比较 对于每个表格里面的位置，从(1,1)开始，这个位置和周围位置的关系如下 上面一格是插入，指的是在FANGZHOU这个string的substring里面插入 左边一格是删除，指的是把RUOPENG这个单词删除一个字母 左上角一格是替代，指的是把这两个单词的字母分别退一位。如果当前位的字母相同，当前位的值等于退一位之后的值，如果当前不同，是退一位的值+替代花费的操作（也就是1） 表格初始化 首先需要确定这个表格的边缘情况，也就是横坐标和纵坐标分别是0的部分，这个部分不能用上面总结出来的公式表示 因为这部分其实就是把不同的substring和空白符号比较，那么需要的最小操作就等于当前字母的位数 填表 从当前的初始状况出发，逐渐把这个表填完，每一个新的格子的值都取决于上一个格子的值 insert = M[i-1][j]+1 delete = M[i][j-1] + 1 replace = M[i-1][j-1] + 1 dont change = M[i-1][j-1] （两个字母匹配） 如果两个字母不匹配的时候，now = min(insert,delete,replace) 最终结果如下，红色部分为字母相同部分 python代码实现12345678910111213141516171819202122def EditDistance(a, b): m = len(a) n = len(b) # 构建表格，注意需要比长度大一格，储存空字符串 M = [[0 for i in range(m + 1)] for j in range(n + 1)] # 初始化表格，substring分别和空字符串比较 for i in range(1, n + 1): M[i][0] = i for i in range(1, m + 1): M[0][i] = i # DP for i in range(1, n + 1): for j in range(1, m + 1): # 判断是否相同，注意这里要减一 if b[i - 1] == a[j - 1]: M[i][j] = M[i - 1][j - 1] else: insert = M[i - 1][j] + 1 delete = M[i][j - 1] + 1 replace = M[i - 1][j - 1] + 1 M[i][j] = min(insert, delete, replace) return M[n][m] 注意分清矩阵的行和列，在这个实现里a是行，b是列 考虑到最前面的空字符串 注意从string里面读取的时候要记得减1 注意构建矩阵的时候行数和列数要加一 右下角的结果就是两个完整字符串对比的结果 时间复杂度 这个方法需要遍历左右的substring的组合，并且把所有的结果都存在一个矩阵里 如果两个string的长度分别是m和n，那么时间复杂度O(mn),空间复杂度O(mn) 最后，RUOPENG在8月8号这天祝距离为8的FANGZHOU，八(7+1)夕快乐]]></content>
      <categories>
        <category>算法</category>
        <category>动态规划</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
        <tag>编辑距离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法图解笔记]]></title>
    <url>%2F2019%2F08%2F06%2F%E7%AE%97%E6%B3%95%E5%9B%BE%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[第一章 算法简介二分查找 必须是有序的数组 对于n个元素的列表，使用二分查找最多需要 log2 n步，用普通的查找最多需要n步1234567891011121314def binary_search(l, item): low = 0 high = len(l) - 1 while low &lt;= high: mid = int((low + high) / 2) # 这里需要转成int，不然没办法做index if l[mid] == item: return mid elif l[mid] &lt; item: low = mid + 1 else: high = mid - 1 return None 运行时间 大O表示法表示了操作数，表示的是这个算法的增量 大O表示了在最糟情况下的运行时间 -&gt; 但是也是需要讨论平均时间的 常见的大O时间 logN 对数时间 Logarithmic N 线性时间 Linear N * logN 包括快速排序等，速度较快 N ^ 2 选择排序等，速度较慢 N！ Factorial time 非常慢 旅行商问题 travelling salesman problem, TSP 一个搞不好可以用n！来解决的问题 你要去五个不同的地方，需要规划怎么样路线最短，最开始的思路就是把每种可能性都列出来，然后对每种路线进行计算。这样的话五个地方就是120种，地方越多越呈阶乘增长 第二章 选择排序数组和链表 数组需要的空间是固定的（也就是说必须连在一起），所以如果后面加进去了其他东西的话就不行了，需要转移位置，或者预留空间 链表的每一个位置都会有到下一个位置的指针，所以不需要移动元素。 但是链表的问题在于，如果想直接找后面的东西的时候需要一个接着一个读取 需要读取整个数据的时候链表效率很高，需要跳跃的时候链表效率很低。而数组在读取随机元素的时候效率很高 数组插入 / 删除线性，读取常数。 链表读取线性，插入 / 删除常数。 在实际中，因为数组支持随机访问（但是链表只支持顺序访问），所以数组的适用范围大一些 选择排序 实现方法：每次都从所有的里面选出最大 / 最小，然后放在最开头 时间复杂度 n ^ 21234567891011121314def select_sort(l): newArr = [] for j in range(len(l)): smallest = float('inf') index = None for i, item in enumerate(l): if item &lt; smallest: smallest = item index = i newArr.append(l.pop(index)) # 注意这里需要把l的大小改变了 # 但是是在带l的loop外面变得所以没有关系 return newArr 第三章 递归 recursion何为递归 函数自己调用自己 递归和循环的作用效果是相同的，没有性能上的优势，但是可以让方案更加清晰 base case：告诉函数什么时候不再调用自己，停止循环 recursive case：函数调用自己 栈 stack 先进后出的数据结构，push（压入）和pop（读取和删除） 在调用另一个函数的时候，当前函数暂停并且处于未完成状态，函数的所有变量都储存在内存里 使用递归的一个问题：如果调用栈的时候很长，会占据大量内存 这种时候需要重新编写代码使用循环 或者使用尾递归（并不是所有语言都支持） 第四章 快速排序（分而治之 divide and conquer）分治 核心：把一个问题分成子问题，再把子问题分成更小的子问题，最后的子问题可以直接求解，这样的话原问题的解就是子问题的解的合并 比如把n规模的问题分成k份，然后在k个问题里面分别再分开 特征 问题缩小规模可以轻松解决 可以分解成若干个小问题 分解出的子问题可以再合并（如果不满足这条，应该考虑贪心或者DP） 分解出的各个子问题是独立的（不满足应该考虑DP） 不用循环而用递归：函数式编程里面没有循环（Haskell） 1234567891011121314def RecursiveSum(l): if l == []: return 0 else: return l[0] + RecursiveSum(l[1:]) # 这里不能改变l本身的大小def MaxNum(l): if len(l) == 2: return l[0] if l[0] &gt; l[1] else l[1] submax = MaxNum(l[1:]) return l[0] if l[0] &gt; submax else submax 注意： 需要找好基本条件，如果找最大值的base就是还剩下两个值 注意return的内容 快速排序 比选择排序速度快很多 base条件，一个元素或者空的数组就不需要排序了 需要设定一个基本值（比如取第一个值，根据这个值把原数组分成两部分），这样这三个大块就分类完成了。然后对于每个小块，再继续分组 比基准小的子数组 基准 比基准大的子数组1234567891011121314def QuickSort(l): if len(l) &lt; 2: return l else: piv = l[0] # 这里是快读得到比他大和比他小的写法，主要从l[1:]开始 less_part = [i for i in l[1:] if i &lt; piv] more_part = [i for i in l[1:] if i &gt; piv] return QuickSort(less_part) + [piv] + QuickSort(more_part) # 注意这里piv是个int，所以连接的时候需要改成list 时间复杂度 快速排序的速度取决于选择的piv的值的大小，也就是说如果完全排好的情况下，复杂度是n2 合并排序的速度是 nlogn，快速排序的平均速度是 nlogn，最佳情况是 logn 快速排序需要logn层，每层需要把n个元素全都遍历一次，所以最终的结果是nlogn 在计算复杂度的时候，复杂度是操作的次数，而这个次数需要乘一个每次操作的常量，在快速排序的时候常量更小，而且快速排序没那么容易遇到最糟情况 第五章 散列表（hash表）hash函数 最终的目的是查找的时候时间复杂度是 1 函数构造：把输入映射到一个数字 无论你什么时候输入，输出的数字是一致的 将不同的输入映射到不同的数字 知道整个存储的范围有多大，不会返回超过这个大小的数字 应用：缓存 网站的缓存数据就存在hash表里面，这样访问速度更快，网站本身需要做的工作更少 访问一个网页 -&gt; 是否在缓存里 -&gt; 有的话调用缓存 -&gt; 没有的话存进缓存 冲突 虽然假设的时候认为每个东西都被映射到不同地方，其实会产生冲突 这种情况下要在hash后面加上list hash函数需要把内容比较平均分分配 如果储存的链表很长，那么性能就会急剧下降 性能 最佳性能，1 最糟性能，插入，删除，查询全都是n 装填因子： 装填的元素数 / 元素总数 一旦超过0.7就需要调整hash的长度了 第六章 BFS：最短路径问题BFS 用于图的查找算法，可以解决两种问题 从A出发有前往B的路径吗 从A出发到B的路径最短是什么 实现图 -&gt; hash表，需要将node映射到所有的邻居 在python里面使用deque创建双端队列 算法实现（广度搜索）： 创建一个队列，储存用于查找的人 首先把初始化的人载入队列 从队列里弹出一个人，查找他是不是（查过之后标记成已检查，列表记录），不是的话把这个人的相邻加入队列（一直重复） 标记成已检查非常重要，因为不标记的话可能会陷入无限循环 如果最后队列空了还没找到，那就是没有 123456789101112131415def BFS(name, graph): search_queue = deque() search_queue += graph[name] searched = [name] # 用来储存已经探索过的人数 while search_queue: person = search_queue.popleft() if person not in searched: if person[-1] == "m": # 只是一个判断是不是这个人的办法 return person else: search_queue += graph[person] searched.append(person) return None 更新版本，不但可以搜索还可以计算长度12345678910111213141516def BFS(name, graph): search_queue = deque() search_queue.append(name) searched = [name] # 用来储存已经探索过的人数 distance = &#123;name: 0&#125; while search_queue: current = search_queue.popleft() for person in graph[current]: if person not in searched: searched.append(person) distance[person] = distance[current] + 1 if person[-1] == "m": return person, distance[person] else: search_queue.append(person) return None, None 注意点： 增加了distance这个dict来储存开始点到这个点的距离 在初始化的时候只在已搜索队列里添加了第一个点的信息，在后面的循环里才添加后面的点 对于每个从queue里面拿出来的点，如果不在已经查找的点里就一定需要加进去，并且计算距离，距离即是和上一点的距离+1 计算过距离之后再判断是不是要找的点 运行时间 需要沿着每条边前进，所以在边上的运行时间是 O(E) 把每个人加到queue里面也需要时间，每个人的时间是常数，所以人数的时间是 O(V) 总的运行时间 E + V 拓扑排序 如果任务A依赖于任务B，那么任务A就必须排在B的后面，这种就是拓扑排序 第七章 狄克斯特拉算法 之前的图找的是最短路径，现在需要给图加权，找加权之后的最短路径 加权之后的最短不一定是边数最短 负的权重不顶用，因为负权重不能确定没有比目前消耗更小的 书里写的错的地方：可以有环，没环都是树了！有向无环图可以直接拓扑排序 核心思想：找到到这个点消耗最少的路径，并且确保没有路径比这个小了 算法流程 找出消耗最低的点 更新这个点相邻点的开销 重复这个过程，直到对所有点都做了（即A点最小之后更新B点，然后更新C点，以此类推） 计算最终流程 具体实现 创建一个表格 包含了每一项和每一项的具体开销，目前不知道的开销标记成inf 需要包含每个点的父节点，才能保证最后可以计算流程 不停的更新这个表，从开销最低的一直更新到开销最高的，如果更新了开销的话同样需要更新父节点 在确定路径的时候，从结尾的地方开始找，然后一路找到开头 一个问题：关于图在python里面的表示 实际就是一个dict叠dict，如果直接访问G[a][b]就可以直接得到这两个点的距离 如果没有加权的话，可以直接dict叠list，因为不需要记录距离了 注意点 最好是最开始指定了第一个消耗最低点，然后再循环里面最后找消耗最低点 初始化的时候注意：cost里面初始为0，father里面去掉这个点，Node（cost最低点）初始化成这个点，循环的条件是Node不是空123456789101112131415161718192021222324252627282930313233343536373839404142def dijkstra(graph, src, target): # 需要创建一个cost表和一个父节点表 cost = &#123;&#125; father = &#123;&#125; visited = [] for i in graph.keys(): # 访问这个图里面所有的key，就是所有的店 cost[i] = float('inf') father[i] = None cost[src] = 0 # 起始点的cost是0 father.pop(src) # 起始点不需要父节点 Node = src # 最小开销点还存在的时候更新所有的点 while Node is not None: for near in graph[Node]: new_distance = cost[Node] + graph[Node][near] if new_distance &lt; cost[near]: cost[near] = new_distance father[near] = Node visited.append(Node) # 找到最小开销的点(放在循环里面好一点) Node = None smallest = float('inf') for i in cost: if i not in visited: if cost[i] &lt; smallest: smallest = cost[i] Node = i # 跳出循环，得到结果 N = &#123; "start": &#123;"a": 2, "b": 6&#125;, "a": &#123;"fin": 1&#125;, "b": &#123;"a": 3, "fin": 5&#125;, "fin": &#123;&#125;&#125;# print(N["start"]["a"])dijkstra(N, "start", "fin") 第八章 贪心算法 处理npc问题，即没有快速算法的解法的问题 对NPC问题找到近似解 例子问题 课表问题： 希望尽可能多的课在这个屋子里面上，但是上课时间冲突，如何排课 先找到这个教室里最早开始的课，然后找到这节课结束之后最早开始的课 装东西 背着包去装东西，容量有限，如何装到最大价值的 从最大的开始装，但是得到的不是最优解，最优解应该动态规划 核心思想：每一步都用局部最优解，得到的结果就是全局最优解。即使得不到最优解，也可以得到近似最优解 只能用贪心的问题 集合覆盖问题，比如想在全部区域广播，但是每家电台只覆盖特定区域，如果才能花费最小的计划 列出所有的可能性的话，复杂度是 2^n 近似算法：从覆盖最多地方的电台开始找，一直到覆盖所有地方 贪心算法的复杂度是 n^2，n是广播台的数量 因为每次都需要遍历一次找出最需要的那个（n)，这样的操作需要进行最多n次（万一每次都覆盖不上） NPC问题：从旅行商问题详解 旅行商问题和求路径问题的区别在于，旅行商问题需要访问一遍所有的地方，找到最短路线 旅行商问题需要查看所有的可能的路线 从简单问题出发 两个地方的时候，可能的路线有两条（一来一回） 三个地方的时候 6条 需要计算出所有的解才有可能从中选出最短的路线 -&gt; NPC问题 近似方法：每次都去离得最近的地方 识别问题 元素较少的时候速度快，随着元素增加非常慢 涉及所有组合 不能分成小问题，必须考虑所有情况 涉及序列（比如旅行商中的城市序列），集合（集合覆盖问题）且难以解决。或者可以转换成这种问题的 第九章 动态规划核心思想 把一个大的问题拆分成很多小问题的解的合并 最终的结果其实类似一个表，每次再得到新的结果的时候，其实是在比较 同等大小下上一个的值（即上一行的值，这个值已经是之前储存下来的最大的值了） 当前放新的东西的价值+放完这个东西之后剩下空间可以放的东西的最大价值（这个最大价值同样也被记录了） DP处理问题的时候只能整件的处理，也就是说分布应该是离散的而不是连续的 而且DP处理问题的时候各个子问题之间不能互相依赖，如果互相依赖了就很复杂了 最长公共子串 比如搜索引擎误输入，怎么判断相近词 每种动态规划都涉及网络，每个网格里面的值就是我需要优化的值 每个单元格里是什么 每个单元格是这个格子之前相同的字母数量 如何把这个问题分成子问题 如果相同，就是前一个的字母数+1，如果不同就是0 网络的坐标轴是什么 在这个问题中，是两个单词的各个字母 注意在这个问题里面，最终答案不是在最后出现的 最长公共字序列！！和子串不一样，对比的是序列而不是字母的个数 当字母不同的时候，选择上边或者左边最大的那个 应用 levenshtein distance（字符串的相似程度，也就是上面的公共子序列） 指出文件的差异，DNA的相似性，确定什么地方断字 核心思想：需要把两个str里面所有的substr的combination都计算一下 实现 初始化条件：插入 实际上来说一个格子有三种操作，删除，插入和置换，这个格子需要改变的操作是这三个操作的最小值 删除 = d[i - 1][j] + 1 插入 = d[i][j - 1] + 1 （相当于这个单词的前一个字母，加上一个插入，这两个没有本质区别） 替换 = d[i - 1][j - 1] + cost，其中这个cost，如果两个相同就是0，两个不同就是1 具体说明见levenshtein distance说明 第十章 K最近邻创建推荐系统 向这个人推荐电影，找到离这个人最近的五个用户 如何判断最近：特征抽取 第十一章 接下来如何树（数据库 + 高级数据结构） 二叉查找树：对于每一个节点，左节点都比他小，右节点都比他大 时间复杂度 logn 平衡问题 延伸： B树，红黑树，堆，延展树 反向索引 搜索引擎的工作原理 把网页创建hash表，key是单词，value是包含单词的页面 傅里叶变换 信号处理 并行算法（提高速度） 对速度的提升是非线性的 并行管理开销 负载均匀 MapReduce 分布式算法 把一台电脑上面处理的工作分布到多台电脑，处理大量数据 分布+归并 布隆过滤器 概率型数据结构：可能出现错报，但是不可能出现漏报 储存空间很少 HyperLogLog 类似于布隆过滤器的算法，不能给出准确的答案但是占据的空间很小 SHA 另一种hash，安全散列算法，给定一个字符串返回hash 比较大型文件 检查密码 局部不敏感，修改其中一个字符，会改变很多 Diffie-Hellman 密钥交换 如何对消息加密，让只有收件人看得懂 线性规划 在给定的约束条件下最大限度的改善指定的指标]]></content>
      <categories>
        <category>算法</category>
        <category>算法图解</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SVD]]></title>
    <url>%2F2019%2F07%2F16%2FSVD%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[fusion360]]></title>
    <url>%2F2019%2F06%2F26%2Ffusion360%2F</url>
    <content type="text"><![CDATA[给予特征 拉伸指令 修饰外形 修改边缘 圆角 倒角 外观处理 选择贴图 右键选择外观 可以选择加到面上面或者加到所有东西上面 render（3D模型2D化） 从model改成渲染 点那个台灯，修改图片的场景设置，比如高宽比 所有东西都弄好了之后直接渲染，渲染到自己满意的地方 画草图 可以把参考的图放在平面上来，这样画起来比较轻松（插入） 需要校准加进去图片的比例 修建偏移之类的对标CAD 画曲线 直接关键点画曲线，可以再调整 几何关系靠计算来 咖啡杯 杯身 旋转体成型 杯盖 新建新的零部件 修改 – 合并（相交运算 草图 – 投影，可以把其他的东西投影到现在的平面]]></content>
      <categories>
        <category>CAD</category>
        <category>Fusion360</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[libProCam笔记]]></title>
    <url>%2F2019%2F06%2F25%2FlibProCam%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Binarizer.cpp这个部分是来计算图像的binary的，包括 计算这个图片的threshold 做背景substract Cpp相关 构造函数 构造一个类的时候使用的函数，这个函数的名字和类名相同，默认是没有参数的，可以自己加上参数，这样创建对象的时候就需要给参数 对标python里面的init 析构函数 名字和构造函数完全相同，但是在前面增加了一个波浪线，没有返回值也没有参数，只是用来在关闭程序的时候释放资源 虚函数 借助指针来达到多态的效果 定义一个函数是虚函数，不代表这个函数不被实现，而是代表基类的指针可以调用子类的这个函数 如果定义为纯虚函数，才说明不会实现 比如下面的例子里面，B是子类，A是基类，创建的是A的指针，但是调用的却是B的函数，这说明这个函数的调用不是在编译的时候被确定的，而是在运行的时候被确定的12345678910111213141516171819202122class A&#123;public: virtual void foo() &#123; cout&lt;&lt;"A::foo() is called"&lt;&lt;endl; &#125;&#125;;class B:public A&#123;public: void foo() &#123; cout&lt;&lt;"B::foo() is called"&lt;&lt;endl; &#125;&#125;;int main(void)&#123; A *a = new B(); a-&gt;foo(); // 在这里，a虽然是指向A的指针，但是被调用的函数(foo)却是B的! return 0;&#125; 纯虚函数，在函数的定义后面加上 =0 经常会在定义基类的时候用纯虚函数，因为基类可能有很多的派生，但是基类本身生成的对象可能是不合理的 比如动物可以派生狮子老虎，但是动物本身不是很合理 在子类里面必须重新声明这个函数，也就是说在子类的时候必须提供一个这个函数的实现，但是基类的作者不知道你怎么实现它]]></content>
      <categories>
        <category>研究室</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些OpenCV里面之前没用到的函数]]></title>
    <url>%2F2019%2F06%2F20%2F%E4%B8%80%E4%BA%9BOpenCV%E9%87%8C%E9%9D%A2%E4%B9%8B%E5%89%8D%E6%B2%A1%E7%94%A8%E5%88%B0%E7%9A%84%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[看了别人写的代码，感觉好多openCV里面的基础功能我都不知道，当时还是在自己写的，比如降噪啊，减去背景啊等等的 关于载入模型看了一个Github上面的项目，是自己训练了一个五个手势的识别，然后用这些手势来控制自己屋子里面的灯光变化，用keras训练的所以先载入了这个的模型，然后有两个不同的预测的函数 第一个函数用了model.predict_classes，这个函数预测出来的直接是类别，打印出来的就是类别的编号 第二个用的是model.predict，这个预测出来的是一个数字，不能直接用，还需要把这个数值argmax(predict_test,axis=1)才可以用（也就是找到最大的） createBackgroundSubtractorMOG2()retval = cv.createBackgroundSubtractorMOG2( [, history[, varThreshold[, detectShadows]]] ) 创建了一个MOG2的background substructor 参数分别是 history的长度 计算的是曼哈顿距离，这个的阈值 是否检测影子，如果检测的话速度回慢一点 创建完的模型有很多功能 这里用到了一个apply，就是对一张图进行这个操作，来计算出这张图片的foreground 这里有一个参数叫learning rate，指的是你的这个模型会不会随着时间而改变，0的话就是不变，1的话就是完全由上一帧形成，然后负数的话会自动选择一个 bitwise_and()dst = cv.bitwise_and( src1, src2[, dst[, mask]] ) 这里计算了每一位的与（and）计算，加上了一个可选的参数mask，这样可以直接计算出来前景去掉背景 videoCapture.set()dst = cv.bitwise_and( src1, src2[, dst[, mask]] ) 这里他的代码没有用属性，直接设置了两个数字，每个数字会代表一个属性，数字的范围是0-18 也就是说她设置了10这个属性，然后把这个属性的大小设置成了200 cv2.bilateralFilter(frame, 5, 50, 100) 一个叫这个名字的滤镜，可以消除掉图片里面你不想要的噪音 效果比较好，可以在消除噪音的同时保证图像比较清晰，但是与此同时这个filter的速度会比大多数的慢一些 图像翻转 flip 两个参数，翻转的图像以及翻转参数 0是竖直翻转，1是水平翻转，小于0的时候是旋转180度（先竖直再水平翻转） inRangedst = cv.inRange( src, lowerb, upperb[, dst] ) 查看是否有数字在这个范围里面，三个channel都在的话就输出1，不在的话就输出0 可以给不同的channel赋不同的值 calcHisthist = cv.calcHist( images, channels, mask, histSize, ranges[, hist[, accumulate]] ) 计算一系列输入的histogram 原来有这个函数，把这个输入normalize到255个channel上面就能得到，这样就可以得到这张图片里面的分布了 而且考虑了上面的mask的情况 calcBackProject（存疑！）dst = cv.calcBackProject( images, channels, hist, ranges, scale[, dst] ) 计算一个hist的back projection CamShift()]]></content>
      <categories>
        <category>图像处理</category>
        <category>OpenCV</category>
      </categories>
      <tags>
        <tag>OpenCv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文Touch180]]></title>
    <url>%2F2019%2F06%2F17%2F%E8%AE%BA%E6%96%87Touch180%2F</url>
    <content type="text"><![CDATA[Touch180: Finger Identification on Mobile Touchscreen using Fisheye Camera and Convolutional Neural Networkabstract 鱼眼+深度学习，证明检测手指的准确性和鲁棒性 生成了一个dataset 训练了一个CNN，确定手指touch的位置 intro 可以通过给不同的手指不同的职责来增强对触摸屏的使用 以前的分别手指的论文 wearable device -&gt; 比较贵 确定触摸的区域 -&gt; 必须多个手指触控 还有一个方法是在手上戴上了一个有颜色的戒指（诶这个方法用来实现现在的device的画画功能感觉怎么样） 用了深度相机的 -&gt; 不适合mobile device 其他用CNN的没有使用鱼眼相机 dataset 直接用不同的frame来做的dataset 用五个二进制的数字来表示labeling net]]></content>
      <categories>
        <category>Papers</category>
        <category>鱼眼手势识别</category>
      </categories>
      <tags>
        <tag>fisheye</tag>
        <tag>hand</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[unity入门制作space shooter]]></title>
    <url>%2F2019%2F06%2F13%2Funity%E5%85%A5%E9%97%A8spaceshooter%2F</url>
    <content type="text"><![CDATA[目标 这个游戏是和雷电类似的游戏 需要设定碰撞等等游戏逻辑，然后设计音乐，图等等东西 setup，player，cameraset up 需要确定好应用的开发平台file-build setting 注意这个游戏想开发网页版的，但是现在已经不支持web player，建议使用web GL 可以在project setting-player里面改变一些游戏的设置（这里改变了宽度和高度） 在右上角的layout可以改变窗口的布局 放置游戏的object 直接从model里面拖进来放进scene或者hierarchy里面 点击F可以锁定这个东西（最佳视角） 需要设置这个object在原点 有一个mesh filiter来决定这个东西用的什么模型 一个mesh renderer来渲染这个模型 这个里面有两个不同的材料 因为需要物体之间的碰撞，所以需要增加physics--rigidbody 加入了这个东西之后，物体就有了物理上的特征 下面由于需要碰撞，所以需要定义这个物体的体积 增加一个physics -- capsule collision 相当于把这个物体的周围加上了一个cage，来确定他的体积 需要在这里面定义碰撞的方向（因为这里面是沿着z运动的，所以碰撞在z轴上面） 可以改一改视角，然后直接拉bar来调节这个consule的大小 关于coliider 除了这里面用到的胶囊型的以外，还有square的sphere的，confound的（混合）？，在能解决问题的时候尽量用上面的基础图形 除此之外，还有一个mesh coillder，用来专门契合这个物体的体积的，但是是最后的选择，选择的时候最好也选择一些比较简单的形状(如图所示，新的碰撞范围会完整契合这个物体) 在coillder里面可以自己设定这个对应的mesh的种类，即使和使用的模型不同也可以（也就是说可以建立一个相对于这个模型简单的模型，然后建立碰撞） 为了选中的这个东西可以被识别为碰撞物体，选择is trigger 为了增加一点神奇的新功能，在预设好的prefab（一个可以重复克隆的对象）里面找到一个引擎的动画，拖到player的子目录下面，这个东西就自动加进去了 相机和light相机 因为一开始相机会初始化在物体之后的位置，所以现在在game界面只能看到这个物体的屁股部分，需要设置相机 点击main camera，这时候右下角会出现相机位置的缩略图 位置 -&gt; 调节到物体上方，并且旋转90度 设置相机的种类 如果选择perspective的相机，可以通过调节FOV来决定看到的是多大 这里选择orthographic（正投影，主视图那种感觉）的相机，然后直接调节看到的size就可以了 因为希望object保持在原点上，所以在这里移动camera 可以在game画面里面直接调节object的位置等等东西 下面把在camera里面把背景改成黑色（soild color） 但是这时候object的颜色并没有变黑，这是因为打开了ambiant light 在window--rendering--lighting setting里面，把source改成color就可以改变环境光的颜色 环境光：ambient light 这个光没有方向，所以如果都加上了的话可能会很奇怪 光 创建一个有方向的light -&gt; main light 应该是最亮的光 希望可以看到飞机的颜色但是不希望太亮 调整这个光的角度以及强度 建立第二个光，来照亮不怎么亮的部分 -&gt; fill light 还是调整角度，照亮第一个光照不到的部分 为了不让这个光那么强，把这个光的强度适当调小 为了适应太空的冷色调，把光源颜色改成蓝绿色 最后增加第三个光，把暗部勾边（相当于素描里面的在边上的高亮部分） -&gt; rim light 为了不照亮东西的上层，在x轴把角度调成复数 为了勾边，颜色是白色的 降低亮度 最后建立一个新的空的object，位置reset好，来整理上面的三个光 注意，因为这里的光是directional light，所以光照的效果和光源的位置无关，只和光源的角度有关 背景 新创建一个quad，调整位置和角度让相机能看到他 remove掉碰撞的部分，因为背景不需要 加上texture -&gt; 可以直接把这张图片拽到对应的位置上面 这样会创建一个新的material加到这个mesh的renderer上面去 缩放这个方块，让这个图片可以完全显示（高宽比必须保持！） 这时候照在player上面的光也可以照在背景上面，但是不是很希望这种结果 一种方法是把background完全独立一个layer出来 另一种方法是改变这个texture的shader 这里改成完全的testure，这样就不会受到光的影响了 最后把船从陷入的background里拽出来 移动player 首先需要在player底下建立新的scripts fixedupdate -&gt; 确定物体现在的位置 首先得到垂直和平行的输入（键盘或者鼠标输入） 物体的移动是一个三维的数组，分别是xyz轴，这里y轴的移动是0.0f，其他两个分别是平行和垂直的移动 因为已经用了rigid body，可以从里面给物体一个速度GetComponent&lt;Rigidbody&gt;().velocity -&gt; 这时候移动的非常慢，因为input接收的只是0和1，所以每秒移动一个unit 这时候加上了一个新的speed参数，每次在计算速度的时候乘上这个参数就可以了 注意，因为这里的speed是个public的值，所以可以直接在unity的UI里面进行操作 这时候出现了一个问题，player会跑出屏幕 增加一个判断条件，移动这个东西如果到了边界，那么把position从先reset到边界上 因为这样在更新下一帧之前都不会出界 使用了mathf里面的一个函数clamp，来设定x和z的范围 这个函数超过了下界就会一直显示下界，超过了上届就会一直显示上届 为了不让设定的xmax，xmin，zmax，zmin在UI里面太占地，所以建立了一个新的class来装这些东西（注意新的class不需要继承），然后在需要用的时候建立新的对象，call 为了能在UI里显示，需要在新创建的class上面加上[System.Serializable] 这些边缘设置什么值可以直接把东西拖到边缘然后看看是什么值就可以了 tilt或者bank：让飞船到左右移动的时候可以旋转一下 增加了旋转功能Quaternion.Euler shots希望把这部分的逻辑和这部分的图像分隔开：这样换模型的时候就很方便了 首先创建一个新的quan，在这个上面加上texture 创建一个新的material，然后再这个里面选择一个texture 然后再把新的material加到对应的东西里面 希望这个东西黑色的部分消失，shader选择mobile--particle--addtive（mobile比较有效率） 增加这个东西的碰撞，去掉VFX的碰撞 然后加上这个光的运动逻辑 transform.forward()向前运动，乘上速度 把这个东西设定成一个prefab（直接拖到prefab的文件夹里面） shoot shots 已经把需要射出去的光线设定成了一个prefab，这时候只要在每次点鼠标的时候把这个东西射出去就可以了 创建一个新的空的object作为player的子目录来定义发出去激光的位置（shotSpawn） 在player中新增一个功能，public的对象是shot和shotSpawn，这两个东西都可以直接从UI里面拖进来，然后设定这个子弹发射的逻辑，每次按下鼠标都并且在0.25秒外会发射子弹 按下鼠标后把showSpawn的transform赋值给shot，这样就知道shot的位置了 问题：现在游戏进行过程中会往root里面增加很多prefab boundary，hazards，enemyboundary在画面里面消失的子弹也删掉 -&gt; 建立一个box 打开trigger 给这个box里面用一个函数，判断是否撞上这个边框，撞上了的话就删除撞上的物体OnTriggerExit 1234567public class DestroyByBoundry : MonoBehaviour&#123; void OnTriggerExit(Collider other) &#123; Destroy(other.gameObject); &#125;&#125; hazrads会撞上player的陨石 首先建立一个新的陨石对象，这个对象应该可以被撞击的，加上碰撞和刚体 加上这个陨石的自动旋转，使用随机的数字，并且把angular drag改成0 加上激光和陨石碰撞之后，两个东西同时消失的效果 单纯的加碰撞效果会发现因为边界引发的陨石消失bug 因为陨石先和边界碰撞了，然后两个一起消失了 需要把Boundary加上一个新的tag1234if (other.tag == "Boundary") &#123; return; &#125; 爆炸！就是艺术！ 在contact destroy的文件里面增加新的爆炸效果 新建一个explosion的gameobject，给这个对象赋值位置Instantiate(explosion, transform.position, transform.rotation); 给player一个新的tag，然后在碰撞里面判断是陨石撞player还是陨石撞激光，赋值不同的爆炸效果 把mover增加到陨石里面，速度设置为负值，这样陨石就能往自己身上掉了 game controller 创建整个游戏的逻辑 设置好的陨石创建成新的prefab 创建一个新的对象作为控制器，加入一个新的对象hazard，初始化好掉下来的敌人的位置，让敌人可以从随机的位置往下掉 每次掉落之间隔着时间（这部分和C++有些不一样），把所有的掉落放在一个while里面 去掉剩余的爆炸效果 score，audio，building加声音 首先把陨石爆炸的背景音加到陨石的prefab里面 背景音乐加到game controller，武器的音乐加到player 武器的音乐需要在每次发射的时候触发 调整各个音量的大小 计算score 新建一个text，设定好这个text的字体效果之类的 然后把这个text reference到gamecontroller里面，然后把最开始的分数初始化，并且写出来更新score的代码 把这个score reference陨石里面 增加文字效果 需要增加重新开始游戏和游戏结束的text 在游戏逻辑里面加上的是这个玩意怎么更新和计算，需要两个flag判断有没有游戏结束 需要在碰撞里面把player弄死 增加最后的效果 增加陨石 复制之前的asteroid并且给他们不同的模型和碰撞 把之前的对象改成一个数组就可以handle很多个对象了，随机选择 增加移动的小星星（项目里面自带的） 让背景重复起来 把背景设置在一个范围内，一旦超过了这个范围就重新开始]]></content>
      <categories>
        <category>Unity</category>
        <category>入门</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VS17的配置问题]]></title>
    <url>%2F2019%2F06%2F07%2FVS17%E7%9A%84%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[无法打开源文件问题 直接从老师那里得到的项目，第一次运行直接出错，查了一下主要需要注意下面几个 装VS的时候有没有装标准库之类的 尝试使用window的其他版本的SDK 右键项目，属性里面 上面两个问题都可以在VS的installer里面找到相关的安装 多个main的问题 这回的文件里面有两个cpp都带着main，如果想要运行的话需要把一个cpp右键移除出项目再运行另一个]]></content>
      <categories>
        <category>IDE</category>
        <category>Visual Studio</category>
      </categories>
      <tags>
        <tag>VS17</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的复制和多维数组]]></title>
    <url>%2F2019%2F06%2F05%2Fpython%E7%9A%84%E5%A4%8D%E5%88%B6%E5%92%8C%E5%A4%9A%E7%BB%B4%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[最近写面试题的时候遇到了自己都想不到的奇怪小错误 多维数组在创建多维数组的时候，本来应该是用嵌套的for循环来生成[[0 for i in range(m)] for j in range(n)](因为一般网测不能调用numpy，不然就直接用numpy搞了) 但是最近想要偷懒的时候尝试用 [[0] * n] * m 来创建，结果疯狂遭遇bug。 最终原因是发现这样创建出来的数组，每一行都是第一行的引用，所以每次操作大家都会一起变 (但是这种方法可以创建一维的) list的复制我一直以为a=b就是list的复制了，但是并不是这样的！！这样的话a是一个关于b的reference，并不是复制b，改变的时候是会一起改变的 下面几种方法可以用： a = list(b) a = b[:] a = b * 1 a = copy.copy(b) #需要import copy]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>list</category>
      </categories>
      <tags>
        <tag>list复制</tag>
        <tag>多维数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于字符串匹配算法KMP和BM]]></title>
    <url>%2F2019%2F06%2F05%2F%E5%85%B3%E4%BA%8E%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95KMP%E5%92%8CBM%2F</url>
    <content type="text"><![CDATA[今天在leetcode终于刷到了string的题，是在一大串字符里面匹配相应的字符。托python的福，居然被我用暴力破解解决了，虽然结果不是很优雅。123456789class Solution: def strStr(self, haystack: str, needle: str) -&gt; int: if needle == "": return 0 for i, ch in enumerate(haystack): if ch == needle[0]: if needle == haystack[i:i+len(needle)]: return i return -1 KMP 首先，把这个需要检测的string（a）的第一个和目标string（t）的第一个进行对比，如果不匹配，后移一位 直到找到第一个相同的字母，然后把a和b同时后移一位 还是相同，继续后移 不同（这部分是这个代码的精髓） 一般的思路是把b全都后移一位，但是这样其实消耗挺大的 KMP的思路是，既然b的前n位都已经比较过了，那就不要放弃这个信息，不要移动回之前比较过的n位了，继续后移移动到全新的位置 需要移动的位数 = 已经匹配到的字数 - 对应最后一位匹配上的东西的匹配值（由partial match table得出） 如何产生这张表比如一个单词 bread 前缀：b,br,bre,brea 后缀：read,ead,ad,d部分匹配值就是前缀和后缀最长的共有元素长度 比如ABCDABD这个string A前后缀都是空的，长度0 AB，前缀A，后缀B，共有长度0 ABC，[A, AB]，后缀为[BC, C]，共有元素的长度0 ABCD，[A,AB,ABC],[B,BC,BCD] -&gt; 0 ABCDA, [A,AB,ABC,ABCD],[BCDA,CDA,DA,A] -&gt; 有一个共有元素A，长度为1 ABCDAB,[A, AB, ABC, ABCD, ABCDA],[BCDAB, CDAB, DAB, AB, B] -&gt; 共有元素AB，长度为2 “ABCDABD”的前缀为[A, AB, ABC, ABCD, ABCDA, ABCDAB]，后缀为[BCDABD, CDABD, DABD, ABD, BD, D]，共有元素的长度为0。（难点：怎么得到上面的这个长度） BM 首先将a和b的头对其开始，然后从尾部开始比较。因为如果尾部不匹配的话，这整个一串都不匹配了。知道了这个不匹配的字符之后，这个字符就被称为坏字符 如果这个坏字符包括在单词里面，则需要把这两个对其 后移位数 = 坏字符的位置 - 搜索词中的上一次出现位置 如果不包含在搜索词里面，那么上一次的位置是-1 最后一位匹配上了，那么就顺着b往前捋 在a里面可以和b后面匹配上的都是good suffix（比如example的e，le，ple等等） 好后缀的后移：后移位数 = 好后缀的位置（最后一个字符为准） - 搜索词中的上一次出现位置 如果没有出现过是 -1 如果有多个好后缀，那么除了最长的好后缀，其他的上一次出现位置必须在头部（b的头部） 在上面两个规则里面，选择移动的最大值 上面两个规则只和搜索词有关，和原来的字符串没关系，所以可以提前生成坏字符和好后缀表，直接比较移动位数]]></content>
      <categories>
        <category>算法</category>
        <category>字符串处理</category>
      </categories>
      <tags>
        <tag>KMP</tag>
        <tag>BM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于python的threading]]></title>
    <url>%2F2019%2F06%2F03%2F%E5%85%B3%E4%BA%8Epython%E7%9A%84threading%2F</url>
    <content type="text"><![CDATA[多线程多线程类似于同时执行多个任务 可以把占用时间长的程序放到后台去处理 可以使用户界面更加吸引人（比如点击按钮，会出现进度条） 处理速度更快]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于动态规划(dynamic programmin)]]></title>
    <url>%2F2019%2F05%2F24%2F%E5%85%B3%E4%BA%8E%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92DP%2F</url>
    <content type="text"><![CDATA[入门ref：https://www.zhihu.com/question/23995189 例子在身上带着不同数额的钞票，目标是凑出来某个金额w，使用尽量少的钞票 如果用贪心算法，实际上就是尽快让w变得更小，有更大面值的就用更大面值的钞票 但是如果换了一组其他的钞票面值，可能就会出现问题（比如 1，5，11凑15） 因为在贪心算法里面，需要先把15降成4，再把4降下来，但是降4的成本很高，需要4张1 在考虑的时候鼠目寸光，只考虑了眼前的情况，没有考虑后续的发展 如果开始列举，其实这个问题就会变成接下来需要凑出来n，需要f(n)张钞票 这时候，凑15其实就变成了三个情况 f(4) + 1 f(10) + 1 f(14) +1 可以发现实际上f(15)只和这三个值有关系，也就是只和n-1，n-5，n-11有关系 f(n) = min(f(n-1),f(n-5),f(n-11))+1 这是一个可以迭代的式子对不对！ 并不关心到底是怎么凑出来的，反正只关心f(w)的值 在代码实现上面，只需从小到大对比所有的cost就可以了，也就是对比新的方案的cost是不是会比以前的方案小。注意在求的时候可能会需要i-1/-5/-11的值，所以要把从头到尾的值都记录下来 比如要求凑15块钱，会先考虑15比1大，那么把1块拿出来，看看取14块钱的时候需要的步骤是多少，然后把5块拿出来，看看比拿1块差多少，最后拿11，看看和之前的cost差多少 区别 dp和贪心算法的区别就在于，dp会分别算出不同策略的代价，而贪心算法包含着冗余的信息（到底怎么使用） 所以就是求出来fn -&gt; 得到求fn需要的fc -&gt; 求fc，不停的循环 也就是把一个问题拆成了不同的子问题 概念 后无效性 一旦fn确定，我们就不需要知道怎么得到的fn了，只在后面直接用就可以了 最优子结构 在得到fn的时候本身得到的就是最优的fn了，所以在用的时候才可以放心的用 一旦问题可以拆成子问题，并且满足上面的两个概念，就可以用dp解了 为什么快 dp和贪心都是在空间里寻找最优解，但是dp在找解的时候已经找到了子问题的最优解，也就是说他已经把子问题里面不可能的状态排除掉了 算法设计 把现在面对的局面看做x 对于x，需要求得答案是fx，目标是求出来fT，找出x和哪些局面p有关，写出一个状态专业方程，来求fp到fx的关系 也就是考虑现在我是谁，和我从哪里来（或者我到哪里去）]]></content>
      <categories>
        <category>算法</category>
        <category>动态规划</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
        <tag>DP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nAssignment3StyleTransfer]]></title>
    <url>%2F2019%2F05%2F22%2FCS231nAssignment3StyleTransfer%2F</url>
    <content type="text"><![CDATA[target 现在有两张图片，需要产生一些新的图片是一张图片的内容但是是另一张图片的style 首先我们希望可以构建一个loss function，可以连接style和每个不同的image，然后在每个图片的pixel上面降低gradient 在这个里面用squeezeNet（在ImageNet上面pretrain的）来提取图片的feature 预先设定好的函数 因为在这部分直接处理的是jpeg的图片而不是cifar-10的图片了，所以在这部分需要对出片进行预处理 同时需要设定一个dtype = torch.FloatTensor 来设计是用CPU跑还是用GPU跑（GPU的里面会带cuda） CNN = torchvision.models.squeezenet1_1(pretrained=True).features提取squeezenet的model，并且设定CNN的type等于上面设定好的dtype 因为不需要再进行训练了，需要把cnn里面的所有自动计算grad的功能关掉 提取特征 输入 x，一个tensor，大小是(N,C,H,W),里面是一个minibatch的数据 cnn，刚才载入好的model 输出 features，一个list，features[i]的大小是(N,C_i,H_i,W_i) 在不同层得到的feature会有不同的channel的数量以及H和W的大小 实现： 在具体的代码实现里面，直接用value得到每一层之后的结果，下一层的输入就是上一层得到的结果123456789def extract_features(x, cnn): features = [] prev_feat = x for i, module in enumerate(cnn._modules.values()): next_feat = module(prev_feat) features.append(next_feat) prev_feat = next_feat return features 计算lossloss一共由三个部分组成，分别是：图片content的loss + style的loss + total var loss 我们这个东西的目的是用一张图片的内容和另一个图片的style 当内容偏离了content图片的content，style偏离了stype图片的时候就需要penalize（处罚） 为了实现这个功能，我们需要用hybrid的loss，并且不是在weights上面调参，而是在每张图片的pixel上面调整 content loss 这个函数衡量生成的图片的feature map和原来作为content的图片偏离多少 我们只关心这个network里面的一层的表示，这一层会有自己特定的channel数量以及filter的大小 我们需要把这个feature map reshape，把所有的空间位置组合到同一个维度上面 但是在实际的实现上面，我们不需要再reshape了，因为大小可以直接对应处理了 123456789101112131415161718def content_loss(content_weight, content_current, content_original): """ Compute the content loss for style transfer. Inputs: - content_weight: Scalar giving the weighting for the content loss. - content_current: features of the current image; this is a PyTorch Tensor of shape (1, C_l, H_l, W_l). - content_target: features of the content image, Tensor with shape (1, C_l, H_l, W_l). Returns: - scalar content loss """ # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** return content_weight * torch.sum((content_original - content_current)**2) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** style loss对于一个给定的层layer，定义loss 计算Gram Mat，G，表示不同filter的相关性。这个矩阵是个协方差矩阵，我们希望形成的图片的activation 统计和style图片的可以match，计算这两个的协方差就是一个办法（并且经过验证效果比较好） 给定一个feature map，G矩阵的形状应该是（Cl，Cl）。Cl是这一层的filter的数量。里面的元素应该等于两个filter的乘积 把生成图片的G和style图片的G做差，平方和就是一层的loss 所有层的loss加在一起就是总共的loss G Mat implement view(),形成一个内容相同但是大小不同的tensor .matmul 两个tensor相乘 .permute 给tensor里面的维度换位12345678910111213141516171819202122232425262728293031def gram_matrix(features, normalize=True): """ Compute the Gram matrix from features. Inputs: - features: PyTorch Tensor of shape (N, C, H, W) giving features for a batch of N images. - normalize: optional, whether to normalize the Gram matrix If True, divide the Gram matrix by the number of neurons (H * W * C) Returns: - gram: PyTorch Tensor of shape (N, C, C) giving the (optionally normalized) Gram matrices for the N input images. """ # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N,C,H,W = features.size() # N,C,M features = features.view(N,C,H*W) # N,C,M x N,M,C -&gt; N,C,C gram = features.matmul(features.permute(0,2,1)) if normalize==True: gram /= (H*W*C) return gram # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** loss implement 输入 feats：现在图片的每一层的feature，从上面的提取特征函数得到 style_layers：indices style_targets：和上面的长度相同，计算的是第i层原图片得到的G Mat style_weights：scalar 在计算的时候只需要考虑每一层里面计算出来的现在的G Mat（注意索引不是i）和原图片的G，和上面一样的计算就可以了 123456789101112131415161718192021222324252627282930313233# Now put it together in the style_loss function...def style_loss(feats, style_layers, style_targets, style_weights): """ Computes the style loss at a set of layers. Inputs: - feats: list of the features at every layer of the current image, as produced by the extract_features function. - style_layers: List of layer indices into feats giving the layers to include in the style loss. - style_targets: List of the same length as style_layers, where style_targets[i] is a PyTorch Tensor giving the Gram matrix of the source style image computed at layer style_layers[i]. - style_weights: List of the same length as style_layers, where style_weights[i] is a scalar giving the weight for the style loss at layer style_layers[i]. Returns: - style_loss: A PyTorch Tensor holding a scalar giving the style loss. """ # Hint: you can do this with one for loop over the style layers, and should # not be very much code (~5 lines). You will need to use your gram_matrix function. # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** loss = torch.tensor(0.).type(dtype) for i in range(len(style_layers)): G_Mat = gram_matrix(feats[style_layers[i]]) loss_layer = style_weights[i] * torch.sum((style_targets[i] - G_Mat)**2) loss += loss_layer return loss # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** total-variation reg 为了让图片显示的内容更加平滑，加入了这个惩罚部分 计算的方法可以是计算每个像素和它相邻像素的差的平方和（相邻像素分别包括垂直和水平） 需要让结果vec化，直接用-1把矩阵错位一个 123456789101112131415161718192021def tv_loss(img, tv_weight): """ Compute total variation loss. Inputs: - img: PyTorch Variable of shape (1, 3, H, W) holding an input image. - tv_weight: Scalar giving the weight w_t to use for the TV loss. Returns: - loss: PyTorch Variable holding a scalar giving the total variation loss for img weighted by tv_weight. """ # Your implementation should be vectorized and not require any loops! # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** H_var = torch.sum((img[:,:,1:,:] - img[:,:,:-1,:])**2) W_var = torch.sum((img[:,:,:,1:] - img[:,:,:,:-1])**2) return (H_var + W_var) * tv_weight # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** 已经写好了转化style的函数 首先提取content和style图片的特征 然后初始化需要生成的图片，这张图片上面需要打开grad 设置好hyper，设定好optimizer 然后在一定的范围里，用cnn提取现在图片的特征 用现在的特征计算loss，然后改变现在的图片]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
        <category>CS231n作业</category>
      </categories>
      <tags>
        <tag>style transfer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nassignment3Vis]]></title>
    <url>%2F2019%2F05%2F21%2FCS231nassignment3Vis%2F</url>
    <content type="text"><![CDATA[Network Visualization (PyTorch) 在这部分用了一个已经在ImageNet上面pretrain过的CNN 用这个CNN来定义一个loss function，然后用这个loss来测量现在的不高兴程度 back的时候计算这个loss对于每个像素的gradient 保持这个model不变，但是在图片上面展示出来gradients的下降，形成让loss最小的图片 这个作业一共分成三个部分： saliency map：一个比较快的方法来展示这个图片哪个部分影响了net分类的决定 fooling image：扰乱一个图片，让他看起来跟人似的，但是会被误分类 class visualization：形成可以得到最大分类得分的图片 注意这里需要先激活conda，不然在jupter里面torch会报错 事先处理 事先定义了函数preprocess的部分，因为pretrain的时候也是提前进行好了预处理 需要下载下来预处理的模型，这里用的是SqueezeNet，因为这样可以直接在CPU上面形成图片 读取一部分ImageNet里面的图片看一看是什么样子的 saliency maps saliency告诉我们每个pixel对分类得分的影响 为了计算这个东西，我们需要计算没有正则化之前的score对于正确分类的gradient（具体到每个pixel） 比如图片的大小是3xHxW，那么得到的gradient的形状也应该是3xHxW 表示的就是这个pixel改变的话对于整个结果改变的影响 为了计算，我们取每个gradient的绝对值，然后取三个channel里面的最大值，最后得到的大小是HxW gather method 就像在assignment1里面选择一个矩阵里面的最大值一样，gather这个方法就是在s.gather(1, y.view(-1, 1)).squeeze()一个N，C的矩阵s里面选择对应的y那个的值然后形成一个行的数组 compute_saliency_map 输入： X:输入的图片 (N,3,H,W) y:label (N,) model:预训练好的模型 输出： saliency，大小是（N，H，W） 注意，因为torch这个对象自己本来就已经带着grad了，所以直接求出来就可以了，但是注意需要定义一下backward之后的大小应该是多少 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def compute_saliency_maps(X, y, model): """ Compute a class saliency map using the model for images X and labels y. Input: - X: Input images; Tensor of shape (N, 3, H, W) - y: Labels for X; LongTensor of shape (N,) - model: A pretrained CNN that will be used to compute the saliency map. Returns: - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input images. """ # Make sure the model is in "test" mode model.eval() # Make input tensor require gradient X.requires_grad_() saliency = None ############################################################################## # TODO: Implement this function. Perform a forward and backward pass through # # the model to compute the gradient of the correct class score with respect # # to each input image. You first want to compute the loss over the correct # # scores (we'll combine losses across a batch by summing), and then compute # # the gradients with a backward pass. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** #forward #NxC scores = model(X) #N correct_scores = scores.gather(1,y.view(-1,1)).squeeze() #backward correct_scores.backward(torch.ones(correct_scores.size())) saliency = X.grad saliency = saliency.abs() saliency,_ = torch.max(saliency, dim = 1) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return saliency fooling images 可以生成fooling image，给一个image和一个目标class，我们让gradient一直升高，去让目标的score最大，一直到最后的分类是目标的分类 输入 X (1,3,224,224) target_y 在0-1000的范围里面 model 预训练的CNN 输出： x_fooling TODO When computing an update step, first normalize the gradient:# dX = learning_rate * g / ||g||_2 需要自己写一个训练的部分 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def make_fooling_image(X, target_y, model): """ Generate a fooling image that is close to X, but that the model classifies as target_y. Inputs: - X: Input image; Tensor of shape (1, 3, 224, 224) - target_y: An integer in the range [0, 1000) - model: A pretrained CNN Returns: - X_fooling: An image that is close to X, but that is classifed as target_y by the model. """ # Initialize our fooling image to the input image, and make it require gradient X_fooling = X.clone() X_fooling = X_fooling.requires_grad_() learning_rate = 1 ############################################################################## # TODO: Generate a fooling image X_fooling that the model will classify as # # the class target_y. You should perform gradient ascent on the score of the # # target class, stopping when the model is fooled. # # When computing an update step, first normalize the gradient: # # dX = learning_rate * g / ||g||_2 # # # # You should write a training loop. # # # # HINT: For most examples, you should be able to generate a fooling image # # in fewer than 100 iterations of gradient ascent. # # You can print your progress over iterations to check your algorithm. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** for i in range(100): scores = model(X_fooling) index = torch.argmax(scores,dim = 1) if index[0] == target_y: break target_score = scores[0,target_y] target_score.backward() grad = X_fooling.grad.data X_fooling.data += learning_rate * (grad/grad.norm()) X_fooling.grad.zero_() # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return X_fooling class visualization 从一个随机的noise开始然后往目标的class上面增加gradient 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980def create_class_visualization(target_y, model, dtype, **kwargs): """ Generate an image to maximize the score of target_y under a pretrained model. Inputs: - target_y: Integer in the range [0, 1000) giving the index of the class - model: A pretrained CNN that will be used to generate the image - dtype: Torch datatype to use for computations Keyword arguments: - l2_reg: Strength of L2 regularization on the image - learning_rate: How big of a step to take - num_iterations: How many iterations to use - blur_every: How often to blur the image as an implicit regularizer - max_jitter: How much to gjitter the image as an implicit regularizer - show_every: How often to show the intermediate result """ model.type(dtype) l2_reg = kwargs.pop('l2_reg', 1e-3) learning_rate = kwargs.pop('learning_rate', 25) num_iterations = kwargs.pop('num_iterations', 100) blur_every = kwargs.pop('blur_every', 10) max_jitter = kwargs.pop('max_jitter', 16) show_every = kwargs.pop('show_every', 25) # Randomly initialize the image as a PyTorch Tensor, and make it requires gradient. img = torch.randn(1, 3, 224, 224).mul_(1.0).type(dtype).requires_grad_() for t in range(num_iterations): # Randomly jitter the image a bit; this gives slightly nicer results ox, oy = random.randint(0, max_jitter), random.randint(0, max_jitter) img.data.copy_(jitter(img.data, ox, oy)) ######################################################################## # TODO: Use the model to compute the gradient of the score for the # # class target_y with respect to the pixels of the image, and make a # # gradient step on the image using the learning rate. Don't forget the # # L2 regularization term! # # Be very careful about the signs of elements in your code. # ######################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** scores = model(img) target_score = scores[0,target_y] target_score.backward() grad = img.grad.data grad -= 2*l2_reg * img.data img.data += learning_rate * (grad/grad.norm()) img.grad.zero_() # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ######################################################################## # END OF YOUR CODE # ######################################################################## # Undo the random jitter img.data.copy_(jitter(img.data, -ox, -oy)) # As regularizer, clamp and periodically blur the image for c in range(3): lo = float(-SQUEEZENET_MEAN[c] / SQUEEZENET_STD[c]) hi = float((1.0 - SQUEEZENET_MEAN[c]) / SQUEEZENET_STD[c]) img.data[:, c].clamp_(min=lo, max=hi) if t % blur_every == 0: blur_image(img.data, sigma=0.5) # Periodically show the image if t == 0 or (t + 1) % show_every == 0 or t == num_iterations - 1: plt.imshow(deprocess(img.data.clone().cpu())) class_name = class_names[target_y] plt.title('%s\nIteration %d / %d' % (class_name, t + 1, num_iterations)) plt.gcf().set_size_inches(4, 4) plt.axis('off') plt.show() return deprocess(img.data.cpu())]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
        <category>CS231n作业</category>
      </categories>
      <tags>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nassignment3LSTM]]></title>
    <url>%2F2019%2F05%2F17%2FCS231nassignment3LSTM%2F</url>
    <content type="text"><![CDATA[targetimplement LSTM update rule and use it for image captioning LSTM 在vanilla RNN里面，可以根据vanilla来计算长的sequence，但是同样会因为不停的乘矩阵导致gradient爆炸的问题，LSTM主要就是用了一个其他的update rule解决了这个问题 和vanilla RNN差不多，现在这个step的x，前一个hidden state。LSTM保持着H-d的cell state，所以也会从前一个接收到前一个的cell state。 LSTM会学一个input-to-hidden的矩阵 4HxD， hidden-to-hidden的矩阵 4HxH， bias 4H 在每一部都会先计算被激活之后的函数（4H），然后把这个结果a分成四个部分，每个部分的大小是H 根据这四个部分计算input gate，forget gate，output gate，block gate 前三个都用sigmoid激活，最后一个用tanh激活 然后用上面的四个参数计算下一个cell state和hidden state step forward 输入的大小是D，hidden的大小是H，minibatch的大小是N input x (N,D) prev_h (N,H) prev_c (N,H) Wx input 2 hidden (D,4H) Wh hidden 2 hidden (H,4H) bias, (4H) output next_h (N,H) next_c (N,H) cache 按照之前给的公式直接计算就行了，其实就是把原来求出来的值分成了四个部分，分别求出来了四个新的值，用这四个新的值的公式可以得到下一个状态的c和h step backward input dnext_h (N,H) 都是上面一个回来的 dnext_c (N,H) cache output dx(N,D) dprev_h (N,H) dprev_c (N,H) dWx (D,4H) dWh (H,4H) db (4H) 按着正方向计算的顺序back回去就可以了，注意这里有个问题就是因为next_c被用来计算next h了，所以dnext_c需要再求一下关于next h的导数，并且把求出来的新的值加在以前的东西上面 后面的矩阵计算尺寸 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124def lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b): """ Forward pass for a single timestep of an LSTM. The input data has dimension D, the hidden state has dimension H, and we use a minibatch size of N. Note that a sigmoid() function has already been provided for you in this file. Inputs: - x: Input data, of shape (N, D) - prev_h: Previous hidden state, of shape (N, H) - prev_c: previous cell state, of shape (N, H) - Wx: Input-to-hidden weights, of shape (D, 4H) - Wh: Hidden-to-hidden weights, of shape (H, 4H) - b: Biases, of shape (4H,) Returns a tuple of: - next_h: Next hidden state, of shape (N, H) - next_c: Next cell state, of shape (N, H) - cache: Tuple of values needed for backward pass. """ next_h, next_c, cache = None, None, None ############################################################################# # TODO: Implement the forward pass for a single timestep of an LSTM. # # You may want to use the numerically stable sigmoid implementation above. # ############################################################################# # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, H = prev_h.shape # -&gt; N,4H a = x.dot(Wx) + prev_h.dot(Wh) + b a_i = a[:, :H] a_f = a[:, H:2 * H] a_o = a[:, 2 * H:3 * H] a_g = a[:, 3 * H:] i = sigmoid(a_i) f = sigmoid(a_f) o = sigmoid(a_o) g = np.tanh(a_g) next_c = f * prev_c + i * g next_h = o * np.tanh(next_c) cache = (x, prev_h, prev_c, Wx, Wh, a, i, f, o, g, next_c, next_h) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return next_h, next_c, cachedef lstm_step_backward(dnext_h, dnext_c, cache): """ Backward pass for a single timestep of an LSTM. Inputs: - dnext_h: Gradients of next hidden state, of shape (N, H) - dnext_c: Gradients of next cell state, of shape (N, H) - cache: Values from the forward pass Returns a tuple of: - dx: Gradient of input data, of shape (N, D) - dprev_h: Gradient of previous hidden state, of shape (N, H) - dprev_c: Gradient of previous cell state, of shape (N, H) - dWx: Gradient of input-to-hidden weights, of shape (D, 4H) - dWh: Gradient of hidden-to-hidden weights, of shape (H, 4H) - db: Gradient of biases, of shape (4H,) """ dx, dprev_h, dprev_c, dWx, dWh, db = None, None, None, None, None, None ############################################################################# # TODO: Implement the backward pass for a single timestep of an LSTM. # # # # HINT: For sigmoid and tanh you can compute local derivatives in terms of # # the output value from the nonlinearity. # ############################################################################# # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, H = dnext_h.shape x, prev_h, prev_c, Wx, Wh, a, i, f, o, g, next_c, next_h = cache # dnext_h/do -&gt; do do = np.tanh(next_c) * dnext_h # dnext_h/dnext_c dnext_c = o * (1 - np.tanh(next_c) ** 2) * dnext_h + dnext_c # dnext_c/df -&gt; df df = prev_c * dnext_c # dnext_c/dprev_c dprev_c = f * dnext_c # dnext_c/di di = g * dnext_c # dnext_c/dg dg = i * dnext_c da = np.zeros((N, 4 * H)) # sigmoid i da[:, :H] = i * (1 - i) * di da[:, H:2 * H] = f * (1 - f) * df da[:, 2 * H:3 * H] = o * (1 - o) * do da[:, 3 * H:] = (1 - g * g) * dg # a = x.dot(Wx) + prev_h.dot(Wh) + b # N,4H D,4H dx = da.dot(Wx.T) # N,D N,4H dWx = x.T.dot(da) # N,4H H,4H dprev_h = da.dot(Wh.T) # N,H N,4H dWh = prev_h.T.dot(da) # da N,4H db = np.sum(da, axis=0) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dx, dprev_h, dprev_c, dWx, dWh, db forward 输入了一大串data，假设输入的data包括了T个vector，每个的dim是D，用的hidden的大小是H，在N的minibatch上面进行，返回对于所有time step的hidden state 初始化的cell是0，不会return cell state，只是LSTM自己的变量 输入 x (N,T,D) h0, (N,H) Wx (D,4H) Wh (H,4H) b (4H) out h (N,T,D) cache 注意h是需要初始化为0的，每次for里面拿出来的是h里面的一部分来赋值 backward 和之前的差不多，注意W和b都是要积累的，之前都是要初始化的 而且back的时候要用reversed的顺序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104def lstm_forward(x, h0, Wx, Wh, b): """ Forward pass for an LSTM over an entire sequence of data. We assume an input sequence composed of T vectors, each of dimension D. The LSTM uses a hidden size of H, and we work over a minibatch containing N sequences. After running the LSTM forward, we return the hidden states for all timesteps. Note that the initial cell state is passed as input, but the initial cell state is set to zero. Also note that the cell state is not returned; it is an internal variable to the LSTM and is not accessed from outside. Inputs: - x: Input data of shape (N, T, D) - h0: Initial hidden state of shape (N, H) - Wx: Weights for input-to-hidden connections, of shape (D, 4H) - Wh: Weights for hidden-to-hidden connections, of shape (H, 4H) - b: Biases of shape (4H,) Returns a tuple of: - h: Hidden states for all timesteps of all sequences, of shape (N, T, H) - cache: Values needed for the backward pass. """ h, cache = None, None ############################################################################# # TODO: Implement the forward pass for an LSTM over an entire timeseries. # # You should use the lstm_step_forward function that you just defined. # ############################################################################# # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, T, D = x.shape N, H = h0.shape prev_h = h0 prev_c = np.zeros((N, H)) cache = &#123;&#125; h = np.zeros((N, T, H)) for step in range(T): prev_h, prev_c, cache_step = lstm_step_forward( x[:, step, :], prev_h, prev_c, Wx, Wh, b) h[:, step, :] = prev_h cache[step] = cache_step # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return h, cachedef lstm_backward(dh, cache): """ Backward pass for an LSTM over an entire sequence of data.] Inputs: - dh: Upstream gradients of hidden states, of shape (N, T, H) - cache: Values from the forward pass Returns a tuple of: - dx: Gradient of input data of shape (N, T, D) - dh0: Gradient of initial hidden state of shape (N, H) - dWx: Gradient of input-to-hidden weight matrix of shape (D, 4H) - dWh: Gradient of hidden-to-hidden weight matrix of shape (H, 4H) - db: Gradient of biases, of shape (4H,) """ dx, dh0, dWx, dWh, db = None, None, None, None, None ############################################################################# # TODO: Implement the backward pass for an LSTM over an entire timeseries. # # You should use the lstm_step_backward function that you just defined. # ############################################################################# # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x = cache[0][0] # 注意这是一个step里面的x，大小是N，D N, D = x.shape _, T, H = dh.shape dx = np.zeros((N, T, D)) dprev_h = np.zeros((N, H)) dprev_c = np.zeros((N, H)) dh0 = np.zeros((N, H)) dWx = np.zeros((D, 4 * H)) dWh = np.zeros((H, 4 * H)) db = np.zeros(4 * H) for step in reversed(range(T)): dnext_h = dh[:, step, :] + dprev_h dnext_c = dprev_c dx[:, step, :], dprev_h, dprev_c, dWx_temp, dWh_temp, db_temp = lstm_step_backward( dnext_h, dnext_c, cache[step]) dWx += dWx_temp dWh += dWh_temp db += db_temp dh0 = dprev_h # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dx, dh0, dWx, dWh, db 剩下的和RNN部分没有什么区别了，主要就是把代码的选项里面加上lstm的部分]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
        <category>CS231n作业</category>
      </categories>
      <tags>
        <tag>word captioning</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于github删除和ignore]]></title>
    <url>%2F2019%2F05%2F16%2F%E5%85%B3%E4%BA%8Egithub%E5%88%A0%E9%99%A4%E5%92%8Cignore%2F</url>
    <content type="text"><![CDATA[removeadd过的文件如果想要都撤销了修改git rm -r --cached .（不小心add之后关上了的情况）如果status之后就发现不对，可以用git reset HEAD &lt;file&gt;，后面加点就是撤销全部的 如果已经push了，可以还原版本12345git revert HEAD 撤销前一次 commit git revert HEAD^ 撤销前前一次 commit git revert commit-id (撤销指定的版本，撤销也会作为一次提交进行保存） (ref：https://blog.csdn.net/kongbaidepao/article/details/52253774) ignore有一些比较大的文件想要忽略掉的，需要在根目录建立一个.gitignore，里面直接放需要的路径就可以了 不要往里面传很大的数据鸭会爆炸的TAT]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>gitignore</tag>
        <tag>remove</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment3RNN]]></title>
    <url>%2F2019%2F05%2F10%2FCS231Nassignment3RNN%2F</url>
    <content type="text"><![CDATA[assignment3 targetIn this exercise you will implement a vanilla recurrent neural networks and use them it to train a model that can generate novel captions for images. Microsoft COCO 在这次的作业里用的是Microsoft的coco dataset，已经是一个很常用的给文字配上说明文（captioning）的dataset了，有80000个训练和40000个val，每个图片包含一个五个字的注释 在这个作业里已经preprocess了data，每个图片已经从VGG-16（ImageNet pretrain）layer 7提取了feature，存在了train2014_vgg16_fc7.h5和val2014_vgg16_fc7.h5 为了减少处理的时间和内存，feature的特征从4096降到了512 真实的图片太大了，所以把图片的url存在了txt里面，这样在vis的时候可以直接下载这些图片（必须联网） 直接处理string的效率太低了，所以在caption的一个encoded版本上面进行处理，这样可以把string表示成一串int。在dataset里面也有这两个之间转换的信息 -&gt; 在转换的时候也加了更多的tokens 事先看了一下图片和对应的语句 RNN 在这章要用rnn language model来进行image captioning cs231n/rnn_layers.py step forwardvanilla RNN的single timestep，用tanh来激活。输入data的大小是D，hidden layer的大小是H，minibatch的大小是N 输入 x(N,D) prev_h:前一个timestep的hidden (N,H) Wx:input- to- hidden connections (D,H) Wh:hidden-to-hidden connections (H,H) b:bias,(H,) 返回(tuple): next_h:下一个hidden state，(N,H) cache:back需要的数据 构成: RNN用的就是上一个的h，这一个的x同时乘以不同的参数，合在一起预测这一次的h 对于某个时间点上的输入，还需要上一个的state h，参数W，乘在一起得到新的state 这个参数的W无论在哪个步骤里面使用，一直都是一样的 1234567891011121314151617181920212223242526272829303132333435363738def rnn_step_forward(x, prev_h, Wx, Wh, b): """ Run the forward pass for a single timestep of a vanilla RNN that uses a tanh activation function. The input data has dimension D, the hidden state has dimension H, and we use a minibatch size of N. Inputs: - x: Input data for this timestep, of shape (N, D). - prev_h: Hidden state from previous timestep, of shape (N, H) - Wx: Weight matrix for input-to-hidden connections, of shape (D, H) - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H) - b: Biases of shape (H,) Returns a tuple of: - next_h: Next hidden state, of shape (N, H) - cache: Tuple of values needed for the backward pass. """ next_h, cache = None, None ############################################################################## # TODO: Implement a single forward step for the vanilla RNN. Store the next # # hidden state and any values you need for the backward pass in the next_h # # and cache variables respectively. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x_1 = x.dot(Wx) h_1 = prev_h.dot(Wh) x_raw = x_1 + h_1 + b next_h = np.tanh(x_raw) cache = (x, prev_h, Wx, Wh, x_raw, next_h) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return next_h, cache step backward 输入： dnext，下一个state的loss的gradient，(N,H) cache 输出： dx:input的gradient，(N,D) dprev_h:前一个hidden state的gradient，(N,H) dWx:Wx的gradient,(D,H) dWh:Wh的gradient，(H,H) db:bias的gradient，(H,) 其实这个求起来gradient更简单了，因为每一个的导数都很好求，搞对了矩阵的形状就可以了 123456789101112131415161718192021222324252627282930313233343536373839404142434445def rnn_step_backward(dnext_h, cache): """ Backward pass for a single timestep of a vanilla RNN. Inputs: - dnext_h: Gradient of loss with respect to next hidden state, of shape (N, H) - cache: Cache object from the forward pass Returns a tuple of: - dx: Gradients of input data, of shape (N, D) - dprev_h: Gradients of previous hidden state, of shape (N, H) - dWx: Gradients of input-to-hidden weights, of shape (D, H) - dWh: Gradients of hidden-to-hidden weights, of shape (H, H) - db: Gradients of bias vector, of shape (H,) """ dx, dprev_h, dWx, dWh, db = None, None, None, None, None ############################################################################## # TODO: Implement the backward pass for a single step of a vanilla RNN. # # # # HINT: For the tanh function, you can compute the local derivative in terms # # of the output value from tanh. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x, prev_h, Wx, Wh, x_raw, next_h = cache # d(tanh) = 1 - tanh * tanh # NxH dx_raw = (1 - next_h * next_h) * dnext_h # H, db = np.sum(dx_raw, axis=0) # N,D .T x N,H -&gt; DxH dWx = x.T.dot(dx_raw) # N H x D,H dx = dx_raw.dot(Wx.T) # N,H .T x N,H dWh = prev_h.T.dot(dx_raw) # N,H dprev_h = dx_raw.dot(Wh.T) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dx, dprev_h, dWx, dWh, db forward + backwoard 刚才只是实现了每一步的forward和backward，现在要实现整个的这个过程了 forward 假设输入的是一系列由T个vector组成的，每个的大小是D minibatch的大小是N，hidden的大小是H，返回整个timesetps里面的hidden state 输入 整个timestep里面的数据x(N,T,D) h0，初始化的hidden state(N,H) Wx (D,H) Wh (H,H) b (H,) 输出 h整个timestep里面的states(N,T,H) cache 实际上就是首先设置了最开始的输入h0，然后在时间循环T里面不停的调用上面已经写好的step的函数，更新prev_h，把不同的值存在cache里面 注意h需要初始化！！ backward 输入了dh和cache，需要输出所有东西的gradient 思路主要是每一个step里面是加的关系，所以对于dWx，dWh和db来说，需要在每次遍历里面加上之前的值，相当于每次都需要加上新的东西 back的时候需要next的时候来求现在的，然后在下一轮把next更新成现在的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899def rnn_forward(x, h0, Wx, Wh, b): """ Run a vanilla RNN forward on an entire sequence of data. We assume an input sequence composed of T vectors, each of dimension D. The RNN uses a hidden size of H, and we work over a minibatch containing N sequences. After running the RNN forward, we return the hidden states for all timesteps. Inputs: - x: Input data for the entire timeseries, of shape (N, T, D). - h0: Initial hidden state, of shape (N, H) - Wx: Weight matrix for input-to-hidden connections, of shape (D, H) - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H) - b: Biases of shape (H,) Returns a tuple of: - h: Hidden states for the entire timeseries, of shape (N, T, H). - cache: Values needed in the backward pass """ h, cache = None, None ############################################################################## # TODO: Implement forward pass for a vanilla RNN running on a sequence of # # input data. You should use the rnn_step_forward function that you defined # # above. You can use a for loop to help compute the forward pass. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, T, D = x.shape N, H = h0.shape h = np.zeros((N, T, H)) prev_h = h0 cache = &#123;&#125; for i in range(T): prev_h, cache_i = rnn_step_forward(x[:, i, :], prev_h, Wx, Wh, b) h[:, i, :] = prev_h cache[i] = cache_i # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return h, cachedef rnn_backward(dh, cache): """ Compute the backward pass for a vanilla RNN over an entire sequence of data. Inputs: - dh: Upstream gradients of all hidden states, of shape (N, T, H). NOTE: 'dh' contains the upstream gradients produced by the individual loss functions at each timestep, *not* the gradients being passed between timesteps (which you'll have to compute yourself by calling rnn_step_backward in a loop). Returns a tuple of: - dx: Gradient of inputs, of shape (N, T, D) - dh0: Gradient of initial hidden state, of shape (N, H) - dWx: Gradient of input-to-hidden weights, of shape (D, H) - dWh: Gradient of hidden-to-hidden weights, of shape (H, H) - db: Gradient of biases, of shape (H,) """ dx, dh0, dWx, dWh, db = None, None, None, None, None ############################################################################## # TODO: Implement the backward pass for a vanilla RNN running an entire # # sequence of data. You should use the rnn_step_backward function that you # # defined above. You can use a for loop to help compute the backward pass. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, T, H = dh.shape N, D = cache[0][0].shape dx = np.zeros((N, T, D)) dh0 = np.zeros((N, H)) dWx = np.zeros((D, H)) dWh = np.zeros((H, H)) db = np.zeros(H) dprev_h = np.zeros((N, H)) for i in reversed(range(T)): cache_i = cache[i] dnext_h = dh[:, i, :] + dprev_h dx[:, i, :], dprev_h, dWx_tmp, dWh_tmp, db_tmp = rnn_step_backward( dnext_h, cache_i) dWx += dWx_tmp dWh += dWh_tmp db += db_tmp dh0 = dprev_h # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dx, dh0, dWx, dWh, db word embedding在深度学习的系统里面主要是用vector来表示单词的，字典里面的每一个都会关系到一个vector，然后这些vectors会和系统的其他部分一起学习在这部分需要把int表示的单词转化成vectors 理解 在一句话里面，一个单词就是一个维度，而word embedding的核心就是降维 把字组成段落，然后用段落来总结出来最后的核心内容 forward 一个minibatch的大小是N，长度是T，把每个单词给到一个大小是D的vector input x (N,T)一个N个数据，每个数据里面T个单词，T给出来的是单词的indice W (V,D)给所有word的vectors return out：(N,T,D)给所有单词一个D的vector cache backward back的时候不能back到word（因为是int），所以只需要得到embedding mat的gradient 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566def word_embedding_forward(x, W): """ Forward pass for word embeddings. We operate on minibatches of size N where each sequence has length T. We assume a vocabulary of V words, assigning each word to a vector of dimension D. Inputs: - x: Integer array of shape (N, T) giving indices of words. Each element idx of x muxt be in the range 0 &lt;= idx &lt; V. - W: Weight matrix of shape (V, D) giving word vectors for all words. Returns a tuple of: - out: Array of shape (N, T, D) giving word vectors for all input words. - cache: Values needed for the backward pass """ out, cache = None, None ############################################################################## # TODO: Implement the forward pass for word embeddings. # # # # HINT: This can be done in one line using NumPy's array indexing. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** out = W[x, :] cache = x, W # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return out, cachedef word_embedding_backward(dout, cache): """ Backward pass for word embeddings. We cannot back-propagate into the words since they are integers, so we only return gradient for the word embedding matrix. HINT: Look up the function np.add.at Inputs: - dout: Upstream gradients of shape (N, T, D) - cache: Values from the forward pass Returns: - dW: Gradient of word embedding matrix, of shape (V, D). """ dW = None ############################################################################## # TODO: Implement the backward pass for word embeddings. # # # # Note that words can appear more than once in a sequence. # # HINT: Look up the function np.add.at # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x, W = cache dW = np.zeros_like(W) np.add.at(dW, x, dout) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dW Temporal Affine layer 在每个timestep的时候，我们需要一个affine来把RNN的hidden vector转换成每个单词在vocabulary里面的scores（原来是根据这个来评分的，然后每次选出来一个合适的单词） 因为和之前做过的一样，所以直接提供了 Temporal SOftmax loss 在RNN的结构里面，每个timestep会生成一个对于vocabulary里面所有单词的score(矩阵) 在每步里面都知道ground truth，所以用softmax来计算每一步的loss和gradient，然后计算一个minibatch里面所有时间的平均loss 因为每个句子不一定一样长，所以在里面加上了NULL的token，让所有东西一边长，但是在计算loss的时候不希望计算这个NULL。所以还会接收一个mask来告诉这个函数哪个地方需要算哪个地方不需要算 RNN for image captioning 在cs231n/classifiers/rnn.py里面，现在只需要考虑vanialla RNN的问题 implement loss里面的forward和backward IO 输入 image features，大小是(N,D) captions：gorund truth，大小是(N,T)其中每个元素应该都在 0-V之间 输出 loss grads TODO affine trans，从图片的特征计算初始化的hidden state，输出的大小是 (N,H) -&gt; W_proj,b_proj -&gt; 这一步初始化的是h0，也就是最开始的状态 word embedding，把输入句子的int（表示在voca里面的位置）转化成vector，输出结果是(N,T,W) vanilla RNN（或者后面的LSTM）来计算中间的timestep里面hidden state的改变，输出结果(N,T,H) temporal affine来把每一步的结果转化成在vocabulary上面的score，(N,T,V) temporal softmax把score转化成loss，注意需要忽略mask上面没有的 在back的时候需要计算loss关于所有参数的gradient，存在上面的dict里面 实际上直接按照之前写好的一直操作就可以了！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105def loss(self, features, captions): """ Compute training-time loss for the RNN. We input image features and ground-truth captions for those images, and use an RNN (or LSTM) to compute loss and gradients on all parameters. Inputs: - features: Input image features, of shape (N, D) - captions: Ground-truth captions; an integer array of shape (N, T) where each element is in the range 0 &lt;= y[i, t] &lt; V Returns a tuple of: - loss: Scalar loss - grads: Dictionary of gradients parallel to self.params """ # Cut captions into two pieces: captions_in has everything but the last word # and will be input to the RNN; captions_out has everything but the first # word and this is what we will expect the RNN to generate. These are offset # by one relative to each other because the RNN should produce word (t+1) # after receiving word t. The first element of captions_in will be the START # token, and the first element of captions_out will be the first word. captions_in = captions[:, :-1] captions_out = captions[:, 1:] # You'll need this mask = (captions_out != self._null) # Weight and bias for the affine transform from image features to initial # hidden state W_proj, b_proj = self.params['W_proj'], self.params['b_proj'] # Word embedding matrix W_embed = self.params['W_embed'] # Input-to-hidden, hidden-to-hidden, and biases for the RNN Wx, Wh, b = self.params['Wx'], self.params['Wh'], self.params['b'] # Weight and bias for the hidden-to-vocab transformation. W_vocab, b_vocab = self.params['W_vocab'], self.params['b_vocab'] loss, grads = 0.0, &#123;&#125; ############################################################################ # TODO: Implement the forward and backward passes for the CaptioningRNN. # # In the forward pass you will need to do the following: # # (1) Use an affine transformation to compute the initial hidden state # # from the image features. This should produce an array of shape (N, H)# # (2) Use a word embedding layer to transform the words in captions_in # # from indices to vectors, giving an array of shape (N, T, W). # # (3) Use either a vanilla RNN or LSTM (depending on self.cell_type) to # # process the sequence of input word vectors and produce hidden state # # vectors for all timesteps, producing an array of shape (N, T, H). # # (4) Use a (temporal) affine transformation to compute scores over the # # vocabulary at every timestep using the hidden states, giving an # # array of shape (N, T, V). # # (5) Use (temporal) softmax to compute loss using captions_out, ignoring # # the points where the output word is &lt;NULL&gt; using the mask above. # # # # In the backward pass you will need to compute the gradient of the loss # # with respect to all model parameters. Use the loss and grads variables # # defined above to store loss and gradients; grads[k] should give the # # gradients for self.params[k]. # # # # Note also that you are allowed to make use of functions from layers.py # # in your implementation, if needed. # ############################################################################ # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** # N,D x D,H -&gt; N,H hidden_init, hidden_init_cache = affine_forward( features, W_proj, b_proj) # N,T -&gt; N,T,D embeding, embeding_cache = word_embedding_forward(captions_in, W_embed) # RNN -&gt; N,T,H if self.cell_type == 'rnn': hidden_state, hidden_cache = rnn_forward( embeding, hidden_init, Wx, Wh, b) # N,T,H x H,V -&gt; N,T,V scores, score_cache = temporal_affine_forward( hidden_state, W_vocab, b_vocab) # N,T,V -&gt; loss loss, dloss = temporal_softmax_loss(scores, captions_out, mask) grads = &#123;&#125; # gradient in temporal affine daffine_x, grads['W_vocab'], grads['b_vocab'] = temporal_affine_backward( dloss, score_cache) if self.cell_type == 'rnn': drnn, dh_init, grads['Wx'], grads['Wh'], grads['b'] = rnn_backward( daffine_x, hidden_cache) grads['W_embed'] = word_embedding_backward(drnn, embeding_cache) dfeatures, grads['W_proj'], grads['b_proj'] = affine_backward( dh_init, hidden_init_cache) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################ # END OF YOUR CODE # ############################################################################ return loss, grads overfit small data 和之前一样，写了一个solver来计算，包括了训练model的所有需要的东西，在optim..py里面有很多不同的update的方法 可以接受train或者val的data和label，可以得到训练或者val的acc。在训练之后这个model里面会保存最好的参数，让val最低 在这一步里面，载入了50个coco的训练数据，然后对一个model进行训练，最后得到的loss会小于0.1 test-time sampling 和分类不同，RNN训练和测试得到的结果会非常不相同 训练的时候，我们把ground-truth放进RNN 测试的时候，我们会sample出来每个timestep的单词的分布，然后把这些分布再喂到下一个step里面 implement在每次step里面，我们把现在的单词embed，和前一个hidden state一起输入进RNN里面，得到下一个hidden state，然后得到vocabulary上面的score，选择最有可能的单词然后根据这个单词得到下一个单词 输入： features (N,D) 还没有进行projection的数据 max_length：最长的caption的长度 输出 captions (N,max_length)，里面放的是0-V的int，第一个应该是 TODO 需要把features初始化，然后第一个输入的单词应该是(最开始) 在之后的每一步里面 用已经学习好的参数，embed上一个单词 RNN step，从上一个hidden和现在的embed得到下一个hidden（需要call每一步的函数而不是完整的函数） 把下一个转化成score 在score里面选择最有可能的单词，写出来这个单词的index， 为了简单，在出现之前不用停止 注意： 应该用的是affine来计算score而不是temporal，因为要计算的只是现在这个范围里面的score，计算出来的大小应该是(N,V)，所以应该在每行找到最合适的 每一步计算出来的最大值应该记在相应step的列上 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485def sample(self, features, max_length=30): """ Run a test-time forward pass for the model, sampling captions for input feature vectors. At each timestep, we embed the current word, pass it and the previous hidden state to the RNN to get the next hidden state, use the hidden state to get scores for all vocab words, and choose the word with the highest score as the next word. The initial hidden state is computed by applying an affine transform to the input image features, and the initial word is the &lt;START&gt; token. For LSTMs you will also have to keep track of the cell state; in that case the initial cell state should be zero. Inputs: - features: Array of input image features of shape (N, D). - max_length: Maximum length T of generated captions. Returns: - captions: Array of shape (N, max_length) giving sampled captions, where each element is an integer in the range [0, V). The first element of captions should be the first sampled word, not the &lt;START&gt; token. """ N = features.shape[0] captions = self._null * np.ones((N, max_length), dtype=np.int32) # Unpack parameters W_proj, b_proj = self.params['W_proj'], self.params['b_proj'] W_embed = self.params['W_embed'] Wx, Wh, b = self.params['Wx'], self.params['Wh'], self.params['b'] W_vocab, b_vocab = self.params['W_vocab'], self.params['b_vocab'] ########################################################################### # TODO: Implement test-time sampling for the model. You will need to # # initialize the hidden state of the RNN by applying the learned affine # # transform to the input image features. The first word that you feed to # # the RNN should be the &lt;START&gt; token; its value is stored in the # # variable self._start. At each timestep you will need to do to: # # (1) Embed the previous word using the learned word embeddings # # (2) Make an RNN step using the previous hidden state and the embedded # # current word to get the next hidden state. # # (3) Apply the learned affine transformation to the next hidden state to # # get scores for all words in the vocabulary # # (4) Select the word with the highest score as the next word, writing it # # (the word index) to the appropriate slot in the captions variable # # # # For simplicity, you do not need to stop generating after an &lt;END&gt; token # # is sampled, but you can if you want to. # # # # HINT: You will not be able to use the rnn_forward or lstm_forward # # functions; you'll need to call rnn_step_forward or lstm_step_forward in # # a loop. # # # # NOTE: we are still working over minibatches in this function. Also if # # you are using an LSTM, initialize the first cell state to zeros. # ########################################################################### # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** hidden_init, _ = affine_forward( features, W_proj, b_proj) start_word, _ = word_embedding_forward(self._start, W_embed) current_word = start_word next_state = hidden_init for step in range(max_length): prev_state = next_state if self.cell_type == 'rnn': next_state, _ = rnn_step_forward( current_word, prev_state, Wx, Wh, b) step_scores, _ = affine_forward( next_state, W_vocab, b_vocab) captions[:, step] = np.argmax(step_scores, axis=1) current_word, _ = word_embedding_forward( captions[:, step], W_embed) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################ # END OF YOUR CODE # ############################################################################ return captions]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
        <category>CS231n作业</category>
      </categories>
      <tags>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习OpenCV第19章，投影和3D视觉]]></title>
    <url>%2F2019%2F05%2F08%2FOpenCV19%2F</url>
    <content type="text"><![CDATA[Chapter 19首先会讨论从3D得到2D信息，然后再讨论从2D推断3D信息如果没有多张图片是很难得到靠谱的3D信息的： 通过stereo vision 通过motion Projections 得到了物体在三维里面的位置之后，因为我们在18章已经calibration了相机，所以可以得到这个点在图片里面的位置 提供了一个函数projectPoints来投影一系列的点，针对刚体 a list of loca‐ tions in the object’s own body-centered coordinate system 加上了平移和旋转，相机intrinsic和distortion 最后输出在画面上的店 Affine and Perspective Transformationsaffine是针对一个list或者一整张图片进行的，可以把一个point从图片的一个location移动到另一个location，perspective trans更多的是针对一个矩形图片 -&gt; related to prspective transformation 总结不同的函数 Bird’s-eye-view trans（p699） 在robtic巡航的时间，经常把排到的画面变成从上往下看的bird-view 需要相机的intrinsic和distortion （把棋盘放在地上进行calibration） 步骤 首先读取相机的参数和distortion model 找到地面上已知的店（比如chessboard），找到至少四个点 cv::getPerspectiveTransform()计算地面上已知点的homography H cv::warpPerspective()形成bird-eye-view three-dim pose estimation物体的三维pose可以从 一个相机：必须先考虑情况惹 多个相机捕捉：从多个不同图片来推断，这样即使是不知道的东西都可以操作 single camera 如果我们知道一个object，我们需要知道这个东西在他自己坐标系里面关键点的坐标 如果现在给了一个新的view point，可以根据关键点的位置来推断 cv::solvePnP() 用来计算一个know object的位置 从图片里面提取特征点，然后计算不同点的位置，这个问题的解是应该是唯一的 PNP问题不是每次都有唯一的解 如果没有足够的关键点，为了保险起见应该有足够的店 或者当物体离得特别远（这时候光线接近于平行了，就不好判断了） 总的来说，单目视觉和人自己的眼睛（单只）看东西的感觉差不多，不能获得精确的大小，还会产生一些错觉（比如把大楼的窗户设计的小来显得楼更高） Stereo Imaging在电脑中，通过计算在两张图里面都出现的点的位置来计算，这样就可以计算这个点的三维位置。虽然这样计算的计算量很大，但是可以通过一些方法来压缩搜寻的范围，从而得到相应的结果。主要分为4步： 在数学上remove掉相机lens的辐射和平移distortion -&gt; undistortion 调整相机之间的角度和距离 -&gt; rectification。这一步输出之后的两张图片应该是row-aligned的（frontal parallel） 找到左右两张图相同的feature -&gt; correspondence。这一步的输出是一个disparity map，输出的是两个图中相同特征点的x坐标方向上面的disparity 最后可以把disparity转换成triangulation，这一步叫做reprojection，这样输出的就是depth map了 triangulation（找到disparity和depth的关系） 整体概念如上图所示，在这张图里我们假设系统已经完全undistort，aligned（两张图片的行和行对上了）了，两个相机的平面完全相同，焦距也相同，并且两个相机的cx已经被calibrated好了（相同） 这时，这个物体点P的depth和disparity是成正比的，求出来的disparity是：xl - xr（xl和xr都是根据各自的相机中心的坐标）: T - (xl - xr)/Z - f = T/Z 这个关系虽然是正比但是不是线性的 当disparity接近0的时候，小的disparity的差异会引发非常大的depth的差异 当disparity非常大的时候，disparity的改变不会对depth引起太多的影响 最终，stereo的系统只在比较接近相机的部分有比较高的depth resolution（如下图所示） 上面的例子是二维转一维的，实际在OpenCV的系统里面是三维转二维的 在实际的应用里面相机不是那么理想的共线的，要尽量确保共线，才不会引起太多的distortion。最终的目的是通过math的计算让他共线，而不是在物理上共线 除此之外，还需要保证相机的拍摄是同步的，避免在拍摄的时候会有东西移动 Epipolar Geometry（简化双目模型）stereo image system的模型： 组合了两个pinhole model 加入了新的points epipoles 主要点： 对于每个相机都会有一个投影的中心O，并且有两个和这个相关的投影平面 在现实中的物体P会在两个投影平面上分别有投影pl和pr el或者er，定义是另一个相机的中心在这个投影平面上的投影，el和pl可以形成一条epipolar line 得到要义 每个三维的点，都会在每个相机上面得到一个epipolar的，这个点和pr/pl的交点就是epipolar line 一个图片里面的feature，在另一个图片里面必须在相对应的epipolar line上面（epipolar constraint） 上面那个定义意味着：可以把在图片上寻找特征从二维（图片）降低到一维（线） 并且图片的order会保存，比如一条线在两张图里面都是水平的 The Essential and Fundamental Matrices E Mat：包括了两个相机的translation和rotation F Mat：包括了E的信息，以及相机的intrinsic（在pixel的层面上关联两个相机） 二者的区别 E只知道两个相机的关系，不知道任何关于图片的信息，只在物体的层面上关联了两个相机 F关联了两个照片在各自图片坐标系里面的关系 E math + F mat（p713，还没有怎么看） 在左边的相机里，观察到的点是pl，在右边的相机观察到的点是pr pr = R（pl - T） cv::findFundamentalMatComputing Epipolar Lines(计算上面模型里面的那条线) 有了F Mat之后希望可以计算上面的epipolar line。每一个图片里面的line都会在另一张图片里有一个对应的line line用一个三个点的vector来表示 cv::computeCorrespondEpilines Stereo Calibration上面已经说了很多的理论知识了所以我们现在就开始calibration吧！ Stereo calibration是在空间上面计算两个相机的位置。相反，后面要说的rectification才是来保证两张图片行是共线的 Stereo calibration主要依靠的是找两个相机之间的T和R矩阵，这两个都可以用cv::stereoCalibrate()来计算 和单目相机的calibration有些相似，但是单目的相机要寻找一系列相机和chessboard之间的R和T 双目的calibration在寻找唯一一个能让左右相机匹配上的R和T 可以得到三个等式求解 因为图片的noise或者rounding error，每组得到的结果可能会有轻微的不同，最后会取中位数 calibration会把右边的相机放在和左边的相机相同的plane上面，这样这两个相机得到的图片就是parallel的，但是这时候还不是row-aligned的！！！ 可以直接通过用这一个函数计算相机的intrinsic，extrinsic和Stereo的参数，不用先进行calibration Stereo Rectification 如果两个图片aligned了，那么根据上面计算出来的disparity就可以很轻易的得到depth map了。但是在实际中只有相机没有这么容易做到 目标：我们需要reproject两个image plane，让他们在完全相同的plane里面，可以得到完美的aligned 我们希望在rectification之后图片的row aliged，这样stereo correspondence（在两个图片里找相同的点）就会变得更可信而且容易计算 在另一张照片里只找match一个点的row 这样的结果会有无限个待选 我们再人为的加上限制 结果会有八个term，四个给左边的相机，四个给右边的相机（两种计算这些参数的算法） 每个相机都会有distCoffs和旋转矩阵R，修正和未修正的相机矩阵（4个） 用上面这些东西，得到map来确定原图要怎么修改cv::initUndistortRectifyMap() Hartley’s algorithm + Bouguet’s algorithm（p730）Rectification mapStereo Correspondence 在两个图片里面match三维的点，只能在两张图片交叠的地方找到 两种不同的算法 block matching：快，效率高，基于“sum of absolute difference” (SAD） 只会找到高度符合的点（highly textured）-&gt; 户外 semi-global block matching (SGBM) ：精确度更高 matching is done at subpixel level using the Birchfield-Tomasi metric enforce a global smoothness constraint on the computed depth information that it approximates by considering many one-dimensional smoothness constraints through the region of interest Block matching三个步骤 prefiltering，normal图片的亮度，增强纹理 用SAD的窗口，搜索水平的epipolar line 在rectificatin之后，每行都是一个epipolar line，所以左边的图片肯定在右边的同一行里面有一个对应的部分 disparity会在一定的pixel范围里进行搜索，不同范围里的disparity代表的是不同的depth。但是超过了最大值的话就找不到depth了 -&gt; Each disparity limit defines a plane at a fixed depth from the cameras Postfiltering，减少比较差的结果 Semi-global block matchingcode example （p752）Structure from Motion 从移动中得到构造信息。但是在静止的情况下，一个相机移动得到的信息和两个相机得到的信息没有本质的区别 但是如果特别大的时候，就需要通过计算frame之间的关系得到最后的结果（SLAM？） 在附录 FitLine（直线拟合） 在三维的分析之中比较常用，所以在这里介绍]]></content>
      <categories>
        <category>图像处理</category>
        <category>OpenCV</category>
        <category>Projection</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Projection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode笔记]]></title>
    <url>%2F2019%2F05%2F07%2FLeetcode%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[进度： array部分差不多 string部分提高往后没有继续 math部分浅尝辄止 开始搞树的部分 1 twoSumGiven an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example: Given nums = [2, 7, 11, 15], target = 9, Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. 1234567class Solution: def twoSum(self, nums: List[int], target: int) -&gt; List[int]: for i, item in enumerate(nums): if target - item in nums and nums.index(target - item) != i: return [i, nums.index(target - item)] 总结： 刚开始用了直接for所有的元素的方法，忘记考虑当两个数字重复的时候需要怎么办，考虑了之后在非常大的数的情况下爆炸了 标准答案说到了hash表，但是其实在python实现里面本身就是个hash（不然怎么从索引得到结果），不需要考虑这个问题 然后考虑了把所有东西都放一个dict里面（毕竟hash？），但是遇到的问题是从value直接得到key会生一些问题。如果把数字作为key，索引作为value会发现数字有重复的，会覆盖key的值 这时候突然发现，如果用数字作为索引的话其实dict和list没有本质区别，在list里面操作就行了，而且list的.index()可以直接返回这个值得坐标（找到的是第一个值！！） 所以直接用enumerate把所有的index和item都列出来就可以解决了，神奇。 27 remove elementGiven an array nums and a value val, remove all instances of that value in-place and return the new length. Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory. The order of elements can be changed. It doesn’t matter what you leave beyond the new length. Example 1: Given nums = [3, 2, 2, 3], val = 3, Your function should return length = 2, with the first two elements of nums being 2. It doesn’t matter what you leave beyond the returned length.Example 2: Given nums = [0, 1, 2, 2, 3, 0, 4, 2], val = 2, Your function should return length = 5, with the first five elements of nums containing 0, 1, 3, 0, and 4. Note that the order of those five elements can be arbitrary. It doesn’t matter what values are set beyond the returned length. 12345678910111213class Solution: def removeElement(self, nums: List[int], val: int) -&gt; int: remove_nums = 0 ori_length = len(nums) for i in range(len(nums)): if nums[i] == val: remove_nums += 1 nums[i] = float('inf') nums.sort() nums = nums[:ori_length - remove_nums] return len(nums) 总结： 这道题的重点是需要in - place的处理，空间复杂度要求很高（然而我的空间结果很垃圾）。一个重点就是返回的list不需要按照原来的顺序排列 从不需要原来的顺序得到的思路是：我把需要删除的东西的位置改成了inf，然后对所有部分进行排序，得到排序之后的结果再进行切片（这里刚开始的思路是删掉这个地方的东西然后再insert，后来发现直接替换就好了） 其实也可以直接用交换位置的方法，不用切片，因为题目只需要前面的这些元素符合要求就可以了，没有说后面的怎么样。 看了一些discussion都是memory只比5 % 的人少。。。但是差距都不大应该没问题！ 看到了一个超级牛逼简要写法：1234while val in nums: nums.remove(val)return len(nums) 80Given a sorted array nums, remove the duplicates in-place such that duplicates appeared at most twice and return the new length. Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory. Example 1: Given nums = [1, 1, 1, 2, 2, 3], Your function should return length = 5, with the first five elements of nums being 1, 1, 2, 2 and 3 respectively. It doesn’t matter what you leave beyond the returned length. 1234567891011121314151617181920212223242526class Solution: def removeDuplicates(self, nums: List[int]) -&gt; int: i = 0 while(True): if i &gt;= len(nums) - 1: if len(nums) &gt; 2 and nums[i] == nums[i - 2]: nums = nums[:nums.index(nums[i]) + 2] break else: break if nums[i] == nums[i + 1]: i += 1 else: next_num = nums[i + 1] start_index = nums.index(nums[i]) next_index = nums.index(next_num) if next_index - start_index &gt; 2: for l in range(start_index + 2, next_index): nums[l] = float('inf') i = next_index while float('inf') in nums: nums.remove(float('inf')) return len(nums) 总结： 我深信我的方法虽然蠢但是没有问题，但是跑出来就是有问题，分明我return之前的数据还都是对的，但是return之后显示的东西就都有问题了 主要思路是这样的 因为in - place操作，所以就不能直接用remove去掉元素导致下标错乱 本来是想和上面的思路一样，换成inf，然后再把有inf的部分删除掉（参考了 # 27的简易解法） 怎么换成inf呢，我判断的方法是找到下一个值得index，然后计算这个index和上一个之间差多少个数，然后把富裕的数字都替换成inf 忽略的问题： 数数数错了很多问题 最开始没有考虑到什么停止 然后没有考虑到如果最后一个数字重复了两遍以上要怎么办的问题（这也是我用next_index的一个弊端） 然后看着大佬的代码哭出了声！！！12345678910class Solution: def removeDuplicates(self, nums: List[int]) -&gt; int: i = 0 for n in nums: if i &lt; 2 or n != nums[i - 2]: nums[i] = n i += 1 return i 总结： 哇这个思路真的牛逼！ 中心思想就是让n来增加但是i不增加，这里已经说了不在意前面项之后list里面的内容，也就是说前n项之后的东西都不用管了。既然如此的话与其用inf来替换这个位置的数字，不如直接用后面的项填在相对应的位置上，只有填成功了才会增加i 这里需要先判断i的值是否小于2，然后再计算nums[i - 2]，否则会out of range i跑的速度没有超过n跑的速度所以没有关系 合理利用题里面的条件限制真的很重要！！ 189 Rotate arrayGiven an array, rotate the array to the right by k steps, where k is non - negative. Example 1: Input: [1, 2, 3, 4, 5, 6, 7] and k = 3Output: [5, 6, 7, 1, 2, 3, 4]Explanation:rotate 1 steps to the right: [7, 1, 2, 3, 4, 5, 6]rotate 2 steps to the right: [6, 7, 1, 2, 3, 4, 5]rotate 3 steps to the right: [5, 6, 7, 1, 2, 3, 4] Example 2: Input: [-1, -100, 3, 99] and k = 2Output: [3, 99, -1, -100]Explanation:rotate 1 steps to the right: [99, -1, -100, 3]rotate 2 steps to the right: [3, 99, -1, -100] Note: Try to come up as many solutions as you can, there are at least 3 different ways to solve this problem.Could you do it in-place with O(1) extra space? 思路 需不需要注意k = 0的时候 如果k的个数特别大需不需要简化一下 123456789101112class Solution: def rotate(self, nums: List[int], k: int) -&gt; None: """ Do not return anything, modify nums in-place instead. """ steps = k % len(nums) unchange_nums = nums[:len(nums) - steps] change_nums = nums[len(nums) - steps:] nums[:steps] = change_nums nums[steps:] = unchange_nums 总结： 居然第一种就这么写出来了，实际上就是把后面的数字移动到前面去 注意nums不能直接用change_nums + unchange_nums，大概是他认为这个不是in - place了吧 另一种方法：in-place123456789101112 k = k % len(nums) self.reverse_nums(nums, 0, len(nums) - 1) self.reverse_nums(nums, 0, k - 1) self.reverse_nums(nums, k, len(nums) - 1)def reverse_nums(self,nums,start,end): while start &lt; end: temp = nums[start] nums[start] = nums[end] nums[end] = temp start += 1 end -= 1 实际上，rotate的另外一种方法是先把整个list反向，然后把前面的k个反向，然后再把后面的(n-k)个反向（这里我是没想到的） 把一个数组反向的算法就是从两头向中间逼近着交换（我该好好去看看基础的算法了。。） 最后，还有一种方法是跳着设置值，也就是说k个之后的值就应该是现在这个位置的值 41 First Missing PositiveGiven an unsorted integer array, find the smallest missing positive integer. Example 1: Input: [1,2,0]Output: 3Example 2: Input: [3,4,-1,1]Output: 2Example 3: Input: [7,8,9,11,12]Output: 1Note: Your algorithm should run in O(n) time and uses constant extra space. 第一个思路：时间nlog(n)12345678class Solution: def firstMissingPositive(self, nums: List[int]) -&gt; int: nums.sort() target = 1 for n in nums: if n == target: target += 1 return target 这个思路整体建立在先排序的基础上，但是排序的时间复杂度本身就已经是nlog(n)了 排序 - 找到比0大的数字从这里开始 - 这个数字不符合的话找下一个 但是我在找比0大的数字的时候还想着把list切片，切片就又需要考虑0啊，1啊，缺多少个数字的问题，空的list。其实根本不用这么麻烦 本质上这个方法就是，找到miss的正数，那就从正数的第一个（1）开始找，如果找到了这个数就继续找下一个（target++），总是能找到的嘛，找到的就是缺的数字了 自己的方法12345678910111213141516class Solution: def firstMissingPositive(self, nums: List[int]) -&gt; int: if nums is None or len(nums) == 0: return 1 for i in range(len(nums)): target_num = i + 1 if nums[i] == target_num: if i == len(nums) - 1: return target_num + 1 else: continue if target_num in nums: temp = nums.index(target_num) nums[temp],nums[i] = nums[i], nums[temp] else: return target_num 桶排序：要把对应的数字放在对应的位置上 这道题里应该的样子就是nums[index] = index + 1 大佬的思路 -&gt; 首先判断边界条件！！(学到了学到了) 看过了上面的提示写出来的第二版 判断边界条件 判断这个数字是不是摆在了正确的位置 正确，判断是否是最后一个数字 是，输出的是最后一个数字+1 不是，这个位置的正确了，判断下一个位置 没有，判断nums里面还有没有应该摆在这个位置的数字 有，那就和这个位置交换 没有，那没有的数字就是缺少的数字了 因为每次都是把数字换到了正确的位置了，所以交换最多进行len(nums)次，时间复杂度是O(n) 123456789def firstMissingPositive(self, nums): for i in xrange(len(nums)): while 0 &lt;= nums[i]-1 &lt; len(nums) and nums[nums[i]-1] != nums[i]: tmp = nums[i]-1 nums[i], nums[tmp] = nums[tmp], nums[i] for i in xrange(len(nums)): if nums[i] != i+1: return i+1 return len(nums)+1 大佬的另一个方法，其实思路和上面的差不多，就是把数字换到正确的位置上，但是判断的条件和我的有一点不同，可能因为我的是基于python的功能 其中，换到正确位置的数字就是在1到len(nums)之间的数字。nums[i]-1是这个数字应该的坐标位置，如果应该的位置和现在的位置的数字不一样，那就交换这两个数字 注意这里需要用while换，要一直换到正确的位置才可以 这样的结果就是大家都按正确的填好了，最后不对的那个位置的index+1就是需要的结果 299You are playing the following Bulls and Cows game with your friend: You write down a number and ask your friend to guess what the number is. Each time your friend makes a guess, you provide a hint that indicates how many digits in said guess match your secret number exactly in both digit and position (called “bulls”) and how many digits match the secret number but locate in the wrong position (called “cows”). Your friend will use successive guesses and hints to eventually derive the secret number. Write a function to return a hint according to the secret number and friend’s guess, use A to indicate the bulls and B to indicate the cows. Please note that both secret number and friend’s guess may contain duplicate digits. Example 1: Input: secret = “1807”, guess = “7810” Output: “1A3B” Explanation: 1 bull and 3 cows. The bull is 8, the cows are 0, 1 and 7.Example 2: Input: secret = “1123”, guess = “0111” Output: “1A1B” Explanation: The 1st 1 in friend’s guess is a bull, the 2nd or 3rd 1 is a cow.Note: You may assume that the secret number and your friend’s guess only contain digits, and their lengths are always equal. 1234567class Solution: def getHint(self, secret: str, guess: str) -&gt; str: bull = sum(a == b for a,b in zip(secret,guess)) cow = 0 for x in set(guess): cow += min(secret.count(x),guess.count(x)) return str(bull) + "A" + str(cow-bull) + "B" 这里自己想了一些比较蠢的想法之后直接参考别人的了 其一是比对他们两个位置和数字都相同的东西，想要转换成dict来比较，但是后来发现string就可以直接index了不用这么麻烦 想过能不能按位做减法，未果 其二是在得到了bull之后把bull的部分从原来的里面剔除出去然后再比较相似的数字 遇到了主要问题是重复的数字怎么办以及如何剔除出去bull 主要思路是这样的： 其实cow的数量就是bull-cow都是的数量减去bull的数量，也就相当于维恩图里面，只有A的量是A的量 - 同时AB的量。这里是bull就相当于AB都有，两个里面所有重复的数量就相当于A的量 这样可以做减法就解决了上面的从bull得到cow的问题！！ 所以说看问题还是要看本质 面对重复的数字，居然可以直接把string转换成set 这里复习一下set好吗！！！这个集合居然可以没有重复的元素，平常我忽视你了呀小可爱，转化成set就不会重复了哦，震惊！！ 这样问题就变成了： 求bull：用zip把两个东西一一对应的打包起来（居然还有你小可爱！）直接对比 求both：guess里面猜的次数就是总体的次数，secret里面的次数是真实的次数，对于每个在guess里面（set）的元素都看看分别在两个里面是多少个，然后小的那个就是both的大小 这里介绍.count()小可爱，居然还可以数数！ 最后both-bull就是结果了 134 gas station居然自己搞出来了一个看起来很蠢的1234567891011121314151617181920212223242526class Solution: def canCompleteCircuit(self, gas: List[int], cost: List[int]) -&gt; int: if sum(gas) &lt; sum(cost): return -1 tank = 0 current = 0 counter = 0 while(True): tank = tank + gas[current] - cost[current] if tank &lt; 0: if current &lt; len(gas): current = current + 1 counter = 0 tank = 0 continue else: return -1 current += 1 current = current % len(gas) counter += 1 # print(current,counter) if counter == len(gas): return current % len(gas) ~时间超过了百分之48的人，感觉可能还可以吧~时间都是骗人的又跑了一次居然超过了百分之86的！！ 重点 一直按着顺序跑，不会跳着走 如果gas的总量从一开始就小于cost的总量，那绝对不可能 我的思路： 从第一个点开始试着跑，一直到试着从最后一个点开始跑，找到了就直接返回 增加一个计数的var，记一共跑了多远，因为是按着顺序跑的所以这个var等于gas的长度的时候就是跑完了 避免out of range问题，需要求余数 遇到问题： 当tank小于0，更新完条件之后记得continue继续循环呀 刚开始想用的判断条件是for或者while里面带条件，还想了一下要不要zip这两个数据，但是都是list实在是没有必要。但是感觉是想的实在是太多了 1234567891011class Solution: def canCompleteCircuit(self, gas: List[int], cost: List[int]) -&gt; int: if sum(gas) &lt; sum(cost): return -1 rest = start = 0 for i in range(len(gas)): rest += gas[i] - cost[i] if rest &lt; 0: start = i + 1 rest = 0 return start 居然有这么简要的写法！！ 所以只要不是sum(gas) &lt; sum(cost)就一定会有解诶，神奇。也就是说我上面有一个返回的-1是没有意义的 而且用for的话就不用再考虑counter的问题了 从哪里失败就从哪里的下一个爬起来 118 Pascal’s TriangleExample: Input: 5Output:[ [1], [1,1], [1,2,1], [1,3,3,1], [1,4,6,4,1]] 1234567891011121314151617181920212223class Solution: def generate(self, numRows: int) -&gt; List[List[int]]: result = [] if numRows == 0: return [] for row in range(numRows): now_row = [] if row == 0: now_row = [1] elif row == 1: now_row = [1,1] else: now_row = [1] for member in range(1,row): now_row.append(result[row-1][member-1] + result[row-1][member]) now_row.append(1) result.append(now_row) return result 总算是自己写出来一个东西了 好简单，除了前两行是特定的，其他的可以归为一类 求一个简单的数学关系就行了，数数别数错了！！注意数0 唯一没有注意的点就是：事先不知道list的大小，所以初始化成空的之后需要用append添加元素 119 杨辉三角形2Given a non-negative index k where k ≤ 33, return the kth index row of the Pascal’s triangle. Note that the row index starts from 0. Input: 3Output: [1,3,3,1] 1234567class Solution: def getRow(self, rowIndex: int) -&gt; List[int]: L = [1] while True: if len(L) == rowIndex + 1: return L L = [u+v for u,v in zip([0]+L,L+[0])] 没想到杨辉三角形的代码也有简要的解法，这个是用L记录了上一行的信息，然后再把这行扩充两个0，相当于这个三角形的本质是两行错位相加！！ 注意最后的L得到的是一个list，list要有list的样子 更加理解了一下zip和单行for的用法 index从0开始，结果开始没有注意到 while true 加上一个 if的效果等同于for的效果！！！越写越糊涂 169 Majority ElementGiven an array of size n, find the majority element. The majority element is the element that appears more than ⌊ n/2 ⌋ times. You may assume that the array is non-empty and the majority element always exist in the array. Example 1: Input: [3,2,3]Output: 3Example 2: Input: [2,2,1,1,1,2,2]Output: 2 1234class Solution: def majorityElement(self, nums: List[int]) -&gt; int: nums.sort() return nums[len(nums)//2] 思路：这回想到了很多历遍的方法，但是感觉太蠢了，终于开始想怎么才能更好的实现了 在写写画画的时候突然考虑到，如果有超过一半的数量都是这个数的话，把这个list排序之后最中间的那个数肯定是这个数 极限情况就是两个元素差1，这时候是多一点的那个数的边界上 其他的情况下就是在出现最多的那个数的中间 本来想要用floor的，但是发现需要math包，所以用了 // 来求除之后的整数 229 Majority Element 2Given an integer array of size n, find all elements that appear more than ⌊ n/3 ⌋ times. Note: The algorithm should run in linear time and in O(1) space. Example 1: Input: [3,2,3]Output: [3]Example 2: Input: [1,1,1,3,3,2,2,2]Output: [1,2]12345678910111213141516171819202122class Solution: def majorityElement(self, nums: List[int]) -&gt; List[int]: if not nums: return [] major1,major2,count1,count2 = 0,1,0,0 for n in nums: if major1 == n: count1 += 1 elif major2 ==n: count2 += 1 elif count1 ==0: major1 = n count1 = 1 elif count2 == 0: major2 = n count2 =1 else: count1 -= 1 count2 -= 1 return [n for n in (major1,major2) if nums.count(n) &gt; len(nums) // 3] 注意这道题说的是出现次数大于1/3的数字，所以结果只有只能是没有，1个或者两个，不存在结果是三个的情况！ 这个想了半天不会做，查了一下用的是Boyer-Moore Majority Vote algorithm 这个算法的主要意思是如果两拨人打架，打架一对一抵消，然后看看剩下的部分哪个比较多 记录剩下的东西的方法就是增加了一个额外的部分，包括major和count两部分，major记录的是有剩余的数是什么，count记录还有多少个 如果count没有了，那么就从现在遇到的新的数开始记 如果现在的数不是需要的，那么count - 1，如果是现在需要的那么count + 1 最开始是用在一个数组里面找超过一半的数的，但是我上一道题用了其他方法所以没用到 注意因为是求1/3的数字，所以虽然有剩下的，但是剩下的不一定都是符合要求的，需要再数一下个数对不对（这才有了return这一行里面的东西） 人类的算法真是奇幻无穷 274 h-indexGiven an array of citations (each citation is a non-negative integer) of a researcher, write a function to compute the researcher’s h-index. According to the definition of h-index on Wikipedia: “A scientist has index h if h of his/her N papers have at least h citations each, and the other N − h papers have no more than h citations each.” Example: Input: citations = [3,0,6,1,5]Output: 3Explanation: [3,0,6,1,5] means the researcher has 5 papers in total and each of them had received 3, 0, 6, 1, 5 citations respectively. Since the researcher has 3 papers with at least 3 citations each and the remaining two with no more than 3 citations each, her h-index is 3.Note: If there are several possible values for h, the maximum one is taken as the h-index. 1234567891011class Solution: def hIndex(self, citations: List[int]) -&gt; int: result = 0 for h_cand in range(len(citations) + 1): h_more = 0 for citation in citations: if citation &gt;= h_cand: h_more += 1 if h_more &gt;= h_cand: result = max(result,h_cand) return result 思路，非常直观的方法，直接iterate所有的元素，如果找到了更大的result的值就取最大的（根据题目要求） 注意的点在需要 h_more &gt;= h_cand而不是等于，因为给出的定义的意思是index-h是有h个的值大于等于h，h_more的个数会比h_cand多（但是因为取了下面的max，所以等于其实也是可以得） 这个的速度真的好慢，尝试一下binary search 1234567891011121314151617class Solution: def hIndex(self, citations: List[int]) -&gt; int: bucket = [0 for n in range(len(citations)+1)] for nums in citations: if nums &gt;= len(citations): bucket[len(citations)] += 1 else: bucket[nums] += 1 result = 0 for nums in range(len(bucket)): nums = len(bucket) - nums -1 result += bucket[nums] if result &gt;= nums: return nums return 0 用了桶排序的神奇方法 还是取决于定义，如果一共有5个paper的话，可以选的h的值有6个，分别是0 1 2 3 4 5，把这留个值分成六个桶，每个里面放的就是比这桶的inde等于的paper的数量 如果总数直接大于最大的桶数，就放在最后一个里面 这是在第一个循环干的事情 第二个循环里，把这些桶里面的值取出来就是比这个桶的index大于等于的paper的数量，从后往前数，如果这个paper的数量大于了现在的index，那就说明现在的index就是h！ 这里学到了一个创建固定长度列表的方法bucket = [0 for n in range(len(citations)+1)] 12345678class Solution: def hIndex(self, citations: List[int]) -&gt; int: citations.sort(reverse = True) result = 0 for i,n in enumerate(citations): if n &gt;= i+1: result = max(result,i+1) return result 再另一种思路，用了排序 如果把这个list按降序排序的话，index的数量加一就是目前数过的paper的数量，citation[index]就是这个数量上面对应的citation的数量，这两个值应该正好相等，或者citation更大一点，需要在排好序的内容里面找到这一项！ 这样速度比桶排序稍微慢一点但是还是蛮快的，起码比第一种要快很多了 275 h-index 21234567891011class Solution: def hIndex(self, citations: List[int]) -&gt; int: n = len(citations) l, r = 0, n-1 while l &lt;= r: mid = (l+r)//2 if citations[mid] &gt;= n-mid: r = mid - 1 else: l = mid + 1 return n-l 可以依然沿用上面的方法，但是可能是因为数据量上去的原因，所以速度变慢了 这里可以加入二分法搜索取代上面的直接iterate while的条件是因为移动一位，所以会出现l&gt;r的情况，在这种情况下就可以停下来了 二分法就是这么写的！ 217 contains duplicate123456class Solution: def containsDuplicate(self, nums: List[int]) -&gt; bool: for n in nums: if nums.count(n) &gt;= 2: return True return False 1234567class Solution: def containsDuplicate(self, nums: List[int]) -&gt; bool: setNums = set(nums) if len(setNums) == len(nums): return False else: return True 消耗时间太长了！！ 说明这个count的时间还是不可以 想到了用set但是没相当怎么用set set可以把有重复内容的变成没有重复内容的！！ 所以set和list的长度是不一样的 219 contains duplicate2Given an array of integers and an integer k, find out whether there are two distinct indices i and j in the array such that nums[i] = nums[j] and the absolute difference between i and j is at most k. Example 1: Input: nums = [1,2,3,1], k = 3Output: trueExample 2: Input: nums = [1,0,1,1], k = 1Output: trueExample 3: Input: nums = [1,2,3,1,2,3], k = 2Output: false 1234567891011class Solution: def containsNearbyDuplicate(self, nums: List[int], k: int) -&gt; bool: if len(set(nums)) &gt;= len(nums): return False extra = &#123;&#125; for i,n in enumerate(nums): if n in extra and i-extra[n] &lt;= k: return True extra[n] = i return False 注意这里需要找到的差的绝对值是最大是k，所以找到一个比k小的很容易！！只要找到就能返回 判断边界条件 把元素作为key放进extra里面，val是这个元素的index，因为key是唯一的所以可以一直找到离得最近的index，这样就越来越能确保满足条件，一旦满足条件就返回，如果所有的都不满足就false 220Given an array of integers, find out whether there are two distinct indices i and j in the array such that the absolute difference between nums[i] and nums[j] is at most t and the absolute difference between i and j is at most k. Example 1: Input: nums = [1,2,3,1], k = 3, t = 0Output: trueExample 2: Input: nums = [1,0,1,1], k = 1, t = 2Output: trueExample 3: Input: nums = [1,5,9,1,5,9], k = 2, t = 3Output: false 1234567891011121314151617class Solution: def containsNearbyAlmostDuplicate(self, nums: List[int], k: int, t: int) -&gt; bool: if t &lt; 0: return False buckets = &#123;&#125; for i in range(len(nums)): bucket = nums[i] // (t+1) if bucket in buckets: return True elif bucket - 1 in buckets and nums[i] - buckets[bucket-1] &lt;= t: return True elif bucket + 1 in buckets and buckets[bucket+1] - nums[i] &lt;=t: return True buckets[bucket] = nums[i] if i &gt;= k: del bucket[nums[i-k] // (t+1)] return False 运用的是桶排序的思路，每个nums[i]会放在一个桶里，这个桶的宽度是这两个数字的差 如果想要这两个数值的差值小于等于t，那么需要这两个数字在一个桶里或者在相邻的桶里（因为后面增加了k的判断条件，所以不用考虑k） 思路 首先考虑了一下k，如果i大于k的时候，就可以直接扔掉i-k之前的数据了，只考虑中间的k+1个数据，这样的话空间复杂度很低。这里的扔掉指的是把bucket里面的值直接扔掉，这样就避免了找到在相同的桶里面却i和j的差值超过k的问题 首先iterate整个nums，把不同的数字放在不同的桶里，注意桶的个数是t+1 然后如果在放之前这个桶有东西，或者相邻的桶的值和现在的值的差是小于等于t的，那么就存在，返回true 如果都不存在的话，把现在的数字放到对应的桶里面 另外一个思路考虑的是二叉树的数据结构，用这个结构可以很快的搜索到离这个数最近的数据并且判断这个数据和这个数的差是不是小于t！ 55 Jump game123456789101112131415class Solution: def canJump(self, nums: List[int]) -&gt; bool: if nums is []: return False if len(nums) == 1: return True current = len(nums) - 1 while current &gt;= 0: flag = False for i in range(0,current): if current - i &lt;= nums[i] and current &gt;= i: flag = True current = i if current == 0: return True if flag == False: return False 虽然超时了但是写的还不错的iterate =。=算了这就是一坨屎！！！ 123456789class Solution: def canJump(self, nums: List[int]) -&gt; bool: current = len(nums) - 1 for i in range(len(nums))[::-1]: if current - i &lt;= nums[i]: current = i if current == 0: return True return False 我的方法其实思路是没有问题的，主要在于太啰嗦了而且循环太多了，其实直接从后往前找就行了！！！从后往前找不用考虑怎么让他循环起来呀，直接一个一个往前推就可以了 前面那个的问题在于多叠了一个while，于是时间瞬间爆炸，写前面的那个的时候也在想着如何找回循环里面去，结果还是用了个蠢办法 1234567class Solution: def canJump(self, nums: List[int]) -&gt; bool: j = 0 for i,n in enumerate(nums): if j &lt; i: return False j = max(i+n,j) return True i+n就是从这步开始可以移动的最大距离，j是上一步可以移动的最大距离，这两个哪个大就走哪个 如果这个距离还赶不上i，那就说明走不到最后了，告辞 45 Jump game 2123456789101112class Solution: def jump(self, nums: List[int]) -&gt; int: if len(nums) &lt;= 1: return 0 start, end = 0, 0 step,maxend = 0,0 while True: step += 1 for i in range(start, end+1): if i+nums[i] &gt;= len(nums) -1: return step maxend = max(maxend, i + nums[i]) start = end + 1 end = maxend 实际上来说用的是BFS的思想，但是不是每次都把东西从queue里面拿出来，而是确定了每次寻找的开始的阀内 start和end分别代表现在可以开始寻找的开始和结束，如果在这个范围里面找到了符合要求的结果，那么直接返回这个步数，如果没找到的话就从下一个范围开始找，下一个范围是上一个范围的end+1 到目前能到的最大的范围 注意符合的要求是大于等于n-1而不是正好走到这个点 求maxend和之前的一样 121 Best Time to Buy and Sell StockSay you have an array for which the ith element is the price of a given stock on day i. If you were only permitted to complete at most one transaction (i.e., buy one and sell one share of the stock), design an algorithm to find the maximum profit. Note that you cannot sell a stock before you buy one. Example 1: Input: [7,1,5,3,6,4]Output: 5Explanation: Buy on day 2 (price = 1) and sell on day 5 (price = 6), profit = 6-1 = 5. Not 7-1 = 6, as selling price needs to be larger than buying price.Example 2: Input: [7,6,4,3,1]Output: 0Explanation: In this case, no transaction is done, i.e. max profit = 0. 12345678910class Solution: def maxProfit(self, prices: List[int]) -&gt; int: minBuy = float('inf') maxProfit = 0 for i in prices: if i &lt; minBuy: minBuy = i elif i - minBuy &gt; maxProfit: maxProfit = i - minBuy return maxProfit 用brute的算法会time limit，这里用的方法是用两个变量分别记录最低的价钱和最高的利润，这样的话只需要对数组遍历一次就能得到最终的结果 因为判断这个价钱低了的话，求这个东西的最大利润也就只能用这个最低价钱之后的东西求了，所以不会冲突 122 现在可以进行多次交易了，但是每次之间不能重叠 其实只要后一次比前一次贵，这个profit就可以一直累计，分为一直上涨或者中间掉下来一下再重新买的感觉 1234567class Solution: def maxProfit(self, prices: List[int]) -&gt; int: maxProfit = 0 for i in range(1,len(prices)): if prices[i] &gt; prices[i-1]: maxProfit += prices[i] - prices[i-1] return maxProfit 123 现在最多进行两次交易,找到最大的利润 1234567891011121314class Solution: def maxProfit(self, prices: List[int]) -&gt; int: cost_1 = float('inf') profit_1 = 0 cost_2 = float('inf') profit_2 = 0 for price in prices: cost_1 = min(cost_1,price) profit_1 = max(profit_1, price - cost_1) cost_2 = min(cost_2,price - profit_1) profit_2 = max(profit_2, price - cost_2) return profit_2 其中，下标带1的是第一次交易之后的结果，下标带2的是第二次交易之后的结果 从总体上来看，第二次买入之后花掉的钱实际上是第二次买入的实际花费 - 第一次交易之后挣的钱（可以是负数）。而第二次卖出之后的总的收益为 第二次卖出的钱 - 第二次买入之后的实际花费 所以，如果需要利润最大，需要第二次买入的实际花费最小，需要第一次的利润最大，需要第一次买入的花费最小，最终形成了这个代码 188 现在需要进行最多k次交易，把profit弄到最大 这部分好像大家都用到了DP 1234567891011121314class Solution: def maxProfit(self, k: int, prices: List[int]) -&gt; int: n = len(prices) if n &lt; 2: return 0 if k &gt;= n/2: return sum(i-j for i, j in zip(prices[1:],prices[: -1]) if i &gt; j) profits = [0] * n for _ in range(k): preprofit = 0 for i in range(1,n): profit = prices[i] - prices[i-1] preprofit = max(preprofit + profit, profits[i]) profits[i] = max(preprofit, profits[i-1]) return profits[-1] 首先考虑边界条件，如果k的数量已经比n/2大了，那么可以直接认为可以进行无限次交易了，就和上面的第二题一样 主要思路就是现在定义了两个变量，一个变量表示在前i天完成的交易，已经得到的最大利润。另一个变量定义了在第i天卖出的话，这时候得到的最大利润。这两个变量的都是在在第j次交易里。 用一个长n的list profits来记录这个天数之后获得的利益。在k次交易中一直更新这个profits里面的最大值。所以实际上关于k的变量不需要考虑 首先分析在第i天得到的利润，就是这一天的价格减去前一天的价格。更新之前i天里面的总利润，就是把最开始的preprfit再加上这一天获得的利润，和本来的preprofit来比大小，更新preprofit 更新实际上第i天的利润，对比实际上前一天的利润和前i天的利润哪个大 309 中间带冷却的买股票 每次卖出去之后必须要cooldown一轮 用了dp和state machine来表示，一共会有三种状态 s0(reset) -sell-&gt; s1 -cool-&gt; s2(reset) -buy-&gt; s0 用一个数组来记录在每天在这个状态里面的最大利润，然后再从最后一天的最大利润里面挑出来一个 注意考虑边界条件 学会了一个新的初始化list的方法 感觉自己终于理解了dp呢（并没有）12345678910111213141516class Solution: def maxProfit(self, prices: List[int]) -&gt; int: n = len(prices) if n &lt; 2: return 0 s0,s1,s2 = [0]*n,[0]*n,[0]*n s0[0] = -prices[0] s1[0] = float('-inf') s2[0] = 0 for i in range(1,n): price = prices[i] s0[i] = max(s0[i-1],s2[i-1] - price) s1[i] = s0[i-1] + price s2[i] = max(s1[i-1],s2[i-1]) return max(s0[n-1],s1[n-1],s2[n-1]) 11 装水Given n non-negative integers a1, a2, …, an , where each represents a point at coordinate (i, ai). n vertical lines are drawn such that the two endpoints of line i is at (i, ai) and (i, 0). Find two lines, which together with x-axis forms a container, such that the container contains the most water. Note: You may not slant the container and n is at least 2. 12345678910111213class Solution: def maxArea(self, height: List[int]) -&gt; int: n = len(height) start, end = 0, n-1 maxArea = 0 while start &lt; end: if height[start] &gt;= height[end]: maxArea = max(maxArea,height[end] * (end-start)) end -= 1 else: maxArea = max(maxArea,height[start] * (end-start)) start += 1 return maxArea 这道题的重点在这个装水的大小是由比较短的那条边决定的。而且肯定是底边越长越牛逼，所以从底边最长的两边开始找，然后在两个高度里面取比较大的继续找下一个 需要用一个变量来储存 max area的大小（这个我想到了） 然后比较快的方法是从两遍开始逼近，这样的话只遍历了这个list一次，时间复杂度是n，好像有个排序算法和这个的想法也差不多 注意while的判断条件其实就是这个 42 装水Given n non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it is able to trap after raining. 12345678910111213141516class Solution: def trap(self, height: List[int]) -&gt; int: n = len(height) if n &lt; 2: return 0 left_max,right_max = [0]*n,[0]*n left_max[0],right_max[-1] = height[0],height[-1] maxTrap = 0 for i in range(1,n): left_max[i] = max(left_max[i-1],height[i]) for i in reversed(range(0,n-1)): right_max[i] = max(right_max[i+1],height[i]) for i in range(n): maxTrap += min(left_max[i],right_max[i]) - height[i] return maxTrap 用dp解决的这个问题 核心思想在竖着（按列）数每个格子，这个格子可不可以装水和左右两边的最高点有关，这个格子能装多少水和1.最短的高点和2.这个格子本身的高度有关 所以可以用三个循环搞定这个问题，用空间换时间，在list里面记录下来每个列对应的左边的最高点和右边的最高点，然后再数每个列的容量，大小是（左右最高中间短的那个） - （这个列对应的高度） 334 升序的三个数字Given an unsorted array return whether an increasing subsequence of length 3 exists or not in the array. Formally the function should: Return true if there exists i, j, ksuch that arr[i] &lt; arr[j] &lt; arr[k] given 0 ≤ i &lt; j &lt; k ≤ n-1 else return false.Note: Your algorithm should run in O(n) time complexity and O(1) space complexity. 123456789101112131415class Solution: def increasingTriplet(self, nums: List[int]) -&gt; bool: if len(nums) &lt; 3: return False first = float('inf') second = float('inf') third = None for i,num in enumerate(nums): if num &lt;= first: first = num elif num &gt; first and num &lt;= second: second = num else: third = num return (third != None) 我最初的思路没有错，需要有变量来保存这三个升序的东西 其实核心的思路在于，如果现在这个数比第一个升序的数字小，那么这个数字完全就可以成为新的第一个数字，比如 3 2 4 5，那么345和245没有什么本质的区别，而一旦third有了取值，那么就说明肯定已经有了一个结果 128Given an unsorted array of integers, find the length of the longest consecutive elements sequence. Your algorithm should run in O(n) complexity. Example: Input: [100, 4, 200, 1, 3, 2]Output: 4Explanation: The longest consecutive elements sequence is [1, 2, 3, 4]. Therefore its length is 4. 123456789101112131415161718192021222324252627282930313233343536class Solution: def longestConsecutive(self, nums: List[int]) -&gt; int:# if nums == []: return 0# max_num = max(nums)# min_num = min(nums)# if max_num &gt; len(nums) or -max# if min_num &lt; 0:# max_num -= min_num# ass_list = [None] * (max_num + 1)# for i,num in enumerate(nums):# # 确保都是正数# if min_num &lt; 0:# num = num-min_num# ass_list[num] = 1 # max_length = 0# prev_length = 0# for i in range(len(ass_list)):# if ass_list[i] != None:# max_length += 1# else:# prev_length = max(max_length,prev_length)# max_length = 0# return max(max_length,prev_length) if nums == []: return 0 current_length,prev_length = 1,1 num_set = set(nums) for num in num_set: if num - 1 not in num_set: current_num = num while current_num+1 in num_set: current_num += 1 current_length += 1 prev_length = max(prev_length,current_length) current_length = 1 return max(current_length, prev_length) 这个问题一开始的思路是错的，已经comment掉了，但是感觉这个想法其实就是更具体化的hash表而已，第一个思路是把所有的数字平均的放在一个list里面，然后每个数字的本身就对应的是他的index，这样的话就可以直接知道有哪些数字是连续的了。但是这种方法在数字特别大的时候空间上就爆炸了，空间复杂度也是和数字大小有关 这时候又要拿出来快乐的hash表了，记住python自己自带hash表 每遇到一个数字，需要判断这个数字的下一个数字在不在这个nums里面，如果在的话更新数字和长度，如果不再的话刷新计数器并且开始下一个数字 但是直接这样算还是会时间爆炸（比如一堆连续的只有一个是跳开的），所以又加进去了一个新的判断条件，这个条件的精髓在于，如果这个数之前的数字在nums里面，那么这个数在算他前面那个数的时候就应该被算上了，所以这部分就可以跳过这个数了，只有当前一个数字不在的时候才需要数长度 164Given an unsorted array, find the maximum difference between the successive elements in its sorted form. Return 0 if the array contains less than 2 elements. Example 1: Input: [3,6,9,1]Output: 3Explanation: The sorted form of the array is [1,3,6,9], either (3,6) or (6,9) has the maximum difference 3.Example 2: Input: [10]Output: 0Explanation: The array contains less than 2 elements, therefore return 0.Note: You may assume all elements in the array are non-negative integers and fit in the 32-bit signed integer range.Try to solve it in linear time/space. 123456789101112class Solution: def maximumGap(self, nums: List[int]) -&gt; int: nums.sort() max_gap = 0 if len(nums) &lt; 2: return 0 for i in range(1,len(nums)): gap = nums[i] - nums[i-1] max_gap = max(max_gap, gap) return max_gap 直接用python自带的排序速度不一定很慢，虽然只超过了百分了20的人但是最后还是跑出来了 这个方法非常直接了 12345678910111213141516171819202122232425262728class Solution: def maximumGap(self, nums: List[int]) -&gt; int: n = len(nums) if n &lt; 2: return 0 max_num, min_num = max(nums), min(nums) if max_num == min_num: return 0 wide = max((max_num - min_num) // (n-1),1) num_b = (max_num - min_num) // wide + 1 maxGap = 0 # prev_bucket = float('-inf') max_b = [0]* num_b min_b = [float('inf')]* num_b for i, num in enumerate(nums): idx = (num-min_num) // wide max_b[idx] = max(max_b[idx],num) min_b[idx] = min(min_b[idx],num) prev_max = max_b[0] for i in range(1,num_b): if max_b[i] == 0: continue maxGap = max(maxGap,min_b[i] - prev_max) prev_max = max_b[i] return maxGap 这个桶排序终于写出来了，基本思路是上面的截图，需要注意的有几点 第一，python不导入math的话没办法求ceiling，但是可以用 -（-a // b）来求 第二，在求bucket的个数的时候，需要多加上一个bucket，因为一个bucket里面最后的数字是放在下一个bucket里面最前面的 第三，可能会有空的bucket，所以不能直接用这个的min减去上一个的max，必须要留一个变量保存上一个的max 第四，当所有数字都相同的时候会变得很麻烦，最后加上去一个条件过滤掉这个部分 28 implement strStr（）Implement strStr(). Return the index of the first occurrence of needle in haystack, or -1 if needle is not part of haystack. Example 1: Input: haystack = “hello”, needle = “ll”Output: 2Example 2: Input: haystack = “aaaaa”, needle = “bba”Output: -1 123456789class Solution: def strStr(self, haystack: str, needle: str) -&gt; int: if needle == "": return 0 for i, ch in enumerate(haystack): if ch == needle[0]: if needle == haystack[i:i+len(needle)]: return i return -1 刚开始特别快乐的暴力破解了，真是万万没想到 感觉python处理起来字符串是真的开心 但是这个的时间不是很快乐 关于字符串匹配有另外两个算法KMP和BM（BM更快一点） 14Write a function to find the longest common prefix string amongst an array of strings. If there is no common prefix, return an empty string “”. Example 1: Input: [“flower”,”flow”,”flight”]Output: “fl”Example 2: Input: [“dog”,”racecar”,”car”]Output: “”Explanation: There is no common prefix among the input strings.123456789101112131415161718192021class Solution: def longestCommonPrefix(self, strs: List[str]) -&gt; str: if len(strs) == 0: return "" if len(strs) == 1: return strs[0] LCP = self.compare(strs[0],strs[1]) for i in range(2,len(strs)): LCP = self.compare(LCP,strs[i]) return LCP def compare(self,a,b): i = j = 0 counter = 0 while i &lt; len(a) and j &lt; len(b): if a[i] == b[i]: counter += 1 else: break i += 1 j += 1 if counter == 0: return "" else: return a[:counter] 思路：平行比较，先找出来前两个里面的prefix，然后再用这个prefix和第三个东西比较 注意输入的长度是1的时候，需要输出整个字符串 注意如果比较失败了的话，要直接停止比较！ 58Given a string s consists of upper/lower-case alphabets and empty space characters ‘ ‘, return the length of last word in the string. If the last word does not exist, return 0. Note: A word is defined as a character sequence consists of non-space characters only. Example: Input: “Hello World”Output: 512345678910111213141516class Solution: def lengthOfLastWord(self, s: str) -&gt; int: if len(s) == 0: return 0 while s[-1] == " ": s = s[:-1] if len(s) == 0: return 0 new_str = s.split(" ") # return new_str print(new_str) return len(new_str[-1]) # cnt = 0 # for v in reversed(s): # if v.isspace(): # if cnt: break # else: cnt += 1 # return cnt 原来运行时间也很玄学 但是还是别人的代码看起来厉害一点！ 387Given a string, find the first non-repeating character in it and return it’s index. If it doesn’t exist, return -1. Examples: s = “leetcode”return 0. s = “loveleetcode”,return 2.1234567891011class Solution: def firstUniqChar(self, s: str) -&gt; int: count = collections.Counter(s) index = 0 for ch in s: if count[ch] == 1: return index else: index += 1 return -1 居然有这么个东西叫做counter，感到震惊！！！ 383Given an arbitrary ransom note string and another string containing letters from all the magazines, write a function that will return true if the ransom note can be constructed from the magazines ; otherwise, it will return false. Each letter in the magazine string can only be used once in your ransom note. Note:You may assume that both strings contain only lowercase letters. canConstruct(“a”, “b”) -&gt; falsecanConstruct(“aa”, “ab”) -&gt; falsecanConstruct(“aa”, “aab”) -&gt; true 这个题目也太写意了吧，意思就是我需要写一个勒索信，然后要从杂志上面找单词，看看能不能用杂志上面的东西拼凑出来这个单词 1234567891011class Solution: def canConstruct(self, ransomNote: str, magazine: str) -&gt; bool: alphabet = [0]*26 for ch in magazine: index = ord(ch) - ord('a') alphabet[index] += 1 for ch in ransomNote: index = ord(ch) - ord('a') alphabet[index] -= 1 if alphabet[index] &lt; 0: return False return True 看到了一个清奇的思路然后自己实现了一下 统计magazine里面每个字母的数量，和需要的字母数量对比，如果不够的话就不行 我在写的时候多iteration了一次26个字母，但是其实在ransomNote里面直接对比和0的大小就可以了 感觉字母和数字最大的区别就在于字母有限而数字无限 344reverse一个list，要求in-place而且占用o1的空间12345678910class Solution: def reverseString(self, s: List[str]) -&gt; None: """ Do not return anything, modify s in-place instead. """ length = len(s) for i in range(length // 2): temp = s[i] s[i] = s[length - 1 - i] s[length - 1 - i] = temp 其实可以不用temp的，直接用 s[i]，s[length - 1 - i] = s[length - 1 - i], s[i]就可以了 151reverse一个string，让这句话倒过来，主要会有多个空格123class Solution: def reverseWords(self, s: str) -&gt; str: return " ".join(s.split()[::-1]) python真的是很作弊了 split不加参数就可以直接分开所有大小的空格 70 爬楼梯 DPYou are climbing a stair case. It takes n steps to reach to the top. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top? Note: Given n will be a positive integer. 123456789101112class Solution: def climbStairs(self, n: int) -&gt; int: if n == 1: return 1 elif n ==0: return 0 elif n == 2: return 2 f = (n+1)*[0]#走n节的时候可以有的方法数量 f[1] = 1 f[2] = 2 for i in range(3,n+1): f[i] = f[i-1] + f[i-2] return f[n] 其实就相当于斐波那契数列，第i种的可能的方法是从i-2走一个2，以及从i-1走一个1的和 345把一个string里面的原因反序 1234567891011121314class Solution: def reverseVowels(self, s: str) -&gt; str: vowels = "AEIOUaeiou" index = [] for i, j in enumerate(s): if j in vowels: index.append(i) s = list(s) i,j = 0,len(index)-1 while i&lt;j: s[index[i]],s[index[j]] = s[index[j]],s[index[i]] i += 1 j -= 1 return "".join(s) 首先判断哪个是原因 然后把元音的部分倒过来 .join把list转回string 205 Isomorphic StringsEasy 767 217 Favorite ShareGiven two strings s and t, determine if they are isomorphic. Two strings are isomorphic if the characters in s can be replaced to get t. All occurrences of a character must be replaced with another character while preserving the order of characters. No two characters may map to the same character but a character may map to itself. Example 1: Input: s = “egg”, t = “add”Output: true1234567891011class Solution: def isIsomorphic(self, s: str, t: str) -&gt; bool: n = len(s) sub_1,sub_2 = [0]*256,[0]*256 for i in range(n): a,b = s[i],t[i] if sub_1[ord(a)] != sub_2[ord(b)]: return False sub_1[ord(a)] = i + 1 sub_2[ord(b)] = i + 1 return True 注意这里面的mapping不一定是字母，也可以是数字 ascii码一共是256个，所以是不会超出这个范围的 主要思路就是这样的，两个数组分别记录的是对应位置的ascii码的mapping的位数，如果这两个位数不一样的话，就说明这两个的mapping方式有问题，所以return False，不然的话return True 290 word patternGiven a pattern and a string str, find if str follows the same pattern. Here follow means a full match, such that there is a bijection between a letter in pattern and a non-empty word in str. Example 1: Input: pattern = “abba”, str = “dog cat cat dog”Output: true12345class Solution: def wordPattern(self, pattern: str, str: str) -&gt; bool: pattern = list(pattern) string = str.split(" ") return len(set(zip(pattern,string))) == len(set(string)) == len(set(pattern)) and len(pattern) == len(string) 又到了活用zip的时候，返回的是一个个对应的东西，也就是说返回的是 a-dog,b-cat,b-cat,a-dog 这时候把他们转化成set，得到的就是不带重复的东西的长度 如果匹配上的长度和原先的长度全都相同（去掉重复的元素），那么就证明匹配上了 49 变位词12345678910111213141516171819class Solution: def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]: # for i,item in enumerate(strs): # item = list(item) # item.sort() # item = "".join(item) # temp[i],temp_sort = item,item # temp_sort.sort() # print(temp,strs) d = &#123;&#125; for word in strs: key = "".join(sorted(word)) if key in d: d.get(key).append(word) else: d[key] = [word] # d[key] = d.get(key,[]) + [word] return d.values() 核心思想 -&gt; 排序，排序之后的变位词就都一样了 leetcode 242,49 这个题的核心思路就是，每个单词按字母顺序排序之后的答案就是这个单词的key，如果两个单词的key一样的话这两个单词就是变位词，如果不一样的话就是新的词 在python里面直接用字典可以很好的储存变位词 56 merge intervalsGiven a collection of intervals, merge all overlapping intervals. Example 1: Input: [[1,3],[2,6],[8,10],[15,18]]Output: [[1,6],[8,10],[15,18]]Explanation: Since intervals [1,3] and [2,6] overlaps, merge them into [1,6]. 12345678910class Solution: def merge(self, intervals: List[List[int]]) -&gt; List[List[int]]: intervals.sort(key = lambda x : x[0]) output = [] for i in intervals: if output and i[0] &lt;= output[-1][1]: output[-1][1] = max(output[-1][1], i[1]) else: output.append(i) return output 注意点： 给的数据输入并不一定是排好序的，所以需要先排好序。这里用到了排序的key的功能。lambda是定义任意函数 g(x)= x[0] 需要输出的格式是list套list，所以需要append 思路错了的一个方向是，其实每个i不应该和隔壁的i比大小，而是应该和output里面的最终结果比大小，因为需要考虑到好几个内容都可以合并的情况 57插入12345678910111213141516171819202122232425262728class Solution: def insert(self, intervals: List[List[int]], newInterval: List[int]) -&gt; List[List[int]]: out = [] adding = False if len(intervals) == 0: return [newInterval] if newInterval[1] &lt; intervals[0][0]: out.append(newInterval) adding = True for i in intervals: if adding is False: if newInterval[0] &gt; i[1]: out.append(i) elif newInterval[1] &lt; i[0]: out.append(newInterval) adding = True else: after_insert = [min(i[0],newInterval[0]),max(i[1],newInterval[1])] out.append(after_insert) adding = True # print("adding") if adding is True: if i[0] &gt; out[-1][1]: out.append(i) else: out[-1][1] = max(out[-1][1],i[1]) if adding is False: out.append(newInterval) return out 自己苦思冥想了一个多小时的答案 有点繁琐，debug的时候主要是情况考虑的不够明确，包括没有考虑空的情况，在最后插入的情况，在最前插入的情况 但是最后总结的想，应该对插入的前后一视同仁，因为状况其实是差不多的，而我把前面分成了好多种状况，后面倒是写成了一种情况 12345678910111213left = []right = []s,e = newInterval[0],newInterval[1]for i in intervals: if i[1] &lt; s: left.append(i) elif i[0] &gt; e: right.append(i) else: s = min(i[0],s) e = max(i[1],e)return left + [[s,e]] + right 这是discussion里面的一种简要的解法，思路的不同就是他是每次都merge到new里面了（也就是s和e），而我是merge到out里面了 其实我的代码本身的也有merge到new的意思，但是被我分出了太多种太复杂的情况 101对称树1234567891011121314151617181920212223# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def isSymmetric(self, root: TreeNode) -&gt; bool: now = [] if root: now.append(root) while now: vals = [] for i in now: if i: vals.append(i.val) else: vals.append(None) if list(reversed(vals)) != vals: return False else: now = [j for i in now if i for j in (i.left, i.right)] return True 遍历的方法，最后一个now的表达式值得学习 注意root是node，而这个node实际的值在vals里面，因为好久没处理node了所以忘记了这一点 12345678910def isSymmetric(self, root: TreeNode) -&gt; bool: def Symm(L,R): if L and R: return L.val == R.val and Symm(L.left,R.right) and Symm(L.right,R.left) else: return L == R # return L is None and R is None #同等意义 return Symm(root, root) # 没有关于空的树的判断条件，所以需要从root开始 这个方法过于优雅，我要哭出来了 87 Scramble StringGiven a string s1, we may represent it as a binary tree by partitioning it to two non-empty substrings recursively. Below is one possible representation of s1 = “great”: great / \ gr eat / \ / \g r e at / \ a tTo scramble the string, we may choose any non-leaf node and swap its two children. For example, if we choose the node “gr” and swap its two children, it produces a scrambled string “rgeat”. rgeat / \ rg eat / \ / \r g e at / \ a t 思路： 首先，如果我这个单词的substring满足这个要求的话，上面一层的单词就满足这个要求，也就是说可以recursive的完成这个工作，对于不同的substring call这个函数来检验是否满足要求 边界条件： 如果string的长度小于等于2，那么怎么换其实都是满足的 如果两个string直接相等，那么也是满足的 先决条件： 如果这两个string的长度都不一样，那么肯定也不一样 如果这两个string里面字母的sort之后都不一样，那么肯定不一样 判断条件： 对于一个string，如果从k位置来分的话，有两种不同的结果。or关系 结果1：s1的前k个和s2的前k个一样 and s1的后n-k个和s2的后n-k个一样 结果2：s1的前k个和s2的后k个一样 and s1的前n-k个和s2的前n-k个一样 1234567891011class Solution: def isScramble(self, s1: str, s2: str) -&gt; bool: n1,n2 = len(s1),len(s2) if n1 != n2 or sorted(s1) != sorted(s2): return False if n1 &lt;= 2 or s1 == s2: return True f = self.isScramble for i in range(1,n1): if (f(s1[0:i], s2[0:i]) and f(s1[i:],s2[i:])) or \ f(s1[0:i], s2[n2-i:]) and f(s1[i:],s2[0:n2-i]): return True return False 38 count and sayThe count-and-say sequence is the sequence of integers with the first five terms as following: 1 11 21 1211 1112211 is read off as “one 1” or 11.11 is read off as “two 1s” or 21.21 is read off as “one 2, then one 1” or 1211. Given an integer n where 1 ≤ n ≤ 30, generate the nth term of the count-and-say sequence. Note: Each term of the sequence of integers will be represented as a string. 自己的智障解法12345678910111213141516171819202122232425262728class Solution: def countAndSay(self, n: int) -&gt; str: if n == 1: return "1" result = [1] for i in range(2,n+1): result = self.Say(result) return result def Say(self,num): n = len(num) counter = 1 counters = "" nums = str(num[0]) for i in range(1,n): if num[i] == num[i-1]: counter += 1 else: counters += str(counter) counter = 1 nums += str(num[i]) counters += str(counter) result = "" for i in range(len(counters)): result += counters[i] result += nums[i] return result 注意，如果要把list接成string，需要先把里面的所有项都转成string 感觉自己还是很不擅长recursive #316 remove deplicate lettersGiven a string which contains only lowercase letters, remove duplicate letters so that every letter appears once and only once. You must make sure your result is the smallest in lexicographical order among all possible results. Example 1: Input: “bcabc”Output: “abc”Example 2: Input: “cbacdcbc”Output: “acdb” 12345678910111213141516171819class Solution: def removeDuplicateLetters(self, s: str) -&gt; str: # s = sorted(s) # i = 0 # for n in s: # # print(n,i,s[i-1]) # if i &lt; 1 or n != s[i-1]: # s[i] = n # i += 1 # return "".join(s[:i]) s = list(s) result = [] last_occurrence = &#123;c: i for i, c in enumerate(s)&#125; for i,n in enumerate(s): if n not in result: while result and n &lt; result[-1] and result[-1] in s[i:]: result.pop() result.append(n) return "".join(result) 这道题里面的重点在lexicographical order 也就是说，在操作的时候，如果这个字母在后面的位置上出现了，但是放在前面的位置上会导致前面变大，那么就取后面的那个结果 本来我想的是可以先把没出现过的放进去，然后再刷新。但是直接放最好的应该更好一些 几种情况： 如果已经出现了：那么直接跳过 如果没出现： 如果比之前的小，并且前面的那个在后面还有，就得往前顶。还要考虑顶没了的情况，也就是result不为空 这里注意这三个条件是并列的，需要同时and。我刚开始把在后面出现放到循环里面去了，所以死循环了 在上面顶完之后，再把最新的加到最后 168 excel column titleGiven a positive integer, return its corresponding column title as appear in an Excel sheet. For example: 1 -&gt; A 2 -&gt; B 3 -&gt; C ... 26 -&gt; Z 27 -&gt; AA 28 -&gt; AB ... 123456789101112131415161718class Solution: def convertToTitle(self, n: int) -&gt; str: result = [] while n &gt; 0: letter = n % 26 n = n // 26 if letter == 0: letter = 26 n = n-1 result.append(letter) result = result[::-1] for i,item in enumerate(result): item += 64 item = str(chr(item)) result[i] = item # print(result) return "".join(result) 自己的傻逼方法： 最先得到的余数应该是最后的字母的值，所以这里出来的result需要翻转一下 翻转list最快的方法是 [::-1] str(chr(n))把数字转成char，ord把char转成数字，大写A是65，小写a是97 1return "" if num == 0 else self.convertToTitle((num - 1) / 26) + chr((num - 1) % 26 + ord('A')) 大佬的一行 忘记了这种str的连接方法 直接减-1计算更方便 171 Excel Sheet Column Number1234567class Solution: def titleToNumber(self, s: str) -&gt; int: # s = s[::-1] # result = 0 # for i,item in enumerate(s): # result += 26^(i) + (ord(item) - ord("A")) return 0 if s == "" else self.titleToNumber(s[:-1]) * 26 + ord(s[-1]) - ord("A") + 1 上面那道题的友情题，模拟大佬写出了解法 注意list的上限，到-1的话是到-2不包括-1 13 roman to integerRoman numerals are represented by seven different symbols: I, V, X, L, C, D and M. Symbol ValueI 1V 5X 10L 50C 100D 500M 1000For example, two is written as II in Roman numeral, just two one’s added together. Twelve is written as, XII, which is simply X + II. The number twenty seven is written as XXVII, which is XX + V + II. Roman numerals are usually written largest to smallest from left to right. However, the numeral for four is not IIII. Instead, the number four is written as IV. Because the one is before the five we subtract it making four. The same principle applies to the number nine, which is written as IX. There are six instances where subtraction is used: I can be placed before V (5) and X (10) to make 4 and 9.X can be placed before L (50) and C (100) to make 40 and 90.C can be placed before D (500) and M (1000) to make 400 and 900.Given a roman numeral, convert it to an integer. Input is guaranteed to be within the range from 1 to 3999.1234567891011121314151617181920class Solution: def romanToInt(self, s: str) -&gt; int: trans = &#123; "I":1, "V":5, "X":10, "L":50, "C":100, "D":500, "M":1000 &#125; s = s.replace("IV","IIII").replace("IX","VIIII") s = s.replace("XL","XXXX").replace("XC","LXXXX") s = s.replace("CD","CCCC").replace("CM","DCCCC") result = 0 for c in s: result += trans[c] return result 比较典型的用dict解决的例子，善用string里面的replace方法 12 int to roman上面的友情题 虽然可以穷举实现，但是我骄傲的自己写出来了recursive的方法 需要注意字母的替换顺序，不然会换错1234567891011121314151617181920212223242526272829303132class Solution: def intToRoman(self, num: int) -&gt; str: space = ["M", "D", "C", "L", "X", "V", "I"] trans = &#123; "I": 1, "V": 5, "X": 10, "L": 50, "C": 100, "D": 500, "M": 1000 &#125; s = self.find_raw(num, 0, space, trans) s = s.replace("DCCCC", "CM").replace("CCCC", "CD") s = s.replace("LXXXX", "XC").replace("XXXX", "XL") s = s.replace("VIIII", "IX").replace("IIII", "IV") return s def find_raw(self, num, name, space, trans): if num &lt; 5: return num * "I" else: temp = (num // trans[space[name]]) * space[name] after = self.find_raw( num % trans[space[name]], name + 1, space, trans) return temp + afters = Solution()print(s.intToRoman(9)) 273 int to english1234567891011121314151617181920212223242526272829class Solution: def numberToWords(self, num: int) -&gt; str: t0to19 = ["Zero", "One", "Two", "Three", "Four", "Five", "Six", "Seven", "Eight", "Nine", "Ten", "Eleven", "Twelve", "Thirteen", "Fourteen", "Fifteen", "Sixteen", "Seventeen", "Eighteen", "Nineteen"] tens = ["Twenty", "Thirty", "Forty", "Fifty", "Sixty", "Seventy", "Eighty", "Ninety"] def word(num, i = 0): if num == 0: return [""] if num &lt; 20: return [t0to19[num]] if num &lt; 100: return [tens[num // 10 - 2]] + word(num % 10) if num &lt; 1000: return [t0to19[num // 100]] + ["Hundred"] + word(num % 100) else: trans = &#123;"Billion": int(1e9), "Million": int( 1e6), "Thousand": int(1e3)&#125; part = ["Billion", "Million", "Thousand"][i] if num // trans[part] == 0: return word(num % trans[part], i + 1) else: return word(num // trans[part]) + [part] + word(num % trans[part], i + 1) s = word(num, 0) while "" in s: s.remove("") return " ".join(s) or "Zero" 注意移除空项的时候，需要用while而不是if 因为最后需要空格连接，所以最好先扔到list里面再出来 这题也太傻比了=。=无论怎么样都要自己手打这么多东西 # 68 text justification需要把这一行字左右对齐1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution: def fullJustify(self, words: List[str], maxWidth: int) -&gt; List[str]: # 每一行填满，如果填不满的时候，词的中间的空格尽量平均 # 最后一行右边加空格 # 每读一个单词后面需要加一行 space = 0 line = [0] # 每一行开头的单词的坐标 for i, word in enumerate(words): if space + len(word) &lt; maxWidth: space += len(word) + 1 elif space + len(word) == maxWidth and i != len(words) - 1: space = 0 line.append(i + 1) elif space + len(word) &gt; maxWidth: space = len(word) + 1 #注意这里的长度变化了 line.append(i) output = [] for i in range(len(line)): if i &lt; len(line) - 1: s = "" this_line = words[line[i]:line[i+1]] length = -1 # 最后一个单词不带空格 for w in this_line: length += len(w) + 1 if len(this_line) == 1: s = this_line[0] + (maxWidth - len(this_line[0])) * " " else: space_len = (maxWidth - length) // (len(this_line) - 1) extra_space = (maxWidth - length) % (len(this_line) - 1) for i,w in enumerate(this_line): if i &lt; len(this_line) - 1: s = s + w + " " + space_len*" " if i &lt;= extra_space - 1: s = s + " " else: s = s + w output.append(s) else: this_line = words[line[i]:] s = " ".join(this_line) s = s + " "*(maxWidth-len(s)) output.append(s) return output 思路 先分开单词 再往里插空格 6把整数转过来12345678910111213141516171819202122class Solution: def reverse(self, x: int) -&gt; int: Positive = True x2 = [] if str(x)[0] == "-": Positive = False x = int(x - x * 2) while x &gt;= 10: num = x % 10 x = x // 10 x2.append(str(num)) x2.append(str(x)) output = "".join(x2) output = int(output) if Positive: output = int(output) else: output = int(output) - 2 * int(output) if output &gt; 2**31 - 1 or output &lt; -2**31: return 0 else: return output 注意啊2的31次方不是2e31啊啊我在干什么 165. Compare Version Numbers 比较两个版本号，需要忽略里面的0 123456789101112131415161718192021222324252627282930313233343536class Solution: def compareVersion(self, version1: str, version2: str) -&gt; int: v1 = version1.split(".") v2 = version2.split(".") v1 = [int(x) for x in v1] v2 = [int(x) for x in v2] # 可以简化为两行 # versions1 = [int(v) for v in version1.split(".")] # versions2 = [int(v) for v in version2.split(".")] if len(v1) &gt; len(v2): length = len(v2) else: length = len(v1) for i in range(length): c1,c2 = v1[i],v2[i] if c1 &gt; c2: return 1 elif c1 &lt; c2: return -1 end = i rest1,rest2 = v1[i+1:],v2[i+1:] if sum(rest1) == sum(rest2): return 0 elif sum(rest1) &gt; sum(rest2): return 1 elif sum(rest1) &lt; sum(rest2): return -1 # 另一种方法，更简洁 # for i in range(max(len(versions1),len(versions2))): # v1 = versions1[i] if i &lt; len(versions1) else 0 # v2 = versions2[i] if i &lt; len(versions2) else 0 # if v1 &gt; v2: # return 1 # elif v1 &lt; v2: # return -1; # return 0; 需要考虑的主要就是长度不一样的情况和塞0的情况，我的想法是取比较小的总长度，然后再比较剩余的 大佬的情况是比较的所有的长度，如果超过了现在的长度就直接设置为0，这样不会影响比较。最后都比完都没差就是0 66Given a non-empty array of digits representing a non-negative integer, plus one to the integer. The digits are stored such that the most significant digit is at the head of the list, and each element in the array contain a single digit. You may assume the integer does not contain any leading zero, except the number 0 itself. Example 1: Input: [1,2,3]Output: [1,2,4]Explanation: The array represents the integer 123. 12345678910111213class Solution: def plusOne(self, digits: List[int]) -&gt; List[int]: n = len(digits) for i in range(n-1,-1,-1): digits[i] += 1 if digits[i] &lt; 10: return digits digits[i] = 0 if digits[0] == 0: digits.append(0) for j in range(n,0,-1): digits[j] = digits[j-1] digits[0] = 1 return digits 没啥好多说的，所有情况都考虑了就行了 但是其实，如果会产生进位，只有可能是因为最后一位是9，所以我这个判断条件稍微有一点没想清楚的感觉 下面这个写出来更加优雅12345678910111213141516class Solution: def plusOne(self, digits): """ :type digits: List[int] :rtype: List[int] """ if len(digits) == 1 and digits[0] == 9: return [1, 0] if digits[-1] != 9: digits[-1] += 1 return digits else: digits[-1] = 0 digits[:-1] = self.plusOne(digits[:-1]) return digits 258 一个数字的逐位相加，直到小于91234567891011class Solution: def addDigits(self, num: int) -&gt; int: if num &lt; 10: return num Sum = 0 for i in str(num): Sum += int(i) return self.addDigits(Sum) # if num == 0 : return 0 # else:return (num - 1) % 9 + 1 上面那种方法是我写的，复杂度是n 下面的方法是数学规律，复杂度是1 144 Binary Tree Preorder TraversalGiven a binary tree, return the preorder traversal of its nodes’ values. Example: Input: [1,null,2,3] 1 \ 2 / 3 Output: [1,2,3] 注意审题：这道题并不是按左小右大的顺序排列的，而且preorder traversal指的就是先访问root，再从左到右访问root的子节点 需要注意输入为空的情况 recursive和iterate都可以完成 在recursive里面，因为需要把内容储存在list里面，所以需要新建一个函数12345678910111213class Solution: def preorderTraversal(self, root: TreeNode) -&gt; List[int]: result = [] if root: self.preorder(root,result) return result def preorder(self,root,result): if root: result.append(root.val) if root.left: self.preorder(root.left,result) if root.right: self.preorder(root.right,result) 1234567891011class Solution: def preorderTraversal(self, root: TreeNode) -&gt; List[int]: stack = [root] result = [] while stack: current = stack.pop() if current: result.append(current.val) stack.append(current.right) stack.append(current.left) return result 注意因为是把内容放在stack里面，所以要先放right才能让他后出来 需要判断current是不是为空 pop默认的就是最后一位 145 Binary Tree Postorder Traversal 和上一道题反序 注意虽然是post，但是还是需要先访问左child，再访问右child 1234567891011121314class Solution: def postorderTraversal(self, root: TreeNode) -&gt; List[int]: res = [] if root: self.post(root,res) return res def post(self,root,res): if root.left: self.post(root.left,res) if root.right: self.post(root.right,res) if root: res.append(root.val) 1234567891011class Solution: def postorderTraversal(self, root: TreeNode) -&gt; List[int]: stack = [root] res = [] while stack: current = stack.pop() if current: res.append(current.val) stack.append(current.left) stack.append(current.right) return res[::-1] iterative的方法可以采用先处理右边的点，再处理左边的点。因为右边的后放进stack所以先出来先进res里面 最后再把结果倒序（牛逼） 102Given a binary tree, return the level order traversal of its nodes’ values. (ie, from left to right, level by level). For example:Given binary tree [3,9,20,null,null,15,7], 3 / \ 9 20 / \ 15 7return its level order traversal as:[ [3], [9,20], [15,7]] 12345678910111213141516171819202122232425262728293031323334# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def levelOrder(self, root: TreeNode) -&gt; List[List[int]]:# self.levels = []# self.find(root,0)# return self.levels # def find(self,node, level):# if node:# if len(self.levels) &lt;= level:# self.levels += [[node.val]]# else:# self.levels[level] += [node.val]# self.find(node.left, level + 1)# self.find(node.right,level + 1) if not root: return [] stack, queue, nCount, res = [root],[],1,[[root.val]] while stack: temp = stack.pop(0) if temp.left: stack.append(temp.left) if temp.right: stack.append(temp.right) nCount -= 1 if nCount == 0: queue = [x.val for x in stack] if queue: res += [queue] nCount = len(stack) #得到的是下一层的个数 return res 两种方法，重点是找到如何重新计数level的层级，第一种方法不是顺着一步一步写进结果里的，是跳着写进去的。第二个方法是直接写进去的 103 把树按层zigzag排列Given a binary tree, return the zigzag level order traversal of its nodes’ values. (ie, from left to right, then right to left for the next level and alternate between). For example:Given binary tree [3,9,20,null,null,15,7], 3 / \ 9 20 / \ 15 7return its zigzag level order traversal as:[ [3], [20,9], [15,7]]12345678910111213141516171819class Solution: def zigzagLevelOrder(self, root: TreeNode) -&gt; List[List[int]]: if not root: return [] levels = [] self.Find(root,0,levels) return levels def Find(self, node, level, levels): if node: if len(levels) &lt;= level: levels.append([node.val]) elif level%2: levels[level].insert(0,node.val) elif not level%2: levels[level].append(node.val) self.Find(node.left,level+1,levels) self.Find(node.right,level+1,levels) 直接判断层数就可以实现，如果用一个flag表示没法在一整层的层面上实现 list是可以两端插入的 100 判断两个tree是不是一样的12345678910111213141516171819class Solution: def isSameTree(self, p: TreeNode, q: TreeNode) -&gt; bool: # if (not p and q) or (not q and p): # return False # if p and q: # if p.val != q.val: return False # else: # return self.isSameTree(p.left,q.left) and self.isSameTree(p.right,q.right) # return p == q # if p and q: # return p.val == q.val and self.isSameTree(p.left,q.left) and self.isSameTree(p.right,q.right) # return p == q if p and q: if p.val != q.val: return False return self.isSameTree(p.left,q.left) and self.isSameTree(p.right,q.right) return p == q 感觉自己写recursive总是有点问题，需要判断好终极条件 226 把一个二叉树对称变换123456789101112131415# 不需要变换树的val，可以直接变换nodeclass Solution: def invertTree(self, root: TreeNode) -&gt; TreeNode: # def invert(L,R): # if L and R: # L.val, R.val = R.val, L.val # invert(L.left,R.right) # invert(L.right,R.left) if root: invert = self.invertTree root.right, root.left = invert(root.left), invert(root.right) return root 需要换node而不是换val 257Given a binary tree, return all root-to-leaf paths. Note: A leaf is a node with no children. Example: Input: 1 / \2 3 \ 5 Output: [“1-&gt;2-&gt;5”, “1-&gt;3”] Explanation: All root-to-leaf paths are: 1-&gt;2-&gt;5, 1-&gt;312345678910111213141516class Solution: def binaryTreePaths(self, root: TreeNode) -&gt; List[str]: if not root: return [] stack = [(root,"")] result = [] while stack: current,ls = stack.pop() if not current.left and not current.right: result.append(ls+str(current.val)) if current.right: stack.append((current.right,ls+str(current.val)+"-&gt;")) if current.left: stack.append((current.left,ls+str(current.val)+"-&gt;")) return result dfs的方法，终止条件是现在的点没有任何child了。自己搞错的地方主要是需要string跟着stack一起走，而不是两个分别判断。 同样的到底可以写出来第112题，本质上是一样的，就是把求路径换成了这个路径的和 同理写出来113，在tuple里面再加上路径的计算就可以了 129也同理！但是129可以直接在每次recursion里面把上一位数乘10，然后加上这一位数，这样会比得到所有路径再计算的速度快很多 111 找出这个tree的最小depth 可以用BFS也可以用DFS，但是注意的是两个return的东西的条件是不一样的。DFS的时候必须把左右树比大小123456789101112131415161718class Solution: def minDepth(self, root: TreeNode) -&gt; int: if not root: return 0 # stack = [(root,1)] # while stack: # current,depth = stack.pop(0) # if not current.left and not current.right: # return depth # if current.left: # stack.append((current.left,depth+1)) # if current.right: # stack.append((current.right,depth+1)) # dfs if root.left is None or root.right is None: return max(self.minDepth(root.left),self.minDepth(root.right))+1 else: return min(self.minDepth(root.left),self.minDepth(root.right))+1 104 寻找最深的层 不用判断条件，直接dfs每次加一就可以实现了12345class Solution: def maxDepth(self, root: TreeNode) -&gt; int: if not root: return 0 # if not root.left and not root.right: return max(self.maxDepth(root.left),self.maxDepth(root.right)) + 1 110 判断是不是平衡树 recursion的方法，注意的是每次返回的时候连带着子树是否平衡一起返回的，整体思路和之前的带着深度一起返回的感觉差不多 或者也可以直接设置一个函数，计算出各个部分的height，然后再放到isBalance里面从上到下计算123456789class Solution: def isBalanced(self, root: TreeNode) -&gt; bool: return self.dfs(root)[1] def dfs(self,root): if not root: return (0, True) #depth, if_balance l_depth, l_balance = self.dfs(root.left) r_depth, r_balance = self.dfs(root.right) return max(l_depth,r_depth)+1, l_balance and r_balance and abs(l_depth-r_depth) &lt;= 1 337/213都是贼偷东西，不能连着偷两家。简单的动态规划问题。这个问题的主要思路如下： 对于每一家，其实都有两种情况：偷这家和不偷这家情况下得到的钱 偷这家的时候，偷到的钱等于：这家的钱+前一家（childnode）不偷时候得到的钱 不偷这家的时候，偷到得钱等于：max（偷前一家，不偷前一家） 注意这种情况下，前一家可以偷可以不偷，取决于有多少钱三个题如下： 最简单的情况是数组 中等情况是一个环，即数组的收尾不能连着偷。在这种情况下其实就是计算两次，一次不偷第一家，一次不偷最后一家，看哪种情况多 最后的情况是二叉树的情况，这种情况下可以给每个点都规定一个tuple分别表示偷了和没偷的结果 1234567891011class Solution: #第二种情况下 def rob(self, nums: List[int]) -&gt; int: if len(nums) == 0: return 0 if len(nums) == 1: return nums[0] return max(self.simple_rob(nums[1:]),self.simple_rob(nums[:-1])) def simple_rob(self,nums): rob,not_rob = 0,0 for n in nums: rob,not_rob = not_rob+n, max(not_rob,rob) return max(rob,not_rob) 12345678910class Solution: #第三种情况下 def rob(self, root: TreeNode) -&gt; int: return max(self.dfs(root)) def dfs(self,root): if not root: return (0,0) # [0]steal this node, [1] don't steal this node left = self.dfs(root.left) right = self.dfs(root.right) return (root.val + left[1] + right[1],max(left[0],left[1]) + max(right[0],right[1])) 235 Lowest Common Ancestor of a Binary Search Tree 找到给的两个点的最低的公共的祖先（parent） 其实需要注意这个思路，思路就是当这两个点都比现在的root小的时候，那这个公共点在root的左边，如果都小的时候就在右边。 因为这里要找的是最low的公共点，也就是离root最远的点 123456789class Solution: def lowestCommonAncestor(self, root: 'TreeNode', p: 'TreeNode', q: 'TreeNode') -&gt; 'TreeNode': if not root or not p or not q: return None if max(p.val,q.val) &lt; root.val: return self.lowestCommonAncestor(root.left,p,q) if min(p.val,q.val) &gt; root.val: return self.lowestCommonAncestor(root.right,p,q) return root 236 依然是找公共祖先，但是不是在BST里面找而是普通的二叉树里面找了，所以也就是不能用BST的性质了123456789class Solution: def lowestCommonAncestor(self, root: 'TreeNode', p: 'TreeNode', q: 'TreeNode') -&gt; 'TreeNode': if root is None or root==p or root ==q: return root left = self.lowestCommonAncestor(root.left,p,q) right = self.lowestCommonAncestor(root.right,p,q) if left and right: return root return left or right 108 Convert Sorted Array to Binary Search Tree 注意，已经给了排好序的array了，而且需要的结果是height-balance的，这里可以直接取这个array最中间的作为root，然后左右分别recursion 如果用平常的插入方法，插入进来的树不一定是平衡的12345678910class Solution: def sortedArrayToBST(self, nums: List[int]) -&gt; TreeNode: if not nums: return None mid = len(nums) // 2 root = TreeNode(nums[mid]) root.left = self.sortedArrayToBST(nums[:mid]) root.right = self.sortedArrayToBST(nums[mid+1:]) return root 77 回溯法，列举所有组合 回溯法需要注意三个阶段 可以选择的条件是什么（需要在这些条件里迭代) 对条件的限制是什么。比如在这个例子里面，如果一个数字用过了就不能再用了。不能实现或者已经实现的条件需要弹出 目标：需要得到一个base case。比如这个题里面，字符串的长度到了k，就需要输入了 用于问题种类：计算或者列举全部的可能 这道题的python的问题，在list里面append之后pop明显会出现一些问题1234567891011121314151617181920class Solution: def combine(self, n: int, k: int) -&gt; List[List[int]]: all_res = [] self.search(1,n,k,[],all_res) return all_res def search(self,index,n,k,res,all_res): #start, n, choose num, all result if len(res) == k: all_res.append(res) # print(all_res) return for i in range(index,n+1): # res.append(i) # print("before",res) # print(i+1,res,all_res) self.search(i+1,n,k,res+[i],all_res) # del(res[-1]) # print("after",res) return 39 所有能到target数字的组合 回溯Input: candidates = [2,3,6,7], target = 7,A solution set is:[ [7], [2,2,3]]123456789101112131415161718class Solution: def combinationSum(self, candidates: List[int], target: int) -&gt; List[List[int]]: def solver(nums,target,index,path,res): if target &lt; 0: return if target == 0: # path.sort() # if path not in res: res.append(path) return for i in range(index,len(nums)): solver(nums,target-nums[i],i,path+[nums[i]],res) res = [] solver(candidates,target,0,[],res) return res 注意这里需要每次从i开始进行下一轮，也就是如果第一个2可以加进去，第二次还是从2开始往里试着加。要是2加不进去了，就只会往2后面的index走（也就是默认给你的list已经是排好序的了） 整体思路和前面几道题差不多。重点就是确认停止的条件，然后每次先判断停止条件，如果不符合再进行recursion。注意recursion的每轮的条件判定 40 数字不是按顺序排好的了，数字会重复出现了 我选择的方法是在每次加入新的path之前，排序，然后比对这个是否在已经算出来的结果里面（虽然好像不快） 123456789101112131415class Solution: def combinationSum2(self, candidates: List[int], target: int) -&gt; List[List[int]]: def solver(nums,target,index,path,res): if target &lt; 0: return if target == 0: path.sort() if path not in res: res.append(path) for i in range(index,len(nums)): solver(nums,target-nums[i],i+1,path+[nums[i]],res) res = [] solver(candidates,target,0,[],res) return res 别人的方法主要增加了两个新的判断，第一个是如果在for里面，现在的数字已经比需要的target大了，那么就不需要继续搜索后面所有的部分了（？）。因为现在所有的数字都是positive的 最重要的是，如果这个数字不是第一个放进去的数字，并且这个数字和之前的数字相同，那么这个数字应该直接被ignore 12345678910111213141516171819class Solution: def combinationSum2(self, candidates: List[int], target: int) -&gt; List[List[int]]: def solver(nums,target,index,path,res): if target &lt; 0: return if target == 0: print(path) res.append(path) for i in range(index,len(nums)): if i &gt; index and nums[i]==nums[i-1]: continue if nums[i] &gt; target: break solver(nums,target-nums[i],i+1,path+[nums[i]],res) res = [] candidates.sort() solver(candidates,target,0,[],res) return res 以 1，1，2，5，6，7，10凑8为例子 当取第一个1的时候，能组出来116，125，17，三个结果。这时候这三个结果都在第一层的i=0的时候的出来的结果。当这一层所有的结果取过之后，就会从第一个1退出来，进到第二个1. 但是如果直接算第2个1，也能组粗125和17，从结果上说这两个1是重复的，所以代码在这部分直接continue了，没有计算第二个1，而是直接跳到了第三个数字2 这样计算重复的方法比我再sort一次然后search一次消耗的时间少很多 216 回溯 从1-9里选k个数字组合，得到目标数字 很简单，没啥可搞的1234567891011121314151617181920class Solution: def combinationSum3(self, k: int, n: int) -&gt; List[List[int]]: def Solver(nums,k,n,index,path,res): if len(path) == k: if n &lt;0: return if n == 0: res.append(path) return for i in range(index,9): if i &gt; n: break Solver(nums,k,n-nums[i],i+1,path+[nums[i]],res) nums = [i for i in range(1,10)] res = [] Solver(nums,k,n,0,[],res) return res 377 虽然放在上面的系列里了但是是DPGiven an integer array with all positive numbers and no duplicates, find the number of possible combinations that add up to a positive integer target. Example: nums = [1, 2, 3]target = 4 The possible combination ways are:(1, 1, 1, 1)(1, 1, 2)(1, 2, 1)(1, 3)(2, 1, 1)(2, 2)(3, 1) Note that different sequences are counted as different combinations. Therefore the output is 7. 123456789class Solution: def combinationSum4(self, nums: List[int], target: int) -&gt; int: nums.sort() com = [1] + [0]*target for i in range(target+1): for num in nums: if num &gt; i: break com[i] += com[i-num] return com[target] 46 找出所有的排列组合Given a collection of distinct integers, return all possible permutations. Example: Input: [1,2,3]Output:[ [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1]] 这里每个数字不止用一次，所以需要一个方法来记录已经visit的数字，或者把nums的大小改变（比如每一次新输入的nums都跳过现在使用的数字） 注意这里面没有重复的数字 我这个方法也可以 12345678910111213141516class Solution: def permute(self, nums: List[int]) -&gt; List[List[int]]: def Solver(nums,index,path,res): if len(path) == len(nums): res.append(path) return for i in nums: if i not in path: Solver(nums,i+1,path+[i],res) res = [] Solver(nums,0,[],res) return res 47在上面的基础上有了重复的数字 首先保证了数组必须要是sort的，这样才能确定相同的数字挨在一起 核心思想就是，每次取出一个数字的时候，把原来nums的这个数直接去掉，下次再从0开始找，这样就能得到所有的数据了 在recursion判断条件上，因为已经确定了数组有序，所有每次记录一个temp，来表示上一个数字，只有当这个数字 第一次被拿出来（index==0）or这个数字和上一个数字不相等or上一个还没有数字的时候，才能进入recursion12345678910111213141516class Solution: def permuteUnique(self, nums: List[int]) -&gt; List[List[int]]: def Solver(nums,temp,path,res): if len(nums) == 0: res.append(path) return for i in range(0,len(nums)): if temp is None or nums[i] != temp or i == 0: temp = nums[i] Solver(nums[:i]+nums[i+1:],temp,path+[nums[i]],res) nums.sort() res = [] Solver(nums,None,[],res) return res 60The set [1,2,3,…,n] contains a total of n! unique permutations. By listing and labeling all of the permutations in order, we get the following sequence for n = 3: “123”“132”“213”“231”“312”“321”Given n and k, return the kth permutation sequence. 时间太长了，不能用backtracking来做 思路，前（n-1）！个数字的开头是1，然后n-1！个是2，然后是3，以此类推一直到最后。因为一共n个数字，n-1！xn也就是n！了 在确定第一个数字之后，第二个数字的前n-2！个是2，然后是3，然后以此类推]]></content>
      <categories>
        <category>算法</category>
        <category>Leetcode</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment2之Pytorch]]></title>
    <url>%2F2019%2F05%2F07%2FCS231nassignment2Pytorch%2F</url>
    <content type="text"><![CDATA[这部分需要在torch和TensorFlow两个framework里面选一个。 PyTorchWhat 加入了Tensor的object（类似于narray），不需要手动的backprop了 Why 在GPU上面跑，不需要CUDA就可以在自己的GPU上面跑NN functions很多 站在巨人的肩膀上！ 在实际使用中应该写的深度学习代码 学习资料 Justin Johnson has made an excellenttutorial for PyTorch. DetailedAPI doc If you have other questions that are not addressed by the API docs, the PyTorch forum is a much better place to ask than StackOverflow. 整体结构 第一部分，准备，使用dataset 第二部分，abstraction level1，直接在最底层的Tensors上面操作 第三部分，abstraction level2，nn.Module定义一个任意的NN结构 第四部分，abstraction level3，nn.Sequential，定义一个简单的线性feed - back网络 第五部分，自己调参，尽量让CIFAR - 10的精度尽可能高 Part 1.Preparationpytorch里面有下载dataset，预处理并且迭代成minibatch的功能 import torchvision.transforms as T 这个包包括了预处理以及增强data的功能，在这里选择了减去平均的RGB并且除以标准差 然后对不同的部分分别构建了一个dataset object（训练，测试，val），这个dataset会载入一次training example，并且在DataLoader部分构建minibatch 1234567891011121314151617181920212223242526272829NUM_TRAIN = 49000# The torchvision.transforms package provides tools for preprocessing data# and for performing data augmentation; here we set up a transform to# preprocess the data by subtracting the mean RGB value and dividing by the# standard deviation of each RGB value; we've hardcoded the mean and std.transform = T.Compose([ T.ToTensor(), T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])# We set up a Dataset object for each split (train / val / test); Datasets load# training examples one at a time, so we wrap each Dataset in a DataLoader which# iterates through the Dataset and forms minibatches. We divide the CIFAR-10# training set into train and val sets by passing a Sampler object to the# DataLoader telling how it should sample from the underlying Dataset.cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True, transform=transform)loader_train = DataLoader(cifar10_train, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True, transform=transform)loader_val = DataLoader(cifar10_val, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, transform=transform)loader_test = DataLoader(cifar10_test, batch_size=64) 需要一个是否使用GPU的flag，并且set到true。在这个作业里面不是必须用GPU跑，但是如果电脑不能enableCUDA的话，就会自动返回CPU模式。 除此之外，建立了两个global var，dtype代表float32，device代表用哪个 因为mac本身不支持CUDA，而且好像新版本的系统还不能安装N卡的部分，所以现在用的CPU 12345678910111213USE_GPU = Truedtype = torch.float32 # we will be using float throughout this tutorialif USE_GPU and torch.cuda.is_available(): device = torch.device('cuda')else: device = torch.device('cpu')# Constant to control how frequently we print train lossprint_every = 100print('using device:', device) Part2 Barebones PyTorch 虽然有很多高层的API已经有了很多功能，但是这部分从比较底层的部分来进行 建立一个简单的fc - relu net，两个中间层，没有bias 用Tensor的method来计算forward，并且用自带的autograd来计算back 如果设定了requires_grad = True，那么在计算的时候不仅会计算值，还会生成计算back的graph if x is a Tensor with x.requires_grad == True then after backpropagation x.grad will be another Tensor holding the gradient of x with respect to the scalar loss at the end PyTorch Tensors: Flatten Function Tensors是一个和narray很像的东西，定义了很多比较好用的功能，比如flatten来reshape image data 在Tensor里面一个图片的形状是NxCxHxW datapoint的数量 channels feature map的H和W 但是在affine里面我们希望一个datapoint可以表现成一个单独的vector，而不是channel和宽和高 所以在这里用flatten来首先读取NCHW的数据，然后返回这个data的view（相当于array里面的reshape，把它改成了Nx？？，其中？？可以是任何值） 123456def flatten(x): N = x.shape[0] # read in N, C, H, W # "flatten" the C * H * W values into a single vector per image return x.view(N, -1) Barebones PyTorch: Two-Layer Network当定义一个 two_layer_fc的时候，会有两层的中间带relu的forward，在写好了forward之后需要确保输出的形状是对的并且没有什么问题(最近好像对这个大小已经没有什么疑问了) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import torch.nn.functional as F # useful stateless functionsdef two_layer_fc(x, params): """ A fully-connected neural networks; the architecture is: NN is fully connected -&gt; ReLU -&gt; fully connected layer. Note that this function only defines the forward pass; PyTorch will take care of the backward pass for us. The input to the network will be a minibatch of data, of shape (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units, and the output layer will produce scores for C classes. Inputs: - x: A PyTorch Tensor of shape (N, d1, ..., dM) giving a minibatch of input data. - params: A list [w1, w2] of PyTorch Tensors giving weights for the network; w1 has shape (D, H) and w2 has shape (H, C). Returns: - scores: A PyTorch Tensor of shape (N, C) giving classification scores for the input data x. """ # first we flatten the image x = flatten(x) # shape: [batch_size, C x H x W] w1, w2 = params # Forward pass: compute predicted y using operations on Tensors. Since w1 and # w2 have requires_grad=True, operations involving these Tensors will cause # PyTorch to build a computational graph, allowing automatic computation of # gradients. Since we are no longer implementing the backward pass by hand we # don't need to keep references to intermediate values. # you can also use `.clamp(min=0)`, equivalent to F.relu() x = F.relu(x.mm(w1)) x = x.mm(w2) return xdef two_layer_fc_test(): hidden_layer_size = 42 # minibatch size 64, feature dimension 50 x = torch.zeros((64, 50), dtype=dtype) w1 = torch.zeros((50, hidden_layer_size), dtype=dtype) w2 = torch.zeros((hidden_layer_size, 10), dtype=dtype) scores = two_layer_fc(x, [w1, w2]) print(scores.size()) # you should see [64, 10]two_layer_fc_test() Barebones PyTorch: Three-Layer ConvNet 上下这两个都是，在测试的时候可以直接pass 0来测试tensor的大小是不是对的 网络的结构 conv with bias，channel_1 filters，KW1xKH1，2 zero - padding RELU conv with bias，channel_2 filters，KW2xKH2，1 zero - padding RELU fc with bias，输出C class 注意！在这里fc之后没有softmax的激活层，因为在后面计算loss的时候会提供softmax，计算起来更加有效率 注意2！在conv2d之前不需要flatten，在fc之前才需要flatten 123456789101112131415161718192021222324252627282930313233343536373839404142434445def three_layer_convnet(x, params): """ Performs the forward pass of a three-layer convolutional network with the architecture defined above. Inputs: - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images - params: A list of PyTorch Tensors giving the weights and biases for the network; should contain the following: - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights for the first convolutional layer - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first convolutional layer - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving weights for the second convolutional layer - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second convolutional layer - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you figure out what the shape should be? (N,channel_2*H*W) - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you figure out what the shape should be? (C,) Returns: - scores: PyTorch Tensor of shape (N, C) giving classification scores for x """ conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params scores = None ################################################################################ # TODO: Implement the forward pass for the three-layer ConvNet. # ################################################################################ # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x = nn.functional.conv2d(x, conv_w1, bias=conv_b1, padding=2) x = nn.functional.conv2d(F.relu(x), conv_w2, bias=conv_b2, padding=1) x = flatten(x) x = x.mm(fc_w) + fc_b scores = x # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ################################################################################ # END OF YOUR CODE # ################################################################################ return scores Barebones PyTorch: Initialization random_weight(shape) initializes a weight tensor with the Kaiming normalization method. -&gt; 使用了KAIMING normal zero_weight(shape) initializes a weight tensor with all zeros. Useful for instantiating bias parameters. 123456789101112131415161718192021222324252627def random_weight(shape): """ Create random Tensors for weights; setting requires_grad=True means that we want to compute gradients for these Tensors during the backward pass. We use Kaiming normalization: sqrt(2 / fan_in) """ if len(shape) == 2: # FC weight fan_in = shape[0] else: # conv weight [out_channel, in_channel, kH, kW] fan_in = np.prod(shape[1:]) # randn is standard normal distribution generator. w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in) w.requires_grad = True return wdef zero_weight(shape): return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)# create a weight of shape [3 x 5]# you should see the type `torch.cuda.FloatTensor` if you use GPU.# Otherwise it should be `torch.FloatTensor`random_weight((3, 5)) Barebones PyTorch: Check Accuracy 在这部分不需要计算grad，所以要关上torch.no_grad()避免浪费 输入 一个DataLoader来给我们想要check的data分块 一个表示模型到底是什么样子的model_fn，来计算预测的scores 这个model需要的参数 没有返回值但是会print出来acc 12345678910111213141516171819202122232425262728def check_accuracy_part2(loader, model_fn, params): """ Check the accuracy of a classification model. Inputs: - loader: A DataLoader for the data split we want to check - model_fn: A function that performs the forward pass of the model, with the signature scores = model_fn(x, params) - params: List of PyTorch Tensors giving parameters of the model Returns: Nothing, but prints the accuracy of the model """ split = 'val' if loader.dataset.train else 'test' print('Checking accuracy on the %s set' % split) num_correct, num_samples = 0, 0 with torch.no_grad(): for x, y in loader: x = x.to(device=device, dtype=dtype) # move to device, e.g. GPU y = y.to(device=device, dtype=torch.int64) scores = model_fn(x, params) _, preds = scores.max(1) num_correct += (preds == y).sum() num_samples += preds.size(0) acc = float(num_correct) / num_samples print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc)) BareBones PyTorch: Training Loop 用stochastic gradient descent without momentum来train，并且用torch.functional.cross_entropy来计算loss 输入 model_fc params learning_rate 没有输出 进行的操作 把data移动到GPU或者CPU 计算score和loss loss.backward() update params，这部分不需要计算grad BareBones PyTorch: Training a ConvNet 需要网络 Convolutional layer(with bias) with 32 5x5 filters, with zero - padding of 2 ReLU Convolutional layer(with bias) with 16 3x3 filters, with zero - padding of 1 ReLU Fully - connected layer(with bias) to compute scores for 10 classes 需要自己初始化参数，不需要tune hypers 注意1：fc的w的大小是D,C，跟数据无关需要从上一层的输出求 conv之后的图片大小从32-&gt; 30 12345678910111213141516171819202122232425262728293031learning_rate = 3e-3channel_1 = 32channel_2 = 16conv_w1 = Noneconv_b1 = Noneconv_w2 = Noneconv_b2 = Nonefc_w = Nonefc_b = None################################################################################# TODO: Initialize the parameters of a three-layer ConvNet. ################################################################################## *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****conv_w1 = random_weight((channel_1, 3, 5, 5))conv_b1 = zero_weight(channel_1)conv_w2 = random_weight((channel_2, channel_1, 5, 5))conv_b2 = zero_weight(channel_2)fc_w = random_weight((channel_2 * 30 * 30, 10))fc_b = zero_weight(10)# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****################################################################################# END OF YOUR CODE #################################################################################params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]train_part2(three_layer_convnet, params, learning_rate) Part3 PyTorch Module API 上面的所有过程是手算来track整个过程的，但是在更大的net里面就没有什么用了 nn.Module来定义网络，并且可以选optmi的方法 Subclass nn.Module. Give your network class an intuitive name like TwoLayerFC. __init__()里面定义自己需要的所有层. nn.Linear and nn.Conv2d 都在模块里自带了. nn.Module will track these internal parameters for you. Refer to the doc to learn more about the dozens of builtin layers. Warning: don’t forget to call the super().__init__() first!（调用父类） In the forward() method, define the connectivity of your network. 直接用init里面初始化好的方法来forward，不要再forward里面增加新的方法 用上面的方法来写一个三层的layer 注意需要初始化w和b的参数，用kaiming的方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class ThreeLayerConvNet(nn.Module): def __init__(self, in_channel, channel_1, channel_2, num_classes): super().__init__() ######################################################################## # TODO: Set up the layers you need for a three-layer ConvNet with the # # architecture defined above. # ######################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** self.conv_1 = nn.Conv2d(in_channel,channel_1,5,stride=1, padding=2,bias=True) nn.init.kaiming_normal_(self.conv_1.weight) nn.init.constant_(self.conv_1.bias, 0) self.conv_2 = nn.Conv2d(channel_1,channel_2,3,stride=1, padding=1,bias=True) nn.init.kaiming_normal_(self.conv_2.weight) nn.init.constant_(self.conv_2.bias, 0) self.fc_3 = nn.Linear(channel_2 * 32 * 32 , num_classes) nn.init.kaiming_normal_(self.fc_3.weight) nn.init.constant_(self.fc_3.bias, 0) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ######################################################################## # END OF YOUR CODE # ######################################################################## def forward(self, x): scores = None ######################################################################## # TODO: Implement the forward function for a 3-layer ConvNet. you # # should use the layers you defined in __init__ and specify the # # connectivity of those layers in forward() # ######################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x = self.conv_1(x) x = self.conv_2(F.relu(x)) x = flatten(F.relu(x)) x = self.fc_3(x) scores = x # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ######################################################################## # END OF YOUR CODE # ######################################################################## return scoresdef test_ThreeLayerConvNet(): x = torch.zeros((64, 3, 32, 32), dtype=dtype) # minibatch size 64, image size [3, 32, 32] model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=8, num_classes=10) scores = model(x) print(scores.size()) # you should see [64, 10]test_ThreeLayerConvNet() Module API: Check Accuracy 不用手动pass参数了，直接就可以得到整个net的acc Module API: Training Loop 用optimizer这个object来update weights 输入 model optimizer epoch，可选 没有return，但是会打印出来training时候的acc 其实就是设置好model和optimizer就可以了 Part4 PyTorch Sequential API nn.Sequential没有上面的灵活，但是可以集成上面的一串功能 需要提前定义一个在forward里面能用的flatten 123456789101112131415161718192021# We need to wrap `flatten` function in a module in order to stack it# in nn.Sequentialclass Flatten(nn.Module): def forward(self, x): return flatten(x)hidden_layer_size = 4000learning_rate = 1e-2model = nn.Sequential( Flatten(), nn.Linear(3 * 32 * 32, hidden_layer_size), nn.ReLU(), nn.Linear(hidden_layer_size, 10),)# you can use Nesterov momentum in optim.SGDoptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)train_part34(model, optimizer) 实现三层，注意需要初始化参数 这里遇到了一个问题是当用random_weight实现的时候，acc会特别低 从这里发现可以重新定义另一个计算方法不同的weights 从这里得知如何给module增加新的function 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657def xavier_normal(shape): """ Create random Tensors for weights; setting requires_grad=True means that we want to compute gradients for these Tensors during the backward pass. We use Xavier normalization: sqrt(2 / (fan_in + fan_out)) """ if len(shape) == 2: # FC weight fan_in = shape[1] fan_out = shape[0] else: fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW] fan_out = shape[0] * shape[2] * shape[3] # randn is standard normal distribution generator. w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / (fan_in + fan_out)) w.requires_grad = True return wchannel_1 = 32channel_2 = 16learning_rate = 1e-2model = Noneoptimizer = None################################################################################# TODO: Rewrite the 2-layer ConvNet with bias from Part III with the ## Sequential API. ################################################################################## *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****model = nn.Sequential( nn.Conv2d(3, channel_1,5,stride = 1,padding = 2), nn.ReLU(), nn.Conv2d(channel_1, channel_2,3,stride = 1,padding = 1), nn.ReLU(), Flatten(), nn.Linear(32*32*channel_2, 10),)def init_weights(m): print(m) if type(m) == nn.Linear: m.weight.data = xavier_normal(m.weight.size()) m.bias.data = zero_weight(m.bias.size())model.apply(init_weights)optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****################################################################################# END OF YOUR CODE ################################################################################train_part34(model, optimizer) Part5 来训练CIFAR-10吧！自己找net的结构，hyper，loss，optimizers来把CIFAR-10的val_acc在10个epoch之内升到70%以上！ Layers in torch.nn package: http://pytorch.org/docs/stable/nn.html Activations: http://pytorch.org/docs/stable/nn.html#non-linear-activations Loss functions: http://pytorch.org/docs/stable/nn.html#loss-functions Optimizers: http://pytorch.org/docs/stable/optim.html 一些可能的方法： Filter size: Above we used 5x5; would smaller filters be more efficient? Number of filters: Above we used 32 filters. Do more or fewer do better? Pooling vs Strided Convolution: Do you use max pooling or just stride convolutions? Batch normalization: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster? Network architecture: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include: [conv-relu-pool]xN -&gt; [affine]xM -&gt; [softmax or SVM] [conv-relu-conv-relu-pool]xN -&gt; [affine]xM -&gt; [softmax or SVM] [batchnorm-relu-conv]xN -&gt; [affine]xM -&gt; [softmax or SVM] Global Average Pooling: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in Google’s Inception Network (See Table 1 for their architecture). Regularization: Add l2 weight regularization, or perhaps use Dropout. 一些tips： 应该会在几百个iter里面就看到进步，如果params work well tune hyper的时候从一大片range和小的train开始，找到好一些的之后再围绕这个范围找（多训一点） 在找hyper的时候应该用val set 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647model = Noneoptimizer = None# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****channel_1 = 16channel_2 = 32channel_3 = 64channel_4 = 64fc_1 = 1024num_classes = 10model = nn.Sequential( nn.Conv2d(3, channel_1,3,stride = 1,padding = 1), nn.BatchNorm2d(channel_1), nn.ReLU(), nn.MaxPool2d(kernel_size = 2), nn.Conv2d(channel_1, channel_2,3,stride = 1,padding = 1), nn.BatchNorm2d(channel_2), nn.ReLU(), nn.MaxPool2d(kernel_size = 2), nn.Conv2d(channel_2, channel_3,3,stride = 1,padding = 1), nn.BatchNorm2d(channel_3), nn.ReLU(), nn.Conv2d(channel_3, channel_4,3,stride = 1,padding = 1), nn.BatchNorm2d(channel_4), nn.ReLU(), nn.MaxPool2d(kernel_size = 2), Flatten(), nn.Linear(4*4*channel_4, num_classes)# nn.Linear(fc_1,num_classes) )learning_rate = 1e-3optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****################################################################################# END OF YOUR CODE ################################################################################# You should get at least 70% accuracytrain_part34(model, optimizer, epochs=10) 第四层conv试过ksize=1，效果不是很好 BN好像效果很好 maxpool多一些，计算负担少而且效果好像比较好 最终val_acc在77-79左右，test_acc = 76.22]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
        <category>CS231n作业</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于python生成动态变量名]]></title>
    <url>%2F2019%2F05%2F07%2F%E5%85%B3%E4%BA%8Epython%E7%94%9F%E6%88%90%E5%8A%A8%E6%80%81%E5%8F%98%E9%87%8F%E5%90%8D%2F</url>
    <content type="text"><![CDATA[动态生成变量名如果想要生成一系列的a0，a1，….a20这种变量名，直接手写太麻烦了 localslocal()，以字典的类型返回当前位置的全部局部变量 1234arrange_list = locals()for i in range(10): arrange_list['list_' + str(i)] = [] 调用动态变量，可以用字典的get方法得到变量的值 1234arrange_list = locals()for i in range(10): print(arrange_list.get('var'+str(i)), end = " ") 利用exec进行赋值12for i in range(5): exec('var&#123;&#125; = &#123;&#125;'.format(i, i)) 调用动态变量12for i in range(5): exec('print(var&#123;&#125;, end = " ")'.format(i))]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>动态生成变量名</tag>
        <tag>变量名</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于多维数组的转置和增加新的维度]]></title>
    <url>%2F2019%2F04%2F25%2F%E5%85%B3%E4%BA%8E%E5%A4%9A%E7%BB%B4%E6%95%B0%E7%BB%84%E7%9A%84%E8%BD%AC%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[在二维转置的时候，a[i][j] = a[j][i]在多维数组转置的时候，需要交换他们的下标比如原来的数组是(X,Y,Z)，转置之后是(Z,X,Y)这时候应该用的是np.transpose(A,(2,0,1)) np.newaxis -&gt; 增加新的维度原来是（6，）的数组，在行上增加维度变成（1,6）的二维数组，在列上增加维度变为(6,1)的二维数组]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>narray</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习OpenCV十八章_Camera models & calibration]]></title>
    <url>%2F2019%2F04%2F22%2FOpenCVCameracalibration%2F</url>
    <content type="text"><![CDATA[camera models &amp; calibration物体会吸收一部分的光，然后反射一部分的光，反射的光就是他自己的颜色，这个光被我们的眼睛（或者相机）接收，然后投影到我们的视网膜（或者相机的图片）上，这之间的几何关系在CV上面非常重要 其中一个非常简单的模型就是pinhole camera model。光穿过一面墙上的一个小的aperture，这个是这章的模型的开始，但是真实pinhole模型不是很好因为他不能快速曝光（聚集的光不够）-&gt; 眼睛会更厉害一点，但是len还会distort图片。 这章的目的： 如何camera calibration 纠正普通的pinhole模型的len的偏差 calibration也同样是获取三维世界的主要方式，因为一个场景不仅仅是三维，他们还有物理的空间和体积，所以获取pixel和三维诗句坐标的关系也很重要 18章纠正的是len的distortion，19章构建整个3D的结构 homography transform -&gt; 一个非常重要的要素 camera model 投影到image plane上面，结果在这个plane上面总是对焦的focus，图片的大小和这个焦距的长度有关 对于理想的pinhole来说，image plane到pinhole的距离就是准确的焦距 从这个基础的模型上 -&gt; 得到一个计算起来更加简单的模型 交换pinhole和projection plane的位置 现在pinhole的位置变成了projective plane的中心 每一个离开物体表面（Q）的光线都朝着projection center走 在横轴和投影面上的交点被定义为principal point 这个新的平面和以前的projective平面一样，上面投影上的物体也都是和原来一样的尺寸 换了模型之后没有了负号：x/f = X/Z 在理想的模型里可能觉得这个principal point就是image的中心，但是实际上中心不会在横轴和投影面的交点上 引入了两个新的参数 cx 和 cy 这两个参数实际上就是中心点的偏差（平面上的偏差），所以得到投影在image plane上面的实际坐标如下 在上面的公式里面用了两个不同的f，fx和fy，这是因为 在实际的图片里来说，其实每个像素格不是正方形而是长方形的 fx = 实际的focal length * sx（每个mm里面的像素数量） -&gt; 最终得到的fx是像素格 注意： sx和sy在calibration的时候并不能直接测量 physical focal length也不能被实际测量 我们只能得到这两个东西的乘积，f basic of projective geometry projective transform -&gt; 把physical world里面的一组点Qi（Xi,Yi,Zi）map到一张图片上面(xi,yi)的过程 用这个东西的时候，一个比较方便的方法是用homogeneous coordinates associ‐ ated with a point in a projective space of dimension n are typically expressed as an (n + 1)-dimensional vector (e.g., x, y, z becomes x, y, z, w), with the additional restric‐ tion that any two points whose values are proportional are, in fact, equivalent points 投影平面上面的维度是两维，我们可以把它表示成三维的东西 -&gt; 把现在存在维度的数字除以增加的维度的值就可以得到以前的值 用这种办法，可以把之前的fx，fy,cx,cy重新组织成一个矩阵：camera intrinsics matrix 下面这个形式重新乘回来就是之前的关系 在opencv里面也有得到homogeneous coordinates和由结果反推回来的函数 注意，在pinhole里面的成像速度是非常慢的，如果需要更快速地形成图片，我们需要通过lens来聚焦非常广范围里面的光 -&gt; 但是结果就是lens会产生distortion Rodrigues Transform 在三维的范围里，经常会使用一个3x3的矩阵来表示一个物体的旋转 只要把需要旋转的vector乘上这个mat就可以得到相应的结果 但是不是很好直观的得到这个旋转矩阵 介绍一种在opencv里面的表示方法 -&gt; 更容易直观的理解意思 本质上来说就是用一个vector表示每个角度上需要旋转多少 Rodrigues Transform指的就是矩阵表示法和向量表示法之间的关系 数学原理：余弦定理？（知道两个向量可以求出来他们之间的角度） 这两个关系之间可以很轻易的互相转化，opencv里面也有相应的库 lens distortion 在实际使用中因为制造球形的镜头更容易一些，并且很难测量是不是平的，所以lens都会产生distortion 在这部分介绍了两种主要得distortion，how to model radial distortion -&gt; 镜片的形状产生的 tangential distortion -&gt; 组装整个相机的时候产生的 radial 相机的distortion一般都会产生在接近imager边缘的部分（fisheye effect） 远离lens中心的部分比起中心部分会折叠更多，所以如果投影一个正方形，边的部分都会鼓起来 如果相机比较便宜的话（web camera），周围的折叠会更多，而好的相机会更注重减少radial distortion的效果 对于辐射的畸变来说，distortion会随着接近边边而增加 在实际中这个畸变很小，所以可以用泰勒级数的r=0附近展开来解决 对于比较便宜的web camera，可以选用k1或者k2 对于鱼眼这种畸变很大的，可以用k3 在distort之后的位置可以用以下的公式表示 (x,y)是原来的位置，corrected是教政治和的位置 r是离开中心的半径 tangential 在制造相机的时候，lens和image plane没有完全平行导致的，所以投影上去会是一个几何变换 这个distortion基本是由两个参数组成：p1和p2 总结下来，在相机的distortion里一共有五个参数，k1k2k3p1p2，这五个函数构成了一个distortion vector(5x1) 虽然在图像里面还有一些其他的畸变，但是因为影响没有这两个大所以opencv没有考虑这部分 calibration 上一部分得到了如何表示相机的参数以及distortion的参数 这部分考虑如何计算这些参数 其中一个函数clibrationCamera() 用相机去照一个已经知道结构的东西，里面有很多已经定义好了的点 通过这个可以得到相机的相对位置和角度，同时也可以得到intrinsic parameters 平移矩阵和旋转矩阵 对于每张照的图片的物体，这个物体的pose可以用一个旋转矩阵+一个平移矩阵描述，也就是用这个矩阵把现实世界中的点转化到投影平面上 旋转矩阵 旋转运动无论在多少维都可以被描述为：一个坐标的vector乘对应大小的方阵 -&gt; 用一个新的坐标系来描述这个点的位置 -&gt; 其实也就是改成了极坐标系？ 三维范围里面的旋转可以用两个角度表示 绕着x，y，z三个方向旋转的角度以及对应的矩阵是这个样子的 这三个方向的R乘在一起就是最后的旋转矩阵R，但是这个的方向是反着的，所以还需要一个transpose转回来 平移矩阵 平移矩阵用来描述怎么从一个坐标系统shift到另一个坐标系统 -&gt; 也就是一个从第一个坐标系原点到第二个坐标系原点的offset 在calibration的时候，就是从物体坐标系的原点到了相机坐标系的原点 平移矩阵： T→ = origin_object − origin_camera. 综合 结合上面两个矩阵来说，从object上面的一个点投影到camera plane上面的一个点的关系为 Pc→ =R⋅(Po→ −T→) 注意分清楚这里面的矩阵和向量 把上面的这个公式，再加上camera自己的intrinsic-correction。整体就是opencv里面需要求的所有部分 所求参数 三维的旋转用三个角度表示，三维的平移用三个parameter表示(x,y,z) -&gt; 现在得到了6个参数 相机的intrinsic mat(fx,fy,cx,cy) -&gt; 一共四个参数 现在一共需要求10个参数（但是相机的intrinsic是不变的） 求参数 -&gt; 在求解的时候，如果使用一个平面物体，那么每张图片都可以得到8个参数（位置的6个会随着图片变化 + 只能用两个参数来求intrinsic） 至少需要2张图片来得到所有的参数 calibration boards 从原则上来说，任何有特征的东西都可以被用来calibration，包括棋盘，圆格，randpattern，arUco等等,有些方法是基于三维的物体的基础上的，但是二维平面的物体更好操作 在这里主要选择的是用棋盘进行calibration 关于chessboard的函数cv::findChessboardCorners() 可以用这个函数找到棋盘的corners， param 需要输入8bit图片 需要输入这个棋盘每行每列应该有的格子数（计算的是内部点） 输出的是这么corner的坐标 可选flag决定需不需要多余的filter cv::cornerSubPix() 上面一步找到的只是corner的大概位置 在find corner里面自动call了这个函数，为了能得到更精确的结果 如果需要得到更精确的结果，可以重复的call这个函数，但是会有tighter termination criteria cv::drawChessboardCorners() 为debug用，更明确的画出来找到的corner 如果没有找到所有的，会把其他可能的用红色circle画出来，如果找到了，每一行的颜色会不一样 下一步转到perspective transform，这个transform会形成一个3x3的homography mat 关于circle grid的函数cv::findCirclesGrid() 和上面的棋盘没有什么本质的区别，主要就是画出来一个是黑白格，另一个是白色的背景上面有黑色的圆点，输出小圆点的位置 这个方法需要圆点是对称的，上下一组算做一行，竖着一列算一列，怎么数非常重要 Homography planar homography是一个平面到另一个平面的projection mapping，所以从一个2D平面到相机平面的过程就是一个planar homography 用矩阵的乘法就可以表示这个过程 其中Q是现实中的点，q是成像器上面的点，整体关系为：q→ = s ⋅ H ⋅ Q→ s，一个随意的scale参数，homography就是由着一个参数决定的 conventionally factored H, H由两个部分组成 physical上面的transformation，实际就是我们看到的这个物体的位置W = [R,t→] projection，取决于相机的intrinsic q→ = s ⋅ M ⋅ W ⋅ Q→，其中M是相机的intrinsic mat 我们希望Q不是给所有空间定义的点，而是一个定义在我们看的平面上面的坐标，这样计算起来会方便（三维转二维） 所以把Q里面的Z的坐标改成了0，这样旋转矩阵就会被简化为一个3x1的列 并且第三个列乘了Z的0之后就被消掉了 最后就可以把H表示出来了 -&gt; 3x3 = intrinsic(3x3) x (rota + trans)(1x3) 在计算homography mat的时候，用了多张同样内容的东西来计算translation和intrinsic 三个旋转，三个平移 -&gt; 每张图片有6个未知的参数 每张图片可以得到8个等式 把一个正方形mapping成一个四边形可以得到4个不同的(x,y) points 所以每多一张图片就可以多出来计算两个新的参数的机会 这样看，pdst→ = H * psrc→，反着也可以推回来，这样我们就算不知道M也可以计算H，或者说我们是用H来计算M 在opencv里面，cv::findHomography()可以用take一堆有关系的点然后返回他们之间的homo mat，点越多计算的越准确 虽然有其他的方法可以计算结果，但是对测量误差不是很友好 three robust fitting methods method to cv::RANSAC 随机的选择提供的点的subset，然后只用这些subset来计算homo mat 然后把剩下的数据拿来计算一下靠谱和不靠谱的 最后保存最有潜力的inliers 在现实中比较好用，可以过滤掉一部分噪音 LMeDS algorithm 减少median error 不需要更多的info和data来运行 但是it will perform well only if the inliers constitute at least a majority of the data points RHO algorithm 加权的第一种方法，运行速度更快 camera calibration棋盘corner个数 到底有多少参数 camera intrinsic 四个 distortion五个（或者更多）三个辐射（可以增加到6个） + 两个平移 这五个参数是从2D -&gt; 2D的 三个corner points可以得到6个信息，足够处理这五个参数 所以一张图就够了（只是原则上这么说） extrinsic parameters，这个东西的实际位置 但是因为intrinsic和extrinsic之间有对应的关系，一张图片并不够 -&gt; 因为在一张图片里还需要计算extrinsic的部分 假设有N个corner，一共有K个images（不同的position） 一共会有 2 N K个，2是x,y的坐标会有两个，然后N个corner，K个图片 暂时忽略distortion的参数，这样需要4个in和6K个ex（因为每张图片的ex都是不一样的） 2NK &gt;= 6K + 4 如果N = 5，只需要一张图片就可以解决。但是为了得到homo mat，至少需要两个K(之前说到过的) 无论检测到多少corner，得到的有用信息就是四个角 -&gt; 由此推测至少两个K 在实际的应用里面，一般需要7x8，至少十张图，这样受到noise的影响更小 具体的数学计算 为了简单，首先假设在calibration的时候根本没有distortion 对于每个view，会得到一个Homo mat，把这个mat拆成一个列向量(3x1) 在前面也知道H可以拆成M和一个[r1,r2,t]的向量相乘，再乘上一个scale s H=[h1,h2,h3] =s⋅M⋅[r1,r2,t],其中landa是1/s: 旋转向量的基底(orthogonal)是互相垂直的，因为已经把scale这个参数提出去了，所以可以直接认为r1和r2是基了，这样的话他们的点乘是0 把r1和r2用M和h来表示，这样的话r1r2等于0就可以转化成一个hM的公式 r1和r2的模也相等，所以可以继续得到一个等式 设置一个矩阵B等于M.-T * M-1，这样可以计算出来B的值(B算出来是对称的) 把B带回原来的等式，化简，然后把K个等式叠加在一起 这样就可以推出来几个参数的表达式 calibration的函数cv::calibrateCamera().来解决calibration的问题 得到的结果包括in mat, dis_co, 旋转向量和平移向量 输出的in mat的大小是3x3 输出的dis_co的大小取决于用多少级的distortion，一般来说是4，5个的已经对fisheye足够了，8个的话calibration的精度就特别高了 如果需要高精度的calibration的话，需要的图片数量也会疯狂增加 输入的部分包括 物体的坐标，指的是在chessboard上面的坐标点，是二维的点，其实也就是第几个格子？ 注意这里，统计的单位是格子，所以如果想要得到physical上的距离，需要在calibration board上量出来一个格子的长度，然后乘这个格子的数量 image上面的坐标，corners 一口气计算所有的参数不是很好实现，一般使用的方法是先固定一部分计算另一部分，然后再固定另一部分计算这一部分。当所有的东西都估计的差不多了，再一起计算 最后还有一个参数是termination criteria，终止的基准 -&gt; epsilon 会根据一个error来计算是否终止 只计算extrinsiccv::slovePnP() 有的时候我们已经得到了相机的intrinsic，只希望得到object的位置 大部分内容和上面都是一样的，除了 物体的位置只需要一个view distCo和intrinsic都是自己设置好的，不需要计算 cv::solvePnPRansac() 上面的函数对于outliers的robust效果不是很好，对于chessboard来说，这个robust不是很重要，因为棋盘自己本身已经很可靠了。但是对于现实世界中的物体来说不是这么可靠 加入了RANSAC部分？ Undistortion 在calibration里面有两个需要解决的事情，一个是distortion，一个是三维表达的正确性 opencv自己有一个可以用的方法 cv::undistor() -&gt; 可以一瞬间完成 cv::initUndistortRectifyMap() + cv::remap() -&gt; 在video上面使用的时候效率更高一些 undistortion map 在把一张图片undistort的时候，我们需要把每个像素都对应到output里面对应的地方去，有几种不同的表达方法 2-channel float 有一个对于NxM的remapping，表示成NxM的array，有两个channel（分别对应X和Y方向的remap），里面是浮点数 对于每一个输入的像素位置(i,j)，有一个对于这两个位置的向量，来表达这两个量应该哪里去 如果计算出来的结果不是一个整数，那么用interpolation来计算最后应该占的格子的数量 第二种表达式是 2-array float，每一个array是一个channel的移动 第三种是fixed point，计算的速度更快一点，但是需要提供的信息的精确度更高 cv::convertMaps() 因为有上面的三种不同的表达形式，所以这个函数用来在各个形式之间转变 cv::initUndistortRectifyMap() 从刚才的部分知道了到底什么是undistortion map，现在开始讨论如何计算这个map 现在先从单目相机开始monocular，如果双目的话可以直接计算depth（下一章） 步骤，分开是因为计算map只需要一次 先计算undistortion map cv::initUndistortRectifyMap() 输入的参数是intrinsic mat和distortion coefficient（从camera calibration得到的） 可以得到一个新的camera mat，这样的话即使不undistortion也可以得到正确的图片（在多个相机的calibration的时候比较重要） 最后会输出两张map 然后在图片上undistort cv::remap() 当计算了上面的map之后，就可以用remap这个函数进行校正了 输入的map的种类也是上面提到的三种都可以 cv::undistort() 如果只有一张图片，或者对于每张图片都需要重新计算map的时候，就需要用这个函数了（所以在项目里面用这个的速度会变慢） sparse undistortion cv::distortionPoints() 如果我没有整张图片，只有一些图片上的点，然后我只关心这些图片上的点，可以用这个函数计算这张图片上面关注点的位置]]></content>
      <categories>
        <category>图像处理</category>
        <category>OpenCV</category>
        <category>Calibration</category>
      </categories>
      <tags>
        <tag>camera</tag>
        <tag>calibration</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nassignment2CNN]]></title>
    <url>%2F2019%2F04%2F18%2FCS231nassignment2CNN%2F</url>
    <content type="text"><![CDATA[target 之前已经实践了fc的相关东西，但是在实际的使用里大家使用的都是CNN 所以这部分就开始实践CNN了 convolution: Native forward pass CNN的核心部分就是卷积 in cs231n/layers.py，conv_forward_naive 首先这时候不用考虑效率问题，最轻松的写就可以了 输入的数据是N个data，每个有C个channel，H的高度和W的宽度 每个输入和F个不同的filter做卷积，每个卷积核对所有的channel作用，卷积核的大小是HHxWW input x, (N,C,H,W) w, fliter weights of shape (F,C,HH,WW) b, bias, (F,) conv_param: dict “stride” 步长 “pad” zero-padding的大小 注意在padding的时候不要调整x，而是得到一个padding之后的新的东西 output out, (N,F,H’,W’) H’ = 1 + (H + 2 * pad - HH) / stride W’ = 1 + (W + 2 * pad - WW) / stride cache: (x,w,b,conv_param) implement 首先需要对输入的图片进行padding np.pad 输入的array pad的宽度，如果默认的话就是前后都加，然后是这个数字的宽度 -&gt; 注意这里的时候因为一共有四个维度，前两个维度是不用pad的 mode = ‘constant’ constant_values，表示的是pad进去的值，可以前后pad的不一样，因为这里是0-padding所以这里是0 要对所有图片进行处理，需要在N个图片里选择一个 在filter的所有里面选择一个 考虑在H方向和W方向的移动步数，然后通过这个步数和步长的乘积在原图里面取需要做卷积的部分 注意这里可以不用考虑channel，因为图片和filter的channel是同样的层数，所以直接可以boardcast 然后这个部分和卷积核相乘（直接乘），求和，加上bias，就是这个像素点上应该的数值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162def conv_forward_naive(x, w, b, conv_param): """ A naive implementation of the forward pass for a convolutional layer. The input consists of N data points, each with C channels, height H and width W. We convolve each input with F different filters, where each filter spans all C channels and has height HH and width WW. Input: - x: Input data of shape (N, C, H, W) - w: Filter weights of shape (F, C, HH, WW) - b: Biases, of shape (F,) - conv_param: A dictionary with the following keys: - 'stride': The number of pixels between adjacent receptive fields in the horizontal and vertical directions. - 'pad': The number of pixels that will be used to zero-pad the input. During padding, 'pad' zeros should be placed symmetrically (i.e equally on both sides) along the height and width axes of the input. Be careful not to modfiy the original input x directly. Returns a tuple of: - out: Output data, of shape (N, F, H', W') where H' and W' are given by H' = 1 + (H + 2 * pad - HH) / stride W' = 1 + (W + 2 * pad - WW) / stride - cache: (x, w, b, conv_param) """ out = None ########################################################################### # TODO: Implement the convolutional forward pass. # # Hint: you can use the function np.pad for padding. # ########################################################################### stride = conv_param['stride'] pad = conv_param['pad'] N, C, H, W = x.shape F, _, HH, WW = w.shape H_out = 1 + (H + 2 * pad - HH) // stride W_out = 1 + (W + 2 * pad - WW) // stride out = np.zeros((N, F, H_out, W_out)) x_pad = np.pad(x, ((0,), (0,), (pad,), (pad,)), 'constant', constant_values=0) # 对原图片的每层进行卷积 for pics in range(N): image = x_pad[pics] for filters in range(F): for H_move in range(H_out): for W_move in range(W_out): image_conv = image[:, stride * H_move: stride * H_move + HH, stride * W_move: stride * W_move + WW] filter_conv = w[filters, :] out_pixel = np.sum(image_conv * filter_conv) + b[filters] out[pics, filters, H_move, W_move] = out_pixel ########################################################################### # END OF YOUR CODE # ########################################################################### cache = (x, w, b, conv_param) return out, cache 可视化中间的图像过程 这里输入了两个不同的输入图片 分别可视化了这个图片的不同weights Convolution: Naive backward pass愉快的简单计算back的过程，先不用考虑cost input dout cache（x,w,b,conv_param) -&gt; 参数是padding 和 stride output dx dw db 实现：conv是怎么求导的？其实排除位置的改变之外，forward只进行了三个操作 把x padding为x_pad wx_pad_conv + b -&gt; 求出一个大小和filter相同的矩阵 把求出来的一个(HH,WW)的矩阵的所有值求sum backward的思路 首先，每一张图片的每一个channel的，dout的大小和输出图片的大小一样 应该是H_out = 1 + (H + 2 * pad - HH) // stride这样求出来的结果 整个dout的size是(N,F,Hout,Wout)，其中N是之前图片的数量，F是新形成的图片的channel 所以在for循环中，dout中选中[n,f,hout,wout]，就可以得到这个特点定的值，称为df df的得到方法是wx+b得到一个矩阵，然后再对这个矩阵求和 因为求和实际就是累加，求导数的时候只要把每一个格子的dx，dw，db导数求出来，然后加在一起就行了 因为公式就是wx + b，所以dx是w，dw是x，db是常数 -&gt; 然后再把每个格子求出来的加在一起，注意各个矩阵的大小，dx应该是在x矩阵里取做卷积的部分，这部分的导数等于w乘df的和 最后，因为x被padding了，dx应该去dx_pad中没有被padding的部分，也就是从[pad:pad + H] 代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051def conv_backward_naive(dout, cache): """ A naive implementation of the backward pass for a convolutional layer. Inputs: - dout: Upstream derivatives. - cache: A tuple of (x, w, b, conv_param) as in conv_forward_naive Returns a tuple of: - dx: Gradient with respect to x - dw: Gradient with respect to w - db: Gradient with respect to b """ dx, dw, db = None, None, None ########################################################################### # TODO: Implement the convolutional backward pass. # ########################################################################### x, w, b, conv_param = cache N, C, H, W = x.shape F, _, HH, WW = w.shape _, _, H_dout, W_dout = dout.shape stride = conv_param['stride'] pad = conv_param['pad'] x_pad = np.pad(x, ((0,), (0,), (pad,), (pad,)), 'constant', constant_values=0) db = np.zeros_like(b) dw = np.zeros_like(w) dx_pad = np.zeros_like(x_pad) # print(dx_pad.shape) for pics in range(N): for filters in range(F): for H_move in range(H_dout): for W_move in range(W_dout): # f=sum(wx_pad + b) (df is a number now) df = dout[pics, filters, H_move, W_move] # d for sum, size (HH,WW) # dsum = df * np.ones((HH, WW)) db[filters] += df dx_pad[pics, :, H_move * stride: H_move * stride + HH, W_move * stride: W_move * stride + WW] += df * w[filters] dw[filters] += x_pad[pics, :, stride * H_move: stride * H_move + HH, stride * W_move: stride * W_move + WW] * df dx = dx_pad[:, :, pad:pad + H, pad:pad + W] ########################################################################### # END OF YOUR CODE # ########################################################################### return dx, dw, db Max-Pooling：Native forwardinput x, (N,C,H,W) pool_param -&gt; dict ‘pool_height’ ‘pool_width’ ‘stride’ 不需要进行padding output out, (N,C,H’,W’) H’ = 1 + (H - pool_height) / stride W’ = 1 + (W - pool_width) / stride cache(x,pool_param) 实现 直接找到相应的块然后求max 注意求max的时候要注意axis,我们需要求得是在一张图片每个channel上面的最大值，在这个式子里面因为已经确定了pics的值，实际上的out其实是一个三维的数组，所以应该求axis = (1,2)上面的最大值，而不是求(2,3上面的) 代码12345678910111213141516171819202122232425262728293031323334353637383940def max_pool_forward_naive(x, pool_param): """ A naive implementation of the forward pass for a max-pooling layer. Inputs: - x: Input data, of shape (N, C, H, W) - pool_param: dictionary with the following keys: - 'pool_height': The height of each pooling region - 'pool_width': The width of each pooling region - 'stride': The distance between adjacent pooling regions No padding is necessary here. Output size is given by Returns a tuple of: - out: Output data, of shape (N, C, H', W') where H' and W' are given by H' = 1 + (H - pool_height) / stride W' = 1 + (W - pool_width) / stride - cache: (x, pool_param) """ out = None ########################################################################### # TODO: Implement the max-pooling forward pass # ########################################################################### N, C, H, W = x.shape pool_height, pool_width, stride = pool_param['pool_height'], pool_param['pool_width'], pool_param['stride'] H_out = 1 + (H - pool_height) // stride W_out = 1 + (W - pool_width) // stride out = np.zeros((N,C,H_out,W_out)) for pics in range(N): for h_out in range(H_out): for w_out in range(W_out): out[pics,:,h_out,w_out] = np.max(x[pics,:,stride * h_out: stride* h_out + pool_height,stride* w_out: stride*w_out + pool_width],axis = (1,2)) ########################################################################### # END OF YOUR CODE # ########################################################################### cache = (x, pool_param) return out, cache Max-pooling: Native backwardinput dout, size = (N,C,W_out,W_out) cache output dx, size = (N,C,W,H) 实现 max的值在实际上是一个router，local gradient对于最大的值的地方是1，其他值的地方影响是0 需要找到x里面值等于最大值的坐标，然后把这个坐标的dx改成对应dout的值（因为链式法则应该dout * 1），其他地方的dx都是0 关于找到这个点的坐标 我用了显得很傻的方法，在x的范围里面找到这个范围里最大的坐标，用了很多圈循环 实际上可以从max的值找到原来的坐标 numpy.unravel_index(indices, dims) 结合np.argmax，返回最大值的坐标 -&gt; ind = np.unravel_index(np.argmax(a, axis=None), a.shape) 这样的话找到的是在每个max的框框里最大值的坐标，在这个框框的范围里找到这个坐标就是需要改变的地方 1234567891011121314151617181920212223242526272829303132333435363738def max_pool_backward_naive(dout, cache): """ A naive implementation of the backward pass for a max-pooling layer. Inputs: - dout: Upstream derivatives - cache: A tuple of (x, pool_param) as in the forward pass. Returns: - dx: Gradient with respect to x """ dx = None ########################################################################### # TODO: Implement the max-pooling backward pass # ########################################################################### x, pool_param = cache N, C, H, W = x.shape pool_height, pool_width, stride = pool_param['pool_height'], pool_param['pool_width'], pool_param['stride'] _,_,H_out,W_out = dout.shape dx = np.zeros_like(x) for pics in range(N): for channels in range(C): for h_out in range(H_out): for w_out in range(W_out): # for H in range(stride * h_out, stride* h_out + pool_height): # for W in range(stride * w_out, stride * w_out + pool_width): # if x[pics,channels,H,W] == np.max(x[pics,channels,stride * h_out: stride* h_out + pool_height,stride* w_out: stride*w_out + pool_width]): # dx[pics,channels,H,W] = dout[pics,channels,h_out,w_out] ind = np.unravel_index(np.argmax(x[pics,channels,stride * h_out: stride* h_out + pool_height,stride* w_out: stride*w_out + pool_width]), (pool_height,pool_width)) dx[pics,channels,stride * h_out: stride* h_out + pool_height,stride* w_out: stride*w_out + pool_width][ind] = dout[pics,channels,h_out,w_out] # print(ind) ########################################################################### # END OF YOUR CODE # ########################################################################### return dx Fast layers 在cs231n/fast_layers.py里面直接提供了比较快版本的计算方法 The fast convolution implementation depends on a Cython extension; to compile it you need to run the following from the cs231n directory: 1python setup.py build_ext --inplace 记得重启一下jupter 12345678910111213141516171819202122232425Testing conv_forward_fast:Naive: 5.283360sFast: 0.014807sSpeedup: 356.809600xDifference: 4.926407851494105e-11Testing conv_backward_fast:Naive: 9.893734sFast: 0.015421sSpeedup: 641.578958xdx difference: 1.949764775345631e-11dw difference: 5.155328198575201e-13db difference: 3.481354613192702e-14Testing pool_forward_fast:Naive: 0.212025sfast: 0.002980sspeedup: 71.143680xdifference: 0.0Testing pool_backward_fast:Naive: 0.391351sfast: 0.012568sspeedup: 31.138711xdx difference: 0.0 可以发现fast版本conv的速度会快300倍，而pooling也会快几十倍 conv sandwich layer -&gt; 已经写好了，conv + relu + poolThree-layer ConvNetcs231n/classifiers/cnn.py,implement一个三层的CNN结构 conv - relu - 2x2 maxpool - affine1 - relu - affine2 - softmax 输入图片的minibatch为(N,C,H,W) init input_dim: (C,H,W)是每张图片长什么样子 num_filters: conv层里面filter的个数 filters_size，直接把高和宽统一成一个数字了，反正都是方形的 hidden_dim：用fc层的数量 num_classes: 最后输出的class的数量 weight_scale：初始化的时候的scale reg：L2 dtype：计算所用的datatype（如 np.float32) loss + gradient 需要初始化三层的参数，W123和b123 初始化weights（正态分布）和bias（全是0） -&gt; 注意fc和conv层的不一样 因为在loss中有帮助input的大小保持的操作，所以第二层的图片可以不考虑padding和stride的变化 W1的大小是filter的大小(F,C,HH,WW)，需要filter的数量，channel的数量，以及每个filter的大小，b1是(filter,) conv_relu之后进行了一次max pool，所以图片的大小缩小了一半 后面两个affine的大小就跟输入，hidden_num和最后的num_classes有关系了，b的大小跟输出走 注意第二个affine之后不需要relu loss用之前写好的softmax 注意需要regularization 直接用之前写好的把gradient back回去就可以了 Sanity check loss¶在建立一个新的net的时候，第一件事就应该是这个 用softmax的时候，我们希望random weight，没有reg的结果是log(C) 如果加上了reg，这个数量会轻微增加一点 overfit small data 直接用非常少的数据来训练一个新的网络，应该能在这个上面overfit 应该会产生一个非常高的训练精度和非常低的val精度 注意在loss里面的时候需要记录下来scores，我就是因为变量名写错了所以一直bug 最后训练出来的train_acc接近100%，而val_acc只有百分之20 1234567891011121314151617181920np.random.seed(231)num_train = 100small_data = &#123; 'X_train': data['X_train'][:num_train], 'y_train': data['y_train'][:num_train], 'X_val': data['X_val'], 'y_val': data['y_val'],&#125;model = ThreeLayerConvNet(weight_scale=1e-2)solver = Solver(model, small_data, num_epochs=15, batch_size=50, update_rule='adam', optim_config=&#123; 'learning_rate': 1e-3, &#125;, verbose=True, print_every=1)solver.train() 训练这个三层的网络 直接用所有数据训练这个网络，应该得到的train_acc应该在40% 最后训练了1个epoch，980次iter1(Epoch 1 / 1) train acc: 0.496000; val_acc: 0.489000 可视化第一层的filter Spatial Batch Normalization 在之前我们已经看到BN对于训练NN很有用了，根据15年的一个论文，CNN里面也可以用BN -&gt; SBN 普通的BN会接收(N,D)大小的input，并且output是同样的大小，normal的时候用data的总数N CNN里面，input为(N,C,H,W)，output大小相同（也就是和X同样尺寸） 如果用卷积得到的特征map，we expect the statistics of each feature channel to be relatively consistent both between different imagesand different locations within the same image -&gt; 所以在SBN里面，计算对每个C里面的特征计算mean和var Spatial batch normalization: forwardcs231n/layers.pyinput: x,(N,C,H,W) gamma,scale parameter (C,) beta,shift param (C,) bn_param: dict mode: train/test eps momentum running_mean running_varoutput out,(N,C,H,W) cache, back的时候需要的东西 注意，可以调用之前写的关于 batchnorm_forward 的内容，代码应该少于五行 这里需要用到多维数组的转置，需要把矩阵变成（N H W） * C的格式，然后在求完bn之后再转回去 之前fc里面使用的时候的大小是(N,D)，这样的话是在所有的N上面取平均 这里的C代替了以前的D，NHW代替了以前的N(把每张特征图看做一个特征处理（一个神经元），这里的特征图指的是一层的东西) 这里用到的是一张特征图里面的所有神经元的参数共享 Spatial batch normalization: backward 输入dout(N,C,H,W)和cache，输出dx，dgamma和dbeta 同样也是直接调用之前的，变形方法和之前一样 Group Normalization 同样原理，把维度变化之后使用 np.newaxis()]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
        <category>CS231n作业</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nassignment2之Dropout]]></title>
    <url>%2F2019%2F04%2F18%2FCS231nassignment2Dropout%2F</url>
    <content type="text"><![CDATA[Target regularization NN randomly setting some features to 0 during forward pass Geoffrey E. Hinton et al, “Improving neural networks by preventing co-adaptation of feature detectors”, arXiv 2012 Dropout forward + backwardin cs231n/layers.py IO input x,input data, of any shape dropout_params p，每个neuron是不是保留的可能性是p mode：’train’的时候会进行dropout，‘test’的时候会直接return input seed：用来generate random number for dropout output out, 和x同样大小 cache, tuple(dropout_params, mask). In training, mask is used to multiply the input 在实现中不推荐用vanilla的方法 123456NOTE: Please implement **inverted** dropout, not the vanilla version of dropout.See http://cs231n.github.io/neural-networks-2/#reg for more details.NOTE 2: Keep in mind that p is the probability of **keep** a neuronoutput; this might be contrary to some sources, where it is referred toas the probability of dropping a neuron output. 实现 在训练的时候在hidd层都drop了一部分，如果愿意的话也可以在input层就drop 在predict的时候不再drop了！但是需要根据drop的比例对output的数量进行scale -&gt; 所以这样就会变得很麻烦（vanilla的方法） 比如比例是p，drop之后剩下了px 那在test的时候x的大小也应该变成px(x -&gt; px) inverted dropout，在训练的时候就对大小进行放缩，在test的时候不接触forward pass 12H1 = np.maximum(0, np.dot(W1, X) + b1)U1 = (np.random.rand(*H1.shape) &lt; p) / p # /p!!! back的实现更容易了，如果这个点被drop了的话对再往前的dx就没有影响，如果这个点没有被drop的话对之前的影响就是常数 code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081def dropout_forward(x, dropout_param): """ Performs the forward pass for (inverted) dropout. Inputs: - x: Input data, of any shape - dropout_param: A dictionary with the following keys: - p: Dropout parameter. We keep each neuron output with probability p. - mode: 'test' or 'train'. If the mode is train, then perform dropout; if the mode is test, then just return the input. - seed: Seed for the random number generator. Passing seed makes this function deterministic, which is needed for gradient checking but not in real networks. Outputs: - out: Array of the same shape as x. - cache: tuple (dropout_param, mask). In training mode, mask is the dropout mask that was used to multiply the input; in test mode, mask is None. NOTE: Please implement **inverted** dropout, not the vanilla version of dropout. See http://cs231n.github.io/neural-networks-2/#reg for more details. NOTE 2: Keep in mind that p is the probability of **keep** a neuron output; this might be contrary to some sources, where it is referred to as the probability of dropping a neuron output. """ p, mode = dropout_param['p'], dropout_param['mode'] if 'seed' in dropout_param: np.random.seed(dropout_param['seed']) mask = None out = None if mode == 'train': ####################################################################### # TODO: Implement training phase forward pass for inverted dropout. # # Store the dropout mask in the mask variable. # ####################################################################### mask = (np.random.randn(*x.shape) &lt; p) / p out = x * mask ####################################################################### # END OF YOUR CODE # ####################################################################### elif mode == 'test': ####################################################################### # TODO: Implement the test phase forward pass for inverted dropout. # ####################################################################### out = x ####################################################################### # END OF YOUR CODE # ####################################################################### cache = (dropout_param, mask) out = out.astype(x.dtype, copy=False) return out, cachedef dropout_backward(dout, cache): """ Perform the backward pass for (inverted) dropout. Inputs: - dout: Upstream derivatives, of any shape - cache: (dropout_param, mask) from dropout_forward. """ dropout_param, mask = cache mode = dropout_param['mode'] dx = None if mode == 'train': ####################################################################### # TODO: Implement training phase backward pass for inverted dropout # ####################################################################### dx = dout * mask ####################################################################### # END OF YOUR CODE # ####################################################################### elif mode == 'test': dx = dout return dx FC with DP 应该在每层的relu之后，增加dropout的部分 在之前定义的function里面加上新的dropout部分，因为倔强的想加在定义好的函数里面，所以产生了一些奇怪的延伸问题 如果想要可选参数，在def function里面直接定义好就行了 如果返回值不需要，直接在返回的时候_就好了 注意在fc_net里面如果dropout = 1 的话，实际上的flag是没有意义的 1234567891011121314151617181920212223242526272829303132333435363738def affine_Normal_relu_dropout_forward(self, x, w, b, mode, gamma=None, beta=None, bn_params=None): Normal_cache = None dp_cache = None a, fc_cache = affine_forward(x, w, b) if mode == "batchnorm": mid, Normal_cache = batchnorm_forward(a, gamma, beta, bn_params) elif mode == "layernorm": mid, Normal_cache = layernorm_forward(a, gamma, beta, bn_params) else: mid = a dp, relu_cache = relu_forward(mid) if self.use_dropout: out, dp_cache = dropout_forward(dp, self.dropout_param) else: out = dp cache = (fc_cache, Normal_cache, relu_cache, dp_cache) return out, cachedef affine_Normal_relu_dropout_backward(self, dout, cache, mode): fc_cache, Normal_cache, relu_cache, dp_cache = cache dgamma = 0.0 dbeta = 0.0 if self.use_dropout: ddp = dropout_backward(dout, dp_cache) else: ddp = dout da = relu_backward(ddp, relu_cache) if mode == "batchnorm": dmid, dgamma, dbeta = batchnorm_backward_alt(da, Normal_cache) elif mode == "layernorm": dmid, dgamma, dbeta = layernorm_backward(da, Normal_cache) else: dmid = da dx, dw, db = affine_backward(dmid, fc_cache) return dx, dw, db, dgamma, dbeta regularization experiment 训练一个2层的网络，500个training，一个没有dropout，另一个0.25的dp 并且可视化了最终的结果 从结果上来看感觉，如果epoch比较少的话，dropout的效果会更好 加上dropout，normalization，的fc网络全部代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260class FullyConnectedNet(object): """ A fully-connected neural network with an arbitrary number of hidden layers, ReLU nonlinearities, and a softmax loss function. This will also implement dropout and batch/layer normalization as options. For a network with L layers, the architecture will be &#123;affine - [batch/layer norm] - relu - [dropout]&#125; x (L - 1) - affine - softmax where batch/layer normalization and dropout are optional, and the &#123;...&#125; block is repeated L - 1 times. Similar to the TwoLayerNet above, learnable parameters are stored in the self.params dictionary and will be learned using the Solver class. """ def __init__(self, hidden_dims, input_dim=3 * 32 * 32, num_classes=10, dropout=1, normalization=None, reg=0.0, weight_scale=1e-2, dtype=np.float32, seed=None): """ Initialize a new FullyConnectedNet. Inputs: - hidden_dims: A list of integers giving the size of each hidden layer. - input_dim: An integer giving the size of the input. - num_classes: An integer giving the number of classes to classify. - dropout: Scalar between 0 and 1 giving dropout strength. If dropout=1 then the network should not use dropout at all. - normalization: What type of normalization the network should use. Valid values are "batchnorm", "layernorm", or None for no normalization (the default). - reg: Scalar giving L2 regularization strength. - weight_scale: Scalar giving the standard deviation for random initialization of the weights. - dtype: A numpy datatype object; all computations will be performed using this datatype. float32 is faster but less accurate, so you should use float64 for numeric gradient checking. - seed: If not None, then pass this random seed to the dropout layers. This will make the dropout layers deteriminstic so we can gradient check the model. """ self.normalization = normalization self.use_dropout = dropout != 1 self.reg = reg self.num_layers = 1 + len(hidden_dims) self.dtype = dtype self.params = &#123;&#125; ############################################################################ # TODO: Initialize the parameters of the network, storing all values in # # the self.params dictionary. Store weights and biases for the first layer # # in W1 and b1; for the second layer use W2 and b2, etc. Weights should be # # initialized from a normal distribution centered at 0 with standard # # deviation equal to weight_scale. Biases should be initialized to zero. # # # # When using batch normalization, store scale and shift parameters for the # # first layer in gamma1 and beta1; for the second layer use gamma2 and # # beta2, etc. Scale parameters should be initialized to ones and shift # # parameters should be initialized to zeros. # ############################################################################ pr_num = input_dim # can't use enumerate beacuse I need the number more than the size of hidden_dims for layer in range(self.num_layers): layer += 1 weights = 'W' + str(layer) bias = 'b' + str(layer) # 这时候是最后一层(the last layer) if layer == self.num_layers: self.params[weights] = np.random.randn( hidden_dims[len(hidden_dims) - 1], num_classes) * weight_scale self.params[bias] = np.zeros(num_classes) # other layers else: hidd_num = hidden_dims[layer - 1] self.params[weights] = np.random.randn( pr_num, hidd_num) * weight_scale self.params[bias] = np.zeros(hidd_num) pr_num = hidd_num if self.normalization in ["batchnorm", "layernorm"]: self.params['gamma' + str(layer)] = np.ones(hidd_num) self.params['beta' + str(layer)] = np.zeros(hidd_num) # print(len(self.params)) # print(self.params) ############################################################################ # END OF YOUR CODE # ############################################################################ # When using dropout we need to pass a dropout_param dictionary to each # dropout layer so that the layer knows the dropout probability and the mode # (train / test). You can pass the same dropout_param to each dropout layer. self.dropout_param = &#123;&#125; if self.use_dropout: self.dropout_param = &#123;'mode': 'train', 'p': dropout&#125; if seed is not None: self.dropout_param['seed'] = seed # With batch normalization we need to keep track of running means and # variances, so we need to pass a special bn_param object to each batch # normalization layer. You should pass self.bn_params[0] to the forward pass # of the first batch normalization layer, self.bn_params[1] to the forward # pass of the second batch normalization layer, etc. self.bn_params = [] if self.normalization == 'batchnorm': self.bn_params = [&#123;'mode': 'train'&#125; for i in range(self.num_layers - 1)] if self.normalization in ["batchnorm", "layernorm"]: self.bn_params = [&#123;&#125; for i in range(self.num_layers - 1)] # Cast all parameters to the correct datatype for k, v in self.params.items(): self.params[k] = v.astype(dtype) def loss(self, X, y=None): """ Compute loss and gradient for the fully-connected net. Input / output: Same as TwoLayerNet above. """ X = X.astype(self.dtype) mode = 'test' if y is None else 'train' # Set train/test mode for batchnorm params and dropout param since they # behave differently during training and testing. if self.use_dropout: self.dropout_param['mode'] = mode if self.normalization == 'batchnorm': for bn_param in self.bn_params: bn_param['mode'] = mode scores = None ############################################################################ # TODO: Implement the forward pass for the fully-connected net, computing # # the class scores for X and storing them in the scores variable. # # # # When using dropout, you'll need to pass self.dropout_param to each # # dropout forward pass. # # # # When using batch normalization, you'll need to pass self.bn_params[0] to # # the forward pass for the first batch normalization layer, pass # # self.bn_params[1] to the forward pass for the second batch normalization # # layer, etc. # ############################################################################ cache = &#123;&#125; temp_out = X for i in range(self.num_layers): w = self.params['W' + str(i + 1)] b = self.params['b' + str(i + 1)] if i == self.num_layers - 1: scores, cache['cache' + str(i + 1)] = affine_forward(temp_out, w, b) else: if self.normalization in ["batchnorm", "layernorm"]: gamma = self.params['gamma' + str(i + 1)] beta = self.params['beta' + str(i + 1)] temp_out, cache['cache' + str(i + 1)] = self.affine_Normal_relu_dropout_forward( temp_out, w, b, self.normalization, gamma, beta, self.bn_params[i]) else: # temp_out, cache['cache' + # str(i + 1)] = affine_relu_forward(temp_out, w, b) temp_out, cache['cache' + str(i + 1)] = self.affine_Normal_relu_dropout_forward( temp_out, w, b, mode=self.normalization) ############################################################################ # END OF YOUR CODE # ############################################################################ # If test mode return early if mode == 'test': return scores loss, grads = 0.0, &#123;&#125; ############################################################################ # TODO: Implement the backward pass for the fully-connected net. Store the # # loss in the loss variable and gradients in the grads dictionary. Compute # # data loss using softmax, and make sure that grads[k] holds the gradients # # for self.params[k]. Don't forget to add L2 regularization! # # # # When using batch/layer normalization, you don't need to regularize the scale# # and shift parameters. # # # # NOTE: To ensure that your implementation matches ours and you pass the # # automated tests, make sure that your L2 regularization includes a factor # # of 0.5 to simplify the expression for the gradient. # ############################################################################ loss, dscores = softmax_loss(scores, y) reg_loss = 0.0 pre_dx = dscores # dgamma = self.params['gamma'] for i in reversed(range(self.num_layers)): i = i + 1 reg_loss = np.sum(np.square(self.params['W' + str(i)])) loss += reg_loss * 0.5 * self.reg # 最后一层 if i == self.num_layers: pre_dx, dw, db = affine_backward( pre_dx, cache['cache' + str(i)]) else: if self.normalization in ["batchnorm", "layernorm"]: pre_dx, dw, db, dgamma, dbeta = self.affine_Normal_relu_dropout_backward( pre_dx, cache['cache' + str(i)], self.normalization) grads['gamma' + str(i)] = dgamma grads['beta' + str(i)] = dbeta else: pre_dx, dw, db, _, _ = self.affine_Normal_relu_dropout_backward( pre_dx, cache['cache' + str(i)], self.normalization) dw += self.reg * self.params['W' + str(i)] db += self.reg * self.params['b' + str(i)] grads['W' + str(i)] = dw grads['b' + str(i)] = db ############################################################################ # END OF YOUR CODE # ############################################################################ return loss, grads def affine_Normal_relu_dropout_forward(self, x, w, b, mode, gamma=None, beta=None, bn_params=None): Normal_cache = None dp_cache = None a, fc_cache = affine_forward(x, w, b) if mode == "batchnorm": mid, Normal_cache = batchnorm_forward(a, gamma, beta, bn_params) elif mode == "layernorm": mid, Normal_cache = layernorm_forward(a, gamma, beta, bn_params) else: mid = a dp, relu_cache = relu_forward(mid) if self.use_dropout: out, dp_cache = dropout_forward(dp, self.dropout_param) else: out = dp cache = (fc_cache, Normal_cache, relu_cache, dp_cache) return out, cache def affine_Normal_relu_dropout_backward(self, dout, cache, mode): fc_cache, Normal_cache, relu_cache, dp_cache = cache dgamma = 0.0 dbeta = 0.0 if self.use_dropout: ddp = dropout_backward(dout, dp_cache) else: ddp = dout da = relu_backward(ddp, relu_cache) if mode == "batchnorm": dmid, dgamma, dbeta = batchnorm_backward_alt(da, Normal_cache) elif mode == "layernorm": dmid, dgamma, dbeta = layernorm_backward(da, Normal_cache) else: dmid = da dx, dw, db = affine_backward(dmid, fc_cache) return dx, dw, db, dgamma, dbeta]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
        <category>CS231n作业</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>Drop out</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL笔记]]></title>
    <url>%2F2019%2F04%2F16%2FOpenGL%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Learn OpenGl on Modern OpenGL. -&gt; 从graphics的programming开始讲的 Getting StartOPENGL 是一个进行图像处理的工具 可以被认为是API，但是实际上是specification 明确说明了每个function应该的输入和输出，以及如何perform 用户在用这个说明来解决问题，因为没有给出明确的implement的过程，所以只要结果符合规则，怎么implement都可以 Core-profile vs Immediate mode 以前的版本用的是immediate mode 比较好用来画图 具体的是实现都在lib里面，developer不是很好的能看到如何计算 效率越来越低 Core-profile 在3.2版本之后改成了这个 强制使用modern practices，如果想要用被分出去的function就会直接报错 效率高，更灵活，更难学 extensions 支持extensions，只要检查支不支持graphic card就可以知道能不能用 可以直接用比较新的东西，不用等着OPENGL更新新的功能 需要在用之前判断他是不是available的，如果不是需要用原来的方法搞 State Machine OpenGL自己就是一个State Machine：一个var的集合，来判断他现在应该如何操作 state -&gt; context 改变state：设定一些options，操作一些buffer，在现在的context来render 例子： 如果我想画三角形，而不是画线了，就改变draw的state 只要这个改变传达到了，下一条线就画的是三角形了 state-changing用来改变context，state-using在现在的state上面开始进行操作 Objects 一个集合来表现OpenGL的subset的state 比如可以用一个object来表示对window的设定，可以设置大小，设置支持的颜色等等123456// The State of OpenGLstruct OpenGL_Context &#123; ... object_name* object_Window_Target; ... &#125;; 12345678910// create objectunsigned int objectId = 0;glGenObject(1, &amp;objectId);// bind object to contextglBindObject(GL_WINDOW_TARGET, objectId);// set options of object currently bound to GL_WINDOW_TARGETglSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_WIDTH, 800);glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_HEIGHT, 600);// set context target back to defaultglBindObject(GL_WINDOW_TARGET, 0); 流程 首先创建了一个object，里面存了一个ref是这个object的id 然后把这个object和context的目标位置bind在了一起 设置了这些window的参数 最后un-bind这两个东西，把window target改回原来的值 这样的话我们可以创建很多object，提前设置好里面的量，等到需要用的时候就直接bind就可以用了 比如我们有一堆object包含了小人，小马，小鹿 想画哪个就把哪个绑定到draw里面，就可以直接画出来了 Crateing a window因为操作系统的问题，所有操作系统上面不是很一样。但是已经有一些提供这些功能的函数了，这里用的是GLFW GLFW 一个lib，用C写的，主要目的是提供把东西渲染到屏幕的功能 可以创建一个context，定义窗口的params，处理用户的输入 已经一口气配置好了这些！https://www.jianshu.com/p/25d5fbf792a2记得在link lib里面把openGL的framework加进去！！！！！ GLAD 因为openGL还需要不同版本的driver的支持，需要有东西来处理这部分的内容 和其他的东西不同，GLAD用的是web service 在这个网页上选择好语言，版本号，确保profile是core，然后生成 直接下载下来对应的zip，然后把include放进include里面，.c文件放在project里面 莫名其妙并不需要这一步，神奇，可能是我在include里面已经搞进来了！！ Hello Window初始化12345678910int main()&#123; glfwInit(); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); //glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); return 0;&#125; 首先进行了初始化 然后configure了GLFW，设置了a large enum of possible options prefixed with GLFW_. （第三行就是最小） -&gt; 大概是设置要用GLFW的版本号 然后也告诉了他想用core 然后需要使用glfwCreateWindow这个函数，来创建这个GLFWwindow* window的变量 创建的函数需要窗口的长宽 窗口名 创建完之后就可以把这个窗口设置成glfwMakeContextCurrent(window);也就是说设置成了现在的thread里面12345678GLFWwindow* window = glfwCreateWindow(800, 600, "LearnOpenGL", NULL, NULL);if (window == NULL)&#123; std::cout &lt;&lt; "Failed to create GLFW window" &lt;&lt; std::endl; glfwTerminate(); return -1;&#125;glfwMakeContextCurrent(window); GLAD GLAD是为OpenGL来管理这些函数的，在使用这些函数之前需要初始化GLAD12345if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress))&#123; std::cout &lt;&lt; "Failed to initialize GLAD" &lt;&lt; std::endl; return -1;&#125; viewpoint 在开始render之前我们还需要告诉GL渲染窗口的大小，用到了glViewport这个函数 前面两个参数定义了这个窗口左下角的坐标 后面两个参数定义了需要render的窗口的大小 每次调整window的大小的时候viewport也需要被调整 engines 我们希望这个engine可以一直持续画图，直到最后我们告诉这个窗口要关闭，所以要建立一个循环 12345while(!glfwWindowShouldClose(window))&#123; glfwSwapBuffers(window); glfwPollEvents(); &#125; 在这个循环里面，pollevent是来检查是不是有trigger进来的事情（比如键盘输入），更新窗口的状态，并且call相应的函数 swapbuffer，会交换color buffer（包括每个像素点颜色的buffer），然后show在窗口里面 last thing glfwTerminate退出这个循环之后，需要清除这些相关的资源，用这个函数放在最底下 input 需要一些键盘上的操作来调整的时候，写了一个processInput的函数 比如下面这个函数就是检测了有没有按下去esc，如果按了的话就关闭窗口 写完之后把这个函数在while循环里面调用12345void processInput(GLFWwindow *window)&#123; if(glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) glfwSetWindowShouldClose(window, true);&#125; rendering 希望在一个loop里面放上去所有的rendering的命令，整个循环看起来应该是这个样子的12345678910111213// render loopwhile(!glfwWindowShouldClose(window))&#123; // input processInput(window); // rendering commands here ... // check and call events and swap the buffers glfwPollEvents(); glfwSwapBuffers(window);&#125; hello triangleopengl里面所有东西都是在3D的空间里的，但是屏幕上显示的东西是2D的。整个这个转换的过程叫做graphics pipeline，可以分成两个步骤：第一个是把物体的3D坐标转化成2D的坐标，第二个是把2D的坐标转化成pixel上面的具体值 pipeline 所有的转化步骤都可以parallel的进行，现在的显卡有很多小的core来进行 -&gt; shaders 在最开始的时候pass进去了一个list的3D坐标 （Vertex Data） 第一步：vertex shader 把3D的坐标转化成不同的3D坐标（相当于把数据转化成点？） primitive assembly 从上一步得到的左右的点得到输入 然后形成一个基本的图形 geometry shader 根据新给的点，形成新的不同的形状，比如在例子里面形成了新的一条线 rasterization stage 把上面得到的primitives map到最后的屏幕上面的相应的pixel上面 Clipping 这一步丢掉了所有在视线外面的fragments，提升性能 fragment shader 计算这个pixel最后的颜色，会在这一步计算光影，以及光线的颜色等等东西 当每个像素的颜色决定了以后，这个object会被送到alpha test和blending 这一步会测试深度原因，判断fragment是在物体的前面还是后面 还会考虑透明度的问题虽然上面的东西很复杂，但是在实际应用的时候只需要要考虑vertex和fragment shader vertex input openGL是3D的东西，所有的点设置input的时候都需要设置三维的坐标 xyz 只有在坐标在 -1 到 1 中间的时候，才会处理这些坐标，这个范围里面的数字是根据屏幕的比例得出来的normalized device coordinates 比如在这个例子里面，需要的渲染一个三角形，那么需要这个三角形的三个点的坐标。注意这个例子里面根本没有考虑深度，而是直接画在了平面上面 12345float vertices[] = &#123; -0.5f, -0.5f, 0.0f, 0.5f, -0.5f, 0.0f, 0.0f, 0.5f, 0.0f&#125;; 在定义好坐标之后需要把这个东西放进vertex shader里面，需要在GPU里面创建一部分内存来存储这个数据，并且需要在GPU里面存储大量的数据（这样不用每次都送了） 每个部分的object都会有一个自己的buffer id，可以通过下面的方法生成一个id。也可以把一串array绑到这个id上面12unsigned int VBO;glGenBuffers(1, &amp;VBO);]]></content>
      <categories>
        <category>OpenGl</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment2之Batch Normalization]]></title>
    <url>%2F2019%2F04%2F15%2FCS231Nassignment2BN%2F</url>
    <content type="text"><![CDATA[target 之前的内容讲了lr的优化方法，比如Adam，另一种方法是根据改变网络的结构，make it easy to train -&gt; batch normalization 想去掉一些uncorrelated features(不相关的特征)，可以在训练数据之前preprocess，变成0-centered分布，这样第一层是没有问题的，但是后面的层里还是会出问题 所以把normalization的部分加入了DN里面，加入了一个BN层，会估计mean和standard deviation of each feature，这样重新centre和normalized learnable shift and scale parameters for each feature dimension 核心思想：粗暴的用BN来解决weights初始化的问题 ref：https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html Batch normalization: forward这个东西的要义就是NN里面的一层，不对维度改变，但是会改变这些值的分布 首先setup，并且载入好了preprocess的数据cs231n/layers.py -&gt; batchnorm_forward keep exp decay 来运行mean &amp; variance of each feature -&gt; 在test的时候去normalize data test-time: 计算sample mean和varience的时候用大量的训练数据而不是用所有图片的平均值，但是在作业里面用的是平均值，因为可以省去一步estimate（torch7 也用的是平均值） 12running_mean = momentum * running_mean + (1 - momentum) * sample_meanrunning_var = momentum * running_var + (1 - momentum) * sample_var I/O input x，data(N,D) gamma：scale parameter(D,) beta：shift parameter(D,) bn_param: 一个dict mode：‘train’ or ‘test’ eps：为了数字上的稳定性的一个常数 momentum：在计算mean和variance上面的一个常数 running mean：(D,)，是running mean running var：(D,) output out：(N,D) cache:在back的时候用 todo 用minibatch的统计来计算mean和variance，用这两个值把data normalize，并且用gamma和beta拉伸这个值，以及shift这些值的位置 在分布的上面，虽然求得是running variance，但是需要normalize的时候考虑的是standard（也就是平方根） implement 其实是和如何计算息息相关的，知道输入，求这个玩意的normal的步骤如下（其中的x就是这个minibatch的全部数据） 求mu，也就是x的mean（注意这里要对列求mean，也就是把所有图片的像素均匀分布，最后得到的结果是D个不是N个） 求var，知道这个东西，可以直接用 np.var(x, axis = 0)来求方差 求normalize： x - x.mean / np.sqrt(x.var + eps) 其中刚开始求出来的var就是方差，也就是标准差的平方 eps是偏差值，这个值加上方差开方是标准差 scale和shift，乘scale的系数，加shift的系数 最后需要计算什么cache和back的推导息息相关 Batch normalization: backward 可以直接画出来计算normal的路径，然后根据这个路径back 要义就是一步一步的求导！一步一步的链式法则 注意的就是求mean回来的导数，理解上来说就是这个矩阵在求导的过程中升维了，从(D,)变成了(N,D)，而在最开始求得时候所有的数字的贡献都是1，所以往回走的时候乘一个（N，D）的全是1的矩阵，并且1/N的常数还在 Batch normalization: alternative backward 在sigmoid的back的过程中有两种不同的方法 一种是写出来整体计算的图（拆分成各种小的计算），然后根据这张图的再back回去 另一种是在纸上先简化了整体的计算过程，然后再直接实现，这样代码会比较简单 ref:https://kevinzakka.github.io/2016/09/14/batch_normalization/ 最终目标 f: BN之后的整体输出结果 y：对normal之后的线性变换（gamma + beta） x’：normal的input mu：batch mean varbatch vatiance 需要求 df/dx,df/dgamma,df/dbeta -&gt; 最终结果整体速度比以前快了x2.5左右，这一步的主要目的就是用来提速的 可以把整体的计算分为以下的三个步骤 这三部分的代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208def batchnorm_forward(x, gamma, beta, bn_param): """ Forward pass for batch normalization. During training the sample mean and (uncorrected) sample variance are computed from minibatch statistics and used to normalize the incoming data. During training we also keep an exponentially decaying running mean of the mean and variance of each feature, and these averages are used to normalize data at test-time. At each timestep we update the running averages for mean and variance using an exponential decay based on the momentum parameter: running_mean = momentum * running_mean + (1 - momentum) * sample_mean running_var = momentum * running_var + (1 - momentum) * sample_var Note that the batch normalization paper suggests a different test-time behavior: they compute sample mean and variance for each feature using a large number of training images rather than using a running average. For this implementation we have chosen to use running averages instead since they do not require an additional estimation step; the torch7 implementation of batch normalization also uses running averages. Input: - x: Data of shape (N, D) - gamma: Scale parameter of shape (D,) - beta: Shift paremeter of shape (D,) - bn_param: Dictionary with the following keys: - mode: 'train' or 'test'; required - eps: Constant for numeric stability - momentum: Constant for running mean / variance. - running_mean: Array of shape (D,) giving running mean of features - running_var Array of shape (D,) giving running variance of features Returns a tuple of: - out: of shape (N, D) - cache: A tuple of values needed in the backward pass """ mode = bn_param['mode'] eps = bn_param.get('eps', 1e-5) momentum = bn_param.get('momentum', 0.9) N, D = x.shape running_mean = bn_param.get('running_mean', np.zeros(D, dtype=x.dtype)) running_var = bn_param.get('running_var', np.zeros(D, dtype=x.dtype)) out, cache = None, None if mode == 'train': ####################################################################### # TODO: Implement the training-time forward pass for batch norm. # # Use minibatch statistics to compute the mean and variance, use # # these statistics to normalize the incoming data, and scale and # # shift the normalized data using gamma and beta. # # # # You should store the output in the variable out. Any intermediates # # that you need for the backward pass should be stored in the cache # # variable. # # # # You should also use your computed sample mean and variance together # # with the momentum variable to update the running mean and running # # variance, storing your result in the running_mean and running_var # # variables. # # # # Note that though you should be keeping track of the running # # variance, you should normalize the data based on the standard # # deviation (square root of variance) instead! # # Referencing the original paper (https://arxiv.org/abs/1502.03167) # # might prove to be helpful. # ####################################################################### mean = np.mean(x, axis=0) xmu = x - mean sq = np.square(xmu) var = np.var(x, axis=0) sqrtvar = np.sqrt(var + eps) ivar = 1. / sqrtvar normalize_raw = xmu * ivar normalize_result = gamma * normalize_raw + beta out = normalize_result running_mean = momentum * running_mean + \ (1 - momentum) * mean running_var = momentum * running_var + (1 - momentum) * var cache = (normalize_raw, gamma, xmu, ivar, sqrtvar, var, eps) ####################################################################### # END OF YOUR CODE # ####################################################################### elif mode == 'test': ####################################################################### # TODO: Implement the test-time forward pass for batch normalization. # # Use the running mean and variance to normalize the incoming data, # # then scale and shift the normalized data using gamma and beta. # # Store the result in the out variable. # ####################################################################### x_normalize = (x - running_mean) / (np.sqrt(running_var + eps)) out = x_normalize * gamma + beta ####################################################################### # END OF YOUR CODE # ####################################################################### else: raise ValueError('Invalid forward batchnorm mode "%s"' % mode) # Store the updated running means back into bn_param bn_param['running_mean'] = running_mean bn_param['running_var'] = running_var return out, cachedef batchnorm_backward(dout, cache): """ Backward pass for batch normalization. For this implementation, you should write out a computation graph for batch normalization on paper and propagate gradients backward through intermediate nodes. Inputs: - dout: Upstream derivatives, of shape (N, D) - cache: Variable of intermediates from batchnorm_forward. Returns a tuple of: - dx: Gradient with respect to inputs x, of shape (N, D) - dgamma: Gradient with respect to scale parameter gamma, of shape (D,) - dbeta: Gradient with respect to shift parameter beta, of shape (D,) """ dx, dgamma, dbeta = None, None, None ########################################################################### # TODO: Implement the backward pass for batch normalization. Store the # # results in the dx, dgamma, and dbeta variables. # # Referencing the original paper (https://arxiv.org/abs/1502.03167) # # might prove to be helpful. # ########################################################################### normalize_raw, gamma, xmu, ivar, sqrtvar, var, eps = cache N, D = dout.shape dbeta = np.sum(dout, axis=0) dgammax = dout dgamma = np.sum(dgammax * normalize_raw, axis=0) dnormalize_raw = dgammax * gamma divar = np.sum(dnormalize_raw * xmu, axis=0) dxmu = dnormalize_raw * ivar dsqrtvar = -1. / (sqrtvar ** 2) * divar dvar = 0.5 * 1. / np.sqrt(var + eps) * dsqrtvar dsq = 1. / N * np.ones((N, D)) * dvar dxmu2 = 2 * xmu * dsq dx1 = (dxmu + dxmu2) dmu = -1 * np.sum(dxmu + dxmu2, axis=0) dx2 = 1. / N * np.ones((N, D)) * dmu dx = dx1 + dx2 ########################################################################### # END OF YOUR CODE # ########################################################################### return dx, dgamma, dbetadef batchnorm_backward_alt(dout, cache): """ Alternative backward pass for batch normalization. For this implementation you should work out the derivatives for the batch normalizaton backward pass on paper and simplify as much as possible. You should be able to derive a simple expression for the backward pass. See the jupyter notebook for more hints. Note: This implementation should expect to receive the same cache variable as batchnorm_backward, but might not use all of the values in the cache. Inputs / outputs: Same as batchnorm_backward """ dx, dgamma, dbeta = None, None, None ########################################################################### # TODO: Implement the backward pass for batch normalization. Store the # # results in the dx, dgamma, and dbeta variables. # # # # After computing the gradient with respect to the centered inputs, you # # should be able to compute gradients with respect to the inputs in a # # single statement; our implementation fits on a single 80-character line.# ########################################################################### normalize_raw, gamma, xmu, ivar, sqrtvar, var, eps = cache N, D = dout.shape dbeta = np.sum(dout, axis=0) dgamma = np.sum(dout * normalize_raw, axis=0) # intermediate partial derivatives dxhat = dout * gamma # final partial derivatives dx = (1. / N) * ivar * (N * dxhat - np.sum(dxhat, axis=0) - normalize_raw * np.sum(dxhat * normalize_raw, axis=0)) ########################################################################### # END OF YOUR CODE # ########################################################################### return dx, dgamma, dbeta Fully Connected Nets with Batch Normalizationin cs231n/classifiers/fc_net.py, add the BN layers into the net. 应该在每个relu之前加上BN，所以在这里不能直接用之前的affine，relu的过程，因为中间又插了一个新的BN层，所以要写一个新的function 最后一层之后的输出不应该BN(应该是涉及到循环的问题) 实现中遇到的问题 self.bn_params的参数类型不是dict而是list，代表的是所有层里面的参数的所有和，当进入到每层的时候具体对应的才是这里的dict 当把affine_BN_relu结合在一起的时候，注意最后一层输出的地方没有BN，所以没有他的cache，需要分开讨论，不然cache的数量不对 注意这个fc_net的class因为需要实现多种不同的功能，所以对于是不是BN要加上条件判断 确实非常像搭乐高了！！ 这里主要，写到这才发现最后一层的时候好像是不需要relu也不需要batchnorm 定义好的函数块123456789101112131415def affine_BN_relu_forward(self, x, w, b, gamma, beta, bn_params): a, fc_cache = affine_forward(x, w, b) mid, BN_cache = batchnorm_forward(a, gamma, beta, bn_params) out, relu_cache = relu_forward(mid) cache = (fc_cache, BN_cache, relu_cache) return out, cache def affine_BN_relu_backward(self, dout, cache): fc_cache, BN_cache, relu_cache = cache da = relu_backward(dout, relu_cache) dmin, dgamma, dbeta = batchnorm_backward_alt(da, BN_cache) dx, dw, db = affine_backward(dmin, fc_cache) return dx, dw, db, dgamma, dbeta 结论 可视化之后可以发现加了norm的话好像会下降的快一点 Batch normalization and initialization 进行试验，了解BN和weight initialization的关系 训练一个八层的网络，包括和不包括BN，用不同的weight initialization plot出来train acc, val_acc,train_loss和weight initialization的关系 BN的作用从图中可以看出来，有了BN以后，weight init对最终结果的影响明显会降低： weight的初始化对最终结果影响很严重，比如如果全是0的话，得到的所有neuron的功能都是一样的 BN其实就是在实际中解决weight init的办法，这样可以减少初始化参数的影响 核心思想就是如果你需要更好的分布，你就加一层让他变成更好的分布 在计算的过程中越乘越小（或者越大），所以计算出来的结果越来越接近0 所以这时候如果把一些input重新分布了，就会减少这个接近0的可能性 Batch normalization and batch size 试验验证BN和batch size的关系 训练6-layer的网络，分别with和without BN，使用不同的batch size By increasing batch size your steps can be more accurate because your sampling will be closer to the real population. If you increase the size of batch, your batch normalisation can have better results. The reason is exactly like the input layer. The samples will be closer to the population for inner activations. Layer Normalization（LN） 前面的所有的BN已经可以让Net更好的被训练了，但是BN的大小和batch的大小有关，所以在实际应用的时候会受到一些限制 在复杂的网络里面的时候，batch_size是被硬件机能限制的 每个minibatch的数据分布可能会比较接近，所以训练之前要shuffle，否则结果会差很多 其中一种解决的方法就是layer normalization 不是在batch上面normal 在layer上面normal each feature vector corresponding to a single datapoint is normalized based on the sum of all terms within that feature vector. Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. “Layer Normalization.” stat 1050 (2016): 21. LN 综合一层的所有维度的输入，计算该层的平均输入和平均方差 然后用同一个规范化操作转换各个维度的输入 相当于以前我们希望可以正则到这个minibatch里面的大家都差不多，现在我们不管batch了，而是调整到一张图片里面的所有数据都是normal的 implementcs231n/layers.py -&gt; layernorm_backward forward + back input x, (N,D) gamma, scale beta,shift ln_params: eps output output,(N,D) cache 实现方法 -&gt; 实际上就是从对一列的操作变成了对一行的操作 比如之前对x取mean就是求每列的mean，现在变成了取每行的mean 在所有normal之后并且scale之前，把这个矩阵在tranpose回来 back 把需要参与计算的东西都tranpose 然后把计算完的dx tranpose回来 fc_nets在fc_nets里面稍加改动，在normalization里面增加BN_NORM和Layer_NORM的选项就可以了，整体改动不大123456789101112131415161718192021def affine_Normal_relu_forward(self, x, w, b, gamma, beta, bn_params, mode): a, fc_cache = affine_forward(x, w, b) if mode == "batchnorm": mid, Normal_cache = batchnorm_forward(a, gamma, beta, bn_params) elif mode == "layernorm": mid, Normal_cache = layernorm_forward(a, gamma, beta, bn_params) out, relu_cache = relu_forward(mid) cache = (fc_cache, Normal_cache, relu_cache) return out, cache def affine_Normal_relu_backward(self, dout, cache, mode): fc_cache, Normal_cache, relu_cache = cache da = relu_backward(dout, relu_cache) if mode == "batchnorm": dmid, dgamma, dbeta = batchnorm_backward_alt(da, Normal_cache) elif mode == "layernorm": dmid, dgamma, dbeta = layernorm_backward(da, Normal_cache) dx, dw, db = affine_backward(dmid, fc_cache) return dx, dw, db, dgamma, dbeta 可以从图像看出来，layernorm中，batchsize的影响变小了]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
        <category>CS231n作业</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>Batch Normalization</tag>
        <tag>Layer Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CppPrimer笔记]]></title>
    <url>%2F2019%2F04%2F15%2FCppPrimer%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第一部分 Basics C++在编译的时候就会检查类型 allow programmers to define types that include operations as well as data 第二章 varibles and basic type2.1 bulid-in基础类型包括算数类型（arithmtic type）和void类型，void用于没有返回值的函数 2.1.1 算数类型include：intergal（bool&amp; char）/ float 不同的长度的叫法不同： char -&gt; wchar_t, char16_t, char32_t(后面两个for unicode，自然语言里面) int -&gt; short, long, long long float -&gt; double, long double 扩展：在储存信息方面，储存在每个byte里面，是最小的计量单位（8bits）。在内存中，每个byte拥有一个address，需要知道地址和类型才知道到底存储的是什么东西。 signed &amp; unsigned（除了bool）： signed：包括0的正数和负数 unsigned：大于等于零 没有写unsigned的话就是signed的 对于char来说，signed，unsigined和char三种 char到底算不算unsigned显示取决于编译器 unsigned从0-255 signed一般是-128 ～ 127 关于到底怎么用： 当确定不可能是负值的时候用unisgned short太短了，long太长了，平常用int，int不够用long long 如果用char，为了考虑到不同编译的结果不同，确定好用signed还是unsigned 用double，float的精度不够，long double小号内存 2.1.2 类型转换（conversions）在把一个东西加到另一个的过程中，支持自动的类型转换 当bool被赋值为非0时，为true，0时为false 给int赋值double，自动变成整数；给doubl赋值int，变成整数后面.0 当unsigned超出界限时，the result is the remainder of the value modulo the number of values the target type can hold. 当signed超出界限的时候，结果是undefined。不知道会发生什么事。 在写代码的时候尽量避免没有定义的，或者在implement中才定义的行为，因为这样容易导致在这个电脑上行得通但是换个地方没准就行不通了 一些引起的问题： int和unsigned相加，会引起wrap around 两个unsigned相减如果小于零会出问题 在for循环的条件里，unsiged作为变量的话永远不会小于零 求求你了反正不要混着用 2.1.3 literals每个literal都有一个type，这是由form和value决定的。 整数类型的 0开头的整数是八进制，0x是16进制 负号不是literal的一部分，比如 -42，42是literal，负号是operator float类型的 十进制带小数点的数字 用exponent，E或者e，e后面的东西就是十的多少次方 character string的类型是一个char的array，complier会在每个string 后面加上‘\0’（null character） escape -&gt; 一些带有奇怪意义的\n，\t,\’等等 如果在\后面跟着多于三个数字，只会读取前三个 \x会读取跟在她后面的所有hex digits 单独改变一个literal，在数字后面加后缀suffix U：unsigned type L：long ULL：unsigned long long 但是如果你要给1024后面加个f就不行，因为1024是整形（这时候又开始怀念python） bool 2.2 变量 Variables变量提供的是：命名好的存储空间，程序可以对他执行，每个变量都有type（其实也就是class或者object吗） 2.2.1 变量的定义 assignment(赋值)和initialize(初始化)在c++里面是不一样的，初始化是在创建的时候赋予的值，赋值是之后改变这个变量的值 list的初始化：尖括号。 在使用bulit-in的时候，可能无法list初始化这个变量，因为会丢失一些信息。比如把一个double扔到int里面 是否可以不初始化就使用取决于class的定义。比如要是int没有初始化的时候是0，string没有初始化的时候是空字符串 2.2.2 变量declaration（声明？）和定义 在分开编写代码的时候，需要知道调用的函数从哪里来。注意：不初始化变量容易出问题，建议初始化每个bulit-in declaration：让程序知道函数的名字 在前面加上extern，就可以declare但是不define 但是如果已经初始化了函数，就不能加extern了，会引起错误 在其他函数的地方调用的时候（use a varible in multiple files），不需要再define了，但是需要声明 defination：创建相应的实体 除了干declaration的事情，他还分配内存，或者提供初始值 变量被define一次，但是可以被declaration无数次。 2.2.3 identifiers（定义的名字） 要求 数字，字母，下划线underscore 对大小写有区分 不能使用C++的关键词 不能含有两个相连的下划线 2.2.4 名字的scope 使用的意义：同一个名字可能会在程序的其他地方被使用，所以要用scope确定这个名字在哪个范围里面有意义（不是namespace啊啊啊啊啊竟然是大括号我震惊） nested scope 在外层被定义的名字可以在内层被重新定义 温情建议：局部变量和全局变量不要使用一个名字 2.3 compound types（有范围的类型？）就是定义在其他类型之上的类型。在c++里面有两个，pointer和reference 2.3.1 reference（lvalue reference）在创建的时候，copy的不是对象的值，而是把refer和值绑在了一起，在创建之后不能再和别的东西绑在一起。reference必须初始化。 不是对象，是一个已经存在的对象的另一个名字 给refer赋值的时候，实际上是赋值给refer所绑定的对象 当给一个refer赋值另一个refer的时候，其实是绑到了同一个对象（但是不应该这么定义） 定义 在refer的名字之前加上&amp;，但是在后续使用的时候可以不带了 refer只能初始化成一个对象，不能是一个具体的值 类型要正确 2.3.2 pointer和refer不同，指针是一个object，他们可以被assign或者copy，在定义的时候不必须初始化，一个指针可以指向不同的东西。在定义的时候用 * 来表示 取址 pointer可以得到另一个对象的address。&amp;也可以作为取址符号得到一个对象的地址（和refer不一样！！） 类型必须匹配 pointer的值（可以是以下四个之一） 指向一个对象 指向一个在对象中末尾的位置（没有使用的实际意义） null指针，表示还没有和其他的绑定 无效的？？如果是无效的话是不能访问的 访问对象 当一个pointer指向对象的时候，使用dereference（ ）来得到她的值。（pointer p是一个地址， p是他这个地址上的值 空指针NULL 使用nullptr定义 assign一个int变量给pointer是非法的，即使这个数是0（赋值的时候给的是变量的地址，带&amp;的） 真诚建议：初始化所有的pointer，没有初始化的很难分辨出来到底这个地址是有效还是无效 assignment 写成 pi = &amp;val的时候，改变的是pi的值，他指向了val 写成 * pi = 0 的时候，改变的是val的值，val变成了0 void* Pointers void* 是一个很牛逼的指针，可以hold所有对象的地址 作用：可以传到函数或者作为函数的返回值，可以和其他指针比较，可以赋值给另一个void* 指针，但是不能操控对象的地址 2.3.3 理解 定义多个变量 虽然在定义指针的时候可以加空格，但是 int* p1，p2之中，p1是指针，p2是int pointer到pointer 写成一串星号可以表示从pointer到pointer refer到pointer &amp;r可以定义成一个pointer（指针写在=右边） 2.4 修饰词 const 作用：希望定义一个variable，value不可以被改变，这时候就用上了const。在创建的时候必须初始化 在实际操作的时候，到底是不是const对数值没有影响，可以用非const来初始化const或者用const来初始化其他的 在创建之后，编译的时候所有的变量名都会换成变量的值 const对每个file来说是local的 如果希望定义一个在所有file里面都可以用的，然后在其他使用的时候声明，这时候用extern const（在定义和后续声明的时候都需要使用） 2.4.1 refer to const 可以refer到一个const，但是之后就不能通过refer来改变变量的值，也不能把一个const的变量赋值给一个非const的refer const refer的意思是这个refer不能被用来改变变量，但是被绑的变量本身可以改变。比如const int &amp;r2 = i，这时候改变i是合法的 2.4.2 pointer and const pointer to const不能被用于改变指向的东西 但是pointer是const的和变量自己改不改没关系。变量是const的话指针必须是const的 const pointer 指针本身就是一个对象，所以指针自己也可以是const的 必须被初始化，一旦初始化了，他的内容（所指向的地址）就不能改变了。 定义的时候用 int * const cpr = &amp;num （const的位置改变了） 但是可以用const pointer来改变所指向东西的值！！！只是这两个东西绑定了不能改了而已 2.4.3 top-level 可以分开考虑pointer和对象 top-level：pointer自己是一个const -&gt; 本身就是const的，可以出现在任何的对象里面 low-level：指向一个const -&gt; 只出现在refer和pointer里面 当copy一个对象的时候，top-level是被忽略的常量指针就是一个常量，不能把常量给普通但是可以把普通给常量 2.4.4 constexpr 常量表达式是编译的时候不能改变的，const object或者literal都是常量表达式。只有在初始化的时候知道了的值才是常量表达式。如果是个const int但是不确定到底是什么，那么就还不算 在前面加上 constexpr，这时候只有当后面的变量是常量的时候才能用 可以在compile的时候判定 当这个类型不是literal的时候，不能定义成常量表达式（literal包括算数，pointer和refer） 在函数内定义的变量一般不会储存在固定的地址，所以这时候指针不能是constexpr（6.1.1） 当使用constexpr的时候，作用在的是指针上而不是指向的东西上1const int *p = nullptr; // p is a pointer to a const int constexpr int *q = nullptr; // q is a const pointer to int 2.5 types 类型2.5.1 type aliases 即为对另一个type的化名 -&gt; 简化比较复杂的type，更好使用 定义方法1： 12typedef double wages; // wages is a synonym for doubletypedef wages base, *p; // base is a synonym for double, p for double* 方法2: using SI = Sales_item； 和pointer以及const -&gt; 用的时候直接替代会出问题123typedef char *pstring;const pstring cstr = 0; // cstr is a constant pointer to charconst pstring *ps; // ps is a pointer to a constant pointer to char 2.5.2 auto 作用：有的时候没法定义变量的type，这时候可以用auto，编译的时候会自动指出变量的类型（从初始化的结果推断出来的） 写成一行定义的时候，auto不能包括不同的类型（如int和double） 指针refer，const和auto 当用auto然后用一个refer初始化的时候，得到的结果是refer绑定的object 如果需要auto之后的结果还是const的，需要在auto前面加上const1234const int ci = i, &amp;cr = ci;auto b = ci; // b is an int (top-level const in ci is dropped)auto c = cr; // c is an int (cr is an alias for ci whose const is top-level) autod=&amp;i; // d isan int*(&amp; ofan int objectis int*)auto e = &amp;ci; // e is const int*(&amp; of a const object is low-level const) 2.5.3 decltype 作用：从expr里面推断出来type，但是不用这个expr来初始化的时候。这时候用decltype(fun())，这时候fun用来判断变量的类型，但是不call 如果是必须初始化的东西（比如pointer或者refer）必须初始化 decltype(* p) is int&amp;, not plain int decltype((variable))肯定是一个refer，但是decltype(variable)只有当variable是refer的时候才是 第三章 string，vector，array第二章说的是c++里面的built-in类型，除此之外还有很多library的类型（标准库），定义了很多高于计算机内部直接访问的数字和字母的类型。 3.1 namespace声明 每次都声明函数的namespace比较麻烦，可以在所有的开始之前用using namespace :: name来声明使用的特定的函数的namespace。或者直接用他代表所有的。 头文件里面不应该用using，因为include的时候就加到所有的东西里面了，那就没有意义了 3.2 stringstring定义在std的namespace里面 3.2.1 定义和初始化 一个不知道的初始化方法： string s(n,’b’)，输出结果是n个b 使用s(“hiya”)和s=”hiya”一个是direct的初始化方法，另一个是copy的初始化方法。比较容易读的方法是创建： string s = string(10,’b’) 3.2.2 string的操作 string的读和写，cout和cin（iostream库） 当键盘有输入的时候，while(cin &gt;&gt; word)这种感觉的东西当条件，cin是会识别空格然后分开的！！！ getline()可以读取一整行，存在第二个参数里面，并且帮忙跳到新的一行 .empty()和.size()可以判定是否为空，以及string里面的char的数量 string:: size_type size的返回值的类型是size_type 注意：因为返回值类型不同，所以当比较size的时候，如果和一个int的负数比较，int会被转换成unisgned的一个巨大的数字，从而导致比较的失败 -&gt; 所以在使用size的语句里面，不用int比较好（亲身证明确实如此，换成double就没事了） 比较字符串 == 或者 ！= 来比较两个是否相等，需要是相同的长度且包括相同的字母 比较两个的大小时 如果长度不同，如果短的每个的字母都和长的相同，那短的比较小 如果任何一位上面的char不同，那就是第一个不同的char比较的结果 add 字符串可以直接相加（指s1+s2） 可以把string和literal混着加，但是两个带引号的不能连在一起直接加（这是什么脑残规则） 练习 可以直接通过索引vector的方法索引string里面的char（但是一个词一个词读取直接用cin&gt;&gt; s也是可以的（我是傻逼吗）） 二择的判断条件可以写成 ((str1.size() &gt; str2.size()) ? str1 : str2) 3.2.3 string里面的chars 有时候需要处理每一个字母，有的时候需要处理特殊的一些字母，定义在函数cctype里面]]></content>
      <categories>
        <category>编程语言</category>
        <category>Cpp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[关于numpy里面random.rand和randn的区别]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%85%B3%E4%BA%8Erandomrand%E5%92%8Crandn%2F</url>
    <content type="text"><![CDATA[python里面常用的两个产生随机数的函数，两个不太一样 其中 np.random.rand()是用来产生0-1之间的随机数的，这个最近应用最多的地方是在产生一个从a-b范围里面的数字，这时候可以先产生一个巨大的随机0-1的矩阵，然后再乘以a和b之间的差 np.random.randn()产生的是随机正态分布的标准值，外面可以乘上std就是需要的正态分布，这样可以用来初始化深度网络的weights，括号里填的都是生成的东西的维度 另外一个问题，randn的参数需要的是inter，所以在输入的时候要不是选择 np.random.randn(x0.shape[0], x0.shape[1]) np.random.randn(*x0.shape)]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>random</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment2之FCnet]]></title>
    <url>%2F2019%2F04%2F11%2FCS231Nassignment2FCnet%2F</url>
    <content type="text"><![CDATA[This part is from the assignment 2018:stanford cs231n assignment2 目标 之前已经实现了两层的fc net，但是在这个网络里面的loss和gradient的计算用的是数学方法 这样的计算可以在两层的网络里实现，但是多层的情况下实现起来太困难了 所以在这里把电脑分成了forward pass和backward pass forward的过程中，接受所有的input，weights，和其他的参数，返回output和cache（存储back的时候需要的东西） 12345678910def layer_forward(x, w): """ Receive inputs x and weights w """ # Do some computations ... z = # ... some intermediate value # Do some more computations ... out = # the output cache = (x, w, z, out) # Values we need to compute gradients return out, cache back的时候会接受derivative和之前存储的cache，然后计算最后的gradient 12345678910111213def layer_backward(dout, cache): """ Receive dout (derivative of loss with respect to outputs) and cache, and compute derivative with respect to inputs. """ # Unpack cache values x, w, z, out = cache # Use values in cache to compute derivatives dx = # Derivative of loss with respect to x dw = # Derivative of loss with respect to w return dx, dw 这样就可以组合各个部分达到最终需要的效果了，无论多深都可以实现了 还需要一部分的优化部分，包括Dropout，Batch/Layer的Normalization Affine layer：forwardinput x：大小（N，d_1…d_k)，minibatch of N，每张图片的维度是d_1到d_k，所以拉成一长条的维度是 d_1 d_2… d_k w：weights，(D,M)，把这个长度是d的图片，输出的时候就变成M了 b:bias,(M,) -&gt; 这个bias会被broadcast到all lines （bias的值是最终分类的class的值，在不是最后一层的时候就是output的值），相当于一个class分一个bias（一列） output output,(N,M) cache:(x,w,b) implement 这里的实现直接reshape就可以了，-1的意思是这个维度上不知道有多少反正你自己给我算算的意思，但是需要N行是确定了的 注意这里验证的时候虽然input的是size，但是实际上是把数字填到这个里面的，所以取N的时候实际上是x.shape[0] Affine layer:backwardinput dout: upstream derivative, shape(N,M) cache: Tuple x w b return dx: (N,d1,d2…,dk) dw:(D,M) db:(M,) implement 注意这里用到的是链式法则：df/dx = df/dq * dq/dx 这里的df/dq就是已经求出来的dout q的式子是 Wx + b，对这三个变量分别求导，求出来大家的，别忘了求导之后的东西需要再乘dout 结果到底怎么算应该按每个矩阵的shape来推出来 ReLU activationforward input：x，随便什么尺寸都可以，这部分只是计算relu这个函数 output out，计算出来的结果 cache，储存x，用来back的运算 implement -&gt; 直接把小于0的部分设置成0就可以了 backward input 返回回来的dout cache output： 计算出来的x的梯度 implement: 求导，当原来的x大于0的时候，导数是1，链式法则是dout。小于等于0的时候是dout 所以直接对dout进行操作就可以了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107def affine_forward(x, w, b): """ Computes the forward pass for an affine (fully-connected) layer. The input x has shape (N, d_1, ..., d_k) and contains a minibatch of N examples, where each example x[i] has shape (d_1, ..., d_k). We will reshape each input into a vector of dimension D = d_1 * ... * d_k, and then transform it to an output vector of dimension M. Inputs: - x: A numpy array containing input data, of shape (N, d_1, ..., d_k) - w: A numpy array of weights, of shape (D, M) - b: A numpy array of biases, of shape (M,) Returns a tuple of: - out: output, of shape (N, M) - cache: (x, w, b) """ out = None ########################################################################### # TODO: Implement the affine forward pass. Store the result in out. You # # will need to reshape the input into rows. # ########################################################################### out = x.reshape(x.shape[0], -1).dot(w) + b ########################################################################### # END OF YOUR CODE # ########################################################################### cache = (x, w, b) return out, cachedef affine_backward(dout, cache): """ Computes the backward pass for an affine layer. Inputs: - dout: Upstream derivative, of shape (N, M) - cache: Tuple of: - x: Input data, of shape (N, d_1, ... d_k) - w: Weights, of shape (D, M) - b: Biases, of shape (M,) Returns a tuple of: - dx: Gradient with respect to x, of shape (N, d1, ..., d_k) - dw: Gradient with respect to w, of shape (D, M) - db: Gradient with respect to b, of shape (M,) """ x, w, b = cache dx, dw, db = None, None, None ########################################################################### # TODO: Implement the affine backward pass. # ########################################################################### dx = dout.dot(w.T).reshape(x.shape) dw = (x.reshape(x.shape[0], -1).T).dot(dout) db = np.sum(dout, axis=0) ########################################################################### # END OF YOUR CODE # ########################################################################### return dx, dw, dbdef relu_forward(x): """ Computes the forward pass for a layer of rectified linear units (ReLUs). Input: - x: Inputs, of any shape Returns a tuple of: - out: Output, of the same shape as x - cache: x """ out = None ########################################################################### # TODO: Implement the ReLU forward pass. # ########################################################################### out = x.copy() out[out &lt;= 0] = 0.0 ########################################################################### # END OF YOUR CODE # ########################################################################### cache = x return out, cachedef relu_backward(dout, cache): """ Computes the backward pass for a layer of rectified linear units (ReLUs). Input: - dout: Upstream derivatives, of any shape - cache: Input x, of same shape as dout Returns: - dx: Gradient with respect to x """ dx, x = None, cache ########################################################################### # TODO: Implement the ReLU backward pass. # ########################################################################### dout[x &lt;= 0] = 0 dx = dout ########################################################################### # END OF YOUR CODE # ########################################################################### return dx sandwich layer在文件cs231n/layer_utils.py里面，有一些比较常见的组合，可以集成成新的函数，这样用的时候就可以直接调用不用自己写了 loss layer -&gt; 和assignment1里面写的内容是一样的two-layer networkcs231n/classifiers/fc_net.py TwoLayerNet init__ 需要初始化weights和bias，weights应该是0.0中心的高斯（=weight_scale），bias应该是0，都存在self.para的字典里面，第几层的名字就叫第几 input 图片的size hidden的个数 class的数量 weight scale，看初始的weights怎么分布 reg，regularization时候的权重 forward 用前面已经写好的东西计算前向 最后得到scores 再用scores计算loss，注意 计算loss也是一层 计算loss的时候注意他这里loss的参数是scores和lable backward back的时候不要忘记了loss也是一层，所以输入第二个sandwich的时候输入的应该是dscores而不是scores？！！！！ 计算gradient，注意他的function里面已经除了总数！ 别忘了加上L2的regularization Solver把之前那些训练啊，验证啊，计算accuracy之类的部分全都扔到一个class里面叫做solver，打开cs231n/solver.py 作用 solver部分包括所有训练分类所需要的逻辑部分，在optim.py里面还用了不同的update方法来实现SGD 这个class接受training和validation的数据和labels，所以可以检查分类的准确率，是否overfitting 需要先构成一个solver的instance，把需要的model，dataset，和不同的东西（learning rate，batch，etc）放进去 先用train()来训练，然后model的para都存着所有训练完的参数 训练的过程也会记录下来（accuracy的改变啥的） 最后训练的结果大约在50%12345678910111213141516171819model = TwoLayerNet()solver = None############################################################################### TODO: Use a Solver instance to train a TwoLayerNet that achieves at least ## 50% accuracy on the validation set. ###############################################################################solver = Solver(model, data, update_rule = 'sgd', optim_config=&#123;'learning_rate': 1e-3,&#125;, lr_decay=0.95, num_epochs=10, batch_size=100, print_every=100)solver.train()############################################################################### END OF YOUR CODE ######################################################################## 可视化这个最终的结果，loss随着epoch的变化和training acc以及val acc的变化12345678910111213141516# Run this cell to visualize training loss and train / val accuracyplt.subplot(2, 1, 1)plt.title('Training loss')plt.plot(solver.loss_history, 'o')plt.xlabel('Iteration')plt.subplot(2, 1, 2)plt.title('Accuracy')plt.plot(solver.train_acc_history, '-o', label='train')plt.plot(solver.val_acc_history, '-o', label='val')plt.plot([0.5] * len(solver.val_acc_history), 'k--')plt.xlabel('Epoch')plt.legend(loc='lower right')plt.gcf().set_size_inches(15, 12)plt.show() 记下来了这个loss和acc的history，所以就可以直接用来可视化了！ Multilayer network现在开始实现有多层的net 需要注意的问题主要是数数数对了，注意数字和layer的数量的关系 为了保证验证的准确，需要把loss的regularization算对才可以 反向往回推的时候，可以用 reversed(range(a))这个东西来进行 总体来说和两层的差不多，就是加进来了for循环 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202class FullyConnectedNet(object): """ A fully-connected neural network with an arbitrary number of hidden layers, ReLU nonlinearities, and a softmax loss function. This will also implement dropout and batch/layer normalization as options. For a network with L layers, the architecture will be &#123;affine - [batch/layer norm] - relu - [dropout]&#125; x (L - 1) - affine - softmax where batch/layer normalization and dropout are optional, and the &#123;...&#125; block is repeated L - 1 times. Similar to the TwoLayerNet above, learnable parameters are stored in the self.params dictionary and will be learned using the Solver class. """ def __init__(self, hidden_dims, input_dim=3 * 32 * 32, num_classes=10, dropout=1, normalization=None, reg=0.0, weight_scale=1e-2, dtype=np.float32, seed=None): """ Initialize a new FullyConnectedNet. Inputs: - hidden_dims: A list of integers giving the size of each hidden layer. - input_dim: An integer giving the size of the input. - num_classes: An integer giving the number of classes to classify. - dropout: Scalar between 0 and 1 giving dropout strength. If dropout=1 then the network should not use dropout at all. - normalization: What type of normalization the network should use. Valid values are "batchnorm", "layernorm", or None for no normalization (the default). - reg: Scalar giving L2 regularization strength. - weight_scale: Scalar giving the standard deviation for random initialization of the weights. - dtype: A numpy datatype object; all computations will be performed using this datatype. float32 is faster but less accurate, so you should use float64 for numeric gradient checking. - seed: If not None, then pass this random seed to the dropout layers. This will make the dropout layers deteriminstic so we can gradient check the model. """ self.normalization = normalization self.use_dropout = dropout != 1 self.reg = reg self.num_layers = 1 + len(hidden_dims) self.dtype = dtype self.params = &#123;&#125; ############################################################################ # TODO: Initialize the parameters of the network, storing all values in # # the self.params dictionary. Store weights and biases for the first layer # # in W1 and b1; for the second layer use W2 and b2, etc. Weights should be # # initialized from a normal distribution centered at 0 with standard # # deviation equal to weight_scale. Biases should be initialized to zero. # # # # When using batch normalization, store scale and shift parameters for the # # first layer in gamma1 and beta1; for the second layer use gamma2 and # # beta2, etc. Scale parameters should be initialized to ones and shift # # parameters should be initialized to zeros. # ############################################################################ pr_num = input_dim # can't use enumerate beacuse I need the number more than the size of hidden_dims for layer in range(self.num_layers): layer += 1 weights = 'W' + str(layer) bias = 'b' + str(layer) # 这时候是最后一层(the last layer) if layer == self.num_layers: self.params[weights] = np.random.randn( hidden_dims[len(hidden_dims) - 1], num_classes) * weight_scale self.params[bias] = np.zeros(num_classes) # other layers else: hidd_num = hidden_dims[layer - 1] self.params[weights] = np.random.randn( pr_num, hidd_num) * weight_scale self.params[bias] = np.zeros(hidd_num) pr_num = hidd_num if self.normalization in ["batchnorm", "layernorm"]: self.params['gamma' + str(layer)] = np.ones(hidd_num) self.params['bata' + str(layer)] = np.zeros(hidd_num) # print(len(self.params)) # print(self.params) ############################################################################ # END OF YOUR CODE # ############################################################################ # When using dropout we need to pass a dropout_param dictionary to each # dropout layer so that the layer knows the dropout probability and the mode # (train / test). You can pass the same dropout_param to each dropout layer. self.dropout_param = &#123;&#125; if self.use_dropout: self.dropout_param = &#123;'mode': 'train', 'p': dropout&#125; if seed is not None: self.dropout_param['seed'] = seed # With batch normalization we need to keep track of running means and # variances, so we need to pass a special bn_param object to each batch # normalization layer. You should pass self.bn_params[0] to the forward pass # of the first batch normalization layer, self.bn_params[1] to the forward # pass of the second batch normalization layer, etc. self.bn_params = [] if self.normalization == 'batchnorm': self.bn_params = [&#123;'mode': 'train'&#125; for i in range(self.num_layers - 1)] if self.normalization == 'layernorm': self.bn_params = [&#123;&#125; for i in range(self.num_layers - 1)] # Cast all parameters to the correct datatype for k, v in self.params.items(): self.params[k] = v.astype(dtype) def loss(self, X, y=None): """ Compute loss and gradient for the fully-connected net. Input / output: Same as TwoLayerNet above. """ X = X.astype(self.dtype) mode = 'test' if y is None else 'train' # Set train/test mode for batchnorm params and dropout param since they # behave differently during training and testing. if self.use_dropout: self.dropout_param['mode'] = mode if self.normalization == 'batchnorm': for bn_param in self.bn_params: bn_param['mode'] = mode scores = None ############################################################################ # TODO: Implement the forward pass for the fully-connected net, computing # # the class scores for X and storing them in the scores variable. # # # # When using dropout, you'll need to pass self.dropout_param to each # # dropout forward pass. # # # # When using batch normalization, you'll need to pass self.bn_params[0] to # # the forward pass for the first batch normalization layer, pass # # self.bn_params[1] to the forward pass for the second batch normalization # # layer, etc. # ############################################################################ cache = &#123;&#125; temp_out = X for i in range(self.num_layers): w = self.params['W' + str(i + 1)] b = self.params['b' + str(i + 1)] if i == self.num_layers - 1: scores, cache['cache' + str(i + 1)] = affine_relu_forward(temp_out, w, b) else: temp_out, cache['cache' + str(i + 1)] = affine_relu_forward(temp_out, w, b) ############################################################################ # END OF YOUR CODE # ############################################################################ # If test mode return early if mode == 'test': return scores loss, grads = 0.0, &#123;&#125; ############################################################################ # TODO: Implement the backward pass for the fully-connected net. Store the # # loss in the loss variable and gradients in the grads dictionary. Compute # # data loss using softmax, and make sure that grads[k] holds the gradients # # for self.params[k]. Don't forget to add L2 regularization! # # # # When using batch/layer normalization, you don't need to regularize the scale # # and shift parameters. # # # # NOTE: To ensure that your implementation matches ours and you pass the # # automated tests, make sure that your L2 regularization includes a factor # # of 0.5 to simplify the expression for the gradient. # ############################################################################ loss, dscores = softmax_loss(scores, y) reg_loss = 0.0 pre_dx = dscores for i in reversed(range(self.num_layers)): i = i + 1 reg_loss = np.sum(np.square(self.params['W' + str(i)])) loss += reg_loss * 0.5 * self.reg pre_dx, dw, db = affine_relu_backward( pre_dx, cache['cache' + str(i)]) dw += self.reg * self.params['W' + str(i)] db += self.reg * self.params['b' + str(i)] grads['W' + str(i)] = dw grads['b' + str(i)] = db ############################################################################ # END OF YOUR CODE # ############################################################################ return loss, grads 检测网络是否overfitting 选择了一个三层的网络，小幅度改变learning rate和init scale 尝试去overfitting出现了一些问题不是太能overfitting我不知道为什么 update rules在得到了back出来的dw之后，就需要用这个dw对w进行update，这里有一些比较常见的update方法 普通的update 仅仅沿着gradient改变的反方向进行(反方向是因为计算出来的gradient是上升的方向)x += - learning_rate * dx SGD + momentumhttp://cs231n.github.io/neural-networks-3/#sgd 是对这个update一点物理上比较直观的理解（其实名字叫做动量） 可以理解为这个东西是在一个平原上跑的一个球，我们需要求的w是这个球的速度，得到的dw是这个球的加速度，而这个球的初速度是0 可以理解为这个球找最低点的时候，除了每步按dw update，还在上面加上了前面速度的影响，也就是加上了惯性！123# Momentum updatev = mu * v - learning_rate * dx # integrate velocityx += v # integrate position Nesterov Momentum(NAG) 在原来的基础上：真实移动方向 = 速度的影响（momentum）+ 梯度的影响 （gradient） 现在：既然我们已经知道了要往前走到动量的影响的位置，那么我根据那个位置的梯度再进行update，岂不是跑的更快！ 总的来说就是考虑到了前面的坡度（二阶导数），如果前面的坡度缓的话我就再跑快点，如果陡的话就跑慢点123v_prev = v # back this upv = mu * v - learning_rate * dx # velocity update stays the samex += -mu * v_prev + (1 + mu) * v # position update changes form cs231n/optim.py 加入了新的计算update的方法 具体的原理还没有看，但是计算就是这样计算的 12345678910111213141516171819202122232425262728293031def sgd_momentum(w, dw, config=None): """ Performs stochastic gradient descent with momentum. config format: - learning_rate: Scalar learning rate. - momentum: Scalar between 0 and 1 giving the momentum value. Setting momentum = 0 reduces to sgd. - velocity: A numpy array of the same shape as w and dw used to store a moving average of the gradients. """ if config is None: config = &#123;&#125; config.setdefault('learning_rate', 1e-2) config.setdefault('momentum', 0.9) v = config.get('velocity', np.zeros_like(w)) next_w = None ########################################################################### # TODO: Implement the momentum update formula. Store the updated value in # # the next_w variable. You should also use and update the velocity v. # ########################################################################### v = config['momentum'] * v - config['learning_rate'] * dw w += v next_w = w ########################################################################### # END OF YOUR CODE # ########################################################################### config['velocity'] = v return next_w, config 可以看出来最终的结果会比普通的SGD上升的更快 分别又尝试了RMSProp and Adam]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
        <category>CS231n作业</category>
      </categories>
      <tags>
        <tag>Fully Connected Net</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于空间投影增强（SAR）的论文]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%85%B3%E4%BA%8E%E7%A9%BA%E9%97%B4%E6%8A%95%E5%BD%B1%E5%A2%9E%E5%BC%BA%E7%9A%84%E8%AE%BA%E6%96%87%2F</url>
    <content type="text"><![CDATA[相关介绍链接koike lab roomAlive 关于opencv的fisheye calibration：http://ninghang.blogspot.com/2012/08/fish-eye-camera-calibration.html 关于calibration的视角的问题，matlab可以找到全部视角：https://www.mathworks.com/help/vision/ug/fisheye-calibration-basics.html DeepCalib: A Deep Learning Approach for Automatic Intrinsic Calibration of Wide Field-of-View Cameras（CVMP ‘18）使用深度学习对fish eye相机的视野进行补全。 文章中公开的code和其他资料 Abstract 广角相机的calibration在各种各样的地方都有应用 3D重建 image undistortion AR camera motion estimation 现在存在的calibration都需要多张图片进行校准（chessboard） 提出了一种完全自动的标定方法，基于CNN 在网上找了非常多的omnidirectional的图片进行训练，生成了具有100多万张图片的dataset Intro 广角相机的calibration最重要的是测量 intrinsic parameters 两个wide FOV的重要参数：focal length &amp; distortion parameter 现存的calibration方法有很多限制： 需要一个object的多个角度的观察 需要观察一个特定的structures 在多张图片中观察相机的移动 现在最有名的方法是chessboard 他们提出的方法可以解决上述的问题，并且针对网上下下来的照片也可以用 主要方法 一个CNN with Inception-V3 architecture 目标 收集具有不同intrinsic parameters的图片，然后自动生成具有不同的focal length和distortion的图片（没懂） 对比不同的CNN结构 related work 以前存在的calibration方法主要可以分成四个不同的部分 最常使用的就是棋盘一类的，需要观察一张图片的不同部分，从而得到结果。问题主要是出在比价麻烦，而且无法对野生的照片进行calibration 基于图片上面的geometric structure，line，消失的点等。不能处理general environments self-calibration（自身还有一些容易收到影响的问题） 需要多张图片 需要camera motion estimation 基于DL的，但是都是解决了部分问题 没有把参数全都估计出来 dataset是从prespective的图片生成回来的，会有不完整的部分（但是他们的很完整而且会有很多应用） Approach选择model -&gt; 自动生成large-scale dataset -&gt; network的structure Projection &amp; distrotion model（考虑生成dataset的机器） 广角相机需要具体的projection model把3D的世界map到图片里面去 考虑了几个model Brown-Conrady’s model(1971) 在实际应用里面不适合广角相机的大的distortion hardly reversible division model [Fitzgibbon 2001] 只是为了fisheye设计的，对相机没有普适性 impossible to revert 这篇文章里面的model unified spherical model [Barreto 2006; Mei and Rives 2007] 原因 fully reversible 可以解决很大的distortion projection和back-projection都admit closed-form solution -&gt; 计算效率非常高（没怎么看懂） generation dataset 因为根本做不到并且还没有那么大的dataset，所以他们打算人工合成一些(synthetically) 没有选择用prspective的图片生成 在普通的图片里面加上distortion会把图片里应该看不到的地方看到（边缘都会变成黑色的） -&gt; 生成的图片不真实 使用panoramas得到图片 因为全景图都是360度的，那么多少度的广角都能驾驭 可以假设把相机放在任何地方 对于给的一张全景图，可以自动生成不同焦距，不同distortion的图片，这样就得到了很大的dataset network architecture Inception-V3 structure 基于上面的，实践了三种不同的网络 一层网络，输出两个不同的结果，一个是f一个是distortion DualNet，由两个独立网络组成，一个输出f，一个输出distortion，这两个值是相互独立的。 SeqNet，两个连在一起的网络，先从A网络里得到f，再把图片和f放进B得到最终的distortion 解决问题： classification regression resultnet的参数 net在imageNet上面pre-train了，然后再进行了进一步的训练 evaluation对比上面不同三个网络的performance user study估计出来的结果很难说明到底是不是成功的undistort了，所以设计了user study Combining Multiple Depth Cameras and Projectors for Interactions On, Above, and Between Surfaces（‘2010）感觉算是比较最早的SAR的部分，重点就是用多个视角的depth camera来捕捉用户的动作，完成相应的交互，不知道在桌子上的投影和在墙上的投影是怎么实现的 abstract 可以交互的displays和surface 可以投影到非常规的投影表面上面去 可以把这些东西扔来扔去，之类的 Intro the user may touch to manipulate a virtual object projected on an un-instrumented table（这个现在已经不新鲜了） office size room depth camera的妙用 这个空间的任何地方都是surface，都可以投影 整个空间是一个大的电脑 可以投影到user自己的身上去-&gt; 可以投影到用户的手上 3D mesh data 硬件构成：multiply的depth camera&amp; projector 支持的interaction 可以交互的非显示器部分（比如墙壁或者桌子） 所有的部分可以连接成一个可交互的部分，可以通过肢体来进行两个屏幕之间的交互（同时摸这两个东西他就会换位置） 可以从display上面pick up出东西来 检测出用户的动作来，支持动作的交互 implement 在天花板上装了三个depth camera和三个projector，可以看到交互的地方，不需要特别精准的calibration PrimeSense camera，有IR和RGBcamera depth image可以用来分离静止的物体 calibration both the cameras and the projectors are registered with the real world. camera a fixed grid of retro-reflective dots 3D camera pose estimation de- scribed by Horn[13] interactive space calibration之后camera就可以捕捉real time的3D mesh model 因为camera和projector一起校准过了，所以投影就可以正确的投影在相应的地方了 根据mesh model可以得到手的三维图形，根据这个图形就可以知道手在touch哪个地方了 在tracking上面用了更简单的算法：[28] [29] 直接对3D的mesh进行操作比较复杂，所以对2D的画面进行了操作 virtual camera first transforming each point in every depth camera image from local camera to world coordinates, and then to virtual camera coordinates by virtual camera view and projection matrices. z方向的坐标由xy写出来 -&gt; 把一张深度图片压成了一个2D的图片 结合多个角度判断用户的最终动作 用上方的摄像机的图片判断用户是不是同时接触两个东西了 空间里的mene -&gt; 在特殊的一个地方有投影 RoomAlive: Magical Experiences Enabled by Scalable, Adaptive Projector-Camera Units(UIST ‘14)感觉是一个比较完全的屋内投影的例子了 Abstract 可以动态的适应任何的屋子 touch, shoot, stomp, dodge, steer投影上去的东西，以及和物理的环境交互 projector-depth camera unit -&gt; 所以就不需要特别多的calibration（可以重点看看这个unit是怎么制作的） Intro 做了一个游戏系统 projector和depth camera一体的东西 cover the room’s walls and furniture with input/output pixels track用户的动作，并且根据动作在屋子里面生成对应的东西 capture &amp; analyze屋子里的结构，得到房间里面的墙以及地板之类的特征 a distributed framework for tracking body movement and touch detection using optical-flow based particle tracking [4,15], and pointing using an infrared gun [19]. -&gt; 其实还不是没有依据视觉来捕捉这个东西 居然装了6个相机-投影仪的unit （procam） related workSpatial Augmented Reality (SAR) use light to change appearance physical objects illumiroom -&gt; 非常喜欢这个idea projection mapping很多都需要在特定的东西上面mapping -&gt; 但是这个可以在整间屋子的任意部分mapping System unit -&gt; color camera + IR camera emitter + wide FOV projector + computer in a large living room (说明这种研究里面屋子的大小也非常的重要) + 6 units plug-in to the Unity3D commercial game engine （怪不得能做游戏 硬件 wide field of view projectors 每个部分connected to他自己特定的电脑 所有的部分都装在房间的屋顶上 auto calibration 并不需要calibration所有的相机 在units之间有一部分的overlap，所以东西在校准的时候观察同一个东西就行了？ 用opencv的校准function chain together所有的部分然后得到了各个相机的关系 auto scene analysis 所有的unit得到的深度信息，生成之后寻找连续的平面（墙，地板等等） Hough transform（并不会这个东西） 游戏 unity3D的plug-in 游戏设计者只需要在设计界面里添加东西就行了 mapping 事实渲染整个东西的任务没有完全解决 4个技术 content in a uniformly random way 哈。。。居然是随机投影出来的 针对不同类型的被投影的东西，会根据不同的原理出现在不同的地方（比如石头只会出现在地面上） 投影的东西针对用户现在的位置，只投在用户自己看得到的地方 在移动屋子里的物理物品的时候，改变屋子的部分 tracking user interface body movement, touching, stomping, pointing/shooting and traditional controller input [4,15]捕捉了depth map -&gt; ‘proxy particles’,就是动作游戏里面的体感捕捉的算法 -&gt; tracked by using a depth-aware optical flow algorithm gun的input选择了红外枪 也支持寻常的游戏手柄 rendering RoomAlive tracks the player’s head position and renders all virtual content with a two-pass view dependent rendering 这部分主要讲游戏怎么设计的limitation calibration errors！这样在交叠的地方会出现重影 system latency 延迟QAQ 在overlap的sensors上面解决tracking issues Peripheral Expansion of Depth Information via Layout Estimation with Fisheye Camera( ‘16)从RGBD鱼眼相机提取深度信息（但是这个用了多个相机的system） abstract 一个普通的RGB相机和一个fish eye，把视角扩展到了180° developed a new method to generate scaled layout hypotheses from relevant corners, combining the extraction of lines in the fisheye image and the depth information overcome severe occlusions. intro 主要就是把现有的RGB fisheye camera和Depth camera结合起来，得到鱼眼的深度信息 Pedestrian Detection in Fish-eye Images using Deep Learning: Combine Faster R-CNN with an effective Cutting Method(SPML ‘18)用鱼眼相机和RCNN来检测行人（感觉这个检测的目标比较小） -&gt; 怎么感觉挺水的 abstract 鱼眼相机的边缘扭曲问题 -&gt; rotary cutting to solve the problem 把相机分成了边缘部分和中间部分 Method 裁剪图片 绕着鱼眼相机的中心旋转，30度，12次 每次旋转完截取三组图片，分别是靠边缘的和靠中心的 -&gt; 更好检测人群（垂直的） 使用这些裁剪的图片training]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>projection mapping</tag>
        <tag>space augumented</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019 1Q AR笔记]]></title>
    <url>%2F2019%2F04%2F09%2F2019Q1AR%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[整体步骤 检测marker 为他计算计算6DOF pose render 3D 图片 把图片和marker组合在一起 slides学习opengl(学习老师的cpp代码风格) Ex1:检测marker的四个基础点打开相机 注意初始化 videocapture 应该是在while的循环之前的 thresholding 函数 cv::threshold(…) src dst thres的值，也就是阈值的边界值 double maxval，在最后一个参数是binary的时候，确定binary的最大值 type，二值图，反二值图，保留原色等乱七八糟的 注意binary之前要先 cvtcolor到灰度图！！！ cv::adaptiveThreshold &lt;- 试试这个函数的作用，不用自己设置threshold了 并不想set这些hypers manully 除了寻常需要设置的东西之外，还需要 adaptiveMethod block size（需要被用来计算threshold的value） C：需要被从整体中减去的一个constant 有些变量的地方用到了const &lt;- 感觉应该学学老师的编程风格detect connected componentscv::findContours 函数 图片 contours vector&lt;std::vector&lt;cv::Point&gt; &gt; hierarchy vector&lt;cv::Vec4i&gt;，contour的拓扑学信息 mode （注意在这里选择要外轮廓还是内外都要） method：估计contour的方法 offset（当从ROI提取轮廓然后在整张图片里面分析的情况） 去除过小的contour12345678910vector&lt;vector&lt;Point&gt;&gt; :: iterator itc = contours.begin(); while(itc != contours.end())&#123; if(itc -&gt; size() &lt; 60)&#123; itc = contours.erase(itc); &#125; else&#123; itc++; &#125; &#125; 老师的代码里面是先进行了估计，计算了bound的面积，然后根据 面积大小，占整张图片的百分比 几个角 cv::isContourConvex ：检查这个marker的凸性，毕竟形状不能是凹的，直接输入这个多边形的array，输出的就是bool 估计contour的多边形 approxPolyDP 被估计的contour 估计出来的的多边形 估计的参数，影响估计的精度 -&gt; const auto epsilon = 0.05 * cv::arcLength(contour, true); 计算一个curve的长度 closed，估计出来的多边形是不是封闭的 画出来只有四个角的多边形 drawContours() 图片 需要画的轮廓s （注意这是这张图片里面的所有轮廓） 需要画的index thickness 线的 线得种类 Optional information about hierarchy. maxLevel Maximal level for drawn contours. If it is 0, only the specified contour is drawn. If it is 1, the function draws the contour(s) and all the nested contours. If it is 2, the function draws the contours, all the nested contours, all the nested-to-nested contours, and so on. This parameter is only taken into account when there is hierarchy available. offset：可选 老师用的方法是计算了各个点和计算了各个边，所以可以画出来边上还有好多点的结果 一种神奇的定义颜色的方式，直接随机出来 const cv::Scalar kEdgeColor(rand() &amp; 255, rand() &amp; 255, rand() &amp; 255); -&gt; 这样的话出来的每一帧的框的颜色都会改变![] 用cv::polylines来画出来polys的curve，并且要画closed的 画出来图片的delimiters(为下一步做准备) 目的：从一个corner到另一个corner的方向vector 步骤 首先在corner上面用circle画出来 检查每个edge 每个edge上有6个点，然后计算两个corner之间的dx和dy的方向，除以部分的数量（7）就是每个小块的方向，然后把这个小块重复6次12const double dx = (double)(contour_approx[(i+1)%kNumOfCorners].x-contour_approx[i].x)/(double)(kNumOfEdgePoints+1);const double dy = (double)(contour_approx[(i+1)%kNumOfCorners].y-contour_approx[i].y)/(double)(kNumOfEdgePoints+1); 第一部分结束后的完整代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#include "ARdetection.hpp"ARDetection::ARDetection(void)&#123; &#125;Mat ARDetection:: SearchMarkers(Mat frame)&#123; Mat img_gray; Mat dst; // threshold之前要先改成灰度图 cvtColor(frame, img_gray, CV_BGR2GRAY); adaptiveThreshold(img_gray, dst, 255, ADAPTIVE_THRESH_MEAN_C, THRESH_BINARY, 33, 5);// threshold(img_gray, dst, 104, 255, THRESH_BINARY); imshow("lalala", dst); waitKey(1); // 每个点，一圈点事是一个contour，一堆kcontours vector&lt;vector&lt;Point&gt;&gt; contours; vector&lt;Vec4i&gt; hierarchy; findContours(dst, contours, hierarchy, RETR_LIST , CHAIN_APPROX_NONE); // 检测图片过小部分// vector&lt;vector&lt;Point&gt;&gt; :: iterator itc = contours.begin();//// while(itc != contours.end())&#123;// if(itc -&gt; size() &lt; 60)&#123;// itc = contours.erase(itc);// &#125;// else&#123;// itc++;// &#125;// &#125; vector&lt;vector&lt;Point&gt;&gt; polys(contours.size()); for(int i=0; i &lt; contours.size(); i++ )&#123; // 根据每个轮廓调节这个参数的大小 const auto epsilon = 0.05*cv::arcLength(contours[i], true); approxPolyDP(contours[i], polys[i], epsilon, true); // if(polys[i].size() == 4)&#123;//// 用这个函数画不出来斜的东西//// rectangle(frame, polys[i][0],polys[i][2], Scalar(0,255,0));// drawContours(frame, polys, i, Scalar(255,0,0), 5, 8, vector&lt;Vec4i&gt;(), 0, Point());// &#125; Rect rect = boundingRect(polys[i]); const int marker_size = rect.area(); const int ImageSize = img_gray.cols * img_gray.rows; const int marker_size_min = int(ImageSize * 0.02); const int marker_size_max = int(ImageSize * 0.95); const int marker_corners_num = 4; const bool is_vaild = (marker_size &gt; marker_size_min) &amp;&amp; (marker_size &lt; marker_size_max) &amp;&amp; (polys[i].size() == marker_corners_num) &amp;&amp; isContourConvex(polys[i]); if (is_vaild == false) continue; // 这样画出来的是随机的颜色的 const Scalar EdgeColor(rand() &amp; 255, rand() &amp; 255, rand() &amp; 255); polylines(frame, polys[i], true, EdgeColor,5); // 下面需要把每个边分成6个部分 for(int j = 0; j &lt; marker_corners_num; ++j)&#123; const int edge_point_num = 6; const int circle_size = 5; circle(frame, polys[i][j], circle_size, Scalar(0,255,0),FILLED); const double dx = (double)(polys[i][(j+1)%marker_corners_num].x - polys[i][j].x)/(double)(edge_point_num + 1); const double dy = (double)(polys[i][(j+1)%marker_corners_num].y - polys[i][j].y)/(double)(edge_point_num + 1); for(int k = 0; k&lt; edge_point_num; ++k)&#123; const double edge_point_x = (double)(polys[i][j].x) + (double)(k+1)*dx; const double edge_point_y = (double)(polys[i][j].y) + (double)(k+1)*dy; Point edge_point((int)edge_point_x,(int)edge_point_y); circle(frame, edge_point, circle_size, Scalar(0,0,255),-1); &#125; &#125; &#125; return frame;&#125; 第一部分运行之后的结果 Ex2. find marker precisely 现在有corner，corner之间的line，这个line还被分成6个部分（~因为大小是6x6？的= 两个边 + 中间四个格？？~） 光检测边缘是不够的，想知道这个边缘实际是什么样子的 现在只知道虚线的部分是什么样子的 并且现在已经把每个边都分部分了 -&gt; 画出来垂直的分块的线，找到这个线和颜色突变的交点，重新画出来新的线（实线） 希望找到颜色突变的地方 但是实际上的颜色不是突变的，是白 -&gt; 灰 -&gt; 黑 操作步骤 预准备 在每个side找六个点 在边上提取三个像素宽度的stride cv::GetQuadrangleSubPix() -&gt; 不会用！ 从输入的array得到四边形 src输入图像 dst提取出来的四边形 变换的矩阵 Sober operator 图像处理里面的常用算子 -&gt; 主要用于边缘检测，用来运算与灰度的相似值 包含两组3x3的矩阵，中间的3x1的0，分别为横向和纵向，另外两面对称 然后与图片做卷积，分别计算x方向和y方向的灰度值 然后把Gx和Gy求平方和的根，最后得出来这个像素点的灰度值（或者有的时候也可以用绝对值来计算，这样计算的消耗小一点） 步骤 在每个stripe里找到最高的change 对这个change和她周围的点（在原来的曲线上），找到一个新的二次曲线 找到这个曲线的顶点（一阶导数） 如何得到图片的subpixel color不是原来的方方正正的，而是沿着那个直线方向的新的方方正正 就是取各个颜色在面积上的平均， 老师的代码 sublixSampleSafe -&gt; 这个函数输入测试的图片（gray和已经得到的subpix点 把这个点求floor，int，得到基准点，然后检查是不是在图片里面（不是的话返回gray，127） 如果在图片里面的话计算出来实际的坐标 确定marker的id corner detection exact sides 找到沿着刚才计算出来6个点的一条线fitLine precise corner 从各个边的交点计算精确的corner（因为各个边已经很精确了） Marker Rectification 创建一个6x6 pix的ID图片 (-0.5,-0.5) to (5.5,5.5) 从原图片的perspective warp到Id image cv::getPerspectiveTransform or cv::warpPerspective 需要找到的是linear transformation]]></content>
      <categories>
        <category>AR</category>
        <category>上课笔记</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>AR</tag>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Notes for papers about smart kitchen]]></title>
    <url>%2F2019%2F04%2F08%2Fkitchen%2F</url>
    <content type="text"><![CDATA[Choptop: An Interactive Chopping Board2018 abstract 一个可交互的案板 可以给用户菜谱的指导，承重，计时 用户可以通过按案板来进行对画面的操作 上面就是长成上图的样子，案板底下充满了各种传感器。 Intro 针对学生不会自己做饭，不吃新鲜的饭的问题，缺时间 -&gt; 一步一步的把怎么做饭写出来了，包括图片动画等东西 built-in timer用来每一步计时 使用mobile device来提高菜单的交互性 考虑到手的脏等问题，所以不是按屏幕而是按案板（这里考虑能不能像pac pac一样，用手势操作） load sensors，可以解决称重的问题 思路 主要目的是一种新的学习做饭的方法 （作为做饭有天赋的人，我认为这样没有灵魂！） related work smart kitchen Research has aimed to improve the cook- ing process, promote healthier eating and make it simpler to procure ingredients，大家都从不同的角度实现智能厨房 他这个论文的东西成本不是特别高也不是特别大（是在嘲讽我吗） load sensing 之前已经用了很多force的传感器 之前也有用过带重量传感器的案板，以及带扭矩传感器的刀[9] 他们认为camera没有什么用，并且把所有的硬件都藏起来了 装这个senser的方法参考了[12] Design硬件 整个硬件是self-contained的 屏幕是单片机控制的 力量传感系用 检测按压用的是edge detection -&gt; 防止检测到其他东西（原理不是太懂） UI The interface updates based on the information delivered from the recognition engine 成功之后还会有声音 按案板的不同部分就可以往不同的方向移动 user study 找了十三个人，准备一道沙拉 [3]里面找到了一个调查问卷System Usability Scale future SVM训练了74%的测试率（好低），提高正确率 提高自动翻页（？ 用用户的手机来达到屏幕的作用 进一步分user study CookTab: Smart cutting board for creating recipe with real-time feedback2012 abstract 考虑到很多厨师做饭随心所欲，而且不会记录下来精准的用量 一个可以记录下来用量的案板 intro 专门针对切菜部分的记录的软件 记录用的材料的名字，菜量，视频和调味方法，然后会有real-time的feedback related work [3]可以记录视频，声音，用的camera和mic 加重量感应的， [2]四个承重的模块，加速度传安琪 但是他们的系统会有real-time的feedback 不好意思好像就是在pad上切菜 Enabling Nutrition-Aware Cooking in a Smart KitchenCHI 2007（大概只能看个概念了） abstract 目标：health cooking（是不是大家的目标都是那么伟大） sensors，detect cooking activities, and digtail feedback intro 主要目标就是如果人加东西假的过量了或者怎么着，就会提醒 Smart Kitchens for People with Cognitive Impairments: A Qualitative Study of Design RequirementsCHI-2018]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>Smart Kitchen</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于mac消去分区]]></title>
    <url>%2F2019%2F04%2F08%2F%E5%85%B3%E4%BA%8Emac%E6%B6%88%E5%8E%BB%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[最近刚接手了别人的mbp，他因为装双系统分区之后，windows分区无法消去。试了一圈之后发现只要再新建一个分区，然后再一起合并就可以了。]]></content>
  </entry>
  <entry>
    <title><![CDATA[关于Python的字典多key，value返回key]]></title>
    <url>%2F2019%2F04%2F05%2F%E5%85%B3%E4%BA%8EPython%E7%9A%84%E5%AD%97%E5%85%B8%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF%2F</url>
    <content type="text"><![CDATA[多个keys1dict = &#123;(key11,key12): value&#125; 大概就是长这个样子的，key的个数多少没有限制，访问value的时候1dict[(key11,key12)] 多个value1dict = &#123;key1:(value1, value2)&#125; 访问的时候大概就是这么取值12dict[key]dict[key][index] 从value找到key 先通过list(dict.key())获得所有的key，变成一个list list(dict.value())得到所有的value的list 上面这两个list的index相同，先获取value的index，然后再作为key的index去key里找 例子：12dict = &#123;'a': 1, 'b': 2&#125;list(dict.key())[list(dict.value()).index('1')]]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>字典</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Human Computer Interaction笔记]]></title>
    <url>%2F2019%2F04%2F04%2FHCI%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Introduction 50% 出勤和 50% report koike森森还有assignment History 1945 Vannevar Bush memex的概念，二战末提出了一种信息机器的设想（个人图书馆） 这种机器内部用微缩胶卷（microfilm）存储信息，也就是自动翻拍，可以不断往里面添加新的信息；桌面上有阅读屏，用来放大阅读微缩胶卷；还有许多个按钮，每一个按钮代表一个主题，只要按一下，相应的微缩胶卷就会显示出来。每一个胶卷内部还记录着相关的其他胶卷的编号，可以方便地切换，形成同主题阅读。在Bush博士的设想中，这种机器还可以与图书馆联网。通过某种机制，将图书馆收藏的胶卷，自动装载到本地机器上。因此，只通过这一个机器，就可以实现海量的信息检索。from 百度百科 as we may think：同时提出了wearable电脑 1946 Eniac 第一个计算机 没有keyboard和display，只能手动 1951 UNIVAC 可以I/O 先在纸条上打孔，然后再放进去读 Ivan Sutherland 1963 SketchPad，display上面有图像了，并且可以对画面进行操作 可以用光笔操作，不是用键盘操作了 CAD鼻祖 第一个VR设备居然也是他做出来的 Sword of Damocles(1968) Douglas Engelbart 居然出现了鼠标，装了rotatory wheels（竖着的那种），可以在两个方向移动（所以装了两个吗？） Alan Kay PC之父 1972 Dynabook，card board做的，因为CPU和GPu太大了，屏幕也没有，并不是真的 1996年东芝做了个叫这个名字的PC 1973 Xerox Alto real working machine 1981 Xerox Star 出现了桌面系统 GUI Ted Nelson Hypertext Editing System -&gt; pen to jumo to another page Steve Jobs &amp; Bill Atkinson HyperCard 1987，同类的信息都在同一张卡上，然后所以的卡都连在一起，可以在卡中间jump。事情就变得非常简单了 Tim Berners-Lee father of WWW （World Wide Web） Richard Bold put that there可以用手势交互，语言交互 非常大的一个display和projector Mark Weiser father of the concept of Ubiquitous conputing(1991) 预言了以后大家家家有电脑 Jaron Lanier VPL data glove &amp; HMD 1989，手套里面有纤维 I/O的硬件如何组合 -&gt; 新的HCI方式 design &amp; evaluationACM SIGCHI What’s HCI CS design 是一个交叉学科 学会 CHI -&gt; 更注重想法，和转化成实现 UIST -&gt; 更注重implement IEEE/ACM Ubicomp CSCM 重要性 保证安全性，提升生活质量 在商业上的产品化 推荐书 The Design of Everyday things 核心思想Affordence: 人想象的这个东西的用途和实际的用途，让用户看到这个东西就知道是干什么用的 比如傻屌的看见按键不知道按哪个的瓦斯炉 方向不同的车座靠背调节 根本不知道哪个是哪个的电灯开关 想法 mapping ui to real layout design is stupid 七个准则 by Norman 8 golden rules by. Shneiderman consistency（一致性） -&gt; 比如mac的pull down最下面都是quit，大家的位置都差不多 Short-term memory 比如菜单里面的个数 7+-2 magic number Bringing Design to software T.Winograd GUI &amp; hypermediaGUI CUI -&gt; GUI CUI: I: keyboard O: charracters in display GUI I: keyboard + mouse O: bitmap in display desktop like a real office emvironment (metaphor) document,folder,trash 对于没有用过电脑的人来说非常容易理解 visualizing to icons operating mouse Jobs居然copy了这个东西 跟现在的也没有太多概念（standard interface for computer) pros visual by icon，因为视觉看出来的东西比较好理解 direct manipulation interaction abstract by folders cons number of icons make user confused more computing more physical space typing is faster with keyboard 其他的一些想法 room metaphor[henderson86] different romms for different task multiply desk (就像mbp的多个桌面一样) based on user studys &lt;- how they use each applications 并没有变成主流，哭哭 超整理法 super-organizing metaphor 如何整理物理文件 organize by time, not name sequentially, not hierarchically implemented by Freeman -&gt; Lifestream GUI的一个特征WIMPwindow, icon, menu, pointer（like mouse） 整体来看 苹果把pull down在左上角，因为从左往右拉比较容易 windows: 因为不想和apple一样所以扔到底下了 difficult for icon 比如路上的标志设计的就很迷，大家都不知道是干啥的 direct manipulation 比如在删除东西的时候CHI需要自己输入，但是GUI可以直接拖进trash里面 WYSIWYGwhat you see is what you get PUI?I: recognizationO: large/ small displays PUI(perceptual)GUI -&gt; PUI PUI: using various input(sensors) GUI: mouse&amp; keyboard, not intuitive vision-based HCIwhy? natural &amp; intuitive? not special device, unwired multimodel application recognition detection &amp; recognition object &lt;-(detect) - object detection system(find the thing in the real world) object database &lt;-recognition- objection recognition system(know what it is) detect the hand colors（shapes?） infrared camera near infrared -&gt; vedio cameras(capture near infrared light to the object) far infrared -&gt; capture the heat hand location(手指在哪，手在哪) hand regions find the centre -&gt; morphlogical operation fingers -&gt; pattern matching(有很多不同的方法) tracking gesture recognition difficult segmentation of hands/body -&gt; depth camera recognition of 3D pose(occlusion) 如果用户转身了，手会被其他的东西挡住 detecting begin/end of gestures 一个非常重要的问题！ high-speed gestures (systems) pac！pac！ as many hands as possible advantages robust against light conditions real-time with 40 people with 2 hands No instruction necessary 3D gestures(for navigation in VR) 2 cameras recognise hand shapes pattern classification(NN) object recognition tag-based pre-registration of objects difficult to attached on something(unbralla, glove…) unnartual overlook based on color information(‘1991) 3D histogram(RGB) translation/rotation invariant(如果图片改变了方向或者变了，但是颜色信息还没变) 但是颜色相似的时候没法分辨 PTAM(‘2007) recgonize feature positions features &amp; markers gaze recognition infrared cameras &amp; LEDs pattern matching corners of eyes,mouse,shaping triangle -&gt; face direction 4/18interactive surface 例子 handheld:phone, tablet horizantal: desk vertical: wall digital desk(‘93) overhead projector + camera + desk metaDesk(‘97) -&gt; 用两个奇怪的方块，对这个map进行操作 LCD tabletop LCD -&gt; larger, thinner,lighter,higher resolusion, less expensive before that use projectors(dark) use as window? real glass is expensive then LCD principles of polarization 滤光吗，两个方向的（偏振片） 这样可以用来检测手，把手之后的背景光滤掉 非常好用 可以用来检测手 AR marker这样的东西实在是太丑了 design invisiable markers 把偏振光片减成了ar marker的样子，人看不到但是机器可以识别 background &amp; motivation traditional surfaces are planar &amp; regid difficult to make 3D surface photoelasricity -&gt; 透明的材料对不同载荷下颜色不同 -&gt; 也可以用来作为影响偏振光的因素，可以用来按，按下去光就能过去惹 electrical shock 为什么会有这种电人的display啊！（BIRIBIRI） beyond 2D surfaceCaytrick surface(‘18)4/22 information visualization更快，更精准的理解info(shape/ colors -&gt; information) SciVis &amp; InfoVis Sci 用户比较专业 用来理解专业的现象 physical data, measured data, simulation data Info abstract data 给人民群众看的，感觉更加直观 how to layout the data three issues scalability 如果我们想要vis info，如果data的量太大了，有些东西看起来就很复杂(eg.trees) limited display size human cant understand tech layout scalability filiter layout graph drawing 好看，economically（多级化的，中心辐射，引力型 -&gt; 不同关系的相斥，圆环状） tree structure TreeMap 5/9 Cognitive processwhy important 看到的不一定就是真实的 通过改变HCI，可以改变看到的东西的 Seven Stage Model]]></content>
      <categories>
        <category>HCI</category>
        <category>上课笔记</category>
      </categories>
      <tags>
        <tag>HCI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Xcode的breakpoint1.1问题以及打开摄像头]]></title>
    <url>%2F2019%2F04%2F04%2FXcodebreakpoint%2F</url>
    <content type="text"><![CDATA[最近上课又要捡起来c++了，半年前才换的mac用xcode没vs顺手，好几次遇到了挺神奇的错误。 thread 1 breakpoint 1.1这个问题其实就是你在代码里面自己加上了断点(breakpoint)，估计是不小心点到的。取消了断点就行 关于Xcode允许相机xcode的相机许可我之前折腾了一个下午才发现怎么搞。 首先，需要有一个允许相机的Info.plist文件，文件内容如下 1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;&lt;plist version="1.0"&gt;&lt;dict&gt;&lt;key&gt;NSCameraUsageDescription&lt;/key&gt;&lt;string&gt;Used to capture new image for photo effect&lt;/string&gt;&lt;key&gt;CFBundleName&lt;/key&gt;&lt;string&gt;$&#123;OPENCV_APPLE_BUNDLE_NAME&#125;&lt;/string&gt;&lt;key&gt;CFBundleIdentifier&lt;/key&gt;&lt;string&gt;$&#123;OPENCV_APPLE_BUNDLE_ID&#125;&lt;/string&gt;&lt;key&gt;CFBundleVersion&lt;/key&gt;&lt;string&gt;$&#123;OPENCV_LIBVERSION&#125;&lt;/string&gt;&lt;key&gt;CFBundleShortVersionString&lt;/key&gt;&lt;string&gt;$&#123;OPENCV_LIBVERSION&#125;&lt;/string&gt;&lt;key&gt;CFBundleSignature&lt;/key&gt;&lt;string&gt;????&lt;/string&gt;&lt;key&gt;CFBundlePackageType&lt;/key&gt;&lt;string&gt;FMWK&lt;/string&gt;&lt;/dict&gt;&lt;/plist&gt; 其中，NSCameraUsageDescription这部分就是打开相机的许可。 但是这个文件直接放在项目里是不行的，需要复制下来，打开products的路径，然后复制到这个路径里面，才可以成功的打开相机]]></content>
      <categories>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>Xcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于SVM的理解]]></title>
    <url>%2F2019%2F04%2F03%2F%E5%85%B3%E4%BA%8ESVM%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[本文参考支持向量机通俗导论内容 SVM到底是啥support vecttor machine，比如在二维平面上，要把一个东西分成两类，SVM就是平面上的一条直线，并且在这两类的正中间，离两边一样远。换句话说，学习策略是把间隔最大化，从而得到凸二次规划问题的解（虽然不是很理解，但是凸问题应该是比较好求解） 分类标准 logistic regression 线性分类器：x表示数据，y表示类别，分类器则需要在n维找到一个超平面hyper plane，超平面的方程就是W.T 也就是 W.T.dot(x) + b = 0 (令人震惊w居然是超平面的方程) 逻辑回归 逻辑回归就是从特征里面学到一个0/1的分类模型 模型的线性组合作为自变量，取值范围是负无穷到正无穷，所以使用logistic函数（竟然就是simoid函数把他们投影到（0，1）上面，得到的值就是y = 1的概率 线性分类器如果把分类的两类改成 -1和1（只是为了方便选了这个数字），其实就是把wx加了b 这时候的点的位置可以用 f(x) = wx + b表示，如果f(x)等于0，那么这个点在超平面上，如果大于0就是在1的类型里，小于0在-1的类型里 这时候问题变成了寻找间隔最大的超平面 function margin，geometrical margin函数距离 当平面上的点是 wx+b = 0 确定了以后， wx+b的绝对值就是点x到超平面的距离 同时 wx+b 的符号和 y（分类标签）的符号对比，如果一致的话是一个类别，不一致的话是另一个 -&gt; y(wx+ b)的正负来表示分类的正确与否 （也就是两个东西同号得正分类正确） 引出函数间隔的定义（这里的y是乘上对应类别的y，所以能得到绝对值） 在训练集中，所有点到超平面的距离的最小点就是function margin 几何距离 但是如果单纯这么评定，当w和b成比例改变的时候，函数间隔也会改变，所以还需要几何间隔上面的式子乘以y（对应类别的标签）就可以得到绝对值了。 也就是说几何margin的主要部分就是把之前的内容除了一个w的范数，变成了标准化之后的长度 最大间隔分类器 max margin classifier对于一组数据来说，超平面和数据点的距离越大，这个数据的分类确信度（confidence）就越高 最大的间距的目标函数即： max\gama， 其中gama是比所有其他间隔都短的函数间隔 如果让最小的函数间隔等于1（为了方便计算），然后求几何间隔，可以得知需要的目标函数变为最大化 1/||w||，其中w是超平面 深入SVM线性可分和不可分原始问题和对偶问题duality 之前的目标函数是 1/||w||，所以求这个的最大值，就是求1/2*||w||^2的最小值（这里求最大值就是求倒数的最小值，然后1/2和平方都是为了方便加的） 目标函数变成二次的，约束条件是线性的，凸二次问题，可以用QP（一个写的差不多的包） -&gt; 目标最优的时候loss 由于这个问题的结构，可以转换成对偶问题求解 给每一个约束条件加上一个拉格朗日乘子 alpha 把这个融合进入目标函数里面 当所有的约束条件都满足的时候，目标函数的结果就是之前需要求的目标函数。 再对这个目标函数（新的）求最小值，得到的结果就是本来需要求的最小值 最后，因为上面的问题不是很好求解，把它的max和min交换了一下，先求所有的间隔的最小值，然后再求这里面alpha条件可以满足的最大值，这两个问题就是对偶问题 d &lt;= p ，在某些条件满足的情况下这两个值相等，这时候求出来对偶问题就可以求出来原始问题的解 转换对偶问题的原因： 对偶问题更容易求解 可以引入核函数，这样可以直接引入非线性问题 K.K.T条件 上一段说的，满足对偶问题的解等价的条件就是KKT条件 KTT条件的意义：非线性规划问题（nonlinear processing）能有最优化解法的充要条件 这部分没有写证明，但是上面的求最值的问题可以被证明是满足KKT条件的问题，所以可以用解决对偶问题的方式来求解。 对偶问题的求解步骤参考内容 https://www.zhihu.com/question/21094489 https://blog.csdn.net/v_JULY_v/article/details/7624837]]></content>
      <categories>
        <category>图像处理</category>
        <category>Machine Learning</category>
        <category>SVM</category>
      </categories>
      <tags>
        <tag>SVM</tag>
        <tag>分类器</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment1之Image Features]]></title>
    <url>%2F2019%2F04%2F03%2FCS231Nassignment1Feature%2F</url>
    <content type="text"><![CDATA[目标 之前实现的都是写好了一个linear classifier然后直接对输入图片的raw pixel进行分类 这部分是先从raw data得到相应的图片特征，然后再对特征进行分类 前面的简单的setup和load data都和之前的一样。 Extract Features 对每张图片计算HOG以及在HSV的color space上面的hue channel。（这是两个不同的功能） HOG可以提取图片的texture的特征，忽略颜色的影响。而颜色的histogram表示的是颜色而忽略texture，颜色的特征会拉成一个新的vector然后进行分类。 如果我们把这两个东西结合可能会有更好的结果。 在这部分的代码里面，直接给出来了提取hog feature和color histogram的两个function，用这两个直接提取出了特征然后构成了一个新的extract_features，由图片内容和特征组成。 然后预处理了特征，减去平均值，除以std（这样大家都在同一个scale里面），最后加上了一个bias的dim 12345678910111213141516171819202122232425from cs231n.features import *num_color_bins = 10 # Number of bins in the color histogramfeature_fns = [hog_feature, lambda img: color_histogram_hsv(img, nbin=num_color_bins)]X_train_feats = extract_features(X_train, feature_fns, verbose=True)X_val_feats = extract_features(X_val, feature_fns)X_test_feats = extract_features(X_test, feature_fns)# Preprocessing: Subtract the mean featuremean_feat = np.mean(X_train_feats, axis=0, keepdims=True)X_train_feats -= mean_featX_val_feats -= mean_featX_test_feats -= mean_feat# Preprocessing: Divide by standard deviation. This ensures that each feature# has roughly the same scale.std_feat = np.std(X_train_feats, axis=0, keepdims=True)X_train_feats /= std_featX_val_feats /= std_featX_test_feats /= std_feat# Preprocessing: Add a bias dimensionX_train_feats = np.hstack([X_train_feats, np.ones((X_train_feats.shape[0], 1))])X_val_feats = np.hstack([X_val_feats, np.ones((X_val_feats.shape[0], 1))])X_test_feats = np.hstack([X_test_feats, np.ones((X_test_feats.shape[0], 1))]) 训练SVM来处理features用处理多个类别的SVM来给这些特征分类，得到的结果应该比直接分类得到的结果好。大概结果为0.44左右，注意这里面用的是grid search而不是random search 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# Use the validation set to tune the learning rate and regularization strengthfrom cs231n.classifiers.linear_classifier import LinearSVMlearning_rates = [1e-9, 1e-8, 1e-7]regularization_strengths = [5e4, 5e5, 5e6]results = &#123;&#125;best_val = -1best_svm = None################################################################################# TODO: ## Use the validation set to set the learning rate and regularization strength. ## This should be identical to the validation that you did for the SVM; save ## the best trained classifer in best_svm. You might also want to play ## with different numbers of bins in the color histogram. If you are careful ## you should be able to get accuracy of near 0.44 on the validation set. #################################################################################for lr in learning_rates: for rs in regularization_strengths: svm = LinearSVM() svm.train(X_train_feats, y_train, learning_rate = lr, reg = rs, num_iters = 1000, verbose = True) y_pred_val = svm.predict(X_val_feats) y_pred_train = svm.predict(X_train_feats) train_acc = np.mean(y_pred_train) val_acc = np.mean(y_pred_val == y_val) results[(lr, rs)] = (train_acc,val_acc) if val_acc &gt; best_val: best_val = val_acc best_svm = svm################################################################################# END OF YOUR CODE ################################################################################## Print out results.for lr, reg in sorted(results): train_accuracy, val_accuracy = results[(lr, reg)] print('lr %e reg %e train accuracy: %f val accuracy: %f' % ( lr, reg, train_accuracy, val_accuracy)) print('best validation accuracy achieved during cross-validation: %f' % best_val) 同时也可视化了不是这个类别却被分到这个类别的错误sample：123456789101112131415161718# An important way to gain intuition about how an algorithm works is to# visualize the mistakes that it makes. In this visualization, we show examples# of images that are misclassified by our current system. The first column# shows images that our system labeled as "plane" but whose true label is# something other than "plane".examples_per_class = 8classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']for cls, cls_name in enumerate(classes): idxs = np.where((y_test != cls) &amp; (y_test_pred == cls))[0] idxs = np.random.choice(idxs, examples_per_class, replace=False) for i, idx in enumerate(idxs): plt.subplot(examples_per_class, len(classes), i * len(classes) + cls + 1) plt.imshow(X_test[idx].astype('uint8')) plt.axis('off') if i == 0: plt.title(cls_name)plt.show() （感觉自己训练了一个傻子） 用两层的nerual net试试看 首先去除上文中bias的dim 然后交叉训练，找到最好的参数 这部分半天loss下不去的原因主要是lr选的太小了 1234567891011121314151617181920212223242526272829303132333435363738394041424344from cs231n.classifiers.neural_net import TwoLayerNetinput_dim = X_train_feats.shape[1]hidden_dim = 500num_classes = 10hidden_size = [300,400,500,600]learning_rate = [1,1e-1,1e-2]reg = [1e-4,1e-3,1e-2]# net = TwoLayerNet(input_dim, hidden_dim, num_classes)best_net = Nonebest_acc = -1result = &#123;&#125;################################################################################# TODO: Train a two-layer neural network on image features. You may want to ## cross-validate various parameters as in previous sections. Store your best ## model in the best_net variable. #################################################################################for lr in learning_rate: for hidd in hidden_size: for rs in reg: net = TwoLayerNet(input_size, hidden, num_class) status = net.train(X_train_feats, y_train, X_val_feats, y_val, num_iters=1200, batch_size=400, learning_rate=lr, learning_rate_decay=0.95, reg=rs, verbose= True) val_acc = (net.predict(X_val_feats) == y_val).mean() result[(lr, rs, hidd)] = (val_acc) if val_acc &gt; best_acc: best_acc = val_acc best_net = net# print(result)# for lr, rs, hidd in sorted(result):# val_accuracy = result[(lr, rs, hidd)]# print('lr %e reg %e hidden_units %e val accuracy: %f' % (# lr, rs, hidd , val_accuracy))print('best validation accuracy achieved during cross-validation: %f' % best_acc)print('best parameter is :',list (result.keys()) [list (result.values()).index (best_acc)])################################################################################# END OF YOUR CODE ################################################################################# best validation accuracy achieved during cross-validation: 0.605000best parameter is : (1, 0.0001, 500) 一点感觉 感觉要是lr太小的话，即使增加iteration的次数，后面的改变也不大 lr最基础的范围应该先定下来 最后换了换参数居然训出来了60%的val正确率 test的正确率在55.8左右]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
        <category>CS231n作业</category>
      </categories>
      <tags>
        <tag>Image Feature</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment1之two_layer_net]]></title>
    <url>%2F2019%2F04%2F02%2FCS231Nassignment1twolayernet%2F</url>
    <content type="text"><![CDATA[目标 Implement a neural network with fc layers for classifiction Test it on CIFAR-10 dataset 初始化auto-reloading external modules 定义relative error123def rel_error(x, y): """ returns relative error """ return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y)))) 这里插入一下np.max和np.maximum的区别 max是求序列的最值，可以输入一个参数，axis表示的是求最值的方向 maximum至少输入两个参数，会把两个参数逐位比较，然后输出比较大的那个结果 但是好像在这里的使用上面，说明x和y不是一个单独的值，应该是两个数组 12345&gt;&gt; np.max([-4, -3, 0, 0, 9])9&gt;&gt; np.maximum([-3, -2, 0, 1, 2], 0)array([0, 0, 0, 1, 2]) 不是很理解这里为什么要除以x+y 设置参数cs231n/classifiers/neural_net.pyself.params储存了需要的参数，参数都被存储在dict里面，一个名字对应一个内容 两层神经网络的参数如下： W1，第一层的weights，（D，H），其中H是第二层的neruon的个数。因为只有一层的时候，D个输入对应C个输出，现在有两层的fc，对应的输出就是第二层的units个数 b1，第一层的bias，（H，） W2，第二层的weights，（H，C） b2，第二层的biasbias都需要初始化为相应大小的0，weights初始化成0-1之间的比较小的数字 Forward pasa计算scores 这部分非常简单，两次Wx+b，并且在第一次之后记得激活就可以了 激活函数用的relu，内容就是score小于0的部分让他直接等于0 计算loss 这里用的是softmax计算loss，和softmax的作业内容一样，将所有的scores exp，求占的百分比，求出来的部分-log，然后把所有的求和 这里用到了boardcasting的问题，注意（100，1）这样的才可以boardcasting，（100，）的是一维数组，需要把它reshape成前面的样子才可以 这里最后的结果还总是差一点，最后发现是因为regularzation的时候多乘了0.5，看题呜呜呜 Backward pass 由于b是线性模型的bias，偏导数是1，直接对class的内容求和然后除以N就是最终结果 对W求导的时候需要用到链式法则，然后直接代码实现一下就行了 这里遇到的主要问题是loss的值会影响他估计的值，因为loss的regularzation改了，所以答案一直对不上。 Training predict 训练和之前写的差不多，训练网络，主要包括写training部分的随机mini-batch和更新weights，记得lr更新的时候要带负号 预测也差不多，算出来scores，找到最大的score就是分类的结果。注意找最大的时候要用argmax，找到的是最大的东西的indice，不然得到的是得分12345678910111213net = init_toy_model()stats = net.train(X, y, X, y, learning_rate=1e-1, reg=5e-6, num_iters=100, verbose=False)print('Final training loss: ', stats['loss_history'][-1])# plot the loss historyplt.plot(stats['loss_history'])plt.xlabel('iteration')plt.ylabel('training loss')plt.title('Training Loss history')plt.show() 使用写好的来训练CIFAR-101234567891011121314input_size = 32 * 32 * 3hidden_size = 50num_classes = 10net = TwoLayerNet(input_size, hidden_size, num_classes)# Train the networkstats = net.train(X_train, y_train, X_val, y_val, num_iters=1000, batch_size=200, learning_rate=1e-4, learning_rate_decay=0.95, reg=0.25, verbose=True)# Predict on the validation setval_acc = (net.predict(X_val) == y_val).mean()print('Validation accuracy: ', val_acc) 这时候得到的准确度应该在28%左右，可以优化 进一步优化 一种可视化的方法是可视化loss function和准确率的关系，分别在训练和val集上面 另种是可视化第一层的weights 两种方法的结果如下： debug模型 问题 loss大体上都是linearly的下降的，说明lr可能太低了 在training和val的准确率上没有gap，说明model的容量太小的，需要增大size 如果容量过大还会导致overfiiting，这时候gap就会很大 tuning hypers 题目里面的建议是tuning几个hyper，还是和之前一样，直接random，search 这里选了三个参数，分别是units的数量，learning rate和reg的强度，随便设置了一下界限 最终计算出来的val准确率是：49.5% 秀秀秀！！ 可视化weigh之后的结果是 震惊，居然最后的测试正确率也达到了49.4！！！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051best_net = None # store the best model into this ################################################################################## TODO: Tune hyperparameters using the validation set. Store your best trained ## model in best_net. ## ## To help debug your network, it may help to use visualizations similar to the ## ones we used above; these visualizations will have significant qualitative ## differences from the ones we saw above for the poorly tuned network. ## ## Tweaking hyperparameters by hand can be fun, but you might find it useful to ## write code to sweep through possible combinations of hyperparameters ## automatically like we did on the previous exercises. ##################################################################################best_acc = -1learning_rates = [1e-3, 1e-2]regularization_strengths = [1e-2, 6e-1]hidden_size = [50, 150]random_search = np.random.rand(30, 3)random_search[:, 0] = random_search[:, 0] * \ (learning_rates[1] - learning_rates[0]) + learning_rates[0]random_search[:, 1] = random_search[:, 1] * \ (regularization_strengths[1] - regularization_strengths[0] ) + regularization_strengths[0]random_search[:, 2] = random_search[:, 2] * \ (hidden_size[1] - hidden_size[0]) + hidden_size[0]for lr, rs, hidd in random_search: input_size = 32 * 32 * 3 hidden = int(hidd) num_class = 10 net = TwoLayerNet(input_size, hidden, num_class) status = net.train(X_train, y_train, X_val, y_val, num_iters=1000, batch_size=200, learning_rate=lr, learning_rate_decay=0.95, reg=rs, verbose=True) val_acc = (net.predict(X_val) == y_val).mean() if val_acc &gt; best_acc: best_acc = val_acc best_net = netprint("best net is with val acc", best_acc)################################################################################## END OF YOUR CODE ################################################################################## 代码部分nerual_net.py部分的完整代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289from __future__ import print_functionimport numpy as npimport matplotlib.pyplot as pltclass TwoLayerNet(object): """ A two-layer fully-connected neural network. The net has an input dimension of N, a hidden layer dimension of H, and performs classification over C classes. We train the network with a softmax loss function and L2 regularization on the weight matrices. The network uses a ReLU nonlinearity after the first fully connected layer. In other words, the network has the following architecture: input - fully connected layer - ReLU - fully connected layer - softmax The outputs of the second fully-connected layer are the scores for each class. """ def __init__(self, input_size, hidden_size, output_size, std=1e-4): """ Initialize the model. Weights are initialized to small random values and biases are initialized to zero. Weights and biases are stored in the variable self.params, which is a dictionary with the following keys: W1: First layer weights; has shape (D, H) b1: First layer biases; has shape (H,) W2: Second layer weights; has shape (H, C) b2: Second layer biases; has shape (C,) Inputs: - input_size: The dimension D of the input data. - hidden_size: The number of neurons H in the hidden layer. - output_size: The number of classes C. """ self.params = &#123;&#125; self.params['W1'] = std * np.random.randn(input_size, hidden_size) self.params['b1'] = np.zeros(hidden_size) self.params['W2'] = std * np.random.randn(hidden_size, output_size) self.params['b2'] = np.zeros(output_size) def loss(self, X, y=None, reg=0.0): """ Compute the loss and gradients for a two layer fully connected neural network. Inputs: - X: Input data of shape (N, D). Each X[i] is a training sample. - y: Vector of training labels. y[i] is the label for X[i], and each y[i] is an integer in the range 0 &lt;= y[i] &lt; C. This parameter is optional; if it is not passed then we only return scores, and if it is passed then we instead return the loss and gradients. - reg: Regularization strength. Returns: If y is None, return a matrix scores of shape (N, C) where scores[i, c] is the score for class c on input X[i]. If y is not None, instead return a tuple of: - loss: Loss (data loss and regularization loss) for this batch of training samples. - grads: Dictionary mapping parameter names to gradients of those parameters with respect to the loss function; has the same keys as self.params. """ # Unpack variables from the params dictionary W1, b1 = self.params['W1'], self.params['b1'] W2, b2 = self.params['W2'], self.params['b2'] N, D = X.shape # Compute the forward pass scores = None ############################################################################# # TODO: Perform the forward pass, computing the class scores for the input. # # Store the result in the scores variable, which should be an array of # # shape (N, C). # ############################################################################# # first layer, shape(N,H) X1 = X.dot(W1) + b1 # 这里加了一个第一层之后的relu激活 relu = np.maximum(0, X1) # final result, shape(N,C) scores = relu.dot(W2) + b2 ############################################################################# # END OF YOUR CODE # ############################################################################# # If the targets are not given then jump out, we're done if y is None: return scores # Compute the loss loss = None ############################################################################# # TODO: Finish the forward pass, and compute the loss. This should include # # both the data loss and L2 regularization for W1 and W2. Store the result # # in the variable loss, which should be a scalar. Use the Softmax # # classifier loss. # ############################################################################# num_train = N scores = scores - np.reshape(np.max(scores, axis=1), (num_train, -1)) scores = np.exp(scores) scores_sum = np.sum(scores, axis=1).reshape(N, 1) # scores_sum = np.sum(scores, axis=1, keepdims=True) p = scores / scores_sum loss = np.sum(-np.log(p[np.arange(N), y])) loss /= num_train # 这里不要乘0.5的系数 # loss += reg * np.sum(W1 * W1) + reg * np.sum(W2 * W2) loss += 0.5 * reg * np.sum(W1 * W1) + 0.5 * reg * np.sum(W2 * W2) # ############################################################################# # # END OF YOUR CODE # # ############################################################################# # # Backward pass: compute gradients grads = &#123;&#125; # ############################################################################# # # TODO: Compute the backward pass, computing the derivatives of the weights # # # and biases. Store the results in the grads dictionary. For example, # # # grads['W1'] should store the gradient on W1, and be a matrix of same size # # ############################################################################# dscores = p dscores[range(N), y] -= 1.0 # dscores /= N # shape dW2(CxN) x(NxH) -&gt; (CxH) # dW2 = np.dot(relu.T, p) dW2 = np.dot(relu.T, dscores) # print(dW2) # 每个class会有一个b，对b求导是1 # shape db2 (C,) db2 = np.sum(p, axis=0) # (NxC) x (HxC).T -&gt; (N,H) dW_relu = np.dot(dscores, W2.T) dW_relu[relu &lt;= 0] = 0 # (NxD).T x (N,H) -&gt; (D,H) dW1 = (X.T).dot(dW_relu) db1 = np.sum(dW_relu, axis=0) dW2 /= N dW1 /= N dW2 += reg * W2 dW1 += reg * W1 db1 /= N db2 /= N grads['W1'] = dW1 grads['b1'] = db1 grads['W2'] = dW2 grads['b2'] = db2 ############################################################################# # END OF YOUR CODE # ############################################################################# return loss, grads def train(self, X, y, X_val, y_val, learning_rate=1e-3, learning_rate_decay=0.95, reg=5e-6, num_iters=100, batch_size=200, verbose=False): """ Train this neural network using stochastic gradient descent. Inputs: - X: A numpy array of shape (N, D) giving training data. - y: A numpy array f shape (N,) giving training labels; y[i] = c means that X[i] has label c, where 0 &lt;= c &lt; C. - X_val: A numpy array of shape (N_val, D) giving validation data. - y_val: A numpy array of shape (N_val,) giving validation labels. - learning_rate: Scalar giving learning rate for optimization. - learning_rate_decay: Scalar giving factor used to decay the learning rate after each epoch. - reg: Scalar giving regularization strength. - num_iters: Number of steps to take when optimizing. - batch_size: Number of training examples to use per step. - verbose: boolean; if true print progress during optimization. """ num_train = X.shape[0] iterations_per_epoch = max(num_train / batch_size, 1) # Use SGD to optimize the parameters in self.model loss_history = [] train_acc_history = [] val_acc_history = [] for it in range(num_iters): X_batch = None y_batch = None ######################################################################### # TODO: Create a random minibatch of training data and labels, storing # # them in X_batch and y_batch respectively. # ######################################################################### rand_mini = np.random.choice(num_train, batch_size, replace=True) X_batch = X[rand_mini] y_batch = y[rand_mini] ######################################################################### # END OF YOUR CODE # ######################################################################### # Compute loss and gradients using the current minibatch loss, grads = self.loss(X_batch, y=y_batch, reg=reg) loss_history.append(loss) ######################################################################### # TODO: Use the gradients in the grads dictionary to update the # # parameters of the network (stored in the dictionary self.params) # # using stochastic gradient descent. You'll need to use the gradients # # stored in the grads dictionary defined above. # ######################################################################### self.params['W1'] -= learning_rate * grads['W1'] self.params['W2'] -= learning_rate * grads['W2'] self.params['b1'] -= learning_rate * grads['b1'] self.params['b2'] -= learning_rate * grads['b2'] ######################################################################### # END OF YOUR CODE # ######################################################################### if verbose and it % 100 == 0: print('iteration %d / %d: loss %f' % (it, num_iters, loss)) # Every epoch, check train and val accuracy and decay learning rate. if it % iterations_per_epoch == 0: # Check accuracy train_acc = (self.predict(X_batch) == y_batch).mean() val_acc = (self.predict(X_val) == y_val).mean() train_acc_history.append(train_acc) val_acc_history.append(val_acc) # Decay learning rate learning_rate *= learning_rate_decay return &#123; 'loss_history': loss_history, 'train_acc_history': train_acc_history, 'val_acc_history': val_acc_history, &#125; def predict(self, X): """ Use the trained weights of this two-layer network to predict labels for data points. For each data point we predict scores for each of the C classes, and assign each data point to the class with the highest score. Inputs: - X: A numpy array of shape (N, D) giving N D-dimensional data points to classify. Returns: - y_pred: A numpy array of shape (N,) giving predicted labels for each of the elements of X. For all i, y_pred[i] = c means that X[i] is predicted to have class c, where 0 &lt;= c &lt; C. """ y_pred = None ########################################################################### # TODO: Implement this function; it should be VERY simple! # ########################################################################### W1 = self.params['W1'] W2 = self.params['W2'] b1 = self.params['b1'] b2 = self.params['b2'] scores = X.dot(W1) + b1 scores[scores &lt; 0] = 0.0 scores = scores.dot(W2) + b2 y_pred = np.argmax(scores, axis=1) ########################################################################### # END OF YOUR CODE # ########################################################################### return y_pred]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
        <category>CS231n作业</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[关于Normalization的方法以及实现]]></title>
    <url>%2F2019%2F04%2F01%2FNormalize%2F</url>
    <content type="text"><![CDATA[在处理数据的时候，因为数据的大小差别会比较大，为了避免数据的特征被其他特征吃掉，需要对数据进行normalization的处理 (0,1) 标准化找到最大值和最小值，以最大值为1，最小值为0，计算其他数据在0到1之间的分布。 12def normal0_1(x,Max,Min): return (x-Min)/(Max-Min) 使用np.max()，np.min来找最大值和最小值 正态分布输入原始数据的均值和标准差，对数据处理，处理之后的数据是标准正态分布（均值是0，标准差是1） 12def Normalization(x, mu, sigma): return (x-mu) / sigma 使用np.average()和np.std()找到均值和标准差 Sigmoid函数sigmoid函数关于（0， 0.5）中心对称，在中心附近斜率较大，在负无穷接近0，正无穷接近1 12def sigmood(x): return 1.0/(1+np.exp(-float(x)))]]></content>
      <categories>
        <category>数学问题</category>
      </categories>
      <tags>
        <tag>Normalize</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231N作业assignment1之softmax]]></title>
    <url>%2F2019%2F04%2F01%2FCS231Nassignment1softmax%2F</url>
    <content type="text"><![CDATA[Softmax这部分主要是softmax的loss要如何计算Assignment From: Assignment1 目标 implement a fully-vectorized loss function for the Softmax classifier implement the fully-vectorized expression for its analytic gradient check your implementation with numerical gradient use a validation set to tune the learning rate and regularization strength optimize the loss function with SGD visualize the final learned weights 预处理（和之前一样（ 载入数据 初始化数据 拉长 normalize 分成训练集测试集validation等等 softmax classifiernaive_softmax_loss中心思想：把得到的score（Wx + b）先exp，然后normalize，最后求-log 输入： W：大小(D,C)，weights X：大小(N,D)，输入的mini-batch y：大小(N,)，标签 reg：regularization的系数 输出： loss dW，即改变的gradient 计算loss 先将所有的scores做exp（这一步可以先进行），这样所有的score都会变成正数 然后对不同class的score分别求normalize（虽然说是normalize，实际求的是这个种类的score在所有的score里面所占的比例） 然后将正确的类型所占的比例求log，再求负号，得出来的就是每个图片的loss（这里注意0的log是无穷，计算不出来） 所有图片的loss求和，然后除以图片总数，regularzation，得出来的就是最终的结果 计算dW 可以这样理解 W是一个参数矩阵，这个矩阵的变化由两个部分组成 第一部分是往什么方向变，这个取决于最后算出来的loss的分布 第二部分是变多少合适，这时候还需要乘一个系数X[i] 所以当算出来loss并且y[i] = j的时候，实际上就是这张图正确分类情况下的错误分类的概率，所以W的改变方向应该是这个的反方向 这张图的其他class的loss则应该是改变的方向 这样就可以看出来 SVM和softmax的不同之处了 对于SVM来说，仅仅通过与0比大小得出一个值，相当于一个0，1的开关，只能根据结果得到一个移动的方向 但是对于softmax来说，不仅得到了方向，还得到了这个方向的占比，所以loss越大的数影响就会越大 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657def svm_loss_naive(W, X, y, reg): """ Structured SVM loss function, naive implementation (with loops). Inputs have dimension D, there are C classes, and we operate on minibatches of N examples. Inputs: - W: A numpy array of shape (D, C) containing weights. - X: A numpy array of shape (N, D) containing a minibatch of data. - y: A numpy array of shape (N,) containing training labels; y[i] = c means that X[i] has label c, where 0 &lt;= c &lt; C. - reg: (float) regularization strength Returns a tuple of: - loss as single float - gradient with respect to weights W; an array of same shape as W """ dW = np.zeros(W.shape) # initialize the gradient as zero # compute the loss and the gradient num_classes = W.shape[1] # 有多少需要训练的个数 num_train = X.shape[0] loss = 0.0 for i in range(num_train): scores = X[i].dot(W) correct_class_score = scores[y[i]] for j in range(num_classes): # 如果这个类型是正确的，那就不用管了 if j == y[i]: continue margin = scores[j] - correct_class_score + 1 # note delta = 1 if margin &gt; 0: loss += margin dW[:, y[i]] += -X[i] dW[:, j] += X[i] # Right now the loss is a sum over all training examples, but we want it # to be an average instead so we divide by num_train. loss /= num_train dW /= num_train # Add regularization to the loss. # reg是lanbda loss += reg * np.sum(W * W) dW += 2 * reg * W ############################################################################# # TODO: # # Compute the gradient of the loss function and store it dW. # # Rather that first computing the loss and then computing the derivative, # # it may be simpler to compute the derivative at the same time that the # # loss is being computed. As a result you may need to modify some of the # # code above to compute the gradient. # ############################################################################# return loss, dW softmax_loss_vectorized提高计算速度 跟svm部分的计算思路一样，直接使用矩阵运算 在求整个score矩阵的变化的时候，正确分类的loss应该被减掉，但是现在是被加上的，所以需要在正确分类的地方加一个-1 debug了很久的地方是：计算dW的时候不需要计算log，因为没有log之前已经是这个loss所占的百分比了：求log是为了变成凸函数，loss没有求log之前并不是凸函数，但是凸函数容易找到最值的优化问问题，所以要求log。但是在计算dW的时候和log没关系 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def softmax_loss_vectorized(W, X, y, reg): """ Softmax loss function, vectorized version. Inputs and outputs are the same as softmax_loss_naive. """ # Initialize the loss and gradient to zero. loss = 0.0 dW = np.zeros_like(W) num_class = W.shape[1] num_train = X.shape[0] ############################################################################# # TODO: Compute the softmax loss and its gradient using no explicit loops. # # Store the loss in loss and the gradient in dW. If you are not careful # # here, it is easy to run into numeric instability. Don't forget the # # regularization! # ############################################################################# # size（N，C） scores = X.dot(W) scores = np.exp(scores) # 对每行求和 scores_sum = np.sum(scores, axis=1) scores_sum = np.repeat(scores_sum, num_class) scores_sum = scores_sum.reshape(num_train, num_class) # true_divide返回浮点数，普通的返回正数，size（N，C） percent = np.true_divide(scores, scores_sum) # 只有正确种类需要求loss Li = -np.log(percent[np.arange(num_train), y]) loss = np.sum(Li) # 注意这里不需要求log dS = percent.copy() dS[np.arange(num_train), y] += -1 dW = (X.T).dot(dS) loss /= num_train loss += reg * np.sum(W * W) dW /= num_train dW += reg * W ############################################################################# # END OF YOUR CODE # ############################################################################# return loss, dW 验证，选hyper和SVM的部分一样，随机搜索hyper，验证结果，训练迭代500次，最终的准确率在36%左右1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# Use the validation set to tune hyperparameters (regularization strength and# learning rate). You should experiment with different ranges for the learning# rates and regularization strengths; if you are careful you should be able to# get a classification accuracy of over 0.35 on the validation set.from cs231n.classifiers import Softmaxresults = &#123;&#125;best_val = -1best_softmax = Nonelearning_rates = [1e-7, 5e-7]regularization_strengths = [2.5e4, 5e4]################################################################################# TODO: ## Use the validation set to set the learning rate and regularization strength. ## This should be identical to the validation that you did for the SVM; save ## the best trained softmax classifer in best_softmax. #################################################################################hyper_values = np.random.rand(50,2)hyper_values[:,0] = (learning_rates[1] - learning_rates[0]) * hyper_values[:,0] + learning_rates[0]hyper_values[:,1] = (regularization_strengths[1] - regularization_strengths[0]) * hyper_values[:,1] + regularization_strengths[0]for lr, rs in hyper_values: softmax = Softmax() softmax.train(X_train,y_train,lr,rs,num_iters = 500,verbose = True) train_pred = softmax.predict(X_train) train_acc = np.mean(y_train == train_pred) val_pred = softmax.predict(X_val) val_acc = np.mean(y_val == val_pred) results[(lr,rs)] = (train_acc,val_acc) if val_acc &gt; best_val: best_val = val_acc best_softmax = softmax################################################################################# END OF YOUR CODE ################################################################################# # Print out results.for lr, reg in sorted(results): train_accuracy, val_accuracy = results[(lr, reg)] print('lr %e reg %e train accuracy: %f val accuracy: %f' % ( lr, reg, train_accuracy, val_accuracy)) print('best validation accuracy achieved during cross-validation: %f' % best_val) 可以看出来感觉softmax比SVM的效果好一些？可视化最终的优化的weight123456789101112131415# Visualize the learned weights for each classw = best_softmax.W[:-1,:] # strip out the biasw = w.reshape(32, 32, 3, 10)w_min, w_max = np.min(w), np.max(w)classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']for i in range(10): plt.subplot(2, 5, i + 1) # Rescale the weights to be between 0 and 255 wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min) plt.imshow(wimg.astype('uint8')) plt.axis('off') plt.title(classes[i])]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
        <category>CS231n作业</category>
      </categories>
      <tags>
        <tag>Softmax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于标量，向量，矩阵求导]]></title>
    <url>%2F2019%2F03%2F30%2F%E5%85%B3%E4%BA%8E%E6%A0%87%E9%87%8F%E5%90%91%E9%87%8F%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[参考文章：https://blog.csdn.net/u010976453/article/details/54381248 关于layout在求导的时候有，因为分子和分母可能的维度不太一样，所以两种不同的布局，分别是分子布局和分母布局假设y（向量）对x（标量）求导： 分子布局，即和原来的y相同 分母布局，为分子布局的tranpose 对标量的导数scalar对scalar求导即最简单的求导 vector对scalar求导比如一个列向量y，对x求导，结果是y里面的每个值都对x求导 matrix对scalr求导矩阵里面的每个值都对x求导 对向量的导数scalar对vector 标量y和向量x，求出来的结果是y对每个x(x1,x2 ….xn)求导 结果为梯度向量，是标量y在空间Rn的梯度，空间以x为基 注意，x是列向量的话，最后求出来的是行的结果 vector对vectory = [y1,y2 …. ym]x = [x1,x2 …. xn]最后求出来的结果是一个m行n列的矩阵，jacobian矩阵 matrix对vector矩阵y =[[y11,y12…y1n],[y21,y22 …y2n],…[yn1,yn2 …ynn]]向量x = [x1,x2…xn]T最终的结果是每一行分别对这个x的向量求导，所以矩阵的列数和向量的行数应该先通 对于矩阵一般只考虑标量对矩阵(剩下的情况和上面类似)最终结果是这个标量对所有的矩阵内容求导，求出来的是梯度矩阵]]></content>
      <categories>
        <category>数学问题</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CS231N作业assignment1之SVM部分]]></title>
    <url>%2F2019%2F03%2F29%2FCS231Nassignment1SVM%2F</url>
    <content type="text"><![CDATA[Assignment from: http: // cs231n.github.io / assignments2018 / assignment1/ 目标： a fully - vectorized loss function for the SVM fully - vectorized expression for its analytic gradient use a validation set to tune the learning rate and regularization strength optimize the loss function with SGD visualize the final learned weights Set up部分1234567891011121314151617181920# Run some setup code for this notebook.from __future__ import print_functionimport randomimport numpy as npfrom cs231n.data_utils import load_CIFAR10import matplotlib.pyplot as plt# This is a bit of magic to make matplotlib figures appear inline in the# notebook rather than in a new window.%matplotlib inlineplt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'# Some more magic so that the notebook will reload external python modules;# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython%load_ext autoreload%autoreload 2 读取CIFAR-10的数据，预处理123456789101112131415161718# Load the raw CIFAR-10 data.cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)try: del X_train, y_train del X_test, y_test print('Clear previously loaded data.')except: passX_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)# As a sanity check, we print out the size of the training and test data.print('Training data shape: ', X_train.shape)print('Training labels shape: ', y_train.shape)print('Test data shape: ', X_test.shape)print('Test labels shape: ', y_test.shape) 结果：1234Training data shape: (50000, 32, 32, 3)Training labels shape: (50000,)Test data shape: (10000, 32, 32, 3)Test labels shape: (10000,) 可视化dataset 从类型中1234567891011121314151617# Visualize some examples from the dataset.# We show a few examples of training images from each class.classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']num_classes = len(classes)samples_per_class = 7for y, cls in enumerate(classes): idxs = np.flatnonzero(y_train == y) idxs = np.random.choice(idxs, samples_per_class, replace=False) for i, idx in enumerate(idxs): plt_idx = i * num_classes + y + 1 plt.subplot(samples_per_class, num_classes, plt_idx) plt.imshow(X_train[idx].astype('uint8')) plt.axis('off') if i == 0: plt.title(cls)plt.show() 1np.flatnonzero(y_train == y) 返回内容非0的index。这句是返回plane类别里面的（y_train == y）所有非0的内容。然后从这些里面随机选择7个内容，画出来。 结果如下： 进一步分为几部分123456789101112131415161718192021222324252627282930313233343536373839# Split the data into train, val, and test sets. In addition we will# create a small development set as a subset of the training data;# we can use this for development so our code runs faster.num_training = 49000num_validation = 1000num_test = 1000# 用这部分来优化代码num_dev = 500# Our validation set will be num_validation points from the original# training set.mask = range(num_training, num_training + num_validation)X_val = X_train[mask]y_val = y_train[mask]# Our training set will be the first num_train points from the original# training set.mask = range(num_training)X_train = X_train[mask]y_train = y_train[mask]# We will also make a development set, which is a small subset of# the training set.mask = np.random.choice(num_training, num_dev, replace=False)X_dev = X_train[mask]y_dev = y_train[mask]# We use the first num_test points of the original test set as our# test set.mask = range(num_test)X_test = X_test[mask]y_test = y_test[mask]print('Train data shape: ', X_train.shape)print('Train labels shape: ', y_train.shape)print('Validation data shape: ', X_val.shape)print('Validation labels shape: ', y_val.shape)print('Test data shape: ', X_test.shape)print('Test labels shape: ', y_test.shape) 12mask = range(num_test)X_test = X_test[mask] 感觉这是一种从一个整体中选取其中一部分的代码 将image拉成row1234567891011# Preprocessing: reshape the image data into rowsX_train = np.reshape(X_train, (X_train.shape[0], -1))X_val = np.reshape(X_val, (X_val.shape[0], -1))X_test = np.reshape(X_test, (X_test.shape[0], -1))X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))# As a sanity check, print out the shapes of the dataprint('Training data shape: ', X_train.shape)print('Validation data shape: ', X_val.shape)print('Test data shape: ', X_test.shape)print('dev data shape: ', X_dev.shape) 当想把无论任何大小的东西拉成一整行的时候，用a.reshape(x, -1)。 X_train.shape[0]行，列数未知，但是拉平了 如果想拉成一整列的时候，用a.reshape(-1, x)。 列数为x，每列有多少东西未知 预处理部分：减去mean image 第一步，求出训练集的mean并且可视化 12345678# Preprocessing: subtract the mean image# first: compute the image mean based on the training datamean_image = np.mean(X_train, axis=0)print(mean_image[:10]) # print a few of the elementsplt.figure(figsize=(4, 4))plt.imshow(mean_image.reshape((32, 32, 3)).astype( 'uint8')) # visualize the mean imageplt.show() 第二步，从train和test里面减去平均数据 12345# second: subtract the mean image from train and test dataX_train -= mean_imageX_val -= mean_imageX_test -= mean_imageX_dev -= mean_image 第三步，把预处理好的所有图片的末尾（拉成行之后的最后）加了一个1（bias的dim） 12345678# third: append the bias dimension of ones (i.e. bias trick) so that our SVM# only has to worry about optimizing a single weight matrix W.X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape) np.hstack()，沿着水平方向把数组叠起来。于此相同，np.vstack()，是沿着垂直方向把数组叠起来。 SVM classifier1cs231n / classifiers / linear_svm.py. svm_loss_naive 有三个输入 X：一个有N个元素的minibatch，每个元素的内容是D(N, D) W: weights，(D, C), 图片的内容是D，一共C个class，所以用的时候跟普遍想法的W是tranpose的 y: 标签，大小(N,) 一共N张照片，每张照片有一个标签 最终结果 一个float的结果：loss W的gradient dW 注意，Wx求出来的就是不同分类的积分 dW的计算(https://blog.csdn.net/zt_1995/article/details/62227201) 形状很奇怪的1(x)指的是，当x为真的时候结果是1，当x为假的时候结果取0 第一个式子表示第i个被正确分类的梯度 有多少个Wj让这个边界值不被满足，就对损失起了多少贡献 乘以xi是因为xi包含了样本的全部特征，所以前面乘以一个系数1就可以了 符号是因为SGD采用负梯度运算 第二个式子表示不正确分类的梯度，只有在yi == j的时候才有贡献，所以没有求和。但是注意，在每张图里面，这个都会在j == yi的时候发生一次，所以每张图的j部分需要加上这个值 最终的结果需要，除以N 别忘了正则化！而且用2\lanmdaW来正则化的效果更好一些 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051def svm_loss_naive(W, X, y, reg): """ Structured SVM loss function, naive implementation (with loops). Inputs have dimension D, there are C classes, and we operate on minibatches of N examples. Inputs: - W: A numpy array of shape (D, C) containing weights. - X: A numpy array of shape (N, D) containing a minibatch of data. - y: A numpy array of shape (N,) containing training labels; y[i] = c means that X[i] has label c, where 0 &lt;= c &lt; C. - reg: (float) regularization strength Returns a tuple of: - loss as single float - gradient with respect to weights W; an array of same shape as W """ dW = np.zeros(W.shape) # initialize the gradient as zero # compute the loss and the gradient num_classes = W.shape[1] # 有多少需要训练的个数 num_train = X.shape[0] loss = 0.0 for i in range(num_train): scores = X[i].dot(W) correct_class_score = scores[y[i]] for j in range(num_classes): # 如果这个类型是正确的，那就不用管了 if j == y[i]: continue margin = scores[j] - correct_class_score + 1 # note delta = 1 if margin &gt; 0: loss += margin dW[:, y[i]] += -X[i] dW[:, j] += X[i] # Right now the loss is a sum over all training examples, but we want it # to be an average instead so we divide by num_train. loss /= num_train dW /= num_train # Add regularization to the loss. # reg是lanbda loss += reg * np.sum(W * W) dW += 2 * reg * W return loss, dW svm_loss_vectorized通过向量化来提高计算速度 计算loss部分 W是一个(D, C)的向量，X是(N, D)的，所以两者相乘可以得到一个(N, C)的矩阵，N为图片数量，C是每张图片对于不同分类的score 在score中取每一行的y中label部分就是这张图正确类型的评分 把整体的score矩阵的所有项减去正确评分的矩阵（应该可以广播但是我刚开始用repeat和reshape复制了一下），减去的结果就是svm中需要和0比的值（margin） 为了求loss，把小于0的项目和正确的项除去（都设置成0） 然后行求和，列求和，除以整体的个数，regularzation 计算dW部分 X.T点乘margin得到的就是最终的loss，所以需要把每个margin里面符合条件的数对了 所有比0大的时候都算1（根据导数的计算结果） 当应该判断正确的类型比0大的时候，这个东西会在每次计算导数的时候都算上一次，所以是行的合 最后乘完之后除以总的个数，再regularzation1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def svm_loss_vectorized(W, X, y, reg): """ Structured SVM loss function, vectorized implementation. Inputs and outputs are the same as svm_loss_naive. """ loss = 0.0 dW = np.zeros(W.shape) # initialize the gradient as zero ############################################################################# # TODO: # # Implement a vectorized version of the structured SVM loss, storing the # # result in loss. # ############################################################################# num_train = X.shape[0] num_classes = W.shape[1] scores = X.dot(W) # 这里是取第N行（图片行）的第C个（class列），得到的是（500，）的正确类的score的矩阵 correct_class_score = scores[np.arange(num_train), y] # correct_class_score = np.repeat(correct_class_score, num_classes) # correct_class_score = correct_class_score.reshape(num_train, num_classes) # DxC margin = scores - correct_class_score + 1.0 margin[np.arange(num_train), y] = 0.0 margin[margin &lt;= 0] = 0.0 loss += np.sum(np.sum(margin, axis=1)) / num_train # loss /= num_train loss += 0.5 * reg * np.sum(W * W) margin[margin &gt; 0] = 1.0 calculate_times = np.sum(margin, axis=1) margin[np.arange(num_train), y] = - calculate_times dW = np.dot(X.T, margin) / num_train dW += 2 * reg * W ############################################################################# # END OF YOUR CODE # ############################################################################# return loss, dW 现在得到了dW和loss，使用SGD来减少loss训练 将整体分成不同的minibatch，使用np.random.choice，注意后面的replce可以选True，这样会重复选择元素但是结果速度好像是更快了 将minibatch的结果计算loss和gradient，然后grad * learning rate来update数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100, batch_size=200, verbose=False): """ Train this linear classifier using stochastic gradient descent. Inputs: - X: A numpy array of shape (N, D) containing training data; there are N training samples each of dimension D. - y: A numpy array of shape (N,) containing training labels; y[i] = c means that X[i] has label 0 &lt;= c &lt; C for C classes. - learning_rate: (float) learning rate for optimization. - reg: (float) regularization strength. - num_iters: (integer) number of steps to take when optimizing - batch_size: (integer) number of training examples to use at each step. - verbose: (boolean) If true, print progress during optimization. Outputs: A list containing the value of the loss function at each training iteration. """ num_train, dim = X.shape # assume y takes values 0...K-1 where K is number of classes num_classes = np.max(y) + 1 if self.W is None: # lazily initialize W self.W = 0.001 * np.random.randn(dim, num_classes) # Run stochastic gradient descent to optimize W loss_history = [] for it in range(num_iters): X_batch = None y_batch = None ######################################################################### # TODO: # # Sample batch_size elements from the training data and their # # corresponding labels to use in this round of gradient descent. # # Store the data in X_batch and their corresponding labels in # # y_batch; after sampling X_batch should have shape (dim, batch_size) # # and y_batch should have shape (batch_size,) # # # # Hint: Use np.random.choice to generate indices. Sampling with # # replacement is faster than sampling without replacement. # ######################################################################### indices = np.random.choice(num_train, batch_size, replace=True) X_batch = X[indices] y_batch = y[indices] ######################################################################### # END OF YOUR CODE # ######################################################################### # evaluate loss and gradient loss, grad = self.loss(X_batch, y_batch, reg) loss_history.append(loss) # perform parameter update ######################################################################### # TODO: # # Update the weights using the gradient and the learning rate. # ######################################################################### self.W += - learning_rate * grad ######################################################################### # END OF YOUR CODE # ######################################################################### if verbose and it % 100 == 0: print('iteration %d / %d: loss %f' % (it, num_iters, loss)) return loss_history 预测结果 已经有了前面的到的训练过的W（self.W） Wx算出来的就是分数 从每一行里面选择最大的分数就是预测的结果123456789101112131415161718192021222324252627def predict(self, X): """ Use the trained weights of this linear classifier to predict labels for data points. Inputs: - X: A numpy array of shape (N, D) containing training data; there are N training samples each of dimension D. Returns: - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional array of length N, and each element is an integer giving the predicted class. """ y_pred = np.zeros(X.shape[0]) ########################################################################### # TODO: # # Implement this method. Store the predicted labels in y_pred. # ########################################################################### scores = X.dot(self.W) y_pred = np.argmax(scores, axis=1) # print(labels.shape) # print(labels) ########################################################################### # END OF YOUR CODE # ########################################################################### return y_pred 交叉验证 在作业里，需要选择两个hyper的值，分别是学习率和regularzation的参数，没有采用交叉验证，但是采用了随机搜索，会比grid search更准确一些 采用不同的参数组合分别训练这个模型，然后得到各自在validation上面的准确率，这个得到准确率最大的组合的参数 注意，在验证的过程中应该选择iter的次数少一点，不然训练的时间会非常长 在这个代码里用了rand来得到0到1之间的随机数，这个数乘以hyper的范围的差，然后再加上下限，就是随机得到的最终结果 1234567891011121314rand_turple = np.random.rand(50,2)rand_turple[:,0] = rand_turple[:,0]*(learning_rates[1]-learning_rates[0]) + learning_rates[0]rand_turple[:,1] = rand_turple[:,1]*(regularization_strengths[1]-regularization_strengths[0])+regularization_strengths[0]for lr,rs in rand_turple: svm = LinearSVM() svm.train(X_train, y_train, learning_rate=lr, reg=rs,num_iters=1500, verbose=True) y_train_pred = svm.predict(X_train) train_acc = np.mean(y_train == y_train_pred) y_val_pred = svm.predict(X_train) val_acc = np.mean(y_train == y_val_pred) results[(lr,rs)] = (train_acc,val_acc) if (val_acc &gt; best_val): best_val = val_acc best_svm = svm 结果可视化123456789101112131415# Visualize the learned weights for each class.# Depending on your choice of learning rate and regularization strength, these may# or may not be nice to look at.w = best_svm.W[:-1,:] # strip out the biasw = w.reshape(32, 32, 3, 10)w_min, w_max = np.min(w), np.max(w)classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']for i in range(10): plt.subplot(2, 5, i + 1) # Rescale the weights to be between 0 and 255 wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min) plt.imshow(wimg.astype('uint8')) plt.axis('off') plt.title(classes[i])]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
        <category>CS231n作业</category>
      </categories>
      <tags>
        <tag>SVM</tag>
        <tag>SGD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TypeError:'method' object is not subscriptable]]></title>
    <url>%2F2019%2F03%2F26%2Fmethod%E4%B8%8D%E6%98%AFsubscripatable%2F</url>
    <content type="text"><![CDATA[遭遇问题TypeError: ‘method’ object is not subscriptable是因为我本来写了一个class的method123def get_page(self, num):num = int(num)return self.pages[num] 但是在调用的时候我用了12get_page[i]get_page(i) #这样才是正确的 找到报错改括号就行了！]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[enumerate枚举]]></title>
    <url>%2F2019%2F03%2F25%2Fenumerate%E6%9E%9A%E4%B8%BE%2F</url>
    <content type="text"><![CDATA[enumerate()枚举对可迭代的数据进行标号并将其里面的数据和标号一并打印出来。1enumerate(iterable, start=0) iterable: 可迭代的数据，比如list start: 打印的初始值，默认从0开始打印 123test = [[11], [21], [31], [41]]for i, cnt in enumerate(test):print(i, cnt) 结果为12340 [11]1 [21]2 [31]3 [41]]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python的None和if的理解]]></title>
    <url>%2F2019%2F03%2F25%2FPython%E7%9A%84None%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[python对变量None的判断None是一种数据类型！！！12&gt;&gt;&gt;type(None)&lt;class 'NoneType'&gt; 说明该值是一个空的对象，是Python里面的特殊的值，跟NULL不一样，跟0也不一样 123456a = Noneb = []if a is None or b is None:print("yahaha")else:print("wocao") 结果为“yahaha” 注意：在if的情况下，使用None有时候可以起到很好的作用1if a is None: 与这个差不多的用法是1if not a: 在python里面，None，空列表[]，字典{},tuple()，0等都会被转化成false，剩下的为true比如：12345a = Noneif a:print("yahaha")else:print("wocao") 这时候的输出是wocao，因为a被认为是false]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[np.delete删除数组内容]]></title>
    <url>%2F2019%2F03%2F25%2Fnp-delete%E5%88%A0%E9%99%A4%E6%95%B0%E7%BB%84%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[np.deletenumpy.delete(arr, obj, axis=None) 返回一个新的array，删除掉obj，沿着axis方向 axis : int, optional The axis along which to delete the subarray defined by obj. If axis is None, obj is applied to the flattened array.(如果不加上axis的话会自动把这个array拉平) axis = 0：删除数组的行 axis = 1: 删除数组的列 axis = none: 把整个数组平铺之后按索引删除 123456789101112import numpy as npids = [[3], [34], [5]]ids_o = [[3], [31]]remove_list = filter(lambda i: i not in ids, ids_o)# print(np.asarray(ids))for i in remove_list:index = np.where(np.asarray(ids_o) == i)[0]print("index = ", index)ids = np.delete(ids, index, axis = 0)print("new ids = \n", ids) 结果：1234index = [1]new ids = [[3][5]] 如果把上面改成1ids = np.delete(ids, 0, axis = 1) 即为删除数组的第0列，结果是 [ ] （因为只有一列） 如果改成1ids = np.delete(ids, index, axis = None) 结果为：12new ids = [3 5]]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[np.where查找索引]]></title>
    <url>%2F2019%2F03%2F25%2Fnp-where%E6%9F%A5%E6%89%BE%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[np.wherenp.where(condition, x, y)满足条件(condition)，输出x，不满足输出y。123np.where([[True,False], [True,True]], # 官网上的例子[[1,2], [3,4]],[[9,8], [7,6]]) 输出12array([[1, 8],[3, 4]]) 上面这个例子的条件为[[True,False], [True,False]]，分别对应最后输出结果的四个值。第一个值从[1,9]中选，因为条件为True，所以是选1。第二个值从[2,8]中选，因为条件为False，所以选8，后面以此类推这里的true指的就是选前面的，false就是指选后面的 1234567&gt;&gt;&gt; a = 10&gt;&gt;&gt; np.where([[a &gt; 5,a &lt; 5], [a == 10,a == 7]],[["chosen","not chosen"], ["chosen","not chosen"]],[["not chosen","chosen"], ["not chosen","chosen"]])array([['chosen', 'chosen'],['chosen', 'chosen']], dtype='&lt;U10') np.where(condition)只有条件 (condition)，没有x和y，则输出满足条件 (即非0) 元素的坐标（注意这里返回的是坐标）12345&gt;&gt;&gt; a = np.array([2,4,6,8,10])&gt;&gt;&gt; np.where(a &gt; 5) # 返回索引(array([2, 3, 4]),) &gt;&gt;&gt; a[np.where(a &gt; 5)] # 等价于 a[a&gt;5]array([ 6, 8, 10]) 123456789101112131415161718&gt;&gt;&gt; a = np.arange(27).reshape(3,3,3)&gt;&gt;&gt; aarray([[[ 0, 1, 2],[ 3, 4, 5],[ 6, 7, 8]],[[ 9, 10, 11],[12, 13, 14],[15, 16, 17]],[[18, 19, 20],[21, 22, 23],[24, 25, 26]]])&gt;&gt;&gt; np.where(a &gt; 5)(array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]),array([2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2]),array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])) 注意这里的最终结果的坐标是要竖着看的，即（0，2，0），（0，2，1）…. 这个方法只能用在array上面，如果需要list的话需要np.asarray 12345678910import numpy as npids = [[3], [34], [5]]ids_o = [[3]]remove_list = filter(lambda i: i not in ids_o, ids)print(np.asarray(ids))for i in remove_list:index = np.where(np.asarray(ids) == i)print(index) 结果123456[[ 3][34][ 5]](array([1]), array([0]))(array([2]), array([0]))[Finished in 0.2s]]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的filter函数]]></title>
    <url>%2F2019%2F03%2F25%2FPython%E7%9A%84filter%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[python filterfilter() 函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表。 该接收两个参数，第一个为函数，第二个为序列，序列的每个元素作为参数传递给函数进行判，然后返回 True 或 False，最后将返回 True 的元素放到新列表中。 返回值是fliter的类型1remove_list = filter(lambda i: i not in ids_o,ids_u) 对于不在ids_o里面的i，是不是在ids_u里面，如果是的话就需要remove这部分东西]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tuple,array,list的大小问题]]></title>
    <url>%2F2019%2F03%2F22%2Ftuple-array-list%E7%9A%84%E5%A4%A7%E5%B0%8F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[每次在使用这群乱七八糟的数据结构的时候我都不明白到底用哪个函数求长度，而且各个结构的表示方法每次都让我感觉很迷茫，所以有了这篇文章。 好像只有array可以用shape来求！其他的都没有shape，array的shape可能是多维的。 数组array 数组的表示方法为最外面是括号，里面是方括号，不同的方括号代表不同的维度，np操作的都是array的部分 如果是一维数组，显示出来的size应该是(1,)这个样子的 size方法1a.size 1np.size(a) len不可以得到整个的大小，但是可以得到数组的行数，相当于a.shape[0]1len(a) 1a.shape[看看求的是第几维] 列表 列表最外面是方括号，不是圆括号！ 不可以直接用 a.size 求，’list’ object has no attribute ‘size’ 1np.size(List) 1len(List) 元组 元组的最外面是圆括号 不可以通过 t.size 来访问 可以通过 Tuple[]直接访问元素 1np.size(Tuple) 1len(Tuple) 字典 外面是大括号，里面是value-key的配对 size不可以用，np.size无法获得真实的大小 1len(Dict)]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在python中调用另外的文件]]></title>
    <url>%2F2019%2F03%2F22%2F%E5%9C%A8python%E4%B8%AD%E8%B0%83%E7%94%A8%E5%8F%A6%E5%A4%96%E7%9A%84%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[关于如何在python中调用其他的文件在cpp里面是使用头文件来导入的，但是提到python突然没想起来是怎么导入的。假设有文件a.py和b.py 在同一目录下12import aa.func() 或者引用模块中的函数123from a import funcfunc() ` 注意：前面一种方法导入的时候需要加上模块的名称限定，但是后面的导入就不用。如果怕麻烦可以导入的时候使用1from a import * 在不同目录下sys.path获取指定模块搜索路径的字符串集合，可以将写好的模块放在得到的某个路径下，就可以在程序中import时正确找到1234import syssys.path.append('a所在的路径')import aa.func() sys是什么 sys是python程序用来请求解释器行为的interface，比如调试，实时运行环境等 sys.argv 从外部向程序内部传递参数12345#!/usr/bin/env pythonimport sysprint sys.argv[0]print sys.argv[1] 运行：123# python sys.py argv1sys.pyargv1 sys.exit() 需要中途退出的时候可以调用，可以返回参数（0是正常退出，其他是异常）12345678910111213141516#!/usr/bin/env pythonimport sysdef exitfunc(value): print value sys.exit(0)print "hello"try: sys.exit(1)except SystemExit,value: exitfunc(value)print "come?" 123# python exit.pyhello1]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于hexo和gitpage的博客搭建以及设置]]></title>
    <url>%2F2019%2F03%2F20%2F%E5%85%B3%E4%BA%8Ehexo%E5%92%8Cgitpage%E7%9A%84%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%8F%8A%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[在commit了40多次之后终于把自己的博客搭好了，中间画遇到了一些奇怪的问题记录一下 github部分 在一些地方看到的说网站的名字必须和github的名字一样，不知道是不是必须的但是还是这么设置了 网站需要选择在master hexo部分基本功能：生成网页1hexo g 传到github上面1hexo d 生成新的md1hexo new &lt;title&gt; 需要把生成的全部清除1hexo clean 添加主题 把相应的主题clone下来，然后修改博客根目录的 _config.yml 文件 遇到404或者不显示模板的时候基本就是没套对 主题内容在主题的config修改这部分遇到的主要问题是两个：根目录config忘记添加一部分123456789101112131415161718jsonContent: meta: false pages: false posts: title: true date: true path: true text: false raw: false content: false slug: false updated: false comments: false link: false permalink: false excerpt: false categories: false tags: true hexo的url和root部分设置不对 github的deploy 地址应该是clone时候的网址 url部分应该是https://bigphess.github.io/，root部分是/ md文件增加图片在config里面设置，生成新的文章的时候就会生成对应的文件夹1post_asset_folder: true 然后把相应的图片放在文件夹里，引用的时候直接md格式引用：1![图片的名字](相对路径)]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[StanfordCS231N笔记]]></title>
    <url>%2F2019%2F03%2F20%2FStanfordCS231N%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Introduction Image Classification pipelinechallenges 图片是由无数数字块组成的 视角的转变，亮度的变化，变形都会产生非常大的变化 viewpoint illumination deformation occlusion background clutter intraclass variation image classifer input:image output: class_label data-driven approach 其他方法不行 attempts: 边缘检测，纹理等等（但是太过具体） 以数据为导向的方法 def train(image, label) def predict(model, test_image) KNNNN 对于每一个测试的data，在数据库里面找到离他最近的图片（选择一共找多少张，这么多张里面投票） 定义距离（hyperparameter） 曼哈顿距离 L1: 两张图相减求绝对值，然后把整张照片求和 欧几里得距离 L2: 距离的平方和开方 实现 training：记住每个图片的内容和label image：N✖D，每行是一张图片（拉成一行），一共N张 label：1-d数组，sizeN predict：计算距离找到最小的角标（np.argmin) 速度：linearly to size of dataset 缺点： 预测的时间太长了（expensive） 但是我们希望训练的时间长但是测试的时间短（CNN） KNN 找到最近的K个，投票 当K增加的时候，整个图片的边缘变得平滑了 K的数量也是一个hyperparameter 需要选择的hyper（并不能很好的找到最优解） K 用什么distance 如何选择最好的参数 总不能尝试所有的参数吧2333 不能使用test data，请在训练的时候忘记自己拥有它 把train data fold成不同的部分，把其中的一部分当成测试数据（validation data），然后测试训练的结果寻找hyper 交叉验证（cross-validation），循环当validation fold然后average result 但是根本不用呢 在test time的performance太差了 两个图片之间的距离太不直观了，你根本不知道图片间的距离会怎么变 linear classificationparametric approach 输入：32x32x3的图片，array of numbers 0,1,…3072 f(x,W) = Wx + b （在线性分类的情况下） （10x1） x: image （3072x1 -&gt; 拉直了） W: parameters，weights （10x3027） b： bias （10x1），不是这个函数的参数，只是用来决定比如猫的数量特别多，偏向猫的bias可能就比较大 输出：10个数字，表示每个class的scores 注意 W是把不同分类的classifer拼在了一起（乐高一样），每一行都是一个不同的class的分类器，点乘这个图片上面的像素，加上bias就是这个图片最终的得分 resize所有的图片到一个大小（目前） 实际上每个class的score就是图片里面每个点的加权求和，可以想象成在数每个不同地方的点的颜色。如果把W矩阵还原，还原出来的就是这个class的感觉上的颜色 可以想象在一个巨高d的space里面，用线性分类 hard part 都用灰度图会有问题 相似的texture（？ loss function optimizationtodo： 定义一个loss function来定义这个score的好坏 找到一个efficiently way去找到minimize 这个loss SVM loss定义 假设如果只有三个种类，一张图片对三个class分别会有不同的score。每张图片都可以计算出一个对应的loss SVM loss Li = sum max（0，sj - si + 1） si: 想要计算这个的loss function 的class的评分（也就是label标注的class的评分） sj: 这张图对于所有其他种类（除了i）的评分 Li: 最终这张图片的loss 1: 是一个safety margin（也是一个hyper parameter）。可以选择其他正数，但是选0会出问题 Li的每一项都在0和差值之间找最大值，然后把每一项的加起来求和 如何理解这个式子：既然对于不同class的评分越高就是越可能，那么评分是负数的话就说明不可能，这样就直接用0把这种可能性抹去了。如果其他种类在正的方面评分越高，说明这个种类跑偏了，loss越大 ###注意点 在上面这张图里，因为车的评分已经是最高了，计算出来的loss就是0 最后再把所有类型的loss求和，除以种类得到最终的loss 用的是求和而不是mean也是取决于自己的决定 也有的SVM里面用的是max之后平方，但是不平方的用的更多一点，也是一个hyper parameter scale 最小：0 最大：infinite bug 在实际应用里面没有那么好的效果 W不是唯一的，比如把这个W加倍，如果loss是0的时候是一样的 -&gt; 需要得到唯一的W weight regularization（解决上面这个问题） 在之前的loss的基础上加上了 \lambda R(W) \lambda是一个hyper parameter，是取决于自己的选择的 R是一个regularization函数，这个函数的作用是抵抗之前的loss。因为之前的loss是从训练集上得到的，比较吻合训练集，所以需要一个比较特别的W来和之前的fight，这样的话结果可能会在实际使用的时候更好一些 主要分类 L2 regularization：W里面的所有项平方然后求和（最常见） L1 regularization：W里面所有项绝对值然后求和 -&gt; 在一些其他地方使用 elastic net（L1+L2）：所有项平方乘参数加绝对值求和 max norm regularization -&gt; 后面讲 dropout 理解L2 比如X是[1,1,1,1],两个W分别是[1,0,0,0]和[0.25,0.25,0.25,0.25] 这样乘出来的最终结果都是一样的，都是1。 但是如果加上了L2的regularization之后就发现第二种方法的loss更少一点。因为他用到了更多的维数，在实际应用之中效果更好。 softmax（用起来更好）（multinomial logistic regression）定义 scores：unnormalized log probabilities of the class 需要把score先exp回来(这样所有的数都变成正数了) 再normalize（除以所有exp之后的的和） 最终，对于正确class的最终处理完的score来说，max这个log或者min（loss function）- log会得到最终最好的结果 最终处理完的score就是每个类型推测出来的占比可能性（和为1） 这里求完-log（p）其实就是信息熵，代表对不确定度的度量 直接比较可能性和log之后比较可能性在本质上是没有区别的 但是数学上一般log之后的数据会看起来好一些实际操作如下 一些问题 极值 Li最小值：0 -&gt; 如果正确类型的可能性是1，求出来的最终值就是0 Li最大值：infinite，可能性非常低非常接近于0 当W的初始化很小，所有score都接近于0： score求exp之后都是1，normalize之后是1/num（class），最后再求log 可以用于开头的检验 SVM和softmax 如果输入是[10,-100,-100]，在这个范围里微小变化，第一个是正确的class 对于SVM来说，后面两个负值都非常小了，根本不会去管后面的两个东西，-100和-200没啥区别 对于softmax来说，后面的-100还是-200还是会对loss最终的值产生影响，softmax希望所有的值都在正确的class上面，后面啥都没有。所以更具有robustness。 SVM会有一个你需要的区域，剩下的根本不考虑；而softmax会考虑所有的区域 上方区域总结 x：训练集里面的数据，放在图片里就是把一个图片拉成一个1xN的向量 y：训练集的标签，用来和最终的结果比对 W: weights，需要优化的部分 L：loss，用来权衡W优化结果的好坏 基本过程 Wx+b得到目前的分类器的score（score function） y是目前分类应该有的结果（label） R（W）得到regularzation的值 分类器得到score，y知道正确的分类，通过softmax或者SVM得到这个分类器目前的loss，再加上R（W）的部分增加robustness最终得到整个分类器的loss optimization lossfollow the slope 通过计算gradient来找到最低点 最基础的想法：（从数学上入手） 因为梯度是lim f(x+,h)-f(x)/h 把W上面的每一个点都加上一个0.00001（接近于0）然后再求上面的式子，就能得到第一次操作的梯度 silly 每一步都需要每一个维度都算一下，在CNN里面参数高达百万个，计算太慢了 因为用的0.00001，其实并不准确 感谢牛顿莱布尼兹发明了微积分 -&gt; 如何具体计算在下一节课 把loss的gradient改成了一个式子 快速，准确，然是容易发生bug（error-prone） practice需要进行gradient check 在写代码的时候用的肯定都是analytic gradient 但是需要在应用之前用numerical gradient检查一下，确保两者的结果是一样的，为了保证代码里面写的积分是正确的 gradient descent mini-batch 在实际应用的时候，不会把整个的训练集都拿来优化W，而是会把一部分拿出来（sample examples） 一小点一小点的拿结果不会非常准确，但是可以step很多次，在实际应用里面一般都不会用整个training set，不是很现实而且效果不是很好。 选择的数量上 32/64/256，这个不是一个很重要的hyperparameter，主要是根据GPU的性能来决定的 最终结果的loss是会下降的，虽然noise很多但是最终会go dowm learning rate 图片中使用linear classifier因为图片像素太多了，不可能对每个像素都用线性分类，所以一般会先提取一些特征然后得到最终的分类结果 color histogram 先得到一张图片的颜色特征分布 然后把整个特征分布拽成一个长的vector进行分类 HOG/SIFT 找到边缘特征，在图片的哪个部分有那种样子的edge bag of words 先把图片里面的一些特征当作一个vocabulary，然后放进一个词典里面 找到词典里每个词出现的频率然后拽成vector 线性分类 总结一般都是先进行特征提取然后再进行线性分类 深度学习特征都是自己提取 Backpropagation &amp; neural network目的：求出来loss function的gradient backpropagation最右边的点因为是df/df所以结果就是1 forward pass：知道开始然后一直顺到结束 在一个node上面，收到了x和y的input，对他们进行f操作，得到最终的结果z z再往后操作得到最后的loss（不知道什么操作） backward pass：从后到前，通过链式法则倒回来 虽然不知道loss对x或者y的gradient，但是可以求出来dz/dx和dz/dy（只和这个点有关） 可以得到dL/dz，然后乘以local gradient local gradient 每一个node上面的gradient往前推的时候，都可以通过链式法则（chain rule）变成这个点输入的gradient和这个点到上一个点的gradient的乘积。 算local的时候，乘的参数是输入进去的参数啊。比如dL/dx = dL/dz（这个带这个点back回来的数字） * dz/dx （这个里面的x带这个点输入进来x的值） 想不明白的时候把不同的点假设成不同名字然后求导！ 在这个网络里面，如果gate是加法（x + y）的话不是求偏导，如果求x的导数的话y并不是参数而是常数，所以求出来的结果是1，所以加法的gate就是直接把这个值相等的分开 加gate是一个gradient distributor，当一个gradient进来的时候会被相同的分开成了两份 也可以把一些gate组成一个大的gate，比如sigmoid 注意，求出来的gradient如果是正的，说明这个点对最终的loss有positive的作用 patterns add：gradient distributor max：router 假设f是max（x，y） local gradient对最大的那个就是1，对其他的都是0 因为如果没能通过max的gate的话根本对后门的loss没有影响。back的时候走最大的点就可以了，其他的都不用管了 multiply：switcher，真，两极反转 当往回的时候，两个点指向一个点，gradient需要相加（如下图） Implementationpsuedocode graph or net object forward: 把input pass进这个gate里面（必须在代码里面记住input） 把整个computational的garph往前推动 最后一个gate会return这个网络的loss backward 输入dz，然后乘不同的x和y 不同的gate分别是不同的文件（API），每个文件里面包括初始化，forward和backward 每次update的时候都需要进行forward和backward，forward得到gradient，backward再回来求最终的loss vectorized 在实际的计算中x，y，z都是矩阵，dz/dx是jacobian矩阵（全部都由偏导组成的矩阵） 比如一个max的门，如果输入是1x4096，输出也是1x4096，但是求偏导出来的矩阵是4096x4096（太大了），矩阵中间只有对角线部分的是需要考虑的（还会有很多0） 然后如果用了minibatch的100，得到的结果就是409600了，更可怕了 所以在每次API的时候，肯定不能写出来所有的链式法则，只用其中的一部分 作业的重点就是如何让这个东西计算出来效率高 neural network两层的NN 输入是图片一共的坐标数量 先通过第一层（max）得到100的中间层（hidden layer）-&gt; 100是hyperparameter，自己定的，但是越多越好吧 然后通过W2得到最终的分类结果（分10类） 其实具体里面是什么东西真的是不知道的？ 神经元 每个神经元的输入是Wx+b，然后经过激活函数 输出 激活函数 activation function sigmoid tanh ReLU 层状 -&gt; 可以更加efficient Neural network 2（training part1）前方提示： 小的dataset也可以有结果 电脑的性能有限 回顾一下历史 perceptron -&gt; 激活函数：0或者1，不能back madaline··· activation function（一个hyerparameter）sigmoid 特点： 把所有的数值都压到了0到1之间 曾经非常受欢迎，因为satrating的效果比较好 问题： 在saturate的情况下（非常接近0或者1），会杀死gradent -&gt; 看函数的图就能感觉出来-10做哟的导数就是0了，back回来没有意义 output不是以0为中心的（预处理的时候希望是0中心的） 不是0中心的问题：如果所有输入的x都是positive的话，得到的gradient要不都是positive要不都是negative 最后走出来的路径都是zig zag的 exp（）在计算上比较expensive tanh 把数字从-1到1之间分布，是一个以0为中心的sigmoid（0-centered），所以sigmoid的缺点（saturated的点会kill gradient）的缺点还在 ReLU 输入是正数的时候直接pass这个值，输入是负数的时候直接kill 可能的优点：（实际应用的时候效果非常好但是具体解释起来也没有那么知道为什么） 不会saturate（不会消失gradient） 计算效率高 更容易相交 问题 不是0-centered 如果x小于0（没有激活） -&gt; kill gradient） 死的时候会死一大片 -&gt; 所以一般的时候会把relu初始化的时候加上一个slightly positive bias 注意learning rate，选不好容易死 leaky ReLU 在小于0的时候会有一个微小的值，所以不会die 在使用的时候converges的速度比sigmoid和tanh快很多 加上了一个参数，可以在back的时候学到，这个值可以确定他是不是ReLU或者其他的 Maxout neuron 把ReLU和leaky ReLU组合了起来，有两个参数。算出来两个分别的值然后取其中大的那个 不会发生saturate或者die的问题 问题在于参数需要计算两次 步骤： 预处理数据 -&gt; 选择architecturedata preprocessingML 处理数据的时候首先需要0-center -&gt; 减去平均值（不是特别需要normalize，ML需要） PCA，Whitening，其实都在DL里不怎么常用 实际应用里：只需要center 比如一张图是32x32x3的 减去mean image（32x32x3） 减去per-channel mean （每个channel的mean，一共是三个数字） weight initialization（重要）请不要这么做：set所有w都是0，得到的结果就是每个神经元的功能都是一样的 small random numbers 0.01* np.random.randn(D,H) 问题： 在比较小的net里可以使用 在layer之间会发生non-homogeneous distribution of activation的问题 所有的activations会变成0 在back的时候所有的gradient都会变成0 如果把0。01变成了1，这时候发现所有的neurons全都是1或者-1 -&gt; gradient也全都是0，死亡 其他的一些论文也讨论过其他方法 Xavier 2010 除以input的sqrt ReLU， non-liear，会breaking。每回relu都会杀掉一半的东西，set到0 He 2015 把input除以2以后sqrt了 在实践中很有用 batch normalization -&gt; 实际中解决w初始化的方法 核心思想：x越来越接近0的原因是因为越乘越小（或者越大），这个时候我们就希望可以normalize这个x的input。因为gaussian的normaliztion是可以积分的，所以可以放回到back里面，在整个的网络里面插入一些normalize的部分就可以了 插在FC或者CNN之后，然后放在激活函数之前 优点 提高net里面的gradient flow 允许更高的学习率 减少对初始化参数的影响 form of regularization -&gt; 可能可以减少dropout的需求 babysitting &amp; learning process检查loss算的对不对 初始化这个net，去掉regularization，检查最后返回的loss 因为什么都没做呢，所以loss应该是最终知道的值（10 class是2。3） 再加上regularization，结果应该小小的变化 尝试训练 overfit一个非常小的dataset，关掉reg，得到非常小的loss和很高的accuracy 一个可能性：建议以一个小的reg开始，找到让loss变小的learning rate（如果不变小可能是rate太小了） cost：NaN，可能是learning rate高了 建议范围： 1e-3 ~ 1e-5 hyper optimization交叉验证 找到准确率高的部分，使用其中的hyper 最好set到log的space 再调整parameter，找到更准确的值 如果结果特别好可能也不对，可能是已经到了boundary了 参数的选择sample randomly的结果更好，不要固定一个选另一个，可能一个参数比另外一个重要很多 如果训练和验证之间的gap太大，说明overfitting，需要增加reg的力度。如果太小可能需要增加model的容量 ratio between the values and updates: ~ 0.0002 / 0.02 = 0.01 (about okay) 需要选择的hyper net architecture learning rate. decay schedule and update type regularization(L2/Dropout) ##总体summary training Neural Net2parameter updateSGD 以前是直接用gradient来update，现在希望变得复杂一点 -&gt; SGD太慢了 为什么SGD太慢： 如果在一个loss的分布上，一个维度特别密集，另一个维度特别稀疏，直接用gradient改变就会在一个方向跑大了 最后就会形成那种zag的形状 momentum update 在计算的时候引入了速度v = mu v - learning_rate dx （v初始化为0） 假设路线就是一个球在loss的圆弧里面运动，mu是～0.5，0.9，0.99（只使用一个值，single number，hyper） 形态，从初始点开始走一个大的圆弧，会跑过了，但是会再快速的converge回去 优点 引入了速度，可以在比较shallow的方向上速度逐渐增加 在比较深的维度上面，就像球在圆弧里面来回滑动 理解 是对这个update一点物理上比较直观的理解（其实名字叫做动量） 可以理解为这个东西是在一个平原上跑的一个球，我们需要求的w是这个球的速度，得到的dw是这个球的加速度，而这个球的初速度是0 可以理解为这个球找最低点的时候，除了每步按dw update，还在上面加上了前面速度的影响，也就是加上了惯性！123# Momentum updatev = mu * v - learning_rate * dx # integrate velocityx += v # integrate position nesterov momentum update 在上面的方法之后 look a head 了一步，得到的是两个向量之间的差 在实际走的过程当中，弧度会比monnument的更大一些，跑过的会更小一些 理解 Nesterov Momentum(NAG) 在原来的基础上：真实移动方向 = 速度的影响（momentum）+ 梯度的影响 （gradient） 现在：既然我们已经知道了要往前走到动量的影响的位置，那么我根据那个位置的梯度再进行update，岂不是跑的更快！ 总的来说就是考虑到了前面的坡度（二阶导数），如果前面的坡度缓的话我就再跑快点，如果陡的话就跑慢点123v_prev = v # back this upv = mu * v - learning_rate * dx # velocity update stays the samex += -mu * v_prev + (1 + mu) * v # position update changes form adaGrad （parameter-adaptive） 首先定义了一个cache，这个cache是gradient的平方的和，只是positive，和parameter的维度是一样的 然后把SGD的学习率（全局的learning rate）scale了一个这个数 -&gt; 这样得到的是不同参数的学习率 “ Added element-wise scaling of the gradient based on the historical sum of squares in each dimension” 结果：在越密集的维度上，update的步伐越小，越稀疏的上面update越大（因为平缓的地方历史gradient的平方和更小，所以update会更大） 问题 step size：时间越长learning rate会最终变到0，然后就停止学习 RMSProp（上面一个的变形） 把cache的定义改变了，增加了一个decay rate（hyper） adaGrad会计算的是所有梯度的平方的和，而这个计算的是gradient对应的平均值，这样的话learning rate的下降会更慢 依然能保持各个维度上面的平衡，但是不会让learning rate变到0 adam -&gt; 另一种自适应学习率的算法 beta都是hyper 结合了上面的两种方法 利用梯度的一阶矩和二阶矩估计动态调整每个参数的学习率 -&gt; 每次迭代学习率会有一个范围，让参数比较平稳 对梯度的一阶和二阶估计（期望的近似） 实际使用 默认用adam 刚开始使用高的learning rate -&gt; 这样进展会非常快 decay over time -&gt; 在进行到一定程度的时候会没有办法更细致的逼近minimum step decay: 比如过一些epoch之后就把lr减少到一半 exponential decay 1/t decay secend order optimization method（ml） 在计算的时候不仅需要gradient，还需要hessian来告诉你曲面的curve程度，以此来确定如何前进（牛顿method） 速度更快，hyper更少 但是在deep nets里面不太能使用，因为参数太多惹 BFGS（approximate inverse Hessian with rank 1 updates over time (O(n^2) each). L-BFGS work well in full batch mini-batch不是很适用 evaluation：model ensembles 可以不用训练很多个model，而是训练一个然后在其中选取不一样的check point track一个参数vector的running average可能会得到更好的效果 regularization（DROPOUT） 在forward的时候，随机的把一些neruon的值设置成0（比如杀掉一半） 为什么要使用： 为了求出来的结果更加的准确，每个特定的特征都不能完全依赖，因为这个feature可能就被drop掉了 计算一个大的net的其中一小部分，被drop掉的部分在back的时候也不会再计算了，就彻底关掉了。相当于在net里面取了一部分sample test time 在测试的时候希望可以把所有的neuron都打开（就进行一次） scale！！！！ 需要注意的问题： 计算训练时候的期望，就发现dropout之后的期望是测试的实际值的1/2（因为drop了一半） 因为以前net没见过这么大的output，会直接死掉，所以需要把测试时候的结果再缩小一半（或者drop的比例，* p） 最终结果：测试时候的输出 = 训练时候的期望输出 另一种方法 inverted dropout 在train的时候 / p 在测试的时候就不用改变了 gradient checking（并没有讲）CNN开始啦卷积层（核心部分） 对一张图片操作： 拥有一张图像32x32x3 拥有卷积核5x5x3（这两个东西必须维度一样） -&gt; 奇数尺寸的效果更好 kernal做卷积（所有的channel），得到一个28x28x1的activaton map 再对这张图片使用下一个不同的卷积核（卷积核的数量是一个hyper） 这样一个32x32x3变成了一个28x28x6（6是选择的hyper的数量） 当把这些层可视化了之后，发现越深图片的feature越高级（从上一级的特征得到的新的特征） 大致布局 卷积层 RELU层 -&gt; 黑白化 pooling层 最后加上fc层 具体计算stride 每次卷积核移动的时候的步长 注意在不同图片大小，不同卷积核大小和不同步长可能不匹配 （图片 - 卷积核）/步长 + 1 是不是整数，结果是输出图片的尺寸 padding 可以在图片周围一圈加上一圈0，这样图片卷积之后的大小就不变了 0-padding的大小和卷积核的大小有关，大小是（卷积核 -1）/2 如果不进行padding，图片会越来越小 参数数量 对一个卷积核：卷积核的大小 * 深度 + 1 （加一是加了一个bias） 一层的参数： 卷积核数量 * 一个卷积核 四个hyper： K：filter的数量，2的指数 -&gt; 计算效率高 S：步长 F：卷积核大小 P：0-padding 1x1的卷积 1x1的卷积层（stride也是1）会有比较好的效果 比如输入是56x56x64，filter是32个1x1x64。因为数据是有深度的，1x1的时候是有意义的（在二维上面没有意义） 现在处理的东西都是方形的从神经元的角度来看CNN 可以把filter认为成一个固定位置的神经元，这个神经元只看到了图片上面的一小部分，没有和全部的图片相连，然后进行了wx+b的运算 当slide这个filter的时候，weight是不变的，可以假设成一圈共享参数的神经元 对同一张图片的不同的filter可以认为成他们是在三维上面排列的一组神经元，每一层神经元都和这一层共享参数（不希望全部都是全联接，因为浪费了很多参数） pooling 在卷积的时候是不会改变图片的大小的 改变图片大小的操作在pooling layer里面实现 长宽缩短，深度不变 max pooling 2x2pool，stride2 -&gt; 每4个格子里面选择一个最大的表示 两个参数 pooling size F 2，3 stride S 2，2 不会改变图片的深度 fully connected 就跟普通的神经网络一样，所有神经元之间都会连接 把最后的图片变成一个列，放进去开始计算 实际应用LeNet-5AlexNet 两天不同的线，因为当时的GPU的效果不够 优点： 第一次使用ReLU 把data normalization了，但是现在看其实并不需要 data augumenation -&gt; 有用！ dropout 0.5，最后几层 ZFNet 在第一层上比alex的stride短，因为alex的步长4跳过了太多图片信息，这里改成了步长2 fliter的数量更多 VGGNet 只有3x3 s1 p1的卷积核，和2x2 s2的max pooling 结果还特别好 图像的尺寸越来越小，但是深度越来越高 需要的计算量：93MB/image（forward） -&gt; 200m/image(所有的计算加起来) 大部分的memory都在前期的层里，大部分的参数都在最后的全链接层里面（最后的计算量太大，后面有更好的方法） VGG也有位置确定，他比overfeat的层数更深 GoogLeNet 是一个一个的小结构组成出来了 参数的数量非常少 5million，取消了fc层 使用了average pool，把7x7x1024变成了1x1x1024 :把每个activate map取平均值 用VGG的人更多因为VGG的结构比较好想2333 ResNet t5 error降到了3.多 平常的加深层数训练集和测试集上边的准确率变化结果不统一，但是res做到了统一 虽然层数特比多，但是速度还是快 -&gt; 加入了skip的部分，把输入跳过了卷积又加了回去，这样back的时候就会分流 top-5 error 在看结果的时候不光看准确率，还会看分类器认为的前5个可能性（可能有几千个分类），如果这5个可能性都不对的话就是求出来的就是top-5 error spatial localization and detection这章的主要内容是识别出来这个东西之后用框框框出来 分类+定位：Localization as Regression 实际上就跟regression差不多 neurral net的输出是bounding box（4个数字），左上角的坐标和长宽 实际的图片标注的内容也有左上角坐标和长宽，求出这两个部分的L2 distance作为loss 步骤 训练（下载）一个分类的model 在net里面加上fc的regression head 用SGD和L2loss训练regression head部分 test的时候分类和regression都用 类别 平常的分类：最终的数量和class的数量相同 一个box里面会有4个数字，一共Cx4个数字 加在什么地方 conv layer之后 fc之后 多个目标的检测（Aside） 知道准确的检测目标的数量k，那么最终的分类数量就是4 * k 应用：人的动作检测 -&gt; 得到关节的位置 分类 + 定位：sliding window：overfeat 核心idea：在检测的时候直接process图片，但是对一张图片在不同的地方进行多次操作 操作步骤： 首先对图片进行conv和pooling，然后对得到的结果进行两个不同的fc， 得到的是1000个的分类种类 另一个的到的是1000x4的bounding box坐标 在一张大的图片上，在不同区域找到需要寻找的东西（比如分成四部分，这四部分是有重叠的，不是pooling那个样子） 得到每个部分对于这个分类的得分，以及相应部分对应的bounding box 最后用没怎么讲的办法merge了这些框，得到了最终结果 进一步优化 因为要对这个图片的不同crop做cnn，计算量会非常大 在fc层其实只是一个向量1x4096，把这个玩意拉成了一个cnn，4096x1x1，然后直接conv1x1的卷积核 现在net里面就只有conv和pooling了，所以就可以处理不同尺寸的图片了（不同尺寸的方形） 而且在处理不同区域的时候是参数是share的 目标检测 主要不同：不能确定图片里面物体的数量 思路： 尝试所有可能的window然后用classifcation找到需要的部分 问题：需要很多次分类 历史解决方法：用非常快的分类器，尝试所有（linear classifier） 更想用的方法：用cnn，只测试tiny subsets of possible locations region proposals 输入一张图片，输出所有可能有物体的区域 不在意到底是什么类型 不在意精确度 但是速度很快 selective search 从一个pixel开始，如果相邻的pixel有一样的颜色或者texture，merge 形成连接区域，再连接不同区域，这个区域也可以再打散 还有很多其他方法：edge boxes（推荐） RCNN（region based CNN） 从输入图片里面用region proposal的方法得到一系列的boundings（不同的位置和scale） 对每个区域crrop和wrap这个区域到fixed size cnn分类，regression head &amp; classifcation head 过程 下载model fine-tune for detection：改变分类的种类等 extract features 为每个class训练一个SVM（看这个区域是否包括寻找的东西） box regression：对每个种类，训练一个linear regression来纠正位置的偏差（太左太右，空隙太多）（dx，dy，dw，dh） datast PASCAL VOC 比较小 ImageNet 不是事很好操作，但是一张图一半只有一个东西 MS-COCO 一张图多个内容 fast RCNN （提速） 在测试时的速度比较慢 -&gt; 一张图里，在不同的proposals之间share conv的计算 训练时不是一起训练的，训练的pipeline也很复杂 -&gt; 把整个系统端对端对的训练一次 ROI pooling 在用的时候希望感兴趣区域的分辨率比较高，fc层希望更低的conv feature 在conv feature map上面投影高分辨率的region proposal 把这个区域分成小格，然后对每个格子进行max pooling(back的时候也是这么回来) 训练8倍！测试146倍！结果更准确！ faster RCNN（再提速） 之前的测试速度计算都没有算region proposal的时间，所以把这个问题也交给conv去干 在最后一层conv后面加入region proposal net 在feature map上面的移动实际就是卷积 训练一个小的网络判断是不是一个物体并分类，以及regression框的位置 在每个位置使用了N anchor boxes，不同的anchor有score来判断他是否属于一个object，在不同的形状上有不同的可能性（？ 后续的paper里面可以一口气train了 yolo 把detection变成了regression的问题 分成不同的小块，在每个块里面都加入 visualization, deep dream, neural style可视化：观察神经网络如何工作 可视化不同位置 可视化activation的神经元 -&gt; 大量的图片扔进神经元里面，找出来一个神经元最感兴趣的部分 可视化fliter -&gt; 只能在第一层进行（其他的层可以但是意义不大） 但是啥算法都会得出来长得差不多的 可视化特征（全联接层的特征向量） -&gt; t-SNE：Embed high-dimensional points so that locally, pairwise distances are conserved，特征相似的东西会聚类 对图片进行遮罩，可以看出来遮住不同地方这张图片被识别出来的概率 deep conv和optimazation的可视化工具：http://yosinski.com/deepvis deconv实现问题1:如何计算任意一个神经元的梯度（代码实现） 找到想要的神经元，forward的时候就停在这里 然后进行back，把所有其他的神经元的都设置成0，只把感兴趣的神经元设置成1，然后计算back出来的结果 最后的结果看起来并不是很好理解，所以改变了back的方法，得到更好的结果（“guided back”） guided back的计算方法 在普通的计算中，back的时候使用relu，会把所有负值都转化成0 在guide的计算里，在激活之后的东西back回去的时候，如果input的东西是负数的话，也会把这个东西kill成0，也就是说一个是block back的时候的gradient的值，另一个还会附加block输入进来的值 发生了什么：把输入进去ReLU的负的影响也取消掉了。如果不取消的话，这些正负就会互相fight，呈现更奇怪的图片。但是去掉负的之后变得就更清晰了。 deconv：直接无视掉relu的存在了 第二个问题：图像优化 how to find an image maximize some class score，但是整个网络不变 输入一张全0的图片 在back的时候把score设置成[0,0,0,1,0,0,…]，只有感兴趣的是1 back回去，找到对图片会产生什么影响 不停的重复这个步骤，更新的是图片不是weight 效果 找到可以让一个类型分数最高的图片（图片是根据网络生成的） 可视化data的梯度 -&gt; 得到了一个类似热量图的东西，这样对黑色的部分改变对这个东西的分类没有很大的影响 上面的步骤可以对任何的神经元进行（生成一张图片） 更好的regular 忽视了惩罚，只max神经元 但是更新之后blur了一下图像，这样可以阻止图片进行高频率积累 第三个问题，CNN的code包含多少信息 是否可以通过net还原出来原来的图片（涉及到隐私泄露的问题） 越往后的时候预测的准确度越低 deep dream 一个非常简单的过程，只有几百行代码，就是optimazation image 每次调用make_step图片都会发生微小的改变 把网络forward到一个位置 把gradient设置成activation设置成一样的 再往回传回去 可以强调对图片贡献最多的部分，不管激活了什么，都会把这个激活加强 deepart 把目标的content传进CNN 把style contet也传进CNN 把目标的loss和style的loss匹配，然后得到相应的opt image 是否可以用生成的图片去fool CNN 把图片的gradient设置成其他的东西，本来希望可以得到混合的结果，但是实际上图片的distort根本看起来不变 有些图片人类看起来差不多，但是gradient（或者HOG）之类的可能彻底是其他的东西 原因： 图片有很高维度的空间 实际训练的图像有一小部分被约束，放了一个线性分类之类只调整了其中的一小部分 在线性分类里，如果在每个维度上面都改变了一点点，实际上的置信区间会发生特别大的改变（大规模的点积运算）.下图只加进去了一点点的金鱼的噪音，分类就变成了100%的金鱼 这个现象不仅仅发生在图片里面，也发生在其他的地方 RNN（recurrent neural network）普通的nets：大小都是固定的 one to oneRNN：可以有灵活的对应结果 一系列的词来描述这张图 machine translation：seq of words -&gt; seq of words frame level的视频classification RNN是什么 可以在任何时间接受一个input（vector），然后对于不同的state产生不同的预测结果，然后需要在一些时间中预测出来vector。只需要特定的情况，其他的情况虽然有但是没有记录下来 过去的状态 + 新的input + 参数w -&gt; 预测出来新的state 注意：同样的function里面的weight是固定的，在不同时间使用但是weight是一样的 比如例子：https://gist.github.com/karpathy/d4dee566867f8291f086 输入一个字母的序列h e l o 预测下面的字母是什么，训练的模型是hello 把每个字母分别feed进去，顺着这个字母顺序来优化参数的序列，因为知道下一个的结果是什么了，就可以朝着这个目标来努力 竟然可以生成句子数学公式甚至代码 在图片中开始使用 从一张图得到一系列的文字 两部分组成 CNN：把test图片输入到CNN，一直到最后的fc，但是然后不进行分类，输入RNN RNN：RNN不仅是现在的输入，还会加入了CNN里面出来的输出。然后得到的结果（得到了没准一个词）进入下一个循环（就跟生成语义的时候一样） 直到在RNN里面找到的token，然后结束RNN LSTM long short term memory（大概是个生物里面的东西） RNN有好多层，每层还有很多个参数来决定这层往哪走 有两个输入x和h，组合到w上面，然后不同的东西乘不同的激活函数 x来自below h是从上一回来的 基于gate和function（forget gate）的类型，会更新c的值（反正都是参数的） 进行这些奇怪的操作的原因就是找到一个平衡和更好的结果 比较 每次普通的RNN都要经过f gate，会彻底改变。back的时候gradient会消失或者爆炸 LSTM里面用加法跳过了这个门，有一定的影响但是没有彻底改变，gradient的消失问题会被控制住（因为只用了加，不会die） gradient clipping可以控制住gradient爆炸 作业相关内容安装anaconda！！！ conda activate cs231npython3 -m IPython notebook 打开！！assignment1knn 两次循环计算距离 不需要一个像素一个像素的计算，用X直接表示i对应的那行的像素值的和，直接做差（每一项之间，平方（每一个，求和（所有项），开方。会快很多！！！！ 12#dists是一个500x5000的矩阵（测试数量和训练数量）dists[i,j] = np.sqrt(np.sum(np.square(X[i] - self.X_train[j]))) 初始化数组的方法是 np.array([[],[]]) 如果一个像素一个像素的循环结果简直太可怕了，害怕]]></content>
      <categories>
        <category>图像处理</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
</search>
