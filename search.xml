<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[å…³äºŽGit]]></title>
    <url>%2F2019%2F10%2F27%2F%E5%85%B3%E4%BA%8EGit%2F</url>
    <content type="text"><![CDATA[Git ä»€ä¹ˆæ˜¯åˆ†æ”¯ Gitå¸¸ç”¨å‘½ä»¤ é›†ä¸­å¼ç³»ç»Ÿå’Œåˆ†å¸ƒå¼ç³»ç»ŸGitå±žäºŽåˆ†å¸ƒå¼ï¼ŒSVNï¼ˆsubversionï¼‰æ˜¯é›†ä¸­å¼çš„ç³»ç»Ÿ é›†ä¸­å¼åªæœ‰åœ¨ä¸­å¿ƒæœåŠ¡å™¨æœ‰ä¸€ä»½ä»£ç ï¼Œåˆ†å¸ƒå¼åœ¨æ¯ä¸ªäººçš„ç”µè„‘ä¸Šéƒ½æœ‰ä¸€ä»½ä»£ç  é›†ä¸­å¼ç‰ˆæœ¬æŽ§åˆ¶æœ‰å®‰å…¨æ€§é—®é¢˜ï¼ˆä¸­å¿ƒæœåŠ¡å™¨æŒ‚äº†ï¼‰ é›†ä¸­å¼éœ€è¦è”ç½‘æ‰èƒ½å·¥ä½œã€‚ åˆ†å¸ƒå¼æ–°å»ºåˆ†æ”¯ï¼Œåˆå¹¶åˆ†æ”¯çš„æ“ä½œæ¯”è¾ƒå¿«ã€‚é›†ä¸­å¼æ–°å»ºåˆ†æ”¯ç›¸å½“äºŽå¤åˆ¶ä¸€ä»½å®Œæ•´ä»£ç  ä¸­å¿ƒæœåŠ¡å™¨Githubä½œä¸ºä¸­å¿ƒæœåŠ¡å™¨ç”¨äºŽäº¤æ¢æ¯ä¸ªç”¨æˆ·çš„ä¿®æ”¹ï¼Œæ²¡æœ‰ä¸­å¿ƒæœåŠ¡å™¨ä¹Ÿèƒ½å·¥ä½œï¼Œå€’æ˜¯ä¸­å¿ƒæœåŠ¡å™¨24å°æ—¶å¼€å¯æ–¹ä¾¿äº¤æµã€‚ å·¥ä½œæµ æ–°å»ºä»“åº“ä¹‹åŽï¼Œç›®å‰çš„ç›®å½•å°±æˆä¸ºäº†å·¥ä½œåŒºã€‚å·¥ä½œåŒºæœ‰ä¸€ä¸ªéšè—ç›®å½•.gitï¼Œå±žäºŽGitçš„ç‰ˆæœ¬åº“ åœ¨ç‰ˆæœ¬åº“é‡Œé¢ï¼Œæœ‰ä¸€ä¸ªStageçš„æš‚å­˜åŒºï¼Œä»¥åŠHistoryç‰ˆæœ¬åº“ã€‚åœ¨Historyé‡Œé¢ä¼šå‚¨å­˜æ‰€æœ‰çš„åˆ†æ”¯ï¼Œç„¶åŽä¼šä½¿ç”¨HEADæŒ‡é’ˆæ¥æŒ‡å‘ç›®å‰åˆ†åŒº ä½¿ç”¨ git add ä¼šæŠŠæ–‡ä»¶æ·»åŠ åˆ°æš‚å­˜åŒºï¼Œä¹Ÿå°±æ˜¯Stage ä½¿ç”¨ git commit ä¼šæŠŠæš‚å­˜åŒºçš„ä¿®æ”¹æäº¤åˆ°å½“å‰çš„åˆ†æ”¯é‡Œé¢ã€‚æäº¤ä¹‹åŽæš‚å­˜åŒºå°±æ¸…ç©ºäº† ä½¿ç”¨ git reset â€“ ä¼šä½¿ç”¨çŽ°åœ¨çš„åˆ†æ”¯å†…å®¹è¦†ç›–æš‚å­˜åŒºï¼Œä¹Ÿå°±æ˜¯æ’¤é”€æœ€åŽä¸€æ¬¡addçš„æ“ä½œ ä½¿ç”¨ git checkout â€“ ä¼šç”¨Stageçš„å†…å®¹è¦†ç›–æœ¬åœ°å†…å®¹ï¼Œæ’¤é”€æœ€åŽä¸€æ¬¡æœ¬åœ°ä¿®æ”¹ä¹Ÿå¯ä»¥ç”¨å¤åˆå‘½ä»¤æ¥è·³è¿‡Stageçš„éƒ¨åˆ† å¦‚æžœä½¿ç”¨ git commit -aå¯ä»¥ç›´æŽ¥æŠŠæ–‡ä»¶çš„ä¿®æ”¹å…ˆåŠ åˆ°æš‚å­˜åŒºï¼Œç„¶åŽå†æäº¤ å¦‚æžœä½¿ç”¨ git checkout HEAD â€“ å¯ä»¥å–å‡ºæœ€åŽä¸€æ¬¡ä¿®æ”¹ï¼Œä¹Ÿå°±æ˜¯å¯¹æœ¬åœ°æ–‡ä»¶è¿›è¡Œå›žæ»šæ“ä½œ åˆ†æ”¯çš„å®žçŽ°åœ¨Gité‡Œé¢ï¼Œä½¿ç”¨äº†æŒ‡é’ˆæŠŠæ¯æ¬¡çš„æäº¤éƒ½è¿žæˆä¸€æ¡çº¿ï¼ŒHEADä¼šæŒ‡å‘å½“å‰çš„æŒ‡é’ˆ æ–°å»ºåˆ†æ”¯ä¼šåœ¨æ—¶é—´çº¿ä¸Šæœ€åŽä¸€ä¸ªèŠ‚ç‚¹æ–°å»ºåˆ†æ”¯ï¼Œå¹¶ä¸”HEADä¼šæŒ‡å‘æ–°çš„åˆ†æ”¯ã€‚è€Œå¯¹æ–°çš„åˆ†æ”¯çš„æ¯æ¬¡æäº¤åªä¼šè®©å½“å‰çš„æŒ‡é’ˆç§»åŠ¨ï¼Œå…¶ä»–çš„æŒ‡é’ˆä¸ä¼šç§»åŠ¨ åˆå¹¶çš„æ—¶å€™æ”¹å˜çš„ä¹Ÿæ˜¯Masterçš„æŒ‡é’ˆ å…³äºŽGitçš„åˆ†æ”¯(branch)ä»€ä¹ˆæ˜¯åˆ†æ”¯ åˆ†æ”¯çš„æ„ä¹‰ï¼šæŠŠçŽ°åœ¨çš„å·¥ä½œä»Žä¸»çº¿ä¸Šåˆ†ç¦»å¼€ï¼Œä»¥å…å½±å“å¼€å‘ä¸»çº¿ï¼ˆè¿™ä¹Ÿæ˜¯Gitæœ€å¤§çš„ä¼˜åŠ¿ï¼Œå› ä¸ºSVNå¼€å‘æ–°çš„åˆ†æ”¯ç›¸å½“äºŽå¤åˆ¶ä»£ç ï¼Œé€Ÿåº¦éžå¸¸æ…¢ï¼‰ ä¸ºäº†ä¸å½±å“å…¶ä»–äººçš„å¼€å‘ï¼Œå¯ä»¥åœ¨ä¸»çº¿ä¸Šå»ºç«‹è‡ªå·±çš„åˆ†æ”¯ï¼Œå·¥ä½œå®ŒæˆåŽåˆå¹¶åˆ°ä¸»åˆ†æ”¯ã€‚æ¯ä¸€æ¬¡çš„æäº¤ä¼šè¢«ä¿å­˜ï¼Œè¿™æ ·å‘ç”Ÿé—®é¢˜æ—¶å€™çš„å®šä½å°±æ›´åŠ å®¹æ˜“äº† åˆ†æ”¯çš„åº”ç”¨ mergeåˆ†æ”¯ï¼Œä¸ºäº†å¯ä»¥éšæ—¶å‘å¸ƒreleaseè€Œåˆ›å»ºçš„åˆ†æ”¯ã€‚é€šå¸¸å¤§å®¶ä¼šæŠŠmasterå½“æˆmergeåˆ†æ”¯æ¥ä½¿ç”¨ Topicåˆ†æ”¯ï¼šä¸ºäº†å¼€å‘æ–°åŠŸèƒ½æˆ–è€…ä¿®å¤Bugçš„åˆ†æ”¯ï¼Œä»Žmergeé‡Œé¢åˆ›å»ºï¼Œå®Œæˆä¹‹åŽéœ€è¦åˆå¹¶åˆ°mergeé‡Œé¢åŽ» åˆ†æ”¯çš„åˆå¹¶ mergeï¼ˆåŽ†å²è®°å½•ä¼šéžå¸¸å¤æ‚ï¼‰ å¦‚æžœä»¥å‰çš„masteræ²¡æœ‰æ”¹å˜ï¼Œå¯ä»¥ç›´æŽ¥åˆå¹¶ï¼ˆfast forwardï¼‰ å¯ä»¥åœ¨åˆå¹¶æ—¶åŠ ä¸Šâ€“no-ffæ¥è¿›è¡ŒFast forwardï¼ŒåŠ ä¸Š-mç”Ÿæˆä¸€ä¸ªæ–°çš„commit å¦‚æžœç›´æŽ¥fast forwardå¯èƒ½ä¼šä¸¢å¤±åˆ†æ”¯ä¿¡æ¯ å¦‚æžœä»¥å‰çš„æœ‰äº†æ–°çš„æ›´æ–°ï¼Œéœ€è¦æŠŠä¸¤ä¸ªåˆ†æ”¯ä¿®æ”¹çš„å†…å®¹ç»“åˆï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„æäº¤ rebaseï¼ˆåŽ†å²è®°å½•ç®€å•ï¼Œä½†æ˜¯å¯èƒ½ä¼šå¯¼è‡´åŽŸæ¥çš„å†…å®¹æ— æ³•æ­£å¸¸è¿è¡Œï¼‰ å¦‚æžœä½¿ç”¨è¿™ä¸ªæ–¹æ³•åˆå¹¶ï¼Œæœ€åŽå¾—åˆ°çš„ç»“æžœä¼šæ˜¯ä¸€æ¡çº¿æ€§çš„ã€‚å¦‚æžœåœ¨æäº¤çš„æ—¶å€™Xå’ŒYå‘ç”Ÿå†²çªï¼Œéœ€è¦ä¿®æ”¹å†²çªçš„éƒ¨åˆ† åˆ†æ”¯çš„å†²çªå¦‚æžœä¸¤ä¸ªåˆ†æ”¯å¯¹åŒä¸€ä¸ªæ–‡ä»¶éƒ½è¿›è¡Œäº†ä¿®æ”¹ï¼Œåˆå¹¶çš„æ—¶å€™å°±ä¼šäº§ç”Ÿå†²çªã€‚æŠŠä¸åŒåˆ†æ”¯çš„å†…å®¹ä¿®æ”¹æˆä¸€æ ·çš„å°±å¯ä»¥è§£å†³åœ¨Gité‡Œé¢ä¼šç”¨ &lt;&lt;&lt;&lt;&lt; ===== &gt;&gt;&gt;&gt;&gt;æ¥è¡¨ç¤º å‚¨è— Stashingåœ¨ä¸€ä¸ªåˆ†æ”¯ä¸Šæ“ä½œä¹‹åŽï¼Œå¦‚æžœæ²¡æœ‰æäº¤è¿™ä¸ªåˆ†æ”¯å°±è¿›è¡Œåˆ‡æ¢ï¼Œé‚£ä¹ˆåœ¨å¦ä¸€ä¸ªåˆ†æ”¯ä¸Šä¹Ÿèƒ½çœ‹åˆ°ä¿®æ”¹ã€‚å› ä¸ºæ‰€æœ‰çš„åˆ†æ”¯éƒ½å…¬ç”¨ä¸€ä¸ªå·¥ä½œåŒºåŸŸã€‚ å¯ä»¥ä½¿ç”¨ git stashæŠŠå½“å‰çš„åˆ†æ”¯ä¿®æ”¹å‚¨è—èµ·æ¥ï¼Œè¿™æ ·å°±å¯ä»¥å®‰å…¨çš„åˆ‡æ¢åˆ°å…¶ä»–åˆ†æ”¯ æ¯”å¦‚ï¼Œå¦‚æžœæ­£åœ¨devåˆ†æ”¯ä¸Šå¼€å‘ï¼Œæ­¤æ—¶æœ‰masterä¸Šé¢çš„bugéœ€è¦ä¿®æ”¹ï¼Œä½†æ˜¯devçš„å¼€å‘è¿˜æ²¡æœ‰å®Œæˆã€‚è¿™æ—¶å€™å¯ä»¥æ–°å»ºä¸€ä¸ªbugåˆ†æ”¯ï¼Œå¹¶ä¸”åˆ‡æ¢åˆ°bugä¹‹å‰å…ˆç”¨stashæŠŠç›®å‰devçš„å¼€å‘è¿›åº¦å‚¨å­˜èµ·æ¥ SSHä¼ è¾“è®¾ç½®Gitçš„ä»“åº“å’ŒGithubçš„ä¸­å¿ƒä»“åº“æ˜¯é€šè¿‡SSHè¿›è¡ŒåŠ å¯†çš„ .gitignoreè¿™ä¸ªæ–‡ä»¶å¯ä»¥å¿½ç•¥ä»¥ä¸‹çš„æ–‡ä»¶ï¼š æ“ä½œç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆçš„æ–‡ä»¶ï¼Œæ¯”å¦‚ç¼©ç•¥å›¾ ç¼–è¯‘ç”Ÿæˆçš„ä¸­é—´æ–‡ä»¶ è‡ªå·±çš„æ•æ„Ÿä¿¡æ¯ã€‚æ¯”å¦‚å­˜æ”¾å£ä»¤çš„é…ç½®æ–‡ä»¶ gitignore]]></content>
      <categories>
        <category>åŸºç¡€</category>
        <category>å·¥å…·</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ­£åˆ™è¡¨è¾¾å¼]]></title>
    <url>%2F2019%2F10%2F24%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[å‚è€ƒèµ„æ–™ï¼š è¯»æ‡‚æ­£åˆ™è¡¨è¾¾å¼å°±æ˜¯è¿™ä¹ˆç®€å• æ­£åˆ™è¡¨è¾¾å¼ æ­£åˆ™è¡¨è¾¾å¼ç½‘ç«™ åŸºæœ¬æ¦‚å¿µæ­£è¦è¡¨ç¾ï¼ˆã›ã„ãã²ã‚‡ã†ã’ã‚“ã€è‹±: regular expressionï¼‰å½¢å¼è¨€èªžåˆ†é‡Žç”¨äºŽæ–‡æœ¬å†…å®¹çš„æŸ¥æ‰¾å’Œæ›¿æ¢ï¼ˆå·®ã—æ›¿ãˆã‚‹ï¼‰ç”¨äºŽå…¶ä»–è¯­è¨€æˆ–è€…äº§å“è½¯ä»¶é‡Œé¢åœ¨ä½¿ç”¨çš„æ—¶å€™ä¸€å®šè¦æ³¨æ„è½¬ä¹‰ç¬¦å·\ï¼Œä¸ä½¿ç”¨è¿™ä¸ªç¬¦å·çš„æ—¶å€™ä»£è¡¨çš„æ˜¯çœŸå®žçš„å†…å®¹ï¼Œä½¿ç”¨äº†æ‰æœ‰ç›¸åº”çš„æ„æ€ æ­£åˆ™å­—ç¬¦å…ƒç¬¦å· è¢«åŒ¹é…çš„å­—ç¬¦ç¬¬ä¸€ä¸ªå¿…é¡»å’Œ^ä¹‹åŽçš„ä¸€æ ·ï¼Œæœ€åŽä¸€ä¸ªå¿…é¡»å’Œ$ä¹‹å‰çš„ä¸€æ · â€œ^â€ï¼š åŒ¹é…è¡Œæˆ–å­—ç¬¦ä¸²çš„èµ·å§‹ä½ç½® æ•´ä¸ªæ–‡æ¡£çš„èµ·å§‹ä½ç½® ï¼„ï¼šè¡Œæˆ–è€…å­—ç¬¦ä¸²çš„ç»“å°¾ \bï¼šç”¨äºŽåŒ¹é…è¾¹ç•Œï¼Œä¸æ¶ˆè€—å­—ç¬¦ï¼ˆBoundaryï¼‰ \bis\b ç”¨æ¥è¯†åˆ«isçš„ä¸¤è¾¹æ˜¯å¦æ˜¯è¾¹ç•Œ \dï¼šåŒ¹é…æ•°å­—ï¼ˆdigitï¼‰ æ¯”å¦‚0å¼€å¤´ï¼Œäº”ä½æ•°-&gt; ^0\d\d\d\d\d$ \wï¼šåŒ¹é…å­—æ¯ï¼Œæ•°å­—ï¼Œä¸‹åˆ’çº¿ï¼ˆåŸºæœ¬å¯ä»¥ç†è§£ä¸ºæ³¨å†Œç”¨æˆ·åçš„è¦æ±‚ï¼‰ \sï¼šåŒ¹é…ç©ºæ ¼ï¼Œ\s+å¯ä»¥è®©ç©ºæ ¼é‡å¤ .ï¼šåŒ¹é…é™¤äº†è½¬è¡Œç¬¦å·ä»¥å¤–çš„ä»»ä½•å­—ç¬¦ã€‚\wçš„åŠ å¼ºç‰ˆï¼Œç›¸å½“äºŽwåŠ ä¸Šç©ºæ ¼ []ï¼šåŒ¹é…åœ¨ç©ºå·å†…å…ƒç´ çš„å­—ç¬¦ï¼ŒåªåŒ¹é…å­˜åœ¨äºŽæ‹¬å·é‡Œé¢çš„ã€‚å¯ä»¥å†™æˆ[a-z] åä¹‰ä¸Šé¢çš„è¡¨è¾¾å†™æˆå¤§å†™ï¼Œå¦‚æžœæ˜¯[]çš„è¯å˜æˆ[^]ï¼Œè¡¨è¾¾çš„æ„æ€æ˜¯ä¸åŒ…æ‹¬è¿™äº›çš„å­—ç¬¦ é‡è¯æœ‰å…³é‡è¯çš„ä¸‰ä¸ªæ¦‚å¿µï¼š è´ªå¿ƒ * ä¼šé¦–å…ˆåŒ¹é…æ•´ä¸ªå­—ç¬¦ä¸²ï¼Œä¼šé€‰æ‹©å°½å¯èƒ½å¤šçš„å†…å®¹ï¼Œå¤±è´¥çš„è¯å°±backtrackingï¼ˆæ¶ˆè€—æœ€å¤§ï¼‰ æ‡’æƒ° ï¼Ÿä»Žèµ·å§‹ä½ç½®å¼€å§‹å°è¯•åŒ¹é…ï¼Œæ¯æ¬¡æ£€æŸ¥ä¸€ä¸ªå†…å®¹ï¼Œç›´åˆ°æ£€æŸ¥å®Œæ‰€æœ‰çš„å†…å®¹ï¼ˆç›¸å½“äºŽéåŽ†ï¼‰ å æœ‰ + è¦†ç›–æ•´ä¸ªå­—ç¬¦ä¸²ï¼Œç„¶åŽå¯»æ‰¾ã€‚ä½†æ˜¯å°±è¯•ä¸€æ¬¡ ç›¸å…³é‡è¯ï¼š è´ªå¿ƒ* ä¼šé‡å¤0æ¬¡æˆ–è€…æ›´å¤š â€aaaaaâ€œé‡Œé¢åŒ¹é…a* ï¼Œé‚£ä¹ˆå¾—åˆ°çš„æ˜¯æ‰€æœ‰çš„å­—ç¬¦a é‡å¤ä¸€æ¬¡æˆ–å¤šæ¬¡ï¼š â€aaaaaâ€œï¼Œa+ä¼šå–å­—ç¬¦ä¸­æ‰€æœ‰aå€¼ï¼Œä½†æ˜¯* å¯ä»¥æ˜¯0æ¬¡ï¼Œ+ä¸è¡Œ ? é‡å¤é›¶æ¬¡æˆ–ä¸€æ¬¡ â€aaaaaâ€œï¼Œa?åªä¼šåŒ¹é…ä¸€æ¬¡ï¼Œç»“æžœä¹Ÿæ˜¯å•ä¸ªå­—ç¬¦a {n}ï¼Œé‡å¤næ¬¡ï¼Œæ¯”å¦‚a{3}ä¼šåŒ¹é…aaa {n,m} é‡å¤n-mæ¬¡ï¼Œæ¯”å¦‚a{3,4}å¯ä»¥åŒ¹é…åˆ°aaaæˆ–è€…aaaa {n,} é‡å¤næ¬¡æˆ–æ›´å¤šæ¬¡ï¼Œä¹Ÿå°±æ˜¯è‡³å°‘é‡å¤næ¬¡ æ‡’æƒ°é™å®šç¬¦ï¼ˆå¤§å®¶å’Œï¼Ÿçš„æŽ’åˆ—ç»„åˆï¼‰ *ï¼Ÿ é‡å¤ä»»æ„æ¬¡ï¼Œä½†æ˜¯å°½å¯èƒ½å°‘é‡å¤ æ¯”å¦‚ acbacbï¼Œæ­£åˆ™ a.*?bï¼Œåªä¼šåŒ¹é…acbï¼Œå› ä¸ºéœ€è¦.é‡å¤çš„æ•°é‡å°½å¯èƒ½å°‘ +ï¼Ÿé‡å¤1æ¬¡æˆ–è€…æ›´å¤šæ¬¡ï¼Œä½†æ˜¯å°½å¯èƒ½å°‘é‡å¤ ?? é‡å¤0æ¬¡æˆ–ä¸€æ¬¡ï¼Œä½†æ˜¯å°½å¯èƒ½å°‘é‡å¤ {n,m}é‡å¤n-mæ¬¡ï¼Œä½†æ˜¯å°½å¯èƒ½å°‘é‡å¤ã€‚æ¯”å¦‚a{0,m}?å–åˆ°çš„æ˜¯ç©º {n,}ï¼Ÿè‡³å°‘é‡å¤næ¬¡ï¼Œå°½å¯èƒ½å°‘é‡å¤ è¿›é˜¶æ•èŽ·åˆ†ç»„å¦‚æžœç»™ä¸€éƒ¨åˆ†çš„å†…å®¹åŠ ä¸Šäº†æ‹¬å·ï¼Œè¿™éƒ¨åˆ†çš„å†…å®¹å°±è¢«æŠ“ä½äº†ã€‚ç„¶åŽå¦‚æžœåŽé¢ç”¨åˆ°äº†ç›¸åŒå†…å®¹çš„è¡¨è¾¾å¼ï¼Œå°±å¯ä»¥ç›´æŽ¥ç”¨ä¸€ä¸ªç¬¦å·ä»£æ›¿ï¼Œè€Œä¸ç”¨ç»§ç»­å†™ä¸€ä¸ªäº†ã€‚ä¸è€ƒè™‘é‡å¤ä½¿ç”¨çš„æ—¶å€™ï¼Œä¹Ÿå¯ä»¥å•ç‹¬åªç”¨äºŽåˆ†ç»„ï¼Œåˆ†ç»„ä¹‹åŽçš„å†…å®¹å¯ä»¥åŠ ä¸Š+ * ï¼Ÿç­‰å†…å®¹è¿›è¡Œé‡å¤ã€‚ä½†æ˜¯æ³¨æ„åµŒå¥—å±‚æ•°è¿‡å¤šä¼šå¼•èµ·æ­§ä¹‰å¸¸ç”¨å†™æ³• (exp)ï¼šåŒ¹é…expã€‚æ•èŽ·åˆ°è‡ªåŠ¨å‘½åçš„ç»„é‡Œé¢ï¼Œ\1è¿™æ ·çš„ (?exp)åŒ¹é…exp,æ•èŽ·å†…å®¹å¹¶è‡ªå·±å‘½åï¼ŒåŽé¢å¼•ç”¨çš„æ—¶å€™éœ€è¦ â€œ\kâ€œ (?:exp)ï¼šåŒ¹é…expï¼Œä½†æ˜¯ä¸æ•èŽ·ï¼Œä¹Ÿä¸ç»™è¿™ä¸ªç»„åˆ†é…ç¼–å· (?=exp)ï¼šåŒ¹é…expå‰é¢çš„ä½ç½® how are you doingï¼Œæ­£åˆ™(?.+(?=ing))ï¼ŒåŽ»ingå‰é¢çš„å­—ç¬¦ï¼ŒåŒ¹é…å‡ºæ¥çš„æ˜¯how are you doï¼ˆåŒ¹é…ingä¹‹å‰çš„.+ï¼‰ (?&lt;=exp)ï¼šåŒ¹é…åŽé¢çš„ä½ç½®ã€‚æ¯”å¦‚(?(?&lt;=how).+)ï¼ŒåŒ¹é…åŽé¢çš„ä½ç½®ï¼Œä¹Ÿå°±æ˜¯åŒ¹é…howä¹‹åŽçš„.+ (?!exp)ï¼šåŒ¹é…åŽé¢ä¸è·Ÿç€expçš„ä½ç½®ã€‚æ¯”å¦‚\d{3}(?!\d)åŒ¹é…ä¸‰ä¸ªæ•°å­—ï¼Œç„¶åŽåŽé¢ä¸å†è·Ÿæ•°å­—äº† (?&lt;!exp)ï¼šåŒ¹é…å‰é¢ä¸æ˜¯expçš„ä½ç½®ã€‚(?!&lt;[0-9])123ï¼ŒåŒ¹é…123ï¼Œå¹¶ä¸”123å‰é¢ä¸èƒ½æ˜¯æ•°å­— ä¾‹å­ï¼šåˆ†ç»„ä½¿ç”¨æ¯”å¦‚åŒ¹é…IPåœ°å€ï¼ŒIPåœ°å€ç”±å››éƒ¨åˆ†ç»„æˆï¼Œæ¯ä¸€éƒ¨åˆ†æ˜¯0-255çš„æ•°å­—ã€‚åˆ™å¯ä»¥åˆ†ä¸ºä»¥ä¸‹çš„éƒ¨åˆ†è¡¨ç¤º ä¸€ä½æ•°å­— ä¸ä»¥0å¼€å¤´çš„ä¸¤ä½æ•° 2å¼€å¤´ï¼Œç¬¬äºŒä½æ˜¯0-4çš„ä¸‰ä½æ•° 25å¼€å¤´ï¼Œç¬¬ä¸‰ä½æ˜¯0-5çš„ä¸‰ä½æ•°1((25[0-5]|(2[0-4]\d)|(1\d&#123;2&#125;)|([1-9]\d)|(\d))\.)&#123;3&#125;(25[0-5]|(2[0-4]\d)|(1\d&#123;2&#125;)|([1-9]\d)|(\d)) å›žæº¯å¼•ç”¨æ¯”å¦‚åŒ¹é…HTMLé‡Œé¢çš„æ ‡é¢˜å…ƒç´ 1&lt;(h[1-6])&gt;\w*?&lt;\/\1&gt; å…¶ä¸­ï¼Œh[1-6]è¢«åˆ†ä¸ºä¸€ç»„ï¼Œè¿™ä¸€ç»„çš„åå­—å«åš\1ï¼Œä¹Ÿå°±æ˜¯è¯´å‰åŽçš„ä¸¤éƒ¨åˆ†éœ€è¦ä¸€æ ·ã€‚h1å¯¹h1ï¼Œh2å¯¹h2æ‰èƒ½åŒ¹é…ä¸Š æ›¿æ¢ï¼ˆéœ€è¦ä¸¤ä¸ªregexpï¼‰æ¯”å¦‚ä¿®æ”¹ç”µè¯å·ç æ ¼å¼313-555-1234 æŸ¥æ‰¾çš„æ­£åˆ™å¼(\d{3})(-)(\d{3})(-)(\d{4}) éœ€è¦æ›¿æ¢æˆä¸ºçš„æ ¼å¼ï¼ˆ$1ï¼‰$3-$5ã€‚ä¹Ÿå°±æ˜¯è¯´æŠŠç¬¬ä¸€ä¸ªæ­£åˆ™å¼ä¸­çš„ç¬¬1ï¼Œ3ï¼Œ5ä¸ªæ‹¬å·ç›´æŽ¥ä»£å…¥äº†åŽé¢æ›¿æ¢çš„æ ¼å¼é‡Œé¢ æ›¿æ¢ä¹‹åŽçš„å†…å®¹ (313)555-1234 å¤§å°å†™è½¬å˜ \l æŠŠåŽé¢è·Ÿéšçš„å•ç‹¬çš„å­—ç¬¦æ”¹æˆå°å†™ \u æŠŠå•ç‹¬çš„å­—ç¬¦æ”¹æˆå¤§å†™ \L æŠŠLä¹‹åŽï¼ŒEä¹‹å‰çš„å…¨éƒ½å˜æˆå°å†™ \U æŠŠUä¹‹åŽï¼ŒEä¹‹å‰çš„å…¨éƒ½å˜æˆå¤§å†™ \E ç»“æŸç¬¦å· å¦‚ï¼Œabcdï¼ŒæŸ¥æ‰¾(\w)(\w{2})(\w)ï¼Œç„¶åŽæ”¹ä¸º$1\U$2\E$3 å‰åŽæŸ¥æ‰¾è®¢å¥½äº†åº”è¯¥åŒ¹é…çš„å†…å®¹çš„é¦–å°¾å†…å®¹ï¼Œä½†æ˜¯ä¸åŒ…æ‹¬è¿™ä¸ªé¦–å°¾å†…å®¹ã€‚ä¹Ÿå°±æ˜¯å‰é¢è¯´åˆ°çš„å‘å‰åŒ¹é…ï¼Ÿ=å’Œå‘åŽåŒ¹é…?&lt;=.ï¼ˆä½†æ˜¯jsä¸æ”¯æŒå‘åŽåŒ¹é…ï¼‰ã€‚å¦‚æžœè¦æ‰¾éžçš„æ¡ä»¶çš„æ—¶å€™ï¼Œéœ€è¦æŠŠ=æ¢æˆ! æ¯”å¦‚åŒ¹é…é‚®ç®±çš„@å‰é¢çš„éƒ¨åˆ† (\w+|.)+(?=@)ï¼ˆè¿™é‡ŒåŠ ä¸Šäº†.ï¼Œå› ä¸ºæˆ‘çš„å­¦æ ¡é‚®ç®±@å‰é¢ä¹Ÿæ˜¯æœ‰. çš„ï¼‰ åŒ¹é…ç»“æžœï¼š **xu.r.aa**@m.titech.ac.jp åµŒå…¥æ¡ä»¶å›žæº¯å¼•ç”¨åˆ¤æ–­æŸä¸ªè¡¨è¾¾å¼æ˜¯å¦åŒ¹é…ï¼Œå¦‚æžœåŒ¹é…çš„è¯ç»§ç»­åŒ¹é…åŽé¢çš„æ¡ä»¶1(\()?abc(?(1)\)) å…ˆåŒ¹é…å·¦æ‹¬å·ï¼ˆ(ï¼‰ï¼Œï¼Ÿæ¥åˆ¤æ–­å·¦æ‹¬å·æœ‰0ä¸ªæˆ–è€…1ä¸ª ï¼Ÿ(1)æ˜¯åˆ¤æ–­çš„è¡¨è¾¾å¼ï¼Œä¹Ÿå°±æ˜¯è¯´èƒ½åŒ¹é…åˆ°å·¦æ‹¬å·çš„æ—¶å€™ï¼Œå†åŒ¹é…å³æ‹¬å·ã€‚ åŒ¹é…ç»“æžœï¼šabcï¼ˆabcï¼‰ï¼ˆabc å‰åŽæŸ¥æ‰¾æ¡ä»¶ä¸ºé¦–å°¾æ˜¯å¦åŒ¹é…ï¼Œå¦‚æžœåŒ¹é…çš„è¯ç»§ç»­ï¼ˆæ³¨æ„é¦–å°¾ä¸åŒ…æ‹¬åœ¨åŒ¹é…å†…å®¹é‡Œé¢ï¼‰1\d&#123;5&#125;(?(?=-)-\d&#123;4&#125;) é¦–å…ˆåŒ¹é…äº”ä½æ•°å­— (?=-)è¡¨ç¤ºå‘å‰æŸ¥æ‰¾-ï¼Œä¹Ÿå°±æ˜¯å¯¹-å‘å‰æŸ¥æ‰¾ï¼Œä½œä¸ºæ¡ä»¶ã€‚å¦‚æžœå‘å‰æŸ¥æ‰¾æˆåŠŸäº†ï¼Œé‚£ä¹ˆç»§ç»­è¿›è¡ŒåŽé¢çš„æ“ä½œï¼Œä¹Ÿå°±æ˜¯åŒ¹é…ä¸€ä¸ª-ï¼Œç„¶åŽåŒ¹é…ä¸€ä¸ª4ä½æ•°å­—44444-444444444-66666]]></content>
      <categories>
        <category>åŸºç¡€</category>
        <category>å·¥å…·</category>
      </categories>
      <tags>
        <tag>æ­£åˆ™è¡¨è¾¾</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ç®—æ³•ï¼šå›žæº¯Backtracking]]></title>
    <url>%2F2019%2F10%2F16%2F%E7%AE%97%E6%B3%95%EF%BC%9A%E5%9B%9E%E6%BA%AFBacktracking%2F</url>
    <content type="text"></content>
      <categories>
        <category>ç®—æ³•</category>
        <category>å›žæº¯</category>
      </categories>
      <tags>
        <tag>backtracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unityç»ƒä¹ FlappyBird]]></title>
    <url>%2F2019%2F10%2F02%2FUnity%E7%BB%83%E4%B9%A0Flappy%2F</url>
    <content type="text"><![CDATA[æ•™ç¨‹åŠç´ ææºè‡ªunityå®˜æ–¹çš„learningèµ„æ–™FlappyBird æ•´ä½“æ€è·¯ï¼šåœ¨æ¸¸æˆé‡Œç‰©ä½“æœ¬ä½“æ˜¯ä¸ä¼šç§»åŠ¨çš„ï¼Œåªæœ‰åŽé¢çš„èƒŒæ™¯æ»šè½´ä¸€ç›´åœ¨ç§»åŠ¨ï¼Œç„¶åŽæ¯æ¬¡åœ¨çŽ©å®¶è§†é‡Žå¤–ç”Ÿæˆéšæœºé«˜åº¦çš„æŸ±å­ã€‚æŸ±å­å’ŒèƒŒæ™¯ä¸€èµ·æ»šåŠ¨ã€‚ ç”Ÿæˆé¸Ÿçš„ç‰©ä½“sprite spriteæ˜¯ä¸€ç§åŠé€æ˜Žçš„textureã€‚ä¸ä¼šç›´æŽ¥è¢«ç”¨äºŽmeshï¼Œè€Œæ˜¯ä¼šç”¨åœ¨é•¿æ–¹å½¢æˆ–è€…æ­£æ–¹å½¢ä¸Š ä¿®æ”¹texture typeå°±å¯ä»¥ä¿®æ”¹ ä¸Žcanvas renderçš„åŒºåˆ«ï¼šå‰è€…å¿…é¡»æ”¾åœ¨canvasé‡Œé¢ï¼Œè€ŒåŽè€…å¯ä»¥æ”¾åœ¨hierarchyçš„ä»»ä½•åœ°æ–¹ spriteæ”¯æŒç½‘æ ¼æž„é€ ï¼Œå¯ä»¥æ¸…é™¤ä¸å¿…è¦çš„é€æ˜Žå…ƒç´ ï¼Œå¯ä»¥ä¸€å®šæƒ…å†µä¸‹é¿å…overdrawçš„é—®é¢˜ sorting layer åœ¨sprite renderé‡Œé¢ä¼šæœ‰ä¸€é¡¹å«åšsorting layerï¼Œè¿™ä¸ªåŠŸèƒ½å¯ä»¥å†³å®šç”»é¢çš„å‰æ™¯å’ŒåŽæ™¯çš„é®æŒ¡å…³ç³»ã€‚å†™çš„è¶Šé ä¸‹çš„è¶Šå‰ rigidbody + collider éœ€è¦è®¾ç½®åˆšä½“å’Œç¢°æ’žå…³ç³» è¿™é‡Œé¢çš„ç¢°æ’žå™¨è®¾ç½®çš„ç§ç±»æ˜¯å¤šè¾¹å½¢çš„ animatorï¼ˆgetcomponentï¼‰ åœ¨è¿™ä¸ªæ¸¸æˆé‡Œï¼Œé¸Ÿçš„ä¸åŒåŠ¨ä½œä¼šè§¦å‘ä¸åŒçš„åŠ¨ç”»ï¼Œæ‰€ä»¥éœ€è¦ä¸ºè¿™ä¸ªé¸Ÿæž„å»ºä¸€ä¸ªåŠ¨ç”»æ¥è¡¨çŽ° åœ¨animationé‡Œé¢ï¼Œå¯ä»¥ç»™é¸Ÿä¸åŒçš„åŠ¨ä½œä¸åŒçš„clipã€‚åœ¨è¿è¡ŒçŠ¶æ€ä¸‹ä¿®æ”¹é¸Ÿåœ¨ä¸åŒclipé‡Œé¢çš„rendererã€‚ åœ¨animatoré‡Œé¢å¯ä»¥è®¾ç½®ä¸åŒåŠ¨ç”»ä¹‹é—´åˆ‡æ¢çš„é€»è¾‘å…³ç³» ä¸€ç§æ˜¯æ ¹æ®æ¡ä»¶åˆ‡æ¢ï¼Œéœ€è¦ä¸ºä¸åŒçš„æ¡ä»¶è®¾ç½®ä¸åŒçš„paramterï¼ˆè¿™é‡Œè®¾å®šçš„æ˜¯triggerï¼Œè¿™ä¸ªçŠ¶æ€å¯ä»¥ç›´æŽ¥åœ¨scripté‡Œé¢setï¼Œæ³¨æ„æ‹¼å†™éœ€è¦ä¸€æ ·ï¼‰ï¼ˆæ­£å¸¸ -æŒ‰-&gt; æŒ¥åŠ¨ç¿…è†€/ æ­£å¸¸ -æ’žå¢™-&gt; æ­»äº¡ï¼‰ ä¸€ç§æ˜¯æ ¹æ®æ—¶é—´åˆ‡æ¢ï¼ˆæŒ¥åŠ¨ç¿…è†€ -&gt; æ­£å¸¸çŠ¶æ€ï¼‰ é¸Ÿçš„è¡Œä¸ºé€»è¾‘ è¿åŠ¨ï¼šæœ¬èº«çš„xè½´ä¸ä¼šè¿åŠ¨ï¼Œyè½´åœ¨æ¯æ¬¡æŒ‰é¼ æ ‡çš„æ—¶å€™ä¸Šå‡ï¼ˆaddForceï¼‰ï¼Œä¸æŒ‰çš„æ—¶å€™é‡åŠ›è‡ªç”±è½ä½“ï¼ˆå¯¹åº”ä¸Šå‡åŠ¨ç”»ï¼‰ ç¢°æ’žï¼šç¢°æ’žåˆ°åœ°é¢æˆ–è€…æŸ±å­éƒ½ä¼šæ­»äº¡ï¼ˆå¯¹åº”æ­»äº¡åŠ¨ç”»ï¼‰ åœ¨é¸Ÿæ­»äº¡çš„æ—¶å€™ï¼Œä¼šå¯¹åº”é¸Ÿçš„æ­»äº¡çŠ¶æ€åœ¨controlleré‡Œé¢çš„åˆ‡æ¢ UIåˆ¶ä½œ UIä½¿ç”¨çš„å°±æ˜¯æ™®é€šçš„UIæ¨¡å¼ï¼Œæ³¨æ„æ‰€æœ‰textéƒ½æ˜¯åœ¨canvasé‡Œé¢çš„ å¯¼å…¥ç´ æåŒ…å­—ä½“ï¼Œå¯ä»¥ç»™å­—ä½“åŠ é˜´å½± UIçš„åˆ†æ•°å˜åŒ–åœ¨gamecontrolleré‡Œé¢è¿›è¡Œæ“ä½œ å­—ä½“é”šç‚¹ä½ç½®è°ƒæ•´éœ€è¦æŒ‰alt/option gameControll è®¾å®šäº†ä¸€ä¸ªstaticçš„GameControlï¼ˆè¿™æ˜¯è¿™ä¸ªè‡ªå»ºç±»çš„åå­—ï¼‰çš„objectï¼Œåå­—æ˜¯instanceã€‚è®¾å®šæˆstaticä¹‹åŽï¼Œæ— è®ºåœ¨å“ªé‡Œçš„codeé‡Œé¢æƒ³è¦è®¿é—®è¿™ä¸ªinstanceï¼Œåªéœ€è¦callGameControl.instanceå°±å¯ä»¥äº† ä¸ºäº†ä¿è¯é‡Œé¢æ‹¥æœ‰è¿™ä¸ªinstanceï¼Œéœ€è¦åœ¨awakeçš„æ—¶å€™è¿›è¡Œæ£€æŸ¥ 1234567891011void Awake() &#123; if (instance == null) &#123; instance = this; &#125; else if(instance != this) &#123; Destroy(gameObject); &#125; &#125; åœ¨gameControlé‡Œé¢è®¾ç½®å¥½äº†æ¸¸æˆç»“æŸçš„å˜é‡ï¼Œè¿™ä¸ªå˜é‡å¯ä»¥ç›´æŽ¥åœ¨birdçš„scripté‡Œé¢è®¿é—®ï¼Œè¿™æ ·å°±å¯ä»¥ç›´æŽ¥åœ¨birdé‡Œé¢å†³å®šæ¸¸æˆç»“æŸæ²¡ç»“æŸï¼Œå†åœ¨çŽ°åœ¨çš„controlé‡Œé¢å†³å®šåˆ†æ•°çš„å˜åŒ–ï¼Œsceneçš„åˆ‡æ¢ç­‰ ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œæ“ä½œï¼Œæ¸¸æˆé‡æ–°å¼€å§‹1234567void Update() &#123; if (gameOver &amp;&amp; Input.GetMouseButtonDown(0)) &#123; SceneManager.LoadScene(SceneManager.GetActiveScene().buildIndex); &#125; &#125; åœ°é¢ï¼ˆåŠèƒŒæ™¯ï¼šä½œä¸ºåœ°é¢çš„å­ç‰©ä½“ï¼‰ åœ°é¢åº”è¯¥æœ‰colliderï¼Œè¿™æ ·é¸Ÿæ’žåˆ°åœ°é¢ä¸Šæ‰ä¼šæ­»ã€‚éœ€è¦ç”¨rd åœ°é¢åº”è¯¥åœ¨startå¼€å§‹å°±æŒ‰ç…§ä¸€ä¸ªé€Ÿåº¦è¿›è¡Œè´Ÿç§»åŠ¨ï¼Œå¦‚æžœæ¸¸æˆç»“æŸçš„è¯ï¼Œåœ°é¢åœæ­¢ç§»åŠ¨ åœ°é¢åº”è¯¥å¤åˆ¶ä¸¤ä»½ï¼Œå½“æ¯æ¬¡ç¬¬ä¸€ä»½å¿«è¦ç§»åŠ¨åˆ°å¤´çš„æ—¶å€™ï¼Œç¬¬äºŒä»½ç§»åŠ¨åˆ°ç¬¬ä¸€ä»½å‰é¢åŽ»ï¼ˆè¿™ä¸ªè·ç¦»å¯ä»¥ç›´æŽ¥ç”¨colliderçš„sizeæ¥å†³å®š åœ°é¢çš„rdåº”è¯¥è®¾ç½®æˆkinematicï¼Œä¹Ÿå°±æ˜¯é™¤äº†scriptè®©ç§»åŠ¨ï¼Œå…¶ä»–çš„æ–¹æ³•ä¸ä¼šè®©ä»–ç§»åŠ¨ éšœç¢ç‰© éšœç¢ç‰©åº”è¯¥è®¾ç½®æˆprefabï¼Œåˆ¶ä½œå¥½çš„ä¸œè¥¿ç›´æŽ¥æ‹–è¿›prefabæ–‡ä»¶å¤¹å°±å¯ä»¥äº†ã€‚åœ¨ç”¨çš„æ—¶å€™å¯ä»¥ç›´æŽ¥åœ¨gamecontrolçš„ç‰©ä½“é‡Œé¢æ“ä½œè¿™ä¸ªprefabï¼Œç›´æŽ¥æ‹–è¿›åŽ»å°±å¯ä»¥äº† éšœç¢ç‰©æœ¬èº«åº”è¯¥å¢žåŠ äº†ä¸€ä¸ªbox colliderçš„triggerï¼Œç„¶åŽåœ¨æ¯ä¸ªæŸ±å­æœ¬èº«é‡Œé¢åŠ ä¸Šäº†OnTriggerEnter2D(Collider2D other)ï¼Œä¹Ÿå°±æ˜¯åœ¨è¿™ä¸ªtriggerçš„åŒºåŸŸé‡Œé¢é‡åˆ°é¸Ÿçš„æ—¶å€™ï¼Œä¼šcallåŠ åˆ†çš„å‡½æ•° pool ç”ŸæˆæŸ±å­çš„æ–¹æ³•ï¼Œç›®å‰çš„æ–¹æ³•æ˜¯æ¯æ¬¡ç”Ÿæˆäº”ä¸ªæŸ±å­ï¼Œå­˜åœ¨ä¸€ä¸ªarrayé‡Œé¢ï¼Œæ¯æ¬¡æ—¶é—´åˆ°äº†å°±éšæœºæ–°çš„æŸ±å­çš„ä½ç½®ã€‚å¦‚æžœäº”ä¸ªæŸ±å­éƒ½ç”¨å®Œäº†å°±é‡å¤´å¼€å§‹ï¼Œä¹Ÿå°±æ˜¯ä»Žindexæ˜¯0çš„æŸ±å­å¼€å§‹ï¼Œé‡æ–°å®šä½åæ ‡ åœ¨åˆå§‹åŒ–äº”ä¸ªæŸ±å­çš„æ—¶å€™ï¼Œç”¨äº†Object.Instantiateï¼Œä¹Ÿå°±æ˜¯æŠŠè¿™äº”ä¸ªæŸ±å­åœ¨æŒ‡å®šçš„ä½ç½®å¤åˆ¶äº†äº”æ¬¡ã€‚å…¶ä¸­rotationçš„å‚æ•°è®¾ç½®çš„æ˜¯Quaternion.identityï¼Œä¹Ÿå°±æ˜¯æ²¡æœ‰æ—‹è½¬çš„æ„æ€ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647using System.Collections;using System.Collections.Generic;using UnityEngine;public class ColumnPool : MonoBehaviour&#123; public int ColumnSize = 5; public GameObject columnPrefab; public float SpwandRate = 4f; public float columnMin = -2f; public float columnMax = 2f; private GameObject[] columns; private Vector2 objectPoolPosition = new Vector2(-15f, -25f); private float timeSinceLastSpwand; private float spwandXPosition = 10f; private int currentColumn = 0; // Start is called before the first frame update void Start() &#123; columns = new GameObject[ColumnSize]; for (int i = 0; i &lt; ColumnSize; i++) &#123; columns[i] = (GameObject)Instantiate(columnPrefab, objectPoolPosition, Quaternion.identity); &#125; &#125; // Update is called once per frame void Update() &#123; timeSinceLastSpwand += Time.deltaTime; if (GameControl.instance.gameOver == false &amp;&amp; timeSinceLastSpwand &gt;= SpwandRate) &#123; timeSinceLastSpwand = 0; float spawnYposition = Random.Range(columnMin, columnMax); columns[currentColumn].transform.position = new Vector2(spwandXPosition, spawnYposition); currentColumn++; if(currentColumn == 4) &#123; currentColumn = 0; &#125; &#125; &#125;&#125; ä»¥ä¸Šï¼Œç®€æ˜“ç‰ˆçš„flappybirdå°±åˆ¶ä½œå®Œæ¯•äº†]]></content>
      <categories>
        <category>Unity</category>
        <category>ç»ƒä¹ </category>
      </categories>
      <tags>
        <tag>Flappy Bird</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ—¥è¯­æ•¬è¯­å­¦ä¹ ]]></title>
    <url>%2F2019%2F09%2F14%2F%E6%97%A5%E8%AF%AD%E6%95%AC%E8%AF%AD%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[ä»Žå¤´å¼€å§‹äº†è§£ä¸€äº›ç»å¸¸å¬åˆ°çš„ç”¨æ³• æœ¬æ—¥ ï¼ ä»Šæ—¥ ã¾ã“ã¨ã« ï¼ æœ¬å½“ã« ã”æ¡ˆå†…ç”³ã—ä¸Šã’ã¾ã™ ï¼ çŸ¥ã‚‰ã›ã¾ã™ ãŸã ã„ã¾ ï¼ ã„ã¾ ã€œã«ãŠãã¾ã—ã¦ ï¼ ã§ ã€œã§ã”ã–ã„ã¾ã™ ï¼ ã€œã§ã™ æ¥å ´ã™ã‚‹ ï¼ ä¼šå ´ã«æ¥ã‚‹ æ•¬è¯­çš„åˆ†ç»„ å°Šæ•¬è¯­ï¼šç”¨æ¥æè¿°å¯¹æ–¹çš„è¡Œä¸ºï¼Œç›´æŽ¥è¡¨ç¤ºæ•¬æ„ è°¦è®©è¯­ï¼›æè¿°è‡ªå·±åšçš„äº‹ï¼Œè´¬ä½Žè‡ªå·±ï¼Œé—´æŽ¥çš„è¡¨ç¤ºæ•¬æ„ ä¸å®è¯­ï¼šè®©æ•´ä¸ªå¯¹è¯çš„æ°”æ°›éƒ½å˜å¾—å¾ˆä¸å®ï¼Œæ°”æ°›æ¯”è¾ƒéƒ‘é‡ åŸºæœ¬å¸¸è¯† ä¸€èˆ¬æ¥è¯´ï¼Œç¤¼è²Œç¨‹åº¦å¯ä»¥åˆ†æˆä¸‰ä¸ªé˜¶å±‚ï¼Œåˆ†åˆ«æ˜¯ç–¯ç‹‚ä½¿ç”¨æ•¬è¯­çš„ -&gt; ä½¿ç”¨ã§ã™ã¾ã™çš„ -&gt; ä½¿ç”¨æ™®é€šå½¢æ€çš„æœ‹å‹é—´çš„å¯¹è¯ ä¸€èˆ¬æ¥è¯´ï¼Œå¯¹å¤–çš„äººç”¨æ•¬è¯­ï¼Œå¯¹å†…çš„äººä¸åŒæ•¬è¯­ æ¯”å¦‚æœ‰äººæ‰“ç”µè¯åˆ°äº†å…¬å¸ï¼Œé—®ä½ çš„éƒ¨é•¿åœ¨ä¸åœ¨ï¼Œä½ è‡ªå·±è¯´éƒ¨é•¿çš„æ—¶å€™å°±ä¸ç”¨ç”¨æ•¬è¯­äº† ä¸‹é¢å¼€å§‹æ ¹æ®ä¸åŒçš„åœºåˆä½¿ç”¨æ•¬è¯­è®¿é—®è®¿é—®æ—¶å€™çš„ç‰¹å®šç”¨è¯­ çŽ„å…³å¤„ ã”ã‚ã‚“ãã ã•ã„ ã™ã„ã¾ã›ã‚“ éƒ¨å±‹ã«å…¥ã‚‹æ™‚ ãŠé‚ªé­”ã—ã¾ã™ å¤±ç¤¼ã—ã¾ã™ å¤±ç¤¼ã„ãŸã—ã¾ã™ éƒ¨å±‹ã‚’å‡ºã‚‹æ™‚ å¤±ç¤¼ã—ã¾ã™ å¤±ç¤¼ã„ãŸã—ã¾ã™ ãŠï¼ã”ã€œãã ã•ã„ ã€œã¦ãã ã•ã„çš„ä¸å®ç”¨æ³• masuåž‹åŽ»masuåŠ ä¸ŠåŽé¢çš„ãŠï¼Œæˆ–è€…suruåž‹ç›´æŽ¥åŠ åŽé¢çš„ã” ä¾‹å­ ãŠå…¥ã‚Šãã ã•ã„ ãŠä¸Šã‚Šãã ã•ã„ -&gt; è¯·è¿›çš„æ„æ€ come in ãŠã‹ã‘ãã ã•ã„ -&gt; è¯·åï¼Œæ¯”å¦‚æ²™å‘ï¼Œæ¤…å­å•¥çš„ã€‚å’Œæ‰“ç”µè¯æ²¡æœ‰å…³ç³» æ—¥æœ¬èªžã§ãŠè©±ã—ãã ã•ã„ ã”æ³¨æ„ãã ã•ã„ æ³¨æ„ï¼šè¿™é‡Œæ²¡æœ‰teï¼Œä¸è¦é¡ºä¾¿åŠ ä¸Šteï¼Œæ²¡æœ‰teï¼Œæ²¡æœ‰ï¼ï¼ï¼ï¼ï¼ ã¤ã¾ã‚‰ãªã„ã‚‚ã®ã§ã™ãŒâ€¦ ä¸€ç‚¹å°ä¸œè¥¿ï¼Œä¸æˆæ•¬æ„ æ›´éšæ„çš„æ—¶å€™å¯ä»¥è¯´ï¼ˆç»™åˆ«äººä¹°äº†åƒçš„çš„è¯ï¼‰ï¼šç¾Žå‘³ã—ã„ã®ã§è²·ã£ã¦ãã¾ã—ãŸ ãŠã€œã«ãªã‚Šã¾ã™ ã€œã¾ã™çš„ä¸å®è¯­ï¼Œsuruçš„åŠ¨è¯ä¸èƒ½ç”¨è¿™ä¸ªç”¨æ³• ä¹Ÿå°±æ˜¯è¯´ä¸€èˆ¬çš„åŠ¨è¯ï¼Œå¦‚æžœä¸æ˜¯ç‰¹æ®Šåž‹çš„è¯ï¼Œå¯ä»¥ç”¨è¿™ä¸ªç”¨æ³•ä»£æ›¿å¹³å¸¸ç›´æŽ¥ç”¨masu ä¾‹ ã“ã®æ•™ç§‘æ›¸ã¯éˆ´æœ¨å…ˆç”ŸãŒãŠæ›¸ãã«ãªã‚Šã¾ã™ ç¤¾é•·ã€ä»Šæœã®æ–°èžã‚’ãŠèª­ã«ãªã‚Šã¾ã—ãŸã‹ ä¸Šé¢çš„å°Šæ•¬è¯­çš„ç‰¹åˆ«å˜å½¢ é£Ÿã¹ã¾ã™ -&gt; (ðŸ™…â€â™€x)ãŠé£Ÿã¹ã«ãªã‚Šã¾ã™ -&gt; (â—)å¬ã—ä¸ŠãŒã‚Šã¾ã™ ã—ã¾ã™ -&gt; (ðŸ™…â€â™€x)ãŠã—ã«ãªã‚Šã¾ã™ -&gt; (â—)ãªã•ã„ã¾ã™ è¦‹ã¾ã™ -&gt; (ðŸ™…â€â™€x)ãŠè¦‹ã«ãªã‚Šã¾ã™ -&gt; (â—)ã”è¦§ã«ãªã‚Šã¾ã™ ä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æžœæ˜¯ä¸‰ç±»åŠ¨è¯çš„è¯ï¼ŒåŽé¢çš„ã™ã‚‹ç›´æŽ¥å˜æˆãªã•ã„ã¾ã™ æ³¨æ„ï¼šç‰¹åˆ«å˜å½¢å¦‚æžœæƒ³ç”¨ãã ã•ã„çš„æ—¶å€™ï¼Œå¯ä»¥ç›´æŽ¥ç”¨ç‰¹åˆ«å˜å½¢ä¹‹åŽçš„åŠ¨è¯åŠ ä¸Šã¦ãã ã•ã„ã€çŽ°åœ¨è¿™é‡Œæ˜¯æœ‰teçš„ï¼Œæ¯”å¦‚ãŠã£ã—ã‚ƒã£ã¦ãã ã•ã„ è¯·è¯´ è¢«åŠ¨ï¼šæ›´åŠ ç®€å•ä¸€ç‚¹çš„ç”¨æ³• ä½¿ç”¨å’Œè¢«åŠ¨æ€ç›¸åŒçš„æ–¹æ³•æ¥è¡¨ç¤ºå°Šæ•¬ï¼Œä¸ç”¨åƒä¸Šé¢çš„ãŠã€œã«ãªã‚Šã¾ã™è¿™ä¹ˆéº»çƒ¦ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡å¯ä»¥æŽ¨æµ‹å®žé™…çš„æ„æ€ ä¾‹ æ›¸ãã¾ã™ -&gt; æ›¸ã‹ã‚Œã¾ã™ï¼ èª­ã¿ã¾ã™ -&gt; èª­ã¾ã‚Œã¾ã™ å‡ºã¾ã™ -&gt; å‡ºã‚‰ã‚Œã¾ã™ ã—ã¾ã™ -&gt; ã•ã‚Œã¾ã™ï¼ æ¥ã¾ã™ -&gt; æ¥ã‚‰ã‚Œã¾ã™ æ³¨æ„ï¼šè¿™ç§ç”¨æ³•ä¸èƒ½å’Œãã ã•ã„ä¸€èµ·ç”¨ï¼Œä¸èƒ½ç”¨è¢«åŠ¨åŽé¢åŠ ãã ã•ã„ï¼Œè¦ç”¨ãã ã•ã„çš„è¯è¯·ç›´æŽ¥ç”¨ä¸Šé¢çš„é‚£ä¸ªå¸¦ãã ã•ã„çš„æ–¹æ³• æ³¨æ„ï¼šè¢«åŠ¨åž‹ ä¸è¦é¡ºå˜´å’Œã•ã›è¯´æ·· ç‰¹æ®Šæ•¬è¯­æž„æˆè¡¨ åŠ¨è¯ å°Šæ•¬è¯­ è°¦è®©è¯­ è¡Œãã¾ã™ ã„ã‚‰ã—ã‚ƒã„ã¾ã™ï¼ãŠã„ã§ã«ãªã‚Šã¾ã™ å‚ã‚Šã¾ã™ï¼ä¼ºã„ã¾ã™ æ¥ã¾ã™ ã„ã‚‰ã—ã‚ƒã„ã¾ã™ï¼ãŠã„ã§ã«ãªã‚Šã¾ã™ å‚ã‚Šã¾ã™ ã„ã¾ã™ ã„ã‚‰ã—ã‚ƒã„ã¾ã™ï¼ãŠã„ã§ã«ãªã‚Šã¾ã™ ãŠã‚Šã¾ã™ è¨€ã„ã¾ã™ ãŠã£ã—ã‚ƒã„ã¾ã™ ï¼ˆè¨±ã¨ï¼‰ç”³ã—ã¾ã™ï¼ï¼ˆæ„è¦‹ã‚’ï¼‰ç”³ã—ä¸Šã’ã¾ã™ è¦‹ã¾ã™ ã”è¦§ã«ãªã‚Šã¾ã™ æ‹è¦‹ã—ã¾ã™ é£Ÿã¹ã¾ã™ï¼é£²ã¿ã¾ã™ å¬ã—ä¸ŠãŒã‚Šã¾ã™ ã„ãŸã ãã¾ã™ çŸ¥ã£ã¦ã„ã¾ã™ ã”å­˜çŸ¥ã§ã™ å­˜ã˜ã¦ãŠã‚Šã¾ã™ï¼çŸ¥ã£ã¦ãŠã‚Šã¾ã™ï¼ï¼ˆé‡‘å­éƒ¨é•·ã‚’ï¼‰å­˜ã˜ä¸Šã’ã¦ãŠã‚Šã¾ã™ æ€ã„ã¾ã™ ãŠæ€ã„ã«ãªã‚Šã¾ã™ å­˜ã˜ã¾ã™ ã—ã¾ã™ ãªã•ã„ã¾ã™ ã„ãŸã—ã¾ã™ ãã‚Œã¾ã™ ãã ã•ã„ã¾ã™ ã‚ã’ã¾ã™ ã•ã—ã‚ã’ã¾ã™ ã‚‚ã‚‰ã„ã¾ã™ ã„ãŸã ãã¾ã™ ä¼šã„ã¾ã™ ãŠä¼šã„ã«ãªã‚Šã¾ã™ ãŠä¼šã„ã—ã¾ã™ï¼ãŠç›®ã«ã‹ã‹ã‚Šã¾ã™ èžãã¾ã™ ãŠèžãã«ãªã‚Šã¾ã™ ãŠèžãã—ã¾ã™ï¼ä¼ºã„ã¾ã™ ã‚ã‚Šã¾ã™ ã‚ã‚Šã¾ã™ ã”ã–ã„ã¾ã™ å¯ã¾ã™ ãŠä¼‘ã¿ã«ãªã‚Šã¾ã™ ç€ã¾ã™ ãŠå¬ã—ã«ãªã‚Šã¾ã™ ä½ã‚“ã§ã„ã¾ã™ ãŠä½ã¾ã„ã§ã™ æŒã¡ã¾ã™ï¼æŒã£ã¦ã„ãã¾ã™ï¼æŒã£ã¦ãã¾ã™ ãŠæŒã¡ã«ãªã‚Šã¾ã™ ãŠæŒã¡ã—ã¾ã™ æ­»ã«ã¾ã—ãŸ ãŠäº¡ããªã‚Šã«ãªã‚Šã¾ã—ãŸ ã€œã§ã™ ã§ã„ã‚‰ã—ã‚ƒã„ã¾ã™ ã§ã”ã–ã„ã¾ã™ ã€œã¦ã„ã¾ã™ ã¦ã„ã‚‰ã—ã‚ƒã„ã¾ã™ ã§ãŠã‚Šã¾ã™ å°Šæ•¬è¯­å’Œè°¦è®©è¯­çš„æ€»ç»“ å¥åž‹ å°Šæ•¬ ãŠï¼ã”ã€œã«ãªã‚Šã¾ã™ ãŠï¼ã”ã€œãã ã•ã„ è°¦è®© ãŠï¼ã”ã€œã—ã¾ã™ ç®€å•ç”¨æ³• åªæœ‰å°Šæ•¬è¯­å¯ä»¥ç”¨è¢«åŠ¨æ¥è¡¨ç¤ºå°Šæ•¬ ç‰¹åˆ«åž‹è§è¡¨ æ³¨æ„å°Šæ•¬è¯­ï¼š åƒå’Œç©¿é•¿å¾—å·®ä¸å¤šï¼Œä½†æ˜¯åƒå–é‡Œé¢ä¸éœ€è¦å‰é¢çš„ãŠ è¯´é‡Œé¢å¸¦ä¿ƒéŸ³ è™½ç„¶æƒ³å¬èµ·æ¥å¾ˆå¥‡æ€ªï¼Œä½†æ˜¯çœŸçš„æ˜¯è¿™æ ·çš„ ä½è¿™ä¸ªè¯æœ‰äº›å¥‡æ€ª æ­»ä¸€å®šæ˜¯è¿‡åŽ»å¼çš„ æ³¨æ„è°¦è®©è¯­ æ¥å’ŒåŽ»éƒ½å¯ä»¥æ˜¯ å‚ã€‚ ä½†æ˜¯åŽ»è¿˜æœ‰ä¼ºã†ã€‚åŒæ—¶ä¼ºã†è¿˜æœ‰å¬çš„æ„æ€ å­˜ã˜ åœ¨çŸ¥é“å’Œæƒ³é‡Œé¢éƒ½å¯ä»¥ç”¨ï¼Œæ³¨æ„åŒºåˆ«ã€‚çŸ¥é“æ˜¯teåž‹çš„ï¼Œæ‰€ä»¥æ˜¯ãŠã‚Šã¾ã™ æ‰“æ‹›å‘¼ç»å¸¸ä½¿ç”¨çš„ã‚ã„ã•ã¤ æœ ãŠã¯ã‚ˆã†ãŒã–ã„ã¾ã™ ãŠã¯ã‚ˆã† ä¼šç¤¾ã‹ã‚‰å¸°ã‚Šæ™‚ ãã‚Œã§ã¯ã€ãŠå¤±ç¤¼ã«ã—ã¾ã™ï¼å¤±ç¤¼ã„ãŸã—ã¾ã™ ã˜ã‚ƒã€ãŠå…ˆã« ãŠç¤¼ ã‚ã‚ŠãŒã©ã†ã”ã–ã„ã¾ã™ -&gt; ã„ã„ãˆï¼ã“ã¡ã‚‰ã“ãï¼ã©ã†ã„ãŸã—ã¾ã—ã¦ ã‚ã‚ŠãŒã©ã† -&gt; ã†ã†ã‚“ï¼å¤§ä¸ˆå¤«ã ã‚ˆ å¤©æ°— ã„ã„å¤©æ°—ã§ã™ã­ï¼æš‘ã„ã§ã™ã­ï¼é›¨ãŒã‚ˆãé™ã‚Šã¾ã™ã­ -&gt; ãã†ã§ã™ã­ ã„ã„å¤©æ°—ã ã‚ˆï¼æš‘ã„ã­ï¼ã‚ˆãé™ã‚‹ã­ -&gt; ãã†ã ã­ åˆ¥ã‚Œã‚‹æ™‚ å¤±ç¤¼ã—ã¾ã™ï¼å¤±ç¤¼ã„ãŸã—ã¾ã™ -&gt; ãŠæ°—ã‚’ã¤ã‘ã¦ï¼ãã‚Œã§ã¯ã¾ãŸ ã˜ã‚ƒã‚ã­ -&gt; æ°—ã‚’ã¤ã‘ã¦ã­ï¼ã˜ã‚ƒã€ã¾ãŸ è°¦è®©è¯­å¥åž‹ ãŠã€œã—ã¾ã™ï¼ã”ã€œã—ã¾ã™ ä¾‹å­ çœ‹è§æ‹¿ç€ä¸œè¥¿çš„ç¤¾é•¿ ãŠæŒã¡ã—ã¾ã™ è¯´æ˜Žçš„æ—¶å€™ ã”èª¬æ˜Žã—ã¾ã™ æˆ‘æ¥å¸®ä½  ãŠæ‰‹ä¼ã„ã—ã¾ã™ ä¸€èˆ¬ä½¿ç”¨è°¦è®©è¯­çš„æ—¶å€™éƒ½ä¼šçœç•¥â€œæˆ‘â€çš„ä¸»è¯­ å¯¹äºŽä¸Šçº§çš„äººä¸èƒ½ç”¨ ã¦ã‚ã’ã‚‹ ï¼ˆè¦ç”¨ã•ã—ä¸Šã’ã‚‹ï¼‰ è°¦è®©è¯­ç‰¹åˆ«åž‹ æ›´å¤šè§ä¸Šé¢çš„è¡¨ ä¾‹å­ ãƒ¡ãƒ¼ãƒ«ã‚’æ‹è¦‹ã—ã¾ã—ãŸ é§…å‰ã§å¶ç„¶å…ˆç”Ÿã«ãŠç›®ã«ã‹ã‹ã‚Šã¾ã—ãŸ ä¾‹æ¥é€±ã®æ±äº¬ã¸ã®ã”å‡ºå¼µã®ã“ã¨ã§ã™ãŒã€ç©ºæ¸¯ã¾ã§ãŠè¿Žãˆã«ã¾ã„ã‚Šã¾ã™ï¼ã†ã‹ãŒã„ã¾ã™ ã®ã§ã€ã”åˆ°ç€ã«ãªã‚‹ï¼ˆåˆ°ç€ã•ã‚Œã‚‹ï¼‰æ™‚é–“ã‚’~å­˜ã˜ã•ã›ã¦ãã ã•ã„~ï¼ˆãŠçŸ¥ã‚‰ã›ãã ã•ã„ï¼Œè¿™é‡Œçš„ä¸»è¯­æ˜¯å¯¹æ–¹ä¸æ˜¯è‡ªå·±ï¼‰ã€‚ç©ºæ¸¯ã§è³‡æ–™ã‚’ãŠæ¸¡ã—ã—ã¾ã™ã®ã§ã€è»Šã®ä¸­ã§ã”è¦§ãã ã•ã„ã€‚ã”æ˜¼é£Ÿã®å¾Œã€ä¼šè­°ã®å ´æ‰€ã¾ã§ãŠé€ã‚Šã—ã¾ã™ã€‚ã©ã†ãžã‚ˆã‚ã—ããŠé¡˜ã„ã„ãŸã—ã¾ã™ é‚€è¯·æ‰“æ‹›å‘¼ å£°ã‚’æŽ›ã‘ã‚‹ -&gt; æ‰¾äººå¸®å¿™çš„æ—¶å€™çš„æ­è¯ éƒ¨é•·ã€ã™ã¿ã¾ã›ã‚“ ã„ã¾ã€ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼ã¡ã‚‡ã£ã¨ã‚ˆã‚ã—ã§ã—ã‚‡ã†ã‹ ã„ã¾ã€ãŠæ™‚é–“ã„ãŸã ã‘ã¾ã™ã‹ æ‰“å¬åˆ«äººçš„å®‰æŽ’ äºˆå®šã‚’èžã æ—¥æ›œæ—¥ã€ä½•ã‹ã”äºˆå®šãŒã‚ã‚Šã¾ã™ã‹ æ¥é€±ã®ç«æ›œæ—¥ã€å°æž—ã•ã‚“ã®ã”éƒ½åˆã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ é‚€è¯· éƒ¨é•·ã«ã‚‚ãœã²æ¥ã¦é ‚ããŸã„ã§ã™ã‹ è¯­æ°”æ¯”è¾ƒå¼ºçš„é‚€è¯· éƒ¨é•·ã«ã‚‚ã”å‡ºå¸­ã„ãŸã ã‘ãªã„ã‹ã¨æ€ã„ã¾ã—ã¦ åŽé¢çš„æ€ã„ã¾ã—ã¦å¸¦æœ‰è¡¨ç¤ºåŽŸå› çš„æ„æ€ ã‚ˆã‚ã—ã‹ã£ãŸã‚‰ã€éƒ¨é•·ã‚‚ã„ã‚‰ã—ã‚ƒã„ã¾ã›ã‚“ã‹ ã‚ˆã‚ã—ã‘ã‚Œã°ã€éƒ¨é•·ã‚‚ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ ã‚‚ã—ã”éƒ½åˆãŒã‚ˆã‚ã—ã‘ã‚Œã°ã€éƒ¨é•·ã‚‚ã„ã‹ãŒã‹ã¨æ€ã„ã¾ã—ã¦ ãŠï¼ã”ã€œãªãï¼ˆä¸æ˜¯ä»€ä¹ˆè¯éƒ½èƒ½ç”¨çš„ï¼ŒåŽé¢ä¸è¦åŠ teï¼‰ ã”å¿ƒé…ãªã ã”é æ…®ãªã ãŠæ°—é£ã„ãªã ãŠã‹ã¾ã„ãªã ã€œã¦ãŠã‚Šã¾ã™ ã¦ã„ã¾ã™çš„è°¦è®©è¯­ ä¾‹å­ ãŠè¿”äº‹ã‚’ãŠæŒã¡ã—ã¦ãŠã‚Šã¾ã™ å½“æ—¥ãŠä¼šã„ã§ãã‚‹ã®ã‚’æ¥½ã—ã¿ã«ã—ã¦ãŠã‚Šã¾ã™ ä¾‹å­ï¼šé‚€è¯·è€å¸ˆ ã‚ˆã‚ã—ã‘ã‚Œã°ã€å…ˆç”Ÿã‚‚ã„ã‚‰ã—ã‚ƒã„ã¾ã›ã‚“ã‹ï¼å…ˆç”Ÿã‚‚æ¥ã¦ããŸã ããŸã„ã¨æ€ã£ã¦ã„ã¾ã™ å…ˆç”Ÿã®ã”éƒ½åˆã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ ãŠè¿”äº‹ã‚’ãŠæŒã¡ã—ã¦ãŠã‚Šã¾ã™ è¯·æ±‚æ‰“æ‹›å‘¼ å‘¼ã³ã‹ã‘ã‚‹ ã‚ã®ã€ã¡ã‚‡ã£ã¨ã‚ˆã‚ã—ã„ã§ã—ã‚‡ã†ã‹ ä»Šã€ãŠå¿™ã—ã„ã§ã—ã‚‡ã†ã‹ ãŠæ™‚é–“ã„ãŸã ãã¦ã‚‚ã‚ˆã‚ã—ã„ã§ã—ã‚‡ã†ã‹ ï¼ˆå®Ÿã¯ï¼‰ã€œã®ã§ã™ãŒ æŒã¡å¸°ã£ã¦æˆ‘ãŒç¤¾ã®ã‚‚ã®ã¨æ¤œè¨Žã—ãŸã„ã®ã§ã™ãŒã€‚ã€‚ã€‚ å®Ÿã¯ä½¿ã„æ–¹ãŒã‚ˆãã‚ã‹ã‚‰ãªã„ã®ã§ã™ãŒã€‚ã€‚ã€‚ ã„ãŸã ã‘ã¾ã›ã‚“ã‹ï¼ã”ï¼ˆãŠï¼‰ã€œã„ãŸã ã‘ã¾ã›ã‚“ã‹ åŽé¢é‚£ç§è¯´æ³•æ›´å¥½ä¸€ç‚¹ï¼Œä¸­é—´å¯ä»¥ç›´æŽ¥å¡«åŠ¨è¯çš„masuåž‹ ã“ã®äºˆå‘Šç·¨ã®DVDã‚’ä¸€æžšãŠé€ã£ã¦ã„ãŸã ã‘ã¾ã›ã‚“ã‹ æ³¨æ„è¿™é‡Œæ²¡æœ‰teï¼ï¼ï¼ ç»§ç»­è¯·æ±‚ æ—¥æœ¬èªžè¨³ã‚’ã¤ã‘ã¦ã„ãŸã ã‘ãªã„ã‹ã¨æ€ã„ã¾ã—ã¦ æ—¥æœ¬èªžè¨³ã‚’ã¤ã‘ã¦ã„ãŸã ã‘ã‚‹ã¨ã‚ã‚ŠãŒãŸã„ã‚“ã§ã™ãŒã€‚* æ€ã„ã¾ã—ã¦å°±è¡¨ç¤ºäº†æ²¡è¯´å®Œï¼Œä½†æ˜¯åŽé¢è·Ÿç€ï¼šä½ èƒ½æŽ¥æ”¶æˆ‘çš„è¯·æ±‚å—çš„æ„æ€ æ‰“æ‹›å‘¼çš„æ–¹å¼ æœ‹å‹ ã§ã™ã¾ã™ æ•¬è¯­ ã­ãˆã€ã‚ã®ã­ å¯ ä¸å¯ ä¸å¯ ã‚ã®- å¯ å¯ å¯ æ‚ªã„ã‚“ã ã‘ã©ï¼æ‚ªã„ã‘ã© å¯ ä¸å¯ ä¸å¯ ã‚ˆã‹ã£ãŸã‚‰ å¯ å¯ å¯ ã™ã¿ã¾ã›ã‚“ãŒ ä¸å¯ å¯ å¯ ã‚ˆã‚ã—ã‹ã£ãŸã‚‰ ä¸å¯ ä¸å¯ å¯ ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒï¼æã‚Œå…¥ã‚Šã¾ã™ãŒï¼æç¸®ã§ã™ãŒ ä¸å¯ ä¸å¯ å¯ æ–‡æœ« æœ‹å‹ ã§ã™ã¾ã™ æ•¬è¯­ ~ã¦ï¼ˆã‚ˆï¼ã­ï¼‰ å¯ ä¸å¯ ä¸å¯ ~ã¦ãã‚Œãªã„ å¯ ä¸å¯ ä¸å¯ ~ã¦ãã‚Œã¾ã›ã‚“ã‹ ä¸å¯ å¯ ä¸å¯ ~ã¦ã‚‚ã‚‰ãˆã¾ã›ã‚“ã‹ ä¸å¯ å¯ ä¸å¯ ~ã„ãŸã ã‘ã¾ã›ã‚“ã‹ ä¸å¯ å¯ å¯ ~ã„ãŸã ã‘ã¾ã›ã‚“ã§ã—ã‚‡ã†ã‹ ä¸å¯ å¯ å¯ ~ã„ãŸã ããŸã„ã‚“ã§ã™ãŒ ä¸å¯ å¯ å¯ ~ã„ãŸã ã‘ãªã„ã‹ã¨æ€ã„ã¾ã—ã¦ ä¸å¯ ä¸å¯ å¯ ~ã„ãŸã ã‘ã‚‹ã¨ã‚ã‚ŠãŒãŸã„ã‚“ã§ã™ãŒ ä¸å¯ ä¸å¯ å¯ ç»ƒä¹ å¥åž‹ ã™ã¿ã¾ã›ã‚“ãŒã€ã€œã¦ã„ãŸã ã‘ã¾ã›ã‚“ã‹ ç”³ã—è¨³ãªã„ã‚“ã§ã™ãŒã€ã€œã¦ã„ãŸã ã‘ã‚‹ã¨ã‚ã‚ŠãŒãŸã„ã‚“ã§ã™ãŒ ç”¨åœ¨éžå¸¸éš¾ä»¥å¼€å£è¯·æ±‚çš„éƒ‘é‡æ³è¯·çš„æƒ…å†µä¸‹ ã‚ã®ãƒ¼ã€ã€œã¦ã‚‚ã‚ˆã‚ã—ã§ã—ã‚‡ã†ã‹ å†™æŽ¨èä¿¡ æ•™å¸«ã®æŽ¨è–¦çŠ¶ãŒå¿…è¦ãªã®ã§ã™ãŒã€ãŠæ›¸ãã„ãŸã ã‘ãªã„ã§ã—ã‚‡ã†ã‹ã€‚ å…ˆç”Ÿã®ç ”ç©¶å®¤ã«ã”ã‚ã„ã•ã¤ã«ä¼ºã„ãŸã„ã¨æ€ã„ã¾ã—ã¦ å…ˆç”Ÿã®ã”éƒ½åˆãŒã‚ˆã‚ã—ã„æ™‚é–“ã‚’ãŠçŸ¥ã‚‰ã›ã„ãŸã ã‘ã‚‹ã¨ã‚ã‚ŠãŒãŸãå­˜ã˜ã¾ã™ è¿”äº‹ã‚’ãŠå¾…ã¡ã—ã¦ãŠã‚Šã¾ã™ æ‹’ç» æ–­ã‚‹ã€œã¯ã¡ã‚‡ã£ã¨ã€‚ã€‚ã€‚ è®©å¯¹æ–¹çœ‹åˆ°è‡ªå·±ä¸ºéš¾çš„æ ·å­ï¼ŒçŸ¥é“è‡ªå·±æœ‰å›°éš¾ æ–­ã‚‹ ä¾‹1ï¼šæ‹’ç»çš„æ—¶å€™è¯´åˆ°å¥å°¾å¯ä»¥ä¸è¯´æ¸…æ¥š ã‚ã€ã‚³ãƒ”ãƒ¼æ‰‹ä¼ã£ã¦ãã‚Œãªã„ã‹ ä»Šã€ãƒ­ãƒ“ãƒ¼ã§ãŠå®¢æ§˜ãŒå¾…ã£ã¦ã„ã‚‰ã£ã—ã‚ƒã‚‹ã®ã§ã€‚ã€‚ã€‚ ä¾‹2ï¼šå¥å°¾ç”¨ã¾ã—ã¦ï¼ˆã¾ã™ï¼‰ã€ã§ã—ã¦ï¼ˆã§ã™ï¼‰æ¥è¡¨ç¤ºåŽŸå›  æ®‹å¿µãªãŒã‚‰ä»Šå›žã¯ä¼ºãˆãªã„ã‚“ã§ã™ã€‚ä»Šå¤œã¯å‹äººã¨ä¼šã†ç´„æŸãŒã‚ã‚Šã¾ã—ã¦ã€‚ã€‚ã€‚ ã™ã¿ã¾ã›ã‚“ã€‚ãŠé…’ã¯ã¡ã‚‡ã£ã¨è‹¦æ‰‹ã§ã—ã¦ã€‚ã€‚ã€‚ ã‚ã‚Šã¾ã™ -&gt; ã”ã–ã„ã¾ã—ã¦ï¼ã  -&gt; ã§ã—ã¦ è¬ã‚‹ æ‹’ç»äº†ä»¥åŽçš„é“æ­‰ è¢«æ‹œæ‰˜äº†äº‹æƒ…çš„æ—¶å€™ ãŠå½¹ã«ç«‹ã¦ãªãã¦ã€ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ è¢«é‚€è¯·äº†çš„æ—¶å€™ã€‚è¯·å…ˆè¯´è°¢è°¢ ã›ã£ã‹ããŠèª˜ã„ãã ã•ã„ã¾ã—ãŸã®ã«ã€ï¼ˆã™ã¿ã¾ã›ã‚“ï¼‰ æ‹’ç»äº†ä½†æ˜¯è¿˜è¦ä¿æŒè‰¯å¥½çš„å…³ç³» ä»Šå›žã¯ä¼ºãˆãªã„ã‚“ã§ã™ãŒã€ã¾ãŸ ä»Šåº¦ï¼æ¬¡å›žï¼æ¬¡ã®æ©Ÿä¼š ã« ãŠèª˜ã„ãã ã•ã„ï¼ã”ä¸€ç·’ã«ã•ã›ã¦ãã ã•ã„ ç»ƒä¹  ã€œã¯ã¡ã‚‡ã£ã¨è‹¦æ‰‹ã§ã—ã¦ ãŠèª˜ã„ãã ã•ã„ã¾ã—ã¦ã‚ã‚ŠãŒã©ã†ã”ã–ã„ã¾ã™ æ®‹å¿µãªãŒã‚‰ã€ãã®æ—¥ã¯å±±ç”°ã•ã‚“ã¨ä¼šè­°ã®äºˆå®šã§ã”ã–ã„ã¾ã™ã€‚ ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€å‚åŠ ã§ãã¾ã›ã‚“ ã›ã£ã‹ãã®ãŠèª˜ã„ãªã®ã«ã™ã¿ã¾ã›ã‚“ã€‚ ä»Šå›žã¯ä¼ºãˆãªã„ã§ã™ãŒã€ã¾ãŸä»Šåº¦ã«ãŠèª˜ã„ãã ã•ã„ ç”³ã—å‡ºã‚‹ è‡ªå·±ä¸»åŠ¨æå‡ºç”³è¯·ãŠï¼ã” ã€œ ï¼ˆã„ãŸï¼‰ã—ã¾ã—ã‚‡ã†ã‹ ä½¿ç”¨è‡ªè°¦è¯­æ¥è¡¨ç¤ºéƒ‘é‡çš„ä¸»åŠ¨æå‡ºï¼Œå¯ä»¥è®©æˆ‘æ¥å¹²è¿™ä»¶äº‹çš„æ„æ€ï¼ï¼æ²¡æœ‰te ä¾‹å­ ãŠè·ç‰©ã‚’ãŠæŒã¡ã—ã¾ã—ã‚‡ã†ã‹ è³‡æ–™ã‚’ãŠé€ã‚Šè‡´ã—ã¾ã—ã‚‡ã†ã‹ åŠ è—¤ã•ã‚“ã«ã¯ç§ã‹ã‚‰ã”é€£çµ¡è‡´ã—ã¾ã—ã‚‡ã†ã‹ ã€œã•ã›ã¦ã„ãŸã ãã¾ã™ åŽŸæœ¬æ˜¯å¾æ±‚å¯¹æ–¹è®¸å¯ä¹‹åŽåšæŸäº‹ï¼ŒåŽæ¥å‘å±•æˆæ•¬è¯­ç”¨æ³•ï¼ˆã•ã›ã¦ã„ãŸã ãã„ã¦ã‚‚ã‚ˆã‚ã—ã„ã§ã—ã‚‡ã†ã‹ï¼‰ æœªç»è®¸å¯å°±ç”¨çš„è¯æœ‰å¼ºåŠ çš„æ„æ€ ä¾‹å­ ä¼šè­°ã®æ—¥ã¯æ˜¼é£Ÿã‚’ç”¨æ„ã•ã›ã¦ã„ãŸã ãã¾ã™ ä»Šæ—¥ã®åˆå¾Œã€ä¼šè­°å®¤ã‚’ä½¿ã‚ã›ã¦ã„ãŸã ããŸã„ã‚“ã§ã™ãŒ ä»Šæ—¥ã¯ç”³ã—è¨³ãªã„ã‚“ã§ã™ãŒã€æ—©ã‚ã«å¸°ã‚‰ã›ã¦ã„ãŸã ã‘ã¾ã›ã‚“ã‹ ã“ã®ãƒ‘ã‚½ã‚³ãƒ³ã‚’ä½¿ã‚ã›ã¦ã„ãŸã ã„ã¦ã‚‚ã‚ˆã‚ã—ã„ã§ã—ã‚‡ã†ã‹ ã€œã•ã›ã¦ãã ã•ã„ è¡¨è¾¾å¯¹æ–¹åŒæ„ä¹‹åŽéžå¸¸å¼ºçƒˆçš„æƒ³åšè¿™ä»¶äº‹ ä¾‹å­ ä»Š åº¦ã®ä»•äº‹ã¯ç§ã«æ‹…å½“ã•ã›ã¦ãã ã•ã„ ä»Šå¤œã¯ç§ã«ã”ã¡ãã†ã‚’ã•ã›ã¦ãã ã•ã„ ãŠè©«ã³ã™ã‚‹ é“æ­‰é“æ­‰å¸¸ç”¨å¥ ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ï¼ˆã§ã—ãŸï¼‰ï¼ ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ï¼ˆã§ã—ãŸï¼‰ å¤§å¤‰å¤±ç¤¼ã„ãŸã—ã¾ã—ãŸ ï¼ ã”è¿·æƒ‘ã‚’ãŠã‹ã‘ã—ã¾ã—ãŸ ï¼ ã©ã†ã‹ãŠè¨±ã—ãã ã•ã„ æŠ¥å‘Šè‡ªå·±çš„å¤±è¯¯ å®Ÿã¯ã€ãŠç´„æŸã®æ™‚é–“ã«ä¼ºãˆãªããªã£ã¦ã—ã¾ã£ãŸã‚“ã§ã™ 11æ—¥ã‚’21æ—¥ã ã¨èžãé–“é•ãˆã¦ã—ã¾ã„ã¾ã—ãŸ ä¼ è¾¾åçœçš„å¿ƒæƒ… ä»¥å¾Œï¼ä»Šå¾Œã¯æ°—ã‚’ã¤ã‘ã¾ã™ äºŒåº¦ã¨ã“ã®ã‚ˆã†ãªãƒŸã‚¹ã‚’ã—ãªã„ã‚ˆã†ã«ã€æ³¨æ„ï¼ç¢ºèªï¼å¾¹åº• ã„ãŸã—ã¾ã™ åˆ«äººå¯¹è‡ªå·±é“æ­‰çš„æ—¶å€™ è½»æ¾ ã‚ã€ã„ãˆã„ãˆã€ã‚ã¾ã‚ŠãŠæ°—ã«ãªã•ã‚‰ãªã„ã§ãã ã•ã„ ä¸¥è‚ƒ ã“ã†ã„ã†ã®ã¯å›°ã‚Šã¾ã™ ã“ã†ã„ã†ã“ã¨ã‚’ã•ã‚Œã‚‹ã¨å›°ã‚‹ã‚“ã§ã™ã‚ˆ ã“ã‚Œã‹ã‚‰æ°—ã‚’ã¤ã‘ã¦ãã ã•ã„ å¥å­ ãŠï¼ã”ã€œã—ã¦ã—ã¾ã„ã¾ã—ã¦ã€ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã§ã—ãŸ ãŠï¼ã”ã€œãã ã•ã„ã¾ã—ãŸã®ã«ã€ä¼ºãˆã¾ã›ã‚“ã§ã€å¤±ç¤¼ã„ãŸã—ã¾ã—ãŸï¼ˆè¡¨ç¤ºçš„æ„æ€æ˜¯ä½ éƒ½é‚€è¯·æˆ‘åšäº†ï¼Œä½ éƒ½å‡†å¤‡å¥½äº†ï¼Œä¹‹ç±»çš„ï¼Œä½†æ˜¯æˆ‘åšä¸äº†ï¼‰ æˆ–è€…ä¸åŠ oï¼ŒåŽé¢åŠ teä¹Ÿå¯ä»¥ å‘å¾® ãŠå¿™ã—ã„ä¸­ã€ãŠæ™‚é–“ã‚’ä½œã£ã¦ãã ã•ã„ã¾ã—ãŸã®ã«ã€æ™‚é–“ã‚’é–“é•ãˆã¦ã—ã¾ã„ã¾ã—ã¦ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã§ã—ãŸã€‚ä»Šå¾Œã¯ååˆ†æ³¨æ„ã„ãŸã—ã¾ã™ã®ã§ã€ãŠè¨±ã—ã¦ãã ã•ã„ã€‚ ææ„è§é—®åˆ«äººçš„æ„è§ ã“ã‚Œã«ã¤ã„ã¦ã¯ã©ã†æ€ã‚ã‚Œã¾ã™ã‹ï¼ã“ã®ç‚¹ã«ã¤ã„ã¦ã¯ã„ã‹ãŒã§ã™ã‹ ã¿ãªã•ã‚“ã®ã”æ„è¦‹ã¯ï¼ä½•ã‹ã”æ„è¦‹ã¯ã‚ã‚Šã¾ã™ã‹ ç”¨ä¸€å¥è¯è¡¨ç¤ºèµžæˆå’Œåå¯¹ èµžæˆï¼šã„ã„ã¨æ€ã„ã¾ã™ åå¯¾ï¼šã†ãƒ¼ã‚“ï¼ãã‚Œã¯ã¡ã‚‡ã£ã¨ã€‚ã€‚ã€‚ï¼ã©ã†ã§ã—ã‚‡ã†ã‹ã€‚ã€‚ã€‚ å¼€å§‹é™ˆè¿°è‡ªå·±çš„æ„è§ ã¡ã‚‡ã£ã¨ã€ã‚ˆã‚ã—ã„ã§ã—ã‚‡ã†ã‹ è¯´è‡ªå·±çš„æ„è§ å’Œå¹³çš„ææ¡ˆï¼ˆä¸€èˆ¬ç”¨è¿™ç§ï¼‰ Vï¼Aã„ ã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ Nï¼Aãª ãªã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ ä¾‹ äºˆç®—ãŒã‚‚ã£ã¨ã‹ã‹ã£ã¦ã—ã¾ã†ã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ æ™‚é–“ãŒè¶³ã‚Šãªãã¦ã€ç„¡ç†ãªã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ æè®® å…·ä½“çš„æ–¹æ¡ˆ V ãŸã‚‰ã©ã†ã‹ã¨æ€ã„ã¾ã™ï¼ˆãŒï¼‰ N ãŒã„ã„ã‹ã¨æ€ã„ã¾ã™ï¼ˆãŒï¼‰ ä¾‹ æ™‚é–“ãŒã‹ã‹ã‚‹ã®ã§ã€1ãƒ¶æœˆå‰ã‹ã‚‰æº–å‚™ã—ãŸã‚‰ã©ã†ã‹ã¨æ€ã„ã¾ã™ãŒ çµå©šã®ãŠç¥ã„ã«ã¯ã€äºŒäººãŒé•·ãä½¿ãˆã‚‹ã‚³ãƒ¼ãƒ’ãƒ¼ã‚«ãƒƒãƒ—ãªã©ãŒã„ã„ã¨æ€ã„ã¾ã™ å½’çº³æ„è§ ãã‚Œã‚ˆã‚Šã‚‚ VãŸ æ–¹ãŒã„ã„ã¨æ€ã„ã¾ã™ ãã‚Œã‚ˆã‚Šã‚‚ã‚‚ã£ã¨ç°¡å˜ã«æº–å‚™ã§ãã‚‹ç™ºè¡¨ã«å¤‰ãˆãŸæ–¹ãŒã„ã„ã¨æ€ã„ã¾ã™ æŽ¥æ”¶æ„è§ ã€œã¯ã„ã„ã“ã¨ã ã¨æ€ã„ã¾ã™ãŒï¼ãã‚Œã‚‚ãã†ã§ã™ãŒ è¯´æ˜Žç†ç”±å¿˜å¹´ä¼šã¯ä¸­è¯æ–™ç†ãŒã„ã„ã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ã€‚ã¨ã„ã†ã®ã¯ã€äººæ•°ãŒæ€¥ã«å¢—ãˆã¦ã‚‚å¤§ä¸ˆå¤«ã§ã™ã—ã€è‹¥ã„äººã¯ãŸãã•ã‚“é£Ÿã¹ãŸã„ã¨ã„ã†äººã‚‚å¤šã„ã§ã™ã—ã€æ–™ç†ã®æ•°ã‚‚å¤šãã§ã€äººæ°—ãŒã‚ã‚Šã¾ã™ã®ã§ã€‚ã€‚ã€‚ã“ã¡ã‚‰ã®æ–¹ãŒã„ã„ã¨æ€ã„ã¾ã™ã€‚ æ•´ä½“å¥åž‹ ã‚ˆã‚ã—ã„ã§ã—ã‚‡ã†ã‹ã€‚ã€œï¼ˆãªï¼‰ã®ã¯ã„ã„ã“ã¨ã ã¨æ€ã„ã¾ã™ãŒã€ã€œï¼ˆãªï¼‰ã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ã€‚ãã‚Œã‚ˆã‚Šã‚‚ã€ã€œãŸæ–¹ãŒã„ã„ã¨æ€ã„ã¾ã™ãŒã€ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ã€‚ å†™é‚®ä»¶ ãŠç–²ã‚Œæ§˜ã§ã™ã€‚ã‚¢ãƒ¬ã‚¯ã‚¹ã§ã™ã€‚ ãƒ¡ãƒ¼ãƒ«ã‚’æ‹è¦‹ã—ã¾ã—ãŸã€‚ ã¾ãšå¸­ã®ã“ã¨ã§ã™ãŒã€ãƒ•ãƒ©ãƒ³ã‚¹æ–™ç†ã¯ã„ã„ã¨æ€ã„ã¾ã™ãŒã€ä¸€äººä¸€äººã®å¸­ãŒé›¢ã‚Œã¦ã„ã¦ã¿ã‚“ãªã§è©±ã™ã“ã¨ã§ããªã„ã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ã€‚ äººæ•°ãŒã¾ã æ±ºã¾ã£ã¦ã„ãªã„ã¨ã„ã†ã“ã¨ã§ã™ãŒã€ãã‚Œãªã‚‰äººæ•°ãŒå¤‰ã‚ã£ã¦ã‚‚å¤§ä¸ˆå¤«ãªä¸­è¯æ–™ç†ãŒã„ã„ã£ã¨æ€ã„ã¾ã™ã€‚ä»Šåº¦ã®ãŠå®¢æ§˜ã¯ã‚¢ã‚¸ã‚¢ã‹ã‚‰ã®ãŠå®¢æ§˜ãŒå¤šã„ã¨ä¼ºã£ã¦ãŠã‚Šã¾ã™ã®ã§ã€ã‚¢ã‚¸ã‚¢æ–™ç†ã®æ–¹ãŒæ…£ã‚Œã¦ã„ã¦ã„ã„ã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ã€‚ ~ä¸­è¯æ–™ç†ãŒã„ã„ã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ã€‚ã¨ã„ã†ã®ã¯ã€äººæ•°ãŒæ€¥ã«å¢—ãˆã¦ã‚‚å¤§ä¸ˆå¤«ã—ã€ãŠå®¢æ§˜ã¯ã‚¢ã‚¸ã‚¢æ–™ç†ã®æ–¹ãŒæ…£ã‚Œã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚~ ãã‚Œã‚ˆã‚Šã‚‚ã€ä¸­è¯æ–™ç†ã®æ–¹ãŒã„ã„ã¨æ€ã„ã¾ã™ãŒã€ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ã€‚ æŽ¥æ”¶é¢„çº¦ã€œã§ã”ã–ã„ã¾ã™ æŽ¥ç”µè¯ ç”¨äºŽè¯´è‡ªå·±æˆ–è€…è‡ªå·±å›¢ä½“çš„äº‹æƒ… ã§ã”ã–ã„ã¾ã™å’Œã§ã„ã‚‰ã—ã‚ƒã„ã¾ã™æ˜¯ä¸€ä¸ªæ„æ€ï¼Œä¸€ä¸ªç”¨åœ¨è‡ªå·±ä¸€ä¸ªç”¨åœ¨å¯¹æ–¹ æ‰¿ã‚Šã¾ã™ï¼ˆã†ã‘ãŸã¾ã‚ã‚‹ï¼‰ æŽ¥å—é¢„çº¦ å¯¹ç›®ä¸Šçš„äººæŽ¥æ”¶é¢„çº¦æ—¶å€™çš„æ•¬è¯­ ã”äºˆç´„ã€æ‰¿ã£ã¦ãŠã‚Šã¾ã™ ã”äºˆç´„ã¯ã€ç§ã€éˆ´æœ¨ãŒæ‰¿ã‚Šã¾ã—ãŸ ã€œã§ã„ã‚‰ã—ã‚ƒã„ã¾ã™ ç¡®å®šé¢„çº¦çš„äººæ•°æˆ–è€…åå­— å¤±ç¤¼ã§ã™ãŒã€ç”°ä¸­ã•ã‚“ã§ã„ã‚‰ã—ã‚ƒã„ã¾ã™ã‹ 3åæ§˜ã§ã„ã‚‰ã—ã‚ƒã„ã¾ã™ã‹ ãŠå…ƒæ°—ã§ã„ã‚‰ã—ã‚ƒã„ã¾ã™ã‹ ä¸èƒ½ç”¨åœ¨å’Œå¯¹æ–¹æ— å…³çš„äº‹æƒ…ä¸Š ãŠï¼ã” ã€œ ã«ãªã‚Œã¾ã™ã‹ åœ¨æ—¥è¯­é‡Œç›´æŽ¥é—®ç›®ä¸Šçš„äººã§ãã¾ã™æ¯”è¾ƒå¤±ç¤¼ï¼Œæ‰€ä»¥ç”¨è¿™ç§æ–¹æ³•çš„æ¯”è¾ƒå¤šã€‚åªæœ‰å½“æœ‰éžå¸¸ç¨€å¥‡çš„æŠ€èƒ½çš„æ—¶å€™æ‰ä¼šç”¨ã§ãã¾ã™ ç¤¾é•·ã¯ã‚¹ãƒšã‚¤ãƒ³èªžãŒãŠè©±ã«ãªã‚Œã¾ã™ã‹ ãŠï¼ã”ã€œã„ãŸã ã‘ã¾ã™ ï¼ ã€œã¦ã‚‚ã‚‰ãˆã¾ã™ï¼ˆè¡¨ç¤ºçš„æ˜¯å¯ä»¥åšçš„æ„æ€ï¼Œæ²¡æœ‰æŽˆå—çš„å«ä¹‰ï¼‰ ã“ã®å»ºç‰©ã®ä¸­ã§ã€wifiãŒãŠä½¿ã„ã„ãŸã ã‘ã¾ã™ ç‰¹æ€¥åˆ¸ã‚’ãŠæ±‚ã‚ã«ãªã‚Œã°ã€ç‰¹æ€¥ã«ã”ä¹—è»Šã„ãŸã ã‘ã¾ã™ ã€œã¯ãªã•ã„ã¾ã™ã‹ ï¼ ã€œã«ã—ã¾ã™ã‹ ï¼ ã«æ±ºã‚ã¾ã™ æ–™ç†ã¯ã©ã®ã‚³ãƒ¼ã‚¹ã«ãªã•ã„ã¾ã™ã‹ ã•ã›ã¦ã„ãŸã ãã¾ã™ å†ä¸€æ¬¡ç¡®è®¤ ç”¨å¤šäº†ä¼šæœ‰å¼ºè¿«çš„æ„æ€ ã”æ³¨æ–‡ã‚’ ç¹°ã‚Šè¿”ã•ã›ã¦ï¼ç¢ºèªã•ã›ã¦ï¼å¾©å”±ã•ã›ã¦ ã„ãŸã ãã¾ã™ èª ã«å‹æ‰‹ãªãŒã‚‰æœ¬æ—¥ã¯åˆå¾Œä¸ƒæ™‚ã§é–‰åº—ã•ã›ã¦ã„ãŸã ãã¾ã™ ã‚µãƒ¼ãƒ“ã‚¹æ•¬èªžãŠï¼ã”ã€œã«ãªã‚Šã¾ã—ãŸã‚‰ å¦‚æžœä½ å†³å®šå¥½äº†çš„è¯ãŠæ±ºã¾ã‚Šã«ãªã‚Šã¾ã—ãŸã‚‰ã€ãŠå‘¼ã³ãã ã•ã„ ãŠï¼ã”ã€œãã ã•ã„ã¾ã› ä¸å®çš„è¯´è¯·æ±‚çš„æ—¶å€™ ãŠä¸€äººä¸€æžšãšã¤ãŠå–ã‚Šãã ã•ã„ã¾ã› ä½•ã‹ã‚ã‚Šã¾ã—ãŸã‚‰ã€ã”ç›¸è«‡ãã ã•ã„ã¾ã› ã”è³ªå•ãŒãŠã‚ã‚Šã§ã—ãŸã‚‰ã€ãŠç­”ãˆã„ãŸã—ã¾ã™ ãŠå›°ã‚Šã§ã—ãŸã‚‰ã€ãŠæ‰‹ä¼ã„ã„ãŸã—ã¾ã™ çŸ­è¯­ ãŠæ±ºã¾ã‚Šã§ã—ãŸã‚‰ï¼ˆãŠæ±ºã¾ã‚Šã«ãªã£ã¦ã„ã¾ã—ãŸã‚‰ï¼‰ã€ä¼ºã„ã¾ã™ ã”äºˆç´„ã‚’ã”å¸Œæœ›ãªã‚‰ï¼ˆã”å¸Œæœ›ã«ãªã‚‹ãªã‚‰ï¼‰ã€ã“ã¡ã‚‰ã§æ‰¿ã‚Šã¾ã™ å…ˆã«ãŠä¸¦ã³ã®æ–¹ï¼ˆãŠä¸¦ã³ã«ãªã£ã¦ã„ã‚‹æ–¹ï¼‰ã‹ã‚‰é †ã«ãŠå…¥ã‚Šãã ã•ã„ æ•´ç†åˆ¸ã‚’ãŠæŒã¡ã§ã™ã‹ï¼ˆãŠæŒã¡ã«ãªã£ã¦ã„ã‚‰ã£ã—ã‚ƒã„ã¾ã™ã‹ï¼‰ å¸¸ç”¨æœåŠ¡ç”¨è¯­ ãŠå¾…ãŸã›ã—ã¾ã—ãŸ ã‹ã—ã“ã¾ã‚Šã¾ã—ãŸ ãŠé£²ã¿ç‰©ã¯ã„ã‹ãŒã„ãŸã—ã¾ã—ã‚‡ã†ã‹ ã‘ã£ã“ã†ã§ã™æŽ¥æ”¶å•†é‡è¯¢é—®åˆ«äººçš„æƒ³æ³•çš„æ—¶å€™ å¯¹ç›®ä¸Šè¯¢é—®æƒ³å¹²ä»€ä¹ˆçš„æ—¶å€™ï¼Œä¸èƒ½ç”¨ã€œã—ãŸã„æ¥é—® å…ˆç”Ÿã¯ä½•ã‚’é£Ÿã¹ãŸã„ã§ã™ã‹ï¼ˆX) å…ˆç”Ÿã¯ä½•ã‚’å¬ã—ä¸ŠãŒã‚Šã¾ã™ã‹ å…ˆç”Ÿã¯ã©ã®ã‚ˆã†ãªã‚‚ã®ãŒãŠå¥½ãã§ã™ã‹ ææ¡ˆã™ã‚‹ æå»ºè®®çš„æ—¶å€™ç”¨ã¨ã‹ä¸æ˜¯å¾ˆä¸å®ï¼Œå¤‰æˆ ãªã© ãƒ“ãƒ¼ãƒ«ã‚’å¬ã—ä¸ŠãŒã‚‹ãªã‚‰ã€éŠ€åº§ãƒ›ãƒ¼ãƒ«ãªã©ã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ æ—¥æœ¬æ–‡åŒ–ä½“é¨“ãªã‚‰ã€éŽŒå€‰ã®ãŠå¯ºã§åº§ç¦…ã‚’ãªã•ã£ãŸã‚‰ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ ã”å­˜çŸ¥ã§ã™ã‹ ãƒ¼ å­˜ã˜ã¦ãŠã‚Šã¾ã™ï¼å­˜ã˜ä¸Šã’ã¦ãŠã‚Šã¾ã™ å¯¹äº‹ç‰©çš„è¯ç”¨å‰è€…ï¼Œå¯¹äººçš„è¯ç”¨åŽè€… ã‚¢ã‚¹ã‚¯å•†äº‹ã®é«˜æ©‹éƒ¨é•·ã‚’ã”å­˜çŸ¥ã§ã™ã‹ ãƒ¼ ã¯ã„ã€å­˜ã˜ä¸Šã’ã¦ãŠã‚Šã¾ã™ï¼ˆå›žç­”åˆ«äººé—®è¯çš„æ—¶å€™ï¼‰ ã”ã€œï¼ˆæ¼¢å­—ï¼‰ã§ã™ åŒæ ·è¡¨è¾¾å°Šæ•¬è¯­çš„æ„æ€ ä½•ã‹ã”å¿ƒé…ã§ã™ã‹ æ˜Žæ—¥ã®ä¼šè­°ã€ã”å‡ºå¸­ã§ã™ã‹ æ¼”è®² å‘è¡¨å¼€å§‹çš†ã¾ã•ã€ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã€‚æœ¬æ—¥ã¯ã€ã€œã«ã¤ã„ã¦ãŠè©±ã—ã—ã¾ã™ã€‚ å¯¹æ¼”è®²æ—¶çš„è§‚ä¼—è¯´è¯åº”è¯¥ç”¨æ•¬è¯­åœ¨è¿›å…¥è¯é¢˜ä¹‹åŽï¼Œæ¯”èµ·æ•¬è¯­æ›´åº”è¯¥ç”¨desu masu ã§ã™ã‹ã‚‰ ï¼ ã ã‹ã‚‰ ã”å­˜çŸ¥ã®ã‚ˆã†ã«ï¼ã”å­˜çŸ¥ã®é€šã‚Š ã€œã‚‰ã‚Œã¦ãŠã‚Šã¾ã™ï¼ˆè€ƒãˆã‚‹ï¼è¨€ã†ï¼è©•ä¾¡ã™ã‚‹ï¼‰ ç»“æŸ ä»¥ä¸Šã€ã€œã„ã¤ã„ã¦ç´¹ä»‹ã„ãŸã—ã¾ã—ãŸ ã”é™è´ã‚ã‚ŠãŒã©ã†ã”ã–ã„ã¾ã™ é¢è¯•ã¦ã¾ã„ã‚Šã¾ã—ãŸï¼ã¦ãã‚‹ é«˜æ ¡ç”Ÿã®æ™‚æ—¥æœ¬èªžã®å‹‰å¼·ã‚’ã—ã¦ã¾ã„ã‚Šã¾ã—ãŸ ç§ã¯ã“ã‚Œã¾ã§ã€é€šè¨³ã®ä»•äº‹ã«ç”°é¶´ã‚ã£ã¦ã¾ã„ã‚Šã¾ã—ãŸ ã€œã¦ãŠã‚Šã¾ã™Nç§ãŒç ”ç©¶ã—ã¦ãŠã‚Šã¾ã™ãƒ†ãƒ¼ãƒžã¯ã€æ—¥æœ¬èªžã®æ•¬èªžã«ã¤ã„ã¦ã§ã™ ã€œæ¬¡ç¬¬ã§ã™ ï¼ ã€œã‚“ã§ã™ å¾¡ç¤¾ã®ãƒ“ã‚¸ãƒã‚¹ã¯ã€ç§ã®ç ”ç©¶ãƒ†ãƒ¼ãƒžã¨é‡ãªã£ã¦ã„ã‚‹ã¨æ€ã„ã€å¤§å¤‰èˆˆå‘³æ·±ãæ„Ÿã˜ãŸæ¬¡ç¬¬ã§ã™ æ¢ç§è¯´æ³•| ã€œã«ã¤ã„ã¦é¢ç™½ã„ã¨æ€ã„ã¾ã—ãŸ | ã€œã«ã¤ã„ã¦èˆˆå‘³æ·±ãæ„Ÿã˜ã¾ã—ãŸ || ã™ã”ãï¼ã¨ã¦ã‚‚ | å¤§å¤‰ï¼éžå¸¸ã« || ã©ã‚“ãª | ã©ã®ã‚ˆã†ãª || ã€œã§ããŸã‚‰ã„ã„ãªã¨è€ƒãˆã¦ã„ã¾ã™ | ã€œã§ããŸã‚‰ã¨è€ƒãˆã¦ãŠã‚Šã¾ã™ || ã€œãã‚ŒãŸã‚‰ã„ã„ãªã¨æ€ã„ã¾ã™ | ã€œãã‚ŒãŸã‚‰ã¨è€ƒãˆã¦ãŠã‚Šã¾ã™ || ã€œã—ãŸã„ã§ã™ | ã€œã§ããŸã‚‰ã¨æ€ã„ã¾ã™ | è‡ªå·±ç´¹ä»‹æœ¬æ—¥ã¯é¢æŽ¥ã®æ©Ÿä¼šã‚’ãã ã•ã„ã¾ã—ã¦ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚æ—©é€Ÿã§ã™ãŒã€è‡ªå·±ç´¹ä»‹ã‚’ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ç§ã¯XXã¨ç”³ã—ã¾ã™ã€‚2018å¹´æ¥æ—¥ã„ãŸã—ã¾ã—ã¦ã€ç¾åœ¨ã€XXXã‚’ç ”ç©¶ã—ã¦ãŠã‚Šã¾ã™ã€‚ã©ã†ãžã‚ˆã‚ã—ããŠé¡˜ã„ã„ãŸã—ã¾ã™ã€‚ è¢«é—®åˆ°é—®é¢˜è¦å…ˆå›žç­” ã¯ã„ï¼Œä¸è¦åŠ é‚£ä¹ˆå¤šçŠ¹è±«è¯ä¸è¦å¤ªå¤šçš„ç”¨ã§ãã¾ã™ å°‘ã—ã§ã‚‚ãŠå½¹ã«ç«‹ã¦ãŸã‚‰ã¨æ€ã„ã¾ã™ ä¾‹ç§ã¯ã‚²ãƒ¼ãƒ ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®é–‹ç™ºã‚’ç¶šã‘ã¦ã¾ã„ã‚Šã¾ã—ãŸã€‚ç§ãŒä½¿ã£ã¦ãŠã‚Šã¾ã™ã‚½ãƒ•ãƒˆã®é–‹ç™ºã‚’å¤šãæ‰‹ãŒã‘ã¦ã„ã‚‰ã£ã—ã‚ƒã‚‹å¾¡ç¤¾ã®äº‹æ¥­å†…å®¹ã‚’ä¼ºã£ã¦ã€éžå¸¸ã«èˆˆå‘³æ·±ãæ„Ÿã˜ã¾ã—ãŸã€‚ã•ã‚‰ã«ã‚ˆã‚Šè‰¯ã„ã‚²ãƒ¼ãƒ ã‚½ãƒ•ãƒˆã‚’é–‹ç™ºã§ããŸã‚‰ã¨è€ƒãˆã¦ãŠã‚Šã¾ã™ã€‚ æŽ¥ç”µè¯ã¯ã„ã€XXXã§ã”ã–ã„ã¾ã™ã„ã¤ã‚‚ãŠä¸–è©±ã«ãªã£ã¦ãŠã‚Šã¾ã™ ã“ã¡ã‚‰ã“ãã€ãŠä¸–è©±ã«ãªã£ã¦ãŠã‚Šã¾ã™ ï¼ˆä¼šç¤¾åï¼‰ã®XXã¨ç”³ã—ã¾ã™ãŒã€XXæ§˜ï¼å½¹è·ã€ã„ã‚‰ã£ã—ã‚ƒã„ã¾ã™ã‹åå‰ ã¯ãŸã ã„ã¾ã€XXä¸­ã§ã”ã–ã„ã¾ã™å¸¸ç”¨è¯­ ä¸åœ¨çš„æ—¶å€™ XXã¯ãŸã ã„ã¾å¸­ã‚’å¤–ã—ã¦ãŠã‚Šã¾ã—ã¦ã€‚ã€‚ã€‚ è®©ä»–ä¸€ä¼šå›žç”µ æŠ˜ã‚Šè¿”ã—XXã«é›»è©±ã•ã›ã¾ã—ã‚‡ã† æŽ¥æ”¶ç•™è¨€ ã‚ˆã‚ã—ã‘ã‚Œã°ã€ç§ãŒã”ç”¨ä»¶ã‚’æ‰¿ã‚Šã¾ã™ãŒã€‚ã€‚ã€‚ æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚XXXã«ç”³ã—ä¼ãˆã¾ã™ã€‚ç§ã€XXãŒæ‰¿ã‚Šã¾ã—ãŸ ç¨åŽå†æ‹¨ æã‚Œå…¥ã‚Šã¾ã™ãŒã€XXåˆ†éŽãŽã«ã‚‚ã†ä¸€åº¦ãŠã‹ã‘ã„ãŸã ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ ãã‚Œã§ã¯ã€XXåˆ†å¾Œã«ã“ã¡ã‚‰ã‹ã‚‰ãŠã‹ã‘ã—ã¾ã™ å†ä¸€æ¬¡è¯·æ•™å§“å å¤±ç¤¼ã§ã™ãŒã€ã‚‚ã†ä¸€åº¦ãŠåå‰ã‚’ä¼ºã£ã¦ã‚‚ã‚ˆã‚ã—ã„ã§ã—ã‚‡ã†ã‹ æŒ‚ç”µè¯ ã§ã¯ã€å¤±ç¤¼ã„ãŸã—ã¾ã™ æ¢äººæŽ¥ ãŠé›»è©±ã‹ã‚ã‚Šã¾ã—ãŸã€‚XXã§ã™ é‡‡è®¿ã€œä¸­ï¼ã¨ã“ã‚ã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ ãŠå¿™ã—ã„ä¸­ï¼ãŠå¯’ã„ä¸­ï¼é›¨ã®ä¸­ã€ã‚ã–ã‚ã–ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ ãŠæ€¥ãŽã®ã¨ã“ã‚ï¼ãŠç–²ã‚Œã®ã¨ã“ã‚ï¼ãŠä¼‘ã¿ã®ã¨ã“ã‚ã€ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ é‡å¤å¯¹æ–¹è¯´çš„è¯æ‰©å±•å¯¹æ–¹è¯´çš„è¯æƒ³ç¡®è®¤æ—¶ ä»Šã€ä½•ã¨ãŠã£ã—ã‚ƒã„ã¾ã—ãŸã§ã—ã‚‡ã†ã‹ã€‚ï¼ã¨ã€ãŠã£ã—ã‚ƒã„ã¾ã™ã¨ ãã®ã€œã¨è¨€ã†ã®ã¯ã€ã©ã®ã‚ˆã†ãªæ„å‘³ã§ã™ã‹ æŠ¥å‘Šæœ‰é¡ºåºçš„æŠ¥å‘Š ã¾ãšã€XXXã«ã¤ã„ã¦å ±å‘Šã—ã¾ã™ ä»¥ä¸Šã€æ¦‚è¦ã„ã¤ã„ã¦ã”å ±å‘Šã—ã¾ã—ãŸ æ¬¡ã«ã€ ãã®æ¬¡ã«ï¼ãã‚Œã‹ã‚‰ æœ€å¾Œã« ã¨ã®ã“ã¨ã§ã™ ï¼ ãã†ã§ã™ è½¬è¿°å¬åˆ°åˆ«äººçš„è¯è¯·çœ‹ ã“ã¨ã‚‰ã®å†™çœŸã‚’ã”è¦§ãã ã•ã„ ã”è¦§ã„ãŸã ãã¨ãŠåˆ†ã‹ã‚Šã®ã‚ˆã†ã«ã€ã€‚ã€‚ã€‚ å‘è¡¨æ„Ÿæƒ³ ã€‚ã€‚ã€‚ã¨æ€ã„ã¾ã™ ã€‚ã€‚ã€‚ã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ ãŸ æ–¹ãŒã„ã„ã¨æ€ã„ã¾ã™ ç»“æŸæŠ¥å‘Š ä»¥ä¸Šã§å ±å‘Šã‚’çµ‚ã‚ã‚Šã¾ã™ ä»¥ä¸Šã€XXXã«ã¤ã„ã¦ã”å ±å‘Šã—ã¾ã—ãŸ ä½•ã‹è³ªå•ã¯ã‚ã‚Šã¾ã›ã‚“ã‹ï¼ã”è³ªå•ãŒãŠã‚ã‚Šã§ã—ãŸã‚‰ã©ã†ãž å¸ä¼šçš„æ•¬è¯­è™½ç„¶æ˜¯æœ‹å‹ï¼Œä½†æ˜¯åœ¨å¾ˆå¤šäººé¢å‰è¯´çš„æ—¶å€™ä¹Ÿè¦ä¸å®ä¸€ç‚¹ãŠVã§ã™ ï¼ ãŠVã«ãªã£ã¦ã„ã‚‰ã£ã—ã‚ƒã„ã¾ã™ çš†ã•ã‚“ãŠæƒã„ã§ã™ã®ã§ã€ çš†ã•ã‚“ãŠè¦‹ãˆã§ã™ã®ã§ã€ ãã‚ãã‚å§‹ã‚ãŸã„ã¨æ€ã„ã¾ã™å¸¸ç”¨è¯­ å¤§ããªæ‹æ‰‹ã§ãŠè¿Žãˆãã ã•ã„ ã€œã•ã‚“ã®å‰é€”ã‚’ç¥ã—ã¦ï¼ä»Šå¾Œã®ã”æ´»èºã¨ã”å¥åº·ã‚’ç¥ˆã£ã¦ã€ä¹¾æ¯ã‚’ã—ãŸã„ã¨æ€ã„ã¾ã™ ä¹¾æ¯ã®éŸ³é ­ã¯ã€œå…ˆç”Ÿã«ãŠé¡˜ã„ã—ãŸã„ã¨æ€ã„ã¾ã™ ãŠæ‰‹å…ƒã®ã‚°ãƒ©ã‚¹ã‚’ãŠæŒã¡ãã ã•ã„ ã”ã‚†ã£ãã‚ŠãŠæ¥½ã—ã¿ãã ã•ã„ ã“ã“ã§ä¸€è¨€ã”æŒ¨æ‹¶ç”³ã—ä¸Šã’ã¾ã™ ã§ã¯ã€ã€œã•ã¾ã«ãŠç¥ã„ã®ã“ã¨ã°ã‚’ã„ãŸã ããŸã„ã¨æ€ã„ã¾ã™ ãã‚ãã‚ãŠèžãã«ã—ãŸã„ã¨æ€ã„ã¾ã™ é‚®ä»¶ | æŒ¨æ‹¶ | ã„ã¤ã‚‚ãŠä¸–è©±ã«ãªã£ã¦ãŠã‚Šã¾ã™ | | ãŠç¤¼ | ãƒ¡ãƒ¼ãƒ«ã€ã‚ã‚ŠãŒã©ã†ã”ã–ã„ã¾ã™ | | å§‹ã‚ã‚‹ | ã§ã¯ã€XXXã®ä»¶ã§ã™ãŒ | | çŸ¥ã‚‰ã›ã‚‹ | æ¬¡å›žã¯å…ˆç”Ÿã‚’ãŠè¿Žãˆã—ã¦ä¸‹è¨˜ã®é€šã‚ŠãŠé£Ÿäº‹ã‚’ã™ã‚‹ã“ã¨ã«ã„ãŸã—ã¾ã—ãŸ | | ãŠé¡˜ã„ | ã”æ¤œè¨Žã„ãŸã ãã¾ã™ã‚ˆã†ãŠé¡˜ã„ã„ãŸã—ã¾ã™ï¼ãŠç›®é€šã—ãã ã•ã„ã¾ã™ã‚ˆã†ãŠé¡˜ã„ç”³ã—ä¸Šã’ã¾ã™ | | è‡ªåˆ†ã®å¸Œæœ› | ãŠç›®ã«ã‹ã‹ã‚ŠãŸã„ã¨å­˜ã˜ã¾ã™ï¼ã‚†ã£ãã‚ŠãŠè©±ã‚’ä¼ºã„ãŸã„ã¨å­˜ã˜ã¾ã™ï¼ä¸€åº¦ãŠã„ã§ã„ãŸã ã‘ãŸã‚‰ã¨å­˜ã˜ã¾ã™ | | çµ‚ã‚ã‚Š | ãŠå¾…ã¡ã—ã¦ãŠã‚Šã¾ã™ï¼ã‚ˆã‚ã—ããŠé¡˜ã„ã„ãŸã—ã¾ã™ï¼å–ã‚Šæ€¥ãŽãŠè¿”äº‹ç”³ã—ä¸Šã’ã¾ã™ | | ã‚‚ã¨ã‚ã‚‹ | ä»¥ä¸Šã€ã”æ¡ˆå†…ï¼ã”æ‹›å¾… ç”³ã—ä¸Šã’ã¾ã™ | | ä»˜ã‘åŠ ãˆã‚‹ | ãªãŠã€ | ä¸€äº›ä¸€äº›ç‰¹å®šè¯´æ³•å®¶äººç§°å‘¼ æˆ‘ ä»– æ™®é€š ä»– æ•¬è¯­ çˆ¶ ã¡ã¡ ãŠçˆ¶ã•ã‚“ ãŠçˆ¶æ§˜ æ¯ ã¯ã¯ ãŠæ¯ã•ã‚“ ãŠæ¯æ§˜ å…„ ã‚ã« ãŠå…„ã•ã‚“ ãŠå…„æ§˜ å§‰ ã‚ã­ ãŠå§‰ã•ã‚“ ãŠå§‰æ§˜ å¼Ÿ ãŠã¨ã†ã¨ å¼Ÿã•ã‚“ å¼Ÿæ§˜ å¦¹ ã„ã‚‚ã†ã¨ å¦¹ã•ã‚“ å¦¹æ§˜ å¤«ï¼ˆãŠã£ã¨ï¼‰ï¼æ—¦é‚£ï¼ä¸»äºº ã”ä¸»äºº ã”ä¸»äººæ§˜ å¦»ï¼ˆã¤ã¾ï¼‰ï¼å®¶å†…ï¼ˆã‹ãªã„ï¼‰ å¥¥ã•ã‚“ å¥¥æ§˜ å­ã©ã‚‚ ãŠå­ã•ã‚“ ãŠå­æ§˜ æ¯å­ æ¯å­ã•ã‚“ ã”å­æ¯ï¼ˆã—ããï¼‰ å¨˜ å¨˜ã•ã‚“ ãŠå¬¢æ§˜ äººç§° ã§ã™ã¾ã™ æ•¬èªž å‹é” ã‚ãŸã— ã‚ãŸãã— ã‚ãŸã—ï¼åƒ•ï¼ä¿º ã‚ãŸã—ãŸã¡ ã‚ãŸãã—ãŸã¡ ã‚ãŸã—ãŸã¡ï¼åƒ•ãŸã¡ï¼ä¿ºãŸã¡ çš†ã•ã‚“ çš†æ§˜ ã¿ã‚“ãª ãŠå®¢ã•ã‚“ ãŠå®¢æ§˜ å®¢ å‹äºº ã”å‹äºº å‹é” ã‚ã®äºº ã‚ã®æ–¹ ã‚ã„ã¤ï¼å½¼ï¼å½¼å¥³ ãŠåº—ã®äºº ãŠåº—ã®æ–¹ åº—å“¡ ä¿‚ã®äºº ä¿‚ã®æ–¹ ä¿‚ é§…å“¡ã•ã‚“ é§…å“¡ã•ã‚“ é§…å“¡ ã‚¢ãƒ¡ãƒªã‚«ã®äºº ã‚¢ãƒ¡ãƒªã‚«ã®æ–¹ ã‚¢ãƒ¡ãƒªã‚«äºº å…¬å¸ï¼Œäººå‘˜ï¼Œå­¦æ ¡ç­‰ è‡ªå·±çš„ ä»–äººçš„ å¼Šç¤¾ï¼ˆã¸ã„ã—ã‚ƒï¼‰ã®XXXï¼ã†ã¡ã®XXX XXXï¼‹èŒä½ å¼Šç¤¾ï¼æˆ‘ãŒç¤¾ï¼å½“ç¤¾ å¾¡ç¤¾ï¼ˆãŠã‚“ã—ã‚ƒï¼‰ï¼è²´ç¤¾ï¼ˆãã—ã‚ƒï¼‰ æœ¬æ ¡ï¼å½“æ ¡ å¾¡æ ¡ï¼è²´æ ¡ æœ¬å­¦ï¼ˆç‰¹æŒ‡å¤§å­¦ï¼‰ å¾¡å­¦ï¼è²´å­¦ å¸¸ç”¨ ãŠï¼ã” è¯ åŠ¨è¯ ãŠ ãŠé›»è©±ã—ã¾ã™ ãŠç´„æŸã—ã¾ã™ ãŠæŒã¡ã—ã¾ã™ ã” å ±å‘Š ç´¹ä»‹ é æ…® å½¢å®¹è¯ ãŠ ãŠå¥½ãï¼ãŠå«Œã„ ãŠå…ƒæ°—ï¼ãŠç–²ã‚Œï¼ãŠæ€¥ãŽ ã” ã”å¥åº·ï¼ã”ç„¡ç† ã”æº€è¶³ï¼ã”ä¸å¿« åè¯ ãŠ ãŠé›»è©±ï¼ãŠå†™çœŸ ãŠè¿”äº‹ï¼ãŠé£Ÿäº‹ ãŠæ‰‹ç´™ï¼ãŠè·ç‰©ï¼ãŠæŒã¡ç‰© ãŠåå‰ï¼ãŠæ°—æŒã¡ ãŠé‡‘ï¼ãŠç¤¼ï¼ãŠåœŸç”£ ãŠå¼å½“ï¼ãŠé¢¨å‘‚ ãŠé£²ã¿ç‰©ï¼ãŠå“ç‰© ãŠæ‰‹æ´—ã„ ãŠè¦‹èˆžã„ï¼ãŠç¥ˆã‚Šï¼ãŠç¥ã„ ã” ã”å®¶æ—ï¼ã”å¤«å©¦ï¼ã”é•·ç”· ã”ä½æ‰€ï¼ã”å°é‘‘ï¼ã”äºˆç®—ï¼ã”æ„å¿—ï¼ã”æœ¬ ã”ç½²åï¼ã”æ³¨æ–‡ï¼ã”è¨ˆç”» ã”äºˆç´„ï¼ã”æ‹›å¾… ã”å‡ºå¸­ï¼ã”å‚åŠ ï¼ã”ç™»éŒ²ï¼ã”å…¥é‡‘ ã”å…¥å­¦ï¼ã”å‡ºç™º ã”çµå©šï¼ã”é–¢ä¿‚ æ—¥å­çš„è¯´æ³• æ™®é€š æ•¬è¯­ ä»Šæ—¥ æœ¬æ—¥ æ˜¨æ—¥ æ˜¨æ—¥ ã•ãã˜ã¤ ã‚ã—ãŸ ã‚ã™ï¼ã¿ã‚‡ã†ã«ã¡ ãŠã¨ã¨ã„ ã„ã£ã•ãã˜ã¤ ã‚ã•ã£ã¦ ã¿ã‚‡ã†ã”ã«ã¡ ä»Šå¹´ æœ¬å¹´ åŽ»å¹´ æ˜¨å¹´ï¼ˆã•ãã­ã‚“ï¼‰ ãŠã¨ã¨ã— ä¸€æ˜¨å¹´ ã„ã£ã•ãã­ã‚“ 1ãƒ¶æœˆ ã²ã¨æœˆ å‰¯è¯çš„è½¬æ¢ æ™®é€š æ•¬è¯­ ã„ã¾ ãŸã ã„ã¾ ã•ã£ã å…ˆã»ã© å¾Œã§ å¾Œã»ã©ï¼ˆã®ã¡ã»ã©ï¼‰ ã“ã®é–“ å…ˆæ—¥ ãã®æ—¥ å½“æ—¥ ã‚‚ã†ã™ã é–“ã‚‚ãªã èµ¶ç´§å¼€å§‹ ã•ã£ãã æ€¥ã„ã¦ï¼ã™ãã« æ—©æ€¥ã«ï¼ˆã•ã£ãã‚…ã†ï¼‰ï¼è‡³æ€¥ï¼ˆã—ãã‚…ã†ï¼‰ ã™ãã« ãŸã ã¡ã« å‰ã« ã‚ã‚‰ã‹ã˜ã‚ ã€œãŸã‚‰ã™ãã« ã€œæ¬¡ç¬¬ã€ æ®‹å¿µ ã‚ã„ã«ã ãœã² ä¸å¯§ã« ä¸é‡ã« ã ã„ãŸã„ æ¦‚ã­ï¼ˆãŠãŠã‚€ã­ï¼‰ å°‘ã— å°‘ã€…ï¼ˆã—ã‚‡ã†ã—ã‚‡ã†ï¼‰ åŠ¨è¯çš„è½¬æ¢ æ™®é€š æ•¬è¯­ ç”¨æ³• å—ã‘å–ã‚‹ï¼ã‚‚ã‚‰ã† å—é ˜ã™ã‚‹ é…é€ç‰© å—ã‘å–ã‚‹ï¼ã‚‚ã‚‰ã† æ‹å—ã™ã‚‹ é…é€ é‚®ä»¶ ä¿¡ æŸ»åŽã™ã‚‹ ç¡®è®¤å†…å®¹ä¹‹åŽæŸ¥æ”¶ï¼Œè‡ªå·±ä¸ç”¨ ç´ã‚ã‚‹ èµ å“ï¼Œè´µé‡ç‰©å“ç­‰ é‡‘ã‚’æ‰•ã† ç´ã‚ã‚‹ ç¨Žé‡‘ é€ã‚‹ é€ä»˜ã™ã‚‹ é‚®å¯„å“ï¼Œé‚®ä»¶ ç™ºé€ã™ã‚‹ é…è¾¾ç‰© å…¥é‡‘ã™ã‚‹ é“¶è¡Œæ±‡æ¬¾ æºå°ã™ã‚‹ ç›–ç«  ä½¿ã† ä½¿ç”¨ã™ã‚‹ ç‰©å“ åˆ©ç”¨ã™ã‚‹ ç‰©å“ï¼ŒæœåŠ¡ ã»ã—ã„ï¼ã—ãŸã„ å¸Œæœ›ã™ã‚‹ å£²ã‚‹ è²©å£²ã™ã‚‹ å£²ã‚Šå‡ºã™ ç™ºå£²ã™ã‚‹ è²·ã† è³¼å…¥ã™ã‚‹ æ±‚ã‚ã‚‹ï¼ˆã‚‚ã¨ã‚ã‚‹ï¼‰ èª­ã‚€ æ‹èª­ã™ã‚‹ é‚®ä»¶ï¼Œä¿¡ èžã æ‹è´ã™ã‚‹ æ„è§ï¼Œæ¼”è®² æ›¸ã è¨˜å…¥ã™ã‚‹ ç”³è¯·ç”¨çº¸ æ›¸ã è¨˜ã™ï¼ˆã—ã‚‹ã™ï¼‰ çŸ¥ã‚‰ã›ã‚‹ é€šçŸ¥ã™ã‚‹ é ¼ã‚€ ä¾é ¼ã™ã‚‹ å—ã‘ã‚‹ æ‰¿ã‚‹ è€ƒãˆã‚‹ æ¤œè¨Žã™ã‚‹ ã‚ã‹ã‚‹ æ‰¿çŸ¥ã™ã‚‹ï¼ç†è§£ã™ã‚‹ï¼äº†æ‰¿ã™ã‚‹ ã‚ãã‚‰ã‚ã‚‹ æ–­å¿µã™ã‚‹ å¿˜ã‚Œã‚‹ å¤±å¿µã™ã‚‹ å¸°å›½ã™ã‚‹ å‡ºç¤¾ã™ã‚‹ï¼å‡ºå‹¤ã™ã‚‹ æ¥è‡ªå·±çš„å…¬å¸ é€€ç¤¾ã™ã‚‹ï¼é€€å‹¤ã™ã‚‹ ä¸‹ç­å›žå®¶ å¤±ç¤¼ã™ã‚‹ å¸°å®…ã™ã‚‹ é€€ç¤¾ï¼é€€è·ã™ã‚‹ è¾žèŒ é–‹åº—ã™ã‚‹ é–‰åº—ã™ã‚‹ æ¥åº—ã™ã‚‹ æ¥å ´ã™ã‚‹ åº§ã‚‹ ã‹ã‘ã‚‹]]></content>
      <categories>
        <category>æ—¥è¯­</category>
        <category>æ•¬è¯­</category>
      </categories>
      <tags>
        <tag>æ•¬è¯­</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ•°æ®ç»“æž„ä¹‹Tree]]></title>
    <url>%2F2019%2F09%2F14%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84Tree%2F</url>
    <content type="text"><![CDATA[åŸºæœ¬ä½œç”¨ æ ‘æ˜¯å›¾çš„ä¸€ç§ï¼Œä½†æ˜¯ä¸æ˜¯é¦–å°¾è¿žåœ¨ä¸€èµ·çš„ æ ‘çš„å…¶ä¸­ä¸€ç±»æ˜¯ä»Ž self-balanced tree BSTæ¼”å˜å‡ºæ¥çš„ï¼ŒåŒ…æ‹¬çº¢é»‘æ ‘ï¼ŒAVLï¼ŒSplayï¼ŒTreapç­‰ç­‰ï¼ˆç»å¸¸åœ¨é¢è¯•å‡ºçŽ°ä½†æ˜¯å®žé™…ä¸å¸¸ç”¨ï¼‰ å¦ä¸€ç§å¤§ç±»æ˜¯ Trieï¼ˆå­—å…¸æ ‘ï¼‰ï¼Œèƒ½ä¿è¯å­—å…¸æŽ’åºã€‚å‰ç¼€æœç´¢ï¼Œæ­£åˆ™åŒ¹é…ï¼Œæ•°æ®åŽ‹ç¼©ï¼Œæž„å»ºç´¢å¼•ç­‰ç­‰ç”¨å¤„ äºŒå‰æ ‘ï¼Œæœ€åŸºç¡€çš„ç»“æž„å®šä¹‰ æ¯ä¸ªæ•°çš„èŠ‚ç‚¹æœ€å¤šåªæœ‰ä¸¤ä¸ªå­èŠ‚ç‚¹ å­èŠ‚ç‚¹åˆ†å·¦å³ï¼Œå¿…é¡»ä¸èƒ½é¢ å€’ åº”ç”¨çŽ¯å¢ƒ hashè¡¨ï¼Œsets æ•°æ®åº“ï¼Œä¼˜å…ˆé˜Ÿåˆ— LDAPæŸ¥æ‰¾ä¿¡æ¯ï¼Œåœ¨XML/HTMLä¸­è¿›è¡Œæœç´¢ ä¸åŒåˆ†æ”¯ï¼š full binary treeï¼šé™¤äº†å¶èŠ‚ç‚¹ï¼ˆä¹Ÿå°±æ˜¯ä¸€ä¸ªå­èŠ‚ç‚¹éƒ½æ²¡æœ‰çš„ç‚¹ï¼‰ï¼Œå…¶ä»–çš„éƒ½æœ‰ä¸¤ä¸ªå­èŠ‚ç‚¹ complete binary treeï¼šé™¤äº†æœ€åŽä¸€å±‚å¤–ï¼Œå…¶ä»–å±‚çš„èŠ‚ç‚¹éƒ½æœ‰ä¸¤ä¸ªå­èŠ‚ç‚¹ï¼Œæœ€åŽä¸€å±‚çš„å­èŠ‚ç‚¹å¿…é¡»æ˜¯å·¦å¯¹é½ perfect binary treeï¼šå½¢æˆå®Œç¾Žçš„ä¸‰è§’å½¢ BST äºŒå‰æœç´¢æ ‘å®šä¹‰ ä¸¤ä¸ªå­èŠ‚ç‚¹é‡Œé¢ï¼Œå·¦è¾¹çš„å¿…é¡»å°äºŽçˆ¶èŠ‚ç‚¹ï¼Œå³è¾¹çš„å¿…é¡»å¤§äºŽçˆ¶èŠ‚ç‚¹ æ“ä½œ æ’å…¥ï¼š å¦‚æžœæ²¡æœ‰ä»»ä½•ç‚¹ï¼Œä½œä¸ºroot å¦‚æžœå¤§æ”¾åˆ°å³è¾¹çš„å­æ ‘ï¼Œå°æ”¾åˆ°å·¦è¾¹çš„å­æ ‘ é‡å¤2ç›´åˆ°æ‰¾åˆ°ç©ºä½ åˆ é™¤ï¼š åˆ é™¤å¶èŠ‚ç‚¹ï¼šæ–­æŽ‰è¿™ä¸ªç‚¹å’Œçˆ¶èŠ‚ç‚¹çš„è”ç³» åˆ é™¤åªæœ‰ä¸€ä¸ªå­èŠ‚ç‚¹çš„ç‚¹ï¼šæŠŠçˆ¶èŠ‚ç‚¹å¯¹å¾…åˆ é™¤ç‚¹çš„referenceæ”¹ä¸ºçˆ¶èŠ‚ç‚¹å¯¹å¾…åˆ é™¤ç‚¹å­èŠ‚ç‚¹çš„reference ä¸¤ä¸ªå­èŠ‚ç‚¹çš„ç‚¹ï¼šå·¦èŠ‚ç‚¹ä¸åŠ¨ï¼Œå³è¾¹çš„æ¢åˆ°çˆ¶èŠ‚ç‚¹çš„ä½ç½®ä¸Š/å³èŠ‚ç‚¹ä¸åŒï¼Œå·¦èŠ‚ç‚¹æ¢åˆ°çˆ¶èŠ‚ç‚¹ åˆ é™¤rootï¼šéœ€è¦æ›´æ”¹å¯¹rootçš„reference éåŽ† é¡ºåºï¼šå·¦-&gt; ä¸­ -&gt; å³ ååºï¼šå·¦ -&gt; å³ -&gt; ä¸­ DFSï¼šä¸­ -&gt; å·¦ -&gt; å³ å¹³è¡¡äºŒå‰æ ‘ AVLæ ‘ å·¦å³ä¸¤ä¸ªå­æ ‘çš„é«˜åº¦å·®ä¸è¶…è¿‡1 ä¸”å­æ ‘æœ¬èº«ä¹Ÿæ˜¯å¹³è¡¡æ ‘ åœ¨æž„å»ºå¹³è¡¡æ ‘çš„æ—¶å€™ç¡®ä¿ä»–ä»¬å¹³è¡¡ï¼Œä»Žè€Œå¯¼è‡´æœ€å·®çš„æ—¶é—´å¤æ‚åº¦ä¹Ÿæ˜¯ logN è™½ç„¶åœ¨æ’å…¥æˆ–è€…åˆ é™¤çš„æ—¶å€™ï¼Œå¯èƒ½ä¼šåœ¨æ—‹è½¬ä¸ŠèŠ±è´¹æ—¶é—´ï¼Œä½†æ˜¯æ•´ä½“æ€§èƒ½æ›´åŠ ç¨³å®š æ—‹è½¬ å¯¹äºŽéœ€è¦æ—‹è½¬çš„æƒ…å†µæ¥è¯´ï¼Œä¸€å…±æœ‰å››ç§åŸºæœ¬çŠ¶å†µ å¯¹äºŽå·¦å·¦æˆ–è€…å³å³ï¼šä½†æ—‹è½¬ å¯¹äºŽå·¦å³æˆ–è€…å³å·¦ï¼šåŒæ—‹è½¬ çº¢é»‘æ ‘ èŠ‚ç‚¹æ˜¯çº¢è‰²æˆ–é»‘è‰² å¶èŠ‚ç‚¹éƒ½æ˜¯é»‘è‰²çš„ rootæ˜¯é»‘è‰²çš„ æ¯ä¸ªçº¢èŠ‚ç‚¹å¿…é¡»æœ‰ä¸¤ä¸ªé»‘å­èŠ‚ç‚¹ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸èƒ½è·¯å¾„ä¸Šæœ‰ä¸¤ä¸ªè¿žç»­çš„çº¢è‰² ä»Žä»»ä¸€èŠ‚ç‚¹åˆ°å…¶æ¯ä¸ªå¶å­çš„æ‰€æœ‰ç®€å•è·¯å¾„éƒ½åŒ…å«ç›¸åŒæ•°ç›®çš„é»‘è‰²èŠ‚ç‚¹ Bæ ‘å®šä¹‰ ç”¨æ¥å¤„ç†æŽ’åºåŽçš„æ•°æ®ï¼ŒæŸ¥æ‰¾ï¼Œæ’å…¥ï¼Œåˆ é™¤ï¼Œå¾ªåºå­˜å–éƒ½åœ¨å¯¹æ•°æ—¶é—´å®Œæˆ å¯¹äºŽæ™®é€šçš„äºŒå‰æ ‘ï¼Œå¯ä»¥æœ‰å¤šäºŽä¸¤ä¸ªçš„èŠ‚ç‚¹ ä¼˜åŒ–å¤§å—æ•°æ®çš„è¯»å†™æ“ä½œï¼ŒåŠ å¿«å­˜å–é€Ÿåº¦ åœ¨æž„å»ºçš„æ—¶å€™ï¼Œæ¯ä¸€ä¸ªç‚¹çš„å­˜å‚¨æ•°é‡æ˜¯æœ‰é™çš„ï¼Œè¶…è¿‡ä¸Šé™çš„æ—¶å€™ï¼Œæœ¬èŠ‚ç‚¹åˆ†åˆ«æˆä¸‰éƒ¨åˆ†ï¼Œä¸€ä¸ªå¾€ä¸Šç§»åŠ¨ï¼Œå¦å¤–ä¸¤ä¸ªåˆ†å¼€B+æ ‘ åªæœ‰è¾¾åˆ°å¶èŠ‚ç‚¹æ‰ç®—å‘½ä¸­ï¼ŒBæ ‘å¯ä»¥åœ¨éžå¶å‘½ä¸­ æ›´é€‚åˆæ–‡ä»¶ç´¢å¼•ç³»ç»Ÿ B * æ ‘ èŠ‚ç‚¹åˆ©ç”¨çŽ‡ä»Ž 1/2å˜æˆäº† 2/3 Trieæ ‘ å­—å…¸æ ‘ hashæ ‘çš„å˜ç§ï¼Œä¿å­˜å¤§é‡å­—ç¬¦ä¸² åˆ©ç”¨å…¬å…±å‰ç¼€å‡å°‘æŸ¥æ‰¾æ—¶é—´ ç‰¹ç‚¹ æ ¹èŠ‚ç‚¹ä¸åŒ…æ‹¬å­—ç¬¦ï¼Œé™¤äº†æ ¹èŠ‚ç‚¹éƒ½åªåŒ…å«ä¸€ä¸ªå­—ç¬¦ ä»Žæ ¹èŠ‚ç‚¹åˆ°æŸä¸€èŠ‚ç‚¹ï¼Œä¸€è·¯è¿žè¿‡åŽ»å°±æ˜¯ç›¸å…³çš„å­—ç¬¦ä¸² æ¯ä¸ªèŠ‚ç‚¹çš„å­èŠ‚ç‚¹çš„å­—ç¬¦éƒ½ä¸ç›¸åŒ å‚è€ƒæ¥æº [Data Structure] æ•°æ®ç»“æž„ä¸­å„ç§æ ‘ åˆå­¦è€…åº”è¯¥äº†è§£çš„æ•°æ®ç»“æž„ï¼š Tree]]></content>
      <categories>
        <category>æ•°æ®ç»“æž„</category>
        <category>æ ‘</category>
      </categories>
      <tags>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unityçš„shader]]></title>
    <url>%2F2019%2F09%2F14%2FUnity%E7%9A%84shader%2F</url>
    <content type="text"><![CDATA[å‚è€ƒæ¥æºè¿™é‡Œ å®šä¹‰ shaderï¼Œç€è‰²å™¨ï¼Œæ˜¯ä¸€æ®µè´Ÿè´£å°†è¾“å…¥çš„meshç”¨æŒ‡å®šçš„æ–¹å¼å’Œè¾“å…¥çš„è´´å›¾ï¼Œé¢œè‰²ç­‰ä½œç”¨ï¼Œç„¶åŽè¾“å‡º è¾“å…¥è´´å›¾æˆ–è€…é¢œè‰²ï¼Œä»¥åŠå¯¹åº”çš„shaderï¼Œå°±å¯ä»¥å¾—åˆ°ä¸€ä¸ªmaterialï¼Œç„¶åŽå°†å¯ä»¥æŠŠææ–™ç»™åˆ°rendereræ¥è¿›è¡Œè¾“å‡º shaderå¦‚æžœæ˜¯è‡ªå·±æ¥å†™çš„è¯ï¼Œéœ€è¦æ–°åˆ›å»ºä¸€ä¸ªshaderæ–‡ä»¶ æ¯”å¦‚åœ¨è¿™é‡Œè€å¸ˆå†™çš„omniProcamçš„æŠ•å½±çš„shaderï¼Œé‡Œé¢çš„å‚æ•°å°±åŒ…æ‹¬äº†fisheyeç›¸æœºçš„å‚æ•°ç­‰ç­‰ã€‚è¿™éƒ¨åˆ†çš„å‚æ•°ä¹Ÿå°±æ˜¯shaderçš„è¾“å…¥ï¼Œå®šä¹‰äº†è¿™ä¸ªshaderéœ€è¦çš„å±žæ€§ éœ€è¦åœ¨é‡Œé¢è®¾å®šä¸åŒçš„subshaderï¼Œè¿™éƒ¨åˆ†æ˜¯ä»£ç çš„ä¸»é¢˜ï¼Œåœ¨æ¯ä¸€ä¸ªé‡Œé¢åŒ…å«ä¸åŒçš„passã€‚ç„¶åŽè¿è¡Œçš„æ—¶å€™ä¼šä»Žæœ€ä¼˜å…ˆçš„ç€è‰²å™¨å¼€å§‹æ‰¾ã€‚åœ¨shaderçš„æœ€åŽéœ€è¦ä¸€ä¸ªfallbackï¼Œä¹Ÿå°±æ˜¯è¯´æ‰€æœ‰çš„subshaderéƒ½ä¸èƒ½è¿è¡Œçš„æ—¶å€™ï¼Œéœ€è¦ä¸€ä¸ªè¿”å›žæƒ…å†µ ä»£ç è®²è§£1234567891011121314151617181920212223242526Shader &quot;Custom/Diffuse Texture&quot; &#123; Properties &#123; _MainTex (&quot;Base (RGB)&quot;, 2D) = &quot;white&quot; &#123;&#125; &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 200 CGPROGRAM #pragma surface surf Lambert sampler2D _MainTex; struct Input &#123; float2 uv_MainTex; &#125;; void surf (Input IN, inout SurfaceOutput o) &#123; half4 c = tex2D (_MainTex, IN.uv_MainTex); o.Albedo = c.rgb; o.Alpha = c.a; &#125; ENDCG &#125; FallBack &quot;Diffuse&quot;&#125; å±žæ€§ Propertiesé‡Œé¢å®šä¹‰äº†è¿™ä¸ªshaderçš„å±žæ€§ï¼Œè¿™é‡Œé¢çš„æ‰€æœ‰å±žæ€§å°†ä½œä¸ºinputæä¾›ç»™å­ç€è‰²å™¨ _Name(&quot;Display Name&quot;, type) = defaultValue[{options}] æ ¼å¼ _å±žæ€§å â€œdisplay nameâ€ æ˜¾ç¤ºç»™ç”¨æˆ·çš„å¯è¯»çš„åå­— typeå±žæ€§çš„ç±»åž‹ é¢œè‰²ï¼ŒRGBA 2Dï¼Œ2çš„æŒ‡æ•°å¤§å°çš„è´´å›¾ rectï¼Œéž2çš„æŒ‡æ•°å¤§å°çš„è´´å›¾ cubeï¼Œç«‹æ–¹ä½“çº¹ç† rangeï¼Œä¸€ä¸ªèŒƒå›´é‡Œé¢çš„æ•° floatï¼Œä»»æ„ä¸€ä¸ªæµ®ç‚¹æ•° å±žæ€§çš„é»˜è®¤å€¼ï¼Œæ¯”å¦‚é¢œè‰²å¯ä»¥è®¾å®šæˆâ€œwhiteâ€ opinioné¡¹ï¼Œè‡³å°‘éœ€è¦åœ¨è´´å›¾åŽé¢åŠ ä¸Šç©ºç™½çš„èŠ±æ‹¬å·ï¼Œåªå’Œ2d rectæˆ–è€…cubeæœ‰å…³ç³» subshader tagï¼šæ¯”å¦‚æ¸²æŸ“ç±»åž‹ï¼Œå¦‚æžœæ˜¯éžé€æ˜Žçš„ç‰©ä½“è¦å†™åœ¨opaqueé‡Œé¢ï¼Œé€æ˜Žçš„å†™åœ¨transparenté‡Œé¢ LODï¼šlevel of detail CGPROGRAMï¼Œå¼€å§‹çš„æ ‡è®°ï¼Œä»Žè¿™é‡Œå¼€å§‹æ˜¯ä¸€æ®µCGç¨‹åºã€‚å’Œæœ€åŽçš„ENDCGæ˜¯å¯¹åº”çš„ #pragma surface surf Lambertä¸€ä¸ªç¼–è¯‘æŒ‡ä»¤ï¼Œå£°æ˜Žäº†è¦å†™ä¸€ä¸ªè¡¨é¢çš„shaderï¼ŒæŒ‡å®šäº†å…‰ç…§æ¨¡åž‹ sampler2Då¯¹è´´å›¾è¿›è¡Œæ“ä½œï¼Œ2dçš„è´´å›¾æ¨¡åž‹ã€‚è™½ç„¶åœ¨ä¹‹å‰çš„å±žæ€§é‡Œé¢å£°æ˜Žè¿‡ä¸€æ¬¡ï¼Œä½†æ˜¯å› ä¸ºè¿™é‡Œé¢æ˜¯cgä»£ç ï¼Œè¿˜æ˜¯éœ€è¦é‡æ–°å£°æ˜Žä¸€æ¬¡ éœ€è¦åœ¨structé‡Œé¢å®šä¹‰å‡ºæ¥éœ€è¦è¾“å…¥å’Œè¾“å‡ºçš„æ•°æ®ç±»åž‹ uvï¼šuv mappingæŒ‡çš„å°±æ˜¯æŠŠä¸€ä¸ª2dè´´å›¾ä¸Šé¢çš„ç‚¹æŒ‰ç…§ä¸€å®šè§„åˆ™æ˜ å°„åˆ°3dæ¨¡åž‹ä¸Šã€‚å¦‚æžœåœ¨è´´å›¾å˜é‡å‰è¾¹åŠ ä¸Šuv.uv_MainTexæŒ‡çš„å°±æ˜¯æå–è¿™ä¸ªå˜é‡çš„uvå€¼ï¼Œä¹Ÿå°±æ˜¯è¯´äºŒç»´åæ ‡ surfå‡½æ•°ï¼Œsurfæ˜¯ä¹‹å‰å®šä¹‰çš„å…‰ç…§æ¨¡åž‹ï¼Œæœ‰ä¸¤ä¸ªå‚æ•° Iné‡Œé¢çš„å†…å®¹æ˜¯uvå€¼ï¼Œä¹Ÿå°±æ˜¯è¯´æ¯æ¬¡éƒ½ä¼šè°ƒç”¨è´´å›¾ä¸Šé¢çš„åæ ‡ç‚¹æ‰è®¡ç®—è¾“å‡º inoutæ˜¯è¾“å‡ºå€¼]]></content>
      <categories>
        <category>Unity</category>
        <category>å…¥é—¨</category>
      </categories>
      <tags>
        <tag>shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[åå¤§ç»å…¸æŽ’åº]]></title>
    <url>%2F2019%2F09%2F03%2F%E5%8D%81%E5%A4%A7%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[å‚è€ƒå‡ºè‡ªï¼šäº”åˆ†é’Ÿå­¦ç®—æ³• æ—¶é—´å¤æ‚åº¦ æœ€å¥½æƒ…å†µ æœ€åæƒ…å†µ ç©ºé—´å¤æ‚åº¦: éœ€ä¸éœ€è¦å¼€è¾Ÿæ–°çš„ç©ºé—´ æŽ’åºæ–¹å¼ï¼šin-placeè¿˜æ˜¯ä¸æ˜¯in - place æŽ’åºç¨³å®šæ€§: ä¹Ÿå°±æ˜¯ä¹‹å‰é¡ºåºçš„ä¸œè¥¿åœ¨æŽ’åºä¹‹åŽæ˜¯å¦è¿˜é¡ºåº å†’æ³¡æŽ’åº å‰é¢ä¸€ä¸ªæ•°å’ŒåŽé¢ä¸€ä¸ªæ¯”ï¼Œå¦‚æžœå‰é¢çš„æ•°æ¯”åŽé¢çš„å¤§(æˆ–è€…å°)ï¼Œå°±äº¤æ¢ä»–ä»¬ä¸¤ä¸ª è¿™æ ·äº¤æ¢ä¸€æ¬¡ä¹‹åŽçš„æœ€åŽä¸€ä¸ªæ•°å°±æ˜¯æ‰€æœ‰æ•°å­—é‡Œé¢çš„æœ€å¤§æ•° ä¹Ÿå°±ç›¸å½“äºŽæœ€å¤§çš„æ•°åƒå†’æ³¡ä¸€æ ·å†’å‡ºæ¥äº†ï¼Œç¬¬ä¸€è½®è¿‡åŽï¼Œç¬¬äºŒè½®å¯ä»¥ç›´æŽ¥å†’å€’æ•°ç¬¬äºŒä¸ªæ•°ï¼Œä¹Ÿå°±æ˜¯è¯´æ¯ä¸€è½®çš„å†…å¾ªçŽ¯æ¬¡æ•°å¯ä»¥é€æ¸å‡å°‘ éœ€è¦é‡å¤næ¬¡ï¼ˆä½†æ˜¯æ¯æ¬¡å¯¹è¶Šæ¥è¶Šå°‘çš„æ•°å­—è¿›è¡Œä¸Šè¿°æ“ä½œï¼‰ï¼Œä»¥ç¡®ä¿æ‰€æœ‰çš„äº¤æ¢éƒ½å·²ç»å®Œæ¯•äº†ã€‚ å¢žåŠ äº†ä¸€ä¸ªflagçš„åˆ¤æ–­ï¼Œå¦‚æžœåœ¨ä¸€è½®é‡Œé¢æ²¡æœ‰ä»»ä½•äº¤æ¢äº§ç”Ÿï¼Œé‚£å°±è¯´æ˜Žæ‰€æœ‰çš„å…ƒç´ éƒ½å·²ç»æŽ’åºå®Œæ¯•äº†ï¼ˆå› ä¸ºå¦‚æžœè¿˜æœ‰æ•°å­—å¾€ä¸Šå†’å¿…ç„¶ä¼šåœ¨å‰é¢æœ‰äº¤æ¢ è¿™æ ·å¦‚æžœæ˜¯æ­£åºæŽ’åˆ—çš„è¯ï¼Œå¯ä»¥ç›´æŽ¥è·³å‡ºå¾ªçŽ¯ï¼Œä¸ç”¨è¿›è¡Œæ¯”è¾ƒï¼Œæ—¶é—´å¤æ‚åº¦æ˜¯n123456789101112131415def bubbleSort(num): n = len(num) for j in range(1, n): flag = True # å¦‚æžœåœ¨è¿™è½®æ²¡æœ‰ä»»ä½•äº¤æ¢ï¼Œå°±å¯ä»¥è¯´æ˜ŽæŽ’åºå·²ç»å®Œæˆäº† for i in range(n - j): if num[i] &gt; num[i + 1]: temp = num[i] num[i] = num[i + 1] num[i + 1] = temp flag = False if flag is True: break return num æ—¶é—´å¤æ‚åº¦ï¼š å½“æ­£åºæŽ’åˆ—çš„æ—¶å€™ï¼Œå› ä¸ºå¯ä»¥ç›´æŽ¥è·³å‡ºå¾ªçŽ¯ï¼Œæ‰€ä»¥åªéœ€è¦éåŽ†ä¸€æ¬¡æ‰€æœ‰çš„æ•°ä¿è¯ä»–ä»¬æŽ’åˆ—æ­£å¸¸ï¼Œæ‰€ä»¥æ—¶é—´å¤æ‚åº¦æ˜¯n å½“å€’åºæŽ’åˆ—çš„æ—¶å€™ï¼Œéœ€è¦æŠŠæ‰€æœ‰éƒ½ç§»åŠ¨ä¸€éï¼Œæ‰€ä»¥æ—¶é—´å¤æ‚åº¦æ˜¯ n ^ 2 å¹³å‡çš„å¤æ‚åº¦æ˜¯næ–¹ ç©ºé—´å¤æ‚åº¦ï¼š å› ä¸ºäº¤æ¢åªéœ€è¦ä¸€ä¸ªé¢å¤–çš„tempæ¥å‚¨å­˜ä¸´æ—¶å˜é‡ï¼Œç©ºé—´å¤æ‚åº¦æ˜¯1 in-placeï¼šæ˜¯çš„ ç¨³å®šæ€§ï¼šç¨³å®šï¼Œå› ä¸ºä¸€æ¬¡æ¢è¿‡æ¥çš„ä¸œè¥¿å°±ä¸åŠ¨äº†ï¼Œåœ¨åˆ¤æ–­å¤§å°çš„æ—¶å€™ä¹Ÿæ˜¯åˆ¤æ–­çš„å¤§äºŽè€Œä¸æ˜¯å¤§äºŽç­‰äºŽï¼Œä¹Ÿå°±æ˜¯è¯´å‰é¢æ¢åˆ°åŽé¢çš„å¤§æ•°æ°¸è¿œä¼šåœ¨åŽé¢çš„æ•°çš„å‰é¢ æ¯”å¦‚[0, 8, 1, 8, 2]ã€‚é¦–å…ˆä¼šæŠŠç¬¬ä¸€ä¸ª8æ¢åˆ°ç¬¬äºŒä¸ª8çš„å‰é¢ï¼Œå› ä¸ºåˆ¤æ–­æ¡ä»¶æ²¡æœ‰ç­‰äºŽï¼Œæ‰€ä»¥è¶Šä¸è¿‡åŽ»ã€‚ é€‰æ‹©æŽ’åº ä»Žæ‰€æœ‰å…ƒç´ ä¸­æ‰¾åˆ°æœ€å°ï¼ˆæˆ–è€…æœ€å¤§ï¼‰å…ƒç´ ï¼Œç„¶åŽæ”¾åˆ°æ•°ç»„çš„ç¬¬ä¸€ä¸ªï¼ˆä¹Ÿå°±æ˜¯å’Œæ•°ç»„çš„ç¬¬ä¸€ä¸ªäº¤æ¢ä½ç½®ï¼‰ï¼Œç„¶åŽè¿™ä¸ªå°±ç®—æ˜¯å›ºå®šä½äº† ç„¶åŽä»Žç¬¬äºŒä¸ªåˆ°æœ€åŽä¸€ä¸ªä¸­é€‰æ‹©çŽ°åœ¨æœ€å°çš„ï¼Œå’Œæ•°ç»„çš„ç¬¬äºŒä¸ªäº¤æ¢ä½ç½®ï¼Œå‰ä¸¤ä¸ªå°±å›ºå®šä½äº† ä»¥æ­¤ç±»æŽ¨ 12345678910111213141516def SelectSort(nums): n = len(nums) for i in range(n): Min = float("inf") index = None for j in range(i, n): if nums[j] &lt; Min: Min = nums[j] index = j if index != i: # è¿™æ ·å¯ä»¥å‡å°‘ä¸€äº›æ ¹æœ¬ä¸ç”¨äº¤æ¢çš„æƒ…å†µï¼Œä¸‹ä¸€ä¸ªä½ç½®ä¸Šæœ¬æ¥å°±æ˜¯æœ€å°çš„ temp = nums[i] nums[i] = nums[index] nums[index] = temp return nums æ—¶é—´å¤æ‚åº¦ï¼š æœ€å¥½æƒ…å†µå’Œæœ€åæƒ…å†µéƒ½ä¸èƒ½é¿å…èµ°ä¸¤ä¸ªå¾ªçŽ¯ï¼Œéƒ½æ˜¯n ^ 2 ç©ºé—´å¤æ‚åº¦: 1, æ¥å‚¨å­˜tempçš„å€¼å’Œæš‚æ—¶çš„æœ€å¤§å€¼çš„å˜é‡ in-placeï¼šæ˜¯çš„ï¼Œæ¢ä½ç½®å°±å¯ä»¥ï¼Œä¸éœ€è¦å•æ‹¿å‡ºæ¥ ç¨³å®šï¼š ä¸ç¨³å®šï¼Œå› ä¸ºåœ¨äº¤æ¢ä½ç½®çš„æ—¶å€™ï¼Œå¹¶ä¸çŸ¥é“çŽ°åœ¨çš„ä¸œè¥¿è¢«äº¤æ¢åˆ°å“ªé‡ŒåŽ»äº† æ¯”å¦‚ï¼š[3, 3, 0, 9]ï¼Œå½“0å’Œ3äº¤æ¢ä½ç½®çš„æ—¶å€™ï¼ŒæŠŠç¬¬ä¸€ä¸ª3äº¤æ¢åˆ°ç¬¬äºŒä¸ª3åŽé¢åŽ»äº† æ’å…¥æŽ’åº åœ¨ç¬¬1è½®ï¼Œè®¤ä¸ºç¬¬1ä¸ªå·²ç»æŽ’å¥½åºäº†ï¼Œç„¶åŽä»Žç¬¬äºŒä¸ªå¼€å§‹æ‹¿å‡ºæ¥ï¼ŒæŠŠå®ƒæ”¾åœ¨æŽ’å¥½åºçš„é‡Œé¢çš„åˆé€‚çš„ä½ç½®ä¸Š ä»Žç¬¬äºŒè½®å¼€å§‹ä¾æ¬¡ç±»æŽ¨ï¼Œæ‰€ä»¥è¿˜æ˜¯ä¸¤ä¸ªå¾ªçŽ¯ åœ¨ç¬¬iè½®é‡Œé¢ï¼Œå‰iä¸ªå…ƒç´ å·²ç»æ˜¯æŽ’å¥½åºçš„äº† åœ¨æ’å…¥çš„è¿‡ç¨‹å½“ä¸­ï¼Œéœ€è¦è€ƒè™‘å¦‚æžœæŠŠæ‰€æœ‰çš„éœ€è¦ç§»åŠ¨çš„æ•°å­—çš„åæ ‡éƒ½ç§»åŠ¨ä¸€ä½ã€‚è¿™æ—¶å€™æ¯”è¾ƒæœ‰æ•ˆçš„è€ƒè™‘æ–¹æ³•æ˜¯ä»Žæœ€å³è¾¹å¼€å§‹å¾€å·¦è¾¹ç§»åŠ¨ï¼Œåªè¦å³è¾¹çš„æ•°æ¯”çŽ°åœ¨çš„tempè¦å¤§ï¼Œè¿™ä¸€ä½ï¼ˆå®žé™…ä¸Šè¿™ä¸€ä½æŒ‡çš„æ˜¯j - 1ï¼Œå› ä¸ºjæ˜¯ç§»åŠ¨ä¹‹åŽçš„åæ ‡ï¼‰å°±éœ€è¦ç§»åŠ¨ã€‚ç§»åŠ¨ä¹‹åŽå†å‡1 åœ¨æ‰€æœ‰çš„éƒ½ç§»åŠ¨ç»“æŸä¹‹åŽï¼Œå¦‚æžœjè¿™ä¸ªä½ç½®å’Œiçš„ä½ç½®ä¸ä¸€æ ·ï¼Œå°±è¯´æ˜Žå‘ç”Ÿäº†æ’å…¥ï¼Œé‚£ä¹ˆå°±æ˜¯nums[j] = è¢«æ’å…¥çš„æ•°å­—temp 12345678910111213def InsertSort(nums): n = len(nums) for i in range(1, n): temp = nums[i] j = i while j &gt; 0 and temp &lt; nums[j - 1]: nums[j] = nums[j - 1] j -= 1 if j != i: nums[j] = temp return nums æ—¶é—´å¤æ‚åº¦ æœ€å¥½çš„æ—¶å€™ï¼Œä¸éœ€è¦æ’å…¥ï¼Œæœ€å¤§å€¼ç›´æŽ¥æ”¾åœ¨äº†å‰é¢æŽ’å¥½åºçš„æœ€å³è¾¹ï¼Œä¹Ÿå°±æ˜¯æ²¡æœ‰å†…å¾ªçŽ¯ï¼Œn æœ€å·®çš„æ—¶å€™ï¼Œååºï¼Œéœ€è¦å…¨éƒ½å¾ªçŽ¯ä¸€é n2 ç©ºé—´å¤æ‚åº¦ 1 in-place ç¨³å®šæ€§ï¼šç¨³å®šï¼Œå› ä¸ºå¦‚æžœæ˜¯[2, 0, 0, 1]ï¼Œç¬¬ä¸€ä¸ª0å…ˆæ’å…¥å˜æˆäº†[0_1, 2, 0_2, 1]ï¼Œç„¶åŽæ’å…¥ç¬¬äºŒä¸ª0çš„æ—¶å€™å› ä¸ºæ¯”è¾ƒçš„æ—¶å€™æ²¡æœ‰æ¯”ç­‰äºŽï¼Œæ‰€ä»¥ä¼šå˜æˆ[0_1, 0_2, 2, 1] å¸Œå°”æŽ’åº é€‰æ‹©ä¸€ä¸ªåºåˆ—æ¥å¯¹è¿™ä¸ªæ•°ç»„è¿›è¡ŒæŽ’åºï¼Œæ¯”å¦‚å¦‚æžœæ˜¯10ä¸ªæ•°ï¼Œå¯ä»¥æ˜¯5 2 1è¿™æ ·çš„ï¼Œæœ€åŽä¸€ä¸ªä¸€å®šæ˜¯1ï¼ˆè®¾å®šçš„å…¬å¼æ˜¯3xn + 1ä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼‰ ç„¶åŽæ ¹æ®è¿™ä¸ªåºåˆ—æŠŠæ•°ç»„åˆ†æˆè¿™ä¸ªåºåˆ—ä¸ªæ•°çš„ç»„ï¼Œå¯¹æ¯ç»„çš„æ•°å­—è¿›è¡Œæ’å…¥æŽ’åºã€‚æ¯”å¦‚ç”¨5åˆ†æˆä¸¤ä»½ï¼Œé‚£å°±è¦è¿›è¡Œ5æ¬¡ï¼Œä¸¤ä¸ªä¹‹é—´çš„æŽ’åº ä¸€å…±è¿›è¡Œçš„æŽ’åºæ¬¡æ•°æ˜¯å’Œåºåˆ—çš„ä¸ªæ•°æœ‰å…³çš„ 123456789101112131415161718def ShellSort(nums): n = len(nums) gap = 1 while gap &lt; n / 3: gap = gap * 3 + 1 # ä¸€ä¸ªç¥žå¥‡çš„é€‰æ‹©æ–¹æ³•ï¼Œä¹Ÿä¸çŸ¥é“ä¸ºä»€ä¹ˆä½†æ˜¯ç¡®å®žå¾ˆå¥½ç”¨ while gap &gt; 0: for i in range(gap, n): # è¿™é‡Œæ‰§è¡Œçš„æ˜¯æ’å…¥æŽ’åºï¼Œå’Œä¸Šé¢çš„æ’å…¥æŽ’åºä¸€æ ·ï¼Œåªä¸è¿‡æ¯æ¬¡è·³gapä¸ªäº† temp = nums[i] j = i while j &gt; 0 and temp &lt; nums[j - gap]: nums[j] = nums[j - gap] j -= gap if j != i: nums[j] = temp # ç›´æŽ¥intå°±å¯ä»¥å‘ä¸‹å–æ•´ï¼Œå› ä¸ºåŠ 1å¹¶ä¸å½±å“å–æ•´æ•ˆæžœ gap = int(gap / 3) return nums å…³äºŽå¢žé‡ï¼Œä¸åŒçš„å¢žé‡å¯¹æ—¶é—´å¤æ‚åº¦æœ‰ä¸åŒçš„å½±å“ ç›®å‰åº”ç”¨æœ€å¤šçš„æ˜¯ Knuthå¢žé‡:1,4,13,40,â€¦,(3^k - 1)/2ï¼Œä¹Ÿå°±æ˜¯ä»£ç é‡Œé¢çš„è¿™ä¸ªå¢žé‡ è¿™æ—¶å€™çš„å¤æ‚åº¦æ˜¯ N^ï¼ˆ3/2ï¼‰ æ—¶é—´å¤æ‚åº¦ï¼š æ ¹æ®ä¸åŒçš„æ­¥é•¿ä¸åŒè€Œæœ‰æ‰€å·®åˆ«ï¼Œè¿˜æœ‰çš„æ­¥é•¿è¿˜æ²¡è®¡ç®—å‡ºæ¥å¤æ‚åº¦ å¦‚æžœæ˜¯åŽŸç‰ˆçš„ï¼Œä¹Ÿå°±æ˜¯åŽŸé•¿åº¦ä¸€ç›´é™¤2çš„è¯ æœ€å¥½æ•ˆæžœï¼šnï¼Œä¹Ÿå°±æ˜¯ä¸éœ€è¦å†…å¾ªçŽ¯ æœ€çƒ‚æ•ˆæžœï¼šn^2 ç©ºé—´å¤æ‚åº¦ 1 in-place ä¸ç¨³å®šï¼Œå› ä¸ºå¾ˆæœ‰å¯èƒ½å› ä¸ºåˆ†ç»„çš„ä¸åŒæŠŠä¸¤ä¸ªæ•°çš„é¡ºåºé¢ å€’ï¼Œæ¯”å¦‚ä¸¤ç»„çš„åŽé¢éƒ½æ˜¯3ï¼Œä½†æ˜¯ç¬¬ä¸€ç»„çš„å‰ä¸€ä¸ªæ˜¯2ï¼Œç¬¬äºŒç»„çš„å‰ä¸€ä¸ªæ˜¯4ï¼Œè¿™æ ·å°±æŠŠç¬¬äºŒä¸ª3æ¢åˆ°å‰é¢åŽ»äº† å½’å¹¶æŽ’åº å½’å¹¶æŽ’åºæ˜¯åˆ†æ²»æ³•çš„ä¸€ä¸ªå…¸åž‹çš„åº”ç”¨ï¼Œå¯ä»¥æŠŠæœ‰åºçš„å­åˆ—åˆå¹¶ï¼Œç„¶åŽå¾—åˆ°æ–°çš„æœ‰åºçš„å­åˆ— æ¯”è¾ƒæ–¹æ³• é¦–å…ˆæ¯”è¾ƒä¸¤ä¸ªå­åˆ—çš„åˆå§‹å€¼a[i]å’Œb[j]ï¼ŒæŠŠæ¯”è¾ƒå°çš„é‚£ä¸ªï¼ˆæ¯”å¦‚iï¼‰æ”¾è¿›æ–°çš„list[k]é‡Œé¢ï¼Œå¹¶ä¸”è®©iå’Œkåˆ†åˆ«åŠ ä¸€ï¼Œç„¶åŽç»§ç»­æ¯”è¾ƒiå’Œjï¼Œç„¶åŽç»“æžœæ”¾è¿›ké‡Œã€‚ å¦‚æžœæœ‰ä¸€ä¸ªå­åˆ—å·²ç»å–å®Œäº†ï¼Œé‚£ä¹ˆå¯ä»¥ç›´æŽ¥æŠŠå¦ä¸€ä¸ªé‡Œé¢çš„å‰©ä½™å…ƒç´ å¤åˆ¶åˆ°æ–°çš„listçš„æœ€åŽ å› ä¸ºçŽ°åœ¨ä½¿ç”¨çš„å­åˆ—å·²ç»æ˜¯æŽ’å¥½åºçš„äº†ï¼Œæ‰€ä»¥å¯ä»¥ä½¿ç”¨è¿™ç§æ¯”è¾ƒæ–¹æ³•ã€‚åˆå§‹çŠ¶æ€è®¤ä¸ºæ¯ä¸€ä¸ªæ•°å­—éƒ½æ˜¯ä¸€ä¸ªå•ç‹¬çš„å­åˆ—ï¼Œæ‰€ä»¥å¾€ä¸Šåˆå¹¶çš„æ—¶å€™éƒ½æ˜¯æœ‰åºçš„äº† å®žçŽ°ï¼š ç”³è¯·ä¸€ä¸ªæ–°çš„ç©ºé—´ï¼Œå¤§å°æ˜¯ä¸¤ä¸ªå­åˆ—çš„å¤§å°ä¹‹å’Œ ä¸¤ä¸ªæŒ‡é’ˆåˆ†åˆ«ä»Žåˆå§‹ä½ç½®å¼€å§‹ æ ¹æ®ä¸Šé¢çš„æ–¹æ³•ç§»åŠ¨æŒ‡é’ˆ åœ¨å®žçŽ°çš„è¿‡ç¨‹ä¸­éœ€è¦ç”¨åˆ°æ‹†åˆ†å’Œåˆå¹¶ä¸¤ä¸ªæ­¥éª¤ 12345678910111213141516171819202122def MergeSort(nums): n = len(nums) if n &lt; 2: return nums middle = int(n / 2) L, R = nums[:middle], nums[middle:] return merge(MergeSort(L), MergeSort(R))def merge(L, R): M = [] i, j = 0, 0 while L and R: if L[0] &lt;= R[0]: M.append(L.pop(0)) else: M.append(R.pop(0)) while L: M.append(L.pop(0)) while R: M.append(R.pop(0)) return M åœ¨pythonå®žçŽ°ä¸­ï¼Œå…¶å®žå¹¶ä¸éœ€è¦ç”¨åæ ‡è¡¨ç¤ºï¼Œå¯ä»¥ç›´æŽ¥ç”¨popæŠŠæ¯æ¬¡éœ€è¦å–çš„ä¸œè¥¿å–å‡ºæ¥ æ—¶é—´å¤æ‚åº¦ æ— è®ºæœ€å¥½æˆ–è€…æœ€åçš„æƒ…å†µéƒ½éœ€è¦æŠŠæ‰€æœ‰ä¸œè¥¿éƒ½æ¯”è¾ƒä¸€å›žï¼Œä¸€å…±æ˜¯lognå±‚ï¼Œæ¯å±‚çš„å®žé™…å†…å®¹éƒ½æ˜¯nä¸ªï¼Œæ‰€ä»¥æœ€ç»ˆçš„å¤æ‚åº¦æ˜¯nlog(n)ã€‚è¿™æ ·çœ‹å‡ºæ¥å½’å¹¶æŽ’åºå¯¹äºŽæœ€å¥½å’Œæœ€åçš„æƒ…å†µæ¯”è¾ƒç¨³å®š ç©ºé—´å¤æ‚åº¦ï¼š ä¸´æ—¶æ•°ç»„çš„æ—¶é—´n + recursiveçš„æ—¶å€™çš„ç©ºé—´logn = O(n) out of place ç¨³å®šæ€§ï¼šç¨³å®šï¼Œå› ä¸ºåœ¨å·¦è¾¹çš„ä¸€å®šæ˜¯åœ¨å·¦è¾¹ å¿«é€ŸæŽ’åº é€‰å–æ•°ç»„çš„ç¬¬ä¸€ä¸ªä½œä¸ºæ ‡å‡†ï¼Œç„¶åŽæŠŠæ¯”è¿™ä¸ªæ ‡å‡†å°çš„éƒ½æ”¾åœ¨å·¦è¾¹ï¼Œæ¯”æ ‡å‡†å¤§çš„éƒ½æ”¾åœ¨å³è¾¹ ç„¶åŽå†åˆ†åˆ«å¯¹å·¦å³è¿›è¡Œå¿«é€ŸæŽ’åº æ³¨æ„ï¼Œåœ¨ä¸æ˜¯pythonçš„æƒ…å†µä¸‹ï¼Œéœ€è¦é€šè¿‡è§’æ ‡äº’æ¢çš„æ–¹æ³•å¾—åˆ°ç»“æžœ å®žçŽ° é€‰æ‹©ä¸€ä¸ªåŸºå‡†piv æ•°åˆ—æœ€å·¦è¾¹çš„æ ‡è®°ä¸ºå·¦æ ‡è®°ï¼Œæœ€å³è¾¹çš„æ ‡è®°æ˜¯å³æ ‡è®° å°†å·¦æ ‡è®°å‘å³æ ‡è®°ç§»åŠ¨ å¦‚æžœå·¦æ ‡è®°çš„å€¼è¶…è¿‡äº†pivçš„å€¼ï¼Œåœæ­¢ ç§»åŠ¨å³æ ‡è®° å½“å³æ ‡è®°å°äºŽpivçš„æ—¶å€™ï¼Œåœæ­¢ç§»åŠ¨ å½“å·¦å³æ ‡è®°éƒ½åœæ­¢çš„æ—¶å€™ï¼Œäº¤æ¢ä¸¤ä¸ªæ•°å­— ç„¶åŽç»§ç»­ç§»åŠ¨ï¼Œç›´åˆ°ä¸¤ä¸ªæ ‡è®°ç¢°åˆ°ä¸€èµ·ï¼Œè¿™æ—¶å€™æŠŠè¿™ä¸ªå€¼å’Œpiväº¤æ¢ 12345678910111213141516def QuickSort(nums, s, e): if s &lt; e: i, j = s, e piv = nums[i] index = i while i &lt; j: while (i &lt; j) and nums[j] &gt;= piv: j -= 1 while (i &lt; j) and nums[i] &lt;= piv: i += 1 nums[i], nums[j] = nums[j], nums[i] nums[i], nums[index] = piv, nums[i] QuickSort(nums, s, i - 1) QuickSort(nums, j + 1, e) return nums 123456789101112131415161718def QuickSort_1(nums): n = len(nums) if n &lt; 2: return nums temp = nums[0] less, more, equal = [], [], [temp] for i in nums[1:]: if i &lt; temp: less.append(i) elif i &gt; temp: more.append(i) elif i == temp: equal.append(i) # less = [x for x in nums[1:] if x &lt; temp] # more = [x for x in nums[1:] if x &gt; temp] # equal = [x for x in nums if x == temp] return QuickSort(less) + equal + QuickSort(more) 1234567891011121314def QuickSort_3(nums): if len(nums) &lt; 2: return nums i, j = 0, len(nums) - 1 piv = nums[i] index = i while i &lt; j: while (i &lt; j) and nums[j] &gt;= piv: j -= 1 while (i &lt; j) and nums[i] &lt;= piv: i += 1 nums[i], nums[j] = nums[j], nums[i] nums[i], nums[index] = piv, nums[i] return QuickSort_3(nums[:i]) + [piv] + QuickSort_3(nums[i + 1:]) ç¬¬ä¸€ç§æ–¹æ³•inputçš„æ—¶å€™éœ€è¦ç¡®å®šæœ€å¼€å§‹å’Œç»“æŸæ—¶å€™çš„indexã€‚çœ‹èµ·æ¥åªæœ‰ç¬¬ä¸€ç§æ–¹æ³•æ˜¯in-placeçš„å®žçŽ°ï¼Ÿ æ—¶é—´å¤æ‚åº¦ï¼š æœ€å·®çš„æ—¶å€™å’Œå†’æ³¡æŽ’åºæ˜¯ä¸€æ ·çš„ï¼ˆä¹Ÿå°±æ˜¯æŽ’å¥½çš„ï¼‰ï¼Œè¿™æ—¶å€™çš„å¤æ‚åº¦æ˜¯n^2 æœ€å¥½çš„æ—¶å€™æ˜¯å®Œå…¨å¹³åˆ†ï¼Œè¿™æ—¶å€™æ˜¯ nlogn ç©ºé—´å¤æ‚åº¦ï¼šå¦‚æžœç”¨ç¬¬ä¸€ç§æ–¹æ³•ï¼Œåªè€—è´¹recursiveæ—¶å€™çš„ç©ºé—´ï¼Œä¹Ÿå°±æ˜¯logn in-place ä¸ç¨³å®šï¼Œå› ä¸ºä¸çŸ¥é“åœ¨æ¢çš„æ—¶å€™å°±æŠŠä»€ä¹ˆå¥‡å¥‡æ€ªæ€ªçš„ä¸œè¥¿æ¢åˆ°å‰é¢åŽ»äº† å †æŽ’åº ä¸€ç§ç±»ä¼¼äºŒå‰æ ‘çš„è®¾è®¡ï¼Œå­èŠ‚ç‚¹çš„æ•°å€¼æ€»æ˜¯å¤§äºŽæˆ–è€…å°äºŽçˆ¶èŠ‚ç‚¹çš„æ•°å€¼ã€‚é¦–å…ˆè¦è®©æ•°æ®å½¢æˆè¿™æ ·çš„ç»“æž„ æ¯æ¬¡æ“ä½œçš„æ—¶å€™ï¼Œéƒ½æŠŠrootçš„å€¼å’Œæœ€åŽä¸€ä¸ªèŠ‚ç‚¹äº¤æ¢ï¼Œäº¤æ¢åŽçš„æœ€åŽä¸€ä¸ªèŠ‚ç‚¹ç§»åŠ¨å‡ºå †ï¼Œç„¶åŽå†é‡æ–°ç§»åŠ¨å †è®©ä»–ä¿æŒä¸Šé¢è¯´çš„æ€§è´¨ ä¸€èˆ¬é€šè¿‡ä¸€ç»´æ•°ç»„æ¥è®¿é—® çˆ¶èŠ‚ç‚¹içš„å·¦èŠ‚ç‚¹ï¼š2i+1 çˆ¶èŠ‚ç‚¹içš„æœ‰èŠ‚ç‚¹ï¼š2i+2 å­èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹ï¼š floorï¼ˆï¼ˆi-1ï¼‰/2ï¼‰ 12345678910111213141516171819202122232425def HeapSort(nums): # startæ˜¯ä»Žæœ€åŽä¸€ä¸ªçˆ¶èŠ‚ç‚¹å¼€å§‹çš„,æž„å»ºå‡ºheap for start in range((len(nums)-2)//2,-1,-1): MinHeap(nums,start,len(nums)-1) for i in range(len(nums)-1,-1,-1): nums[i],nums[0] = nums[0],nums[i] # å› ä¸ºè¿™é‡Œæ¢åˆ°æœ€åŽåŽ»çš„æ•°å­—å°±å·²ç»ç¡®å®šæ˜¯æœ€å¤§å€¼äº†ï¼Œæ‰€ä»¥å†è€ƒè™‘çš„æ—¶å€™ä¸ç”¨è€ƒè™‘ä»–äº† MinHeap(nums,0,i-1) return numsdef MinHeap(nums, start, end): dad = start child = dad * 2 + 1 # å¦‚æžœå­èŠ‚ç‚¹è¿˜åœ¨è¿™ä¸ªå †é‡Œé¢çš„è¯ while child &lt;= end: if child + 1 &lt;= end and nums[child] &gt; nums[child + 1]: # æ¯”è¾ƒä¸¤ä¸ªå­èŠ‚ç‚¹ï¼Œé€‰å‡ºæ¥æ›´å°çš„é‚£ä¸ª child += 1 if nums[dad] &lt; nums[child]: break else: nums[dad], nums[child] = nums[child], nums[dad] dad = child child = dad * 2 + 1 æ³¨æ„ï¼šå¦‚æžœæ˜¯maxheapï¼ˆå³rootä¸Šçš„æ•°å­—æ˜¯æœ€å¤§çš„æ•°å­—çš„è¯ï¼‰ï¼Œå®žé™…æŽ’å‡ºæ¥çš„æ˜¯ç”±å°åˆ°å¤§ï¼Œå› ä¸ºmaxçš„æ•°å­—åœ¨æ¯ä¸€æ¬¡éƒ½è¢«æ¢åˆ°äº†æœ€åŽé¢ æ—¶é—´å¤æ‚åº¦ï¼šnlogn ç©ºé—´å¤æ‚åº¦ï¼š1 ä¸Šé¢çš„ä»£ç å¯ä»¥åŽŸåœ°å®Œæˆçš„ in place ç¨³å®šæ€§ï¼šä¸ç¨³å®šï¼Œè¿™ç§çžŽæ¢çš„å¾ˆéš¾æžæ¸…æ¥šåˆ°åº•æ¢åˆ°å“ªé‡ŒåŽ»äº† è®¡æ•°æŽ’åº æ‰«æä¸€éæ•´ä¸ªæ•°ç»„ï¼Œæ‰¾åˆ°æœ€å¤§å€¼maxå’Œæœ€å°å€¼minï¼ŒèŠ±è´¹æ—¶é—´n åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°ç»„ï¼Œå¤§å°æ˜¯max-min + 1 ç„¶åŽç”¨æ–°æ•°ç»„é‡Œé¢çš„indexæ¥ç»Ÿè®¡æ¯ä¸ªæ•°å­—å‡ºçŽ°çš„æ¬¡æ•°ï¼Œæœ€åŽæ•´ç†å‡ºæ¥ 123456789def CountingSort(nums): Max,Min = max(nums),min(nums) counting = [0 for i in range(Max-Min+1)] result = [] for n in nums: counting[n-Min] += 1 for n,i in enumerate(counting): result += i * [n + Min] return result 12345678910111213141516def CountingSort_2(nums): #å¹¶ä¸åˆ›å»ºæ–°çš„æ•°ç»„ Max= max(nums) bucketLen = Max + 1 bucket = [0]*bucketLen sortedIndex = 0 n = len(nums) for i in range(n): # å¦‚æžœçŽ°åœ¨çš„è¿™ä¸ªä½ç½®æ˜¯ç©ºçš„ if not bucket[nums[i]]: bucket[nums[i]] = 0 bucket[nums[i]] += 1 for j in range(bucketLen): while bucket[j] &gt; 0: nums[sortedIndex] = j sortedIndex += 1 bucket[j] -= 1 ä¸æ˜¯æ¯”è¾ƒæŽ’åºï¼Œæ—¶é—´ä¸Šæ¥è¯´æ¯”ä»»ä½•æ¯”è¾ƒæŽ’åºéƒ½å¿« æ²¡æ³•ç”¨åœ¨æŽ’åºçš„ä¸œè¥¿ä¸æ˜¯æ•°å­—çš„æƒ…å†µä¸‹ï¼Œæ•°å­—å·®å¼‚éžå¸¸å¤§çš„æƒ…å†µä¼šå¾ˆå å†…å­˜ã€‚æŽ’åºçš„å¿…é¡»æ˜¯æ•´æ•° æ—¶é—´å¤æ‚åº¦ n+kï¼Œåªéœ€è¦åœ¨æ•´ä¸ªæ•°ç»„é‡Œæ‰¾å‡ºæœ€å¤§å€¼å’Œæœ€å°å€¼ï¼Œç„¶åŽåœ¨kæ—¶é—´é‡Œé¢æ•°æ•°æ¯ä¸ªæ•°å­—å‡ºçŽ°äº†å¤šå°‘æ¬¡ã€‚å…¶ä¸­kæ˜¯è¿™äº›æ•´æ•°çš„èŒƒå›´ ç©ºé—´å¤æ‚åº¦ kç”¨æ¥å‚¨å­˜è®¡æ•°çš„æ•°ç»„ ç¨³å®šï¼šä¸ºäº†ä¿è¯æ•°ç»„çš„ç¨³å®šæ€§ï¼Œéœ€è¦åå‘å¡«å……æ•°ç»„ï¼ˆçŽ°åœ¨çš„æ–¹æ³•ä¸èƒ½ä¿è¯ç¨³å®šæ€§ï¼‰ æ¡¶æŽ’åº æ€æƒ³åŸºäºŽä¸Šé¢çš„è®¡æ•°æŽ’åºï¼Œä½†æ˜¯æ²¡æœ‰åˆ†é‚£ä¹ˆå¤šç§ ä¸»è¦æƒ³æ³•å°±æ˜¯å…ˆæŠŠçŽ°åœ¨çš„å†…å®¹åˆ†åˆ°kä¸ªä¸åŒçš„æ¡¶é‡Œé¢ï¼Œå†åœ¨æ¯ä¸ªæ¡¶é‡Œé¢åˆ†åˆ«æŽ’åº æ­¥éª¤ æŠŠæ•°æ®åˆ†åˆ°kä¸ªæ¡¶é‡Œ æ¯ä¸ªæ¡¶çš„èŒƒå›´æ˜¯ floorï¼ˆï¼ˆmax-min+1ï¼‰/ kï¼‰ æ”¾å…¥æ¡¶çš„ç¼–å·ä¸º floor((æ•°å­—-æœ€å°å€¼)/æ¯ä¸ªæ¡¶çš„èŒƒå›´) å¯¹æ¯ä¸ªä¸ä¸ºç©ºçš„æ¡¶æŽ’åº è¿žæŽ¥æ¯ä¸ªä¸ä¸ºç©ºçš„æ¡¶ æ—¶é—´å¤æ‚åº¦ï¼š æœ€å¥½n+k -&gt; å¹³å‡åˆ† æœ€å·®æ˜¯n^2 éƒ½åˆ†åˆ°ä¸€ä¸ªæ¡¶é‡Œäº† ç©ºé—´å¤æ‚åº¦ n+k ç¨³å®šï¼Œæ³¨æ„å…ˆæ”¾è¿›æ¡¶é‡Œçš„è¦å…ˆæ‹¿å‡ºæ¥ï¼Œæ‰èƒ½ä¿è¯ç¨³å®š åŸºæ•°æŽ’åº radix sort éžæ¯”è¾ƒçš„æ•´æ•°æŽ’åºçš„ç®—æ³•ã€‚ä¹Ÿå¯ä»¥ç”¨åœ¨å­—æ¯ä¸Šï¼Œä¹Ÿå°±æ˜¯LSDå’ŒMSD æŠŠæ•´æ•°æŒ‰ä½åˆ‡å‰²æˆä¸åŒçš„æ•°å­—ï¼Œç„¶åŽæ¯ä¸ªä½çš„æ•°å­—åˆ†åˆ«æ¯”è¾ƒã€‚éœ€è¦æŠŠæ¯”è¾ƒçš„ä½æ”¾è¿›0-9çš„ä¹ä¸ªæ¡¶é‡Œ æ­¥éª¤ æ‰€æœ‰æ•°ç»Ÿä¸€åˆ°ä¸€ä¸ªé•¿åº¦ï¼ŒçŸ­çš„è¯å‰é¢è¡¥0 ä»Žæœ€ä½Žä½å¼€å§‹ï¼Œä¾æ®æœ€ä½Žä½è¿›è¡ŒæŽ’åº ä¸€ç›´æŽ’åˆ°æœ€é«˜ä½ï¼ŒæŽ’åºä¹‹åŽå°±æ˜¯æœ‰åºçš„äº†]]></content>
      <categories>
        <category>ç®—æ³•</category>
        <category>æŽ’åº</category>
      </categories>
      <tags>
        <tag>ç»å…¸æŽ’åº</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[unityæ˜¾ç¤ºç›¸æœºç”»é¢å¹¶åœ¨opencvå¤„ç†]]></title>
    <url>%2F2019%2F08%2F22%2Funity%E6%98%BE%E7%A4%BA%E7%9B%B8%E6%9C%BA%E7%94%BB%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[æ‰“å¼€ç›¸æœºæ˜¾ç¤ºæ–¹æ³•é¦–å…ˆéœ€è¦æ˜Žç¡®ï¼Œç›®å‰çœ‹åˆ°çš„æ˜¾ç¤ºå›¾ç‰‡æœ‰ä¸¤ç§æ–¹æ³•ï¼Œä¸€ç§æ˜¯æ¸²æŸ“åˆ°å®žé™…çš„gameobjectä¸Šé¢åŽ»ï¼Œå¦ä¸€ç§æ˜¯drawåˆ°GUIä¸Šé¢åŽ»ã€‚å…³äºŽgameobjectåœ¨ä¸Šä¸€ä¸ªæ˜¾ç¤ºå›¾ç‰‡é‡Œé¢æœ‰äº†å¤§è‡´çš„äº†è§£ã€‚è¿™é‡Œä¸»è¦è¯´çš„å†…å®¹åŒ…æ‹¬ ç›¸æœºæ˜¾ç¤ºçš„å¿…å¤‡æ­¥éª¤ å…³äºŽGUI å…³äºŽrenderer ç›¸æœºå†…å®¹æ˜¾ç¤º åœ¨unityä¸­ï¼Œæœ‰ä¸€ä¸ªä¸“é—¨çš„ç±»å«åšWebCamTextureï¼Œæˆ‘ä»¬éœ€è¦ä¸ºè¯»å–è¿›æ¥çš„ç›¸æœºtextureåˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è±¡ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œéœ€è¦ä¸‰ä¸ªéƒ¨åˆ†ï¼Œç›¸æœºçº¹ç†ï¼Œç›¸æœºåå­—ï¼ˆstringï¼‰ä»¥åŠç›¸æœºæ˜¯å¦æ‰“å¼€ï¼ˆboolï¼‰ startéƒ¨åˆ† åœ¨è¿™éƒ¨åˆ†ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦æŠŠåˆ›å»ºçš„cameraTextureå®žä¾‹åŒ– å…¶æ¬¡ï¼Œæˆ‘ä»¬éœ€è¦è°ƒç”¨StartCoroutineå‡½æ•°ï¼Œåœ¨å…¶ä¸­è°ƒç”¨æµ‹è¯•å‡½æ•°æ¥ç¡®å®šç›¸æœºæ˜¯å¦æ‰“å¼€ StartCoroutine åœ¨ä¸€èˆ¬çš„æ‰§è¡Œé‡Œé¢ï¼Œunityæ˜¯é€å¸§è¿è¡Œçš„ï¼Œæ‰€ä»¥å½“æ“ä½œèŠ±è´¹æ—¶é—´çš„æ—¶å€™ï¼Œå¸§çŽ‡ä¸‹é™ï¼Œå°±ä¼šå‘ç”Ÿå¡é¡¿ è¿™éƒ¨åˆ†å¼€å§‹äº†ä¸€ä¸ªåç¨‹ï¼ˆCoroutineï¼‰ï¼Œä½¿ç”¨yieldï¼Œå¯ä»¥åœ¨ä»»ä½•éƒ¨åˆ†æš‚åœè¿™ä¸ªCoroutineçš„æ‰§è¡Œã€‚å¦‚æžœè¢«æˆåŠŸæš‚åœï¼Œå®ƒä¼šåœ¨ä¸‹ä¸€å¸§æ¢å¤æ­£å¸¸ã€‚æ‰€ä»¥è¿™ä¸ªæ–¹æ³•åœ¨å¤šå¸§è¿è¡Œä¹‹ä¸­éžå¸¸å¥½ç”¨ã€‚ unityä¼šå‡è£…å¼€è¾Ÿä¸€ä¸ªæ–°çº¿ç¨‹æ¥æ‰§è¡Œï¼Œä½†æ˜¯ä¸ä¼šå½±å“ä¸»çº¿ç¨‹çš„æŒç»­æ•ˆæžœ å‚è€ƒ ä»Žè¿™é‡Œçš„åŠŸèƒ½æ¥è¯´ï¼Œyieldä¼šæ£€æŸ¥ç”¨æˆ·æœ‰æ²¡æœ‰æŽˆæƒï¼Œå¦‚æžœæ²¡æœ‰æŽˆæƒçš„è¯ï¼Œè¿è¡Œè¢«ç»ˆæ­¢ï¼Œè·³åˆ°ä¸‹ä¸€å¸§ã€‚å¦‚æžœæŽˆæƒæˆåŠŸäº†çš„è¯ï¼Œè¿è¡ŒæˆåŠŸï¼Œç›¸æœºæ‰“å¼€ã€‚ IEnumerator åœ¨StartCoroutineè°ƒç”¨çš„æ˜¯ä¸€ä¸ªIEnumeratorå‡½æ•°ï¼Œä»–é€šè¿‡yieldä¸€ä¸ªboolæ¥å†³å®šæ˜¯ä¸æ˜¯ç»§ç»­è¿è¡Œè¿™ä¸ªå‡½æ•° æŽˆæƒ åœ¨testé‡Œé¢éœ€è¦è€ƒè™‘æœ‰æ²¡æœ‰ç”¨æˆ·çš„æŽˆæƒ æœ‰æŽˆæƒçš„æƒ…å†µä¸‹ï¼Œéœ€è¦æŠŠç›®å‰çš„WebCamTextureï¼ˆæ³¨æ„è¿™é‡Œä¸æ˜¯å»ºç«‹çš„å®žä¾‹ï¼‰çš„deviceçš„æ•°æ®ä¼ é€’ç»™WebCamDeviceï¼ŒåŒ…æ‹¬ç±»åž‹ï¼Œåå­—ç­‰ç­‰ã€‚ ç„¶åŽéœ€è¦æŠŠåŒ…æ‹¬è¿™ä¸ªç›¸æœºåå­—ï¼Œsizeå’Œfpsçš„ä¿¡æ¯ä¼ ç»™ä¹‹å‰cameraTextureçš„å®žä¾‹ ä»¥ä¸Šéƒ½è®¾å®šå¥½ä¹‹åŽï¼ŒWebCamTexture.Playä¼šæ¿€æ´»è¿™ä¸ªç›¸æœºï¼Œè®©ä»–å¼€å§‹å·¥ä½œ ç„¶åŽå†è®²ç›¸æœºçš„textureæ¸²æŸ“åˆ°objectçš„è¡¨é¢ä¸Š12345678910yield return Application.RequestUserAuthorization(UserAuthorization.WebCam); if(Application.HasUserAuthorization(UserAuthorization.WebCam)) &#123; WebCamDevice[] devices = WebCamTexture.devices; cameraName = devices[0].name; cameraTexture = new WebCamTexture(cameraName, 1024, 768, 15); cameraTexture.Play(); isOpen = true; renderer.material.mainTexture = cameraTexture; &#125; GUI GUIä¸»è¦æ˜¯æä¾›äº†å›¾å½¢åŒ–çš„çª—å£ï¼Œå®žé™…ä¸Šæ˜¾ç¤ºçš„å…ƒç´ æ˜¯ç›´æŽ¥æ˜¾ç¤ºåœ¨gameç”»é¢ä¸Šçš„ï¼Œä¹Ÿå°±æ˜¯è¯´è¿™éƒ¨åˆ†æ˜¯å’Œå®žé™…ç›¸æœºæ‹æ‘„åˆ°çš„ç”»é¢ç‹¬ç«‹çš„ã€‚æ— è®ºç›¸æœºå¦‚ä½•ç§»åŠ¨ï¼Œç‰©ä½“å¦‚ä½•æ”¹å˜ï¼Œæœ€ç»ˆGUIçš„ç”»é¢éƒ½ä¼šæ˜¾ç¤ºåˆ°åŒæ ·çš„åœ°æ–¹ MonoBehaviour.OnGUI() æ³¨æ„OnGUIå‡½æ•°å¹¶ä¸éœ€è¦æˆ‘ä»¬è‡ªå·±åŽ»è°ƒç”¨ï¼Œä¸éœ€è¦å†updateé‡Œé¢è°ƒç”¨ï¼ OnGUIæ˜¯APIé‡Œé¢è‡ªå¸¦çš„å‡½æ•°ï¼Œæˆ‘ä»¬éœ€è¦åœ¨è¿™ä¸ªå‡½æ•°ä¸­æ¸²æŸ“å’Œå¤„ç†GUIçš„event åœ¨å®žé™…åº”ç”¨ä¸­ï¼ŒOnGUIå¯èƒ½æ¯ä¸€ä¸ªframeè¢«callå¾ˆå¤šæ¬¡ï¼Œæ¯æ¬¡eventï¼ˆä¾‹å¦‚é¼ æ ‡æ“ä½œï¼Œé”®ç›˜ç­‰ç­‰ï¼‰å‘ç”Ÿçš„æ—¶å€™éƒ½ä¼šcallè¿™ä¸ªå‡½æ•° ä¾‹å¦‚ä¸‹é¢å®˜æ–¹çš„ä¾‹å­ï¼Œæ¯æ¬¡é¼ æ ‡ç‚¹å‡»çš„æ—¶å€™ï¼Œå°±ä¼šprintå‡ºç›¸åº”çš„è¯æ¥12345678910111213using UnityEngine;using System.Collections;public class ExampleClass : MonoBehaviour&#123; void OnGUI() &#123; if (GUI.Button(new Rect(10, 10, 150, 100), "I am a button")) &#123; print("You clicked the button!"); &#125; &#125;&#125; GUI.DrawTexture åœ¨GUIçš„å®žçŽ°ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å°†ç›¸æœºè¯»å–åˆ°çš„éƒ¨åˆ†drawçš„GUIçš„ä¸Šé¢ï¼Œæ‰€ä»¥è°ƒç”¨äº†è¿™ä¸ªå‡½æ•° éœ€è¦ç¡®å®šçš„å‚æ•°åŒ…æ‹¬ï¼šä½ç½®ï¼Œéœ€è¦æ¸²æŸ“çš„textureï¼Œç¼©æ”¾æ¯”ä¾‹ç­‰ç­‰ å®žçŽ° ä»£ç éƒ¨åˆ†å‚è€ƒ1234567891011121314151617181920212223242526272829303132333435363738394041424344454647using System.Collections;using System.Collections.Generic;using UnityEngine;public class showCamera : MonoBehaviour&#123; protected WebCamTexture cameraTexture; protected string cameraName = ""; protected bool isOpen = false; //protected MeshRenderer renderer; // Start is called before the first frame update void Start() &#123; //renderer = this.GetComponent&lt;MeshRenderer&gt;(); cameraTexture = new WebCamTexture(); StartCoroutine(Test()); &#125; // Update is called once per frame void Update() &#123; &#125; IEnumerator Test() &#123; yield return Application.RequestUserAuthorization(UserAuthorization.WebCam); if(Application.HasUserAuthorization(UserAuthorization.WebCam)) &#123; WebCamDevice[] devices = WebCamTexture.devices; cameraName = devices[0].name; cameraTexture = new WebCamTexture(cameraName, 1024, 768, 15); cameraTexture.Play(); isOpen = true; //renderer.material.mainTexture = cameraTexture; &#125; &#125; void OnGUI() &#123; if(isOpen) &#123; GUI.DrawTexture(new Rect(0, 0, 400, 300), cameraTexture, ScaleMode.ScaleToFit); &#125; &#125;&#125; æ¸²æŸ“åˆ°objectä¸Šé¢ å’Œä¹‹å‰çš„æ“ä½œç±»ä¼¼ï¼Œéœ€è¦ æž„å»ºMeshRendererçš„object åœ¨starté‡Œé¢è¯»å–å‡ºç‰©ä½“çš„MeshRendererï¼ˆgetcomponentï¼‰ æœ€åŽæ‰“å¼€ç›¸æœºåŽï¼ŒæŠŠç›¸æœºçš„å†…å®¹æ¸²æŸ“åˆ°MeshRendererä¸Šé¢ 12345678910111213141516171819202122232425262728293031323334353637383940414243using System.Collections;using System.Collections.Generic;using UnityEngine;public class showCamera : MonoBehaviour&#123; protected WebCamTexture cameraTexture; protected string cameraName = ""; protected bool isOpen = false; protected MeshRenderer renderer; // Start is called before the first frame update void Start() &#123; renderer = this.GetComponent&lt;MeshRenderer&gt;(); //cameraTexture = new WebCamTexture(); StartCoroutine(Test()); &#125; IEnumerator Test() &#123; yield return Application.RequestUserAuthorization(UserAuthorization.WebCam); if(Application.HasUserAuthorization(UserAuthorization.WebCam)) &#123; WebCamDevice[] devices = WebCamTexture.devices; cameraName = devices[0].name; cameraTexture = new WebCamTexture(cameraName, 1024, 768, 15); cameraTexture.Play(); isOpen = true; renderer.material.mainTexture = cameraTexture; &#125; &#125; //void OnGUI() //&#123; // if(isOpen) // &#123; // GUI.DrawTexture(new Rect(0, 0, 400, 300), cameraTexture, ScaleMode.ScaleToFit); // &#125; //&#125;&#125; å°†å›¾ç‰‡æ”¾å…¥opencvæ¥æº å¾—åˆ°äº†webçš„textureä¹‹åŽï¼Œå¯ä»¥ç›´æŽ¥ç”¨openCVçš„éƒ¨åˆ†æŠŠè¿™ä¸ªçŽ©æ„è½¬æ¢æˆmatï¼Œç„¶åŽå¤„ç† è¿™é‡Œçš„é—®é¢˜æ˜¯åˆšå¼€å§‹matçš„å¤§å°èŽ«åå…¶å¦™çš„æ˜¯16ï¼Œæ‰€ä»¥éœ€è¦åŠ ä¸Šä¸€ä¸ªåˆ¤æ–­æ¡ä»¶ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667using System.Collections;using System.Collections.Generic;using UnityEngine;using OpenCVForUnity.CoreModule;using OpenCVForUnity.UnityUtils;using OpenCVForUnity.ImgprocModule;public class showCamera : MonoBehaviour&#123; protected WebCamTexture cameraTexture; //protected string cameraName = ""; //protected bool isOpen = false; private Color32[] colors; private Mat rgbaMat; private Texture2D tex; // Start is called before the first frame update void Start() &#123; //renderer = this.GetComponent&lt;MeshRenderer&gt;(); //cameraTexture = new WebCamTexture(); //StartCoroutine(Test()); cameraTexture = new WebCamTexture(WebCamTexture.devices[0].name, 640, 480); cameraTexture.Play(); StartCoroutine(init()); &#125; private IEnumerator init() &#123; Debug.Log(cameraTexture.width); if (cameraTexture.width &lt;= 16) &#123; while(!cameraTexture.didUpdateThisFrame) &#123; yield return new WaitForEndOfFrame(); &#125; cameraTexture.Pause(); colors = cameraTexture.GetPixels32(); cameraTexture.Stop(); yield return new WaitForEndOfFrame(); cameraTexture.Play(); tex = new Texture2D(cameraTexture.width, cameraTexture.height, TextureFormat.RGBA32, false); rgbaMat = new Mat(cameraTexture.height, cameraTexture.width, CvType.CV_8UC4); GetComponent&lt;Renderer&gt;().material.mainTexture = tex; &#125; &#125; private void Update() &#123; Debug.Log(cameraTexture.width); if (cameraTexture.didUpdateThisFrame &amp;&amp; rgbaMat != null) &#123; Utils.webCamTextureToMat(cameraTexture, rgbaMat); //Imgproc.cvtColor(rgbaMat, rgbaMat, Imgproc.COLOR_RGB2HSV); Utils.matToTexture2D(rgbaMat, tex); tex.Apply(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Unity</category>
        <category>OpenCV</category>
      </categories>
      <tags>
        <tag>Unity</tag>
        <tag>WebCamera</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ç¼–ç¨‹ç çŽ‘ProgrammingPearls]]></title>
    <url>%2F2019%2F08%2F20%2F%E7%BC%96%E7%A8%8B%E7%8F%A0%E7%8E%91ProgrammingPearls%2F</url>
    <content type="text"><![CDATA[ç¬¬ä¸€ç« é—®é¢˜ å¼€å§‹çš„é—®é¢˜æ˜¯å¦‚ä½•å¯¹æ–‡ä»¶è¿›è¡ŒæŽ’åº -&gt; merge sort æ•´åˆé—®é¢˜ä¹‹åŽï¼Œé—®é¢˜å˜æˆäº†éœ€è¦å¯¹7ä½æ•°å­—è¿›è¡ŒæŽ’åºï¼Œè¿™æ ·çš„è¯éœ€è¦çš„æ—¶é—´å°±è¿œå°äºŽmerge sortäº† å¦ä¸€ç§æ–¹æ³• å¦‚æžœåœ¨æ¯ä¸ªbyteé‡Œé¢å­˜ä¸€ä¸ªæ•°å­—ï¼Œé‚£ä¹ˆ1MBå¯ä»¥å­˜143000å·¦å³çš„å·ç ï¼ˆe6/7) ä½†æ˜¯å¦‚æžœæŠŠæ¯ä¸ªæ•°å­—è¡¨ç¤ºæˆä¸€ä¸ª32ä½çš„intï¼ˆä¹Ÿå°±æ˜¯è¯´æ¯7ä½æ•°å­˜æˆä¸€ä¸ª32ä½çš„æ•´æ•°ï¼Œé‚£ä¹ˆè¿™7ä½æ•°å°±å 4ä¸ªbyteï¼‰ï¼Œé‚£ä¹ˆå¯ä»¥å­˜250000å·¦å³çš„å·ç  ä»Žè¿™ä¸ªè§’åº¦è€ƒè™‘ï¼Œå¿«æŽ’çš„é€Ÿåº¦æ¯”mergeå¿« å®žçŽ° ä»Žä¸Šé¢çš„é—®é¢˜åˆ†æžæ¥çœ‹ï¼Œç”¨bitmapæˆ–è€…bit vectoræ¥è¡¨ç¤ºæ•°æ®å¾ˆå¸¸è§ã€‚ æ¯”å¦‚ï¼Œå¯ä»¥ç”¨ä¸€ä¸ª20bitçš„stringæ¥è¡¨ç¤º{1,2,3,5,8,13} 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 åœ¨è¿™ä¸ªé‡Œé¢ï¼Œå‡ºçŽ°åœ¨é›†åˆé‡Œçš„æ•°å­—å°±è¡¨ç¤ºä¸º1ï¼Œæ²¡æœ‰å‡ºçŽ°çš„å°±è¡¨ç¤ºä¸º0 åœ¨å®žé™…è§£å†³é—®é¢˜è¿‡ç¨‹ä¸­ï¼Œ7ä½æ•°å­—å¯ä»¥è¡¨ç¤ºæˆä¸€ä¸ªå°äºŽåƒä¸‡çš„æ•°ã€‚å¦‚æžœç”¨ä¸€ä¸ªåƒä¸‡çš„äºŒè¿›åˆ¶ä¸²æ¥è¡¨ç¤ºï¼Œé‚£ä¹ˆå¦‚æžœæ•´ä¸ªæ–‡ä»¶é‡Œé¢æœ‰çŽ°åœ¨çš„å·ç çš„æ—¶å€™ï¼Œè¿™ä¸ªä½æ‰è¢«è¡¨ç¤ºä¸º1ï¼Œå¦åˆ™å°±è¢«è¡¨ç¤ºä¸º0 åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µ å…³é—­æ‰€æœ‰çš„ä½ï¼Œå³åƒä¸‡ä¸ªä½å…¨éƒ½æ˜¯0 ä»Žè¾“å…¥æ–‡ä»¶é‡Œé¢å¯¼å…¥æ‰€æœ‰çš„æ•°å­—ï¼Œæ¯”å¦‚2897çš„è¯ï¼Œå°±æ˜¯b[2897]=1 å…¨éƒ¨è¾“å…¥å®Œæ¯•ä¹‹åŽï¼Œå†æ ¹æ®çŽ°æœ‰å­˜åœ¨çš„æ•°å­—å°±å¯ä»¥ç›´æŽ¥æŽ’åºï¼Œè¾“å‡ºäº† å¤„ç†åŽŸåˆ™æ€»åŽŸåˆ™ï¼šåœ¨å¼€å§‹å¤„ç†é—®é¢˜ä¹‹å‰åˆ†æžé—®é¢˜ï¼Œæ‰èƒ½è®©é—®é¢˜æ›´å¥½è§£å†³ ç¡®å®šæ­£ç¡®çš„é—®é¢˜ -&gt; æœ€é‡è¦çš„ä¸€ç‚¹ é€‰æ‹©äº†bitmapçš„æ•°æ®ç»“æž„ï¼šé€‰æ‹©è¿™ä¸ªæ•°æ®ç»“æž„æ˜¯æ ¹æ®ç”µè¯å·ç ä¸ä¼šé‡å¤è¿™ä¸ªç‰¹æ®Šæ¡ä»¶å¾—åˆ°çš„ multi-pass æ—¶é—´å’Œç©ºé—´çš„trade off ç®€å•è®¾è®¡ ç¬¬äºŒç«  ç®—æ³•é—®é¢˜1ï¼š å¦‚æžœæœ‰æœ€å¤š40äº¿ä¸ªæŽ’å¥½åºçš„32ä½æµ®ç‚¹æ•°ï¼Œå…¶ä¸­æœ‰é—æ¼çš„æ•°æ®ï¼Œå¦‚ä½•æ‰¾åˆ°é—æ¼çš„æ•°æ®ã€‚è€ƒè™‘å†…å­˜è¶³å¤Ÿçš„æ—¶å€™å’Œå†…å­˜ä¸å¤Ÿçš„æ—¶å€™çš„æƒ…å†µ å¦‚æžœå†…å­˜è¶³å¤Ÿï¼Œå¯ä»¥åƒç¬¬ä¸€ç« è¯´çš„ä¸€æ ·ï¼Œç”¨ä½å›¾æ¥è¡¨ç¤ºè¿™äº›æ•°æ®ï¼Œç„¶åŽçœ‹å“ªäº›æ²¡æœ‰ å¦‚æžœå†…å­˜ä¸å¤Ÿï¼Ÿ äºŒåˆ†æŸ¥æ‰¾ å¿…é¡»å®šä¹‰èŒƒå›´ï¼ŒèŒƒå›´é‡Œé¢æ¯ä¸ªæ•°å­—çš„è¡¨ç¤ºæ–¹æ³•å’ŒæŽ¢æµ‹æ–¹æ³• æ¯”å¦‚å¦‚æžœæŠŠè¿™äº›æ•°æ®åˆ†æˆä¸¤éƒ¨åˆ†ï¼Œæ¯”å¦‚1-10é‡Œé¢å–ä¸­ä½æ•°ï¼Œå› ä¸ºç¼ºæ•°æ®çš„åŽŸå› ï¼Œæ€»æ˜¯ä¼šæœ‰ä¸€è¾¹çš„ä¸ªæ•°å°‘ï¼Œé‚£ä¹ˆç¼ºçš„æ•°æ®å°±è‚¯å®šåœ¨å°‘çš„è¿™è¾¹ é—®é¢˜2ï¼š å°†å…·æœ‰nä¸ªå…ƒç´ çš„å‘é‡xå·¦æ—‹iä¸ªä½ç½®ï¼Œæ—¶é—´ä¸Šä¸Žnæˆæ­£æ¯”ï¼Œæœ‰åå‡ å­—èŠ‚çš„é¢å¤–ç©ºé—´ ç›´æŽ¥æ–¹æ³• å‚¨å­˜åˆ°é¢å¤–æ•°ç»„ -&gt; å¤ªæµªè´¹ç©ºé—´äº† å®šä¹‰ä¸€ä¸ªå‡½æ•°å°†æ•°ç»„æ¯æ¬¡ç§»åŠ¨ä¸€ä¸ªä½ç½® -&gt; å¤ªæµªè´¹æ—¶é—´äº†ï¼ˆè™½ç„¶æ—¶é—´ä¸Šå’Œnæˆæ­£æ¯”ï¼‰ å¦ä¸€ä¸ªæ€è€ƒ æŠŠä¸€ä¸ªæ•°ç»„åˆ†æˆä¸åŒçš„ç»„ï¼Œæ¯æ¬¡æŠŠå¯¹åº”ç»„çš„å†…å®¹è½¬ç§»ï¼Œç›´åˆ°æ‰€æœ‰å†…å®¹éƒ½è½¬ç§»æˆåŠŸã€‚æ¯”å¦‚æŠŠx[0]æŒªå‡ºåŽ»ï¼Œx[3]è¯ºåˆ°x[0],x[6]æŒªåˆ°3ï¼Œç„¶åŽ0æŒªåˆ°6ã€‚ç„¶åŽå†æŒªx[1]å’Œä»–çš„å¯¹åº”çš„å†…å®¹ä»¬ å¦ä¸€ç§æ€è€ƒæ–¹æ³•ï¼šæ—‹è½¬xå®žé™…å°±æ˜¯æŠŠabè½¬æ¢æˆba å¦‚æžœaæ˜¯å‰iä¸ªå…ƒç´ ï¼Œaæ¯”bçŸ­ï¼ŒæŠŠbåˆ†å‰²æˆb1å’Œb2ï¼Œè®©b2å’Œaçš„é•¿åº¦ä¸€æ · é‚£ä¹ˆå¯ä»¥å…ˆäº¤æ¢aå’Œb2 -&gt; b2 a b1 ç„¶åŽå†é›†ä¸­ç²¾åŠ›äº¤æ¢b1å’Œb2é‡Œçš„å…ƒç´ ï¼Œä¹Ÿå°±æ˜¯è¯´è¿™å¯ä»¥æ˜¯ä¸€ä¸ªrecursiveçš„è¡¨ç¤ºæ–¹æ³• è½¬ç½®ï¼šè¿™ä¸ªçœ‹èµ·æ¥åœ¨å†™Leetcodeçš„æ—¶å€™éžå¸¸å¥½ç”¨å•Šï¼ï¼ï¼ä½†æ˜¯æ³¨æ„åœ¨pythoné‡Œé¢reverseè¦è‡ªå·±å†™ å¦‚æžœæŠŠé—®é¢˜çœ‹æˆè½¬ç½®ï¼Œå®žé™…ä¸Šæ•°ç»„abå¯ä»¥ å…ˆè½¬ç½®aï¼šaTb å†è½¬ç½®bï¼šaTbT å†è½¬ç½®æ•´ä¸ªæ•°ç»„ï¼šï¼ˆaTbTï¼‰T = ba ä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æžœabcdefgæƒ³è®©ä»–æ—‹è½¬ä¸‰ä½ï¼Œå®žé™…ä¸Šå¯ä»¥åšåˆ°çš„æ˜¯ reverseï¼ˆ0ï¼Œ2ï¼‰ï¼šcbadefg reverseï¼ˆ3ï¼Œ6ï¼‰ï¼šcbagfed reverseï¼ˆ0ï¼Œ6ï¼‰ï¼šdefgabc é—®é¢˜3 æ‰¾åˆ°ä¸€ä¸ªå•è¯çš„å˜ä½è¯ï¼šæ¯”å¦‚potså’Œstop è§£å†³æ–¹æ³• æ³¨æ„ï¼Œæ‰¾åˆ°æ‰€æœ‰çš„å¯èƒ½æ€§æ˜¯å¾ˆæ„šè ¢çš„ï¼Œæ¯”å¦‚ä¸€ä¸ª22ä¸ªå­—æ¯çš„è¯ï¼Œæ‰€æœ‰çš„å˜ä½22ï¼å¤§æ¦‚æ˜¯10e21ï¼Œæ—¶é—´çˆ†ç‚¸äº† æ ¸å¿ƒæ€æƒ³ -&gt; æŽ’åºï¼ŒæŽ’åºä¹‹åŽçš„å˜ä½è¯å°±éƒ½ä¸€æ ·äº† leetcode 242,49 è¿™ä¸ªé¢˜çš„æ ¸å¿ƒæ€è·¯å°±æ˜¯ï¼Œæ¯ä¸ªå•è¯æŒ‰å­—æ¯é¡ºåºæŽ’åºä¹‹åŽçš„ç­”æ¡ˆå°±æ˜¯è¿™ä¸ªå•è¯çš„keyï¼Œå¦‚æžœä¸¤ä¸ªå•è¯çš„keyä¸€æ ·çš„è¯è¿™ä¸¤ä¸ªå•è¯å°±æ˜¯å˜ä½è¯ï¼Œå¦‚æžœä¸ä¸€æ ·çš„è¯å°±æ˜¯æ–°çš„è¯ åœ¨pythoné‡Œé¢ç›´æŽ¥ç”¨å­—å…¸å¯ä»¥å¾ˆå¥½çš„å‚¨å­˜å˜ä½è¯ ç¬¬ä¸‰ç«  æ•°æ®ç»“æž„æ•°æ®ç»“æž„çš„æ„ä¹‰å°±æ˜¯è®©ä»£ç å¯ä»¥æ›´åŠ ç®€çŸ­æ•´æ´ -&gt; æ¯”å¦‚ç”¨æ•°ç»„ä»£æ›¿å¾ªçŽ¯ åŽŸåˆ™ï¼šèƒ½ç”¨å°ç¨‹åºè§£å†³çš„å°±ä¸è¦ç”¨å¤§ç¨‹åº æŠŠé‡å¤æ€§ä»£ç æ”¹å†™ å°è£…å¤æ‚çš„ç»“æž„ å°½å¯èƒ½ä½¿ç”¨é«˜çº§å·¥å…· è®©æ•°æ®åŽ»æž„é€ ç¨‹åº ç¬¬å››ç«  æ­£ç¡®ç¼–å†™ç¨‹åºå†™ä¸€ä¸ªå®Œå…¨æ­£ç¡®çš„binary searchå§ï¼ æ³¨æ„ç‚¹ æ±‚ä¸­ä½æ•°çš„æ—¶å€™æ˜¯å‰åŽç›¸åŠ ï¼Œé™¤ä»¥äºŒ æ³¨æ„è·³å‡ºå¾ªçŽ¯çš„æ¡ä»¶æ˜¯ start&gt; end ä¸ºäº†æ»¡è¶³ä¸Šé¢çš„å¾ªçŽ¯æ¡ä»¶ï¼Œéœ€è¦æ¯æ¬¡åˆ¤æ–­å®Œmidä¹‹åŽï¼ŒæŠŠstartæˆ–è€…endç§»åŠ¨ä¸€ä½ï¼Œä¸ç„¶ä¼šé™·å…¥æ­»å¾ªçŽ¯ åŽé¢çš„9ï¼Œ11ï¼Œ14ä¼šç”¨åˆ°ç¨‹åºçš„éªŒè¯æŠ€æœ¯12345678910111213141516class Solution: def search(self, nums: List[int], target: int) -&gt; int: start = 0 end = len(nums) - 1 mid = (start + end) // 2 while start &lt;= end: if target == nums[mid]: return mid elif target &gt; nums[mid]: start = mid + 1 mid = (end + start) // 2 elif target &lt; nums[mid]: end = mid - 1 mid = (start + end) // 2 return -1 ç¬¬äº”ç«  æ¬¡è¦é—®é¢˜ è™½ç„¶æ¯æ¬¡å†™å®Œäº†ç¨‹åºï¼Œå¤§å®¶åŸºæœ¬éƒ½ä¼šé€‰æ‹©æŠŠå®ƒç›´æŽ¥æ’å…¥ç³»ç»Ÿï¼Œç„¶åŽå¼ºçƒˆçš„å¸Œæœ›ä»–èƒ½è¿è¡Œ ï¼ˆå“­äº†ï¼Œå†™çš„ä¹Ÿå¤ªçœŸå®žäº†ï¼‰ æµ‹è¯•ç”¨ä¾‹ è®¾ç½®æžå°çš„æµ‹è¯•ç”¨ä¾‹ï¼ˆæ¯”å¦‚0ä¸ªï¼Œ1ä¸ªï¼Œ2ä¸ªå…ƒç´ ç­‰ç­‰ï¼‰ è®¾ç½®å¯ä»¥è‡ªåŠ¨ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹ è®¡æ—¶ï¼Œæµ‹è¯•ä¸åŒæ–¹æ³•çš„æ—¶é—´ è°ƒè¯• -&gt; å¼•å‘bugæ˜¯ä¼šæœ‰å®žé™…çš„é€»è¾‘åŽŸå› çš„ï¼Œè°ƒè¯•çš„æ—¶å€™éœ€è¦å…³æ³¨è¿™äº›é—®é¢˜ ç¬¬å…­ç«  æ€§èƒ½é€è§†åœ¨åŽé¢çš„ä¸‰ç« ä¼šè¯´åˆ°æé«˜è¿è¡Œæ•ˆçŽ‡çš„ä¸‰ä¸ªæ–¹æ³•ï¼Œåœ¨ç¬¬å…­ç« ä¸»è¦è®²çš„æ˜¯å„ä¸ªå±‚æ¬¡å¦‚ä½•ç»„åˆä¸ºä¸€ä¸ªæ•´ä½“ æ¡ˆä¾‹ ä¸€ä¸ªæ¨¡æ‹Ÿå¤©ä½“é—´å—åŠ›å…³ç³»ï¼Œæ¥æ¨¡æ‹Ÿè¿åŠ¨çš„ç¨‹åºï¼Œé€šè¿‡å¯¹ç¨‹åºçš„æ”¹è¿›ï¼Œåœ¨n=1000çš„ç¨‹åº¦ä¸‹ï¼ŒæŠŠé€Ÿåº¦ä»Žä¸€å¹´æå‡åˆ°äº†ä¸åˆ°ä¸€å¤©ï¼Œé€Ÿåº¦æå‡ç³»æ•°çº¦ä¸º400 æ”¹è¿›æ–¹æ³• ç®—æ³•å’Œæ•°æ®ç»“æž„ï¼ŒæŠŠæ—¶é—´å¤æ‚åº¦n2 -&gt; nlognï¼ˆäºŒå‰æ ‘ï¼‰ ç®—æ³•ä¼˜åŒ–ï¼Œä¼˜åŒ–äº†ä¸¤ä¸ªç²’å­é çš„å¾ˆè¿‘çš„æƒ…å†µ æ•°æ®ç»“æž„é‡ç»„ï¼Œå‡å°‘äº†å±€éƒ¨è®¡ç®—çš„æ¬¡æ•° ä»£ç ä¼˜åŒ–ï¼š64ä½æµ®ç‚¹æ•°æ”¹ä¸º32ä½ï¼Œè®¡ç®—æ—¶é—´å‡åŠã€‚ç”¨æ±‡ç¼–é‡å†™äº†æŸä¸ªå‡½æ•°ï¼Œç»™ç¼“æ…¢çš„å‡½æ•°åŠ é€Ÿ ç¡¬ä»¶ï¼Œæå‡äº†ç¡¬ä»¶ ç®—æ³•åŠ é€Ÿä¸ä¸€å®šæ˜¯ç‹¬ç«‹äºŽç¡¬ä»¶çš„ï¼Œæ¯”å¦‚åœ¨è¶…çº§è®¡ç®—æœºä¸Šï¼Œæ ‘å½¢ç»“æž„å¯¹æ—¶é—´çš„å½±å“å°±å¾ˆå° è®¾è®¡å±‚æ¬¡ é—®é¢˜çš„å®šä¹‰ ç³»ç»Ÿç»“æž„ -&gt; ç¬¬ä¸ƒç« ï¼Œå°åº•ä¼°è®¡ ç®—æ³•å’Œæ•°æ®ç»“æž„ -&gt; 2,8ç«  ä»£ç ä¼˜åŒ– -&gt; 9 ç³»ç»Ÿè½¯ä»¶ ç¡¬ä»¶ï¼šæ¯”å¦‚å®žçŽ°æŸä¸ªåŠŸèƒ½çš„ä¸“é—¨ç¡¬ä»¶ åŽŸåˆ™ å¦‚æžœéœ€è¦å°‘é‡åŠ é€Ÿï¼Œç ”ç©¶æœ€å¥½çš„å±‚æ¬¡ã€‚è™½ç„¶ä¿®æ”¹ç®—æ³•æ˜¯éžå¸¸å¸¸è§çš„ç­”æ¡ˆï¼Œä½†æ˜¯åœ¨ç ”ç©¶ä¹‹å‰æœ€å¥½è€ƒè™‘ä¸€ä¸‹æ‰€æœ‰å¯èƒ½çš„å±‚æ¬¡ã€‚æ¯”å¦‚ç¡¬ä»¶ï¼Ÿè¿™ç§çš„ï¼Œæœ€å¥½èƒ½æ‰¾åˆ°ä¸€ä¸ªå¾—åˆ°æœ€å¤§åŠ é€Ÿï¼Œåˆæ‰€éœ€ç²¾åŠ›æœ€å°‘çš„å±‚æ¬¡ å¦‚æžœéœ€è¦å¤§é‡åŠ é€Ÿï¼Œéœ€è¦ç ”ç©¶å¤šä¸ªå±‚æ¬¡ã€‚å°±åƒä¸Šé¢çš„æ¡ˆä¾‹ä¸€æ · å°åº•è®¡ç®—åœ¨å¤„ç†é—®é¢˜ä¹‹å‰ï¼Œéœ€è¦å¯¹è¿™ä¸ªé—®é¢˜çš„è§„æ¨¡æœ‰ä¸€ä¸ªå¤§æ¦‚çš„ä¼°è®¡ï¼Œæ‰èƒ½æ›´å¥½çš„å¤„ç†é—®é¢˜ å¸®åŠ©å°åº•è®¡ç®— ä¸¤ä¸ªä¸åŒæ–¹é¢çš„ç­”æ¡ˆå¯¹æ¯” é‡çº²æ£€æµ‹ ç»éªŒæ³•åˆ™ å®žè·µ æ€§èƒ½ä¼°è®¡ + å®‰å…¨ç³»æ•°]]></content>
      <categories>
        <category>ç®—æ³•</category>
        <category>ç¼–ç¨‹ç çŽ‘</category>
      </categories>
      <tags>
        <tag>Programming Pearls</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unityä¸ŽopenCVæ˜¾ç¤ºå›¾ç‰‡]]></title>
    <url>%2F2019%2F08%2F20%2Funity%E4%B8%8EopenCV%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[å…³äºŽopencvåº“ unityå¸¦äº†opencvåº“ï¼Œä½†æ˜¯è¿™ä¸ªåº“æ˜¯based on javaçš„åŸºç¡€ä¸Šçš„ï¼Œä¹Ÿå°±æ˜¯è¯´æˆ‘ç»§ç”¨è¿‡opencvçš„c++å’Œpythonä¹‹åŽè¿™å›žè¦ç”¨javaäº† OpenCV for Unityæ–‡æ¡£ æ³¨æ„ï¼šéœ€è¦åœ¨è½½å…¥opecvçš„assetä¹‹åŽï¼ŒæŠŠStreamingAssetsæ–‡ä»¶å¤¹ç§»åŠ¨åˆ°Asseté‡Œé¢ï¼Œéœ€è¦æ“ä½œtool--set plugin settings opencvè‡ªå¸¦äº†å¾ˆå¤šexampleï¼ŒæŠŠè¿™äº›åŠ å…¥åˆ°building settingé‡Œé¢å°±å¯ä»¥ç”¨äº† æ˜¾ç¤ºå›¾ç‰‡é¦–å…ˆæ˜Žç¡®ä¸€ç‚¹ï¼Œunityé‡Œé¢æ˜¾ç¤ºå›¾ç‰‡æ²¡æœ‰imshowè¿™ç§ä¸œè¥¿ï¼Œéœ€è¦æŠŠå›¾ç‰‡çš„matè½¬åŒ–æˆtextureæ ¼å¼ï¼Œç„¶åŽæŠŠè¿™ä¸ªtextureåŠ åˆ°objectä¸Šé¢ åœ¨è¿™é‡Œæˆ‘å»ºç«‹äº†ä¸€ä¸ªplaneçš„objectï¼Œå¹¶ä¸”è°ƒæ•´äº†ç›¸æœºçš„è§’åº¦ï¼Œç”¨æ¥æ˜¾ç¤ºå›¾ç‰‡ è¿™éƒ¨åˆ†åœ¨starté‡Œé¢è¿›è¡Œï¼Œä¹Ÿå°±æ˜¯çŽ°åœ¨çš„å›¾ç‰‡æ˜¯é™æ€æ˜¾ç¤º var varæ˜¯ç”¨æ¥æŽ¨æ–­è¿™ä¸ªå˜é‡ç±»åž‹ï¼Œå› ä¸ºvarä¹‹åŽç›´æŽ¥åˆ›å»ºäº†å˜é‡ï¼Œæ‰€ä»¥å¯ä»¥æŽ¨æ–­å‡ºæ¥ã€‚ä½†æ˜¯javaè¿˜æ˜¯é™æ€è¯­è¨€ è¿™ç§æ ·å­æ˜¯ä¸è¡Œçš„var foo; foo = &quot;foo&quot;; åœ¨forå¾ªçŽ¯é‡Œå¯ä»¥ imread åŸºç¡€åŠŸèƒ½å’Œä»¥å‰ä¸€æ ·ï¼Œè¯»å–ä¸€å¼ å›¾ç‰‡ï¼Œå­˜ä¸ºmatæ ¼å¼ è·¯å¾„ä¸­ä½¿ç”¨äº†Application.streamingAssetsPathï¼Œä¹Ÿå°±æ˜¯ä¸Šæ–‡ä¸­è¯´åˆ°éœ€è¦ç§»åŠ¨åˆ°assetæ–‡ä»¶å¤¹é‡Œçš„opencvè‡ªå¸¦çš„æ–‡ä»¶å¤¹ã€‚ Imgcodecså’ŒImgprocç­‰éƒ½æ˜¯ä»¥å‰æ²¡æœ‰æŽ¥è§¦è¿‡çš„åº“ï¼Œå¦‚æžœéœ€è¦å›¾ç‰‡æ­£å¸¸æ˜¾ç¤ºï¼Œéœ€è¦æŠŠæ ¼å¼ä»ŽBGRæ”¹æˆRGB Texture2D è¿™ä¸ªæ˜¯å¤„ç†ç‰©ä½“è¡¨é¢çº¹ç†çš„ä¸€ä¸ªclassï¼Œæž„å»ºæ–°çš„çš„æ—¶å€™éœ€è¦ç¡®å®šè¿™ä¸ªtextureçš„å¤§å° åœ¨è¿™é‡Œéœ€è¦åˆ›å»ºä¸€ä¸ªæ–°çš„texture2Dï¼Œæ‰èƒ½åœ¨ä¹‹åŽæŠŠmatè½¬åˆ°textureé‡Œé¢ Utils.matToTexture2D(dst, tex) ç”¨äºŽmatå’Œçº¹ç†çš„è½¬æ¢ï¼ŒåŒæ ·ä¹Ÿæœ‰textureè½¬åˆ°matçš„æ–¹æ³• GetComponent() å¾—åˆ°è¿™ä¸ªgameObjectçš„ä¸€ä¸ªéƒ¨åˆ†ï¼Œå°–æ‹¬å·é‡Œé¢çš„åå­—å–å†³äºŽçŽ°åœ¨è¿™ä¸ªobjecté‡Œé¢æœ‰ä»€ä¹ˆ è¿™é‡Œç”¨çš„æ˜¯planeï¼Œé‡Œé¢è‡ªå¸¦rendererçš„å±žæ€§ï¼Œå¹¶ä¸”rendereré‡Œé¢å¸¦æœ‰materialï¼Œç”¨æ¥ä¿®æ”¹æž„æˆè¿™ä¸ªobjectçš„ææ–™ æ€»ç»“ ç”¨unityæ˜¾ç¤ºå›¾ç‰‡çš„ä¸­å¿ƒæ€æƒ³å°±æ˜¯è¿™ä¸ªå›¾ç‰‡å˜æˆäº†objectä¸Šé¢çš„textureï¼Œè¿™ä¸ªå›¾ç‰‡ä¸èƒ½è„±ç¦»objectè€Œç‹¬ç«‹å­˜åœ¨ï¼Œæ‰€ä»¥éœ€è¦é¦–å…ˆä¸ºè¿™ä¸ªå›¾ç‰‡æž„å»ºobject æœ€ç»ˆç»“æžœå¦‚ä¸‹ 123456789101112131415161718192021222324252627using System.Collections;using System.Collections.Generic;using UnityEngine;using OpenCVForUnity;using UnityEngine.UI;using OpenCVForUnity.ImgcodecsModule;using OpenCVForUnity.ImgprocModule;using OpenCVForUnity.CoreModule;public class remove : MonoBehaviour&#123; void Start() &#123; var dst = Imgcodecs.imread(Application.streamingAssetsPath + "/image.JPG"); Imgproc.cvtColor(dst, dst, Imgproc.COLOR_BGR2RGB); //Debug.Log(dst.channels()); Texture2D tex = new Texture2D(dst.width(), dst.height(), TextureFormat.RGBA32, false); OpenCVForUnity.UnityUtils.Utils.matToTexture2D(dst, tex); gameObject.GetComponent&lt;Renderer&gt;().material.mainTexture = tex; &#125;&#125;]]></content>
      <categories>
        <category>Unity</category>
        <category>OpenCV</category>
      </categories>
      <tags>
        <tag>å›¾åƒå¤„ç†</tag>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OmniProcamUnityæ–‡ä»¶æ€»ç»“]]></title>
    <url>%2F2019%2F08%2F19%2FOmniProcamUnity%E6%96%87%E4%BB%B6%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[æ–‡ä»¶æž„æˆ Lib libOmniProCam libOmniProCamCalibration OmniProcam Projection Camera ProjectionTarget RenderTexture Shader DebugUI LibOmniProCamManager å…¶ä¸­ï¼Œåœ¨libé‡Œé¢æœ‰calibrationç”¨çš„æŽ¥å£ï¼Œåœ¨é‡Œé¢è®¾å®šå¥½äº†æŠ•å½±ä»ªéœ€è¦çš„å‚æ•°æ•°é‡å’Œç›¸æœºéœ€è¦çš„å‚æ•°æ•°é‡ã€‚åœ¨libé‡Œé¢ç›´æŽ¥æ”¾äº†è€å¸ˆå†™å¥½çš„dllï¼Œæ‰€ä»¥å…¶å®žcsæ–‡ä»¶æ˜¯åœ¨è®¿é—®è¿™äº›dllçš„å†…å®¹ Camera ç›®çš„ï¼šåˆå§‹åŒ–ç›¸æœº å˜é‡ åˆ›å»ºä¸€ä¸ªclassï¼šcameraInitializerï¼Œç»§æ‰¿äº†Monobehaviour MonoBehaviouræ˜¯æ¯ä¸€ä¸ªunityçš„scriptçš„åŸºç¡€ç±» publicçš„gameobjectï¼Œç”¨æ¥å†³å®šsetupå“ªä¸ªç›¸æœºï¼Œè¿™ä¸ªç›¸æœºç›´æŽ¥ä»Žunityçš„UIé‡Œé¢æ‹½è¿›åŽ» protectedçš„cameraç±»ï¼Œtargetcamera projectedå¯ä»¥åœ¨è¿™ä¸ªclassä»¥åŠæ‰€æœ‰ç»§æ‰¿è¿™ä¸ªclassçš„é‡Œé¢è¢«è®¿é—®ï¼Œä½†æ˜¯privateåªèƒ½åœ¨è¿™ä¸ªclassä¸­è¢«è®¿é—® Cameraæ˜¯unityé‡Œé¢ä¸€ä¸ªè¡¨ç¤ºç›¸æœºçš„ç±» åˆ›å»ºäº†ä¸¤ä¸ªfloatçš„æ•°ç»„ï¼Œå¤§å°å’Œä¹‹å‰è®¾ç½®å¥½çš„ç›¸æœºå‚æ•°ï¼Œå’ŒæŠ•å½±ä»ªå‚æ•°ä¸€æ · åˆå§‹åŒ–ä¸‰ä¸ª4x4çš„çŸ©é˜µï¼Œåˆ†åˆ«æ˜¯ç›¸æœºçš„intrinsicï¼Œextrinsicä»¥åŠç›¸æœºçš„æŠ•å½±çŸ©é˜µ Matrix4x4å¯ä»¥è¡¨ç¤ºtransformationçš„çŸ©é˜µï¼ŒåŒ…æ‹¬å¹³ç§»æ—‹è½¬ç­‰ç­‰ å‡½æ•° void Awake() åŠŸèƒ½ åœ¨å¼€å§‹ä¹‹å‰åˆå§‹åŒ–variableæˆ–è€…game stateï¼Œåœ¨æ•´ä¸ªstripté‡Œé¢åªè¢«callä¸€æ¬¡ åœ¨æ‰€æœ‰çš„objectåˆå§‹åŒ–ç»“æŸä¹‹åŽ é€šå¸¸åœ¨startä¹‹å‰è¢«call æ•ˆæžœ åˆå§‹åŒ–äº†calibration è®¾å®šå¥½äº†ç›®æ ‡çš„ç›¸æœºï¼Œå¹¶ä¸”æŠŠè¿™ä¸ªç›¸æœºsetup protected void setupCamera(Camera targetCamera, int cameraIndex) ç›´æŽ¥calläº†dllé‡Œé¢å†™å¥½çš„åŠŸèƒ½ï¼ˆä½†æ˜¯è¿™é‡Œå¾—åˆ°çš„æ˜¯projectorçš„ï¼Œä¸ºä»€ä¹ˆï¼Ÿï¼‰ï¼Œå¾—åˆ°äº†å„ç§å‚æ•° å…³äºŽGChandle ç„¶åŽæŠŠdistortionå’Œéƒ½è®°å½•ä¸‹æ¥äº†ï¼Œç›´æŽ¥æŠŠtranslationå’Œrotationï¼ˆç›¸æœºçš„å¤–çŸ©é˜µï¼‰èµ‹å€¼ç»™äº†ç›®æ ‡ç›¸æœºã€è¿™æ ·ç›®æ ‡ç›¸æœºå°±èƒ½ç›´æŽ¥ç§»åŠ¨åˆ°åº”è¯¥åˆ°çš„ä½ç½®ä¸Šäº† å¦å¤–ä¸¤ä¸ªå‡½æ•°å¯ä»¥è¿”å›žè¿™é‡Œç›®å‰æ²¡æœ‰ç”¨åˆ°çš„distortion kï¼ˆ4ä¸ªï¼‰å’Œcï¼ˆ2ä¸ªï¼‰ device]]></content>
      <categories>
        <category>ç ”ç©¶å®¤</category>
        <category>OmniProcamV2</category>
      </categories>
      <tags>
        <tag>OmniProcam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Levenshtein Distanceçš„å…·ä½“åˆ†æž]]></title>
    <url>%2F2019%2F08%2F08%2FLevenshtein%2F</url>
    <content type="text"><![CDATA[ç¼–è¾‘è·ç¦» ç¼–è¾‘è·ç¦»æ˜¯è¡¡é‡å­—ç¬¦ä¸²ç›¸ä¼¼åº¦çš„è·ç¦» ä¸»è¦åº”ç”¨æ¯”å¦‚è¡¡é‡DNAçš„ç›¸ä¼¼æ€§ï¼Œè¡¡é‡ä»€ä¹ˆåœ°æ–¹æ–­å­—ï¼Œæ–‡ä»¶çš„å·®å¼‚ç­‰ç­‰ åŸºæœ¬æ“ä½œ å¯¹äºŽå­—ç¬¦ä¸²é‡Œé¢çš„ä¸¤ä¸ªå­—æ¯ï¼Œæœ‰ä¸‰ç§æ“ä½œæ–¹æ³•èƒ½è®©ä»–ä»¬æ”¹å˜ æ’å…¥ä¸€ä¸ªæ–°çš„å­—æ¯ åˆ é™¤ä¸€ä¸ªå·²ç»å­˜åœ¨çš„å­—æ¯ æŠŠçŽ°æœ‰çš„å­—æ¯æ›¿æ¢æˆå…¶ä»–å­—æ¯ å¯¹äºŽä¸¤ä¸ªstringï¼Œæœ‰å››ç§åŸºæœ¬çš„æ“ä½œ ç¬¬ä¸€ç§ï¼Œä¸å˜ ï¼ˆæ¯”å¦‚ruopengå’Œfagï¼‰ åŽŸæœ¬çš„æ“ä½œ ruopeng[0,6] -&gt; fag[0,2] å˜æ¢ä¹‹åŽ ruopen[0,5] -&gt; fa[0,1] å› ä¸ºæœ€åŽä¸€ä½ç›¸åŒï¼Œè¿™ä¸ªé—®é¢˜å¯ä»¥æ‹†åˆ†æˆæœ€åŽä¸€ä¸ªå­—æ¯ï¼Œå’Œä¸åŒ…æ‹¬æœ€åŽä¸€ä¸ªå­—æ¯çš„substringï¼Œè¿™ä¸ªé—®é¢˜å°±å¯ä»¥æ‹†åˆ†äº† ç¬¬äºŒç§ï¼Œæ›¿ä»£ replace ï¼ˆæ¯”å¦‚ peng å’Œ zhouï¼‰ åŽŸæœ¬æ“ä½œ peng[0,3] -&gt; zhou[0,3] å˜æ¢ä¹‹åŽ pen[0,2] -&gt; zho[0,2] + replace(g -&gt; u) å…¶ä¸­ï¼Œæ›¿æ¢çš„æ“ä½œæ˜¯ä¸€æ­¥ï¼Œæ›¿æ¢ä¹‹åŽæœ€åŽä¸€ä½çš„å­—æ¯ç›¸åŒï¼Œè¿™ä¸ªé—®é¢˜å°±å¯ä»¥æ‹†åˆ†æˆæ›´å°çš„é—®é¢˜äº† ç¬¬ä¸‰ç§ï¼Œæ’å…¥ insert åŽŸæœ¬æ“ä½œ peng[0,3] -&gt; zhou[0,3] å˜æ¢ä¹‹åŽ peng[0,3] -&gt; zho[0,2] + insert(u) é¦–å…ˆï¼Œç›´æŽ¥æŠŠè¿™ä¸ªé—®é¢˜é‡Œé¢çš„zhouæ‹†åˆ†æˆäº†æ›´å°çš„é—®é¢˜zhoï¼Œç„¶åŽå†è¿›è¡Œä¸€ä¸ªæ’å…¥æ“ä½œï¼ˆä¸€æ­¥ï¼‰ï¼Œä½¿zhoé‡æ–°å˜æˆäº†u ç¬¬å››ç§ï¼Œåˆ é™¤ deletion åŽŸæœ¬æ“ä½œ peng[0,3] -&gt; zhou[0,3] å˜æ¢ä¹‹åŽ pen[0,2] -&gt; zhou[0,3] + delete(g) åŒæ—¶ä¹Ÿå¯ä»¥å°è¯•å°è¯•åˆ é™¤æŽ‰å‰ä¸€ä¸ªstringé‡Œé¢çš„æœ€åŽä¸€ä¸ªå­—æ¯gï¼Œä¸å†ç®¡é‡Œé¢çš„gï¼ŒæŠŠè¿™ä¸ªå­—ç¬¦ä¸²å°è¯•å˜æˆpenæ¥è¿›è¡Œæ¯”è¾ƒ æ ¸å¿ƒæ€æƒ³ é¦–å…ˆï¼Œæˆ‘ä»¬é’ˆå¯¹è¿™ä¸¤ä¸ªstringåˆ¶ä½œä¸€ä¸ªtable å¯¹äºŽè¿™ä¸ªè¡¨æ¥è¯´ï¼Œæ¯ä¸€ä¸ªä½ç½®éƒ½ç›¸å½“äºŽè¿™ä¸ªä½ç½®å¯¹åº”çš„ä¸¤ä¸ªsubstringçš„ç›¸ä¼¼ç¨‹åº¦ï¼Œæ¯”å¦‚Eå’ŒFå¯¹åº”çš„å°±æ˜¯ â€RUOPEâ€œ å’Œ â€Fâ€œä¸¤ä¸ªsubstringå¯¹åº”çš„ç›¸ä¼¼åº¦ åœ¨æ¯ä¸ªå•è¯å¼€å§‹ä¹‹å‰ï¼Œè¿˜æœ‰ä¸€ä¸ªç©ºç™½ç¬¦å·ï¼Œå¯¹åº”çš„substringå°±æ˜¯ç©ºç™½ã€‚æ¯”å¦‚ç©ºç™½ç¬¦å·è¿™ä¸€åˆ—å¯¹åº”çš„å°±æ˜¯â€â€œåˆ†åˆ«å’Œâ€Fâ€œï¼Œâ€FAâ€œï¼Œâ€FANâ€œç­‰å…ƒç´ çš„æ¯”è¾ƒ å¯¹äºŽæ¯ä¸ªè¡¨æ ¼é‡Œé¢çš„ä½ç½®ï¼Œä»Ž(1,1)å¼€å§‹ï¼Œè¿™ä¸ªä½ç½®å’Œå‘¨å›´ä½ç½®çš„å…³ç³»å¦‚ä¸‹ ä¸Šé¢ä¸€æ ¼æ˜¯æ’å…¥ï¼ŒæŒ‡çš„æ˜¯åœ¨FANGZHOUè¿™ä¸ªstringçš„substringé‡Œé¢æ’å…¥ å·¦è¾¹ä¸€æ ¼æ˜¯åˆ é™¤ï¼ŒæŒ‡çš„æ˜¯æŠŠRUOPENGè¿™ä¸ªå•è¯åˆ é™¤ä¸€ä¸ªå­—æ¯ å·¦ä¸Šè§’ä¸€æ ¼æ˜¯æ›¿ä»£ï¼ŒæŒ‡çš„æ˜¯æŠŠè¿™ä¸¤ä¸ªå•è¯çš„å­—æ¯åˆ†åˆ«é€€ä¸€ä½ã€‚å¦‚æžœå½“å‰ä½çš„å­—æ¯ç›¸åŒï¼Œå½“å‰ä½çš„å€¼ç­‰äºŽé€€ä¸€ä½ä¹‹åŽçš„å€¼ï¼Œå¦‚æžœå½“å‰ä¸åŒï¼Œæ˜¯é€€ä¸€ä½çš„å€¼+æ›¿ä»£èŠ±è´¹çš„æ“ä½œï¼ˆä¹Ÿå°±æ˜¯1ï¼‰ è¡¨æ ¼åˆå§‹åŒ– é¦–å…ˆéœ€è¦ç¡®å®šè¿™ä¸ªè¡¨æ ¼çš„è¾¹ç¼˜æƒ…å†µï¼Œä¹Ÿå°±æ˜¯æ¨ªåæ ‡å’Œçºµåæ ‡åˆ†åˆ«æ˜¯0çš„éƒ¨åˆ†ï¼Œè¿™ä¸ªéƒ¨åˆ†ä¸èƒ½ç”¨ä¸Šé¢æ€»ç»“å‡ºæ¥çš„å…¬å¼è¡¨ç¤º å› ä¸ºè¿™éƒ¨åˆ†å…¶å®žå°±æ˜¯æŠŠä¸åŒçš„substringå’Œç©ºç™½ç¬¦å·æ¯”è¾ƒï¼Œé‚£ä¹ˆéœ€è¦çš„æœ€å°æ“ä½œå°±ç­‰äºŽå½“å‰å­—æ¯çš„ä½æ•° å¡«è¡¨ ä»Žå½“å‰çš„åˆå§‹çŠ¶å†µå‡ºå‘ï¼Œé€æ¸æŠŠè¿™ä¸ªè¡¨å¡«å®Œï¼Œæ¯ä¸€ä¸ªæ–°çš„æ ¼å­çš„å€¼éƒ½å–å†³äºŽä¸Šä¸€ä¸ªæ ¼å­çš„å€¼ insert = M[i-1][j]+1 delete = M[i][j-1] + 1 replace = M[i-1][j-1] + 1 dont change = M[i-1][j-1] ï¼ˆä¸¤ä¸ªå­—æ¯åŒ¹é…ï¼‰ å¦‚æžœä¸¤ä¸ªå­—æ¯ä¸åŒ¹é…çš„æ—¶å€™ï¼Œnow = min(insert,delete,replace) æœ€ç»ˆç»“æžœå¦‚ä¸‹ï¼Œçº¢è‰²éƒ¨åˆ†ä¸ºå­—æ¯ç›¸åŒéƒ¨åˆ† pythonä»£ç å®žçŽ°12345678910111213141516171819202122def EditDistance(a, b): m = len(a) n = len(b) # æž„å»ºè¡¨æ ¼ï¼Œæ³¨æ„éœ€è¦æ¯”é•¿åº¦å¤§ä¸€æ ¼ï¼Œå‚¨å­˜ç©ºå­—ç¬¦ä¸² M = [[0 for i in range(m + 1)] for j in range(n + 1)] # åˆå§‹åŒ–è¡¨æ ¼ï¼Œsubstringåˆ†åˆ«å’Œç©ºå­—ç¬¦ä¸²æ¯”è¾ƒ for i in range(1, n + 1): M[i][0] = i for i in range(1, m + 1): M[0][i] = i # DP for i in range(1, n + 1): for j in range(1, m + 1): # åˆ¤æ–­æ˜¯å¦ç›¸åŒï¼Œæ³¨æ„è¿™é‡Œè¦å‡ä¸€ if b[i - 1] == a[j - 1]: M[i][j] = M[i - 1][j - 1] else: insert = M[i - 1][j] + 1 delete = M[i][j - 1] + 1 replace = M[i - 1][j - 1] + 1 M[i][j] = min(insert, delete, replace) return M[n][m] æ³¨æ„åˆ†æ¸…çŸ©é˜µçš„è¡Œå’Œåˆ—ï¼Œåœ¨è¿™ä¸ªå®žçŽ°é‡Œaæ˜¯è¡Œï¼Œbæ˜¯åˆ— è€ƒè™‘åˆ°æœ€å‰é¢çš„ç©ºå­—ç¬¦ä¸² æ³¨æ„ä»Žstringé‡Œé¢è¯»å–çš„æ—¶å€™è¦è®°å¾—å‡1 æ³¨æ„æž„å»ºçŸ©é˜µçš„æ—¶å€™è¡Œæ•°å’Œåˆ—æ•°è¦åŠ ä¸€ å³ä¸‹è§’çš„ç»“æžœå°±æ˜¯ä¸¤ä¸ªå®Œæ•´å­—ç¬¦ä¸²å¯¹æ¯”çš„ç»“æžœ æ—¶é—´å¤æ‚åº¦ è¿™ä¸ªæ–¹æ³•éœ€è¦éåŽ†å·¦å³çš„substringçš„ç»„åˆï¼Œå¹¶ä¸”æŠŠæ‰€æœ‰çš„ç»“æžœéƒ½å­˜åœ¨ä¸€ä¸ªçŸ©é˜µé‡Œ å¦‚æžœä¸¤ä¸ªstringçš„é•¿åº¦åˆ†åˆ«æ˜¯må’Œnï¼Œé‚£ä¹ˆæ—¶é—´å¤æ‚åº¦O(mn),ç©ºé—´å¤æ‚åº¦O(mn) æœ€åŽï¼ŒRUOPENGåœ¨8æœˆ8å·è¿™å¤©ç¥è·ç¦»ä¸º8çš„FANGZHOUï¼Œå…«(7+1)å¤•å¿«ä¹]]></content>
      <categories>
        <category>ç®—æ³•</category>
        <category>åŠ¨æ€è§„åˆ’</category>
      </categories>
      <tags>
        <tag>åŠ¨æ€è§„åˆ’</tag>
        <tag>ç¼–è¾‘è·ç¦»</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ç®—æ³•å›¾è§£ç¬”è®°]]></title>
    <url>%2F2019%2F08%2F06%2F%E7%AE%97%E6%B3%95%E5%9B%BE%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[ç¬¬ä¸€ç«  ç®—æ³•ç®€ä»‹äºŒåˆ†æŸ¥æ‰¾ å¿…é¡»æ˜¯æœ‰åºçš„æ•°ç»„ å¯¹äºŽnä¸ªå…ƒç´ çš„åˆ—è¡¨ï¼Œä½¿ç”¨äºŒåˆ†æŸ¥æ‰¾æœ€å¤šéœ€è¦ log2 næ­¥ï¼Œç”¨æ™®é€šçš„æŸ¥æ‰¾æœ€å¤šéœ€è¦næ­¥1234567891011121314def binary_search(l, item): low = 0 high = len(l) - 1 while low &lt;= high: mid = int((low + high) / 2) # è¿™é‡Œéœ€è¦è½¬æˆintï¼Œä¸ç„¶æ²¡åŠžæ³•åšindex if l[mid] == item: return mid elif l[mid] &lt; item: low = mid + 1 else: high = mid - 1 return None è¿è¡Œæ—¶é—´ å¤§Oè¡¨ç¤ºæ³•è¡¨ç¤ºäº†æ“ä½œæ•°ï¼Œè¡¨ç¤ºçš„æ˜¯è¿™ä¸ªç®—æ³•çš„å¢žé‡ å¤§Oè¡¨ç¤ºäº†åœ¨æœ€ç³Ÿæƒ…å†µä¸‹çš„è¿è¡Œæ—¶é—´ -&gt; ä½†æ˜¯ä¹Ÿæ˜¯éœ€è¦è®¨è®ºå¹³å‡æ—¶é—´çš„ å¸¸è§çš„å¤§Oæ—¶é—´ logN å¯¹æ•°æ—¶é—´ Logarithmic N çº¿æ€§æ—¶é—´ Linear N * logN åŒ…æ‹¬å¿«é€ŸæŽ’åºç­‰ï¼Œé€Ÿåº¦è¾ƒå¿« N ^ 2 é€‰æ‹©æŽ’åºç­‰ï¼Œé€Ÿåº¦è¾ƒæ…¢ Nï¼ Factorial time éžå¸¸æ…¢ æ—…è¡Œå•†é—®é¢˜ travelling salesman problem, TSP ä¸€ä¸ªæžä¸å¥½å¯ä»¥ç”¨nï¼æ¥è§£å†³çš„é—®é¢˜ ä½ è¦åŽ»äº”ä¸ªä¸åŒçš„åœ°æ–¹ï¼Œéœ€è¦è§„åˆ’æ€Žä¹ˆæ ·è·¯çº¿æœ€çŸ­ï¼Œæœ€å¼€å§‹çš„æ€è·¯å°±æ˜¯æŠŠæ¯ç§å¯èƒ½æ€§éƒ½åˆ—å‡ºæ¥ï¼Œç„¶åŽå¯¹æ¯ç§è·¯çº¿è¿›è¡Œè®¡ç®—ã€‚è¿™æ ·çš„è¯äº”ä¸ªåœ°æ–¹å°±æ˜¯120ç§ï¼Œåœ°æ–¹è¶Šå¤šè¶Šå‘ˆé˜¶ä¹˜å¢žé•¿ ç¬¬äºŒç«  é€‰æ‹©æŽ’åºæ•°ç»„å’Œé“¾è¡¨ æ•°ç»„éœ€è¦çš„ç©ºé—´æ˜¯å›ºå®šçš„ï¼ˆä¹Ÿå°±æ˜¯è¯´å¿…é¡»è¿žåœ¨ä¸€èµ·ï¼‰ï¼Œæ‰€ä»¥å¦‚æžœåŽé¢åŠ è¿›åŽ»äº†å…¶ä»–ä¸œè¥¿çš„è¯å°±ä¸è¡Œäº†ï¼Œéœ€è¦è½¬ç§»ä½ç½®ï¼Œæˆ–è€…é¢„ç•™ç©ºé—´ é“¾è¡¨çš„æ¯ä¸€ä¸ªä½ç½®éƒ½ä¼šæœ‰åˆ°ä¸‹ä¸€ä¸ªä½ç½®çš„æŒ‡é’ˆï¼Œæ‰€ä»¥ä¸éœ€è¦ç§»åŠ¨å…ƒç´ ã€‚ ä½†æ˜¯é“¾è¡¨çš„é—®é¢˜åœ¨äºŽï¼Œå¦‚æžœæƒ³ç›´æŽ¥æ‰¾åŽé¢çš„ä¸œè¥¿çš„æ—¶å€™éœ€è¦ä¸€ä¸ªæŽ¥ç€ä¸€ä¸ªè¯»å– éœ€è¦è¯»å–æ•´ä¸ªæ•°æ®çš„æ—¶å€™é“¾è¡¨æ•ˆçŽ‡å¾ˆé«˜ï¼Œéœ€è¦è·³è·ƒçš„æ—¶å€™é“¾è¡¨æ•ˆçŽ‡å¾ˆä½Žã€‚è€Œæ•°ç»„åœ¨è¯»å–éšæœºå…ƒç´ çš„æ—¶å€™æ•ˆçŽ‡å¾ˆé«˜ æ•°ç»„æ’å…¥ / åˆ é™¤çº¿æ€§ï¼Œè¯»å–å¸¸æ•°ã€‚ é“¾è¡¨è¯»å–çº¿æ€§ï¼Œæ’å…¥ / åˆ é™¤å¸¸æ•°ã€‚ åœ¨å®žé™…ä¸­ï¼Œå› ä¸ºæ•°ç»„æ”¯æŒéšæœºè®¿é—®ï¼ˆä½†æ˜¯é“¾è¡¨åªæ”¯æŒé¡ºåºè®¿é—®ï¼‰ï¼Œæ‰€ä»¥æ•°ç»„çš„é€‚ç”¨èŒƒå›´å¤§ä¸€äº› é€‰æ‹©æŽ’åº å®žçŽ°æ–¹æ³•ï¼šæ¯æ¬¡éƒ½ä»Žæ‰€æœ‰çš„é‡Œé¢é€‰å‡ºæœ€å¤§ / æœ€å°ï¼Œç„¶åŽæ”¾åœ¨æœ€å¼€å¤´ æ—¶é—´å¤æ‚åº¦ n ^ 21234567891011121314def select_sort(l): newArr = [] for j in range(len(l)): smallest = float('inf') index = None for i, item in enumerate(l): if item &lt; smallest: smallest = item index = i newArr.append(l.pop(index)) # æ³¨æ„è¿™é‡Œéœ€è¦æŠŠlçš„å¤§å°æ”¹å˜äº† # ä½†æ˜¯æ˜¯åœ¨å¸¦lçš„loopå¤–é¢å˜å¾—æ‰€ä»¥æ²¡æœ‰å…³ç³» return newArr ç¬¬ä¸‰ç«  é€’å½’ recursionä½•ä¸ºé€’å½’ å‡½æ•°è‡ªå·±è°ƒç”¨è‡ªå·± é€’å½’å’Œå¾ªçŽ¯çš„ä½œç”¨æ•ˆæžœæ˜¯ç›¸åŒçš„ï¼Œæ²¡æœ‰æ€§èƒ½ä¸Šçš„ä¼˜åŠ¿ï¼Œä½†æ˜¯å¯ä»¥è®©æ–¹æ¡ˆæ›´åŠ æ¸…æ™° base caseï¼šå‘Šè¯‰å‡½æ•°ä»€ä¹ˆæ—¶å€™ä¸å†è°ƒç”¨è‡ªå·±ï¼Œåœæ­¢å¾ªçŽ¯ recursive caseï¼šå‡½æ•°è°ƒç”¨è‡ªå·± æ ˆ stack å…ˆè¿›åŽå‡ºçš„æ•°æ®ç»“æž„ï¼Œpushï¼ˆåŽ‹å…¥ï¼‰å’Œpopï¼ˆè¯»å–å’Œåˆ é™¤ï¼‰ åœ¨è°ƒç”¨å¦ä¸€ä¸ªå‡½æ•°çš„æ—¶å€™ï¼Œå½“å‰å‡½æ•°æš‚åœå¹¶ä¸”å¤„äºŽæœªå®ŒæˆçŠ¶æ€ï¼Œå‡½æ•°çš„æ‰€æœ‰å˜é‡éƒ½å‚¨å­˜åœ¨å†…å­˜é‡Œ ä½¿ç”¨é€’å½’çš„ä¸€ä¸ªé—®é¢˜ï¼šå¦‚æžœè°ƒç”¨æ ˆçš„æ—¶å€™å¾ˆé•¿ï¼Œä¼šå æ®å¤§é‡å†…å­˜ è¿™ç§æ—¶å€™éœ€è¦é‡æ–°ç¼–å†™ä»£ç ä½¿ç”¨å¾ªçŽ¯ æˆ–è€…ä½¿ç”¨å°¾é€’å½’ï¼ˆå¹¶ä¸æ˜¯æ‰€æœ‰è¯­è¨€éƒ½æ”¯æŒï¼‰ ç¬¬å››ç«  å¿«é€ŸæŽ’åºï¼ˆåˆ†è€Œæ²»ä¹‹ divide and conquerï¼‰åˆ†æ²» æ ¸å¿ƒï¼šæŠŠä¸€ä¸ªé—®é¢˜åˆ†æˆå­é—®é¢˜ï¼Œå†æŠŠå­é—®é¢˜åˆ†æˆæ›´å°çš„å­é—®é¢˜ï¼Œæœ€åŽçš„å­é—®é¢˜å¯ä»¥ç›´æŽ¥æ±‚è§£ï¼Œè¿™æ ·çš„è¯åŽŸé—®é¢˜çš„è§£å°±æ˜¯å­é—®é¢˜çš„è§£çš„åˆå¹¶ æ¯”å¦‚æŠŠnè§„æ¨¡çš„é—®é¢˜åˆ†æˆkä»½ï¼Œç„¶åŽåœ¨kä¸ªé—®é¢˜é‡Œé¢åˆ†åˆ«å†åˆ†å¼€ ç‰¹å¾ é—®é¢˜ç¼©å°è§„æ¨¡å¯ä»¥è½»æ¾è§£å†³ å¯ä»¥åˆ†è§£æˆè‹¥å¹²ä¸ªå°é—®é¢˜ åˆ†è§£å‡ºçš„å­é—®é¢˜å¯ä»¥å†åˆå¹¶ï¼ˆå¦‚æžœä¸æ»¡è¶³è¿™æ¡ï¼Œåº”è¯¥è€ƒè™‘è´ªå¿ƒæˆ–è€…DPï¼‰ åˆ†è§£å‡ºçš„å„ä¸ªå­é—®é¢˜æ˜¯ç‹¬ç«‹çš„ï¼ˆä¸æ»¡è¶³åº”è¯¥è€ƒè™‘DPï¼‰ ä¸ç”¨å¾ªçŽ¯è€Œç”¨é€’å½’ï¼šå‡½æ•°å¼ç¼–ç¨‹é‡Œé¢æ²¡æœ‰å¾ªçŽ¯ï¼ˆHaskellï¼‰ 1234567891011121314def RecursiveSum(l): if l == []: return 0 else: return l[0] + RecursiveSum(l[1:]) # è¿™é‡Œä¸èƒ½æ”¹å˜læœ¬èº«çš„å¤§å°def MaxNum(l): if len(l) == 2: return l[0] if l[0] &gt; l[1] else l[1] submax = MaxNum(l[1:]) return l[0] if l[0] &gt; submax else submax æ³¨æ„ï¼š éœ€è¦æ‰¾å¥½åŸºæœ¬æ¡ä»¶ï¼Œå¦‚æžœæ‰¾æœ€å¤§å€¼çš„baseå°±æ˜¯è¿˜å‰©ä¸‹ä¸¤ä¸ªå€¼ æ³¨æ„returnçš„å†…å®¹ å¿«é€ŸæŽ’åº æ¯”é€‰æ‹©æŽ’åºé€Ÿåº¦å¿«å¾ˆå¤š baseæ¡ä»¶ï¼Œä¸€ä¸ªå…ƒç´ æˆ–è€…ç©ºçš„æ•°ç»„å°±ä¸éœ€è¦æŽ’åºäº† éœ€è¦è®¾å®šä¸€ä¸ªåŸºæœ¬å€¼ï¼ˆæ¯”å¦‚å–ç¬¬ä¸€ä¸ªå€¼ï¼Œæ ¹æ®è¿™ä¸ªå€¼æŠŠåŽŸæ•°ç»„åˆ†æˆä¸¤éƒ¨åˆ†ï¼‰ï¼Œè¿™æ ·è¿™ä¸‰ä¸ªå¤§å—å°±åˆ†ç±»å®Œæˆäº†ã€‚ç„¶åŽå¯¹äºŽæ¯ä¸ªå°å—ï¼Œå†ç»§ç»­åˆ†ç»„ æ¯”åŸºå‡†å°çš„å­æ•°ç»„ åŸºå‡† æ¯”åŸºå‡†å¤§çš„å­æ•°ç»„1234567891011121314def QuickSort(l): if len(l) &lt; 2: return l else: piv = l[0] # è¿™é‡Œæ˜¯å¿«è¯»å¾—åˆ°æ¯”ä»–å¤§å’Œæ¯”ä»–å°çš„å†™æ³•ï¼Œä¸»è¦ä»Žl[1:]å¼€å§‹ less_part = [i for i in l[1:] if i &lt; piv] more_part = [i for i in l[1:] if i &gt; piv] return QuickSort(less_part) + [piv] + QuickSort(more_part) # æ³¨æ„è¿™é‡Œpivæ˜¯ä¸ªintï¼Œæ‰€ä»¥è¿žæŽ¥çš„æ—¶å€™éœ€è¦æ”¹æˆlist æ—¶é—´å¤æ‚åº¦ å¿«é€ŸæŽ’åºçš„é€Ÿåº¦å–å†³äºŽé€‰æ‹©çš„pivçš„å€¼çš„å¤§å°ï¼Œä¹Ÿå°±æ˜¯è¯´å¦‚æžœå®Œå…¨æŽ’å¥½çš„æƒ…å†µä¸‹ï¼Œå¤æ‚åº¦æ˜¯n2 åˆå¹¶æŽ’åºçš„é€Ÿåº¦æ˜¯ nlognï¼Œå¿«é€ŸæŽ’åºçš„å¹³å‡é€Ÿåº¦æ˜¯ nlognï¼Œæœ€ä½³æƒ…å†µæ˜¯ logn å¿«é€ŸæŽ’åºéœ€è¦lognå±‚ï¼Œæ¯å±‚éœ€è¦æŠŠnä¸ªå…ƒç´ å…¨éƒ½éåŽ†ä¸€æ¬¡ï¼Œæ‰€ä»¥æœ€ç»ˆçš„ç»“æžœæ˜¯nlogn åœ¨è®¡ç®—å¤æ‚åº¦çš„æ—¶å€™ï¼Œå¤æ‚åº¦æ˜¯æ“ä½œçš„æ¬¡æ•°ï¼Œè€Œè¿™ä¸ªæ¬¡æ•°éœ€è¦ä¹˜ä¸€ä¸ªæ¯æ¬¡æ“ä½œçš„å¸¸é‡ï¼Œåœ¨å¿«é€ŸæŽ’åºçš„æ—¶å€™å¸¸é‡æ›´å°ï¼Œè€Œä¸”å¿«é€ŸæŽ’åºæ²¡é‚£ä¹ˆå®¹æ˜“é‡åˆ°æœ€ç³Ÿæƒ…å†µ ç¬¬äº”ç«  æ•£åˆ—è¡¨ï¼ˆhashè¡¨ï¼‰hashå‡½æ•° æœ€ç»ˆçš„ç›®çš„æ˜¯æŸ¥æ‰¾çš„æ—¶å€™æ—¶é—´å¤æ‚åº¦æ˜¯ 1 å‡½æ•°æž„é€ ï¼šæŠŠè¾“å…¥æ˜ å°„åˆ°ä¸€ä¸ªæ•°å­— æ— è®ºä½ ä»€ä¹ˆæ—¶å€™è¾“å…¥ï¼Œè¾“å‡ºçš„æ•°å­—æ˜¯ä¸€è‡´çš„ å°†ä¸åŒçš„è¾“å…¥æ˜ å°„åˆ°ä¸åŒçš„æ•°å­— çŸ¥é“æ•´ä¸ªå­˜å‚¨çš„èŒƒå›´æœ‰å¤šå¤§ï¼Œä¸ä¼šè¿”å›žè¶…è¿‡è¿™ä¸ªå¤§å°çš„æ•°å­— åº”ç”¨ï¼šç¼“å­˜ ç½‘ç«™çš„ç¼“å­˜æ•°æ®å°±å­˜åœ¨hashè¡¨é‡Œé¢ï¼Œè¿™æ ·è®¿é—®é€Ÿåº¦æ›´å¿«ï¼Œç½‘ç«™æœ¬èº«éœ€è¦åšçš„å·¥ä½œæ›´å°‘ è®¿é—®ä¸€ä¸ªç½‘é¡µ -&gt; æ˜¯å¦åœ¨ç¼“å­˜é‡Œ -&gt; æœ‰çš„è¯è°ƒç”¨ç¼“å­˜ -&gt; æ²¡æœ‰çš„è¯å­˜è¿›ç¼“å­˜ å†²çª è™½ç„¶å‡è®¾çš„æ—¶å€™è®¤ä¸ºæ¯ä¸ªä¸œè¥¿éƒ½è¢«æ˜ å°„åˆ°ä¸åŒåœ°æ–¹ï¼Œå…¶å®žä¼šäº§ç”Ÿå†²çª è¿™ç§æƒ…å†µä¸‹è¦åœ¨hashåŽé¢åŠ ä¸Šlist hashå‡½æ•°éœ€è¦æŠŠå†…å®¹æ¯”è¾ƒå¹³å‡åˆ†åˆ†é… å¦‚æžœå‚¨å­˜çš„é“¾è¡¨å¾ˆé•¿ï¼Œé‚£ä¹ˆæ€§èƒ½å°±ä¼šæ€¥å‰§ä¸‹é™ æ€§èƒ½ æœ€ä½³æ€§èƒ½ï¼Œ1 æœ€ç³Ÿæ€§èƒ½ï¼Œæ’å…¥ï¼Œåˆ é™¤ï¼ŒæŸ¥è¯¢å…¨éƒ½æ˜¯n è£…å¡«å› å­ï¼š è£…å¡«çš„å…ƒç´ æ•° / å…ƒç´ æ€»æ•° ä¸€æ—¦è¶…è¿‡0.7å°±éœ€è¦è°ƒæ•´hashçš„é•¿åº¦äº† ç¬¬å…­ç«  BFSï¼šæœ€çŸ­è·¯å¾„é—®é¢˜BFS ç”¨äºŽå›¾çš„æŸ¥æ‰¾ç®—æ³•ï¼Œå¯ä»¥è§£å†³ä¸¤ç§é—®é¢˜ ä»ŽAå‡ºå‘æœ‰å‰å¾€Bçš„è·¯å¾„å— ä»ŽAå‡ºå‘åˆ°Bçš„è·¯å¾„æœ€çŸ­æ˜¯ä»€ä¹ˆ å®žçŽ°å›¾ -&gt; hashè¡¨ï¼Œéœ€è¦å°†nodeæ˜ å°„åˆ°æ‰€æœ‰çš„é‚»å±… åœ¨pythoné‡Œé¢ä½¿ç”¨dequeåˆ›å»ºåŒç«¯é˜Ÿåˆ— ç®—æ³•å®žçŽ°ï¼ˆå¹¿åº¦æœç´¢ï¼‰ï¼š åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—ï¼Œå‚¨å­˜ç”¨äºŽæŸ¥æ‰¾çš„äºº é¦–å…ˆæŠŠåˆå§‹åŒ–çš„äººè½½å…¥é˜Ÿåˆ— ä»Žé˜Ÿåˆ—é‡Œå¼¹å‡ºä¸€ä¸ªäººï¼ŒæŸ¥æ‰¾ä»–æ˜¯ä¸æ˜¯ï¼ˆæŸ¥è¿‡ä¹‹åŽæ ‡è®°æˆå·²æ£€æŸ¥ï¼Œåˆ—è¡¨è®°å½•ï¼‰ï¼Œä¸æ˜¯çš„è¯æŠŠè¿™ä¸ªäººçš„ç›¸é‚»åŠ å…¥é˜Ÿåˆ—ï¼ˆä¸€ç›´é‡å¤ï¼‰ æ ‡è®°æˆå·²æ£€æŸ¥éžå¸¸é‡è¦ï¼Œå› ä¸ºä¸æ ‡è®°çš„è¯å¯èƒ½ä¼šé™·å…¥æ— é™å¾ªçŽ¯ å¦‚æžœæœ€åŽé˜Ÿåˆ—ç©ºäº†è¿˜æ²¡æ‰¾åˆ°ï¼Œé‚£å°±æ˜¯æ²¡æœ‰ 123456789101112131415def BFS(name, graph): search_queue = deque() search_queue += graph[name] searched = [name] # ç”¨æ¥å‚¨å­˜å·²ç»æŽ¢ç´¢è¿‡çš„äººæ•° while search_queue: person = search_queue.popleft() if person not in searched: if person[-1] == "m": # åªæ˜¯ä¸€ä¸ªåˆ¤æ–­æ˜¯ä¸æ˜¯è¿™ä¸ªäººçš„åŠžæ³• return person else: search_queue += graph[person] searched.append(person) return None æ›´æ–°ç‰ˆæœ¬ï¼Œä¸ä½†å¯ä»¥æœç´¢è¿˜å¯ä»¥è®¡ç®—é•¿åº¦12345678910111213141516def BFS(name, graph): search_queue = deque() search_queue.append(name) searched = [name] # ç”¨æ¥å‚¨å­˜å·²ç»æŽ¢ç´¢è¿‡çš„äººæ•° distance = &#123;name: 0&#125; while search_queue: current = search_queue.popleft() for person in graph[current]: if person not in searched: searched.append(person) distance[person] = distance[current] + 1 if person[-1] == "m": return person, distance[person] else: search_queue.append(person) return None, None æ³¨æ„ç‚¹ï¼š å¢žåŠ äº†distanceè¿™ä¸ªdictæ¥å‚¨å­˜å¼€å§‹ç‚¹åˆ°è¿™ä¸ªç‚¹çš„è·ç¦» åœ¨åˆå§‹åŒ–çš„æ—¶å€™åªåœ¨å·²æœç´¢é˜Ÿåˆ—é‡Œæ·»åŠ äº†ç¬¬ä¸€ä¸ªç‚¹çš„ä¿¡æ¯ï¼Œåœ¨åŽé¢çš„å¾ªçŽ¯é‡Œæ‰æ·»åŠ åŽé¢çš„ç‚¹ å¯¹äºŽæ¯ä¸ªä»Žqueueé‡Œé¢æ‹¿å‡ºæ¥çš„ç‚¹ï¼Œå¦‚æžœä¸åœ¨å·²ç»æŸ¥æ‰¾çš„ç‚¹é‡Œå°±ä¸€å®šéœ€è¦åŠ è¿›åŽ»ï¼Œå¹¶ä¸”è®¡ç®—è·ç¦»ï¼Œè·ç¦»å³æ˜¯å’Œä¸Šä¸€ç‚¹çš„è·ç¦»+1 è®¡ç®—è¿‡è·ç¦»ä¹‹åŽå†åˆ¤æ–­æ˜¯ä¸æ˜¯è¦æ‰¾çš„ç‚¹ è¿è¡Œæ—¶é—´ éœ€è¦æ²¿ç€æ¯æ¡è¾¹å‰è¿›ï¼Œæ‰€ä»¥åœ¨è¾¹ä¸Šçš„è¿è¡Œæ—¶é—´æ˜¯ O(E) æŠŠæ¯ä¸ªäººåŠ åˆ°queueé‡Œé¢ä¹Ÿéœ€è¦æ—¶é—´ï¼Œæ¯ä¸ªäººçš„æ—¶é—´æ˜¯å¸¸æ•°ï¼Œæ‰€ä»¥äººæ•°çš„æ—¶é—´æ˜¯ O(V) æ€»çš„è¿è¡Œæ—¶é—´ E + V æ‹“æ‰‘æŽ’åº å¦‚æžœä»»åŠ¡Aä¾èµ–äºŽä»»åŠ¡Bï¼Œé‚£ä¹ˆä»»åŠ¡Aå°±å¿…é¡»æŽ’åœ¨Bçš„åŽé¢ï¼Œè¿™ç§å°±æ˜¯æ‹“æ‰‘æŽ’åº ç¬¬ä¸ƒç«  ç‹„å…‹æ–¯ç‰¹æ‹‰ç®—æ³• ä¹‹å‰çš„å›¾æ‰¾çš„æ˜¯æœ€çŸ­è·¯å¾„ï¼ŒçŽ°åœ¨éœ€è¦ç»™å›¾åŠ æƒï¼Œæ‰¾åŠ æƒä¹‹åŽçš„æœ€çŸ­è·¯å¾„ åŠ æƒä¹‹åŽçš„æœ€çŸ­ä¸ä¸€å®šæ˜¯è¾¹æ•°æœ€çŸ­ è´Ÿçš„æƒé‡ä¸é¡¶ç”¨ï¼Œå› ä¸ºè´Ÿæƒé‡ä¸èƒ½ç¡®å®šæ²¡æœ‰æ¯”ç›®å‰æ¶ˆè€—æ›´å°çš„ ä¹¦é‡Œå†™çš„é”™çš„åœ°æ–¹ï¼šå¯ä»¥æœ‰çŽ¯ï¼Œæ²¡çŽ¯éƒ½æ˜¯æ ‘äº†ï¼æœ‰å‘æ— çŽ¯å›¾å¯ä»¥ç›´æŽ¥æ‹“æ‰‘æŽ’åº æ ¸å¿ƒæ€æƒ³ï¼šæ‰¾åˆ°åˆ°è¿™ä¸ªç‚¹æ¶ˆè€—æœ€å°‘çš„è·¯å¾„ï¼Œå¹¶ä¸”ç¡®ä¿æ²¡æœ‰è·¯å¾„æ¯”è¿™ä¸ªå°äº† ç®—æ³•æµç¨‹ æ‰¾å‡ºæ¶ˆè€—æœ€ä½Žçš„ç‚¹ æ›´æ–°è¿™ä¸ªç‚¹ç›¸é‚»ç‚¹çš„å¼€é”€ é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œç›´åˆ°å¯¹æ‰€æœ‰ç‚¹éƒ½åšäº†ï¼ˆå³Aç‚¹æœ€å°ä¹‹åŽæ›´æ–°Bç‚¹ï¼Œç„¶åŽæ›´æ–°Cç‚¹ï¼Œä»¥æ­¤ç±»æŽ¨ï¼‰ è®¡ç®—æœ€ç»ˆæµç¨‹ å…·ä½“å®žçŽ° åˆ›å»ºä¸€ä¸ªè¡¨æ ¼ åŒ…å«äº†æ¯ä¸€é¡¹å’Œæ¯ä¸€é¡¹çš„å…·ä½“å¼€é”€ï¼Œç›®å‰ä¸çŸ¥é“çš„å¼€é”€æ ‡è®°æˆinf éœ€è¦åŒ…å«æ¯ä¸ªç‚¹çš„çˆ¶èŠ‚ç‚¹ï¼Œæ‰èƒ½ä¿è¯æœ€åŽå¯ä»¥è®¡ç®—æµç¨‹ ä¸åœçš„æ›´æ–°è¿™ä¸ªè¡¨ï¼Œä»Žå¼€é”€æœ€ä½Žçš„ä¸€ç›´æ›´æ–°åˆ°å¼€é”€æœ€é«˜çš„ï¼Œå¦‚æžœæ›´æ–°äº†å¼€é”€çš„è¯åŒæ ·éœ€è¦æ›´æ–°çˆ¶èŠ‚ç‚¹ åœ¨ç¡®å®šè·¯å¾„çš„æ—¶å€™ï¼Œä»Žç»“å°¾çš„åœ°æ–¹å¼€å§‹æ‰¾ï¼Œç„¶åŽä¸€è·¯æ‰¾åˆ°å¼€å¤´ ä¸€ä¸ªé—®é¢˜ï¼šå…³äºŽå›¾åœ¨pythoné‡Œé¢çš„è¡¨ç¤º å®žé™…å°±æ˜¯ä¸€ä¸ªdictå dictï¼Œå¦‚æžœç›´æŽ¥è®¿é—®G[a][b]å°±å¯ä»¥ç›´æŽ¥å¾—åˆ°è¿™ä¸¤ä¸ªç‚¹çš„è·ç¦» å¦‚æžœæ²¡æœ‰åŠ æƒçš„è¯ï¼Œå¯ä»¥ç›´æŽ¥dictå listï¼Œå› ä¸ºä¸éœ€è¦è®°å½•è·ç¦»äº† æ³¨æ„ç‚¹ æœ€å¥½æ˜¯æœ€å¼€å§‹æŒ‡å®šäº†ç¬¬ä¸€ä¸ªæ¶ˆè€—æœ€ä½Žç‚¹ï¼Œç„¶åŽå†å¾ªçŽ¯é‡Œé¢æœ€åŽæ‰¾æ¶ˆè€—æœ€ä½Žç‚¹ åˆå§‹åŒ–çš„æ—¶å€™æ³¨æ„ï¼šcosté‡Œé¢åˆå§‹ä¸º0ï¼Œfatheré‡Œé¢åŽ»æŽ‰è¿™ä¸ªç‚¹ï¼ŒNodeï¼ˆcostæœ€ä½Žç‚¹ï¼‰åˆå§‹åŒ–æˆè¿™ä¸ªç‚¹ï¼Œå¾ªçŽ¯çš„æ¡ä»¶æ˜¯Nodeä¸æ˜¯ç©º123456789101112131415161718192021222324252627282930313233343536373839404142def dijkstra(graph, src, target): # éœ€è¦åˆ›å»ºä¸€ä¸ªcostè¡¨å’Œä¸€ä¸ªçˆ¶èŠ‚ç‚¹è¡¨ cost = &#123;&#125; father = &#123;&#125; visited = [] for i in graph.keys(): # è®¿é—®è¿™ä¸ªå›¾é‡Œé¢æ‰€æœ‰çš„keyï¼Œå°±æ˜¯æ‰€æœ‰çš„åº— cost[i] = float('inf') father[i] = None cost[src] = 0 # èµ·å§‹ç‚¹çš„costæ˜¯0 father.pop(src) # èµ·å§‹ç‚¹ä¸éœ€è¦çˆ¶èŠ‚ç‚¹ Node = src # æœ€å°å¼€é”€ç‚¹è¿˜å­˜åœ¨çš„æ—¶å€™æ›´æ–°æ‰€æœ‰çš„ç‚¹ while Node is not None: for near in graph[Node]: new_distance = cost[Node] + graph[Node][near] if new_distance &lt; cost[near]: cost[near] = new_distance father[near] = Node visited.append(Node) # æ‰¾åˆ°æœ€å°å¼€é”€çš„ç‚¹(æ”¾åœ¨å¾ªçŽ¯é‡Œé¢å¥½ä¸€ç‚¹) Node = None smallest = float('inf') for i in cost: if i not in visited: if cost[i] &lt; smallest: smallest = cost[i] Node = i # è·³å‡ºå¾ªçŽ¯ï¼Œå¾—åˆ°ç»“æžœ N = &#123; "start": &#123;"a": 2, "b": 6&#125;, "a": &#123;"fin": 1&#125;, "b": &#123;"a": 3, "fin": 5&#125;, "fin": &#123;&#125;&#125;# print(N["start"]["a"])dijkstra(N, "start", "fin") ç¬¬å…«ç«  è´ªå¿ƒç®—æ³• å¤„ç†npcé—®é¢˜ï¼Œå³æ²¡æœ‰å¿«é€Ÿç®—æ³•çš„è§£æ³•çš„é—®é¢˜ å¯¹NPCé—®é¢˜æ‰¾åˆ°è¿‘ä¼¼è§£ ä¾‹å­é—®é¢˜ è¯¾è¡¨é—®é¢˜ï¼š å¸Œæœ›å°½å¯èƒ½å¤šçš„è¯¾åœ¨è¿™ä¸ªå±‹å­é‡Œé¢ä¸Šï¼Œä½†æ˜¯ä¸Šè¯¾æ—¶é—´å†²çªï¼Œå¦‚ä½•æŽ’è¯¾ å…ˆæ‰¾åˆ°è¿™ä¸ªæ•™å®¤é‡Œæœ€æ—©å¼€å§‹çš„è¯¾ï¼Œç„¶åŽæ‰¾åˆ°è¿™èŠ‚è¯¾ç»“æŸä¹‹åŽæœ€æ—©å¼€å§‹çš„è¯¾ è£…ä¸œè¥¿ èƒŒç€åŒ…åŽ»è£…ä¸œè¥¿ï¼Œå®¹é‡æœ‰é™ï¼Œå¦‚ä½•è£…åˆ°æœ€å¤§ä»·å€¼çš„ ä»Žæœ€å¤§çš„å¼€å§‹è£…ï¼Œä½†æ˜¯å¾—åˆ°çš„ä¸æ˜¯æœ€ä¼˜è§£ï¼Œæœ€ä¼˜è§£åº”è¯¥åŠ¨æ€è§„åˆ’ æ ¸å¿ƒæ€æƒ³ï¼šæ¯ä¸€æ­¥éƒ½ç”¨å±€éƒ¨æœ€ä¼˜è§£ï¼Œå¾—åˆ°çš„ç»“æžœå°±æ˜¯å…¨å±€æœ€ä¼˜è§£ã€‚å³ä½¿å¾—ä¸åˆ°æœ€ä¼˜è§£ï¼Œä¹Ÿå¯ä»¥å¾—åˆ°è¿‘ä¼¼æœ€ä¼˜è§£ åªèƒ½ç”¨è´ªå¿ƒçš„é—®é¢˜ é›†åˆè¦†ç›–é—®é¢˜ï¼Œæ¯”å¦‚æƒ³åœ¨å…¨éƒ¨åŒºåŸŸå¹¿æ’­ï¼Œä½†æ˜¯æ¯å®¶ç”µå°åªè¦†ç›–ç‰¹å®šåŒºåŸŸï¼Œå¦‚æžœæ‰èƒ½èŠ±è´¹æœ€å°çš„è®¡åˆ’ åˆ—å‡ºæ‰€æœ‰çš„å¯èƒ½æ€§çš„è¯ï¼Œå¤æ‚åº¦æ˜¯ 2^n è¿‘ä¼¼ç®—æ³•ï¼šä»Žè¦†ç›–æœ€å¤šåœ°æ–¹çš„ç”µå°å¼€å§‹æ‰¾ï¼Œä¸€ç›´åˆ°è¦†ç›–æ‰€æœ‰åœ°æ–¹ è´ªå¿ƒç®—æ³•çš„å¤æ‚åº¦æ˜¯ n^2ï¼Œnæ˜¯å¹¿æ’­å°çš„æ•°é‡ å› ä¸ºæ¯æ¬¡éƒ½éœ€è¦éåŽ†ä¸€æ¬¡æ‰¾å‡ºæœ€éœ€è¦çš„é‚£ä¸ªï¼ˆn)ï¼Œè¿™æ ·çš„æ“ä½œéœ€è¦è¿›è¡Œæœ€å¤šnæ¬¡ï¼ˆä¸‡ä¸€æ¯æ¬¡éƒ½è¦†ç›–ä¸ä¸Šï¼‰ NPCé—®é¢˜ï¼šä»Žæ—…è¡Œå•†é—®é¢˜è¯¦è§£ æ—…è¡Œå•†é—®é¢˜å’Œæ±‚è·¯å¾„é—®é¢˜çš„åŒºåˆ«åœ¨äºŽï¼Œæ—…è¡Œå•†é—®é¢˜éœ€è¦è®¿é—®ä¸€éæ‰€æœ‰çš„åœ°æ–¹ï¼Œæ‰¾åˆ°æœ€çŸ­è·¯çº¿ æ—…è¡Œå•†é—®é¢˜éœ€è¦æŸ¥çœ‹æ‰€æœ‰çš„å¯èƒ½çš„è·¯çº¿ ä»Žç®€å•é—®é¢˜å‡ºå‘ ä¸¤ä¸ªåœ°æ–¹çš„æ—¶å€™ï¼Œå¯èƒ½çš„è·¯çº¿æœ‰ä¸¤æ¡ï¼ˆä¸€æ¥ä¸€å›žï¼‰ ä¸‰ä¸ªåœ°æ–¹çš„æ—¶å€™ 6æ¡ éœ€è¦è®¡ç®—å‡ºæ‰€æœ‰çš„è§£æ‰æœ‰å¯èƒ½ä»Žä¸­é€‰å‡ºæœ€çŸ­çš„è·¯çº¿ -&gt; NPCé—®é¢˜ è¿‘ä¼¼æ–¹æ³•ï¼šæ¯æ¬¡éƒ½åŽ»ç¦»å¾—æœ€è¿‘çš„åœ°æ–¹ è¯†åˆ«é—®é¢˜ å…ƒç´ è¾ƒå°‘çš„æ—¶å€™é€Ÿåº¦å¿«ï¼Œéšç€å…ƒç´ å¢žåŠ éžå¸¸æ…¢ æ¶‰åŠæ‰€æœ‰ç»„åˆ ä¸èƒ½åˆ†æˆå°é—®é¢˜ï¼Œå¿…é¡»è€ƒè™‘æ‰€æœ‰æƒ…å†µ æ¶‰åŠåºåˆ—ï¼ˆæ¯”å¦‚æ—…è¡Œå•†ä¸­çš„åŸŽå¸‚åºåˆ—ï¼‰ï¼Œé›†åˆï¼ˆé›†åˆè¦†ç›–é—®é¢˜ï¼‰ä¸”éš¾ä»¥è§£å†³ã€‚æˆ–è€…å¯ä»¥è½¬æ¢æˆè¿™ç§é—®é¢˜çš„ ç¬¬ä¹ç«  åŠ¨æ€è§„åˆ’æ ¸å¿ƒæ€æƒ³ æŠŠä¸€ä¸ªå¤§çš„é—®é¢˜æ‹†åˆ†æˆå¾ˆå¤šå°é—®é¢˜çš„è§£çš„åˆå¹¶ æœ€ç»ˆçš„ç»“æžœå…¶å®žç±»ä¼¼ä¸€ä¸ªè¡¨ï¼Œæ¯æ¬¡å†å¾—åˆ°æ–°çš„ç»“æžœçš„æ—¶å€™ï¼Œå…¶å®žæ˜¯åœ¨æ¯”è¾ƒ åŒç­‰å¤§å°ä¸‹ä¸Šä¸€ä¸ªçš„å€¼ï¼ˆå³ä¸Šä¸€è¡Œçš„å€¼ï¼Œè¿™ä¸ªå€¼å·²ç»æ˜¯ä¹‹å‰å‚¨å­˜ä¸‹æ¥çš„æœ€å¤§çš„å€¼äº†ï¼‰ å½“å‰æ”¾æ–°çš„ä¸œè¥¿çš„ä»·å€¼+æ”¾å®Œè¿™ä¸ªä¸œè¥¿ä¹‹åŽå‰©ä¸‹ç©ºé—´å¯ä»¥æ”¾çš„ä¸œè¥¿çš„æœ€å¤§ä»·å€¼ï¼ˆè¿™ä¸ªæœ€å¤§ä»·å€¼åŒæ ·ä¹Ÿè¢«è®°å½•äº†ï¼‰ DPå¤„ç†é—®é¢˜çš„æ—¶å€™åªèƒ½æ•´ä»¶çš„å¤„ç†ï¼Œä¹Ÿå°±æ˜¯è¯´åˆ†å¸ƒåº”è¯¥æ˜¯ç¦»æ•£çš„è€Œä¸æ˜¯è¿žç»­çš„ è€Œä¸”DPå¤„ç†é—®é¢˜çš„æ—¶å€™å„ä¸ªå­é—®é¢˜ä¹‹é—´ä¸èƒ½äº’ç›¸ä¾èµ–ï¼Œå¦‚æžœäº’ç›¸ä¾èµ–äº†å°±å¾ˆå¤æ‚äº† æœ€é•¿å…¬å…±å­ä¸² æ¯”å¦‚æœç´¢å¼•æ“Žè¯¯è¾“å…¥ï¼Œæ€Žä¹ˆåˆ¤æ–­ç›¸è¿‘è¯ æ¯ç§åŠ¨æ€è§„åˆ’éƒ½æ¶‰åŠç½‘ç»œï¼Œæ¯ä¸ªç½‘æ ¼é‡Œé¢çš„å€¼å°±æ˜¯æˆ‘éœ€è¦ä¼˜åŒ–çš„å€¼ æ¯ä¸ªå•å…ƒæ ¼é‡Œæ˜¯ä»€ä¹ˆ æ¯ä¸ªå•å…ƒæ ¼æ˜¯è¿™ä¸ªæ ¼å­ä¹‹å‰ç›¸åŒçš„å­—æ¯æ•°é‡ å¦‚ä½•æŠŠè¿™ä¸ªé—®é¢˜åˆ†æˆå­é—®é¢˜ å¦‚æžœç›¸åŒï¼Œå°±æ˜¯å‰ä¸€ä¸ªçš„å­—æ¯æ•°+1ï¼Œå¦‚æžœä¸åŒå°±æ˜¯0 ç½‘ç»œçš„åæ ‡è½´æ˜¯ä»€ä¹ˆ åœ¨è¿™ä¸ªé—®é¢˜ä¸­ï¼Œæ˜¯ä¸¤ä¸ªå•è¯çš„å„ä¸ªå­—æ¯ æ³¨æ„åœ¨è¿™ä¸ªé—®é¢˜é‡Œé¢ï¼Œæœ€ç»ˆç­”æ¡ˆä¸æ˜¯åœ¨æœ€åŽå‡ºçŽ°çš„ æœ€é•¿å…¬å…±å­—åºåˆ—ï¼ï¼å’Œå­ä¸²ä¸ä¸€æ ·ï¼Œå¯¹æ¯”çš„æ˜¯åºåˆ—è€Œä¸æ˜¯å­—æ¯çš„ä¸ªæ•° å½“å­—æ¯ä¸åŒçš„æ—¶å€™ï¼Œé€‰æ‹©ä¸Šè¾¹æˆ–è€…å·¦è¾¹æœ€å¤§çš„é‚£ä¸ª åº”ç”¨ levenshtein distanceï¼ˆå­—ç¬¦ä¸²çš„ç›¸ä¼¼ç¨‹åº¦ï¼Œä¹Ÿå°±æ˜¯ä¸Šé¢çš„å…¬å…±å­åºåˆ—ï¼‰ æŒ‡å‡ºæ–‡ä»¶çš„å·®å¼‚ï¼ŒDNAçš„ç›¸ä¼¼æ€§ï¼Œç¡®å®šä»€ä¹ˆåœ°æ–¹æ–­å­— æ ¸å¿ƒæ€æƒ³ï¼šéœ€è¦æŠŠä¸¤ä¸ªstré‡Œé¢æ‰€æœ‰çš„substrçš„combinationéƒ½è®¡ç®—ä¸€ä¸‹ å®žçŽ° åˆå§‹åŒ–æ¡ä»¶ï¼šæ’å…¥ å®žé™…ä¸Šæ¥è¯´ä¸€ä¸ªæ ¼å­æœ‰ä¸‰ç§æ“ä½œï¼Œåˆ é™¤ï¼Œæ’å…¥å’Œç½®æ¢ï¼Œè¿™ä¸ªæ ¼å­éœ€è¦æ”¹å˜çš„æ“ä½œæ˜¯è¿™ä¸‰ä¸ªæ“ä½œçš„æœ€å°å€¼ åˆ é™¤ = d[i - 1][j] + 1 æ’å…¥ = d[i][j - 1] + 1 ï¼ˆç›¸å½“äºŽè¿™ä¸ªå•è¯çš„å‰ä¸€ä¸ªå­—æ¯ï¼ŒåŠ ä¸Šä¸€ä¸ªæ’å…¥ï¼Œè¿™ä¸¤ä¸ªæ²¡æœ‰æœ¬è´¨åŒºåˆ«ï¼‰ æ›¿æ¢ = d[i - 1][j - 1] + costï¼Œå…¶ä¸­è¿™ä¸ªcostï¼Œå¦‚æžœä¸¤ä¸ªç›¸åŒå°±æ˜¯0ï¼Œä¸¤ä¸ªä¸åŒå°±æ˜¯1 å…·ä½“è¯´æ˜Žè§levenshtein distanceè¯´æ˜Ž ç¬¬åç«  Kæœ€è¿‘é‚»åˆ›å»ºæŽ¨èç³»ç»Ÿ å‘è¿™ä¸ªäººæŽ¨èç”µå½±ï¼Œæ‰¾åˆ°ç¦»è¿™ä¸ªäººæœ€è¿‘çš„äº”ä¸ªç”¨æˆ· å¦‚ä½•åˆ¤æ–­æœ€è¿‘ï¼šç‰¹å¾æŠ½å– ç¬¬åä¸€ç«  æŽ¥ä¸‹æ¥å¦‚ä½•æ ‘ï¼ˆæ•°æ®åº“ + é«˜çº§æ•°æ®ç»“æž„ï¼‰ äºŒå‰æŸ¥æ‰¾æ ‘ï¼šå¯¹äºŽæ¯ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå·¦èŠ‚ç‚¹éƒ½æ¯”ä»–å°ï¼Œå³èŠ‚ç‚¹éƒ½æ¯”ä»–å¤§ æ—¶é—´å¤æ‚åº¦ logn å¹³è¡¡é—®é¢˜ å»¶ä¼¸ï¼š Bæ ‘ï¼Œçº¢é»‘æ ‘ï¼Œå †ï¼Œå»¶å±•æ ‘ åå‘ç´¢å¼• æœç´¢å¼•æ“Žçš„å·¥ä½œåŽŸç† æŠŠç½‘é¡µåˆ›å»ºhashè¡¨ï¼Œkeyæ˜¯å•è¯ï¼Œvalueæ˜¯åŒ…å«å•è¯çš„é¡µé¢ å‚…é‡Œå¶å˜æ¢ ä¿¡å·å¤„ç† å¹¶è¡Œç®—æ³•ï¼ˆæé«˜é€Ÿåº¦ï¼‰ å¯¹é€Ÿåº¦çš„æå‡æ˜¯éžçº¿æ€§çš„ å¹¶è¡Œç®¡ç†å¼€é”€ è´Ÿè½½å‡åŒ€ MapReduce åˆ†å¸ƒå¼ç®—æ³• æŠŠä¸€å°ç”µè„‘ä¸Šé¢å¤„ç†çš„å·¥ä½œåˆ†å¸ƒåˆ°å¤šå°ç”µè„‘ï¼Œå¤„ç†å¤§é‡æ•°æ® åˆ†å¸ƒ+å½’å¹¶ å¸ƒéš†è¿‡æ»¤å™¨ æ¦‚çŽ‡åž‹æ•°æ®ç»“æž„ï¼šå¯èƒ½å‡ºçŽ°é”™æŠ¥ï¼Œä½†æ˜¯ä¸å¯èƒ½å‡ºçŽ°æ¼æŠ¥ å‚¨å­˜ç©ºé—´å¾ˆå°‘ HyperLogLog ç±»ä¼¼äºŽå¸ƒéš†è¿‡æ»¤å™¨çš„ç®—æ³•ï¼Œä¸èƒ½ç»™å‡ºå‡†ç¡®çš„ç­”æ¡ˆä½†æ˜¯å æ®çš„ç©ºé—´å¾ˆå° SHA å¦ä¸€ç§hashï¼Œå®‰å…¨æ•£åˆ—ç®—æ³•ï¼Œç»™å®šä¸€ä¸ªå­—ç¬¦ä¸²è¿”å›žhash æ¯”è¾ƒå¤§åž‹æ–‡ä»¶ æ£€æŸ¥å¯†ç  å±€éƒ¨ä¸æ•æ„Ÿï¼Œä¿®æ”¹å…¶ä¸­ä¸€ä¸ªå­—ç¬¦ï¼Œä¼šæ”¹å˜å¾ˆå¤š Diffie-Hellman å¯†é’¥äº¤æ¢ å¦‚ä½•å¯¹æ¶ˆæ¯åŠ å¯†ï¼Œè®©åªæœ‰æ”¶ä»¶äººçœ‹å¾—æ‡‚ çº¿æ€§è§„åˆ’ åœ¨ç»™å®šçš„çº¦æŸæ¡ä»¶ä¸‹æœ€å¤§é™åº¦çš„æ”¹å–„æŒ‡å®šçš„æŒ‡æ ‡]]></content>
      <categories>
        <category>ç®—æ³•</category>
        <category>ç®—æ³•å›¾è§£</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SVD]]></title>
    <url>%2F2019%2F07%2F16%2FSVD%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[fusion360]]></title>
    <url>%2F2019%2F06%2F26%2Ffusion360%2F</url>
    <content type="text"><![CDATA[ç»™äºˆç‰¹å¾ æ‹‰ä¼¸æŒ‡ä»¤ ä¿®é¥°å¤–å½¢ ä¿®æ”¹è¾¹ç¼˜ åœ†è§’ å€’è§’ å¤–è§‚å¤„ç† é€‰æ‹©è´´å›¾ å³é”®é€‰æ‹©å¤–è§‚ å¯ä»¥é€‰æ‹©åŠ åˆ°é¢ä¸Šé¢æˆ–è€…åŠ åˆ°æ‰€æœ‰ä¸œè¥¿ä¸Šé¢ renderï¼ˆ3Dæ¨¡åž‹2DåŒ–ï¼‰ ä»Žmodelæ”¹æˆæ¸²æŸ“ ç‚¹é‚£ä¸ªå°ç¯ï¼Œä¿®æ”¹å›¾ç‰‡çš„åœºæ™¯è®¾ç½®ï¼Œæ¯”å¦‚é«˜å®½æ¯” æ‰€æœ‰ä¸œè¥¿éƒ½å¼„å¥½äº†ä¹‹åŽç›´æŽ¥æ¸²æŸ“ï¼Œæ¸²æŸ“åˆ°è‡ªå·±æ»¡æ„çš„åœ°æ–¹ ç”»è‰å›¾ å¯ä»¥æŠŠå‚è€ƒçš„å›¾æ”¾åœ¨å¹³é¢ä¸Šæ¥ï¼Œè¿™æ ·ç”»èµ·æ¥æ¯”è¾ƒè½»æ¾ï¼ˆæ’å…¥ï¼‰ éœ€è¦æ ¡å‡†åŠ è¿›åŽ»å›¾ç‰‡çš„æ¯”ä¾‹ ä¿®å»ºåç§»ä¹‹ç±»çš„å¯¹æ ‡CAD ç”»æ›²çº¿ ç›´æŽ¥å…³é”®ç‚¹ç”»æ›²çº¿ï¼Œå¯ä»¥å†è°ƒæ•´ å‡ ä½•å…³ç³»é è®¡ç®—æ¥ å’–å•¡æ¯ æ¯èº« æ—‹è½¬ä½“æˆåž‹ æ¯ç›– æ–°å»ºæ–°çš„é›¶éƒ¨ä»¶ ä¿®æ”¹ â€“ åˆå¹¶ï¼ˆç›¸äº¤è¿ç®— è‰å›¾ â€“ æŠ•å½±ï¼Œå¯ä»¥æŠŠå…¶ä»–çš„ä¸œè¥¿æŠ•å½±åˆ°çŽ°åœ¨çš„å¹³é¢]]></content>
      <categories>
        <category>CAD</category>
        <category>Fusion360</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[libProCamç¬”è®°]]></title>
    <url>%2F2019%2F06%2F25%2FlibProCam%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Binarizer.cppè¿™ä¸ªéƒ¨åˆ†æ˜¯æ¥è®¡ç®—å›¾åƒçš„binaryçš„ï¼ŒåŒ…æ‹¬ è®¡ç®—è¿™ä¸ªå›¾ç‰‡çš„threshold åšèƒŒæ™¯substract Cppç›¸å…³ æž„é€ å‡½æ•° æž„é€ ä¸€ä¸ªç±»çš„æ—¶å€™ä½¿ç”¨çš„å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°çš„åå­—å’Œç±»åç›¸åŒï¼Œé»˜è®¤æ˜¯æ²¡æœ‰å‚æ•°çš„ï¼Œå¯ä»¥è‡ªå·±åŠ ä¸Šå‚æ•°ï¼Œè¿™æ ·åˆ›å»ºå¯¹è±¡çš„æ—¶å€™å°±éœ€è¦ç»™å‚æ•° å¯¹æ ‡pythoné‡Œé¢çš„init æžæž„å‡½æ•° åå­—å’Œæž„é€ å‡½æ•°å®Œå…¨ç›¸åŒï¼Œä½†æ˜¯åœ¨å‰é¢å¢žåŠ äº†ä¸€ä¸ªæ³¢æµªçº¿ï¼Œæ²¡æœ‰è¿”å›žå€¼ä¹Ÿæ²¡æœ‰å‚æ•°ï¼Œåªæ˜¯ç”¨æ¥åœ¨å…³é—­ç¨‹åºçš„æ—¶å€™é‡Šæ”¾èµ„æº è™šå‡½æ•° å€ŸåŠ©æŒ‡é’ˆæ¥è¾¾åˆ°å¤šæ€çš„æ•ˆæžœ å®šä¹‰ä¸€ä¸ªå‡½æ•°æ˜¯è™šå‡½æ•°ï¼Œä¸ä»£è¡¨è¿™ä¸ªå‡½æ•°ä¸è¢«å®žçŽ°ï¼Œè€Œæ˜¯ä»£è¡¨åŸºç±»çš„æŒ‡é’ˆå¯ä»¥è°ƒç”¨å­ç±»çš„è¿™ä¸ªå‡½æ•° å¦‚æžœå®šä¹‰ä¸ºçº¯è™šå‡½æ•°ï¼Œæ‰è¯´æ˜Žä¸ä¼šå®žçŽ° æ¯”å¦‚ä¸‹é¢çš„ä¾‹å­é‡Œé¢ï¼ŒBæ˜¯å­ç±»ï¼ŒAæ˜¯åŸºç±»ï¼Œåˆ›å»ºçš„æ˜¯Açš„æŒ‡é’ˆï¼Œä½†æ˜¯è°ƒç”¨çš„å´æ˜¯Bçš„å‡½æ•°ï¼Œè¿™è¯´æ˜Žè¿™ä¸ªå‡½æ•°çš„è°ƒç”¨ä¸æ˜¯åœ¨ç¼–è¯‘çš„æ—¶å€™è¢«ç¡®å®šçš„ï¼Œè€Œæ˜¯åœ¨è¿è¡Œçš„æ—¶å€™è¢«ç¡®å®šçš„12345678910111213141516171819202122class A&#123;public: virtual void foo() &#123; cout&lt;&lt;"A::foo() is called"&lt;&lt;endl; &#125;&#125;;class B:public A&#123;public: void foo() &#123; cout&lt;&lt;"B::foo() is called"&lt;&lt;endl; &#125;&#125;;int main(void)&#123; A *a = new B(); a-&gt;foo(); // åœ¨è¿™é‡Œï¼Œaè™½ç„¶æ˜¯æŒ‡å‘Açš„æŒ‡é’ˆï¼Œä½†æ˜¯è¢«è°ƒç”¨çš„å‡½æ•°(foo)å´æ˜¯Bçš„! return 0;&#125; çº¯è™šå‡½æ•°ï¼Œåœ¨å‡½æ•°çš„å®šä¹‰åŽé¢åŠ ä¸Š =0 ç»å¸¸ä¼šåœ¨å®šä¹‰åŸºç±»çš„æ—¶å€™ç”¨çº¯è™šå‡½æ•°ï¼Œå› ä¸ºåŸºç±»å¯èƒ½æœ‰å¾ˆå¤šçš„æ´¾ç”Ÿï¼Œä½†æ˜¯åŸºç±»æœ¬èº«ç”Ÿæˆçš„å¯¹è±¡å¯èƒ½æ˜¯ä¸åˆç†çš„ æ¯”å¦‚åŠ¨ç‰©å¯ä»¥æ´¾ç”Ÿç‹®å­è€è™Žï¼Œä½†æ˜¯åŠ¨ç‰©æœ¬èº«ä¸æ˜¯å¾ˆåˆç† åœ¨å­ç±»é‡Œé¢å¿…é¡»é‡æ–°å£°æ˜Žè¿™ä¸ªå‡½æ•°ï¼Œä¹Ÿå°±æ˜¯è¯´åœ¨å­ç±»çš„æ—¶å€™å¿…é¡»æä¾›ä¸€ä¸ªè¿™ä¸ªå‡½æ•°çš„å®žçŽ°ï¼Œä½†æ˜¯åŸºç±»çš„ä½œè€…ä¸çŸ¥é“ä½ æ€Žä¹ˆå®žçŽ°å®ƒ]]></content>
      <categories>
        <category>ç ”ç©¶å®¤</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ä¸€äº›OpenCVé‡Œé¢ä¹‹å‰æ²¡ç”¨åˆ°çš„å‡½æ•°]]></title>
    <url>%2F2019%2F06%2F20%2F%E4%B8%80%E4%BA%9BOpenCV%E9%87%8C%E9%9D%A2%E4%B9%8B%E5%89%8D%E6%B2%A1%E7%94%A8%E5%88%B0%E7%9A%84%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[çœ‹äº†åˆ«äººå†™çš„ä»£ç ï¼Œæ„Ÿè§‰å¥½å¤šopenCVé‡Œé¢çš„åŸºç¡€åŠŸèƒ½æˆ‘éƒ½ä¸çŸ¥é“ï¼Œå½“æ—¶è¿˜æ˜¯åœ¨è‡ªå·±å†™çš„ï¼Œæ¯”å¦‚é™å™ªå•Šï¼Œå‡åŽ»èƒŒæ™¯å•Šç­‰ç­‰çš„ å…³äºŽè½½å…¥æ¨¡åž‹çœ‹äº†ä¸€ä¸ªGithubä¸Šé¢çš„é¡¹ç›®ï¼Œæ˜¯è‡ªå·±è®­ç»ƒäº†ä¸€ä¸ªäº”ä¸ªæ‰‹åŠ¿çš„è¯†åˆ«ï¼Œç„¶åŽç”¨è¿™äº›æ‰‹åŠ¿æ¥æŽ§åˆ¶è‡ªå·±å±‹å­é‡Œé¢çš„ç¯å…‰å˜åŒ–ï¼Œç”¨kerasè®­ç»ƒçš„æ‰€ä»¥å…ˆè½½å…¥äº†è¿™ä¸ªçš„æ¨¡åž‹ï¼Œç„¶åŽæœ‰ä¸¤ä¸ªä¸åŒçš„é¢„æµ‹çš„å‡½æ•° ç¬¬ä¸€ä¸ªå‡½æ•°ç”¨äº†model.predict_classesï¼Œè¿™ä¸ªå‡½æ•°é¢„æµ‹å‡ºæ¥çš„ç›´æŽ¥æ˜¯ç±»åˆ«ï¼Œæ‰“å°å‡ºæ¥çš„å°±æ˜¯ç±»åˆ«çš„ç¼–å· ç¬¬äºŒä¸ªç”¨çš„æ˜¯model.predictï¼Œè¿™ä¸ªé¢„æµ‹å‡ºæ¥çš„æ˜¯ä¸€ä¸ªæ•°å­—ï¼Œä¸èƒ½ç›´æŽ¥ç”¨ï¼Œè¿˜éœ€è¦æŠŠè¿™ä¸ªæ•°å€¼argmax(predict_test,axis=1)æ‰å¯ä»¥ç”¨ï¼ˆä¹Ÿå°±æ˜¯æ‰¾åˆ°æœ€å¤§çš„ï¼‰ createBackgroundSubtractorMOG2()retval = cv.createBackgroundSubtractorMOG2( [, history[, varThreshold[, detectShadows]]] ) åˆ›å»ºäº†ä¸€ä¸ªMOG2çš„background substructor å‚æ•°åˆ†åˆ«æ˜¯ historyçš„é•¿åº¦ è®¡ç®—çš„æ˜¯æ›¼å“ˆé¡¿è·ç¦»ï¼Œè¿™ä¸ªçš„é˜ˆå€¼ æ˜¯å¦æ£€æµ‹å½±å­ï¼Œå¦‚æžœæ£€æµ‹çš„è¯é€Ÿåº¦å›žæ…¢ä¸€ç‚¹ åˆ›å»ºå®Œçš„æ¨¡åž‹æœ‰å¾ˆå¤šåŠŸèƒ½ è¿™é‡Œç”¨åˆ°äº†ä¸€ä¸ªapplyï¼Œå°±æ˜¯å¯¹ä¸€å¼ å›¾è¿›è¡Œè¿™ä¸ªæ“ä½œï¼Œæ¥è®¡ç®—å‡ºè¿™å¼ å›¾ç‰‡çš„foreground è¿™é‡Œæœ‰ä¸€ä¸ªå‚æ•°å«learning rateï¼ŒæŒ‡çš„æ˜¯ä½ çš„è¿™ä¸ªæ¨¡åž‹ä¼šä¸ä¼šéšç€æ—¶é—´è€Œæ”¹å˜ï¼Œ0çš„è¯å°±æ˜¯ä¸å˜ï¼Œ1çš„è¯å°±æ˜¯å®Œå…¨ç”±ä¸Šä¸€å¸§å½¢æˆï¼Œç„¶åŽè´Ÿæ•°çš„è¯ä¼šè‡ªåŠ¨é€‰æ‹©ä¸€ä¸ª bitwise_and()dst = cv.bitwise_and( src1, src2[, dst[, mask]] ) è¿™é‡Œè®¡ç®—äº†æ¯ä¸€ä½çš„ä¸Žï¼ˆandï¼‰è®¡ç®—ï¼ŒåŠ ä¸Šäº†ä¸€ä¸ªå¯é€‰çš„å‚æ•°maskï¼Œè¿™æ ·å¯ä»¥ç›´æŽ¥è®¡ç®—å‡ºæ¥å‰æ™¯åŽ»æŽ‰èƒŒæ™¯ videoCapture.set()dst = cv.bitwise_and( src1, src2[, dst[, mask]] ) è¿™é‡Œä»–çš„ä»£ç æ²¡æœ‰ç”¨å±žæ€§ï¼Œç›´æŽ¥è®¾ç½®äº†ä¸¤ä¸ªæ•°å­—ï¼Œæ¯ä¸ªæ•°å­—ä¼šä»£è¡¨ä¸€ä¸ªå±žæ€§ï¼Œæ•°å­—çš„èŒƒå›´æ˜¯0-18 ä¹Ÿå°±æ˜¯è¯´å¥¹è®¾ç½®äº†10è¿™ä¸ªå±žæ€§ï¼Œç„¶åŽæŠŠè¿™ä¸ªå±žæ€§çš„å¤§å°è®¾ç½®æˆäº†200 cv2.bilateralFilter(frame, 5, 50, 100) ä¸€ä¸ªå«è¿™ä¸ªåå­—çš„æ»¤é•œï¼Œå¯ä»¥æ¶ˆé™¤æŽ‰å›¾ç‰‡é‡Œé¢ä½ ä¸æƒ³è¦çš„å™ªéŸ³ æ•ˆæžœæ¯”è¾ƒå¥½ï¼Œå¯ä»¥åœ¨æ¶ˆé™¤å™ªéŸ³çš„åŒæ—¶ä¿è¯å›¾åƒæ¯”è¾ƒæ¸…æ™°ï¼Œä½†æ˜¯ä¸Žæ­¤åŒæ—¶è¿™ä¸ªfilterçš„é€Ÿåº¦ä¼šæ¯”å¤§å¤šæ•°çš„æ…¢ä¸€äº› å›¾åƒç¿»è½¬ flip ä¸¤ä¸ªå‚æ•°ï¼Œç¿»è½¬çš„å›¾åƒä»¥åŠç¿»è½¬å‚æ•° 0æ˜¯ç«–ç›´ç¿»è½¬ï¼Œ1æ˜¯æ°´å¹³ç¿»è½¬ï¼Œå°äºŽ0çš„æ—¶å€™æ˜¯æ—‹è½¬180åº¦ï¼ˆå…ˆç«–ç›´å†æ°´å¹³ç¿»è½¬ï¼‰ inRangedst = cv.inRange( src, lowerb, upperb[, dst] ) æŸ¥çœ‹æ˜¯å¦æœ‰æ•°å­—åœ¨è¿™ä¸ªèŒƒå›´é‡Œé¢ï¼Œä¸‰ä¸ªchanneléƒ½åœ¨çš„è¯å°±è¾“å‡º1ï¼Œä¸åœ¨çš„è¯å°±è¾“å‡º0 å¯ä»¥ç»™ä¸åŒçš„channelèµ‹ä¸åŒçš„å€¼ calcHisthist = cv.calcHist( images, channels, mask, histSize, ranges[, hist[, accumulate]] ) è®¡ç®—ä¸€ç³»åˆ—è¾“å…¥çš„histogram åŽŸæ¥æœ‰è¿™ä¸ªå‡½æ•°ï¼ŒæŠŠè¿™ä¸ªè¾“å…¥normalizeåˆ°255ä¸ªchannelä¸Šé¢å°±èƒ½å¾—åˆ°ï¼Œè¿™æ ·å°±å¯ä»¥å¾—åˆ°è¿™å¼ å›¾ç‰‡é‡Œé¢çš„åˆ†å¸ƒäº† è€Œä¸”è€ƒè™‘äº†ä¸Šé¢çš„maskçš„æƒ…å†µ calcBackProjectï¼ˆå­˜ç–‘ï¼ï¼‰dst = cv.calcBackProject( images, channels, hist, ranges, scale[, dst] ) è®¡ç®—ä¸€ä¸ªhistçš„back projection CamShift()]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>OpenCV</category>
      </categories>
      <tags>
        <tag>OpenCv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è®ºæ–‡Touch180]]></title>
    <url>%2F2019%2F06%2F17%2F%E8%AE%BA%E6%96%87Touch180%2F</url>
    <content type="text"><![CDATA[Touch180: Finger Identification on Mobile Touchscreen using Fisheye Camera and Convolutional Neural Networkabstract é±¼çœ¼+æ·±åº¦å­¦ä¹ ï¼Œè¯æ˜Žæ£€æµ‹æ‰‹æŒ‡çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ ç”Ÿæˆäº†ä¸€ä¸ªdataset è®­ç»ƒäº†ä¸€ä¸ªCNNï¼Œç¡®å®šæ‰‹æŒ‡touchçš„ä½ç½® intro å¯ä»¥é€šè¿‡ç»™ä¸åŒçš„æ‰‹æŒ‡ä¸åŒçš„èŒè´£æ¥å¢žå¼ºå¯¹è§¦æ‘¸å±çš„ä½¿ç”¨ ä»¥å‰çš„åˆ†åˆ«æ‰‹æŒ‡çš„è®ºæ–‡ wearable device -&gt; æ¯”è¾ƒè´µ ç¡®å®šè§¦æ‘¸çš„åŒºåŸŸ -&gt; å¿…é¡»å¤šä¸ªæ‰‹æŒ‡è§¦æŽ§ è¿˜æœ‰ä¸€ä¸ªæ–¹æ³•æ˜¯åœ¨æ‰‹ä¸Šæˆ´ä¸Šäº†ä¸€ä¸ªæœ‰é¢œè‰²çš„æˆ’æŒ‡ï¼ˆè¯¶è¿™ä¸ªæ–¹æ³•ç”¨æ¥å®žçŽ°çŽ°åœ¨çš„deviceçš„ç”»ç”»åŠŸèƒ½æ„Ÿè§‰æ€Žä¹ˆæ ·ï¼‰ ç”¨äº†æ·±åº¦ç›¸æœºçš„ -&gt; ä¸é€‚åˆmobile device å…¶ä»–ç”¨CNNçš„æ²¡æœ‰ä½¿ç”¨é±¼çœ¼ç›¸æœº dataset ç›´æŽ¥ç”¨ä¸åŒçš„frameæ¥åšçš„dataset ç”¨äº”ä¸ªäºŒè¿›åˆ¶çš„æ•°å­—æ¥è¡¨ç¤ºlabeling net]]></content>
      <categories>
        <category>Papers</category>
        <category>é±¼çœ¼æ‰‹åŠ¿è¯†åˆ«</category>
      </categories>
      <tags>
        <tag>fisheye</tag>
        <tag>hand</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[unityå…¥é—¨åˆ¶ä½œspace shooter]]></title>
    <url>%2F2019%2F06%2F13%2Funity%E5%85%A5%E9%97%A8spaceshooter%2F</url>
    <content type="text"><![CDATA[ç›®æ ‡ è¿™ä¸ªæ¸¸æˆæ˜¯å’Œé›·ç”µç±»ä¼¼çš„æ¸¸æˆ éœ€è¦è®¾å®šç¢°æ’žç­‰ç­‰æ¸¸æˆé€»è¾‘ï¼Œç„¶åŽè®¾è®¡éŸ³ä¹ï¼Œå›¾ç­‰ç­‰ä¸œè¥¿ setupï¼Œplayerï¼Œcameraset up éœ€è¦ç¡®å®šå¥½åº”ç”¨çš„å¼€å‘å¹³å°file-build setting æ³¨æ„è¿™ä¸ªæ¸¸æˆæƒ³å¼€å‘ç½‘é¡µç‰ˆçš„ï¼Œä½†æ˜¯çŽ°åœ¨å·²ç»ä¸æ”¯æŒweb playerï¼Œå»ºè®®ä½¿ç”¨web GL å¯ä»¥åœ¨project setting-playeré‡Œé¢æ”¹å˜ä¸€äº›æ¸¸æˆçš„è®¾ç½®ï¼ˆè¿™é‡Œæ”¹å˜äº†å®½åº¦å’Œé«˜åº¦ï¼‰ åœ¨å³ä¸Šè§’çš„layoutå¯ä»¥æ”¹å˜çª—å£çš„å¸ƒå±€ æ”¾ç½®æ¸¸æˆçš„object ç›´æŽ¥ä»Žmodelé‡Œé¢æ‹–è¿›æ¥æ”¾è¿›sceneæˆ–è€…hierarchyé‡Œé¢ ç‚¹å‡»Få¯ä»¥é”å®šè¿™ä¸ªä¸œè¥¿ï¼ˆæœ€ä½³è§†è§’ï¼‰ éœ€è¦è®¾ç½®è¿™ä¸ªobjectåœ¨åŽŸç‚¹ æœ‰ä¸€ä¸ªmesh filiteræ¥å†³å®šè¿™ä¸ªä¸œè¥¿ç”¨çš„ä»€ä¹ˆæ¨¡åž‹ ä¸€ä¸ªmesh rendereræ¥æ¸²æŸ“è¿™ä¸ªæ¨¡åž‹ è¿™ä¸ªé‡Œé¢æœ‰ä¸¤ä¸ªä¸åŒçš„ææ–™ å› ä¸ºéœ€è¦ç‰©ä½“ä¹‹é—´çš„ç¢°æ’žï¼Œæ‰€ä»¥éœ€è¦å¢žåŠ physics--rigidbody åŠ å…¥äº†è¿™ä¸ªä¸œè¥¿ä¹‹åŽï¼Œç‰©ä½“å°±æœ‰äº†ç‰©ç†ä¸Šçš„ç‰¹å¾ ä¸‹é¢ç”±äºŽéœ€è¦ç¢°æ’žï¼Œæ‰€ä»¥éœ€è¦å®šä¹‰è¿™ä¸ªç‰©ä½“çš„ä½“ç§¯ å¢žåŠ ä¸€ä¸ªphysics -- capsule collision ç›¸å½“äºŽæŠŠè¿™ä¸ªç‰©ä½“çš„å‘¨å›´åŠ ä¸Šäº†ä¸€ä¸ªcageï¼Œæ¥ç¡®å®šä»–çš„ä½“ç§¯ éœ€è¦åœ¨è¿™é‡Œé¢å®šä¹‰ç¢°æ’žçš„æ–¹å‘ï¼ˆå› ä¸ºè¿™é‡Œé¢æ˜¯æ²¿ç€zè¿åŠ¨çš„ï¼Œæ‰€ä»¥ç¢°æ’žåœ¨zè½´ä¸Šé¢ï¼‰ å¯ä»¥æ”¹ä¸€æ”¹è§†è§’ï¼Œç„¶åŽç›´æŽ¥æ‹‰baræ¥è°ƒèŠ‚è¿™ä¸ªconsuleçš„å¤§å° å…³äºŽcoliider é™¤äº†è¿™é‡Œé¢ç”¨åˆ°çš„èƒ¶å›Šåž‹çš„ä»¥å¤–ï¼Œè¿˜æœ‰squareçš„sphereçš„ï¼Œconfoundçš„ï¼ˆæ··åˆï¼‰ï¼Ÿï¼Œåœ¨èƒ½è§£å†³é—®é¢˜çš„æ—¶å€™å°½é‡ç”¨ä¸Šé¢çš„åŸºç¡€å›¾å½¢ é™¤æ­¤ä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªmesh coillderï¼Œç”¨æ¥ä¸“é—¨å¥‘åˆè¿™ä¸ªç‰©ä½“çš„ä½“ç§¯çš„ï¼Œä½†æ˜¯æ˜¯æœ€åŽçš„é€‰æ‹©ï¼Œé€‰æ‹©çš„æ—¶å€™æœ€å¥½ä¹Ÿé€‰æ‹©ä¸€äº›æ¯”è¾ƒç®€å•çš„å½¢çŠ¶(å¦‚å›¾æ‰€ç¤ºï¼Œæ–°çš„ç¢°æ’žèŒƒå›´ä¼šå®Œæ•´å¥‘åˆè¿™ä¸ªç‰©ä½“) åœ¨coillderé‡Œé¢å¯ä»¥è‡ªå·±è®¾å®šè¿™ä¸ªå¯¹åº”çš„meshçš„ç§ç±»ï¼Œå³ä½¿å’Œä½¿ç”¨çš„æ¨¡åž‹ä¸åŒä¹Ÿå¯ä»¥ï¼ˆä¹Ÿå°±æ˜¯è¯´å¯ä»¥å»ºç«‹ä¸€ä¸ªç›¸å¯¹äºŽè¿™ä¸ªæ¨¡åž‹ç®€å•çš„æ¨¡åž‹ï¼Œç„¶åŽå»ºç«‹ç¢°æ’žï¼‰ ä¸ºäº†é€‰ä¸­çš„è¿™ä¸ªä¸œè¥¿å¯ä»¥è¢«è¯†åˆ«ä¸ºç¢°æ’žç‰©ä½“ï¼Œé€‰æ‹©is trigger ä¸ºäº†å¢žåŠ ä¸€ç‚¹ç¥žå¥‡çš„æ–°åŠŸèƒ½ï¼Œåœ¨é¢„è®¾å¥½çš„prefabï¼ˆä¸€ä¸ªå¯ä»¥é‡å¤å…‹éš†çš„å¯¹è±¡ï¼‰é‡Œé¢æ‰¾åˆ°ä¸€ä¸ªå¼•æ“Žçš„åŠ¨ç”»ï¼Œæ‹–åˆ°playerçš„å­ç›®å½•ä¸‹é¢ï¼Œè¿™ä¸ªä¸œè¥¿å°±è‡ªåŠ¨åŠ è¿›åŽ»äº† ç›¸æœºå’Œlightç›¸æœº å› ä¸ºä¸€å¼€å§‹ç›¸æœºä¼šåˆå§‹åŒ–åœ¨ç‰©ä½“ä¹‹åŽçš„ä½ç½®ï¼Œæ‰€ä»¥çŽ°åœ¨åœ¨gameç•Œé¢åªèƒ½çœ‹åˆ°è¿™ä¸ªç‰©ä½“çš„å±è‚¡éƒ¨åˆ†ï¼Œéœ€è¦è®¾ç½®ç›¸æœº ç‚¹å‡»main cameraï¼Œè¿™æ—¶å€™å³ä¸‹è§’ä¼šå‡ºçŽ°ç›¸æœºä½ç½®çš„ç¼©ç•¥å›¾ ä½ç½® -&gt; è°ƒèŠ‚åˆ°ç‰©ä½“ä¸Šæ–¹ï¼Œå¹¶ä¸”æ—‹è½¬90åº¦ è®¾ç½®ç›¸æœºçš„ç§ç±» å¦‚æžœé€‰æ‹©perspectiveçš„ç›¸æœºï¼Œå¯ä»¥é€šè¿‡è°ƒèŠ‚FOVæ¥å†³å®šçœ‹åˆ°çš„æ˜¯å¤šå¤§ è¿™é‡Œé€‰æ‹©orthographicï¼ˆæ­£æŠ•å½±ï¼Œä¸»è§†å›¾é‚£ç§æ„Ÿè§‰ï¼‰çš„ç›¸æœºï¼Œç„¶åŽç›´æŽ¥è°ƒèŠ‚çœ‹åˆ°çš„sizeå°±å¯ä»¥äº† å› ä¸ºå¸Œæœ›objectä¿æŒåœ¨åŽŸç‚¹ä¸Šï¼Œæ‰€ä»¥åœ¨è¿™é‡Œç§»åŠ¨camera å¯ä»¥åœ¨gameç”»é¢é‡Œé¢ç›´æŽ¥è°ƒèŠ‚objectçš„ä½ç½®ç­‰ç­‰ä¸œè¥¿ ä¸‹é¢æŠŠåœ¨cameraé‡Œé¢æŠŠèƒŒæ™¯æ”¹æˆé»‘è‰²ï¼ˆsoild colorï¼‰ ä½†æ˜¯è¿™æ—¶å€™objectçš„é¢œè‰²å¹¶æ²¡æœ‰å˜é»‘ï¼Œè¿™æ˜¯å› ä¸ºæ‰“å¼€äº†ambiant light åœ¨window--rendering--lighting settingé‡Œé¢ï¼ŒæŠŠsourceæ”¹æˆcolorå°±å¯ä»¥æ”¹å˜çŽ¯å¢ƒå…‰çš„é¢œè‰² çŽ¯å¢ƒå…‰ï¼šambient light è¿™ä¸ªå…‰æ²¡æœ‰æ–¹å‘ï¼Œæ‰€ä»¥å¦‚æžœéƒ½åŠ ä¸Šäº†çš„è¯å¯èƒ½ä¼šå¾ˆå¥‡æ€ª å…‰ åˆ›å»ºä¸€ä¸ªæœ‰æ–¹å‘çš„light -&gt; main light åº”è¯¥æ˜¯æœ€äº®çš„å…‰ å¸Œæœ›å¯ä»¥çœ‹åˆ°é£žæœºçš„é¢œè‰²ä½†æ˜¯ä¸å¸Œæœ›å¤ªäº® è°ƒæ•´è¿™ä¸ªå…‰çš„è§’åº¦ä»¥åŠå¼ºåº¦ å»ºç«‹ç¬¬äºŒä¸ªå…‰ï¼Œæ¥ç…§äº®ä¸æ€Žä¹ˆäº®çš„éƒ¨åˆ† -&gt; fill light è¿˜æ˜¯è°ƒæ•´è§’åº¦ï¼Œç…§äº®ç¬¬ä¸€ä¸ªå…‰ç…§ä¸åˆ°çš„éƒ¨åˆ† ä¸ºäº†ä¸è®©è¿™ä¸ªå…‰é‚£ä¹ˆå¼ºï¼ŒæŠŠè¿™ä¸ªå…‰çš„å¼ºåº¦é€‚å½“è°ƒå° ä¸ºäº†é€‚åº”å¤ªç©ºçš„å†·è‰²è°ƒï¼ŒæŠŠå…‰æºé¢œè‰²æ”¹æˆè“ç»¿è‰² æœ€åŽå¢žåŠ ç¬¬ä¸‰ä¸ªå…‰ï¼ŒæŠŠæš—éƒ¨å‹¾è¾¹ï¼ˆç›¸å½“äºŽç´ æé‡Œé¢çš„åœ¨è¾¹ä¸Šçš„é«˜äº®éƒ¨åˆ†ï¼‰ -&gt; rim light ä¸ºäº†ä¸ç…§äº®ä¸œè¥¿çš„ä¸Šå±‚ï¼Œåœ¨xè½´æŠŠè§’åº¦è°ƒæˆå¤æ•° ä¸ºäº†å‹¾è¾¹ï¼Œé¢œè‰²æ˜¯ç™½è‰²çš„ é™ä½Žäº®åº¦ æœ€åŽå»ºç«‹ä¸€ä¸ªæ–°çš„ç©ºçš„objectï¼Œä½ç½®resetå¥½ï¼Œæ¥æ•´ç†ä¸Šé¢çš„ä¸‰ä¸ªå…‰ æ³¨æ„ï¼Œå› ä¸ºè¿™é‡Œçš„å…‰æ˜¯directional lightï¼Œæ‰€ä»¥å…‰ç…§çš„æ•ˆæžœå’Œå…‰æºçš„ä½ç½®æ— å…³ï¼Œåªå’Œå…‰æºçš„è§’åº¦æœ‰å…³ èƒŒæ™¯ æ–°åˆ›å»ºä¸€ä¸ªquadï¼Œè°ƒæ•´ä½ç½®å’Œè§’åº¦è®©ç›¸æœºèƒ½çœ‹åˆ°ä»– removeæŽ‰ç¢°æ’žçš„éƒ¨åˆ†ï¼Œå› ä¸ºèƒŒæ™¯ä¸éœ€è¦ åŠ ä¸Štexture -&gt; å¯ä»¥ç›´æŽ¥æŠŠè¿™å¼ å›¾ç‰‡æ‹½åˆ°å¯¹åº”çš„ä½ç½®ä¸Šé¢ è¿™æ ·ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„materialåŠ åˆ°è¿™ä¸ªmeshçš„rendererä¸Šé¢åŽ» ç¼©æ”¾è¿™ä¸ªæ–¹å—ï¼Œè®©è¿™ä¸ªå›¾ç‰‡å¯ä»¥å®Œå…¨æ˜¾ç¤ºï¼ˆé«˜å®½æ¯”å¿…é¡»ä¿æŒï¼ï¼‰ è¿™æ—¶å€™ç…§åœ¨playerä¸Šé¢çš„å…‰ä¹Ÿå¯ä»¥ç…§åœ¨èƒŒæ™¯ä¸Šé¢ï¼Œä½†æ˜¯ä¸æ˜¯å¾ˆå¸Œæœ›è¿™ç§ç»“æžœ ä¸€ç§æ–¹æ³•æ˜¯æŠŠbackgroundå®Œå…¨ç‹¬ç«‹ä¸€ä¸ªlayerå‡ºæ¥ å¦ä¸€ç§æ–¹æ³•æ˜¯æ”¹å˜è¿™ä¸ªtextureçš„shader è¿™é‡Œæ”¹æˆå®Œå…¨çš„testureï¼Œè¿™æ ·å°±ä¸ä¼šå—åˆ°å…‰çš„å½±å“äº† æœ€åŽæŠŠèˆ¹ä»Žé™·å…¥çš„backgroundé‡Œæ‹½å‡ºæ¥ ç§»åŠ¨player é¦–å…ˆéœ€è¦åœ¨playeråº•ä¸‹å»ºç«‹æ–°çš„scripts fixedupdate -&gt; ç¡®å®šç‰©ä½“çŽ°åœ¨çš„ä½ç½® é¦–å…ˆå¾—åˆ°åž‚ç›´å’Œå¹³è¡Œçš„è¾“å…¥ï¼ˆé”®ç›˜æˆ–è€…é¼ æ ‡è¾“å…¥ï¼‰ ç‰©ä½“çš„ç§»åŠ¨æ˜¯ä¸€ä¸ªä¸‰ç»´çš„æ•°ç»„ï¼Œåˆ†åˆ«æ˜¯xyzè½´ï¼Œè¿™é‡Œyè½´çš„ç§»åŠ¨æ˜¯0.0fï¼Œå…¶ä»–ä¸¤ä¸ªåˆ†åˆ«æ˜¯å¹³è¡Œå’Œåž‚ç›´çš„ç§»åŠ¨ å› ä¸ºå·²ç»ç”¨äº†rigid bodyï¼Œå¯ä»¥ä»Žé‡Œé¢ç»™ç‰©ä½“ä¸€ä¸ªé€Ÿåº¦GetComponent&lt;Rigidbody&gt;().velocity -&gt; è¿™æ—¶å€™ç§»åŠ¨çš„éžå¸¸æ…¢ï¼Œå› ä¸ºinputæŽ¥æ”¶çš„åªæ˜¯0å’Œ1ï¼Œæ‰€ä»¥æ¯ç§’ç§»åŠ¨ä¸€ä¸ªunit è¿™æ—¶å€™åŠ ä¸Šäº†ä¸€ä¸ªæ–°çš„speedå‚æ•°ï¼Œæ¯æ¬¡åœ¨è®¡ç®—é€Ÿåº¦çš„æ—¶å€™ä¹˜ä¸Šè¿™ä¸ªå‚æ•°å°±å¯ä»¥äº† æ³¨æ„ï¼Œå› ä¸ºè¿™é‡Œçš„speedæ˜¯ä¸ªpublicçš„å€¼ï¼Œæ‰€ä»¥å¯ä»¥ç›´æŽ¥åœ¨unityçš„UIé‡Œé¢è¿›è¡Œæ“ä½œ è¿™æ—¶å€™å‡ºçŽ°äº†ä¸€ä¸ªé—®é¢˜ï¼Œplayerä¼šè·‘å‡ºå±å¹• å¢žåŠ ä¸€ä¸ªåˆ¤æ–­æ¡ä»¶ï¼Œç§»åŠ¨è¿™ä¸ªä¸œè¥¿å¦‚æžœåˆ°äº†è¾¹ç•Œï¼Œé‚£ä¹ˆæŠŠpositionä»Žå…ˆresetåˆ°è¾¹ç•Œä¸Š å› ä¸ºè¿™æ ·åœ¨æ›´æ–°ä¸‹ä¸€å¸§ä¹‹å‰éƒ½ä¸ä¼šå‡ºç•Œ ä½¿ç”¨äº†mathfé‡Œé¢çš„ä¸€ä¸ªå‡½æ•°clampï¼Œæ¥è®¾å®šxå’Œzçš„èŒƒå›´ è¿™ä¸ªå‡½æ•°è¶…è¿‡äº†ä¸‹ç•Œå°±ä¼šä¸€ç›´æ˜¾ç¤ºä¸‹ç•Œï¼Œè¶…è¿‡äº†ä¸Šå±Šå°±ä¼šä¸€ç›´æ˜¾ç¤ºä¸Šå±Š ä¸ºäº†ä¸è®©è®¾å®šçš„xmaxï¼Œxminï¼Œzmaxï¼Œzminåœ¨UIé‡Œé¢å¤ªå åœ°ï¼Œæ‰€ä»¥å»ºç«‹äº†ä¸€ä¸ªæ–°çš„classæ¥è£…è¿™äº›ä¸œè¥¿ï¼ˆæ³¨æ„æ–°çš„classä¸éœ€è¦ç»§æ‰¿ï¼‰ï¼Œç„¶åŽåœ¨éœ€è¦ç”¨çš„æ—¶å€™å»ºç«‹æ–°çš„å¯¹è±¡ï¼Œcall ä¸ºäº†èƒ½åœ¨UIé‡Œæ˜¾ç¤ºï¼Œéœ€è¦åœ¨æ–°åˆ›å»ºçš„classä¸Šé¢åŠ ä¸Š[System.Serializable] è¿™äº›è¾¹ç¼˜è®¾ç½®ä»€ä¹ˆå€¼å¯ä»¥ç›´æŽ¥æŠŠä¸œè¥¿æ‹–åˆ°è¾¹ç¼˜ç„¶åŽçœ‹çœ‹æ˜¯ä»€ä¹ˆå€¼å°±å¯ä»¥äº† tiltæˆ–è€…bankï¼šè®©é£žèˆ¹åˆ°å·¦å³ç§»åŠ¨çš„æ—¶å€™å¯ä»¥æ—‹è½¬ä¸€ä¸‹ å¢žåŠ äº†æ—‹è½¬åŠŸèƒ½Quaternion.Euler shotså¸Œæœ›æŠŠè¿™éƒ¨åˆ†çš„é€»è¾‘å’Œè¿™éƒ¨åˆ†çš„å›¾åƒåˆ†éš”å¼€ï¼šè¿™æ ·æ¢æ¨¡åž‹çš„æ—¶å€™å°±å¾ˆæ–¹ä¾¿äº† é¦–å…ˆåˆ›å»ºä¸€ä¸ªæ–°çš„quanï¼Œåœ¨è¿™ä¸ªä¸Šé¢åŠ ä¸Štexture åˆ›å»ºä¸€ä¸ªæ–°çš„materialï¼Œç„¶åŽå†è¿™ä¸ªé‡Œé¢é€‰æ‹©ä¸€ä¸ªtexture ç„¶åŽå†æŠŠæ–°çš„materialåŠ åˆ°å¯¹åº”çš„ä¸œè¥¿é‡Œé¢ å¸Œæœ›è¿™ä¸ªä¸œè¥¿é»‘è‰²çš„éƒ¨åˆ†æ¶ˆå¤±ï¼Œshaderé€‰æ‹©mobile--particle--addtiveï¼ˆmobileæ¯”è¾ƒæœ‰æ•ˆçŽ‡ï¼‰ å¢žåŠ è¿™ä¸ªä¸œè¥¿çš„ç¢°æ’žï¼ŒåŽ»æŽ‰VFXçš„ç¢°æ’ž ç„¶åŽåŠ ä¸Šè¿™ä¸ªå…‰çš„è¿åŠ¨é€»è¾‘ transform.forward()å‘å‰è¿åŠ¨ï¼Œä¹˜ä¸Šé€Ÿåº¦ æŠŠè¿™ä¸ªä¸œè¥¿è®¾å®šæˆä¸€ä¸ªprefabï¼ˆç›´æŽ¥æ‹–åˆ°prefabçš„æ–‡ä»¶å¤¹é‡Œé¢ï¼‰ shoot shots å·²ç»æŠŠéœ€è¦å°„å‡ºåŽ»çš„å…‰çº¿è®¾å®šæˆäº†ä¸€ä¸ªprefabï¼Œè¿™æ—¶å€™åªè¦åœ¨æ¯æ¬¡ç‚¹é¼ æ ‡çš„æ—¶å€™æŠŠè¿™ä¸ªä¸œè¥¿å°„å‡ºåŽ»å°±å¯ä»¥äº† åˆ›å»ºä¸€ä¸ªæ–°çš„ç©ºçš„objectä½œä¸ºplayerçš„å­ç›®å½•æ¥å®šä¹‰å‘å‡ºåŽ»æ¿€å…‰çš„ä½ç½®ï¼ˆshotSpawnï¼‰ åœ¨playerä¸­æ–°å¢žä¸€ä¸ªåŠŸèƒ½ï¼Œpublicçš„å¯¹è±¡æ˜¯shotå’ŒshotSpawnï¼Œè¿™ä¸¤ä¸ªä¸œè¥¿éƒ½å¯ä»¥ç›´æŽ¥ä»ŽUIé‡Œé¢æ‹–è¿›æ¥ï¼Œç„¶åŽè®¾å®šè¿™ä¸ªå­å¼¹å‘å°„çš„é€»è¾‘ï¼Œæ¯æ¬¡æŒ‰ä¸‹é¼ æ ‡éƒ½å¹¶ä¸”åœ¨0.25ç§’å¤–ä¼šå‘å°„å­å¼¹ æŒ‰ä¸‹é¼ æ ‡åŽæŠŠshowSpawnçš„transformèµ‹å€¼ç»™shotï¼Œè¿™æ ·å°±çŸ¥é“shotçš„ä½ç½®äº† é—®é¢˜ï¼šçŽ°åœ¨æ¸¸æˆè¿›è¡Œè¿‡ç¨‹ä¸­ä¼šå¾€rooté‡Œé¢å¢žåŠ å¾ˆå¤šprefab boundaryï¼Œhazardsï¼Œenemyboundaryåœ¨ç”»é¢é‡Œé¢æ¶ˆå¤±çš„å­å¼¹ä¹Ÿåˆ æŽ‰ -&gt; å»ºç«‹ä¸€ä¸ªbox æ‰“å¼€trigger ç»™è¿™ä¸ªboxé‡Œé¢ç”¨ä¸€ä¸ªå‡½æ•°ï¼Œåˆ¤æ–­æ˜¯å¦æ’žä¸Šè¿™ä¸ªè¾¹æ¡†ï¼Œæ’žä¸Šäº†çš„è¯å°±åˆ é™¤æ’žä¸Šçš„ç‰©ä½“OnTriggerExit 1234567public class DestroyByBoundry : MonoBehaviour&#123; void OnTriggerExit(Collider other) &#123; Destroy(other.gameObject); &#125;&#125; hazradsä¼šæ’žä¸Šplayerçš„é™¨çŸ³ é¦–å…ˆå»ºç«‹ä¸€ä¸ªæ–°çš„é™¨çŸ³å¯¹è±¡ï¼Œè¿™ä¸ªå¯¹è±¡åº”è¯¥å¯ä»¥è¢«æ’žå‡»çš„ï¼ŒåŠ ä¸Šç¢°æ’žå’Œåˆšä½“ åŠ ä¸Šè¿™ä¸ªé™¨çŸ³çš„è‡ªåŠ¨æ—‹è½¬ï¼Œä½¿ç”¨éšæœºçš„æ•°å­—ï¼Œå¹¶ä¸”æŠŠangular dragæ”¹æˆ0 åŠ ä¸Šæ¿€å…‰å’Œé™¨çŸ³ç¢°æ’žä¹‹åŽï¼Œä¸¤ä¸ªä¸œè¥¿åŒæ—¶æ¶ˆå¤±çš„æ•ˆæžœ å•çº¯çš„åŠ ç¢°æ’žæ•ˆæžœä¼šå‘çŽ°å› ä¸ºè¾¹ç•Œå¼•å‘çš„é™¨çŸ³æ¶ˆå¤±bug å› ä¸ºé™¨çŸ³å…ˆå’Œè¾¹ç•Œç¢°æ’žäº†ï¼Œç„¶åŽä¸¤ä¸ªä¸€èµ·æ¶ˆå¤±äº† éœ€è¦æŠŠBoundaryåŠ ä¸Šä¸€ä¸ªæ–°çš„tag1234if (other.tag == "Boundary") &#123; return; &#125; çˆ†ç‚¸ï¼å°±æ˜¯è‰ºæœ¯ï¼ åœ¨contact destroyçš„æ–‡ä»¶é‡Œé¢å¢žåŠ æ–°çš„çˆ†ç‚¸æ•ˆæžœ æ–°å»ºä¸€ä¸ªexplosionçš„gameobjectï¼Œç»™è¿™ä¸ªå¯¹è±¡èµ‹å€¼ä½ç½®Instantiate(explosion, transform.position, transform.rotation); ç»™playerä¸€ä¸ªæ–°çš„tagï¼Œç„¶åŽåœ¨ç¢°æ’žé‡Œé¢åˆ¤æ–­æ˜¯é™¨çŸ³æ’žplayerè¿˜æ˜¯é™¨çŸ³æ’žæ¿€å…‰ï¼Œèµ‹å€¼ä¸åŒçš„çˆ†ç‚¸æ•ˆæžœ æŠŠmoverå¢žåŠ åˆ°é™¨çŸ³é‡Œé¢ï¼Œé€Ÿåº¦è®¾ç½®ä¸ºè´Ÿå€¼ï¼Œè¿™æ ·é™¨çŸ³å°±èƒ½å¾€è‡ªå·±èº«ä¸ŠæŽ‰äº† game controller åˆ›å»ºæ•´ä¸ªæ¸¸æˆçš„é€»è¾‘ è®¾ç½®å¥½çš„é™¨çŸ³åˆ›å»ºæˆæ–°çš„prefab åˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è±¡ä½œä¸ºæŽ§åˆ¶å™¨ï¼ŒåŠ å…¥ä¸€ä¸ªæ–°çš„å¯¹è±¡hazardï¼Œåˆå§‹åŒ–å¥½æŽ‰ä¸‹æ¥çš„æ•Œäººçš„ä½ç½®ï¼Œè®©æ•Œäººå¯ä»¥ä»Žéšæœºçš„ä½ç½®å¾€ä¸‹æŽ‰ æ¯æ¬¡æŽ‰è½ä¹‹é—´éš”ç€æ—¶é—´ï¼ˆè¿™éƒ¨åˆ†å’ŒC++æœ‰äº›ä¸ä¸€æ ·ï¼‰ï¼ŒæŠŠæ‰€æœ‰çš„æŽ‰è½æ”¾åœ¨ä¸€ä¸ªwhileé‡Œé¢ åŽ»æŽ‰å‰©ä½™çš„çˆ†ç‚¸æ•ˆæžœ scoreï¼Œaudioï¼ŒbuildingåŠ å£°éŸ³ é¦–å…ˆæŠŠé™¨çŸ³çˆ†ç‚¸çš„èƒŒæ™¯éŸ³åŠ åˆ°é™¨çŸ³çš„prefabé‡Œé¢ èƒŒæ™¯éŸ³ä¹åŠ åˆ°game controllerï¼Œæ­¦å™¨çš„éŸ³ä¹åŠ åˆ°player æ­¦å™¨çš„éŸ³ä¹éœ€è¦åœ¨æ¯æ¬¡å‘å°„çš„æ—¶å€™è§¦å‘ è°ƒæ•´å„ä¸ªéŸ³é‡çš„å¤§å° è®¡ç®—score æ–°å»ºä¸€ä¸ªtextï¼Œè®¾å®šå¥½è¿™ä¸ªtextçš„å­—ä½“æ•ˆæžœä¹‹ç±»çš„ ç„¶åŽæŠŠè¿™ä¸ªtext referenceåˆ°gamecontrolleré‡Œé¢ï¼Œç„¶åŽæŠŠæœ€å¼€å§‹çš„åˆ†æ•°åˆå§‹åŒ–ï¼Œå¹¶ä¸”å†™å‡ºæ¥æ›´æ–°scoreçš„ä»£ç  æŠŠè¿™ä¸ªscore referenceé™¨çŸ³é‡Œé¢ å¢žåŠ æ–‡å­—æ•ˆæžœ éœ€è¦å¢žåŠ é‡æ–°å¼€å§‹æ¸¸æˆå’Œæ¸¸æˆç»“æŸçš„text åœ¨æ¸¸æˆé€»è¾‘é‡Œé¢åŠ ä¸Šçš„æ˜¯è¿™ä¸ªçŽ©æ„æ€Žä¹ˆæ›´æ–°å’Œè®¡ç®—ï¼Œéœ€è¦ä¸¤ä¸ªflagåˆ¤æ–­æœ‰æ²¡æœ‰æ¸¸æˆç»“æŸ éœ€è¦åœ¨ç¢°æ’žé‡Œé¢æŠŠplayerå¼„æ­» å¢žåŠ æœ€åŽçš„æ•ˆæžœ å¢žåŠ é™¨çŸ³ å¤åˆ¶ä¹‹å‰çš„asteroidå¹¶ä¸”ç»™ä»–ä»¬ä¸åŒçš„æ¨¡åž‹å’Œç¢°æ’ž æŠŠä¹‹å‰çš„å¯¹è±¡æ”¹æˆä¸€ä¸ªæ•°ç»„å°±å¯ä»¥handleå¾ˆå¤šä¸ªå¯¹è±¡äº†ï¼Œéšæœºé€‰æ‹© å¢žåŠ ç§»åŠ¨çš„å°æ˜Ÿæ˜Ÿï¼ˆé¡¹ç›®é‡Œé¢è‡ªå¸¦çš„ï¼‰ è®©èƒŒæ™¯é‡å¤èµ·æ¥ æŠŠèƒŒæ™¯è®¾ç½®åœ¨ä¸€ä¸ªèŒƒå›´å†…ï¼Œä¸€æ—¦è¶…è¿‡äº†è¿™ä¸ªèŒƒå›´å°±é‡æ–°å¼€å§‹]]></content>
      <categories>
        <category>Unity</category>
        <category>å…¥é—¨</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VS17çš„é…ç½®é—®é¢˜]]></title>
    <url>%2F2019%2F06%2F07%2FVS17%E7%9A%84%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[æ— æ³•æ‰“å¼€æºæ–‡ä»¶é—®é¢˜ ç›´æŽ¥ä»Žè€å¸ˆé‚£é‡Œå¾—åˆ°çš„é¡¹ç›®ï¼Œç¬¬ä¸€æ¬¡è¿è¡Œç›´æŽ¥å‡ºé”™ï¼ŒæŸ¥äº†ä¸€ä¸‹ä¸»è¦éœ€è¦æ³¨æ„ä¸‹é¢å‡ ä¸ª è£…VSçš„æ—¶å€™æœ‰æ²¡æœ‰è£…æ ‡å‡†åº“ä¹‹ç±»çš„ å°è¯•ä½¿ç”¨windowçš„å…¶ä»–ç‰ˆæœ¬çš„SDK å³é”®é¡¹ç›®ï¼Œå±žæ€§é‡Œé¢ ä¸Šé¢ä¸¤ä¸ªé—®é¢˜éƒ½å¯ä»¥åœ¨VSçš„installeré‡Œé¢æ‰¾åˆ°ç›¸å…³çš„å®‰è£… å¤šä¸ªmainçš„é—®é¢˜ è¿™å›žçš„æ–‡ä»¶é‡Œé¢æœ‰ä¸¤ä¸ªcppéƒ½å¸¦ç€mainï¼Œå¦‚æžœæƒ³è¦è¿è¡Œçš„è¯éœ€è¦æŠŠä¸€ä¸ªcppå³é”®ç§»é™¤å‡ºé¡¹ç›®å†è¿è¡Œå¦ä¸€ä¸ª]]></content>
      <categories>
        <category>IDE</category>
        <category>Visual Studio</category>
      </categories>
      <tags>
        <tag>VS17</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pythonçš„å¤åˆ¶å’Œå¤šç»´æ•°ç»„]]></title>
    <url>%2F2019%2F06%2F05%2Fpython%E7%9A%84%E5%A4%8D%E5%88%B6%E5%92%8C%E5%A4%9A%E7%BB%B4%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[æœ€è¿‘å†™é¢è¯•é¢˜çš„æ—¶å€™é‡åˆ°äº†è‡ªå·±éƒ½æƒ³ä¸åˆ°çš„å¥‡æ€ªå°é”™è¯¯ å¤šç»´æ•°ç»„åœ¨åˆ›å»ºå¤šç»´æ•°ç»„çš„æ—¶å€™ï¼Œæœ¬æ¥åº”è¯¥æ˜¯ç”¨åµŒå¥—çš„forå¾ªçŽ¯æ¥ç”Ÿæˆ[[0 for i in range(m)] for j in range(n)](å› ä¸ºä¸€èˆ¬ç½‘æµ‹ä¸èƒ½è°ƒç”¨numpyï¼Œä¸ç„¶å°±ç›´æŽ¥ç”¨numpyæžäº†) ä½†æ˜¯æœ€è¿‘æƒ³è¦å·æ‡’çš„æ—¶å€™å°è¯•ç”¨ [[0] * n] * m æ¥åˆ›å»ºï¼Œç»“æžœç–¯ç‹‚é­é‡bugã€‚ æœ€ç»ˆåŽŸå› æ˜¯å‘çŽ°è¿™æ ·åˆ›å»ºå‡ºæ¥çš„æ•°ç»„ï¼Œæ¯ä¸€è¡Œéƒ½æ˜¯ç¬¬ä¸€è¡Œçš„å¼•ç”¨ï¼Œæ‰€ä»¥æ¯æ¬¡æ“ä½œå¤§å®¶éƒ½ä¼šä¸€èµ·å˜ (ä½†æ˜¯è¿™ç§æ–¹æ³•å¯ä»¥åˆ›å»ºä¸€ç»´çš„) listçš„å¤åˆ¶æˆ‘ä¸€ç›´ä»¥ä¸ºa=bå°±æ˜¯listçš„å¤åˆ¶äº†ï¼Œä½†æ˜¯å¹¶ä¸æ˜¯è¿™æ ·çš„ï¼ï¼è¿™æ ·çš„è¯aæ˜¯ä¸€ä¸ªå…³äºŽbçš„referenceï¼Œå¹¶ä¸æ˜¯å¤åˆ¶bï¼Œæ”¹å˜çš„æ—¶å€™æ˜¯ä¼šä¸€èµ·æ”¹å˜çš„ ä¸‹é¢å‡ ç§æ–¹æ³•å¯ä»¥ç”¨ï¼š a = list(b) a = b[:] a = b * 1 a = copy.copy(b) #éœ€è¦import copy]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
        <category>list</category>
      </categories>
      <tags>
        <tag>listå¤åˆ¶</tag>
        <tag>å¤šç»´æ•°ç»„</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽå­—ç¬¦ä¸²åŒ¹é…ç®—æ³•KMPå’ŒBM]]></title>
    <url>%2F2019%2F06%2F05%2F%E5%85%B3%E4%BA%8E%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95KMP%E5%92%8CBM%2F</url>
    <content type="text"><![CDATA[ä»Šå¤©åœ¨leetcodeç»ˆäºŽåˆ·åˆ°äº†stringçš„é¢˜ï¼Œæ˜¯åœ¨ä¸€å¤§ä¸²å­—ç¬¦é‡Œé¢åŒ¹é…ç›¸åº”çš„å­—ç¬¦ã€‚æ‰˜pythonçš„ç¦ï¼Œå±…ç„¶è¢«æˆ‘ç”¨æš´åŠ›ç ´è§£è§£å†³äº†ï¼Œè™½ç„¶ç»“æžœä¸æ˜¯å¾ˆä¼˜é›…ã€‚123456789class Solution: def strStr(self, haystack: str, needle: str) -&gt; int: if needle == "": return 0 for i, ch in enumerate(haystack): if ch == needle[0]: if needle == haystack[i:i+len(needle)]: return i return -1 KMP é¦–å…ˆï¼ŒæŠŠè¿™ä¸ªéœ€è¦æ£€æµ‹çš„stringï¼ˆaï¼‰çš„ç¬¬ä¸€ä¸ªå’Œç›®æ ‡stringï¼ˆtï¼‰çš„ç¬¬ä¸€ä¸ªè¿›è¡Œå¯¹æ¯”ï¼Œå¦‚æžœä¸åŒ¹é…ï¼ŒåŽç§»ä¸€ä½ ç›´åˆ°æ‰¾åˆ°ç¬¬ä¸€ä¸ªç›¸åŒçš„å­—æ¯ï¼Œç„¶åŽæŠŠaå’ŒbåŒæ—¶åŽç§»ä¸€ä½ è¿˜æ˜¯ç›¸åŒï¼Œç»§ç»­åŽç§» ä¸åŒï¼ˆè¿™éƒ¨åˆ†æ˜¯è¿™ä¸ªä»£ç çš„ç²¾é«“ï¼‰ ä¸€èˆ¬çš„æ€è·¯æ˜¯æŠŠbå…¨éƒ½åŽç§»ä¸€ä½ï¼Œä½†æ˜¯è¿™æ ·å…¶å®žæ¶ˆè€—æŒºå¤§çš„ KMPçš„æ€è·¯æ˜¯ï¼Œæ—¢ç„¶bçš„å‰nä½éƒ½å·²ç»æ¯”è¾ƒè¿‡äº†ï¼Œé‚£å°±ä¸è¦æ”¾å¼ƒè¿™ä¸ªä¿¡æ¯ï¼Œä¸è¦ç§»åŠ¨å›žä¹‹å‰æ¯”è¾ƒè¿‡çš„nä½äº†ï¼Œç»§ç»­åŽç§»ç§»åŠ¨åˆ°å…¨æ–°çš„ä½ç½® éœ€è¦ç§»åŠ¨çš„ä½æ•° = å·²ç»åŒ¹é…åˆ°çš„å­—æ•° - å¯¹åº”æœ€åŽä¸€ä½åŒ¹é…ä¸Šçš„ä¸œè¥¿çš„åŒ¹é…å€¼ï¼ˆç”±partial match tableå¾—å‡ºï¼‰ å¦‚ä½•äº§ç”Ÿè¿™å¼ è¡¨æ¯”å¦‚ä¸€ä¸ªå•è¯ bread å‰ç¼€ï¼šb,br,bre,brea åŽç¼€ï¼šread,ead,ad,déƒ¨åˆ†åŒ¹é…å€¼å°±æ˜¯å‰ç¼€å’ŒåŽç¼€æœ€é•¿çš„å…±æœ‰å…ƒç´ é•¿åº¦ æ¯”å¦‚ABCDABDè¿™ä¸ªstring Aå‰åŽç¼€éƒ½æ˜¯ç©ºçš„ï¼Œé•¿åº¦0 ABï¼Œå‰ç¼€Aï¼ŒåŽç¼€Bï¼Œå…±æœ‰é•¿åº¦0 ABCï¼Œ[A, AB]ï¼ŒåŽç¼€ä¸º[BC, C]ï¼Œå…±æœ‰å…ƒç´ çš„é•¿åº¦0 ABCDï¼Œ[A,AB,ABC],[B,BC,BCD] -&gt; 0 ABCDA, [A,AB,ABC,ABCD],[BCDA,CDA,DA,A] -&gt; æœ‰ä¸€ä¸ªå…±æœ‰å…ƒç´ Aï¼Œé•¿åº¦ä¸º1 ABCDAB,[A, AB, ABC, ABCD, ABCDA],[BCDAB, CDAB, DAB, AB, B] -&gt; å…±æœ‰å…ƒç´ ABï¼Œé•¿åº¦ä¸º2 â€œABCDABDâ€çš„å‰ç¼€ä¸º[A, AB, ABC, ABCD, ABCDA, ABCDAB]ï¼ŒåŽç¼€ä¸º[BCDABD, CDABD, DABD, ABD, BD, D]ï¼Œå…±æœ‰å…ƒç´ çš„é•¿åº¦ä¸º0ã€‚ï¼ˆéš¾ç‚¹ï¼šæ€Žä¹ˆå¾—åˆ°ä¸Šé¢çš„è¿™ä¸ªé•¿åº¦ï¼‰ BM é¦–å…ˆå°†aå’Œbçš„å¤´å¯¹å…¶å¼€å§‹ï¼Œç„¶åŽä»Žå°¾éƒ¨å¼€å§‹æ¯”è¾ƒã€‚å› ä¸ºå¦‚æžœå°¾éƒ¨ä¸åŒ¹é…çš„è¯ï¼Œè¿™æ•´ä¸ªä¸€ä¸²éƒ½ä¸åŒ¹é…äº†ã€‚çŸ¥é“äº†è¿™ä¸ªä¸åŒ¹é…çš„å­—ç¬¦ä¹‹åŽï¼Œè¿™ä¸ªå­—ç¬¦å°±è¢«ç§°ä¸ºåå­—ç¬¦ å¦‚æžœè¿™ä¸ªåå­—ç¬¦åŒ…æ‹¬åœ¨å•è¯é‡Œé¢ï¼Œåˆ™éœ€è¦æŠŠè¿™ä¸¤ä¸ªå¯¹å…¶ åŽç§»ä½æ•° = åå­—ç¬¦çš„ä½ç½® - æœç´¢è¯ä¸­çš„ä¸Šä¸€æ¬¡å‡ºçŽ°ä½ç½® å¦‚æžœä¸åŒ…å«åœ¨æœç´¢è¯é‡Œé¢ï¼Œé‚£ä¹ˆä¸Šä¸€æ¬¡çš„ä½ç½®æ˜¯-1 æœ€åŽä¸€ä½åŒ¹é…ä¸Šäº†ï¼Œé‚£ä¹ˆå°±é¡ºç€bå¾€å‰æ‹ åœ¨aé‡Œé¢å¯ä»¥å’ŒbåŽé¢åŒ¹é…ä¸Šçš„éƒ½æ˜¯good suffixï¼ˆæ¯”å¦‚exampleçš„eï¼Œleï¼Œpleç­‰ç­‰ï¼‰ å¥½åŽç¼€çš„åŽç§»ï¼šåŽç§»ä½æ•° = å¥½åŽç¼€çš„ä½ç½®ï¼ˆæœ€åŽä¸€ä¸ªå­—ç¬¦ä¸ºå‡†ï¼‰ - æœç´¢è¯ä¸­çš„ä¸Šä¸€æ¬¡å‡ºçŽ°ä½ç½® å¦‚æžœæ²¡æœ‰å‡ºçŽ°è¿‡æ˜¯ -1 å¦‚æžœæœ‰å¤šä¸ªå¥½åŽç¼€ï¼Œé‚£ä¹ˆé™¤äº†æœ€é•¿çš„å¥½åŽç¼€ï¼Œå…¶ä»–çš„ä¸Šä¸€æ¬¡å‡ºçŽ°ä½ç½®å¿…é¡»åœ¨å¤´éƒ¨ï¼ˆbçš„å¤´éƒ¨ï¼‰ åœ¨ä¸Šé¢ä¸¤ä¸ªè§„åˆ™é‡Œé¢ï¼Œé€‰æ‹©ç§»åŠ¨çš„æœ€å¤§å€¼ ä¸Šé¢ä¸¤ä¸ªè§„åˆ™åªå’Œæœç´¢è¯æœ‰å…³ï¼Œå’ŒåŽŸæ¥çš„å­—ç¬¦ä¸²æ²¡å…³ç³»ï¼Œæ‰€ä»¥å¯ä»¥æå‰ç”Ÿæˆåå­—ç¬¦å’Œå¥½åŽç¼€è¡¨ï¼Œç›´æŽ¥æ¯”è¾ƒç§»åŠ¨ä½æ•°]]></content>
      <categories>
        <category>ç®—æ³•</category>
        <category>å­—ç¬¦ä¸²å¤„ç†</category>
      </categories>
      <tags>
        <tag>KMP</tag>
        <tag>BM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽpythonçš„threading]]></title>
    <url>%2F2019%2F06%2F03%2F%E5%85%B3%E4%BA%8Epython%E7%9A%84threading%2F</url>
    <content type="text"><![CDATA[å¤šçº¿ç¨‹å¤šçº¿ç¨‹ç±»ä¼¼äºŽåŒæ—¶æ‰§è¡Œå¤šä¸ªä»»åŠ¡ å¯ä»¥æŠŠå ç”¨æ—¶é—´é•¿çš„ç¨‹åºæ”¾åˆ°åŽå°åŽ»å¤„ç† å¯ä»¥ä½¿ç”¨æˆ·ç•Œé¢æ›´åŠ å¸å¼•äººï¼ˆæ¯”å¦‚ç‚¹å‡»æŒ‰é’®ï¼Œä¼šå‡ºçŽ°è¿›åº¦æ¡ï¼‰ å¤„ç†é€Ÿåº¦æ›´å¿«]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>çº¿ç¨‹</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽåŠ¨æ€è§„åˆ’(dynamic programmin)]]></title>
    <url>%2F2019%2F05%2F24%2F%E5%85%B3%E4%BA%8E%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92DP%2F</url>
    <content type="text"><![CDATA[å…¥é—¨refï¼šhttps://www.zhihu.com/question/23995189 ä¾‹å­åœ¨èº«ä¸Šå¸¦ç€ä¸åŒæ•°é¢çš„é’žç¥¨ï¼Œç›®æ ‡æ˜¯å‡‘å‡ºæ¥æŸä¸ªé‡‘é¢wï¼Œä½¿ç”¨å°½é‡å°‘çš„é’žç¥¨ å¦‚æžœç”¨è´ªå¿ƒç®—æ³•ï¼Œå®žé™…ä¸Šå°±æ˜¯å°½å¿«è®©wå˜å¾—æ›´å°ï¼Œæœ‰æ›´å¤§é¢å€¼çš„å°±ç”¨æ›´å¤§é¢å€¼çš„é’žç¥¨ ä½†æ˜¯å¦‚æžœæ¢äº†ä¸€ç»„å…¶ä»–çš„é’žç¥¨é¢å€¼ï¼Œå¯èƒ½å°±ä¼šå‡ºçŽ°é—®é¢˜ï¼ˆæ¯”å¦‚ 1ï¼Œ5ï¼Œ11å‡‘15ï¼‰ å› ä¸ºåœ¨è´ªå¿ƒç®—æ³•é‡Œé¢ï¼Œéœ€è¦å…ˆæŠŠ15é™æˆ4ï¼Œå†æŠŠ4é™ä¸‹æ¥ï¼Œä½†æ˜¯é™4çš„æˆæœ¬å¾ˆé«˜ï¼Œéœ€è¦4å¼ 1 åœ¨è€ƒè™‘çš„æ—¶å€™é¼ ç›®å¯¸å…‰ï¼Œåªè€ƒè™‘äº†çœ¼å‰çš„æƒ…å†µï¼Œæ²¡æœ‰è€ƒè™‘åŽç»­çš„å‘å±• å¦‚æžœå¼€å§‹åˆ—ä¸¾ï¼Œå…¶å®žè¿™ä¸ªé—®é¢˜å°±ä¼šå˜æˆæŽ¥ä¸‹æ¥éœ€è¦å‡‘å‡ºæ¥nï¼Œéœ€è¦f(n)å¼ é’žç¥¨ è¿™æ—¶å€™ï¼Œå‡‘15å…¶å®žå°±å˜æˆäº†ä¸‰ä¸ªæƒ…å†µ f(4) + 1 f(10) + 1 f(14) +1 å¯ä»¥å‘çŽ°å®žé™…ä¸Šf(15)åªå’Œè¿™ä¸‰ä¸ªå€¼æœ‰å…³ç³»ï¼Œä¹Ÿå°±æ˜¯åªå’Œn-1ï¼Œn-5ï¼Œn-11æœ‰å…³ç³» f(n) = min(f(n-1),f(n-5),f(n-11))+1 è¿™æ˜¯ä¸€ä¸ªå¯ä»¥è¿­ä»£çš„å¼å­å¯¹ä¸å¯¹ï¼ å¹¶ä¸å…³å¿ƒåˆ°åº•æ˜¯æ€Žä¹ˆå‡‘å‡ºæ¥çš„ï¼Œåæ­£åªå…³å¿ƒf(w)çš„å€¼ åœ¨ä»£ç å®žçŽ°ä¸Šé¢ï¼Œåªéœ€ä»Žå°åˆ°å¤§å¯¹æ¯”æ‰€æœ‰çš„costå°±å¯ä»¥äº†ï¼Œä¹Ÿå°±æ˜¯å¯¹æ¯”æ–°çš„æ–¹æ¡ˆçš„costæ˜¯ä¸æ˜¯ä¼šæ¯”ä»¥å‰çš„æ–¹æ¡ˆå°ã€‚æ³¨æ„åœ¨æ±‚çš„æ—¶å€™å¯èƒ½ä¼šéœ€è¦i-1/-5/-11çš„å€¼ï¼Œæ‰€ä»¥è¦æŠŠä»Žå¤´åˆ°å°¾çš„å€¼éƒ½è®°å½•ä¸‹æ¥ æ¯”å¦‚è¦æ±‚å‡‘15å—é’±ï¼Œä¼šå…ˆè€ƒè™‘15æ¯”1å¤§ï¼Œé‚£ä¹ˆæŠŠ1å—æ‹¿å‡ºæ¥ï¼Œçœ‹çœ‹å–14å—é’±çš„æ—¶å€™éœ€è¦çš„æ­¥éª¤æ˜¯å¤šå°‘ï¼Œç„¶åŽæŠŠ5å—æ‹¿å‡ºæ¥ï¼Œçœ‹çœ‹æ¯”æ‹¿1å—å·®å¤šå°‘ï¼Œæœ€åŽæ‹¿11ï¼Œçœ‹çœ‹å’Œä¹‹å‰çš„costå·®å¤šå°‘ åŒºåˆ« dpå’Œè´ªå¿ƒç®—æ³•çš„åŒºåˆ«å°±åœ¨äºŽï¼Œdpä¼šåˆ†åˆ«ç®—å‡ºä¸åŒç­–ç•¥çš„ä»£ä»·ï¼Œè€Œè´ªå¿ƒç®—æ³•åŒ…å«ç€å†—ä½™çš„ä¿¡æ¯ï¼ˆåˆ°åº•æ€Žä¹ˆä½¿ç”¨ï¼‰ æ‰€ä»¥å°±æ˜¯æ±‚å‡ºæ¥fn -&gt; å¾—åˆ°æ±‚fnéœ€è¦çš„fc -&gt; æ±‚fcï¼Œä¸åœçš„å¾ªçŽ¯ ä¹Ÿå°±æ˜¯æŠŠä¸€ä¸ªé—®é¢˜æ‹†æˆäº†ä¸åŒçš„å­é—®é¢˜ æ¦‚å¿µ åŽæ— æ•ˆæ€§ ä¸€æ—¦fnç¡®å®šï¼Œæˆ‘ä»¬å°±ä¸éœ€è¦çŸ¥é“æ€Žä¹ˆå¾—åˆ°çš„fnäº†ï¼Œåªåœ¨åŽé¢ç›´æŽ¥ç”¨å°±å¯ä»¥äº† æœ€ä¼˜å­ç»“æž„ åœ¨å¾—åˆ°fnçš„æ—¶å€™æœ¬èº«å¾—åˆ°çš„å°±æ˜¯æœ€ä¼˜çš„fnäº†ï¼Œæ‰€ä»¥åœ¨ç”¨çš„æ—¶å€™æ‰å¯ä»¥æ”¾å¿ƒçš„ç”¨ ä¸€æ—¦é—®é¢˜å¯ä»¥æ‹†æˆå­é—®é¢˜ï¼Œå¹¶ä¸”æ»¡è¶³ä¸Šé¢çš„ä¸¤ä¸ªæ¦‚å¿µï¼Œå°±å¯ä»¥ç”¨dpè§£äº† ä¸ºä»€ä¹ˆå¿« dpå’Œè´ªå¿ƒéƒ½æ˜¯åœ¨ç©ºé—´é‡Œå¯»æ‰¾æœ€ä¼˜è§£ï¼Œä½†æ˜¯dpåœ¨æ‰¾è§£çš„æ—¶å€™å·²ç»æ‰¾åˆ°äº†å­é—®é¢˜çš„æœ€ä¼˜è§£ï¼Œä¹Ÿå°±æ˜¯è¯´ä»–å·²ç»æŠŠå­é—®é¢˜é‡Œé¢ä¸å¯èƒ½çš„çŠ¶æ€æŽ’é™¤æŽ‰äº† ç®—æ³•è®¾è®¡ æŠŠçŽ°åœ¨é¢å¯¹çš„å±€é¢çœ‹åšx å¯¹äºŽxï¼Œéœ€è¦æ±‚å¾—ç­”æ¡ˆæ˜¯fxï¼Œç›®æ ‡æ˜¯æ±‚å‡ºæ¥fTï¼Œæ‰¾å‡ºxå’Œå“ªäº›å±€é¢pæœ‰å…³ï¼Œå†™å‡ºä¸€ä¸ªçŠ¶æ€ä¸“ä¸šæ–¹ç¨‹ï¼Œæ¥æ±‚fpåˆ°fxçš„å…³ç³» ä¹Ÿå°±æ˜¯è€ƒè™‘çŽ°åœ¨æˆ‘æ˜¯è°ï¼Œå’Œæˆ‘ä»Žå“ªé‡Œæ¥ï¼ˆæˆ–è€…æˆ‘åˆ°å“ªé‡ŒåŽ»ï¼‰]]></content>
      <categories>
        <category>ç®—æ³•</category>
        <category>åŠ¨æ€è§„åˆ’</category>
      </categories>
      <tags>
        <tag>åŠ¨æ€è§„åˆ’</tag>
        <tag>DP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nAssignment3StyleTransfer]]></title>
    <url>%2F2019%2F05%2F22%2FCS231nAssignment3StyleTransfer%2F</url>
    <content type="text"><![CDATA[target çŽ°åœ¨æœ‰ä¸¤å¼ å›¾ç‰‡ï¼Œéœ€è¦äº§ç”Ÿä¸€äº›æ–°çš„å›¾ç‰‡æ˜¯ä¸€å¼ å›¾ç‰‡çš„å†…å®¹ä½†æ˜¯æ˜¯å¦ä¸€å¼ å›¾ç‰‡çš„style é¦–å…ˆæˆ‘ä»¬å¸Œæœ›å¯ä»¥æž„å»ºä¸€ä¸ªloss functionï¼Œå¯ä»¥è¿žæŽ¥styleå’Œæ¯ä¸ªä¸åŒçš„imageï¼Œç„¶åŽåœ¨æ¯ä¸ªå›¾ç‰‡çš„pixelä¸Šé¢é™ä½Žgradient åœ¨è¿™ä¸ªé‡Œé¢ç”¨squeezeNetï¼ˆåœ¨ImageNetä¸Šé¢pretrainçš„ï¼‰æ¥æå–å›¾ç‰‡çš„feature é¢„å…ˆè®¾å®šå¥½çš„å‡½æ•° å› ä¸ºåœ¨è¿™éƒ¨åˆ†ç›´æŽ¥å¤„ç†çš„æ˜¯jpegçš„å›¾ç‰‡è€Œä¸æ˜¯cifar-10çš„å›¾ç‰‡äº†ï¼Œæ‰€ä»¥åœ¨è¿™éƒ¨åˆ†éœ€è¦å¯¹å‡ºç‰‡è¿›è¡Œé¢„å¤„ç† åŒæ—¶éœ€è¦è®¾å®šä¸€ä¸ªdtype = torch.FloatTensor æ¥è®¾è®¡æ˜¯ç”¨CPUè·‘è¿˜æ˜¯ç”¨GPUè·‘ï¼ˆGPUçš„é‡Œé¢ä¼šå¸¦cudaï¼‰ CNN = torchvision.models.squeezenet1_1(pretrained=True).featuresæå–squeezenetçš„modelï¼Œå¹¶ä¸”è®¾å®šCNNçš„typeç­‰äºŽä¸Šé¢è®¾å®šå¥½çš„dtype å› ä¸ºä¸éœ€è¦å†è¿›è¡Œè®­ç»ƒäº†ï¼Œéœ€è¦æŠŠcnné‡Œé¢çš„æ‰€æœ‰è‡ªåŠ¨è®¡ç®—gradçš„åŠŸèƒ½å…³æŽ‰ æå–ç‰¹å¾ è¾“å…¥ xï¼Œä¸€ä¸ªtensorï¼Œå¤§å°æ˜¯(N,C,H,W),é‡Œé¢æ˜¯ä¸€ä¸ªminibatchçš„æ•°æ® cnnï¼Œåˆšæ‰è½½å…¥å¥½çš„model è¾“å‡º featuresï¼Œä¸€ä¸ªlistï¼Œfeatures[i]çš„å¤§å°æ˜¯(N,C_i,H_i,W_i) åœ¨ä¸åŒå±‚å¾—åˆ°çš„featureä¼šæœ‰ä¸åŒçš„channelçš„æ•°é‡ä»¥åŠHå’ŒWçš„å¤§å° å®žçŽ°ï¼š åœ¨å…·ä½“çš„ä»£ç å®žçŽ°é‡Œé¢ï¼Œç›´æŽ¥ç”¨valueå¾—åˆ°æ¯ä¸€å±‚ä¹‹åŽçš„ç»“æžœï¼Œä¸‹ä¸€å±‚çš„è¾“å…¥å°±æ˜¯ä¸Šä¸€å±‚å¾—åˆ°çš„ç»“æžœ123456789def extract_features(x, cnn): features = [] prev_feat = x for i, module in enumerate(cnn._modules.values()): next_feat = module(prev_feat) features.append(next_feat) prev_feat = next_feat return features è®¡ç®—losslossä¸€å…±ç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼Œåˆ†åˆ«æ˜¯ï¼šå›¾ç‰‡contentçš„loss + styleçš„loss + total var loss æˆ‘ä»¬è¿™ä¸ªä¸œè¥¿çš„ç›®çš„æ˜¯ç”¨ä¸€å¼ å›¾ç‰‡çš„å†…å®¹å’Œå¦ä¸€ä¸ªå›¾ç‰‡çš„style å½“å†…å®¹åç¦»äº†contentå›¾ç‰‡çš„contentï¼Œstyleåç¦»äº†stypeå›¾ç‰‡çš„æ—¶å€™å°±éœ€è¦penalizeï¼ˆå¤„ç½šï¼‰ ä¸ºäº†å®žçŽ°è¿™ä¸ªåŠŸèƒ½ï¼Œæˆ‘ä»¬éœ€è¦ç”¨hybridçš„lossï¼Œå¹¶ä¸”ä¸æ˜¯åœ¨weightsä¸Šé¢è°ƒå‚ï¼Œè€Œæ˜¯åœ¨æ¯å¼ å›¾ç‰‡çš„pixelä¸Šé¢è°ƒæ•´ content loss è¿™ä¸ªå‡½æ•°è¡¡é‡ç”Ÿæˆçš„å›¾ç‰‡çš„feature mapå’ŒåŽŸæ¥ä½œä¸ºcontentçš„å›¾ç‰‡åç¦»å¤šå°‘ æˆ‘ä»¬åªå…³å¿ƒè¿™ä¸ªnetworké‡Œé¢çš„ä¸€å±‚çš„è¡¨ç¤ºï¼Œè¿™ä¸€å±‚ä¼šæœ‰è‡ªå·±ç‰¹å®šçš„channelæ•°é‡ä»¥åŠfilterçš„å¤§å° æˆ‘ä»¬éœ€è¦æŠŠè¿™ä¸ªfeature map reshapeï¼ŒæŠŠæ‰€æœ‰çš„ç©ºé—´ä½ç½®ç»„åˆåˆ°åŒä¸€ä¸ªç»´åº¦ä¸Šé¢ ä½†æ˜¯åœ¨å®žé™…çš„å®žçŽ°ä¸Šé¢ï¼Œæˆ‘ä»¬ä¸éœ€è¦å†reshapeäº†ï¼Œå› ä¸ºå¤§å°å¯ä»¥ç›´æŽ¥å¯¹åº”å¤„ç†äº† 123456789101112131415161718def content_loss(content_weight, content_current, content_original): """ Compute the content loss for style transfer. Inputs: - content_weight: Scalar giving the weighting for the content loss. - content_current: features of the current image; this is a PyTorch Tensor of shape (1, C_l, H_l, W_l). - content_target: features of the content image, Tensor with shape (1, C_l, H_l, W_l). Returns: - scalar content loss """ # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** return content_weight * torch.sum((content_original - content_current)**2) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** style losså¯¹äºŽä¸€ä¸ªç»™å®šçš„å±‚layerï¼Œå®šä¹‰loss è®¡ç®—Gram Matï¼ŒGï¼Œè¡¨ç¤ºä¸åŒfilterçš„ç›¸å…³æ€§ã€‚è¿™ä¸ªçŸ©é˜µæ˜¯ä¸ªåæ–¹å·®çŸ©é˜µï¼Œæˆ‘ä»¬å¸Œæœ›å½¢æˆçš„å›¾ç‰‡çš„activation ç»Ÿè®¡å’Œstyleå›¾ç‰‡çš„å¯ä»¥matchï¼Œè®¡ç®—è¿™ä¸¤ä¸ªçš„åæ–¹å·®å°±æ˜¯ä¸€ä¸ªåŠžæ³•ï¼ˆå¹¶ä¸”ç»è¿‡éªŒè¯æ•ˆæžœæ¯”è¾ƒå¥½ï¼‰ ç»™å®šä¸€ä¸ªfeature mapï¼ŒGçŸ©é˜µçš„å½¢çŠ¶åº”è¯¥æ˜¯ï¼ˆClï¼ŒClï¼‰ã€‚Clæ˜¯è¿™ä¸€å±‚çš„filterçš„æ•°é‡ã€‚é‡Œé¢çš„å…ƒç´ åº”è¯¥ç­‰äºŽä¸¤ä¸ªfilterçš„ä¹˜ç§¯ æŠŠç”Ÿæˆå›¾ç‰‡çš„Gå’Œstyleå›¾ç‰‡çš„Gåšå·®ï¼Œå¹³æ–¹å’Œå°±æ˜¯ä¸€å±‚çš„loss æ‰€æœ‰å±‚çš„lossåŠ åœ¨ä¸€èµ·å°±æ˜¯æ€»å…±çš„loss G Mat implement view(),å½¢æˆä¸€ä¸ªå†…å®¹ç›¸åŒä½†æ˜¯å¤§å°ä¸åŒçš„tensor .matmul ä¸¤ä¸ªtensorç›¸ä¹˜ .permute ç»™tensoré‡Œé¢çš„ç»´åº¦æ¢ä½12345678910111213141516171819202122232425262728293031def gram_matrix(features, normalize=True): """ Compute the Gram matrix from features. Inputs: - features: PyTorch Tensor of shape (N, C, H, W) giving features for a batch of N images. - normalize: optional, whether to normalize the Gram matrix If True, divide the Gram matrix by the number of neurons (H * W * C) Returns: - gram: PyTorch Tensor of shape (N, C, C) giving the (optionally normalized) Gram matrices for the N input images. """ # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N,C,H,W = features.size() # N,C,M features = features.view(N,C,H*W) # N,C,M x N,M,C -&gt; N,C,C gram = features.matmul(features.permute(0,2,1)) if normalize==True: gram /= (H*W*C) return gram # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** loss implement è¾“å…¥ featsï¼šçŽ°åœ¨å›¾ç‰‡çš„æ¯ä¸€å±‚çš„featureï¼Œä»Žä¸Šé¢çš„æå–ç‰¹å¾å‡½æ•°å¾—åˆ° style_layersï¼šindices style_targetsï¼šå’Œä¸Šé¢çš„é•¿åº¦ç›¸åŒï¼Œè®¡ç®—çš„æ˜¯ç¬¬iå±‚åŽŸå›¾ç‰‡å¾—åˆ°çš„G Mat style_weightsï¼šscalar åœ¨è®¡ç®—çš„æ—¶å€™åªéœ€è¦è€ƒè™‘æ¯ä¸€å±‚é‡Œé¢è®¡ç®—å‡ºæ¥çš„çŽ°åœ¨çš„G Matï¼ˆæ³¨æ„ç´¢å¼•ä¸æ˜¯iï¼‰å’ŒåŽŸå›¾ç‰‡çš„Gï¼Œå’Œä¸Šé¢ä¸€æ ·çš„è®¡ç®—å°±å¯ä»¥äº† 123456789101112131415161718192021222324252627282930313233# Now put it together in the style_loss function...def style_loss(feats, style_layers, style_targets, style_weights): """ Computes the style loss at a set of layers. Inputs: - feats: list of the features at every layer of the current image, as produced by the extract_features function. - style_layers: List of layer indices into feats giving the layers to include in the style loss. - style_targets: List of the same length as style_layers, where style_targets[i] is a PyTorch Tensor giving the Gram matrix of the source style image computed at layer style_layers[i]. - style_weights: List of the same length as style_layers, where style_weights[i] is a scalar giving the weight for the style loss at layer style_layers[i]. Returns: - style_loss: A PyTorch Tensor holding a scalar giving the style loss. """ # Hint: you can do this with one for loop over the style layers, and should # not be very much code (~5 lines). You will need to use your gram_matrix function. # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** loss = torch.tensor(0.).type(dtype) for i in range(len(style_layers)): G_Mat = gram_matrix(feats[style_layers[i]]) loss_layer = style_weights[i] * torch.sum((style_targets[i] - G_Mat)**2) loss += loss_layer return loss # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** total-variation reg ä¸ºäº†è®©å›¾ç‰‡æ˜¾ç¤ºçš„å†…å®¹æ›´åŠ å¹³æ»‘ï¼ŒåŠ å…¥äº†è¿™ä¸ªæƒ©ç½šéƒ¨åˆ† è®¡ç®—çš„æ–¹æ³•å¯ä»¥æ˜¯è®¡ç®—æ¯ä¸ªåƒç´ å’Œå®ƒç›¸é‚»åƒç´ çš„å·®çš„å¹³æ–¹å’Œï¼ˆç›¸é‚»åƒç´ åˆ†åˆ«åŒ…æ‹¬åž‚ç›´å’Œæ°´å¹³ï¼‰ éœ€è¦è®©ç»“æžœvecåŒ–ï¼Œç›´æŽ¥ç”¨-1æŠŠçŸ©é˜µé”™ä½ä¸€ä¸ª 123456789101112131415161718192021def tv_loss(img, tv_weight): """ Compute total variation loss. Inputs: - img: PyTorch Variable of shape (1, 3, H, W) holding an input image. - tv_weight: Scalar giving the weight w_t to use for the TV loss. Returns: - loss: PyTorch Variable holding a scalar giving the total variation loss for img weighted by tv_weight. """ # Your implementation should be vectorized and not require any loops! # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** H_var = torch.sum((img[:,:,1:,:] - img[:,:,:-1,:])**2) W_var = torch.sum((img[:,:,:,1:] - img[:,:,:,:-1])**2) return (H_var + W_var) * tv_weight # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** å·²ç»å†™å¥½äº†è½¬åŒ–styleçš„å‡½æ•° é¦–å…ˆæå–contentå’Œstyleå›¾ç‰‡çš„ç‰¹å¾ ç„¶åŽåˆå§‹åŒ–éœ€è¦ç”Ÿæˆçš„å›¾ç‰‡ï¼Œè¿™å¼ å›¾ç‰‡ä¸Šé¢éœ€è¦æ‰“å¼€grad è®¾ç½®å¥½hyperï¼Œè®¾å®šå¥½optimizer ç„¶åŽåœ¨ä¸€å®šçš„èŒƒå›´é‡Œï¼Œç”¨cnnæå–çŽ°åœ¨å›¾ç‰‡çš„ç‰¹å¾ ç”¨çŽ°åœ¨çš„ç‰¹å¾è®¡ç®—lossï¼Œç„¶åŽæ”¹å˜çŽ°åœ¨çš„å›¾ç‰‡]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
        <category>CS231nä½œä¸š</category>
      </categories>
      <tags>
        <tag>style transfer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nassignment3Vis]]></title>
    <url>%2F2019%2F05%2F21%2FCS231nassignment3Vis%2F</url>
    <content type="text"><![CDATA[Network Visualization (PyTorch) åœ¨è¿™éƒ¨åˆ†ç”¨äº†ä¸€ä¸ªå·²ç»åœ¨ImageNetä¸Šé¢pretrainè¿‡çš„CNN ç”¨è¿™ä¸ªCNNæ¥å®šä¹‰ä¸€ä¸ªloss functionï¼Œç„¶åŽç”¨è¿™ä¸ªlossæ¥æµ‹é‡çŽ°åœ¨çš„ä¸é«˜å…´ç¨‹åº¦ backçš„æ—¶å€™è®¡ç®—è¿™ä¸ªlosså¯¹äºŽæ¯ä¸ªåƒç´ çš„gradient ä¿æŒè¿™ä¸ªmodelä¸å˜ï¼Œä½†æ˜¯åœ¨å›¾ç‰‡ä¸Šé¢å±•ç¤ºå‡ºæ¥gradientsçš„ä¸‹é™ï¼Œå½¢æˆè®©lossæœ€å°çš„å›¾ç‰‡ è¿™ä¸ªä½œä¸šä¸€å…±åˆ†æˆä¸‰ä¸ªéƒ¨åˆ†ï¼š saliency mapï¼šä¸€ä¸ªæ¯”è¾ƒå¿«çš„æ–¹æ³•æ¥å±•ç¤ºè¿™ä¸ªå›¾ç‰‡å“ªä¸ªéƒ¨åˆ†å½±å“äº†netåˆ†ç±»çš„å†³å®š fooling imageï¼šæ‰°ä¹±ä¸€ä¸ªå›¾ç‰‡ï¼Œè®©ä»–çœ‹èµ·æ¥è·Ÿäººä¼¼çš„ï¼Œä½†æ˜¯ä¼šè¢«è¯¯åˆ†ç±» class visualizationï¼šå½¢æˆå¯ä»¥å¾—åˆ°æœ€å¤§åˆ†ç±»å¾—åˆ†çš„å›¾ç‰‡ æ³¨æ„è¿™é‡Œéœ€è¦å…ˆæ¿€æ´»condaï¼Œä¸ç„¶åœ¨jupteré‡Œé¢torchä¼šæŠ¥é”™ äº‹å…ˆå¤„ç† äº‹å…ˆå®šä¹‰äº†å‡½æ•°preprocessçš„éƒ¨åˆ†ï¼Œå› ä¸ºpretrainçš„æ—¶å€™ä¹Ÿæ˜¯æå‰è¿›è¡Œå¥½äº†é¢„å¤„ç† éœ€è¦ä¸‹è½½ä¸‹æ¥é¢„å¤„ç†çš„æ¨¡åž‹ï¼Œè¿™é‡Œç”¨çš„æ˜¯SqueezeNetï¼Œå› ä¸ºè¿™æ ·å¯ä»¥ç›´æŽ¥åœ¨CPUä¸Šé¢å½¢æˆå›¾ç‰‡ è¯»å–ä¸€éƒ¨åˆ†ImageNeté‡Œé¢çš„å›¾ç‰‡çœ‹ä¸€çœ‹æ˜¯ä»€ä¹ˆæ ·å­çš„ saliency maps saliencyå‘Šè¯‰æˆ‘ä»¬æ¯ä¸ªpixelå¯¹åˆ†ç±»å¾—åˆ†çš„å½±å“ ä¸ºäº†è®¡ç®—è¿™ä¸ªä¸œè¥¿ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ²¡æœ‰æ­£åˆ™åŒ–ä¹‹å‰çš„scoreå¯¹äºŽæ­£ç¡®åˆ†ç±»çš„gradientï¼ˆå…·ä½“åˆ°æ¯ä¸ªpixelï¼‰ æ¯”å¦‚å›¾ç‰‡çš„å¤§å°æ˜¯3xHxWï¼Œé‚£ä¹ˆå¾—åˆ°çš„gradientçš„å½¢çŠ¶ä¹Ÿåº”è¯¥æ˜¯3xHxW è¡¨ç¤ºçš„å°±æ˜¯è¿™ä¸ªpixelæ”¹å˜çš„è¯å¯¹äºŽæ•´ä¸ªç»“æžœæ”¹å˜çš„å½±å“ ä¸ºäº†è®¡ç®—ï¼Œæˆ‘ä»¬å–æ¯ä¸ªgradientçš„ç»å¯¹å€¼ï¼Œç„¶åŽå–ä¸‰ä¸ªchannelé‡Œé¢çš„æœ€å¤§å€¼ï¼Œæœ€åŽå¾—åˆ°çš„å¤§å°æ˜¯HxW gather method å°±åƒåœ¨assignment1é‡Œé¢é€‰æ‹©ä¸€ä¸ªçŸ©é˜µé‡Œé¢çš„æœ€å¤§å€¼ä¸€æ ·ï¼Œgatherè¿™ä¸ªæ–¹æ³•å°±æ˜¯åœ¨s.gather(1, y.view(-1, 1)).squeeze()ä¸€ä¸ªNï¼ŒCçš„çŸ©é˜µsé‡Œé¢é€‰æ‹©å¯¹åº”çš„yé‚£ä¸ªçš„å€¼ç„¶åŽå½¢æˆä¸€ä¸ªè¡Œçš„æ•°ç»„ compute_saliency_map è¾“å…¥ï¼š X:è¾“å…¥çš„å›¾ç‰‡ (N,3,H,W) y:label (N,) model:é¢„è®­ç»ƒå¥½çš„æ¨¡åž‹ è¾“å‡ºï¼š saliencyï¼Œå¤§å°æ˜¯ï¼ˆNï¼ŒHï¼ŒWï¼‰ æ³¨æ„ï¼Œå› ä¸ºtorchè¿™ä¸ªå¯¹è±¡è‡ªå·±æœ¬æ¥å°±å·²ç»å¸¦ç€gradäº†ï¼Œæ‰€ä»¥ç›´æŽ¥æ±‚å‡ºæ¥å°±å¯ä»¥äº†ï¼Œä½†æ˜¯æ³¨æ„éœ€è¦å®šä¹‰ä¸€ä¸‹backwardä¹‹åŽçš„å¤§å°åº”è¯¥æ˜¯å¤šå°‘ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def compute_saliency_maps(X, y, model): """ Compute a class saliency map using the model for images X and labels y. Input: - X: Input images; Tensor of shape (N, 3, H, W) - y: Labels for X; LongTensor of shape (N,) - model: A pretrained CNN that will be used to compute the saliency map. Returns: - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input images. """ # Make sure the model is in "test" mode model.eval() # Make input tensor require gradient X.requires_grad_() saliency = None ############################################################################## # TODO: Implement this function. Perform a forward and backward pass through # # the model to compute the gradient of the correct class score with respect # # to each input image. You first want to compute the loss over the correct # # scores (we'll combine losses across a batch by summing), and then compute # # the gradients with a backward pass. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** #forward #NxC scores = model(X) #N correct_scores = scores.gather(1,y.view(-1,1)).squeeze() #backward correct_scores.backward(torch.ones(correct_scores.size())) saliency = X.grad saliency = saliency.abs() saliency,_ = torch.max(saliency, dim = 1) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return saliency fooling images å¯ä»¥ç”Ÿæˆfooling imageï¼Œç»™ä¸€ä¸ªimageå’Œä¸€ä¸ªç›®æ ‡classï¼Œæˆ‘ä»¬è®©gradientä¸€ç›´å‡é«˜ï¼ŒåŽ»è®©ç›®æ ‡çš„scoreæœ€å¤§ï¼Œä¸€ç›´åˆ°æœ€åŽçš„åˆ†ç±»æ˜¯ç›®æ ‡çš„åˆ†ç±» è¾“å…¥ X (1,3,224,224) target_y åœ¨0-1000çš„èŒƒå›´é‡Œé¢ model é¢„è®­ç»ƒçš„CNN è¾“å‡ºï¼š x_fooling TODO When computing an update step, first normalize the gradient:# dX = learning_rate * g / ||g||_2 éœ€è¦è‡ªå·±å†™ä¸€ä¸ªè®­ç»ƒçš„éƒ¨åˆ† 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def make_fooling_image(X, target_y, model): """ Generate a fooling image that is close to X, but that the model classifies as target_y. Inputs: - X: Input image; Tensor of shape (1, 3, 224, 224) - target_y: An integer in the range [0, 1000) - model: A pretrained CNN Returns: - X_fooling: An image that is close to X, but that is classifed as target_y by the model. """ # Initialize our fooling image to the input image, and make it require gradient X_fooling = X.clone() X_fooling = X_fooling.requires_grad_() learning_rate = 1 ############################################################################## # TODO: Generate a fooling image X_fooling that the model will classify as # # the class target_y. You should perform gradient ascent on the score of the # # target class, stopping when the model is fooled. # # When computing an update step, first normalize the gradient: # # dX = learning_rate * g / ||g||_2 # # # # You should write a training loop. # # # # HINT: For most examples, you should be able to generate a fooling image # # in fewer than 100 iterations of gradient ascent. # # You can print your progress over iterations to check your algorithm. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** for i in range(100): scores = model(X_fooling) index = torch.argmax(scores,dim = 1) if index[0] == target_y: break target_score = scores[0,target_y] target_score.backward() grad = X_fooling.grad.data X_fooling.data += learning_rate * (grad/grad.norm()) X_fooling.grad.zero_() # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return X_fooling class visualization ä»Žä¸€ä¸ªéšæœºçš„noiseå¼€å§‹ç„¶åŽå¾€ç›®æ ‡çš„classä¸Šé¢å¢žåŠ gradient 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980def create_class_visualization(target_y, model, dtype, **kwargs): """ Generate an image to maximize the score of target_y under a pretrained model. Inputs: - target_y: Integer in the range [0, 1000) giving the index of the class - model: A pretrained CNN that will be used to generate the image - dtype: Torch datatype to use for computations Keyword arguments: - l2_reg: Strength of L2 regularization on the image - learning_rate: How big of a step to take - num_iterations: How many iterations to use - blur_every: How often to blur the image as an implicit regularizer - max_jitter: How much to gjitter the image as an implicit regularizer - show_every: How often to show the intermediate result """ model.type(dtype) l2_reg = kwargs.pop('l2_reg', 1e-3) learning_rate = kwargs.pop('learning_rate', 25) num_iterations = kwargs.pop('num_iterations', 100) blur_every = kwargs.pop('blur_every', 10) max_jitter = kwargs.pop('max_jitter', 16) show_every = kwargs.pop('show_every', 25) # Randomly initialize the image as a PyTorch Tensor, and make it requires gradient. img = torch.randn(1, 3, 224, 224).mul_(1.0).type(dtype).requires_grad_() for t in range(num_iterations): # Randomly jitter the image a bit; this gives slightly nicer results ox, oy = random.randint(0, max_jitter), random.randint(0, max_jitter) img.data.copy_(jitter(img.data, ox, oy)) ######################################################################## # TODO: Use the model to compute the gradient of the score for the # # class target_y with respect to the pixels of the image, and make a # # gradient step on the image using the learning rate. Don't forget the # # L2 regularization term! # # Be very careful about the signs of elements in your code. # ######################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** scores = model(img) target_score = scores[0,target_y] target_score.backward() grad = img.grad.data grad -= 2*l2_reg * img.data img.data += learning_rate * (grad/grad.norm()) img.grad.zero_() # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ######################################################################## # END OF YOUR CODE # ######################################################################## # Undo the random jitter img.data.copy_(jitter(img.data, -ox, -oy)) # As regularizer, clamp and periodically blur the image for c in range(3): lo = float(-SQUEEZENET_MEAN[c] / SQUEEZENET_STD[c]) hi = float((1.0 - SQUEEZENET_MEAN[c]) / SQUEEZENET_STD[c]) img.data[:, c].clamp_(min=lo, max=hi) if t % blur_every == 0: blur_image(img.data, sigma=0.5) # Periodically show the image if t == 0 or (t + 1) % show_every == 0 or t == num_iterations - 1: plt.imshow(deprocess(img.data.clone().cpu())) class_name = class_names[target_y] plt.title('%s\nIteration %d / %d' % (class_name, t + 1, num_iterations)) plt.gcf().set_size_inches(4, 4) plt.axis('off') plt.show() return deprocess(img.data.cpu())]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
        <category>CS231nä½œä¸š</category>
      </categories>
      <tags>
        <tag>å¯è§†åŒ–</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nassignment3LSTM]]></title>
    <url>%2F2019%2F05%2F17%2FCS231nassignment3LSTM%2F</url>
    <content type="text"><![CDATA[targetimplement LSTM update rule and use it for image captioning LSTM åœ¨vanilla RNNé‡Œé¢ï¼Œå¯ä»¥æ ¹æ®vanillaæ¥è®¡ç®—é•¿çš„sequenceï¼Œä½†æ˜¯åŒæ ·ä¼šå› ä¸ºä¸åœçš„ä¹˜çŸ©é˜µå¯¼è‡´gradientçˆ†ç‚¸çš„é—®é¢˜ï¼ŒLSTMä¸»è¦å°±æ˜¯ç”¨äº†ä¸€ä¸ªå…¶ä»–çš„update ruleè§£å†³äº†è¿™ä¸ªé—®é¢˜ å’Œvanilla RNNå·®ä¸å¤šï¼ŒçŽ°åœ¨è¿™ä¸ªstepçš„xï¼Œå‰ä¸€ä¸ªhidden stateã€‚LSTMä¿æŒç€H-dçš„cell stateï¼Œæ‰€ä»¥ä¹Ÿä¼šä»Žå‰ä¸€ä¸ªæŽ¥æ”¶åˆ°å‰ä¸€ä¸ªçš„cell stateã€‚ LSTMä¼šå­¦ä¸€ä¸ªinput-to-hiddençš„çŸ©é˜µ 4HxDï¼Œ hidden-to-hiddençš„çŸ©é˜µ 4HxHï¼Œ bias 4H åœ¨æ¯ä¸€éƒ¨éƒ½ä¼šå…ˆè®¡ç®—è¢«æ¿€æ´»ä¹‹åŽçš„å‡½æ•°ï¼ˆ4Hï¼‰ï¼Œç„¶åŽæŠŠè¿™ä¸ªç»“æžœaåˆ†æˆå››ä¸ªéƒ¨åˆ†ï¼Œæ¯ä¸ªéƒ¨åˆ†çš„å¤§å°æ˜¯H æ ¹æ®è¿™å››ä¸ªéƒ¨åˆ†è®¡ç®—input gateï¼Œforget gateï¼Œoutput gateï¼Œblock gate å‰ä¸‰ä¸ªéƒ½ç”¨sigmoidæ¿€æ´»ï¼Œæœ€åŽä¸€ä¸ªç”¨tanhæ¿€æ´» ç„¶åŽç”¨ä¸Šé¢çš„å››ä¸ªå‚æ•°è®¡ç®—ä¸‹ä¸€ä¸ªcell stateå’Œhidden state step forward è¾“å…¥çš„å¤§å°æ˜¯Dï¼Œhiddençš„å¤§å°æ˜¯Hï¼Œminibatchçš„å¤§å°æ˜¯N input x (N,D) prev_h (N,H) prev_c (N,H) Wx input 2 hidden (D,4H) Wh hidden 2 hidden (H,4H) bias, (4H) output next_h (N,H) next_c (N,H) cache æŒ‰ç…§ä¹‹å‰ç»™çš„å…¬å¼ç›´æŽ¥è®¡ç®—å°±è¡Œäº†ï¼Œå…¶å®žå°±æ˜¯æŠŠåŽŸæ¥æ±‚å‡ºæ¥çš„å€¼åˆ†æˆäº†å››ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«æ±‚å‡ºæ¥äº†å››ä¸ªæ–°çš„å€¼ï¼Œç”¨è¿™å››ä¸ªæ–°çš„å€¼çš„å…¬å¼å¯ä»¥å¾—åˆ°ä¸‹ä¸€ä¸ªçŠ¶æ€çš„cå’Œh step backward input dnext_h (N,H) éƒ½æ˜¯ä¸Šé¢ä¸€ä¸ªå›žæ¥çš„ dnext_c (N,H) cache output dx(N,D) dprev_h (N,H) dprev_c (N,H) dWx (D,4H) dWh (H,4H) db (4H) æŒ‰ç€æ­£æ–¹å‘è®¡ç®—çš„é¡ºåºbackå›žåŽ»å°±å¯ä»¥äº†ï¼Œæ³¨æ„è¿™é‡Œæœ‰ä¸ªé—®é¢˜å°±æ˜¯å› ä¸ºnext_cè¢«ç”¨æ¥è®¡ç®—next häº†ï¼Œæ‰€ä»¥dnext_céœ€è¦å†æ±‚ä¸€ä¸‹å…³äºŽnext hçš„å¯¼æ•°ï¼Œå¹¶ä¸”æŠŠæ±‚å‡ºæ¥çš„æ–°çš„å€¼åŠ åœ¨ä»¥å‰çš„ä¸œè¥¿ä¸Šé¢ åŽé¢çš„çŸ©é˜µè®¡ç®—å°ºå¯¸ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124def lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b): """ Forward pass for a single timestep of an LSTM. The input data has dimension D, the hidden state has dimension H, and we use a minibatch size of N. Note that a sigmoid() function has already been provided for you in this file. Inputs: - x: Input data, of shape (N, D) - prev_h: Previous hidden state, of shape (N, H) - prev_c: previous cell state, of shape (N, H) - Wx: Input-to-hidden weights, of shape (D, 4H) - Wh: Hidden-to-hidden weights, of shape (H, 4H) - b: Biases, of shape (4H,) Returns a tuple of: - next_h: Next hidden state, of shape (N, H) - next_c: Next cell state, of shape (N, H) - cache: Tuple of values needed for backward pass. """ next_h, next_c, cache = None, None, None ############################################################################# # TODO: Implement the forward pass for a single timestep of an LSTM. # # You may want to use the numerically stable sigmoid implementation above. # ############################################################################# # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, H = prev_h.shape # -&gt; N,4H a = x.dot(Wx) + prev_h.dot(Wh) + b a_i = a[:, :H] a_f = a[:, H:2 * H] a_o = a[:, 2 * H:3 * H] a_g = a[:, 3 * H:] i = sigmoid(a_i) f = sigmoid(a_f) o = sigmoid(a_o) g = np.tanh(a_g) next_c = f * prev_c + i * g next_h = o * np.tanh(next_c) cache = (x, prev_h, prev_c, Wx, Wh, a, i, f, o, g, next_c, next_h) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return next_h, next_c, cachedef lstm_step_backward(dnext_h, dnext_c, cache): """ Backward pass for a single timestep of an LSTM. Inputs: - dnext_h: Gradients of next hidden state, of shape (N, H) - dnext_c: Gradients of next cell state, of shape (N, H) - cache: Values from the forward pass Returns a tuple of: - dx: Gradient of input data, of shape (N, D) - dprev_h: Gradient of previous hidden state, of shape (N, H) - dprev_c: Gradient of previous cell state, of shape (N, H) - dWx: Gradient of input-to-hidden weights, of shape (D, 4H) - dWh: Gradient of hidden-to-hidden weights, of shape (H, 4H) - db: Gradient of biases, of shape (4H,) """ dx, dprev_h, dprev_c, dWx, dWh, db = None, None, None, None, None, None ############################################################################# # TODO: Implement the backward pass for a single timestep of an LSTM. # # # # HINT: For sigmoid and tanh you can compute local derivatives in terms of # # the output value from the nonlinearity. # ############################################################################# # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, H = dnext_h.shape x, prev_h, prev_c, Wx, Wh, a, i, f, o, g, next_c, next_h = cache # dnext_h/do -&gt; do do = np.tanh(next_c) * dnext_h # dnext_h/dnext_c dnext_c = o * (1 - np.tanh(next_c) ** 2) * dnext_h + dnext_c # dnext_c/df -&gt; df df = prev_c * dnext_c # dnext_c/dprev_c dprev_c = f * dnext_c # dnext_c/di di = g * dnext_c # dnext_c/dg dg = i * dnext_c da = np.zeros((N, 4 * H)) # sigmoid i da[:, :H] = i * (1 - i) * di da[:, H:2 * H] = f * (1 - f) * df da[:, 2 * H:3 * H] = o * (1 - o) * do da[:, 3 * H:] = (1 - g * g) * dg # a = x.dot(Wx) + prev_h.dot(Wh) + b # N,4H D,4H dx = da.dot(Wx.T) # N,D N,4H dWx = x.T.dot(da) # N,4H H,4H dprev_h = da.dot(Wh.T) # N,H N,4H dWh = prev_h.T.dot(da) # da N,4H db = np.sum(da, axis=0) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dx, dprev_h, dprev_c, dWx, dWh, db forward è¾“å…¥äº†ä¸€å¤§ä¸²dataï¼Œå‡è®¾è¾“å…¥çš„dataåŒ…æ‹¬äº†Tä¸ªvectorï¼Œæ¯ä¸ªçš„dimæ˜¯Dï¼Œç”¨çš„hiddençš„å¤§å°æ˜¯Hï¼Œåœ¨Nçš„minibatchä¸Šé¢è¿›è¡Œï¼Œè¿”å›žå¯¹äºŽæ‰€æœ‰time stepçš„hidden state åˆå§‹åŒ–çš„cellæ˜¯0ï¼Œä¸ä¼šreturn cell stateï¼Œåªæ˜¯LSTMè‡ªå·±çš„å˜é‡ è¾“å…¥ x (N,T,D) h0, (N,H) Wx (D,4H) Wh (H,4H) b (4H) out h (N,T,D) cache æ³¨æ„hæ˜¯éœ€è¦åˆå§‹åŒ–ä¸º0çš„ï¼Œæ¯æ¬¡foré‡Œé¢æ‹¿å‡ºæ¥çš„æ˜¯hé‡Œé¢çš„ä¸€éƒ¨åˆ†æ¥èµ‹å€¼ backward å’Œä¹‹å‰çš„å·®ä¸å¤šï¼Œæ³¨æ„Wå’Œbéƒ½æ˜¯è¦ç§¯ç´¯çš„ï¼Œä¹‹å‰éƒ½æ˜¯è¦åˆå§‹åŒ–çš„ è€Œä¸”backçš„æ—¶å€™è¦ç”¨reversedçš„é¡ºåº 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104def lstm_forward(x, h0, Wx, Wh, b): """ Forward pass for an LSTM over an entire sequence of data. We assume an input sequence composed of T vectors, each of dimension D. The LSTM uses a hidden size of H, and we work over a minibatch containing N sequences. After running the LSTM forward, we return the hidden states for all timesteps. Note that the initial cell state is passed as input, but the initial cell state is set to zero. Also note that the cell state is not returned; it is an internal variable to the LSTM and is not accessed from outside. Inputs: - x: Input data of shape (N, T, D) - h0: Initial hidden state of shape (N, H) - Wx: Weights for input-to-hidden connections, of shape (D, 4H) - Wh: Weights for hidden-to-hidden connections, of shape (H, 4H) - b: Biases of shape (4H,) Returns a tuple of: - h: Hidden states for all timesteps of all sequences, of shape (N, T, H) - cache: Values needed for the backward pass. """ h, cache = None, None ############################################################################# # TODO: Implement the forward pass for an LSTM over an entire timeseries. # # You should use the lstm_step_forward function that you just defined. # ############################################################################# # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, T, D = x.shape N, H = h0.shape prev_h = h0 prev_c = np.zeros((N, H)) cache = &#123;&#125; h = np.zeros((N, T, H)) for step in range(T): prev_h, prev_c, cache_step = lstm_step_forward( x[:, step, :], prev_h, prev_c, Wx, Wh, b) h[:, step, :] = prev_h cache[step] = cache_step # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return h, cachedef lstm_backward(dh, cache): """ Backward pass for an LSTM over an entire sequence of data.] Inputs: - dh: Upstream gradients of hidden states, of shape (N, T, H) - cache: Values from the forward pass Returns a tuple of: - dx: Gradient of input data of shape (N, T, D) - dh0: Gradient of initial hidden state of shape (N, H) - dWx: Gradient of input-to-hidden weight matrix of shape (D, 4H) - dWh: Gradient of hidden-to-hidden weight matrix of shape (H, 4H) - db: Gradient of biases, of shape (4H,) """ dx, dh0, dWx, dWh, db = None, None, None, None, None ############################################################################# # TODO: Implement the backward pass for an LSTM over an entire timeseries. # # You should use the lstm_step_backward function that you just defined. # ############################################################################# # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x = cache[0][0] # æ³¨æ„è¿™æ˜¯ä¸€ä¸ªstepé‡Œé¢çš„xï¼Œå¤§å°æ˜¯Nï¼ŒD N, D = x.shape _, T, H = dh.shape dx = np.zeros((N, T, D)) dprev_h = np.zeros((N, H)) dprev_c = np.zeros((N, H)) dh0 = np.zeros((N, H)) dWx = np.zeros((D, 4 * H)) dWh = np.zeros((H, 4 * H)) db = np.zeros(4 * H) for step in reversed(range(T)): dnext_h = dh[:, step, :] + dprev_h dnext_c = dprev_c dx[:, step, :], dprev_h, dprev_c, dWx_temp, dWh_temp, db_temp = lstm_step_backward( dnext_h, dnext_c, cache[step]) dWx += dWx_temp dWh += dWh_temp db += db_temp dh0 = dprev_h # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dx, dh0, dWx, dWh, db å‰©ä¸‹çš„å’ŒRNNéƒ¨åˆ†æ²¡æœ‰ä»€ä¹ˆåŒºåˆ«äº†ï¼Œä¸»è¦å°±æ˜¯æŠŠä»£ç çš„é€‰é¡¹é‡Œé¢åŠ ä¸Šlstmçš„éƒ¨åˆ†]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
        <category>CS231nä½œä¸š</category>
      </categories>
      <tags>
        <tag>word captioning</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽgithubåˆ é™¤å’Œignore]]></title>
    <url>%2F2019%2F05%2F16%2F%E5%85%B3%E4%BA%8Egithub%E5%88%A0%E9%99%A4%E5%92%8Cignore%2F</url>
    <content type="text"><![CDATA[removeaddè¿‡çš„æ–‡ä»¶å¦‚æžœæƒ³è¦éƒ½æ’¤é”€äº†ä¿®æ”¹git rm -r --cached .ï¼ˆä¸å°å¿ƒaddä¹‹åŽå…³ä¸Šäº†çš„æƒ…å†µï¼‰å¦‚æžœstatusä¹‹åŽå°±å‘çŽ°ä¸å¯¹ï¼Œå¯ä»¥ç”¨git reset HEAD &lt;file&gt;ï¼ŒåŽé¢åŠ ç‚¹å°±æ˜¯æ’¤é”€å…¨éƒ¨çš„ å¦‚æžœå·²ç»pushäº†ï¼Œå¯ä»¥è¿˜åŽŸç‰ˆæœ¬12345git revert HEAD æ’¤é”€å‰ä¸€æ¬¡ commit git revert HEAD^ æ’¤é”€å‰å‰ä¸€æ¬¡ commit git revert commit-id (æ’¤é”€æŒ‡å®šçš„ç‰ˆæœ¬ï¼Œæ’¤é”€ä¹Ÿä¼šä½œä¸ºä¸€æ¬¡æäº¤è¿›è¡Œä¿å­˜ï¼‰ (refï¼šhttps://blog.csdn.net/kongbaidepao/article/details/52253774) ignoreæœ‰ä¸€äº›æ¯”è¾ƒå¤§çš„æ–‡ä»¶æƒ³è¦å¿½ç•¥æŽ‰çš„ï¼Œéœ€è¦åœ¨æ ¹ç›®å½•å»ºç«‹ä¸€ä¸ª.gitignoreï¼Œé‡Œé¢ç›´æŽ¥æ”¾éœ€è¦çš„è·¯å¾„å°±å¯ä»¥äº† ä¸è¦å¾€é‡Œé¢ä¼ å¾ˆå¤§çš„æ•°æ®é¸­ä¼šçˆ†ç‚¸çš„TAT]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>gitignore</tag>
        <tag>remove</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment3RNN]]></title>
    <url>%2F2019%2F05%2F10%2FCS231Nassignment3RNN%2F</url>
    <content type="text"><![CDATA[assignment3 targetIn this exercise you will implement a vanilla recurrent neural networks and use them it to train a model that can generate novel captions for images. Microsoft COCO åœ¨è¿™æ¬¡çš„ä½œä¸šé‡Œç”¨çš„æ˜¯Microsoftçš„coco datasetï¼Œå·²ç»æ˜¯ä¸€ä¸ªå¾ˆå¸¸ç”¨çš„ç»™æ–‡å­—é…ä¸Šè¯´æ˜Žæ–‡ï¼ˆcaptioningï¼‰çš„datasetäº†ï¼Œæœ‰80000ä¸ªè®­ç»ƒå’Œ40000ä¸ªvalï¼Œæ¯ä¸ªå›¾ç‰‡åŒ…å«ä¸€ä¸ªäº”ä¸ªå­—çš„æ³¨é‡Š åœ¨è¿™ä¸ªä½œä¸šé‡Œå·²ç»preprocessäº†dataï¼Œæ¯ä¸ªå›¾ç‰‡å·²ç»ä»ŽVGG-16ï¼ˆImageNet pretrainï¼‰layer 7æå–äº†featureï¼Œå­˜åœ¨äº†train2014_vgg16_fc7.h5å’Œval2014_vgg16_fc7.h5 ä¸ºäº†å‡å°‘å¤„ç†çš„æ—¶é—´å’Œå†…å­˜ï¼Œfeatureçš„ç‰¹å¾ä»Ž4096é™åˆ°äº†512 çœŸå®žçš„å›¾ç‰‡å¤ªå¤§äº†ï¼Œæ‰€ä»¥æŠŠå›¾ç‰‡çš„urlå­˜åœ¨äº†txté‡Œé¢ï¼Œè¿™æ ·åœ¨visçš„æ—¶å€™å¯ä»¥ç›´æŽ¥ä¸‹è½½è¿™äº›å›¾ç‰‡ï¼ˆå¿…é¡»è”ç½‘ï¼‰ ç›´æŽ¥å¤„ç†stringçš„æ•ˆçŽ‡å¤ªä½Žäº†ï¼Œæ‰€ä»¥åœ¨captionçš„ä¸€ä¸ªencodedç‰ˆæœ¬ä¸Šé¢è¿›è¡Œå¤„ç†ï¼Œè¿™æ ·å¯ä»¥æŠŠstringè¡¨ç¤ºæˆä¸€ä¸²intã€‚åœ¨dataseté‡Œé¢ä¹Ÿæœ‰è¿™ä¸¤ä¸ªä¹‹é—´è½¬æ¢çš„ä¿¡æ¯ -&gt; åœ¨è½¬æ¢çš„æ—¶å€™ä¹ŸåŠ äº†æ›´å¤šçš„tokens äº‹å…ˆçœ‹äº†ä¸€ä¸‹å›¾ç‰‡å’Œå¯¹åº”çš„è¯­å¥ RNN åœ¨è¿™ç« è¦ç”¨rnn language modelæ¥è¿›è¡Œimage captioning cs231n/rnn_layers.py step forwardvanilla RNNçš„single timestepï¼Œç”¨tanhæ¥æ¿€æ´»ã€‚è¾“å…¥dataçš„å¤§å°æ˜¯Dï¼Œhidden layerçš„å¤§å°æ˜¯Hï¼Œminibatchçš„å¤§å°æ˜¯N è¾“å…¥ x(N,D) prev_h:å‰ä¸€ä¸ªtimestepçš„hidden (N,H) Wx:input- to- hidden connections (D,H) Wh:hidden-to-hidden connections (H,H) b:bias,(H,) è¿”å›ž(tuple): next_h:ä¸‹ä¸€ä¸ªhidden stateï¼Œ(N,H) cache:backéœ€è¦çš„æ•°æ® æž„æˆ: RNNç”¨çš„å°±æ˜¯ä¸Šä¸€ä¸ªçš„hï¼Œè¿™ä¸€ä¸ªçš„xåŒæ—¶ä¹˜ä»¥ä¸åŒçš„å‚æ•°ï¼Œåˆåœ¨ä¸€èµ·é¢„æµ‹è¿™ä¸€æ¬¡çš„h å¯¹äºŽæŸä¸ªæ—¶é—´ç‚¹ä¸Šçš„è¾“å…¥ï¼Œè¿˜éœ€è¦ä¸Šä¸€ä¸ªçš„state hï¼Œå‚æ•°Wï¼Œä¹˜åœ¨ä¸€èµ·å¾—åˆ°æ–°çš„state è¿™ä¸ªå‚æ•°çš„Wæ— è®ºåœ¨å“ªä¸ªæ­¥éª¤é‡Œé¢ä½¿ç”¨ï¼Œä¸€ç›´éƒ½æ˜¯ä¸€æ ·çš„ 1234567891011121314151617181920212223242526272829303132333435363738def rnn_step_forward(x, prev_h, Wx, Wh, b): """ Run the forward pass for a single timestep of a vanilla RNN that uses a tanh activation function. The input data has dimension D, the hidden state has dimension H, and we use a minibatch size of N. Inputs: - x: Input data for this timestep, of shape (N, D). - prev_h: Hidden state from previous timestep, of shape (N, H) - Wx: Weight matrix for input-to-hidden connections, of shape (D, H) - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H) - b: Biases of shape (H,) Returns a tuple of: - next_h: Next hidden state, of shape (N, H) - cache: Tuple of values needed for the backward pass. """ next_h, cache = None, None ############################################################################## # TODO: Implement a single forward step for the vanilla RNN. Store the next # # hidden state and any values you need for the backward pass in the next_h # # and cache variables respectively. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x_1 = x.dot(Wx) h_1 = prev_h.dot(Wh) x_raw = x_1 + h_1 + b next_h = np.tanh(x_raw) cache = (x, prev_h, Wx, Wh, x_raw, next_h) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return next_h, cache step backward è¾“å…¥ï¼š dnextï¼Œä¸‹ä¸€ä¸ªstateçš„lossçš„gradientï¼Œ(N,H) cache è¾“å‡ºï¼š dx:inputçš„gradientï¼Œ(N,D) dprev_h:å‰ä¸€ä¸ªhidden stateçš„gradientï¼Œ(N,H) dWx:Wxçš„gradient,(D,H) dWh:Whçš„gradientï¼Œ(H,H) db:biasçš„gradientï¼Œ(H,) å…¶å®žè¿™ä¸ªæ±‚èµ·æ¥gradientæ›´ç®€å•äº†ï¼Œå› ä¸ºæ¯ä¸€ä¸ªçš„å¯¼æ•°éƒ½å¾ˆå¥½æ±‚ï¼Œæžå¯¹äº†çŸ©é˜µçš„å½¢çŠ¶å°±å¯ä»¥äº† 123456789101112131415161718192021222324252627282930313233343536373839404142434445def rnn_step_backward(dnext_h, cache): """ Backward pass for a single timestep of a vanilla RNN. Inputs: - dnext_h: Gradient of loss with respect to next hidden state, of shape (N, H) - cache: Cache object from the forward pass Returns a tuple of: - dx: Gradients of input data, of shape (N, D) - dprev_h: Gradients of previous hidden state, of shape (N, H) - dWx: Gradients of input-to-hidden weights, of shape (D, H) - dWh: Gradients of hidden-to-hidden weights, of shape (H, H) - db: Gradients of bias vector, of shape (H,) """ dx, dprev_h, dWx, dWh, db = None, None, None, None, None ############################################################################## # TODO: Implement the backward pass for a single step of a vanilla RNN. # # # # HINT: For the tanh function, you can compute the local derivative in terms # # of the output value from tanh. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x, prev_h, Wx, Wh, x_raw, next_h = cache # d(tanh) = 1 - tanh * tanh # NxH dx_raw = (1 - next_h * next_h) * dnext_h # H, db = np.sum(dx_raw, axis=0) # N,D .T x N,H -&gt; DxH dWx = x.T.dot(dx_raw) # N H x D,H dx = dx_raw.dot(Wx.T) # N,H .T x N,H dWh = prev_h.T.dot(dx_raw) # N,H dprev_h = dx_raw.dot(Wh.T) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dx, dprev_h, dWx, dWh, db forward + backwoard åˆšæ‰åªæ˜¯å®žçŽ°äº†æ¯ä¸€æ­¥çš„forwardå’Œbackwardï¼ŒçŽ°åœ¨è¦å®žçŽ°æ•´ä¸ªçš„è¿™ä¸ªè¿‡ç¨‹äº† forward å‡è®¾è¾“å…¥çš„æ˜¯ä¸€ç³»åˆ—ç”±Tä¸ªvectorç»„æˆçš„ï¼Œæ¯ä¸ªçš„å¤§å°æ˜¯D minibatchçš„å¤§å°æ˜¯Nï¼Œhiddençš„å¤§å°æ˜¯Hï¼Œè¿”å›žæ•´ä¸ªtimesetpsé‡Œé¢çš„hidden state è¾“å…¥ æ•´ä¸ªtimestepé‡Œé¢çš„æ•°æ®x(N,T,D) h0ï¼Œåˆå§‹åŒ–çš„hidden state(N,H) Wx (D,H) Wh (H,H) b (H,) è¾“å‡º hæ•´ä¸ªtimestepé‡Œé¢çš„states(N,T,H) cache å®žé™…ä¸Šå°±æ˜¯é¦–å…ˆè®¾ç½®äº†æœ€å¼€å§‹çš„è¾“å…¥h0ï¼Œç„¶åŽåœ¨æ—¶é—´å¾ªçŽ¯Té‡Œé¢ä¸åœçš„è°ƒç”¨ä¸Šé¢å·²ç»å†™å¥½çš„stepçš„å‡½æ•°ï¼Œæ›´æ–°prev_hï¼ŒæŠŠä¸åŒçš„å€¼å­˜åœ¨cacheé‡Œé¢ æ³¨æ„héœ€è¦åˆå§‹åŒ–ï¼ï¼ backward è¾“å…¥äº†dhå’Œcacheï¼Œéœ€è¦è¾“å‡ºæ‰€æœ‰ä¸œè¥¿çš„gradient æ€è·¯ä¸»è¦æ˜¯æ¯ä¸€ä¸ªstepé‡Œé¢æ˜¯åŠ çš„å…³ç³»ï¼Œæ‰€ä»¥å¯¹äºŽdWxï¼ŒdWhå’Œdbæ¥è¯´ï¼Œéœ€è¦åœ¨æ¯æ¬¡éåŽ†é‡Œé¢åŠ ä¸Šä¹‹å‰çš„å€¼ï¼Œç›¸å½“äºŽæ¯æ¬¡éƒ½éœ€è¦åŠ ä¸Šæ–°çš„ä¸œè¥¿ backçš„æ—¶å€™éœ€è¦nextçš„æ—¶å€™æ¥æ±‚çŽ°åœ¨çš„ï¼Œç„¶åŽåœ¨ä¸‹ä¸€è½®æŠŠnextæ›´æ–°æˆçŽ°åœ¨çš„ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899def rnn_forward(x, h0, Wx, Wh, b): """ Run a vanilla RNN forward on an entire sequence of data. We assume an input sequence composed of T vectors, each of dimension D. The RNN uses a hidden size of H, and we work over a minibatch containing N sequences. After running the RNN forward, we return the hidden states for all timesteps. Inputs: - x: Input data for the entire timeseries, of shape (N, T, D). - h0: Initial hidden state, of shape (N, H) - Wx: Weight matrix for input-to-hidden connections, of shape (D, H) - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H) - b: Biases of shape (H,) Returns a tuple of: - h: Hidden states for the entire timeseries, of shape (N, T, H). - cache: Values needed in the backward pass """ h, cache = None, None ############################################################################## # TODO: Implement forward pass for a vanilla RNN running on a sequence of # # input data. You should use the rnn_step_forward function that you defined # # above. You can use a for loop to help compute the forward pass. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, T, D = x.shape N, H = h0.shape h = np.zeros((N, T, H)) prev_h = h0 cache = &#123;&#125; for i in range(T): prev_h, cache_i = rnn_step_forward(x[:, i, :], prev_h, Wx, Wh, b) h[:, i, :] = prev_h cache[i] = cache_i # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return h, cachedef rnn_backward(dh, cache): """ Compute the backward pass for a vanilla RNN over an entire sequence of data. Inputs: - dh: Upstream gradients of all hidden states, of shape (N, T, H). NOTE: 'dh' contains the upstream gradients produced by the individual loss functions at each timestep, *not* the gradients being passed between timesteps (which you'll have to compute yourself by calling rnn_step_backward in a loop). Returns a tuple of: - dx: Gradient of inputs, of shape (N, T, D) - dh0: Gradient of initial hidden state, of shape (N, H) - dWx: Gradient of input-to-hidden weights, of shape (D, H) - dWh: Gradient of hidden-to-hidden weights, of shape (H, H) - db: Gradient of biases, of shape (H,) """ dx, dh0, dWx, dWh, db = None, None, None, None, None ############################################################################## # TODO: Implement the backward pass for a vanilla RNN running an entire # # sequence of data. You should use the rnn_step_backward function that you # # defined above. You can use a for loop to help compute the backward pass. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, T, H = dh.shape N, D = cache[0][0].shape dx = np.zeros((N, T, D)) dh0 = np.zeros((N, H)) dWx = np.zeros((D, H)) dWh = np.zeros((H, H)) db = np.zeros(H) dprev_h = np.zeros((N, H)) for i in reversed(range(T)): cache_i = cache[i] dnext_h = dh[:, i, :] + dprev_h dx[:, i, :], dprev_h, dWx_tmp, dWh_tmp, db_tmp = rnn_step_backward( dnext_h, cache_i) dWx += dWx_tmp dWh += dWh_tmp db += db_tmp dh0 = dprev_h # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dx, dh0, dWx, dWh, db word embeddingåœ¨æ·±åº¦å­¦ä¹ çš„ç³»ç»Ÿé‡Œé¢ä¸»è¦æ˜¯ç”¨vectoræ¥è¡¨ç¤ºå•è¯çš„ï¼Œå­—å…¸é‡Œé¢çš„æ¯ä¸€ä¸ªéƒ½ä¼šå…³ç³»åˆ°ä¸€ä¸ªvectorï¼Œç„¶åŽè¿™äº›vectorsä¼šå’Œç³»ç»Ÿçš„å…¶ä»–éƒ¨åˆ†ä¸€èµ·å­¦ä¹ åœ¨è¿™éƒ¨åˆ†éœ€è¦æŠŠintè¡¨ç¤ºçš„å•è¯è½¬åŒ–æˆvectors ç†è§£ åœ¨ä¸€å¥è¯é‡Œé¢ï¼Œä¸€ä¸ªå•è¯å°±æ˜¯ä¸€ä¸ªç»´åº¦ï¼Œè€Œword embeddingçš„æ ¸å¿ƒå°±æ˜¯é™ç»´ æŠŠå­—ç»„æˆæ®µè½ï¼Œç„¶åŽç”¨æ®µè½æ¥æ€»ç»“å‡ºæ¥æœ€åŽçš„æ ¸å¿ƒå†…å®¹ forward ä¸€ä¸ªminibatchçš„å¤§å°æ˜¯Nï¼Œé•¿åº¦æ˜¯Tï¼ŒæŠŠæ¯ä¸ªå•è¯ç»™åˆ°ä¸€ä¸ªå¤§å°æ˜¯Dçš„vector input x (N,T)ä¸€ä¸ªNä¸ªæ•°æ®ï¼Œæ¯ä¸ªæ•°æ®é‡Œé¢Tä¸ªå•è¯ï¼ŒTç»™å‡ºæ¥çš„æ˜¯å•è¯çš„indice W (V,D)ç»™æ‰€æœ‰wordçš„vectors return outï¼š(N,T,D)ç»™æ‰€æœ‰å•è¯ä¸€ä¸ªDçš„vector cache backward backçš„æ—¶å€™ä¸èƒ½backåˆ°wordï¼ˆå› ä¸ºæ˜¯intï¼‰ï¼Œæ‰€ä»¥åªéœ€è¦å¾—åˆ°embedding matçš„gradient 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566def word_embedding_forward(x, W): """ Forward pass for word embeddings. We operate on minibatches of size N where each sequence has length T. We assume a vocabulary of V words, assigning each word to a vector of dimension D. Inputs: - x: Integer array of shape (N, T) giving indices of words. Each element idx of x muxt be in the range 0 &lt;= idx &lt; V. - W: Weight matrix of shape (V, D) giving word vectors for all words. Returns a tuple of: - out: Array of shape (N, T, D) giving word vectors for all input words. - cache: Values needed for the backward pass """ out, cache = None, None ############################################################################## # TODO: Implement the forward pass for word embeddings. # # # # HINT: This can be done in one line using NumPy's array indexing. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** out = W[x, :] cache = x, W # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return out, cachedef word_embedding_backward(dout, cache): """ Backward pass for word embeddings. We cannot back-propagate into the words since they are integers, so we only return gradient for the word embedding matrix. HINT: Look up the function np.add.at Inputs: - dout: Upstream gradients of shape (N, T, D) - cache: Values from the forward pass Returns: - dW: Gradient of word embedding matrix, of shape (V, D). """ dW = None ############################################################################## # TODO: Implement the backward pass for word embeddings. # # # # Note that words can appear more than once in a sequence. # # HINT: Look up the function np.add.at # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x, W = cache dW = np.zeros_like(W) np.add.at(dW, x, dout) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dW Temporal Affine layer åœ¨æ¯ä¸ªtimestepçš„æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªaffineæ¥æŠŠRNNçš„hidden vectorè½¬æ¢æˆæ¯ä¸ªå•è¯åœ¨vocabularyé‡Œé¢çš„scoresï¼ˆåŽŸæ¥æ˜¯æ ¹æ®è¿™ä¸ªæ¥è¯„åˆ†çš„ï¼Œç„¶åŽæ¯æ¬¡é€‰å‡ºæ¥ä¸€ä¸ªåˆé€‚çš„å•è¯ï¼‰ å› ä¸ºå’Œä¹‹å‰åšè¿‡çš„ä¸€æ ·ï¼Œæ‰€ä»¥ç›´æŽ¥æä¾›äº† Temporal SOftmax loss åœ¨RNNçš„ç»“æž„é‡Œé¢ï¼Œæ¯ä¸ªtimestepä¼šç”Ÿæˆä¸€ä¸ªå¯¹äºŽvocabularyé‡Œé¢æ‰€æœ‰å•è¯çš„score(çŸ©é˜µ) åœ¨æ¯æ­¥é‡Œé¢éƒ½çŸ¥é“ground truthï¼Œæ‰€ä»¥ç”¨softmaxæ¥è®¡ç®—æ¯ä¸€æ­¥çš„losså’Œgradientï¼Œç„¶åŽè®¡ç®—ä¸€ä¸ªminibatché‡Œé¢æ‰€æœ‰æ—¶é—´çš„å¹³å‡loss å› ä¸ºæ¯ä¸ªå¥å­ä¸ä¸€å®šä¸€æ ·é•¿ï¼Œæ‰€ä»¥åœ¨é‡Œé¢åŠ ä¸Šäº†NULLçš„tokenï¼Œè®©æ‰€æœ‰ä¸œè¥¿ä¸€è¾¹é•¿ï¼Œä½†æ˜¯åœ¨è®¡ç®—lossçš„æ—¶å€™ä¸å¸Œæœ›è®¡ç®—è¿™ä¸ªNULLã€‚æ‰€ä»¥è¿˜ä¼šæŽ¥æ”¶ä¸€ä¸ªmaskæ¥å‘Šè¯‰è¿™ä¸ªå‡½æ•°å“ªä¸ªåœ°æ–¹éœ€è¦ç®—å“ªä¸ªåœ°æ–¹ä¸éœ€è¦ç®— RNN for image captioning åœ¨cs231n/classifiers/rnn.pyé‡Œé¢ï¼ŒçŽ°åœ¨åªéœ€è¦è€ƒè™‘vanialla RNNçš„é—®é¢˜ implement lossé‡Œé¢çš„forwardå’Œbackward IO è¾“å…¥ image featuresï¼Œå¤§å°æ˜¯(N,D) captionsï¼šgorund truthï¼Œå¤§å°æ˜¯(N,T)å…¶ä¸­æ¯ä¸ªå…ƒç´ åº”è¯¥éƒ½åœ¨ 0-Vä¹‹é—´ è¾“å‡º loss grads TODO affine transï¼Œä»Žå›¾ç‰‡çš„ç‰¹å¾è®¡ç®—åˆå§‹åŒ–çš„hidden stateï¼Œè¾“å‡ºçš„å¤§å°æ˜¯ (N,H) -&gt; W_proj,b_proj -&gt; è¿™ä¸€æ­¥åˆå§‹åŒ–çš„æ˜¯h0ï¼Œä¹Ÿå°±æ˜¯æœ€å¼€å§‹çš„çŠ¶æ€ word embeddingï¼ŒæŠŠè¾“å…¥å¥å­çš„intï¼ˆè¡¨ç¤ºåœ¨vocaé‡Œé¢çš„ä½ç½®ï¼‰è½¬åŒ–æˆvectorï¼Œè¾“å‡ºç»“æžœæ˜¯(N,T,W) vanilla RNNï¼ˆæˆ–è€…åŽé¢çš„LSTMï¼‰æ¥è®¡ç®—ä¸­é—´çš„timestepé‡Œé¢hidden stateçš„æ”¹å˜ï¼Œè¾“å‡ºç»“æžœ(N,T,H) temporal affineæ¥æŠŠæ¯ä¸€æ­¥çš„ç»“æžœè½¬åŒ–æˆåœ¨vocabularyä¸Šé¢çš„scoreï¼Œ(N,T,V) temporal softmaxæŠŠscoreè½¬åŒ–æˆlossï¼Œæ³¨æ„éœ€è¦å¿½ç•¥maskä¸Šé¢æ²¡æœ‰çš„ åœ¨backçš„æ—¶å€™éœ€è¦è®¡ç®—losså…³äºŽæ‰€æœ‰å‚æ•°çš„gradientï¼Œå­˜åœ¨ä¸Šé¢çš„dicté‡Œé¢ å®žé™…ä¸Šç›´æŽ¥æŒ‰ç…§ä¹‹å‰å†™å¥½çš„ä¸€ç›´æ“ä½œå°±å¯ä»¥äº†ï¼ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105def loss(self, features, captions): """ Compute training-time loss for the RNN. We input image features and ground-truth captions for those images, and use an RNN (or LSTM) to compute loss and gradients on all parameters. Inputs: - features: Input image features, of shape (N, D) - captions: Ground-truth captions; an integer array of shape (N, T) where each element is in the range 0 &lt;= y[i, t] &lt; V Returns a tuple of: - loss: Scalar loss - grads: Dictionary of gradients parallel to self.params """ # Cut captions into two pieces: captions_in has everything but the last word # and will be input to the RNN; captions_out has everything but the first # word and this is what we will expect the RNN to generate. These are offset # by one relative to each other because the RNN should produce word (t+1) # after receiving word t. The first element of captions_in will be the START # token, and the first element of captions_out will be the first word. captions_in = captions[:, :-1] captions_out = captions[:, 1:] # You'll need this mask = (captions_out != self._null) # Weight and bias for the affine transform from image features to initial # hidden state W_proj, b_proj = self.params['W_proj'], self.params['b_proj'] # Word embedding matrix W_embed = self.params['W_embed'] # Input-to-hidden, hidden-to-hidden, and biases for the RNN Wx, Wh, b = self.params['Wx'], self.params['Wh'], self.params['b'] # Weight and bias for the hidden-to-vocab transformation. W_vocab, b_vocab = self.params['W_vocab'], self.params['b_vocab'] loss, grads = 0.0, &#123;&#125; ############################################################################ # TODO: Implement the forward and backward passes for the CaptioningRNN. # # In the forward pass you will need to do the following: # # (1) Use an affine transformation to compute the initial hidden state # # from the image features. This should produce an array of shape (N, H)# # (2) Use a word embedding layer to transform the words in captions_in # # from indices to vectors, giving an array of shape (N, T, W). # # (3) Use either a vanilla RNN or LSTM (depending on self.cell_type) to # # process the sequence of input word vectors and produce hidden state # # vectors for all timesteps, producing an array of shape (N, T, H). # # (4) Use a (temporal) affine transformation to compute scores over the # # vocabulary at every timestep using the hidden states, giving an # # array of shape (N, T, V). # # (5) Use (temporal) softmax to compute loss using captions_out, ignoring # # the points where the output word is &lt;NULL&gt; using the mask above. # # # # In the backward pass you will need to compute the gradient of the loss # # with respect to all model parameters. Use the loss and grads variables # # defined above to store loss and gradients; grads[k] should give the # # gradients for self.params[k]. # # # # Note also that you are allowed to make use of functions from layers.py # # in your implementation, if needed. # ############################################################################ # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** # N,D x D,H -&gt; N,H hidden_init, hidden_init_cache = affine_forward( features, W_proj, b_proj) # N,T -&gt; N,T,D embeding, embeding_cache = word_embedding_forward(captions_in, W_embed) # RNN -&gt; N,T,H if self.cell_type == 'rnn': hidden_state, hidden_cache = rnn_forward( embeding, hidden_init, Wx, Wh, b) # N,T,H x H,V -&gt; N,T,V scores, score_cache = temporal_affine_forward( hidden_state, W_vocab, b_vocab) # N,T,V -&gt; loss loss, dloss = temporal_softmax_loss(scores, captions_out, mask) grads = &#123;&#125; # gradient in temporal affine daffine_x, grads['W_vocab'], grads['b_vocab'] = temporal_affine_backward( dloss, score_cache) if self.cell_type == 'rnn': drnn, dh_init, grads['Wx'], grads['Wh'], grads['b'] = rnn_backward( daffine_x, hidden_cache) grads['W_embed'] = word_embedding_backward(drnn, embeding_cache) dfeatures, grads['W_proj'], grads['b_proj'] = affine_backward( dh_init, hidden_init_cache) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################ # END OF YOUR CODE # ############################################################################ return loss, grads overfit small data å’Œä¹‹å‰ä¸€æ ·ï¼Œå†™äº†ä¸€ä¸ªsolveræ¥è®¡ç®—ï¼ŒåŒ…æ‹¬äº†è®­ç»ƒmodelçš„æ‰€æœ‰éœ€è¦çš„ä¸œè¥¿ï¼Œåœ¨optim..pyé‡Œé¢æœ‰å¾ˆå¤šä¸åŒçš„updateçš„æ–¹æ³• å¯ä»¥æŽ¥å—trainæˆ–è€…valçš„dataå’Œlabelï¼Œå¯ä»¥å¾—åˆ°è®­ç»ƒæˆ–è€…valçš„accã€‚åœ¨è®­ç»ƒä¹‹åŽè¿™ä¸ªmodelé‡Œé¢ä¼šä¿å­˜æœ€å¥½çš„å‚æ•°ï¼Œè®©valæœ€ä½Ž åœ¨è¿™ä¸€æ­¥é‡Œé¢ï¼Œè½½å…¥äº†50ä¸ªcocoçš„è®­ç»ƒæ•°æ®ï¼Œç„¶åŽå¯¹ä¸€ä¸ªmodelè¿›è¡Œè®­ç»ƒï¼Œæœ€åŽå¾—åˆ°çš„lossä¼šå°äºŽ0.1 test-time sampling å’Œåˆ†ç±»ä¸åŒï¼ŒRNNè®­ç»ƒå’Œæµ‹è¯•å¾—åˆ°çš„ç»“æžœä¼šéžå¸¸ä¸ç›¸åŒ è®­ç»ƒçš„æ—¶å€™ï¼Œæˆ‘ä»¬æŠŠground-truthæ”¾è¿›RNN æµ‹è¯•çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¼šsampleå‡ºæ¥æ¯ä¸ªtimestepçš„å•è¯çš„åˆ†å¸ƒï¼Œç„¶åŽæŠŠè¿™äº›åˆ†å¸ƒå†å–‚åˆ°ä¸‹ä¸€ä¸ªstepé‡Œé¢ implementåœ¨æ¯æ¬¡stepé‡Œé¢ï¼Œæˆ‘ä»¬æŠŠçŽ°åœ¨çš„å•è¯embedï¼Œå’Œå‰ä¸€ä¸ªhidden stateä¸€èµ·è¾“å…¥è¿›RNNé‡Œé¢ï¼Œå¾—åˆ°ä¸‹ä¸€ä¸ªhidden stateï¼Œç„¶åŽå¾—åˆ°vocabularyä¸Šé¢çš„scoreï¼Œé€‰æ‹©æœ€æœ‰å¯èƒ½çš„å•è¯ç„¶åŽæ ¹æ®è¿™ä¸ªå•è¯å¾—åˆ°ä¸‹ä¸€ä¸ªå•è¯ è¾“å…¥ï¼š features (N,D) è¿˜æ²¡æœ‰è¿›è¡Œprojectionçš„æ•°æ® max_lengthï¼šæœ€é•¿çš„captionçš„é•¿åº¦ è¾“å‡º captions (N,max_length)ï¼Œé‡Œé¢æ”¾çš„æ˜¯0-Vçš„intï¼Œç¬¬ä¸€ä¸ªåº”è¯¥æ˜¯ TODO éœ€è¦æŠŠfeaturesåˆå§‹åŒ–ï¼Œç„¶åŽç¬¬ä¸€ä¸ªè¾“å…¥çš„å•è¯åº”è¯¥æ˜¯(æœ€å¼€å§‹) åœ¨ä¹‹åŽçš„æ¯ä¸€æ­¥é‡Œé¢ ç”¨å·²ç»å­¦ä¹ å¥½çš„å‚æ•°ï¼Œembedä¸Šä¸€ä¸ªå•è¯ RNN stepï¼Œä»Žä¸Šä¸€ä¸ªhiddenå’ŒçŽ°åœ¨çš„embedå¾—åˆ°ä¸‹ä¸€ä¸ªhiddenï¼ˆéœ€è¦callæ¯ä¸€æ­¥çš„å‡½æ•°è€Œä¸æ˜¯å®Œæ•´çš„å‡½æ•°ï¼‰ æŠŠä¸‹ä¸€ä¸ªè½¬åŒ–æˆscore åœ¨scoreé‡Œé¢é€‰æ‹©æœ€æœ‰å¯èƒ½çš„å•è¯ï¼Œå†™å‡ºæ¥è¿™ä¸ªå•è¯çš„indexï¼Œ ä¸ºäº†ç®€å•ï¼Œåœ¨å‡ºçŽ°ä¹‹å‰ä¸ç”¨åœæ­¢ æ³¨æ„ï¼š åº”è¯¥ç”¨çš„æ˜¯affineæ¥è®¡ç®—scoreè€Œä¸æ˜¯temporalï¼Œå› ä¸ºè¦è®¡ç®—çš„åªæ˜¯çŽ°åœ¨è¿™ä¸ªèŒƒå›´é‡Œé¢çš„scoreï¼Œè®¡ç®—å‡ºæ¥çš„å¤§å°åº”è¯¥æ˜¯(N,V)ï¼Œæ‰€ä»¥åº”è¯¥åœ¨æ¯è¡Œæ‰¾åˆ°æœ€åˆé€‚çš„ æ¯ä¸€æ­¥è®¡ç®—å‡ºæ¥çš„æœ€å¤§å€¼åº”è¯¥è®°åœ¨ç›¸åº”stepçš„åˆ—ä¸Š 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485def sample(self, features, max_length=30): """ Run a test-time forward pass for the model, sampling captions for input feature vectors. At each timestep, we embed the current word, pass it and the previous hidden state to the RNN to get the next hidden state, use the hidden state to get scores for all vocab words, and choose the word with the highest score as the next word. The initial hidden state is computed by applying an affine transform to the input image features, and the initial word is the &lt;START&gt; token. For LSTMs you will also have to keep track of the cell state; in that case the initial cell state should be zero. Inputs: - features: Array of input image features of shape (N, D). - max_length: Maximum length T of generated captions. Returns: - captions: Array of shape (N, max_length) giving sampled captions, where each element is an integer in the range [0, V). The first element of captions should be the first sampled word, not the &lt;START&gt; token. """ N = features.shape[0] captions = self._null * np.ones((N, max_length), dtype=np.int32) # Unpack parameters W_proj, b_proj = self.params['W_proj'], self.params['b_proj'] W_embed = self.params['W_embed'] Wx, Wh, b = self.params['Wx'], self.params['Wh'], self.params['b'] W_vocab, b_vocab = self.params['W_vocab'], self.params['b_vocab'] ########################################################################### # TODO: Implement test-time sampling for the model. You will need to # # initialize the hidden state of the RNN by applying the learned affine # # transform to the input image features. The first word that you feed to # # the RNN should be the &lt;START&gt; token; its value is stored in the # # variable self._start. At each timestep you will need to do to: # # (1) Embed the previous word using the learned word embeddings # # (2) Make an RNN step using the previous hidden state and the embedded # # current word to get the next hidden state. # # (3) Apply the learned affine transformation to the next hidden state to # # get scores for all words in the vocabulary # # (4) Select the word with the highest score as the next word, writing it # # (the word index) to the appropriate slot in the captions variable # # # # For simplicity, you do not need to stop generating after an &lt;END&gt; token # # is sampled, but you can if you want to. # # # # HINT: You will not be able to use the rnn_forward or lstm_forward # # functions; you'll need to call rnn_step_forward or lstm_step_forward in # # a loop. # # # # NOTE: we are still working over minibatches in this function. Also if # # you are using an LSTM, initialize the first cell state to zeros. # ########################################################################### # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** hidden_init, _ = affine_forward( features, W_proj, b_proj) start_word, _ = word_embedding_forward(self._start, W_embed) current_word = start_word next_state = hidden_init for step in range(max_length): prev_state = next_state if self.cell_type == 'rnn': next_state, _ = rnn_step_forward( current_word, prev_state, Wx, Wh, b) step_scores, _ = affine_forward( next_state, W_vocab, b_vocab) captions[:, step] = np.argmax(step_scores, axis=1) current_word, _ = word_embedding_forward( captions[:, step], W_embed) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################ # END OF YOUR CODE # ############################################################################ return captions]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
        <category>CS231nä½œä¸š</category>
      </categories>
      <tags>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å­¦ä¹ OpenCVç¬¬19ç« ï¼ŒæŠ•å½±å’Œ3Dè§†è§‰]]></title>
    <url>%2F2019%2F05%2F08%2FOpenCV19%2F</url>
    <content type="text"><![CDATA[Chapter 19é¦–å…ˆä¼šè®¨è®ºä»Ž3Då¾—åˆ°2Dä¿¡æ¯ï¼Œç„¶åŽå†è®¨è®ºä»Ž2DæŽ¨æ–­3Dä¿¡æ¯å¦‚æžœæ²¡æœ‰å¤šå¼ å›¾ç‰‡æ˜¯å¾ˆéš¾å¾—åˆ°é è°±çš„3Dä¿¡æ¯çš„ï¼š é€šè¿‡stereo vision é€šè¿‡motion Projections å¾—åˆ°äº†ç‰©ä½“åœ¨ä¸‰ç»´é‡Œé¢çš„ä½ç½®ä¹‹åŽï¼Œå› ä¸ºæˆ‘ä»¬åœ¨18ç« å·²ç»calibrationäº†ç›¸æœºï¼Œæ‰€ä»¥å¯ä»¥å¾—åˆ°è¿™ä¸ªç‚¹åœ¨å›¾ç‰‡é‡Œé¢çš„ä½ç½® æä¾›äº†ä¸€ä¸ªå‡½æ•°projectPointsæ¥æŠ•å½±ä¸€ç³»åˆ—çš„ç‚¹ï¼Œé’ˆå¯¹åˆšä½“ a list of locaâ€ tions in the objectâ€™s own body-centered coordinate system åŠ ä¸Šäº†å¹³ç§»å’Œæ—‹è½¬ï¼Œç›¸æœºintrinsicå’Œdistortion æœ€åŽè¾“å‡ºåœ¨ç”»é¢ä¸Šçš„åº— Affine and Perspective Transformationsaffineæ˜¯é’ˆå¯¹ä¸€ä¸ªlistæˆ–è€…ä¸€æ•´å¼ å›¾ç‰‡è¿›è¡Œçš„ï¼Œå¯ä»¥æŠŠä¸€ä¸ªpointä»Žå›¾ç‰‡çš„ä¸€ä¸ªlocationç§»åŠ¨åˆ°å¦ä¸€ä¸ªlocationï¼Œperspective transæ›´å¤šçš„æ˜¯é’ˆå¯¹ä¸€ä¸ªçŸ©å½¢å›¾ç‰‡ -&gt; related to prspective transformation æ€»ç»“ä¸åŒçš„å‡½æ•° Birdâ€™s-eye-view transï¼ˆp699ï¼‰ åœ¨robticå·¡èˆªçš„æ—¶é—´ï¼Œç»å¸¸æŠŠæŽ’åˆ°çš„ç”»é¢å˜æˆä»Žä¸Šå¾€ä¸‹çœ‹çš„bird-view éœ€è¦ç›¸æœºçš„intrinsicå’Œdistortion ï¼ˆæŠŠæ£‹ç›˜æ”¾åœ¨åœ°ä¸Šè¿›è¡Œcalibrationï¼‰ æ­¥éª¤ é¦–å…ˆè¯»å–ç›¸æœºçš„å‚æ•°å’Œdistortion model æ‰¾åˆ°åœ°é¢ä¸Šå·²çŸ¥çš„åº—ï¼ˆæ¯”å¦‚chessboardï¼‰ï¼Œæ‰¾åˆ°è‡³å°‘å››ä¸ªç‚¹ cv::getPerspectiveTransform()è®¡ç®—åœ°é¢ä¸Šå·²çŸ¥ç‚¹çš„homography H cv::warpPerspective()å½¢æˆbird-eye-view three-dim pose estimationç‰©ä½“çš„ä¸‰ç»´poseå¯ä»¥ä»Ž ä¸€ä¸ªç›¸æœºï¼šå¿…é¡»å…ˆè€ƒè™‘æƒ…å†µæƒ¹ å¤šä¸ªç›¸æœºæ•æ‰ï¼šä»Žå¤šä¸ªä¸åŒå›¾ç‰‡æ¥æŽ¨æ–­ï¼Œè¿™æ ·å³ä½¿æ˜¯ä¸çŸ¥é“çš„ä¸œè¥¿éƒ½å¯ä»¥æ“ä½œ single camera å¦‚æžœæˆ‘ä»¬çŸ¥é“ä¸€ä¸ªobjectï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“è¿™ä¸ªä¸œè¥¿åœ¨ä»–è‡ªå·±åæ ‡ç³»é‡Œé¢å…³é”®ç‚¹çš„åæ ‡ å¦‚æžœçŽ°åœ¨ç»™äº†ä¸€ä¸ªæ–°çš„view pointï¼Œå¯ä»¥æ ¹æ®å…³é”®ç‚¹çš„ä½ç½®æ¥æŽ¨æ–­ cv::solvePnP() ç”¨æ¥è®¡ç®—ä¸€ä¸ªknow objectçš„ä½ç½® ä»Žå›¾ç‰‡é‡Œé¢æå–ç‰¹å¾ç‚¹ï¼Œç„¶åŽè®¡ç®—ä¸åŒç‚¹çš„ä½ç½®ï¼Œè¿™ä¸ªé—®é¢˜çš„è§£æ˜¯åº”è¯¥æ˜¯å”¯ä¸€çš„ PNPé—®é¢˜ä¸æ˜¯æ¯æ¬¡éƒ½æœ‰å”¯ä¸€çš„è§£ å¦‚æžœæ²¡æœ‰è¶³å¤Ÿçš„å…³é”®ç‚¹ï¼Œä¸ºäº†ä¿é™©èµ·è§åº”è¯¥æœ‰è¶³å¤Ÿçš„åº— æˆ–è€…å½“ç‰©ä½“ç¦»å¾—ç‰¹åˆ«è¿œï¼ˆè¿™æ—¶å€™å…‰çº¿æŽ¥è¿‘äºŽå¹³è¡Œäº†ï¼Œå°±ä¸å¥½åˆ¤æ–­äº†ï¼‰ æ€»çš„æ¥è¯´ï¼Œå•ç›®è§†è§‰å’Œäººè‡ªå·±çš„çœ¼ç›ï¼ˆå•åªï¼‰çœ‹ä¸œè¥¿çš„æ„Ÿè§‰å·®ä¸å¤šï¼Œä¸èƒ½èŽ·å¾—ç²¾ç¡®çš„å¤§å°ï¼Œè¿˜ä¼šäº§ç”Ÿä¸€äº›é”™è§‰ï¼ˆæ¯”å¦‚æŠŠå¤§æ¥¼çš„çª—æˆ·è®¾è®¡çš„å°æ¥æ˜¾å¾—æ¥¼æ›´é«˜ï¼‰ Stereo Imagingåœ¨ç”µè„‘ä¸­ï¼Œé€šè¿‡è®¡ç®—åœ¨ä¸¤å¼ å›¾é‡Œé¢éƒ½å‡ºçŽ°çš„ç‚¹çš„ä½ç½®æ¥è®¡ç®—ï¼Œè¿™æ ·å°±å¯ä»¥è®¡ç®—è¿™ä¸ªç‚¹çš„ä¸‰ç»´ä½ç½®ã€‚è™½ç„¶è¿™æ ·è®¡ç®—çš„è®¡ç®—é‡å¾ˆå¤§ï¼Œä½†æ˜¯å¯ä»¥é€šè¿‡ä¸€äº›æ–¹æ³•æ¥åŽ‹ç¼©æœå¯»çš„èŒƒå›´ï¼Œä»Žè€Œå¾—åˆ°ç›¸åº”çš„ç»“æžœã€‚ä¸»è¦åˆ†ä¸º4æ­¥ï¼š åœ¨æ•°å­¦ä¸ŠremoveæŽ‰ç›¸æœºlensçš„è¾å°„å’Œå¹³ç§»distortion -&gt; undistortion è°ƒæ•´ç›¸æœºä¹‹é—´çš„è§’åº¦å’Œè·ç¦» -&gt; rectificationã€‚è¿™ä¸€æ­¥è¾“å‡ºä¹‹åŽçš„ä¸¤å¼ å›¾ç‰‡åº”è¯¥æ˜¯row-alignedçš„ï¼ˆfrontal parallelï¼‰ æ‰¾åˆ°å·¦å³ä¸¤å¼ å›¾ç›¸åŒçš„feature -&gt; correspondenceã€‚è¿™ä¸€æ­¥çš„è¾“å‡ºæ˜¯ä¸€ä¸ªdisparity mapï¼Œè¾“å‡ºçš„æ˜¯ä¸¤ä¸ªå›¾ä¸­ç›¸åŒç‰¹å¾ç‚¹çš„xåæ ‡æ–¹å‘ä¸Šé¢çš„disparity æœ€åŽå¯ä»¥æŠŠdisparityè½¬æ¢æˆtriangulationï¼Œè¿™ä¸€æ­¥å«åšreprojectionï¼Œè¿™æ ·è¾“å‡ºçš„å°±æ˜¯depth mapäº† triangulationï¼ˆæ‰¾åˆ°disparityå’Œdepthçš„å…³ç³»ï¼‰ æ•´ä½“æ¦‚å¿µå¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œåœ¨è¿™å¼ å›¾é‡Œæˆ‘ä»¬å‡è®¾ç³»ç»Ÿå·²ç»å®Œå…¨undistortï¼Œalignedï¼ˆä¸¤å¼ å›¾ç‰‡çš„è¡Œå’Œè¡Œå¯¹ä¸Šäº†ï¼‰äº†ï¼Œä¸¤ä¸ªç›¸æœºçš„å¹³é¢å®Œå…¨ç›¸åŒï¼Œç„¦è·ä¹Ÿç›¸åŒï¼Œå¹¶ä¸”ä¸¤ä¸ªç›¸æœºçš„cxå·²ç»è¢«calibratedå¥½äº†ï¼ˆç›¸åŒï¼‰ è¿™æ—¶ï¼Œè¿™ä¸ªç‰©ä½“ç‚¹Pçš„depthå’Œdisparityæ˜¯æˆæ­£æ¯”çš„ï¼Œæ±‚å‡ºæ¥çš„disparityæ˜¯ï¼šxl - xrï¼ˆxlå’Œxréƒ½æ˜¯æ ¹æ®å„è‡ªçš„ç›¸æœºä¸­å¿ƒçš„åæ ‡ï¼‰: T - (xl - xr)/Z - f = T/Z è¿™ä¸ªå…³ç³»è™½ç„¶æ˜¯æ­£æ¯”ä½†æ˜¯ä¸æ˜¯çº¿æ€§çš„ å½“disparityæŽ¥è¿‘0çš„æ—¶å€™ï¼Œå°çš„disparityçš„å·®å¼‚ä¼šå¼•å‘éžå¸¸å¤§çš„depthçš„å·®å¼‚ å½“disparityéžå¸¸å¤§çš„æ—¶å€™ï¼Œdisparityçš„æ”¹å˜ä¸ä¼šå¯¹depthå¼•èµ·å¤ªå¤šçš„å½±å“ æœ€ç»ˆï¼Œstereoçš„ç³»ç»Ÿåªåœ¨æ¯”è¾ƒæŽ¥è¿‘ç›¸æœºçš„éƒ¨åˆ†æœ‰æ¯”è¾ƒé«˜çš„depth resolutionï¼ˆå¦‚ä¸‹å›¾æ‰€ç¤ºï¼‰ ä¸Šé¢çš„ä¾‹å­æ˜¯äºŒç»´è½¬ä¸€ç»´çš„ï¼Œå®žé™…åœ¨OpenCVçš„ç³»ç»Ÿé‡Œé¢æ˜¯ä¸‰ç»´è½¬äºŒç»´çš„ åœ¨å®žé™…çš„åº”ç”¨é‡Œé¢ç›¸æœºä¸æ˜¯é‚£ä¹ˆç†æƒ³çš„å…±çº¿çš„ï¼Œè¦å°½é‡ç¡®ä¿å…±çº¿ï¼Œæ‰ä¸ä¼šå¼•èµ·å¤ªå¤šçš„distortionã€‚æœ€ç»ˆçš„ç›®çš„æ˜¯é€šè¿‡mathçš„è®¡ç®—è®©ä»–å…±çº¿ï¼Œè€Œä¸æ˜¯åœ¨ç‰©ç†ä¸Šå…±çº¿ é™¤æ­¤ä¹‹å¤–ï¼Œè¿˜éœ€è¦ä¿è¯ç›¸æœºçš„æ‹æ‘„æ˜¯åŒæ­¥çš„ï¼Œé¿å…åœ¨æ‹æ‘„çš„æ—¶å€™ä¼šæœ‰ä¸œè¥¿ç§»åŠ¨ Epipolar Geometryï¼ˆç®€åŒ–åŒç›®æ¨¡åž‹ï¼‰stereo image systemçš„æ¨¡åž‹ï¼š ç»„åˆäº†ä¸¤ä¸ªpinhole model åŠ å…¥äº†æ–°çš„points epipoles ä¸»è¦ç‚¹ï¼š å¯¹äºŽæ¯ä¸ªç›¸æœºéƒ½ä¼šæœ‰ä¸€ä¸ªæŠ•å½±çš„ä¸­å¿ƒOï¼Œå¹¶ä¸”æœ‰ä¸¤ä¸ªå’Œè¿™ä¸ªç›¸å…³çš„æŠ•å½±å¹³é¢ åœ¨çŽ°å®žä¸­çš„ç‰©ä½“Pä¼šåœ¨ä¸¤ä¸ªæŠ•å½±å¹³é¢ä¸Šåˆ†åˆ«æœ‰æŠ•å½±plå’Œpr elæˆ–è€…erï¼Œå®šä¹‰æ˜¯å¦ä¸€ä¸ªç›¸æœºçš„ä¸­å¿ƒåœ¨è¿™ä¸ªæŠ•å½±å¹³é¢ä¸Šçš„æŠ•å½±ï¼Œelå’Œplå¯ä»¥å½¢æˆä¸€æ¡epipolar line å¾—åˆ°è¦ä¹‰ æ¯ä¸ªä¸‰ç»´çš„ç‚¹ï¼Œéƒ½ä¼šåœ¨æ¯ä¸ªç›¸æœºä¸Šé¢å¾—åˆ°ä¸€ä¸ªepipolarçš„ï¼Œè¿™ä¸ªç‚¹å’Œpr/plçš„äº¤ç‚¹å°±æ˜¯epipolar line ä¸€ä¸ªå›¾ç‰‡é‡Œé¢çš„featureï¼Œåœ¨å¦ä¸€ä¸ªå›¾ç‰‡é‡Œé¢å¿…é¡»åœ¨ç›¸å¯¹åº”çš„epipolar lineä¸Šé¢ï¼ˆepipolar constraintï¼‰ ä¸Šé¢é‚£ä¸ªå®šä¹‰æ„å‘³ç€ï¼šå¯ä»¥æŠŠåœ¨å›¾ç‰‡ä¸Šå¯»æ‰¾ç‰¹å¾ä»ŽäºŒç»´ï¼ˆå›¾ç‰‡ï¼‰é™ä½Žåˆ°ä¸€ç»´ï¼ˆçº¿ï¼‰ å¹¶ä¸”å›¾ç‰‡çš„orderä¼šä¿å­˜ï¼Œæ¯”å¦‚ä¸€æ¡çº¿åœ¨ä¸¤å¼ å›¾é‡Œé¢éƒ½æ˜¯æ°´å¹³çš„ The Essential and Fundamental Matrices E Matï¼šåŒ…æ‹¬äº†ä¸¤ä¸ªç›¸æœºçš„translationå’Œrotation F Matï¼šåŒ…æ‹¬äº†Eçš„ä¿¡æ¯ï¼Œä»¥åŠç›¸æœºçš„intrinsicï¼ˆåœ¨pixelçš„å±‚é¢ä¸Šå…³è”ä¸¤ä¸ªç›¸æœºï¼‰ äºŒè€…çš„åŒºåˆ« EåªçŸ¥é“ä¸¤ä¸ªç›¸æœºçš„å…³ç³»ï¼Œä¸çŸ¥é“ä»»ä½•å…³äºŽå›¾ç‰‡çš„ä¿¡æ¯ï¼Œåªåœ¨ç‰©ä½“çš„å±‚é¢ä¸Šå…³è”äº†ä¸¤ä¸ªç›¸æœº Få…³è”äº†ä¸¤ä¸ªç…§ç‰‡åœ¨å„è‡ªå›¾ç‰‡åæ ‡ç³»é‡Œé¢çš„å…³ç³» E math + F matï¼ˆp713ï¼Œè¿˜æ²¡æœ‰æ€Žä¹ˆçœ‹ï¼‰ åœ¨å·¦è¾¹çš„ç›¸æœºé‡Œï¼Œè§‚å¯Ÿåˆ°çš„ç‚¹æ˜¯plï¼Œåœ¨å³è¾¹çš„ç›¸æœºè§‚å¯Ÿåˆ°çš„ç‚¹æ˜¯pr pr = Rï¼ˆpl - Tï¼‰ cv::findFundamentalMatComputing Epipolar Lines(è®¡ç®—ä¸Šé¢æ¨¡åž‹é‡Œé¢çš„é‚£æ¡çº¿) æœ‰äº†F Matä¹‹åŽå¸Œæœ›å¯ä»¥è®¡ç®—ä¸Šé¢çš„epipolar lineã€‚æ¯ä¸€ä¸ªå›¾ç‰‡é‡Œé¢çš„lineéƒ½ä¼šåœ¨å¦ä¸€å¼ å›¾ç‰‡é‡Œæœ‰ä¸€ä¸ªå¯¹åº”çš„line lineç”¨ä¸€ä¸ªä¸‰ä¸ªç‚¹çš„vectoræ¥è¡¨ç¤º cv::computeCorrespondEpilines Stereo Calibrationä¸Šé¢å·²ç»è¯´äº†å¾ˆå¤šçš„ç†è®ºçŸ¥è¯†äº†æ‰€ä»¥æˆ‘ä»¬çŽ°åœ¨å°±å¼€å§‹calibrationå§ï¼ Stereo calibrationæ˜¯åœ¨ç©ºé—´ä¸Šé¢è®¡ç®—ä¸¤ä¸ªç›¸æœºçš„ä½ç½®ã€‚ç›¸åï¼ŒåŽé¢è¦è¯´çš„rectificationæ‰æ˜¯æ¥ä¿è¯ä¸¤å¼ å›¾ç‰‡è¡Œæ˜¯å…±çº¿çš„ Stereo calibrationä¸»è¦ä¾é çš„æ˜¯æ‰¾ä¸¤ä¸ªç›¸æœºä¹‹é—´çš„Tå’ŒRçŸ©é˜µï¼Œè¿™ä¸¤ä¸ªéƒ½å¯ä»¥ç”¨cv::stereoCalibrate()æ¥è®¡ç®— å’Œå•ç›®ç›¸æœºçš„calibrationæœ‰äº›ç›¸ä¼¼ï¼Œä½†æ˜¯å•ç›®çš„ç›¸æœºè¦å¯»æ‰¾ä¸€ç³»åˆ—ç›¸æœºå’Œchessboardä¹‹é—´çš„Rå’ŒT åŒç›®çš„calibrationåœ¨å¯»æ‰¾å”¯ä¸€ä¸€ä¸ªèƒ½è®©å·¦å³ç›¸æœºåŒ¹é…ä¸Šçš„Rå’ŒT å¯ä»¥å¾—åˆ°ä¸‰ä¸ªç­‰å¼æ±‚è§£ å› ä¸ºå›¾ç‰‡çš„noiseæˆ–è€…rounding errorï¼Œæ¯ç»„å¾—åˆ°çš„ç»“æžœå¯èƒ½ä¼šæœ‰è½»å¾®çš„ä¸åŒï¼Œæœ€åŽä¼šå–ä¸­ä½æ•° calibrationä¼šæŠŠå³è¾¹çš„ç›¸æœºæ”¾åœ¨å’Œå·¦è¾¹çš„ç›¸æœºç›¸åŒçš„planeä¸Šé¢ï¼Œè¿™æ ·è¿™ä¸¤ä¸ªç›¸æœºå¾—åˆ°çš„å›¾ç‰‡å°±æ˜¯parallelçš„ï¼Œä½†æ˜¯è¿™æ—¶å€™è¿˜ä¸æ˜¯row-alignedçš„ï¼ï¼ï¼ å¯ä»¥ç›´æŽ¥é€šè¿‡ç”¨è¿™ä¸€ä¸ªå‡½æ•°è®¡ç®—ç›¸æœºçš„intrinsicï¼Œextrinsicå’ŒStereoçš„å‚æ•°ï¼Œä¸ç”¨å…ˆè¿›è¡Œcalibration Stereo Rectification å¦‚æžœä¸¤ä¸ªå›¾ç‰‡alignedäº†ï¼Œé‚£ä¹ˆæ ¹æ®ä¸Šé¢è®¡ç®—å‡ºæ¥çš„disparityå°±å¯ä»¥å¾ˆè½»æ˜“çš„å¾—åˆ°depth mapäº†ã€‚ä½†æ˜¯åœ¨å®žé™…ä¸­åªæœ‰ç›¸æœºæ²¡æœ‰è¿™ä¹ˆå®¹æ˜“åšåˆ° ç›®æ ‡ï¼šæˆ‘ä»¬éœ€è¦reprojectä¸¤ä¸ªimage planeï¼Œè®©ä»–ä»¬åœ¨å®Œå…¨ç›¸åŒçš„planeé‡Œé¢ï¼Œå¯ä»¥å¾—åˆ°å®Œç¾Žçš„aligned æˆ‘ä»¬å¸Œæœ›åœ¨rectificationä¹‹åŽå›¾ç‰‡çš„row aligedï¼Œè¿™æ ·stereo correspondenceï¼ˆåœ¨ä¸¤ä¸ªå›¾ç‰‡é‡Œæ‰¾ç›¸åŒçš„ç‚¹ï¼‰å°±ä¼šå˜å¾—æ›´å¯ä¿¡è€Œä¸”å®¹æ˜“è®¡ç®— åœ¨å¦ä¸€å¼ ç…§ç‰‡é‡Œåªæ‰¾matchä¸€ä¸ªç‚¹çš„row è¿™æ ·çš„ç»“æžœä¼šæœ‰æ— é™ä¸ªå¾…é€‰ æˆ‘ä»¬å†äººä¸ºçš„åŠ ä¸Šé™åˆ¶ ç»“æžœä¼šæœ‰å…«ä¸ªtermï¼Œå››ä¸ªç»™å·¦è¾¹çš„ç›¸æœºï¼Œå››ä¸ªç»™å³è¾¹çš„ç›¸æœºï¼ˆä¸¤ç§è®¡ç®—è¿™äº›å‚æ•°çš„ç®—æ³•ï¼‰ æ¯ä¸ªç›¸æœºéƒ½ä¼šæœ‰distCoffså’Œæ—‹è½¬çŸ©é˜µRï¼Œä¿®æ­£å’Œæœªä¿®æ­£çš„ç›¸æœºçŸ©é˜µï¼ˆ4ä¸ªï¼‰ ç”¨ä¸Šé¢è¿™äº›ä¸œè¥¿ï¼Œå¾—åˆ°mapæ¥ç¡®å®šåŽŸå›¾è¦æ€Žä¹ˆä¿®æ”¹cv::initUndistortRectifyMap() Hartleyâ€™s algorithm + Bouguetâ€™s algorithmï¼ˆp730ï¼‰Rectification mapStereo Correspondence åœ¨ä¸¤ä¸ªå›¾ç‰‡é‡Œé¢matchä¸‰ç»´çš„ç‚¹ï¼Œåªèƒ½åœ¨ä¸¤å¼ å›¾ç‰‡äº¤å çš„åœ°æ–¹æ‰¾åˆ° ä¸¤ç§ä¸åŒçš„ç®—æ³• block matchingï¼šå¿«ï¼Œæ•ˆçŽ‡é«˜ï¼ŒåŸºäºŽâ€œsum of absolute differenceâ€ (SADï¼‰ åªä¼šæ‰¾åˆ°é«˜åº¦ç¬¦åˆçš„ç‚¹ï¼ˆhighly texturedï¼‰-&gt; æˆ·å¤– semi-global block matching (SGBM) ï¼šç²¾ç¡®åº¦æ›´é«˜ matching is done at subpixel level using the Birchfield-Tomasi metric enforce a global smoothness constraint on the computed depth information that it approximates by considering many one-dimensional smoothness constraints through the region of interest Block matchingä¸‰ä¸ªæ­¥éª¤ prefilteringï¼Œnormalå›¾ç‰‡çš„äº®åº¦ï¼Œå¢žå¼ºçº¹ç† ç”¨SADçš„çª—å£ï¼Œæœç´¢æ°´å¹³çš„epipolar line åœ¨rectificatinä¹‹åŽï¼Œæ¯è¡Œéƒ½æ˜¯ä¸€ä¸ªepipolar lineï¼Œæ‰€ä»¥å·¦è¾¹çš„å›¾ç‰‡è‚¯å®šåœ¨å³è¾¹çš„åŒä¸€è¡Œé‡Œé¢æœ‰ä¸€ä¸ªå¯¹åº”çš„éƒ¨åˆ† disparityä¼šåœ¨ä¸€å®šçš„pixelèŒƒå›´é‡Œè¿›è¡Œæœç´¢ï¼Œä¸åŒèŒƒå›´é‡Œçš„disparityä»£è¡¨çš„æ˜¯ä¸åŒçš„depthã€‚ä½†æ˜¯è¶…è¿‡äº†æœ€å¤§å€¼çš„è¯å°±æ‰¾ä¸åˆ°depthäº† -&gt; Each disparity limit defines a plane at a fixed depth from the cameras Postfilteringï¼Œå‡å°‘æ¯”è¾ƒå·®çš„ç»“æžœ Semi-global block matchingcode example ï¼ˆp752ï¼‰Structure from Motion ä»Žç§»åŠ¨ä¸­å¾—åˆ°æž„é€ ä¿¡æ¯ã€‚ä½†æ˜¯åœ¨é™æ­¢çš„æƒ…å†µä¸‹ï¼Œä¸€ä¸ªç›¸æœºç§»åŠ¨å¾—åˆ°çš„ä¿¡æ¯å’Œä¸¤ä¸ªç›¸æœºå¾—åˆ°çš„ä¿¡æ¯æ²¡æœ‰æœ¬è´¨çš„åŒºåˆ« ä½†æ˜¯å¦‚æžœç‰¹åˆ«å¤§çš„æ—¶å€™ï¼Œå°±éœ€è¦é€šè¿‡è®¡ç®—frameä¹‹é—´çš„å…³ç³»å¾—åˆ°æœ€åŽçš„ç»“æžœï¼ˆSLAMï¼Ÿï¼‰ åœ¨é™„å½• FitLineï¼ˆç›´çº¿æ‹Ÿåˆï¼‰ åœ¨ä¸‰ç»´çš„åˆ†æžä¹‹ä¸­æ¯”è¾ƒå¸¸ç”¨ï¼Œæ‰€ä»¥åœ¨è¿™é‡Œä»‹ç»]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>OpenCV</category>
        <category>Projection</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Projection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcodeç¬”è®°]]></title>
    <url>%2F2019%2F05%2F07%2FLeetcode%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[è¿›åº¦ï¼š arrayéƒ¨åˆ†å·®ä¸å¤š stringéƒ¨åˆ†æé«˜å¾€åŽæ²¡æœ‰ç»§ç»­ mathéƒ¨åˆ†æµ…å°è¾„æ­¢ å¼€å§‹æžæ ‘çš„éƒ¨åˆ† 1 twoSumGiven an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example: Given nums = [2, 7, 11, 15], target = 9, Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. 1234567class Solution: def twoSum(self, nums: List[int], target: int) -&gt; List[int]: for i, item in enumerate(nums): if target - item in nums and nums.index(target - item) != i: return [i, nums.index(target - item)] æ€»ç»“ï¼š åˆšå¼€å§‹ç”¨äº†ç›´æŽ¥foræ‰€æœ‰çš„å…ƒç´ çš„æ–¹æ³•ï¼Œå¿˜è®°è€ƒè™‘å½“ä¸¤ä¸ªæ•°å­—é‡å¤çš„æ—¶å€™éœ€è¦æ€Žä¹ˆåŠžï¼Œè€ƒè™‘äº†ä¹‹åŽåœ¨éžå¸¸å¤§çš„æ•°çš„æƒ…å†µä¸‹çˆ†ç‚¸äº† æ ‡å‡†ç­”æ¡ˆè¯´åˆ°äº†hashè¡¨ï¼Œä½†æ˜¯å…¶å®žåœ¨pythonå®žçŽ°é‡Œé¢æœ¬èº«å°±æ˜¯ä¸ªhashï¼ˆä¸ç„¶æ€Žä¹ˆä»Žç´¢å¼•å¾—åˆ°ç»“æžœï¼‰ï¼Œä¸éœ€è¦è€ƒè™‘è¿™ä¸ªé—®é¢˜ ç„¶åŽè€ƒè™‘äº†æŠŠæ‰€æœ‰ä¸œè¥¿éƒ½æ”¾ä¸€ä¸ªdicté‡Œé¢ï¼ˆæ¯•ç«Ÿhashï¼Ÿï¼‰ï¼Œä½†æ˜¯é‡åˆ°çš„é—®é¢˜æ˜¯ä»Žvalueç›´æŽ¥å¾—åˆ°keyä¼šç”Ÿä¸€äº›é—®é¢˜ã€‚å¦‚æžœæŠŠæ•°å­—ä½œä¸ºkeyï¼Œç´¢å¼•ä½œä¸ºvalueä¼šå‘çŽ°æ•°å­—æœ‰é‡å¤çš„ï¼Œä¼šè¦†ç›–keyçš„å€¼ è¿™æ—¶å€™çªç„¶å‘çŽ°ï¼Œå¦‚æžœç”¨æ•°å­—ä½œä¸ºç´¢å¼•çš„è¯å…¶å®ždictå’Œlistæ²¡æœ‰æœ¬è´¨åŒºåˆ«ï¼Œåœ¨listé‡Œé¢æ“ä½œå°±è¡Œäº†ï¼Œè€Œä¸”listçš„.index()å¯ä»¥ç›´æŽ¥è¿”å›žè¿™ä¸ªå€¼å¾—åæ ‡ï¼ˆæ‰¾åˆ°çš„æ˜¯ç¬¬ä¸€ä¸ªå€¼ï¼ï¼ï¼‰ æ‰€ä»¥ç›´æŽ¥ç”¨enumerateæŠŠæ‰€æœ‰çš„indexå’Œiteméƒ½åˆ—å‡ºæ¥å°±å¯ä»¥è§£å†³äº†ï¼Œç¥žå¥‡ã€‚ 27 remove elementGiven an array nums and a value val, remove all instances of that value in-place and return the new length. Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory. The order of elements can be changed. It doesnâ€™t matter what you leave beyond the new length. Example 1: Given nums = [3, 2, 2, 3], val = 3, Your function should return length = 2, with the first two elements of nums being 2. It doesnâ€™t matter what you leave beyond the returned length.Example 2: Given nums = [0, 1, 2, 2, 3, 0, 4, 2], val = 2, Your function should return length = 5, with the first five elements of nums containing 0, 1, 3, 0, and 4. Note that the order of those five elements can be arbitrary. It doesnâ€™t matter what values are set beyond the returned length. 12345678910111213class Solution: def removeElement(self, nums: List[int], val: int) -&gt; int: remove_nums = 0 ori_length = len(nums) for i in range(len(nums)): if nums[i] == val: remove_nums += 1 nums[i] = float('inf') nums.sort() nums = nums[:ori_length - remove_nums] return len(nums) æ€»ç»“ï¼š è¿™é“é¢˜çš„é‡ç‚¹æ˜¯éœ€è¦in - placeçš„å¤„ç†ï¼Œç©ºé—´å¤æ‚åº¦è¦æ±‚å¾ˆé«˜ï¼ˆç„¶è€Œæˆ‘çš„ç©ºé—´ç»“æžœå¾ˆåžƒåœ¾ï¼‰ã€‚ä¸€ä¸ªé‡ç‚¹å°±æ˜¯è¿”å›žçš„listä¸éœ€è¦æŒ‰ç…§åŽŸæ¥çš„é¡ºåºæŽ’åˆ— ä»Žä¸éœ€è¦åŽŸæ¥çš„é¡ºåºå¾—åˆ°çš„æ€è·¯æ˜¯ï¼šæˆ‘æŠŠéœ€è¦åˆ é™¤çš„ä¸œè¥¿çš„ä½ç½®æ”¹æˆäº†infï¼Œç„¶åŽå¯¹æ‰€æœ‰éƒ¨åˆ†è¿›è¡ŒæŽ’åºï¼Œå¾—åˆ°æŽ’åºä¹‹åŽçš„ç»“æžœå†è¿›è¡Œåˆ‡ç‰‡ï¼ˆè¿™é‡Œåˆšå¼€å§‹çš„æ€è·¯æ˜¯åˆ æŽ‰è¿™ä¸ªåœ°æ–¹çš„ä¸œè¥¿ç„¶åŽå†insertï¼ŒåŽæ¥å‘çŽ°ç›´æŽ¥æ›¿æ¢å°±å¥½äº†ï¼‰ å…¶å®žä¹Ÿå¯ä»¥ç›´æŽ¥ç”¨äº¤æ¢ä½ç½®çš„æ–¹æ³•ï¼Œä¸ç”¨åˆ‡ç‰‡ï¼Œå› ä¸ºé¢˜ç›®åªéœ€è¦å‰é¢çš„è¿™äº›å…ƒç´ ç¬¦åˆè¦æ±‚å°±å¯ä»¥äº†ï¼Œæ²¡æœ‰è¯´åŽé¢çš„æ€Žä¹ˆæ ·ã€‚ çœ‹äº†ä¸€äº›discussionéƒ½æ˜¯memoryåªæ¯”5 % çš„äººå°‘ã€‚ã€‚ã€‚ä½†æ˜¯å·®è·éƒ½ä¸å¤§åº”è¯¥æ²¡é—®é¢˜ï¼ çœ‹åˆ°äº†ä¸€ä¸ªè¶…çº§ç‰›é€¼ç®€è¦å†™æ³•ï¼š1234while val in nums: nums.remove(val)return len(nums) 80Given a sorted array nums, remove the duplicates in-place such that duplicates appeared at most twice and return the new length. Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory. Example 1: Given nums = [1, 1, 1, 2, 2, 3], Your function should return length = 5, with the first five elements of nums being 1, 1, 2, 2 and 3 respectively. It doesnâ€™t matter what you leave beyond the returned length. 1234567891011121314151617181920212223242526class Solution: def removeDuplicates(self, nums: List[int]) -&gt; int: i = 0 while(True): if i &gt;= len(nums) - 1: if len(nums) &gt; 2 and nums[i] == nums[i - 2]: nums = nums[:nums.index(nums[i]) + 2] break else: break if nums[i] == nums[i + 1]: i += 1 else: next_num = nums[i + 1] start_index = nums.index(nums[i]) next_index = nums.index(next_num) if next_index - start_index &gt; 2: for l in range(start_index + 2, next_index): nums[l] = float('inf') i = next_index while float('inf') in nums: nums.remove(float('inf')) return len(nums) æ€»ç»“ï¼š æˆ‘æ·±ä¿¡æˆ‘çš„æ–¹æ³•è™½ç„¶è ¢ä½†æ˜¯æ²¡æœ‰é—®é¢˜ï¼Œä½†æ˜¯è·‘å‡ºæ¥å°±æ˜¯æœ‰é—®é¢˜ï¼Œåˆ†æ˜Žæˆ‘returnä¹‹å‰çš„æ•°æ®è¿˜éƒ½æ˜¯å¯¹çš„ï¼Œä½†æ˜¯returnä¹‹åŽæ˜¾ç¤ºçš„ä¸œè¥¿å°±éƒ½æœ‰é—®é¢˜äº† ä¸»è¦æ€è·¯æ˜¯è¿™æ ·çš„ å› ä¸ºin - placeæ“ä½œï¼Œæ‰€ä»¥å°±ä¸èƒ½ç›´æŽ¥ç”¨removeåŽ»æŽ‰å…ƒç´ å¯¼è‡´ä¸‹æ ‡é”™ä¹± æœ¬æ¥æ˜¯æƒ³å’Œä¸Šé¢çš„æ€è·¯ä¸€æ ·ï¼Œæ¢æˆinfï¼Œç„¶åŽå†æŠŠæœ‰infçš„éƒ¨åˆ†åˆ é™¤æŽ‰ï¼ˆå‚è€ƒäº† # 27çš„ç®€æ˜“è§£æ³•ï¼‰ æ€Žä¹ˆæ¢æˆinfå‘¢ï¼Œæˆ‘åˆ¤æ–­çš„æ–¹æ³•æ˜¯æ‰¾åˆ°ä¸‹ä¸€ä¸ªå€¼å¾—indexï¼Œç„¶åŽè®¡ç®—è¿™ä¸ªindexå’Œä¸Šä¸€ä¸ªä¹‹é—´å·®å¤šå°‘ä¸ªæ•°ï¼Œç„¶åŽæŠŠå¯Œè£•çš„æ•°å­—éƒ½æ›¿æ¢æˆinf å¿½ç•¥çš„é—®é¢˜ï¼š æ•°æ•°æ•°é”™äº†å¾ˆå¤šé—®é¢˜ æœ€å¼€å§‹æ²¡æœ‰è€ƒè™‘åˆ°ä»€ä¹ˆåœæ­¢ ç„¶åŽæ²¡æœ‰è€ƒè™‘åˆ°å¦‚æžœæœ€åŽä¸€ä¸ªæ•°å­—é‡å¤äº†ä¸¤éä»¥ä¸Šè¦æ€Žä¹ˆåŠžçš„é—®é¢˜ï¼ˆè¿™ä¹Ÿæ˜¯æˆ‘ç”¨next_indexçš„ä¸€ä¸ªå¼Šç«¯ï¼‰ ç„¶åŽçœ‹ç€å¤§ä½¬çš„ä»£ç å“­å‡ºäº†å£°ï¼ï¼ï¼12345678910class Solution: def removeDuplicates(self, nums: List[int]) -&gt; int: i = 0 for n in nums: if i &lt; 2 or n != nums[i - 2]: nums[i] = n i += 1 return i æ€»ç»“ï¼š å“‡è¿™ä¸ªæ€è·¯çœŸçš„ç‰›é€¼ï¼ ä¸­å¿ƒæ€æƒ³å°±æ˜¯è®©næ¥å¢žåŠ ä½†æ˜¯iä¸å¢žåŠ ï¼Œè¿™é‡Œå·²ç»è¯´äº†ä¸åœ¨æ„å‰é¢é¡¹ä¹‹åŽlisté‡Œé¢çš„å†…å®¹ï¼Œä¹Ÿå°±æ˜¯è¯´å‰né¡¹ä¹‹åŽçš„ä¸œè¥¿éƒ½ä¸ç”¨ç®¡äº†ã€‚æ—¢ç„¶å¦‚æ­¤çš„è¯ä¸Žå…¶ç”¨infæ¥æ›¿æ¢è¿™ä¸ªä½ç½®çš„æ•°å­—ï¼Œä¸å¦‚ç›´æŽ¥ç”¨åŽé¢çš„é¡¹å¡«åœ¨ç›¸å¯¹åº”çš„ä½ç½®ä¸Šï¼Œåªæœ‰å¡«æˆåŠŸäº†æ‰ä¼šå¢žåŠ i è¿™é‡Œéœ€è¦å…ˆåˆ¤æ–­içš„å€¼æ˜¯å¦å°äºŽ2ï¼Œç„¶åŽå†è®¡ç®—nums[i - 2]ï¼Œå¦åˆ™ä¼šout of range iè·‘çš„é€Ÿåº¦æ²¡æœ‰è¶…è¿‡nè·‘çš„é€Ÿåº¦æ‰€ä»¥æ²¡æœ‰å…³ç³» åˆç†åˆ©ç”¨é¢˜é‡Œé¢çš„æ¡ä»¶é™åˆ¶çœŸçš„å¾ˆé‡è¦ï¼ï¼ 189 Rotate arrayGiven an array, rotate the array to the right by k steps, where k is non - negative. Example 1: Input: [1, 2, 3, 4, 5, 6, 7] and k = 3Output: [5, 6, 7, 1, 2, 3, 4]Explanation:rotate 1 steps to the right: [7, 1, 2, 3, 4, 5, 6]rotate 2 steps to the right: [6, 7, 1, 2, 3, 4, 5]rotate 3 steps to the right: [5, 6, 7, 1, 2, 3, 4] Example 2: Input: [-1, -100, 3, 99] and k = 2Output: [3, 99, -1, -100]Explanation:rotate 1 steps to the right: [99, -1, -100, 3]rotate 2 steps to the right: [3, 99, -1, -100] Note: Try to come up as many solutions as you can, there are at least 3 different ways to solve this problem.Could you do it in-place with O(1) extra space? æ€è·¯ éœ€ä¸éœ€è¦æ³¨æ„k = 0çš„æ—¶å€™ å¦‚æžœkçš„ä¸ªæ•°ç‰¹åˆ«å¤§éœ€ä¸éœ€è¦ç®€åŒ–ä¸€ä¸‹ 123456789101112class Solution: def rotate(self, nums: List[int], k: int) -&gt; None: """ Do not return anything, modify nums in-place instead. """ steps = k % len(nums) unchange_nums = nums[:len(nums) - steps] change_nums = nums[len(nums) - steps:] nums[:steps] = change_nums nums[steps:] = unchange_nums æ€»ç»“ï¼š å±…ç„¶ç¬¬ä¸€ç§å°±è¿™ä¹ˆå†™å‡ºæ¥äº†ï¼Œå®žé™…ä¸Šå°±æ˜¯æŠŠåŽé¢çš„æ•°å­—ç§»åŠ¨åˆ°å‰é¢åŽ» æ³¨æ„numsä¸èƒ½ç›´æŽ¥ç”¨change_nums + unchange_numsï¼Œå¤§æ¦‚æ˜¯ä»–è®¤ä¸ºè¿™ä¸ªä¸æ˜¯in - placeäº†å§ å¦ä¸€ç§æ–¹æ³•ï¼šin-place123456789101112 k = k % len(nums) self.reverse_nums(nums, 0, len(nums) - 1) self.reverse_nums(nums, 0, k - 1) self.reverse_nums(nums, k, len(nums) - 1)def reverse_nums(self,nums,start,end): while start &lt; end: temp = nums[start] nums[start] = nums[end] nums[end] = temp start += 1 end -= 1 å®žé™…ä¸Šï¼Œrotateçš„å¦å¤–ä¸€ç§æ–¹æ³•æ˜¯å…ˆæŠŠæ•´ä¸ªliståå‘ï¼Œç„¶åŽæŠŠå‰é¢çš„kä¸ªåå‘ï¼Œç„¶åŽå†æŠŠåŽé¢çš„(n-k)ä¸ªåå‘ï¼ˆè¿™é‡Œæˆ‘æ˜¯æ²¡æƒ³åˆ°çš„ï¼‰ æŠŠä¸€ä¸ªæ•°ç»„åå‘çš„ç®—æ³•å°±æ˜¯ä»Žä¸¤å¤´å‘ä¸­é—´é€¼è¿‘ç€äº¤æ¢ï¼ˆæˆ‘è¯¥å¥½å¥½åŽ»çœ‹çœ‹åŸºç¡€çš„ç®—æ³•äº†ã€‚ã€‚ï¼‰ æœ€åŽï¼Œè¿˜æœ‰ä¸€ç§æ–¹æ³•æ˜¯è·³ç€è®¾ç½®å€¼ï¼Œä¹Ÿå°±æ˜¯è¯´kä¸ªä¹‹åŽçš„å€¼å°±åº”è¯¥æ˜¯çŽ°åœ¨è¿™ä¸ªä½ç½®çš„å€¼ 41 First Missing PositiveGiven an unsorted integer array, find the smallest missing positive integer. Example 1: Input: [1,2,0]Output: 3Example 2: Input: [3,4,-1,1]Output: 2Example 3: Input: [7,8,9,11,12]Output: 1Note: Your algorithm should run in O(n) time and uses constant extra space. ç¬¬ä¸€ä¸ªæ€è·¯ï¼šæ—¶é—´nlog(n)12345678class Solution: def firstMissingPositive(self, nums: List[int]) -&gt; int: nums.sort() target = 1 for n in nums: if n == target: target += 1 return target è¿™ä¸ªæ€è·¯æ•´ä½“å»ºç«‹åœ¨å…ˆæŽ’åºçš„åŸºç¡€ä¸Šï¼Œä½†æ˜¯æŽ’åºçš„æ—¶é—´å¤æ‚åº¦æœ¬èº«å°±å·²ç»æ˜¯nlog(n)äº† æŽ’åº - æ‰¾åˆ°æ¯”0å¤§çš„æ•°å­—ä»Žè¿™é‡Œå¼€å§‹ - è¿™ä¸ªæ•°å­—ä¸ç¬¦åˆçš„è¯æ‰¾ä¸‹ä¸€ä¸ª ä½†æ˜¯æˆ‘åœ¨æ‰¾æ¯”0å¤§çš„æ•°å­—çš„æ—¶å€™è¿˜æƒ³ç€æŠŠliståˆ‡ç‰‡ï¼Œåˆ‡ç‰‡å°±åˆéœ€è¦è€ƒè™‘0å•Šï¼Œ1å•Šï¼Œç¼ºå¤šå°‘ä¸ªæ•°å­—çš„é—®é¢˜ï¼Œç©ºçš„listã€‚å…¶å®žæ ¹æœ¬ä¸ç”¨è¿™ä¹ˆéº»çƒ¦ æœ¬è´¨ä¸Šè¿™ä¸ªæ–¹æ³•å°±æ˜¯ï¼Œæ‰¾åˆ°missçš„æ­£æ•°ï¼Œé‚£å°±ä»Žæ­£æ•°çš„ç¬¬ä¸€ä¸ªï¼ˆ1ï¼‰å¼€å§‹æ‰¾ï¼Œå¦‚æžœæ‰¾åˆ°äº†è¿™ä¸ªæ•°å°±ç»§ç»­æ‰¾ä¸‹ä¸€ä¸ªï¼ˆtarget++ï¼‰ï¼Œæ€»æ˜¯èƒ½æ‰¾åˆ°çš„å˜›ï¼Œæ‰¾åˆ°çš„å°±æ˜¯ç¼ºçš„æ•°å­—äº† è‡ªå·±çš„æ–¹æ³•12345678910111213141516class Solution: def firstMissingPositive(self, nums: List[int]) -&gt; int: if nums is None or len(nums) == 0: return 1 for i in range(len(nums)): target_num = i + 1 if nums[i] == target_num: if i == len(nums) - 1: return target_num + 1 else: continue if target_num in nums: temp = nums.index(target_num) nums[temp],nums[i] = nums[i], nums[temp] else: return target_num æ¡¶æŽ’åºï¼šè¦æŠŠå¯¹åº”çš„æ•°å­—æ”¾åœ¨å¯¹åº”çš„ä½ç½®ä¸Š è¿™é“é¢˜é‡Œåº”è¯¥çš„æ ·å­å°±æ˜¯nums[index] = index + 1 å¤§ä½¬çš„æ€è·¯ -&gt; é¦–å…ˆåˆ¤æ–­è¾¹ç•Œæ¡ä»¶ï¼ï¼(å­¦åˆ°äº†å­¦åˆ°äº†) çœ‹è¿‡äº†ä¸Šé¢çš„æç¤ºå†™å‡ºæ¥çš„ç¬¬äºŒç‰ˆ åˆ¤æ–­è¾¹ç•Œæ¡ä»¶ åˆ¤æ–­è¿™ä¸ªæ•°å­—æ˜¯ä¸æ˜¯æ‘†åœ¨äº†æ­£ç¡®çš„ä½ç½® æ­£ç¡®ï¼Œåˆ¤æ–­æ˜¯å¦æ˜¯æœ€åŽä¸€ä¸ªæ•°å­— æ˜¯ï¼Œè¾“å‡ºçš„æ˜¯æœ€åŽä¸€ä¸ªæ•°å­—+1 ä¸æ˜¯ï¼Œè¿™ä¸ªä½ç½®çš„æ­£ç¡®äº†ï¼Œåˆ¤æ–­ä¸‹ä¸€ä¸ªä½ç½® æ²¡æœ‰ï¼Œåˆ¤æ–­numsé‡Œé¢è¿˜æœ‰æ²¡æœ‰åº”è¯¥æ‘†åœ¨è¿™ä¸ªä½ç½®çš„æ•°å­— æœ‰ï¼Œé‚£å°±å’Œè¿™ä¸ªä½ç½®äº¤æ¢ æ²¡æœ‰ï¼Œé‚£æ²¡æœ‰çš„æ•°å­—å°±æ˜¯ç¼ºå°‘çš„æ•°å­—äº† å› ä¸ºæ¯æ¬¡éƒ½æ˜¯æŠŠæ•°å­—æ¢åˆ°äº†æ­£ç¡®çš„ä½ç½®äº†ï¼Œæ‰€ä»¥äº¤æ¢æœ€å¤šè¿›è¡Œlen(nums)æ¬¡ï¼Œæ—¶é—´å¤æ‚åº¦æ˜¯O(n) 123456789def firstMissingPositive(self, nums): for i in xrange(len(nums)): while 0 &lt;= nums[i]-1 &lt; len(nums) and nums[nums[i]-1] != nums[i]: tmp = nums[i]-1 nums[i], nums[tmp] = nums[tmp], nums[i] for i in xrange(len(nums)): if nums[i] != i+1: return i+1 return len(nums)+1 å¤§ä½¬çš„å¦ä¸€ä¸ªæ–¹æ³•ï¼Œå…¶å®žæ€è·¯å’Œä¸Šé¢çš„å·®ä¸å¤šï¼Œå°±æ˜¯æŠŠæ•°å­—æ¢åˆ°æ­£ç¡®çš„ä½ç½®ä¸Šï¼Œä½†æ˜¯åˆ¤æ–­çš„æ¡ä»¶å’Œæˆ‘çš„æœ‰ä¸€ç‚¹ä¸åŒï¼Œå¯èƒ½å› ä¸ºæˆ‘çš„æ˜¯åŸºäºŽpythonçš„åŠŸèƒ½ å…¶ä¸­ï¼Œæ¢åˆ°æ­£ç¡®ä½ç½®çš„æ•°å­—å°±æ˜¯åœ¨1åˆ°len(nums)ä¹‹é—´çš„æ•°å­—ã€‚nums[i]-1æ˜¯è¿™ä¸ªæ•°å­—åº”è¯¥çš„åæ ‡ä½ç½®ï¼Œå¦‚æžœåº”è¯¥çš„ä½ç½®å’ŒçŽ°åœ¨çš„ä½ç½®çš„æ•°å­—ä¸ä¸€æ ·ï¼Œé‚£å°±äº¤æ¢è¿™ä¸¤ä¸ªæ•°å­— æ³¨æ„è¿™é‡Œéœ€è¦ç”¨whileæ¢ï¼Œè¦ä¸€ç›´æ¢åˆ°æ­£ç¡®çš„ä½ç½®æ‰å¯ä»¥ è¿™æ ·çš„ç»“æžœå°±æ˜¯å¤§å®¶éƒ½æŒ‰æ­£ç¡®çš„å¡«å¥½äº†ï¼Œæœ€åŽä¸å¯¹çš„é‚£ä¸ªä½ç½®çš„index+1å°±æ˜¯éœ€è¦çš„ç»“æžœ 299You are playing the following Bulls and Cows game with your friend: You write down a number and ask your friend to guess what the number is. Each time your friend makes a guess, you provide a hint that indicates how many digits in said guess match your secret number exactly in both digit and position (called â€œbullsâ€) and how many digits match the secret number but locate in the wrong position (called â€œcowsâ€). Your friend will use successive guesses and hints to eventually derive the secret number. Write a function to return a hint according to the secret number and friendâ€™s guess, use A to indicate the bulls and B to indicate the cows. Please note that both secret number and friendâ€™s guess may contain duplicate digits. Example 1: Input: secret = â€œ1807â€, guess = â€œ7810â€ Output: â€œ1A3Bâ€ Explanation: 1 bull and 3 cows. The bull is 8, the cows are 0, 1 and 7.Example 2: Input: secret = â€œ1123â€, guess = â€œ0111â€ Output: â€œ1A1Bâ€ Explanation: The 1st 1 in friendâ€™s guess is a bull, the 2nd or 3rd 1 is a cow.Note: You may assume that the secret number and your friendâ€™s guess only contain digits, and their lengths are always equal. 1234567class Solution: def getHint(self, secret: str, guess: str) -&gt; str: bull = sum(a == b for a,b in zip(secret,guess)) cow = 0 for x in set(guess): cow += min(secret.count(x),guess.count(x)) return str(bull) + "A" + str(cow-bull) + "B" è¿™é‡Œè‡ªå·±æƒ³äº†ä¸€äº›æ¯”è¾ƒè ¢çš„æƒ³æ³•ä¹‹åŽç›´æŽ¥å‚è€ƒåˆ«äººçš„äº† å…¶ä¸€æ˜¯æ¯”å¯¹ä»–ä»¬ä¸¤ä¸ªä½ç½®å’Œæ•°å­—éƒ½ç›¸åŒçš„ä¸œè¥¿ï¼Œæƒ³è¦è½¬æ¢æˆdictæ¥æ¯”è¾ƒï¼Œä½†æ˜¯åŽæ¥å‘çŽ°stringå°±å¯ä»¥ç›´æŽ¥indexäº†ä¸ç”¨è¿™ä¹ˆéº»çƒ¦ æƒ³è¿‡èƒ½ä¸èƒ½æŒ‰ä½åšå‡æ³•ï¼Œæœªæžœ å…¶äºŒæ˜¯åœ¨å¾—åˆ°äº†bullä¹‹åŽæŠŠbullçš„éƒ¨åˆ†ä»ŽåŽŸæ¥çš„é‡Œé¢å‰”é™¤å‡ºåŽ»ç„¶åŽå†æ¯”è¾ƒç›¸ä¼¼çš„æ•°å­— é‡åˆ°äº†ä¸»è¦é—®é¢˜æ˜¯é‡å¤çš„æ•°å­—æ€Žä¹ˆåŠžä»¥åŠå¦‚ä½•å‰”é™¤å‡ºåŽ»bull ä¸»è¦æ€è·¯æ˜¯è¿™æ ·çš„ï¼š å…¶å®žcowçš„æ•°é‡å°±æ˜¯bull-cowéƒ½æ˜¯çš„æ•°é‡å‡åŽ»bullçš„æ•°é‡ï¼Œä¹Ÿå°±ç›¸å½“äºŽç»´æ©å›¾é‡Œé¢ï¼Œåªæœ‰Açš„é‡æ˜¯Açš„é‡ - åŒæ—¶ABçš„é‡ã€‚è¿™é‡Œæ˜¯bullå°±ç›¸å½“äºŽABéƒ½æœ‰ï¼Œä¸¤ä¸ªé‡Œé¢æ‰€æœ‰é‡å¤çš„æ•°é‡å°±ç›¸å½“äºŽAçš„é‡ è¿™æ ·å¯ä»¥åšå‡æ³•å°±è§£å†³äº†ä¸Šé¢çš„ä»Žbullå¾—åˆ°cowçš„é—®é¢˜ï¼ï¼ æ‰€ä»¥è¯´çœ‹é—®é¢˜è¿˜æ˜¯è¦çœ‹æœ¬è´¨ é¢å¯¹é‡å¤çš„æ•°å­—ï¼Œå±…ç„¶å¯ä»¥ç›´æŽ¥æŠŠstringè½¬æ¢æˆset è¿™é‡Œå¤ä¹ ä¸€ä¸‹setå¥½å—ï¼ï¼ï¼è¿™ä¸ªé›†åˆå±…ç„¶å¯ä»¥æ²¡æœ‰é‡å¤çš„å…ƒç´ ï¼Œå¹³å¸¸æˆ‘å¿½è§†ä½ äº†å‘€å°å¯çˆ±ï¼Œè½¬åŒ–æˆsetå°±ä¸ä¼šé‡å¤äº†å“¦ï¼Œéœ‡æƒŠï¼ï¼ è¿™æ ·é—®é¢˜å°±å˜æˆäº†ï¼š æ±‚bullï¼šç”¨zipæŠŠä¸¤ä¸ªä¸œè¥¿ä¸€ä¸€å¯¹åº”çš„æ‰“åŒ…èµ·æ¥ï¼ˆå±…ç„¶è¿˜æœ‰ä½ å°å¯çˆ±ï¼ï¼‰ç›´æŽ¥å¯¹æ¯” æ±‚bothï¼šguessé‡Œé¢çŒœçš„æ¬¡æ•°å°±æ˜¯æ€»ä½“çš„æ¬¡æ•°ï¼Œsecreté‡Œé¢çš„æ¬¡æ•°æ˜¯çœŸå®žçš„æ¬¡æ•°ï¼Œå¯¹äºŽæ¯ä¸ªåœ¨guessé‡Œé¢ï¼ˆsetï¼‰çš„å…ƒç´ éƒ½çœ‹çœ‹åˆ†åˆ«åœ¨ä¸¤ä¸ªé‡Œé¢æ˜¯å¤šå°‘ä¸ªï¼Œç„¶åŽå°çš„é‚£ä¸ªå°±æ˜¯bothçš„å¤§å° è¿™é‡Œä»‹ç».count()å°å¯çˆ±ï¼Œå±…ç„¶è¿˜å¯ä»¥æ•°æ•°ï¼ æœ€åŽboth-bullå°±æ˜¯ç»“æžœäº† 134 gas stationå±…ç„¶è‡ªå·±æžå‡ºæ¥äº†ä¸€ä¸ªçœ‹èµ·æ¥å¾ˆè ¢çš„1234567891011121314151617181920212223242526class Solution: def canCompleteCircuit(self, gas: List[int], cost: List[int]) -&gt; int: if sum(gas) &lt; sum(cost): return -1 tank = 0 current = 0 counter = 0 while(True): tank = tank + gas[current] - cost[current] if tank &lt; 0: if current &lt; len(gas): current = current + 1 counter = 0 tank = 0 continue else: return -1 current += 1 current = current % len(gas) counter += 1 # print(current,counter) if counter == len(gas): return current % len(gas) ~æ—¶é—´è¶…è¿‡äº†ç™¾åˆ†ä¹‹48çš„äººï¼Œæ„Ÿè§‰å¯èƒ½è¿˜å¯ä»¥å§~æ—¶é—´éƒ½æ˜¯éª—äººçš„åˆè·‘äº†ä¸€æ¬¡å±…ç„¶è¶…è¿‡äº†ç™¾åˆ†ä¹‹86çš„ï¼ï¼ é‡ç‚¹ ä¸€ç›´æŒ‰ç€é¡ºåºè·‘ï¼Œä¸ä¼šè·³ç€èµ° å¦‚æžœgasçš„æ€»é‡ä»Žä¸€å¼€å§‹å°±å°äºŽcostçš„æ€»é‡ï¼Œé‚£ç»å¯¹ä¸å¯èƒ½ æˆ‘çš„æ€è·¯ï¼š ä»Žç¬¬ä¸€ä¸ªç‚¹å¼€å§‹è¯•ç€è·‘ï¼Œä¸€ç›´åˆ°è¯•ç€ä»Žæœ€åŽä¸€ä¸ªç‚¹å¼€å§‹è·‘ï¼Œæ‰¾åˆ°äº†å°±ç›´æŽ¥è¿”å›ž å¢žåŠ ä¸€ä¸ªè®¡æ•°çš„varï¼Œè®°ä¸€å…±è·‘äº†å¤šè¿œï¼Œå› ä¸ºæ˜¯æŒ‰ç€é¡ºåºè·‘çš„æ‰€ä»¥è¿™ä¸ªvarç­‰äºŽgasçš„é•¿åº¦çš„æ—¶å€™å°±æ˜¯è·‘å®Œäº† é¿å…out of rangeé—®é¢˜ï¼Œéœ€è¦æ±‚ä½™æ•° é‡åˆ°é—®é¢˜ï¼š å½“tankå°äºŽ0ï¼Œæ›´æ–°å®Œæ¡ä»¶ä¹‹åŽè®°å¾—continueç»§ç»­å¾ªçŽ¯å‘€ åˆšå¼€å§‹æƒ³ç”¨çš„åˆ¤æ–­æ¡ä»¶æ˜¯foræˆ–è€…whileé‡Œé¢å¸¦æ¡ä»¶ï¼Œè¿˜æƒ³äº†ä¸€ä¸‹è¦ä¸è¦zipè¿™ä¸¤ä¸ªæ•°æ®ï¼Œä½†æ˜¯éƒ½æ˜¯listå®žåœ¨æ˜¯æ²¡æœ‰å¿…è¦ã€‚ä½†æ˜¯æ„Ÿè§‰æ˜¯æƒ³çš„å®žåœ¨æ˜¯å¤ªå¤šäº† 1234567891011class Solution: def canCompleteCircuit(self, gas: List[int], cost: List[int]) -&gt; int: if sum(gas) &lt; sum(cost): return -1 rest = start = 0 for i in range(len(gas)): rest += gas[i] - cost[i] if rest &lt; 0: start = i + 1 rest = 0 return start å±…ç„¶æœ‰è¿™ä¹ˆç®€è¦çš„å†™æ³•ï¼ï¼ æ‰€ä»¥åªè¦ä¸æ˜¯sum(gas) &lt; sum(cost)å°±ä¸€å®šä¼šæœ‰è§£è¯¶ï¼Œç¥žå¥‡ã€‚ä¹Ÿå°±æ˜¯è¯´æˆ‘ä¸Šé¢æœ‰ä¸€ä¸ªè¿”å›žçš„-1æ˜¯æ²¡æœ‰æ„ä¹‰çš„ è€Œä¸”ç”¨forçš„è¯å°±ä¸ç”¨å†è€ƒè™‘counterçš„é—®é¢˜äº† ä»Žå“ªé‡Œå¤±è´¥å°±ä»Žå“ªé‡Œçš„ä¸‹ä¸€ä¸ªçˆ¬èµ·æ¥ 118 Pascalâ€™s TriangleExample: Input: 5Output:[ [1], [1,1], [1,2,1], [1,3,3,1], [1,4,6,4,1]] 1234567891011121314151617181920212223class Solution: def generate(self, numRows: int) -&gt; List[List[int]]: result = [] if numRows == 0: return [] for row in range(numRows): now_row = [] if row == 0: now_row = [1] elif row == 1: now_row = [1,1] else: now_row = [1] for member in range(1,row): now_row.append(result[row-1][member-1] + result[row-1][member]) now_row.append(1) result.append(now_row) return result æ€»ç®—æ˜¯è‡ªå·±å†™å‡ºæ¥ä¸€ä¸ªä¸œè¥¿äº† å¥½ç®€å•ï¼Œé™¤äº†å‰ä¸¤è¡Œæ˜¯ç‰¹å®šçš„ï¼Œå…¶ä»–çš„å¯ä»¥å½’ä¸ºä¸€ç±» æ±‚ä¸€ä¸ªç®€å•çš„æ•°å­¦å…³ç³»å°±è¡Œäº†ï¼Œæ•°æ•°åˆ«æ•°é”™äº†ï¼ï¼æ³¨æ„æ•°0 å”¯ä¸€æ²¡æœ‰æ³¨æ„çš„ç‚¹å°±æ˜¯ï¼šäº‹å…ˆä¸çŸ¥é“listçš„å¤§å°ï¼Œæ‰€ä»¥åˆå§‹åŒ–æˆç©ºçš„ä¹‹åŽéœ€è¦ç”¨appendæ·»åŠ å…ƒç´  119 æ¨è¾‰ä¸‰è§’å½¢2Given a non-negative index k where k â‰¤ 33, return the kth index row of the Pascalâ€™s triangle. Note that the row index starts from 0. Input: 3Output: [1,3,3,1] 1234567class Solution: def getRow(self, rowIndex: int) -&gt; List[int]: L = [1] while True: if len(L) == rowIndex + 1: return L L = [u+v for u,v in zip([0]+L,L+[0])] æ²¡æƒ³åˆ°æ¨è¾‰ä¸‰è§’å½¢çš„ä»£ç ä¹Ÿæœ‰ç®€è¦çš„è§£æ³•ï¼Œè¿™ä¸ªæ˜¯ç”¨Lè®°å½•äº†ä¸Šä¸€è¡Œçš„ä¿¡æ¯ï¼Œç„¶åŽå†æŠŠè¿™è¡Œæ‰©å……ä¸¤ä¸ª0ï¼Œç›¸å½“äºŽè¿™ä¸ªä¸‰è§’å½¢çš„æœ¬è´¨æ˜¯ä¸¤è¡Œé”™ä½ç›¸åŠ ï¼ï¼ æ³¨æ„æœ€åŽçš„Lå¾—åˆ°çš„æ˜¯ä¸€ä¸ªlistï¼Œlistè¦æœ‰listçš„æ ·å­ æ›´åŠ ç†è§£äº†ä¸€ä¸‹zipå’Œå•è¡Œforçš„ç”¨æ³• indexä»Ž0å¼€å§‹ï¼Œç»“æžœå¼€å§‹æ²¡æœ‰æ³¨æ„åˆ° while true åŠ ä¸Šä¸€ä¸ª ifçš„æ•ˆæžœç­‰åŒäºŽforçš„æ•ˆæžœï¼ï¼ï¼è¶Šå†™è¶Šç³Šæ¶‚ 169 Majority ElementGiven an array of size n, find the majority element. The majority element is the element that appears more than âŒŠ n/2 âŒ‹ times. You may assume that the array is non-empty and the majority element always exist in the array. Example 1: Input: [3,2,3]Output: 3Example 2: Input: [2,2,1,1,1,2,2]Output: 2 1234class Solution: def majorityElement(self, nums: List[int]) -&gt; int: nums.sort() return nums[len(nums)//2] æ€è·¯ï¼šè¿™å›žæƒ³åˆ°äº†å¾ˆå¤šåŽ†éçš„æ–¹æ³•ï¼Œä½†æ˜¯æ„Ÿè§‰å¤ªè ¢äº†ï¼Œç»ˆäºŽå¼€å§‹æƒ³æ€Žä¹ˆæ‰èƒ½æ›´å¥½çš„å®žçŽ°äº† åœ¨å†™å†™ç”»ç”»çš„æ—¶å€™çªç„¶è€ƒè™‘åˆ°ï¼Œå¦‚æžœæœ‰è¶…è¿‡ä¸€åŠçš„æ•°é‡éƒ½æ˜¯è¿™ä¸ªæ•°çš„è¯ï¼ŒæŠŠè¿™ä¸ªlistæŽ’åºä¹‹åŽæœ€ä¸­é—´çš„é‚£ä¸ªæ•°è‚¯å®šæ˜¯è¿™ä¸ªæ•° æžé™æƒ…å†µå°±æ˜¯ä¸¤ä¸ªå…ƒç´ å·®1ï¼Œè¿™æ—¶å€™æ˜¯å¤šä¸€ç‚¹çš„é‚£ä¸ªæ•°çš„è¾¹ç•Œä¸Š å…¶ä»–çš„æƒ…å†µä¸‹å°±æ˜¯åœ¨å‡ºçŽ°æœ€å¤šçš„é‚£ä¸ªæ•°çš„ä¸­é—´ æœ¬æ¥æƒ³è¦ç”¨floorçš„ï¼Œä½†æ˜¯å‘çŽ°éœ€è¦mathåŒ…ï¼Œæ‰€ä»¥ç”¨äº† // æ¥æ±‚é™¤ä¹‹åŽçš„æ•´æ•° 229 Majority Element 2Given an integer array of size n, find all elements that appear more than âŒŠ n/3 âŒ‹ times. Note: The algorithm should run in linear time and in O(1) space. Example 1: Input: [3,2,3]Output: [3]Example 2: Input: [1,1,1,3,3,2,2,2]Output: [1,2]12345678910111213141516171819202122class Solution: def majorityElement(self, nums: List[int]) -&gt; List[int]: if not nums: return [] major1,major2,count1,count2 = 0,1,0,0 for n in nums: if major1 == n: count1 += 1 elif major2 ==n: count2 += 1 elif count1 ==0: major1 = n count1 = 1 elif count2 == 0: major2 = n count2 =1 else: count1 -= 1 count2 -= 1 return [n for n in (major1,major2) if nums.count(n) &gt; len(nums) // 3] æ³¨æ„è¿™é“é¢˜è¯´çš„æ˜¯å‡ºçŽ°æ¬¡æ•°å¤§äºŽ1/3çš„æ•°å­—ï¼Œæ‰€ä»¥ç»“æžœåªæœ‰åªèƒ½æ˜¯æ²¡æœ‰ï¼Œ1ä¸ªæˆ–è€…ä¸¤ä¸ªï¼Œä¸å­˜åœ¨ç»“æžœæ˜¯ä¸‰ä¸ªçš„æƒ…å†µï¼ è¿™ä¸ªæƒ³äº†åŠå¤©ä¸ä¼šåšï¼ŒæŸ¥äº†ä¸€ä¸‹ç”¨çš„æ˜¯Boyer-Moore Majority Vote algorithm è¿™ä¸ªç®—æ³•çš„ä¸»è¦æ„æ€æ˜¯å¦‚æžœä¸¤æ‹¨äººæ‰“æž¶ï¼Œæ‰“æž¶ä¸€å¯¹ä¸€æŠµæ¶ˆï¼Œç„¶åŽçœ‹çœ‹å‰©ä¸‹çš„éƒ¨åˆ†å“ªä¸ªæ¯”è¾ƒå¤š è®°å½•å‰©ä¸‹çš„ä¸œè¥¿çš„æ–¹æ³•å°±æ˜¯å¢žåŠ äº†ä¸€ä¸ªé¢å¤–çš„éƒ¨åˆ†ï¼ŒåŒ…æ‹¬majorå’Œcountä¸¤éƒ¨åˆ†ï¼Œmajorè®°å½•çš„æ˜¯æœ‰å‰©ä½™çš„æ•°æ˜¯ä»€ä¹ˆï¼Œcountè®°å½•è¿˜æœ‰å¤šå°‘ä¸ª å¦‚æžœcountæ²¡æœ‰äº†ï¼Œé‚£ä¹ˆå°±ä»ŽçŽ°åœ¨é‡åˆ°çš„æ–°çš„æ•°å¼€å§‹è®° å¦‚æžœçŽ°åœ¨çš„æ•°ä¸æ˜¯éœ€è¦çš„ï¼Œé‚£ä¹ˆcount - 1ï¼Œå¦‚æžœæ˜¯çŽ°åœ¨éœ€è¦çš„é‚£ä¹ˆcount + 1 æœ€å¼€å§‹æ˜¯ç”¨åœ¨ä¸€ä¸ªæ•°ç»„é‡Œé¢æ‰¾è¶…è¿‡ä¸€åŠçš„æ•°çš„ï¼Œä½†æ˜¯æˆ‘ä¸Šä¸€é“é¢˜ç”¨äº†å…¶ä»–æ–¹æ³•æ‰€ä»¥æ²¡ç”¨åˆ° æ³¨æ„å› ä¸ºæ˜¯æ±‚1/3çš„æ•°å­—ï¼Œæ‰€ä»¥è™½ç„¶æœ‰å‰©ä¸‹çš„ï¼Œä½†æ˜¯å‰©ä¸‹çš„ä¸ä¸€å®šéƒ½æ˜¯ç¬¦åˆè¦æ±‚çš„ï¼Œéœ€è¦å†æ•°ä¸€ä¸‹ä¸ªæ•°å¯¹ä¸å¯¹ï¼ˆè¿™æ‰æœ‰äº†returnè¿™ä¸€è¡Œé‡Œé¢çš„ä¸œè¥¿ï¼‰ äººç±»çš„ç®—æ³•çœŸæ˜¯å¥‡å¹»æ— ç©· 274 h-indexGiven an array of citations (each citation is a non-negative integer) of a researcher, write a function to compute the researcherâ€™s h-index. According to the definition of h-index on Wikipedia: â€œA scientist has index h if h of his/her N papers have at least h citations each, and the other N âˆ’ h papers have no more than h citations each.â€ Example: Input: citations = [3,0,6,1,5]Output: 3Explanation: [3,0,6,1,5] means the researcher has 5 papers in total and each of them had received 3, 0, 6, 1, 5 citations respectively. Since the researcher has 3 papers with at least 3 citations each and the remaining two with no more than 3 citations each, her h-index is 3.Note: If there are several possible values for h, the maximum one is taken as the h-index. 1234567891011class Solution: def hIndex(self, citations: List[int]) -&gt; int: result = 0 for h_cand in range(len(citations) + 1): h_more = 0 for citation in citations: if citation &gt;= h_cand: h_more += 1 if h_more &gt;= h_cand: result = max(result,h_cand) return result æ€è·¯ï¼Œéžå¸¸ç›´è§‚çš„æ–¹æ³•ï¼Œç›´æŽ¥iterateæ‰€æœ‰çš„å…ƒç´ ï¼Œå¦‚æžœæ‰¾åˆ°äº†æ›´å¤§çš„resultçš„å€¼å°±å–æœ€å¤§çš„ï¼ˆæ ¹æ®é¢˜ç›®è¦æ±‚ï¼‰ æ³¨æ„çš„ç‚¹åœ¨éœ€è¦ h_more &gt;= h_candè€Œä¸æ˜¯ç­‰äºŽï¼Œå› ä¸ºç»™å‡ºçš„å®šä¹‰çš„æ„æ€æ˜¯index-hæ˜¯æœ‰hä¸ªçš„å€¼å¤§äºŽç­‰äºŽhï¼Œh_moreçš„ä¸ªæ•°ä¼šæ¯”h_candå¤šï¼ˆä½†æ˜¯å› ä¸ºå–äº†ä¸‹é¢çš„maxï¼Œæ‰€ä»¥ç­‰äºŽå…¶å®žä¹Ÿæ˜¯å¯ä»¥å¾—ï¼‰ è¿™ä¸ªçš„é€Ÿåº¦çœŸçš„å¥½æ…¢ï¼Œå°è¯•ä¸€ä¸‹binary search 1234567891011121314151617class Solution: def hIndex(self, citations: List[int]) -&gt; int: bucket = [0 for n in range(len(citations)+1)] for nums in citations: if nums &gt;= len(citations): bucket[len(citations)] += 1 else: bucket[nums] += 1 result = 0 for nums in range(len(bucket)): nums = len(bucket) - nums -1 result += bucket[nums] if result &gt;= nums: return nums return 0 ç”¨äº†æ¡¶æŽ’åºçš„ç¥žå¥‡æ–¹æ³• è¿˜æ˜¯å–å†³äºŽå®šä¹‰ï¼Œå¦‚æžœä¸€å…±æœ‰5ä¸ªpaperçš„è¯ï¼Œå¯ä»¥é€‰çš„hçš„å€¼æœ‰6ä¸ªï¼Œåˆ†åˆ«æ˜¯0 1 2 3 4 5ï¼ŒæŠŠè¿™ç•™ä¸ªå€¼åˆ†æˆå…­ä¸ªæ¡¶ï¼Œæ¯ä¸ªé‡Œé¢æ”¾çš„å°±æ˜¯æ¯”è¿™æ¡¶çš„indeç­‰äºŽçš„paperçš„æ•°é‡ å¦‚æžœæ€»æ•°ç›´æŽ¥å¤§äºŽæœ€å¤§çš„æ¡¶æ•°ï¼Œå°±æ”¾åœ¨æœ€åŽä¸€ä¸ªé‡Œé¢ è¿™æ˜¯åœ¨ç¬¬ä¸€ä¸ªå¾ªçŽ¯å¹²çš„äº‹æƒ… ç¬¬äºŒä¸ªå¾ªçŽ¯é‡Œï¼ŒæŠŠè¿™äº›æ¡¶é‡Œé¢çš„å€¼å–å‡ºæ¥å°±æ˜¯æ¯”è¿™ä¸ªæ¡¶çš„indexå¤§äºŽç­‰äºŽçš„paperçš„æ•°é‡ï¼Œä»ŽåŽå¾€å‰æ•°ï¼Œå¦‚æžœè¿™ä¸ªpaperçš„æ•°é‡å¤§äºŽäº†çŽ°åœ¨çš„indexï¼Œé‚£å°±è¯´æ˜ŽçŽ°åœ¨çš„indexå°±æ˜¯hï¼ è¿™é‡Œå­¦åˆ°äº†ä¸€ä¸ªåˆ›å»ºå›ºå®šé•¿åº¦åˆ—è¡¨çš„æ–¹æ³•bucket = [0 for n in range(len(citations)+1)] 12345678class Solution: def hIndex(self, citations: List[int]) -&gt; int: citations.sort(reverse = True) result = 0 for i,n in enumerate(citations): if n &gt;= i+1: result = max(result,i+1) return result å†å¦ä¸€ç§æ€è·¯ï¼Œç”¨äº†æŽ’åº å¦‚æžœæŠŠè¿™ä¸ªlistæŒ‰é™åºæŽ’åºçš„è¯ï¼Œindexçš„æ•°é‡åŠ ä¸€å°±æ˜¯ç›®å‰æ•°è¿‡çš„paperçš„æ•°é‡ï¼Œcitation[index]å°±æ˜¯è¿™ä¸ªæ•°é‡ä¸Šé¢å¯¹åº”çš„citationçš„æ•°é‡ï¼Œè¿™ä¸¤ä¸ªå€¼åº”è¯¥æ­£å¥½ç›¸ç­‰ï¼Œæˆ–è€…citationæ›´å¤§ä¸€ç‚¹ï¼Œéœ€è¦åœ¨æŽ’å¥½åºçš„å†…å®¹é‡Œé¢æ‰¾åˆ°è¿™ä¸€é¡¹ï¼ è¿™æ ·é€Ÿåº¦æ¯”æ¡¶æŽ’åºç¨å¾®æ…¢ä¸€ç‚¹ä½†æ˜¯è¿˜æ˜¯è›®å¿«çš„ï¼Œèµ·ç æ¯”ç¬¬ä¸€ç§è¦å¿«å¾ˆå¤šäº† 275 h-index 21234567891011class Solution: def hIndex(self, citations: List[int]) -&gt; int: n = len(citations) l, r = 0, n-1 while l &lt;= r: mid = (l+r)//2 if citations[mid] &gt;= n-mid: r = mid - 1 else: l = mid + 1 return n-l å¯ä»¥ä¾ç„¶æ²¿ç”¨ä¸Šé¢çš„æ–¹æ³•ï¼Œä½†æ˜¯å¯èƒ½æ˜¯å› ä¸ºæ•°æ®é‡ä¸ŠåŽ»çš„åŽŸå› ï¼Œæ‰€ä»¥é€Ÿåº¦å˜æ…¢äº† è¿™é‡Œå¯ä»¥åŠ å…¥äºŒåˆ†æ³•æœç´¢å–ä»£ä¸Šé¢çš„ç›´æŽ¥iterate whileçš„æ¡ä»¶æ˜¯å› ä¸ºç§»åŠ¨ä¸€ä½ï¼Œæ‰€ä»¥ä¼šå‡ºçŽ°l&gt;rçš„æƒ…å†µï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹å°±å¯ä»¥åœä¸‹æ¥äº† äºŒåˆ†æ³•å°±æ˜¯è¿™ä¹ˆå†™çš„ï¼ 217 contains duplicate123456class Solution: def containsDuplicate(self, nums: List[int]) -&gt; bool: for n in nums: if nums.count(n) &gt;= 2: return True return False 1234567class Solution: def containsDuplicate(self, nums: List[int]) -&gt; bool: setNums = set(nums) if len(setNums) == len(nums): return False else: return True æ¶ˆè€—æ—¶é—´å¤ªé•¿äº†ï¼ï¼ è¯´æ˜Žè¿™ä¸ªcountçš„æ—¶é—´è¿˜æ˜¯ä¸å¯ä»¥ æƒ³åˆ°äº†ç”¨setä½†æ˜¯æ²¡ç›¸å½“æ€Žä¹ˆç”¨set setå¯ä»¥æŠŠæœ‰é‡å¤å†…å®¹çš„å˜æˆæ²¡æœ‰é‡å¤å†…å®¹çš„ï¼ï¼ æ‰€ä»¥setå’Œlistçš„é•¿åº¦æ˜¯ä¸ä¸€æ ·çš„ 219 contains duplicate2Given an array of integers and an integer k, find out whether there are two distinct indices i and j in the array such that nums[i] = nums[j] and the absolute difference between i and j is at most k. Example 1: Input: nums = [1,2,3,1], k = 3Output: trueExample 2: Input: nums = [1,0,1,1], k = 1Output: trueExample 3: Input: nums = [1,2,3,1,2,3], k = 2Output: false 1234567891011class Solution: def containsNearbyDuplicate(self, nums: List[int], k: int) -&gt; bool: if len(set(nums)) &gt;= len(nums): return False extra = &#123;&#125; for i,n in enumerate(nums): if n in extra and i-extra[n] &lt;= k: return True extra[n] = i return False æ³¨æ„è¿™é‡Œéœ€è¦æ‰¾åˆ°çš„å·®çš„ç»å¯¹å€¼æ˜¯æœ€å¤§æ˜¯kï¼Œæ‰€ä»¥æ‰¾åˆ°ä¸€ä¸ªæ¯”kå°çš„å¾ˆå®¹æ˜“ï¼ï¼åªè¦æ‰¾åˆ°å°±èƒ½è¿”å›ž åˆ¤æ–­è¾¹ç•Œæ¡ä»¶ æŠŠå…ƒç´ ä½œä¸ºkeyæ”¾è¿›extraé‡Œé¢ï¼Œvalæ˜¯è¿™ä¸ªå…ƒç´ çš„indexï¼Œå› ä¸ºkeyæ˜¯å”¯ä¸€çš„æ‰€ä»¥å¯ä»¥ä¸€ç›´æ‰¾åˆ°ç¦»å¾—æœ€è¿‘çš„indexï¼Œè¿™æ ·å°±è¶Šæ¥è¶Šèƒ½ç¡®ä¿æ»¡è¶³æ¡ä»¶ï¼Œä¸€æ—¦æ»¡è¶³æ¡ä»¶å°±è¿”å›žï¼Œå¦‚æžœæ‰€æœ‰çš„éƒ½ä¸æ»¡è¶³å°±false 220Given an array of integers, find out whether there are two distinct indices i and j in the array such that the absolute difference between nums[i] and nums[j] is at most t and the absolute difference between i and j is at most k. Example 1: Input: nums = [1,2,3,1], k = 3, t = 0Output: trueExample 2: Input: nums = [1,0,1,1], k = 1, t = 2Output: trueExample 3: Input: nums = [1,5,9,1,5,9], k = 2, t = 3Output: false 1234567891011121314151617class Solution: def containsNearbyAlmostDuplicate(self, nums: List[int], k: int, t: int) -&gt; bool: if t &lt; 0: return False buckets = &#123;&#125; for i in range(len(nums)): bucket = nums[i] // (t+1) if bucket in buckets: return True elif bucket - 1 in buckets and nums[i] - buckets[bucket-1] &lt;= t: return True elif bucket + 1 in buckets and buckets[bucket+1] - nums[i] &lt;=t: return True buckets[bucket] = nums[i] if i &gt;= k: del bucket[nums[i-k] // (t+1)] return False è¿ç”¨çš„æ˜¯æ¡¶æŽ’åºçš„æ€è·¯ï¼Œæ¯ä¸ªnums[i]ä¼šæ”¾åœ¨ä¸€ä¸ªæ¡¶é‡Œï¼Œè¿™ä¸ªæ¡¶çš„å®½åº¦æ˜¯è¿™ä¸¤ä¸ªæ•°å­—çš„å·® å¦‚æžœæƒ³è¦è¿™ä¸¤ä¸ªæ•°å€¼çš„å·®å€¼å°äºŽç­‰äºŽtï¼Œé‚£ä¹ˆéœ€è¦è¿™ä¸¤ä¸ªæ•°å­—åœ¨ä¸€ä¸ªæ¡¶é‡Œæˆ–è€…åœ¨ç›¸é‚»çš„æ¡¶é‡Œï¼ˆå› ä¸ºåŽé¢å¢žåŠ äº†kçš„åˆ¤æ–­æ¡ä»¶ï¼Œæ‰€ä»¥ä¸ç”¨è€ƒè™‘kï¼‰ æ€è·¯ é¦–å…ˆè€ƒè™‘äº†ä¸€ä¸‹kï¼Œå¦‚æžœiå¤§äºŽkçš„æ—¶å€™ï¼Œå°±å¯ä»¥ç›´æŽ¥æ‰”æŽ‰i-kä¹‹å‰çš„æ•°æ®äº†ï¼Œåªè€ƒè™‘ä¸­é—´çš„k+1ä¸ªæ•°æ®ï¼Œè¿™æ ·çš„è¯ç©ºé—´å¤æ‚åº¦å¾ˆä½Žã€‚è¿™é‡Œçš„æ‰”æŽ‰æŒ‡çš„æ˜¯æŠŠbucketé‡Œé¢çš„å€¼ç›´æŽ¥æ‰”æŽ‰ï¼Œè¿™æ ·å°±é¿å…äº†æ‰¾åˆ°åœ¨ç›¸åŒçš„æ¡¶é‡Œé¢å´iå’Œjçš„å·®å€¼è¶…è¿‡kçš„é—®é¢˜ é¦–å…ˆiterateæ•´ä¸ªnumsï¼ŒæŠŠä¸åŒçš„æ•°å­—æ”¾åœ¨ä¸åŒçš„æ¡¶é‡Œï¼Œæ³¨æ„æ¡¶çš„ä¸ªæ•°æ˜¯t+1 ç„¶åŽå¦‚æžœåœ¨æ”¾ä¹‹å‰è¿™ä¸ªæ¡¶æœ‰ä¸œè¥¿ï¼Œæˆ–è€…ç›¸é‚»çš„æ¡¶çš„å€¼å’ŒçŽ°åœ¨çš„å€¼çš„å·®æ˜¯å°äºŽç­‰äºŽtçš„ï¼Œé‚£ä¹ˆå°±å­˜åœ¨ï¼Œè¿”å›žtrue å¦‚æžœéƒ½ä¸å­˜åœ¨çš„è¯ï¼ŒæŠŠçŽ°åœ¨çš„æ•°å­—æ”¾åˆ°å¯¹åº”çš„æ¡¶é‡Œé¢ å¦å¤–ä¸€ä¸ªæ€è·¯è€ƒè™‘çš„æ˜¯äºŒå‰æ ‘çš„æ•°æ®ç»“æž„ï¼Œç”¨è¿™ä¸ªç»“æž„å¯ä»¥å¾ˆå¿«çš„æœç´¢åˆ°ç¦»è¿™ä¸ªæ•°æœ€è¿‘çš„æ•°æ®å¹¶ä¸”åˆ¤æ–­è¿™ä¸ªæ•°æ®å’Œè¿™ä¸ªæ•°çš„å·®æ˜¯ä¸æ˜¯å°äºŽtï¼ 55 Jump game123456789101112131415class Solution: def canJump(self, nums: List[int]) -&gt; bool: if nums is []: return False if len(nums) == 1: return True current = len(nums) - 1 while current &gt;= 0: flag = False for i in range(0,current): if current - i &lt;= nums[i] and current &gt;= i: flag = True current = i if current == 0: return True if flag == False: return False è™½ç„¶è¶…æ—¶äº†ä½†æ˜¯å†™çš„è¿˜ä¸é”™çš„iterate =ã€‚=ç®—äº†è¿™å°±æ˜¯ä¸€å¨å±Žï¼ï¼ï¼ 123456789class Solution: def canJump(self, nums: List[int]) -&gt; bool: current = len(nums) - 1 for i in range(len(nums))[::-1]: if current - i &lt;= nums[i]: current = i if current == 0: return True return False æˆ‘çš„æ–¹æ³•å…¶å®žæ€è·¯æ˜¯æ²¡æœ‰é—®é¢˜çš„ï¼Œä¸»è¦åœ¨äºŽå¤ªå•°å—¦äº†è€Œä¸”å¾ªçŽ¯å¤ªå¤šäº†ï¼Œå…¶å®žç›´æŽ¥ä»ŽåŽå¾€å‰æ‰¾å°±è¡Œäº†ï¼ï¼ï¼ä»ŽåŽå¾€å‰æ‰¾ä¸ç”¨è€ƒè™‘æ€Žä¹ˆè®©ä»–å¾ªçŽ¯èµ·æ¥å‘€ï¼Œç›´æŽ¥ä¸€ä¸ªä¸€ä¸ªå¾€å‰æŽ¨å°±å¯ä»¥äº† å‰é¢é‚£ä¸ªçš„é—®é¢˜åœ¨äºŽå¤šå äº†ä¸€ä¸ªwhileï¼ŒäºŽæ˜¯æ—¶é—´çž¬é—´çˆ†ç‚¸ï¼Œå†™å‰é¢çš„é‚£ä¸ªçš„æ—¶å€™ä¹Ÿåœ¨æƒ³ç€å¦‚ä½•æ‰¾å›žå¾ªçŽ¯é‡Œé¢åŽ»ï¼Œç»“æžœè¿˜æ˜¯ç”¨äº†ä¸ªè ¢åŠžæ³• 1234567class Solution: def canJump(self, nums: List[int]) -&gt; bool: j = 0 for i,n in enumerate(nums): if j &lt; i: return False j = max(i+n,j) return True i+nå°±æ˜¯ä»Žè¿™æ­¥å¼€å§‹å¯ä»¥ç§»åŠ¨çš„æœ€å¤§è·ç¦»ï¼Œjæ˜¯ä¸Šä¸€æ­¥å¯ä»¥ç§»åŠ¨çš„æœ€å¤§è·ç¦»ï¼Œè¿™ä¸¤ä¸ªå“ªä¸ªå¤§å°±èµ°å“ªä¸ª å¦‚æžœè¿™ä¸ªè·ç¦»è¿˜èµ¶ä¸ä¸Šiï¼Œé‚£å°±è¯´æ˜Žèµ°ä¸åˆ°æœ€åŽäº†ï¼Œå‘Šè¾ž 45 Jump game 2123456789101112class Solution: def jump(self, nums: List[int]) -&gt; int: if len(nums) &lt;= 1: return 0 start, end = 0, 0 step,maxend = 0,0 while True: step += 1 for i in range(start, end+1): if i+nums[i] &gt;= len(nums) -1: return step maxend = max(maxend, i + nums[i]) start = end + 1 end = maxend å®žé™…ä¸Šæ¥è¯´ç”¨çš„æ˜¯BFSçš„æ€æƒ³ï¼Œä½†æ˜¯ä¸æ˜¯æ¯æ¬¡éƒ½æŠŠä¸œè¥¿ä»Žqueueé‡Œé¢æ‹¿å‡ºæ¥ï¼Œè€Œæ˜¯ç¡®å®šäº†æ¯æ¬¡å¯»æ‰¾çš„å¼€å§‹çš„é˜€å†… startå’Œendåˆ†åˆ«ä»£è¡¨çŽ°åœ¨å¯ä»¥å¼€å§‹å¯»æ‰¾çš„å¼€å§‹å’Œç»“æŸï¼Œå¦‚æžœåœ¨è¿™ä¸ªèŒƒå›´é‡Œé¢æ‰¾åˆ°äº†ç¬¦åˆè¦æ±‚çš„ç»“æžœï¼Œé‚£ä¹ˆç›´æŽ¥è¿”å›žè¿™ä¸ªæ­¥æ•°ï¼Œå¦‚æžœæ²¡æ‰¾åˆ°çš„è¯å°±ä»Žä¸‹ä¸€ä¸ªèŒƒå›´å¼€å§‹æ‰¾ï¼Œä¸‹ä¸€ä¸ªèŒƒå›´æ˜¯ä¸Šä¸€ä¸ªèŒƒå›´çš„end+1 åˆ°ç›®å‰èƒ½åˆ°çš„æœ€å¤§çš„èŒƒå›´ æ³¨æ„ç¬¦åˆçš„è¦æ±‚æ˜¯å¤§äºŽç­‰äºŽn-1è€Œä¸æ˜¯æ­£å¥½èµ°åˆ°è¿™ä¸ªç‚¹ æ±‚maxendå’Œä¹‹å‰çš„ä¸€æ · 121 Best Time to Buy and Sell StockSay you have an array for which the ith element is the price of a given stock on day i. If you were only permitted to complete at most one transaction (i.e., buy one and sell one share of the stock), design an algorithm to find the maximum profit. Note that you cannot sell a stock before you buy one. Example 1: Input: [7,1,5,3,6,4]Output: 5Explanation: Buy on day 2 (price = 1) and sell on day 5 (price = 6), profit = 6-1 = 5. Not 7-1 = 6, as selling price needs to be larger than buying price.Example 2: Input: [7,6,4,3,1]Output: 0Explanation: In this case, no transaction is done, i.e. max profit = 0. 12345678910class Solution: def maxProfit(self, prices: List[int]) -&gt; int: minBuy = float('inf') maxProfit = 0 for i in prices: if i &lt; minBuy: minBuy = i elif i - minBuy &gt; maxProfit: maxProfit = i - minBuy return maxProfit ç”¨bruteçš„ç®—æ³•ä¼štime limitï¼Œè¿™é‡Œç”¨çš„æ–¹æ³•æ˜¯ç”¨ä¸¤ä¸ªå˜é‡åˆ†åˆ«è®°å½•æœ€ä½Žçš„ä»·é’±å’Œæœ€é«˜çš„åˆ©æ¶¦ï¼Œè¿™æ ·çš„è¯åªéœ€è¦å¯¹æ•°ç»„éåŽ†ä¸€æ¬¡å°±èƒ½å¾—åˆ°æœ€ç»ˆçš„ç»“æžœ å› ä¸ºåˆ¤æ–­è¿™ä¸ªä»·é’±ä½Žäº†çš„è¯ï¼Œæ±‚è¿™ä¸ªä¸œè¥¿çš„æœ€å¤§åˆ©æ¶¦ä¹Ÿå°±åªèƒ½ç”¨è¿™ä¸ªæœ€ä½Žä»·é’±ä¹‹åŽçš„ä¸œè¥¿æ±‚äº†ï¼Œæ‰€ä»¥ä¸ä¼šå†²çª 122 çŽ°åœ¨å¯ä»¥è¿›è¡Œå¤šæ¬¡äº¤æ˜“äº†ï¼Œä½†æ˜¯æ¯æ¬¡ä¹‹é—´ä¸èƒ½é‡å  å…¶å®žåªè¦åŽä¸€æ¬¡æ¯”å‰ä¸€æ¬¡è´µï¼Œè¿™ä¸ªprofitå°±å¯ä»¥ä¸€ç›´ç´¯è®¡ï¼Œåˆ†ä¸ºä¸€ç›´ä¸Šæ¶¨æˆ–è€…ä¸­é—´æŽ‰ä¸‹æ¥ä¸€ä¸‹å†é‡æ–°ä¹°çš„æ„Ÿè§‰ 1234567class Solution: def maxProfit(self, prices: List[int]) -&gt; int: maxProfit = 0 for i in range(1,len(prices)): if prices[i] &gt; prices[i-1]: maxProfit += prices[i] - prices[i-1] return maxProfit 123 çŽ°åœ¨æœ€å¤šè¿›è¡Œä¸¤æ¬¡äº¤æ˜“,æ‰¾åˆ°æœ€å¤§çš„åˆ©æ¶¦ 1234567891011121314class Solution: def maxProfit(self, prices: List[int]) -&gt; int: cost_1 = float('inf') profit_1 = 0 cost_2 = float('inf') profit_2 = 0 for price in prices: cost_1 = min(cost_1,price) profit_1 = max(profit_1, price - cost_1) cost_2 = min(cost_2,price - profit_1) profit_2 = max(profit_2, price - cost_2) return profit_2 å…¶ä¸­ï¼Œä¸‹æ ‡å¸¦1çš„æ˜¯ç¬¬ä¸€æ¬¡äº¤æ˜“ä¹‹åŽçš„ç»“æžœï¼Œä¸‹æ ‡å¸¦2çš„æ˜¯ç¬¬äºŒæ¬¡äº¤æ˜“ä¹‹åŽçš„ç»“æžœ ä»Žæ€»ä½“ä¸Šæ¥çœ‹ï¼Œç¬¬äºŒæ¬¡ä¹°å…¥ä¹‹åŽèŠ±æŽ‰çš„é’±å®žé™…ä¸Šæ˜¯ç¬¬äºŒæ¬¡ä¹°å…¥çš„å®žé™…èŠ±è´¹ - ç¬¬ä¸€æ¬¡äº¤æ˜“ä¹‹åŽæŒ£çš„é’±ï¼ˆå¯ä»¥æ˜¯è´Ÿæ•°ï¼‰ã€‚è€Œç¬¬äºŒæ¬¡å–å‡ºä¹‹åŽçš„æ€»çš„æ”¶ç›Šä¸º ç¬¬äºŒæ¬¡å–å‡ºçš„é’± - ç¬¬äºŒæ¬¡ä¹°å…¥ä¹‹åŽçš„å®žé™…èŠ±è´¹ æ‰€ä»¥ï¼Œå¦‚æžœéœ€è¦åˆ©æ¶¦æœ€å¤§ï¼Œéœ€è¦ç¬¬äºŒæ¬¡ä¹°å…¥çš„å®žé™…èŠ±è´¹æœ€å°ï¼Œéœ€è¦ç¬¬ä¸€æ¬¡çš„åˆ©æ¶¦æœ€å¤§ï¼Œéœ€è¦ç¬¬ä¸€æ¬¡ä¹°å…¥çš„èŠ±è´¹æœ€å°ï¼Œæœ€ç»ˆå½¢æˆäº†è¿™ä¸ªä»£ç  188 çŽ°åœ¨éœ€è¦è¿›è¡Œæœ€å¤škæ¬¡äº¤æ˜“ï¼ŒæŠŠprofitå¼„åˆ°æœ€å¤§ è¿™éƒ¨åˆ†å¥½åƒå¤§å®¶éƒ½ç”¨åˆ°äº†DP 1234567891011121314class Solution: def maxProfit(self, k: int, prices: List[int]) -&gt; int: n = len(prices) if n &lt; 2: return 0 if k &gt;= n/2: return sum(i-j for i, j in zip(prices[1:],prices[: -1]) if i &gt; j) profits = [0] * n for _ in range(k): preprofit = 0 for i in range(1,n): profit = prices[i] - prices[i-1] preprofit = max(preprofit + profit, profits[i]) profits[i] = max(preprofit, profits[i-1]) return profits[-1] é¦–å…ˆè€ƒè™‘è¾¹ç•Œæ¡ä»¶ï¼Œå¦‚æžœkçš„æ•°é‡å·²ç»æ¯”n/2å¤§äº†ï¼Œé‚£ä¹ˆå¯ä»¥ç›´æŽ¥è®¤ä¸ºå¯ä»¥è¿›è¡Œæ— é™æ¬¡äº¤æ˜“äº†ï¼Œå°±å’Œä¸Šé¢çš„ç¬¬äºŒé¢˜ä¸€æ · ä¸»è¦æ€è·¯å°±æ˜¯çŽ°åœ¨å®šä¹‰äº†ä¸¤ä¸ªå˜é‡ï¼Œä¸€ä¸ªå˜é‡è¡¨ç¤ºåœ¨å‰iå¤©å®Œæˆçš„äº¤æ˜“ï¼Œå·²ç»å¾—åˆ°çš„æœ€å¤§åˆ©æ¶¦ã€‚å¦ä¸€ä¸ªå˜é‡å®šä¹‰äº†åœ¨ç¬¬iå¤©å–å‡ºçš„è¯ï¼Œè¿™æ—¶å€™å¾—åˆ°çš„æœ€å¤§åˆ©æ¶¦ã€‚è¿™ä¸¤ä¸ªå˜é‡çš„éƒ½æ˜¯åœ¨åœ¨ç¬¬jæ¬¡äº¤æ˜“é‡Œã€‚ ç”¨ä¸€ä¸ªé•¿nçš„list profitsæ¥è®°å½•è¿™ä¸ªå¤©æ•°ä¹‹åŽèŽ·å¾—çš„åˆ©ç›Šã€‚åœ¨kæ¬¡äº¤æ˜“ä¸­ä¸€ç›´æ›´æ–°è¿™ä¸ªprofitsé‡Œé¢çš„æœ€å¤§å€¼ã€‚æ‰€ä»¥å®žé™…ä¸Šå…³äºŽkçš„å˜é‡ä¸éœ€è¦è€ƒè™‘ é¦–å…ˆåˆ†æžåœ¨ç¬¬iå¤©å¾—åˆ°çš„åˆ©æ¶¦ï¼Œå°±æ˜¯è¿™ä¸€å¤©çš„ä»·æ ¼å‡åŽ»å‰ä¸€å¤©çš„ä»·æ ¼ã€‚æ›´æ–°ä¹‹å‰iå¤©é‡Œé¢çš„æ€»åˆ©æ¶¦ï¼Œå°±æ˜¯æŠŠæœ€å¼€å§‹çš„preprfitå†åŠ ä¸Šè¿™ä¸€å¤©èŽ·å¾—çš„åˆ©æ¶¦ï¼Œå’Œæœ¬æ¥çš„preprofitæ¥æ¯”å¤§å°ï¼Œæ›´æ–°preprofit æ›´æ–°å®žé™…ä¸Šç¬¬iå¤©çš„åˆ©æ¶¦ï¼Œå¯¹æ¯”å®žé™…ä¸Šå‰ä¸€å¤©çš„åˆ©æ¶¦å’Œå‰iå¤©çš„åˆ©æ¶¦å“ªä¸ªå¤§ 309 ä¸­é—´å¸¦å†·å´çš„ä¹°è‚¡ç¥¨ æ¯æ¬¡å–å‡ºåŽ»ä¹‹åŽå¿…é¡»è¦cooldownä¸€è½® ç”¨äº†dpå’Œstate machineæ¥è¡¨ç¤ºï¼Œä¸€å…±ä¼šæœ‰ä¸‰ç§çŠ¶æ€ s0(reset) -sell-&gt; s1 -cool-&gt; s2(reset) -buy-&gt; s0 ç”¨ä¸€ä¸ªæ•°ç»„æ¥è®°å½•åœ¨æ¯å¤©åœ¨è¿™ä¸ªçŠ¶æ€é‡Œé¢çš„æœ€å¤§åˆ©æ¶¦ï¼Œç„¶åŽå†ä»Žæœ€åŽä¸€å¤©çš„æœ€å¤§åˆ©æ¶¦é‡Œé¢æŒ‘å‡ºæ¥ä¸€ä¸ª æ³¨æ„è€ƒè™‘è¾¹ç•Œæ¡ä»¶ å­¦ä¼šäº†ä¸€ä¸ªæ–°çš„åˆå§‹åŒ–listçš„æ–¹æ³• æ„Ÿè§‰è‡ªå·±ç»ˆäºŽç†è§£äº†dpå‘¢ï¼ˆå¹¶æ²¡æœ‰ï¼‰12345678910111213141516class Solution: def maxProfit(self, prices: List[int]) -&gt; int: n = len(prices) if n &lt; 2: return 0 s0,s1,s2 = [0]*n,[0]*n,[0]*n s0[0] = -prices[0] s1[0] = float('-inf') s2[0] = 0 for i in range(1,n): price = prices[i] s0[i] = max(s0[i-1],s2[i-1] - price) s1[i] = s0[i-1] + price s2[i] = max(s1[i-1],s2[i-1]) return max(s0[n-1],s1[n-1],s2[n-1]) 11 è£…æ°´Given n non-negative integers a1, a2, â€¦, an , where each represents a point at coordinate (i, ai). n vertical lines are drawn such that the two endpoints of line i is at (i, ai) and (i, 0). Find two lines, which together with x-axis forms a container, such that the container contains the most water. Note: You may not slant the container and n is at least 2. 12345678910111213class Solution: def maxArea(self, height: List[int]) -&gt; int: n = len(height) start, end = 0, n-1 maxArea = 0 while start &lt; end: if height[start] &gt;= height[end]: maxArea = max(maxArea,height[end] * (end-start)) end -= 1 else: maxArea = max(maxArea,height[start] * (end-start)) start += 1 return maxArea è¿™é“é¢˜çš„é‡ç‚¹åœ¨è¿™ä¸ªè£…æ°´çš„å¤§å°æ˜¯ç”±æ¯”è¾ƒçŸ­çš„é‚£æ¡è¾¹å†³å®šçš„ã€‚è€Œä¸”è‚¯å®šæ˜¯åº•è¾¹è¶Šé•¿è¶Šç‰›é€¼ï¼Œæ‰€ä»¥ä»Žåº•è¾¹æœ€é•¿çš„ä¸¤è¾¹å¼€å§‹æ‰¾ï¼Œç„¶åŽåœ¨ä¸¤ä¸ªé«˜åº¦é‡Œé¢å–æ¯”è¾ƒå¤§çš„ç»§ç»­æ‰¾ä¸‹ä¸€ä¸ª éœ€è¦ç”¨ä¸€ä¸ªå˜é‡æ¥å‚¨å­˜ max areaçš„å¤§å°ï¼ˆè¿™ä¸ªæˆ‘æƒ³åˆ°äº†ï¼‰ ç„¶åŽæ¯”è¾ƒå¿«çš„æ–¹æ³•æ˜¯ä»Žä¸¤éå¼€å§‹é€¼è¿‘ï¼Œè¿™æ ·çš„è¯åªéåŽ†äº†è¿™ä¸ªlistä¸€æ¬¡ï¼Œæ—¶é—´å¤æ‚åº¦æ˜¯nï¼Œå¥½åƒæœ‰ä¸ªæŽ’åºç®—æ³•å’Œè¿™ä¸ªçš„æƒ³æ³•ä¹Ÿå·®ä¸å¤š æ³¨æ„whileçš„åˆ¤æ–­æ¡ä»¶å…¶å®žå°±æ˜¯è¿™ä¸ª 42 è£…æ°´Given n non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it is able to trap after raining. 12345678910111213141516class Solution: def trap(self, height: List[int]) -&gt; int: n = len(height) if n &lt; 2: return 0 left_max,right_max = [0]*n,[0]*n left_max[0],right_max[-1] = height[0],height[-1] maxTrap = 0 for i in range(1,n): left_max[i] = max(left_max[i-1],height[i]) for i in reversed(range(0,n-1)): right_max[i] = max(right_max[i+1],height[i]) for i in range(n): maxTrap += min(left_max[i],right_max[i]) - height[i] return maxTrap ç”¨dpè§£å†³çš„è¿™ä¸ªé—®é¢˜ æ ¸å¿ƒæ€æƒ³åœ¨ç«–ç€ï¼ˆæŒ‰åˆ—ï¼‰æ•°æ¯ä¸ªæ ¼å­ï¼Œè¿™ä¸ªæ ¼å­å¯ä¸å¯ä»¥è£…æ°´å’Œå·¦å³ä¸¤è¾¹çš„æœ€é«˜ç‚¹æœ‰å…³ï¼Œè¿™ä¸ªæ ¼å­èƒ½è£…å¤šå°‘æ°´å’Œ1.æœ€çŸ­çš„é«˜ç‚¹å’Œ2.è¿™ä¸ªæ ¼å­æœ¬èº«çš„é«˜åº¦æœ‰å…³ æ‰€ä»¥å¯ä»¥ç”¨ä¸‰ä¸ªå¾ªçŽ¯æžå®šè¿™ä¸ªé—®é¢˜ï¼Œç”¨ç©ºé—´æ¢æ—¶é—´ï¼Œåœ¨listé‡Œé¢è®°å½•ä¸‹æ¥æ¯ä¸ªåˆ—å¯¹åº”çš„å·¦è¾¹çš„æœ€é«˜ç‚¹å’Œå³è¾¹çš„æœ€é«˜ç‚¹ï¼Œç„¶åŽå†æ•°æ¯ä¸ªåˆ—çš„å®¹é‡ï¼Œå¤§å°æ˜¯ï¼ˆå·¦å³æœ€é«˜ä¸­é—´çŸ­çš„é‚£ä¸ªï¼‰ - ï¼ˆè¿™ä¸ªåˆ—å¯¹åº”çš„é«˜åº¦ï¼‰ 334 å‡åºçš„ä¸‰ä¸ªæ•°å­—Given an unsorted array return whether an increasing subsequence of length 3 exists or not in the array. Formally the function should: Return true if there exists i, j, ksuch that arr[i] &lt; arr[j] &lt; arr[k] given 0 â‰¤ i &lt; j &lt; k â‰¤ n-1 else return false.Note: Your algorithm should run in O(n) time complexity and O(1) space complexity. 123456789101112131415class Solution: def increasingTriplet(self, nums: List[int]) -&gt; bool: if len(nums) &lt; 3: return False first = float('inf') second = float('inf') third = None for i,num in enumerate(nums): if num &lt;= first: first = num elif num &gt; first and num &lt;= second: second = num else: third = num return (third != None) æˆ‘æœ€åˆçš„æ€è·¯æ²¡æœ‰é”™ï¼Œéœ€è¦æœ‰å˜é‡æ¥ä¿å­˜è¿™ä¸‰ä¸ªå‡åºçš„ä¸œè¥¿ å…¶å®žæ ¸å¿ƒçš„æ€è·¯åœ¨äºŽï¼Œå¦‚æžœçŽ°åœ¨è¿™ä¸ªæ•°æ¯”ç¬¬ä¸€ä¸ªå‡åºçš„æ•°å­—å°ï¼Œé‚£ä¹ˆè¿™ä¸ªæ•°å­—å®Œå…¨å°±å¯ä»¥æˆä¸ºæ–°çš„ç¬¬ä¸€ä¸ªæ•°å­—ï¼Œæ¯”å¦‚ 3 2 4 5ï¼Œé‚£ä¹ˆ345å’Œ245æ²¡æœ‰ä»€ä¹ˆæœ¬è´¨çš„åŒºåˆ«ï¼Œè€Œä¸€æ—¦thirdæœ‰äº†å–å€¼ï¼Œé‚£ä¹ˆå°±è¯´æ˜Žè‚¯å®šå·²ç»æœ‰äº†ä¸€ä¸ªç»“æžœ 128Given an unsorted array of integers, find the length of the longest consecutive elements sequence. Your algorithm should run in O(n) complexity. Example: Input: [100, 4, 200, 1, 3, 2]Output: 4Explanation: The longest consecutive elements sequence is [1, 2, 3, 4]. Therefore its length is 4. 123456789101112131415161718192021222324252627282930313233343536class Solution: def longestConsecutive(self, nums: List[int]) -&gt; int:# if nums == []: return 0# max_num = max(nums)# min_num = min(nums)# if max_num &gt; len(nums) or -max# if min_num &lt; 0:# max_num -= min_num# ass_list = [None] * (max_num + 1)# for i,num in enumerate(nums):# # ç¡®ä¿éƒ½æ˜¯æ­£æ•°# if min_num &lt; 0:# num = num-min_num# ass_list[num] = 1 # max_length = 0# prev_length = 0# for i in range(len(ass_list)):# if ass_list[i] != None:# max_length += 1# else:# prev_length = max(max_length,prev_length)# max_length = 0# return max(max_length,prev_length) if nums == []: return 0 current_length,prev_length = 1,1 num_set = set(nums) for num in num_set: if num - 1 not in num_set: current_num = num while current_num+1 in num_set: current_num += 1 current_length += 1 prev_length = max(prev_length,current_length) current_length = 1 return max(current_length, prev_length) è¿™ä¸ªé—®é¢˜ä¸€å¼€å§‹çš„æ€è·¯æ˜¯é”™çš„ï¼Œå·²ç»commentæŽ‰äº†ï¼Œä½†æ˜¯æ„Ÿè§‰è¿™ä¸ªæƒ³æ³•å…¶å®žå°±æ˜¯æ›´å…·ä½“åŒ–çš„hashè¡¨è€Œå·²ï¼Œç¬¬ä¸€ä¸ªæ€è·¯æ˜¯æŠŠæ‰€æœ‰çš„æ•°å­—å¹³å‡çš„æ”¾åœ¨ä¸€ä¸ªlisté‡Œé¢ï¼Œç„¶åŽæ¯ä¸ªæ•°å­—çš„æœ¬èº«å°±å¯¹åº”çš„æ˜¯ä»–çš„indexï¼Œè¿™æ ·çš„è¯å°±å¯ä»¥ç›´æŽ¥çŸ¥é“æœ‰å“ªäº›æ•°å­—æ˜¯è¿žç»­çš„äº†ã€‚ä½†æ˜¯è¿™ç§æ–¹æ³•åœ¨æ•°å­—ç‰¹åˆ«å¤§çš„æ—¶å€™ç©ºé—´ä¸Šå°±çˆ†ç‚¸äº†ï¼Œç©ºé—´å¤æ‚åº¦ä¹Ÿæ˜¯å’Œæ•°å­—å¤§å°æœ‰å…³ è¿™æ—¶å€™åˆè¦æ‹¿å‡ºæ¥å¿«ä¹çš„hashè¡¨äº†ï¼Œè®°ä½pythonè‡ªå·±è‡ªå¸¦hashè¡¨ æ¯é‡åˆ°ä¸€ä¸ªæ•°å­—ï¼Œéœ€è¦åˆ¤æ–­è¿™ä¸ªæ•°å­—çš„ä¸‹ä¸€ä¸ªæ•°å­—åœ¨ä¸åœ¨è¿™ä¸ªnumsé‡Œé¢ï¼Œå¦‚æžœåœ¨çš„è¯æ›´æ–°æ•°å­—å’Œé•¿åº¦ï¼Œå¦‚æžœä¸å†çš„è¯åˆ·æ–°è®¡æ•°å™¨å¹¶ä¸”å¼€å§‹ä¸‹ä¸€ä¸ªæ•°å­— ä½†æ˜¯ç›´æŽ¥è¿™æ ·ç®—è¿˜æ˜¯ä¼šæ—¶é—´çˆ†ç‚¸ï¼ˆæ¯”å¦‚ä¸€å †è¿žç»­çš„åªæœ‰ä¸€ä¸ªæ˜¯è·³å¼€çš„ï¼‰ï¼Œæ‰€ä»¥åˆåŠ è¿›åŽ»äº†ä¸€ä¸ªæ–°çš„åˆ¤æ–­æ¡ä»¶ï¼Œè¿™ä¸ªæ¡ä»¶çš„ç²¾é«“åœ¨äºŽï¼Œå¦‚æžœè¿™ä¸ªæ•°ä¹‹å‰çš„æ•°å­—åœ¨numsé‡Œé¢ï¼Œé‚£ä¹ˆè¿™ä¸ªæ•°åœ¨ç®—ä»–å‰é¢é‚£ä¸ªæ•°çš„æ—¶å€™å°±åº”è¯¥è¢«ç®—ä¸Šäº†ï¼Œæ‰€ä»¥è¿™éƒ¨åˆ†å°±å¯ä»¥è·³è¿‡è¿™ä¸ªæ•°äº†ï¼Œåªæœ‰å½“å‰ä¸€ä¸ªæ•°å­—ä¸åœ¨çš„æ—¶å€™æ‰éœ€è¦æ•°é•¿åº¦ 164Given an unsorted array, find the maximum difference between the successive elements in its sorted form. Return 0 if the array contains less than 2 elements. Example 1: Input: [3,6,9,1]Output: 3Explanation: The sorted form of the array is [1,3,6,9], either (3,6) or (6,9) has the maximum difference 3.Example 2: Input: [10]Output: 0Explanation: The array contains less than 2 elements, therefore return 0.Note: You may assume all elements in the array are non-negative integers and fit in the 32-bit signed integer range.Try to solve it in linear time/space. 123456789101112class Solution: def maximumGap(self, nums: List[int]) -&gt; int: nums.sort() max_gap = 0 if len(nums) &lt; 2: return 0 for i in range(1,len(nums)): gap = nums[i] - nums[i-1] max_gap = max(max_gap, gap) return max_gap ç›´æŽ¥ç”¨pythonè‡ªå¸¦çš„æŽ’åºé€Ÿåº¦ä¸ä¸€å®šå¾ˆæ…¢ï¼Œè™½ç„¶åªè¶…è¿‡äº†ç™¾åˆ†äº†20çš„äººä½†æ˜¯æœ€åŽè¿˜æ˜¯è·‘å‡ºæ¥äº† è¿™ä¸ªæ–¹æ³•éžå¸¸ç›´æŽ¥äº† 12345678910111213141516171819202122232425262728class Solution: def maximumGap(self, nums: List[int]) -&gt; int: n = len(nums) if n &lt; 2: return 0 max_num, min_num = max(nums), min(nums) if max_num == min_num: return 0 wide = max((max_num - min_num) // (n-1),1) num_b = (max_num - min_num) // wide + 1 maxGap = 0 # prev_bucket = float('-inf') max_b = [0]* num_b min_b = [float('inf')]* num_b for i, num in enumerate(nums): idx = (num-min_num) // wide max_b[idx] = max(max_b[idx],num) min_b[idx] = min(min_b[idx],num) prev_max = max_b[0] for i in range(1,num_b): if max_b[i] == 0: continue maxGap = max(maxGap,min_b[i] - prev_max) prev_max = max_b[i] return maxGap è¿™ä¸ªæ¡¶æŽ’åºç»ˆäºŽå†™å‡ºæ¥äº†ï¼ŒåŸºæœ¬æ€è·¯æ˜¯ä¸Šé¢çš„æˆªå›¾ï¼Œéœ€è¦æ³¨æ„çš„æœ‰å‡ ç‚¹ ç¬¬ä¸€ï¼Œpythonä¸å¯¼å…¥mathçš„è¯æ²¡åŠžæ³•æ±‚ceilingï¼Œä½†æ˜¯å¯ä»¥ç”¨ -ï¼ˆ-a // bï¼‰æ¥æ±‚ ç¬¬äºŒï¼Œåœ¨æ±‚bucketçš„ä¸ªæ•°çš„æ—¶å€™ï¼Œéœ€è¦å¤šåŠ ä¸Šä¸€ä¸ªbucketï¼Œå› ä¸ºä¸€ä¸ªbucketé‡Œé¢æœ€åŽçš„æ•°å­—æ˜¯æ”¾åœ¨ä¸‹ä¸€ä¸ªbucketé‡Œé¢æœ€å‰é¢çš„ ç¬¬ä¸‰ï¼Œå¯èƒ½ä¼šæœ‰ç©ºçš„bucketï¼Œæ‰€ä»¥ä¸èƒ½ç›´æŽ¥ç”¨è¿™ä¸ªçš„minå‡åŽ»ä¸Šä¸€ä¸ªçš„maxï¼Œå¿…é¡»è¦ç•™ä¸€ä¸ªå˜é‡ä¿å­˜ä¸Šä¸€ä¸ªçš„max ç¬¬å››ï¼Œå½“æ‰€æœ‰æ•°å­—éƒ½ç›¸åŒçš„æ—¶å€™ä¼šå˜å¾—å¾ˆéº»çƒ¦ï¼Œæœ€åŽåŠ ä¸ŠåŽ»ä¸€ä¸ªæ¡ä»¶è¿‡æ»¤æŽ‰è¿™ä¸ªéƒ¨åˆ† 28 implement strStrï¼ˆï¼‰Implement strStr(). Return the index of the first occurrence of needle in haystack, or -1 if needle is not part of haystack. Example 1: Input: haystack = â€œhelloâ€, needle = â€œllâ€Output: 2Example 2: Input: haystack = â€œaaaaaâ€, needle = â€œbbaâ€Output: -1 123456789class Solution: def strStr(self, haystack: str, needle: str) -&gt; int: if needle == "": return 0 for i, ch in enumerate(haystack): if ch == needle[0]: if needle == haystack[i:i+len(needle)]: return i return -1 åˆšå¼€å§‹ç‰¹åˆ«å¿«ä¹çš„æš´åŠ›ç ´è§£äº†ï¼ŒçœŸæ˜¯ä¸‡ä¸‡æ²¡æƒ³åˆ° æ„Ÿè§‰pythonå¤„ç†èµ·æ¥å­—ç¬¦ä¸²æ˜¯çœŸçš„å¼€å¿ƒ ä½†æ˜¯è¿™ä¸ªçš„æ—¶é—´ä¸æ˜¯å¾ˆå¿«ä¹ å…³äºŽå­—ç¬¦ä¸²åŒ¹é…æœ‰å¦å¤–ä¸¤ä¸ªç®—æ³•KMPå’ŒBMï¼ˆBMæ›´å¿«ä¸€ç‚¹ï¼‰ 14Write a function to find the longest common prefix string amongst an array of strings. If there is no common prefix, return an empty string â€œâ€. Example 1: Input: [â€œflowerâ€,â€flowâ€,â€flightâ€]Output: â€œflâ€Example 2: Input: [â€œdogâ€,â€racecarâ€,â€carâ€]Output: â€œâ€Explanation: There is no common prefix among the input strings.123456789101112131415161718192021class Solution: def longestCommonPrefix(self, strs: List[str]) -&gt; str: if len(strs) == 0: return "" if len(strs) == 1: return strs[0] LCP = self.compare(strs[0],strs[1]) for i in range(2,len(strs)): LCP = self.compare(LCP,strs[i]) return LCP def compare(self,a,b): i = j = 0 counter = 0 while i &lt; len(a) and j &lt; len(b): if a[i] == b[i]: counter += 1 else: break i += 1 j += 1 if counter == 0: return "" else: return a[:counter] æ€è·¯ï¼šå¹³è¡Œæ¯”è¾ƒï¼Œå…ˆæ‰¾å‡ºæ¥å‰ä¸¤ä¸ªé‡Œé¢çš„prefixï¼Œç„¶åŽå†ç”¨è¿™ä¸ªprefixå’Œç¬¬ä¸‰ä¸ªä¸œè¥¿æ¯”è¾ƒ æ³¨æ„è¾“å…¥çš„é•¿åº¦æ˜¯1çš„æ—¶å€™ï¼Œéœ€è¦è¾“å‡ºæ•´ä¸ªå­—ç¬¦ä¸² æ³¨æ„å¦‚æžœæ¯”è¾ƒå¤±è´¥äº†çš„è¯ï¼Œè¦ç›´æŽ¥åœæ­¢æ¯”è¾ƒï¼ 58Given a string s consists of upper/lower-case alphabets and empty space characters â€˜ â€˜, return the length of last word in the string. If the last word does not exist, return 0. Note: A word is defined as a character sequence consists of non-space characters only. Example: Input: â€œHello Worldâ€Output: 512345678910111213141516class Solution: def lengthOfLastWord(self, s: str) -&gt; int: if len(s) == 0: return 0 while s[-1] == " ": s = s[:-1] if len(s) == 0: return 0 new_str = s.split(" ") # return new_str print(new_str) return len(new_str[-1]) # cnt = 0 # for v in reversed(s): # if v.isspace(): # if cnt: break # else: cnt += 1 # return cnt åŽŸæ¥è¿è¡Œæ—¶é—´ä¹Ÿå¾ˆçŽ„å­¦ ä½†æ˜¯è¿˜æ˜¯åˆ«äººçš„ä»£ç çœ‹èµ·æ¥åŽ‰å®³ä¸€ç‚¹ï¼ 387Given a string, find the first non-repeating character in it and return itâ€™s index. If it doesnâ€™t exist, return -1. Examples: s = â€œleetcodeâ€return 0. s = â€œloveleetcodeâ€,return 2.1234567891011class Solution: def firstUniqChar(self, s: str) -&gt; int: count = collections.Counter(s) index = 0 for ch in s: if count[ch] == 1: return index else: index += 1 return -1 å±…ç„¶æœ‰è¿™ä¹ˆä¸ªä¸œè¥¿å«åšcounterï¼Œæ„Ÿåˆ°éœ‡æƒŠï¼ï¼ï¼ 383Given an arbitrary ransom note string and another string containing letters from all the magazines, write a function that will return true if the ransom note can be constructed from the magazines ; otherwise, it will return false. Each letter in the magazine string can only be used once in your ransom note. Note:You may assume that both strings contain only lowercase letters. canConstruct(â€œaâ€, â€œbâ€) -&gt; falsecanConstruct(â€œaaâ€, â€œabâ€) -&gt; falsecanConstruct(â€œaaâ€, â€œaabâ€) -&gt; true è¿™ä¸ªé¢˜ç›®ä¹Ÿå¤ªå†™æ„äº†å§ï¼Œæ„æ€å°±æ˜¯æˆ‘éœ€è¦å†™ä¸€ä¸ªå‹’ç´¢ä¿¡ï¼Œç„¶åŽè¦ä»Žæ‚å¿—ä¸Šé¢æ‰¾å•è¯ï¼Œçœ‹çœ‹èƒ½ä¸èƒ½ç”¨æ‚å¿—ä¸Šé¢çš„ä¸œè¥¿æ‹¼å‡‘å‡ºæ¥è¿™ä¸ªå•è¯ 1234567891011class Solution: def canConstruct(self, ransomNote: str, magazine: str) -&gt; bool: alphabet = [0]*26 for ch in magazine: index = ord(ch) - ord('a') alphabet[index] += 1 for ch in ransomNote: index = ord(ch) - ord('a') alphabet[index] -= 1 if alphabet[index] &lt; 0: return False return True çœ‹åˆ°äº†ä¸€ä¸ªæ¸…å¥‡çš„æ€è·¯ç„¶åŽè‡ªå·±å®žçŽ°äº†ä¸€ä¸‹ ç»Ÿè®¡magazineé‡Œé¢æ¯ä¸ªå­—æ¯çš„æ•°é‡ï¼Œå’Œéœ€è¦çš„å­—æ¯æ•°é‡å¯¹æ¯”ï¼Œå¦‚æžœä¸å¤Ÿçš„è¯å°±ä¸è¡Œ æˆ‘åœ¨å†™çš„æ—¶å€™å¤šiterationäº†ä¸€æ¬¡26ä¸ªå­—æ¯ï¼Œä½†æ˜¯å…¶å®žåœ¨ransomNoteé‡Œé¢ç›´æŽ¥å¯¹æ¯”å’Œ0çš„å¤§å°å°±å¯ä»¥äº† æ„Ÿè§‰å­—æ¯å’Œæ•°å­—æœ€å¤§çš„åŒºåˆ«å°±åœ¨äºŽå­—æ¯æœ‰é™è€Œæ•°å­—æ— é™ 344reverseä¸€ä¸ªlistï¼Œè¦æ±‚in-placeè€Œä¸”å ç”¨o1çš„ç©ºé—´12345678910class Solution: def reverseString(self, s: List[str]) -&gt; None: """ Do not return anything, modify s in-place instead. """ length = len(s) for i in range(length // 2): temp = s[i] s[i] = s[length - 1 - i] s[length - 1 - i] = temp å…¶å®žå¯ä»¥ä¸ç”¨tempçš„ï¼Œç›´æŽ¥ç”¨ s[i]ï¼Œs[length - 1 - i] = s[length - 1 - i], s[i]å°±å¯ä»¥äº† 151reverseä¸€ä¸ªstringï¼Œè®©è¿™å¥è¯å€’è¿‡æ¥ï¼Œä¸»è¦ä¼šæœ‰å¤šä¸ªç©ºæ ¼123class Solution: def reverseWords(self, s: str) -&gt; str: return " ".join(s.split()[::-1]) pythonçœŸçš„æ˜¯å¾ˆä½œå¼Šäº† splitä¸åŠ å‚æ•°å°±å¯ä»¥ç›´æŽ¥åˆ†å¼€æ‰€æœ‰å¤§å°çš„ç©ºæ ¼ 70 çˆ¬æ¥¼æ¢¯ DPYou are climbing a stair case. It takes n steps to reach to the top. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top? Note: Given n will be a positive integer. 123456789101112class Solution: def climbStairs(self, n: int) -&gt; int: if n == 1: return 1 elif n ==0: return 0 elif n == 2: return 2 f = (n+1)*[0]#èµ°nèŠ‚çš„æ—¶å€™å¯ä»¥æœ‰çš„æ–¹æ³•æ•°é‡ f[1] = 1 f[2] = 2 for i in range(3,n+1): f[i] = f[i-1] + f[i-2] return f[n] å…¶å®žå°±ç›¸å½“äºŽæ–æ³¢é‚£å¥‘æ•°åˆ—ï¼Œç¬¬iç§çš„å¯èƒ½çš„æ–¹æ³•æ˜¯ä»Ži-2èµ°ä¸€ä¸ª2ï¼Œä»¥åŠä»Ži-1èµ°ä¸€ä¸ª1çš„å’Œ 345æŠŠä¸€ä¸ªstringé‡Œé¢çš„åŽŸå› ååº 1234567891011121314class Solution: def reverseVowels(self, s: str) -&gt; str: vowels = "AEIOUaeiou" index = [] for i, j in enumerate(s): if j in vowels: index.append(i) s = list(s) i,j = 0,len(index)-1 while i&lt;j: s[index[i]],s[index[j]] = s[index[j]],s[index[i]] i += 1 j -= 1 return "".join(s) é¦–å…ˆåˆ¤æ–­å“ªä¸ªæ˜¯åŽŸå›  ç„¶åŽæŠŠå…ƒéŸ³çš„éƒ¨åˆ†å€’è¿‡æ¥ .joinæŠŠlistè½¬å›žstring 205 Isomorphic StringsEasy 767 217 Favorite ShareGiven two strings s and t, determine if they are isomorphic. Two strings are isomorphic if the characters in s can be replaced to get t. All occurrences of a character must be replaced with another character while preserving the order of characters. No two characters may map to the same character but a character may map to itself. Example 1: Input: s = â€œeggâ€, t = â€œaddâ€Output: true1234567891011class Solution: def isIsomorphic(self, s: str, t: str) -&gt; bool: n = len(s) sub_1,sub_2 = [0]*256,[0]*256 for i in range(n): a,b = s[i],t[i] if sub_1[ord(a)] != sub_2[ord(b)]: return False sub_1[ord(a)] = i + 1 sub_2[ord(b)] = i + 1 return True æ³¨æ„è¿™é‡Œé¢çš„mappingä¸ä¸€å®šæ˜¯å­—æ¯ï¼Œä¹Ÿå¯ä»¥æ˜¯æ•°å­— asciiç ä¸€å…±æ˜¯256ä¸ªï¼Œæ‰€ä»¥æ˜¯ä¸ä¼šè¶…å‡ºè¿™ä¸ªèŒƒå›´çš„ ä¸»è¦æ€è·¯å°±æ˜¯è¿™æ ·çš„ï¼Œä¸¤ä¸ªæ•°ç»„åˆ†åˆ«è®°å½•çš„æ˜¯å¯¹åº”ä½ç½®çš„asciiç çš„mappingçš„ä½æ•°ï¼Œå¦‚æžœè¿™ä¸¤ä¸ªä½æ•°ä¸ä¸€æ ·çš„è¯ï¼Œå°±è¯´æ˜Žè¿™ä¸¤ä¸ªçš„mappingæ–¹å¼æœ‰é—®é¢˜ï¼Œæ‰€ä»¥return Falseï¼Œä¸ç„¶çš„è¯return True 290 word patternGiven a pattern and a string str, find if str follows the same pattern. Here follow means a full match, such that there is a bijection between a letter in pattern and a non-empty word in str. Example 1: Input: pattern = â€œabbaâ€, str = â€œdog cat cat dogâ€Output: true12345class Solution: def wordPattern(self, pattern: str, str: str) -&gt; bool: pattern = list(pattern) string = str.split(" ") return len(set(zip(pattern,string))) == len(set(string)) == len(set(pattern)) and len(pattern) == len(string) åˆåˆ°äº†æ´»ç”¨zipçš„æ—¶å€™ï¼Œè¿”å›žçš„æ˜¯ä¸€ä¸ªä¸ªå¯¹åº”çš„ä¸œè¥¿ï¼Œä¹Ÿå°±æ˜¯è¯´è¿”å›žçš„æ˜¯ a-dog,b-cat,b-cat,a-dog è¿™æ—¶å€™æŠŠä»–ä»¬è½¬åŒ–æˆsetï¼Œå¾—åˆ°çš„å°±æ˜¯ä¸å¸¦é‡å¤çš„ä¸œè¥¿çš„é•¿åº¦ å¦‚æžœåŒ¹é…ä¸Šçš„é•¿åº¦å’ŒåŽŸå…ˆçš„é•¿åº¦å…¨éƒ½ç›¸åŒï¼ˆåŽ»æŽ‰é‡å¤çš„å…ƒç´ ï¼‰ï¼Œé‚£ä¹ˆå°±è¯æ˜ŽåŒ¹é…ä¸Šäº† 49 å˜ä½è¯12345678910111213141516171819class Solution: def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]: # for i,item in enumerate(strs): # item = list(item) # item.sort() # item = "".join(item) # temp[i],temp_sort = item,item # temp_sort.sort() # print(temp,strs) d = &#123;&#125; for word in strs: key = "".join(sorted(word)) if key in d: d.get(key).append(word) else: d[key] = [word] # d[key] = d.get(key,[]) + [word] return d.values() æ ¸å¿ƒæ€æƒ³ -&gt; æŽ’åºï¼ŒæŽ’åºä¹‹åŽçš„å˜ä½è¯å°±éƒ½ä¸€æ ·äº† leetcode 242,49 è¿™ä¸ªé¢˜çš„æ ¸å¿ƒæ€è·¯å°±æ˜¯ï¼Œæ¯ä¸ªå•è¯æŒ‰å­—æ¯é¡ºåºæŽ’åºä¹‹åŽçš„ç­”æ¡ˆå°±æ˜¯è¿™ä¸ªå•è¯çš„keyï¼Œå¦‚æžœä¸¤ä¸ªå•è¯çš„keyä¸€æ ·çš„è¯è¿™ä¸¤ä¸ªå•è¯å°±æ˜¯å˜ä½è¯ï¼Œå¦‚æžœä¸ä¸€æ ·çš„è¯å°±æ˜¯æ–°çš„è¯ åœ¨pythoné‡Œé¢ç›´æŽ¥ç”¨å­—å…¸å¯ä»¥å¾ˆå¥½çš„å‚¨å­˜å˜ä½è¯ 56 merge intervalsGiven a collection of intervals, merge all overlapping intervals. Example 1: Input: [[1,3],[2,6],[8,10],[15,18]]Output: [[1,6],[8,10],[15,18]]Explanation: Since intervals [1,3] and [2,6] overlaps, merge them into [1,6]. 12345678910class Solution: def merge(self, intervals: List[List[int]]) -&gt; List[List[int]]: intervals.sort(key = lambda x : x[0]) output = [] for i in intervals: if output and i[0] &lt;= output[-1][1]: output[-1][1] = max(output[-1][1], i[1]) else: output.append(i) return output æ³¨æ„ç‚¹ï¼š ç»™çš„æ•°æ®è¾“å…¥å¹¶ä¸ä¸€å®šæ˜¯æŽ’å¥½åºçš„ï¼Œæ‰€ä»¥éœ€è¦å…ˆæŽ’å¥½åºã€‚è¿™é‡Œç”¨åˆ°äº†æŽ’åºçš„keyçš„åŠŸèƒ½ã€‚lambdaæ˜¯å®šä¹‰ä»»æ„å‡½æ•° g(x)= x[0] éœ€è¦è¾“å‡ºçš„æ ¼å¼æ˜¯listå¥—listï¼Œæ‰€ä»¥éœ€è¦append æ€è·¯é”™äº†çš„ä¸€ä¸ªæ–¹å‘æ˜¯ï¼Œå…¶å®žæ¯ä¸ªiä¸åº”è¯¥å’Œéš”å£çš„iæ¯”å¤§å°ï¼Œè€Œæ˜¯åº”è¯¥å’Œoutputé‡Œé¢çš„æœ€ç»ˆç»“æžœæ¯”å¤§å°ï¼Œå› ä¸ºéœ€è¦è€ƒè™‘åˆ°å¥½å‡ ä¸ªå†…å®¹éƒ½å¯ä»¥åˆå¹¶çš„æƒ…å†µ 57æ’å…¥12345678910111213141516171819202122232425262728class Solution: def insert(self, intervals: List[List[int]], newInterval: List[int]) -&gt; List[List[int]]: out = [] adding = False if len(intervals) == 0: return [newInterval] if newInterval[1] &lt; intervals[0][0]: out.append(newInterval) adding = True for i in intervals: if adding is False: if newInterval[0] &gt; i[1]: out.append(i) elif newInterval[1] &lt; i[0]: out.append(newInterval) adding = True else: after_insert = [min(i[0],newInterval[0]),max(i[1],newInterval[1])] out.append(after_insert) adding = True # print("adding") if adding is True: if i[0] &gt; out[-1][1]: out.append(i) else: out[-1][1] = max(out[-1][1],i[1]) if adding is False: out.append(newInterval) return out è‡ªå·±è‹¦æ€å†¥æƒ³äº†ä¸€ä¸ªå¤šå°æ—¶çš„ç­”æ¡ˆ æœ‰ç‚¹ç¹çï¼Œdebugçš„æ—¶å€™ä¸»è¦æ˜¯æƒ…å†µè€ƒè™‘çš„ä¸å¤Ÿæ˜Žç¡®ï¼ŒåŒ…æ‹¬æ²¡æœ‰è€ƒè™‘ç©ºçš„æƒ…å†µï¼Œåœ¨æœ€åŽæ’å…¥çš„æƒ…å†µï¼Œåœ¨æœ€å‰æ’å…¥çš„æƒ…å†µ ä½†æ˜¯æœ€åŽæ€»ç»“çš„æƒ³ï¼Œåº”è¯¥å¯¹æ’å…¥çš„å‰åŽä¸€è§†åŒä»ï¼Œå› ä¸ºçŠ¶å†µå…¶å®žæ˜¯å·®ä¸å¤šçš„ï¼Œè€Œæˆ‘æŠŠå‰é¢åˆ†æˆäº†å¥½å¤šç§çŠ¶å†µï¼ŒåŽé¢å€’æ˜¯å†™æˆäº†ä¸€ç§æƒ…å†µ 12345678910111213left = []right = []s,e = newInterval[0],newInterval[1]for i in intervals: if i[1] &lt; s: left.append(i) elif i[0] &gt; e: right.append(i) else: s = min(i[0],s) e = max(i[1],e)return left + [[s,e]] + right è¿™æ˜¯discussioné‡Œé¢çš„ä¸€ç§ç®€è¦çš„è§£æ³•ï¼Œæ€è·¯çš„ä¸åŒå°±æ˜¯ä»–æ˜¯æ¯æ¬¡éƒ½mergeåˆ°newé‡Œé¢äº†ï¼ˆä¹Ÿå°±æ˜¯så’Œeï¼‰ï¼Œè€Œæˆ‘æ˜¯mergeåˆ°outé‡Œé¢äº† å…¶å®žæˆ‘çš„ä»£ç æœ¬èº«çš„ä¹Ÿæœ‰mergeåˆ°newçš„æ„æ€ï¼Œä½†æ˜¯è¢«æˆ‘åˆ†å‡ºäº†å¤ªå¤šç§å¤ªå¤æ‚çš„æƒ…å†µ 101å¯¹ç§°æ ‘1234567891011121314151617181920212223# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def isSymmetric(self, root: TreeNode) -&gt; bool: now = [] if root: now.append(root) while now: vals = [] for i in now: if i: vals.append(i.val) else: vals.append(None) if list(reversed(vals)) != vals: return False else: now = [j for i in now if i for j in (i.left, i.right)] return True éåŽ†çš„æ–¹æ³•ï¼Œæœ€åŽä¸€ä¸ªnowçš„è¡¨è¾¾å¼å€¼å¾—å­¦ä¹  æ³¨æ„rootæ˜¯nodeï¼Œè€Œè¿™ä¸ªnodeå®žé™…çš„å€¼åœ¨valsé‡Œé¢ï¼Œå› ä¸ºå¥½ä¹…æ²¡å¤„ç†nodeäº†æ‰€ä»¥å¿˜è®°äº†è¿™ä¸€ç‚¹ 12345678910def isSymmetric(self, root: TreeNode) -&gt; bool: def Symm(L,R): if L and R: return L.val == R.val and Symm(L.left,R.right) and Symm(L.right,R.left) else: return L == R # return L is None and R is None #åŒç­‰æ„ä¹‰ return Symm(root, root) # æ²¡æœ‰å…³äºŽç©ºçš„æ ‘çš„åˆ¤æ–­æ¡ä»¶ï¼Œæ‰€ä»¥éœ€è¦ä»Žrootå¼€å§‹ è¿™ä¸ªæ–¹æ³•è¿‡äºŽä¼˜é›…ï¼Œæˆ‘è¦å“­å‡ºæ¥äº† 87 Scramble StringGiven a string s1, we may represent it as a binary tree by partitioning it to two non-empty substrings recursively. Below is one possible representation of s1 = â€œgreatâ€: great / \ gr eat / \ / \g r e at / \ a tTo scramble the string, we may choose any non-leaf node and swap its two children. For example, if we choose the node â€œgrâ€ and swap its two children, it produces a scrambled string â€œrgeatâ€. rgeat / \ rg eat / \ / \r g e at / \ a t æ€è·¯ï¼š é¦–å…ˆï¼Œå¦‚æžœæˆ‘è¿™ä¸ªå•è¯çš„substringæ»¡è¶³è¿™ä¸ªè¦æ±‚çš„è¯ï¼Œä¸Šé¢ä¸€å±‚çš„å•è¯å°±æ»¡è¶³è¿™ä¸ªè¦æ±‚ï¼Œä¹Ÿå°±æ˜¯è¯´å¯ä»¥recursiveçš„å®Œæˆè¿™ä¸ªå·¥ä½œï¼Œå¯¹äºŽä¸åŒçš„substring callè¿™ä¸ªå‡½æ•°æ¥æ£€éªŒæ˜¯å¦æ»¡è¶³è¦æ±‚ è¾¹ç•Œæ¡ä»¶ï¼š å¦‚æžœstringçš„é•¿åº¦å°äºŽç­‰äºŽ2ï¼Œé‚£ä¹ˆæ€Žä¹ˆæ¢å…¶å®žéƒ½æ˜¯æ»¡è¶³çš„ å¦‚æžœä¸¤ä¸ªstringç›´æŽ¥ç›¸ç­‰ï¼Œé‚£ä¹ˆä¹Ÿæ˜¯æ»¡è¶³çš„ å…ˆå†³æ¡ä»¶ï¼š å¦‚æžœè¿™ä¸¤ä¸ªstringçš„é•¿åº¦éƒ½ä¸ä¸€æ ·ï¼Œé‚£ä¹ˆè‚¯å®šä¹Ÿä¸ä¸€æ · å¦‚æžœè¿™ä¸¤ä¸ªstringé‡Œé¢å­—æ¯çš„sortä¹‹åŽéƒ½ä¸ä¸€æ ·ï¼Œé‚£ä¹ˆè‚¯å®šä¸ä¸€æ · åˆ¤æ–­æ¡ä»¶ï¼š å¯¹äºŽä¸€ä¸ªstringï¼Œå¦‚æžœä»Žkä½ç½®æ¥åˆ†çš„è¯ï¼Œæœ‰ä¸¤ç§ä¸åŒçš„ç»“æžœã€‚orå…³ç³» ç»“æžœ1ï¼šs1çš„å‰kä¸ªå’Œs2çš„å‰kä¸ªä¸€æ · and s1çš„åŽn-kä¸ªå’Œs2çš„åŽn-kä¸ªä¸€æ · ç»“æžœ2ï¼šs1çš„å‰kä¸ªå’Œs2çš„åŽkä¸ªä¸€æ · and s1çš„å‰n-kä¸ªå’Œs2çš„å‰n-kä¸ªä¸€æ · 1234567891011class Solution: def isScramble(self, s1: str, s2: str) -&gt; bool: n1,n2 = len(s1),len(s2) if n1 != n2 or sorted(s1) != sorted(s2): return False if n1 &lt;= 2 or s1 == s2: return True f = self.isScramble for i in range(1,n1): if (f(s1[0:i], s2[0:i]) and f(s1[i:],s2[i:])) or \ f(s1[0:i], s2[n2-i:]) and f(s1[i:],s2[0:n2-i]): return True return False 38 count and sayThe count-and-say sequence is the sequence of integers with the first five terms as following: 1 11 21 1211 1112211 is read off as â€œone 1â€ or 11.11 is read off as â€œtwo 1sâ€ or 21.21 is read off as â€œone 2, then one 1â€ or 1211. Given an integer n where 1 â‰¤ n â‰¤ 30, generate the nth term of the count-and-say sequence. Note: Each term of the sequence of integers will be represented as a string. è‡ªå·±çš„æ™ºéšœè§£æ³•12345678910111213141516171819202122232425262728class Solution: def countAndSay(self, n: int) -&gt; str: if n == 1: return "1" result = [1] for i in range(2,n+1): result = self.Say(result) return result def Say(self,num): n = len(num) counter = 1 counters = "" nums = str(num[0]) for i in range(1,n): if num[i] == num[i-1]: counter += 1 else: counters += str(counter) counter = 1 nums += str(num[i]) counters += str(counter) result = "" for i in range(len(counters)): result += counters[i] result += nums[i] return result æ³¨æ„ï¼Œå¦‚æžœè¦æŠŠlistæŽ¥æˆstringï¼Œéœ€è¦å…ˆæŠŠé‡Œé¢çš„æ‰€æœ‰é¡¹éƒ½è½¬æˆstring æ„Ÿè§‰è‡ªå·±è¿˜æ˜¯å¾ˆä¸æ“…é•¿recursive #316 remove deplicate lettersGiven a string which contains only lowercase letters, remove duplicate letters so that every letter appears once and only once. You must make sure your result is the smallest in lexicographical order among all possible results. Example 1: Input: â€œbcabcâ€Output: â€œabcâ€Example 2: Input: â€œcbacdcbcâ€Output: â€œacdbâ€ 12345678910111213141516171819class Solution: def removeDuplicateLetters(self, s: str) -&gt; str: # s = sorted(s) # i = 0 # for n in s: # # print(n,i,s[i-1]) # if i &lt; 1 or n != s[i-1]: # s[i] = n # i += 1 # return "".join(s[:i]) s = list(s) result = [] last_occurrence = &#123;c: i for i, c in enumerate(s)&#125; for i,n in enumerate(s): if n not in result: while result and n &lt; result[-1] and result[-1] in s[i:]: result.pop() result.append(n) return "".join(result) è¿™é“é¢˜é‡Œé¢çš„é‡ç‚¹åœ¨lexicographical order ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨æ“ä½œçš„æ—¶å€™ï¼Œå¦‚æžœè¿™ä¸ªå­—æ¯åœ¨åŽé¢çš„ä½ç½®ä¸Šå‡ºçŽ°äº†ï¼Œä½†æ˜¯æ”¾åœ¨å‰é¢çš„ä½ç½®ä¸Šä¼šå¯¼è‡´å‰é¢å˜å¤§ï¼Œé‚£ä¹ˆå°±å–åŽé¢çš„é‚£ä¸ªç»“æžœ æœ¬æ¥æˆ‘æƒ³çš„æ˜¯å¯ä»¥å…ˆæŠŠæ²¡å‡ºçŽ°è¿‡çš„æ”¾è¿›åŽ»ï¼Œç„¶åŽå†åˆ·æ–°ã€‚ä½†æ˜¯ç›´æŽ¥æ”¾æœ€å¥½çš„åº”è¯¥æ›´å¥½ä¸€äº› å‡ ç§æƒ…å†µï¼š å¦‚æžœå·²ç»å‡ºçŽ°äº†ï¼šé‚£ä¹ˆç›´æŽ¥è·³è¿‡ å¦‚æžœæ²¡å‡ºçŽ°ï¼š å¦‚æžœæ¯”ä¹‹å‰çš„å°ï¼Œå¹¶ä¸”å‰é¢çš„é‚£ä¸ªåœ¨åŽé¢è¿˜æœ‰ï¼Œå°±å¾—å¾€å‰é¡¶ã€‚è¿˜è¦è€ƒè™‘é¡¶æ²¡äº†çš„æƒ…å†µï¼Œä¹Ÿå°±æ˜¯resultä¸ä¸ºç©º è¿™é‡Œæ³¨æ„è¿™ä¸‰ä¸ªæ¡ä»¶æ˜¯å¹¶åˆ—çš„ï¼Œéœ€è¦åŒæ—¶andã€‚æˆ‘åˆšå¼€å§‹æŠŠåœ¨åŽé¢å‡ºçŽ°æ”¾åˆ°å¾ªçŽ¯é‡Œé¢åŽ»äº†ï¼Œæ‰€ä»¥æ­»å¾ªçŽ¯äº† åœ¨ä¸Šé¢é¡¶å®Œä¹‹åŽï¼Œå†æŠŠæœ€æ–°çš„åŠ åˆ°æœ€åŽ 168 excel column titleGiven a positive integer, return its corresponding column title as appear in an Excel sheet. For example: 1 -&gt; A 2 -&gt; B 3 -&gt; C ... 26 -&gt; Z 27 -&gt; AA 28 -&gt; AB ... 123456789101112131415161718class Solution: def convertToTitle(self, n: int) -&gt; str: result = [] while n &gt; 0: letter = n % 26 n = n // 26 if letter == 0: letter = 26 n = n-1 result.append(letter) result = result[::-1] for i,item in enumerate(result): item += 64 item = str(chr(item)) result[i] = item # print(result) return "".join(result) è‡ªå·±çš„å‚»é€¼æ–¹æ³•ï¼š æœ€å…ˆå¾—åˆ°çš„ä½™æ•°åº”è¯¥æ˜¯æœ€åŽçš„å­—æ¯çš„å€¼ï¼Œæ‰€ä»¥è¿™é‡Œå‡ºæ¥çš„resultéœ€è¦ç¿»è½¬ä¸€ä¸‹ ç¿»è½¬listæœ€å¿«çš„æ–¹æ³•æ˜¯ [::-1] str(chr(n))æŠŠæ•°å­—è½¬æˆcharï¼ŒordæŠŠcharè½¬æˆæ•°å­—ï¼Œå¤§å†™Aæ˜¯65ï¼Œå°å†™aæ˜¯97 1return "" if num == 0 else self.convertToTitle((num - 1) / 26) + chr((num - 1) % 26 + ord('A')) å¤§ä½¬çš„ä¸€è¡Œ å¿˜è®°äº†è¿™ç§strçš„è¿žæŽ¥æ–¹æ³• ç›´æŽ¥å‡-1è®¡ç®—æ›´æ–¹ä¾¿ 171 Excel Sheet Column Number1234567class Solution: def titleToNumber(self, s: str) -&gt; int: # s = s[::-1] # result = 0 # for i,item in enumerate(s): # result += 26^(i) + (ord(item) - ord("A")) return 0 if s == "" else self.titleToNumber(s[:-1]) * 26 + ord(s[-1]) - ord("A") + 1 ä¸Šé¢é‚£é“é¢˜çš„å‹æƒ…é¢˜ï¼Œæ¨¡æ‹Ÿå¤§ä½¬å†™å‡ºäº†è§£æ³• æ³¨æ„listçš„ä¸Šé™ï¼Œåˆ°-1çš„è¯æ˜¯åˆ°-2ä¸åŒ…æ‹¬-1 13 roman to integerRoman numerals are represented by seven different symbols: I, V, X, L, C, D and M. Symbol ValueI 1V 5X 10L 50C 100D 500M 1000For example, two is written as II in Roman numeral, just two oneâ€™s added together. Twelve is written as, XII, which is simply X + II. The number twenty seven is written as XXVII, which is XX + V + II. Roman numerals are usually written largest to smallest from left to right. However, the numeral for four is not IIII. Instead, the number four is written as IV. Because the one is before the five we subtract it making four. The same principle applies to the number nine, which is written as IX. There are six instances where subtraction is used: I can be placed before V (5) and X (10) to make 4 and 9.X can be placed before L (50) and C (100) to make 40 and 90.C can be placed before D (500) and M (1000) to make 400 and 900.Given a roman numeral, convert it to an integer. Input is guaranteed to be within the range from 1 to 3999.1234567891011121314151617181920class Solution: def romanToInt(self, s: str) -&gt; int: trans = &#123; "I":1, "V":5, "X":10, "L":50, "C":100, "D":500, "M":1000 &#125; s = s.replace("IV","IIII").replace("IX","VIIII") s = s.replace("XL","XXXX").replace("XC","LXXXX") s = s.replace("CD","CCCC").replace("CM","DCCCC") result = 0 for c in s: result += trans[c] return result æ¯”è¾ƒå…¸åž‹çš„ç”¨dictè§£å†³çš„ä¾‹å­ï¼Œå–„ç”¨stringé‡Œé¢çš„replaceæ–¹æ³• 12 int to romanä¸Šé¢çš„å‹æƒ…é¢˜ è™½ç„¶å¯ä»¥ç©·ä¸¾å®žçŽ°ï¼Œä½†æ˜¯æˆ‘éª„å‚²çš„è‡ªå·±å†™å‡ºæ¥äº†recursiveçš„æ–¹æ³• éœ€è¦æ³¨æ„å­—æ¯çš„æ›¿æ¢é¡ºåºï¼Œä¸ç„¶ä¼šæ¢é”™1234567891011121314151617181920212223242526272829303132class Solution: def intToRoman(self, num: int) -&gt; str: space = ["M", "D", "C", "L", "X", "V", "I"] trans = &#123; "I": 1, "V": 5, "X": 10, "L": 50, "C": 100, "D": 500, "M": 1000 &#125; s = self.find_raw(num, 0, space, trans) s = s.replace("DCCCC", "CM").replace("CCCC", "CD") s = s.replace("LXXXX", "XC").replace("XXXX", "XL") s = s.replace("VIIII", "IX").replace("IIII", "IV") return s def find_raw(self, num, name, space, trans): if num &lt; 5: return num * "I" else: temp = (num // trans[space[name]]) * space[name] after = self.find_raw( num % trans[space[name]], name + 1, space, trans) return temp + afters = Solution()print(s.intToRoman(9)) 273 int to english1234567891011121314151617181920212223242526272829class Solution: def numberToWords(self, num: int) -&gt; str: t0to19 = ["Zero", "One", "Two", "Three", "Four", "Five", "Six", "Seven", "Eight", "Nine", "Ten", "Eleven", "Twelve", "Thirteen", "Fourteen", "Fifteen", "Sixteen", "Seventeen", "Eighteen", "Nineteen"] tens = ["Twenty", "Thirty", "Forty", "Fifty", "Sixty", "Seventy", "Eighty", "Ninety"] def word(num, i = 0): if num == 0: return [""] if num &lt; 20: return [t0to19[num]] if num &lt; 100: return [tens[num // 10 - 2]] + word(num % 10) if num &lt; 1000: return [t0to19[num // 100]] + ["Hundred"] + word(num % 100) else: trans = &#123;"Billion": int(1e9), "Million": int( 1e6), "Thousand": int(1e3)&#125; part = ["Billion", "Million", "Thousand"][i] if num // trans[part] == 0: return word(num % trans[part], i + 1) else: return word(num // trans[part]) + [part] + word(num % trans[part], i + 1) s = word(num, 0) while "" in s: s.remove("") return " ".join(s) or "Zero" æ³¨æ„ç§»é™¤ç©ºé¡¹çš„æ—¶å€™ï¼Œéœ€è¦ç”¨whileè€Œä¸æ˜¯if å› ä¸ºæœ€åŽéœ€è¦ç©ºæ ¼è¿žæŽ¥ï¼Œæ‰€ä»¥æœ€å¥½å…ˆæ‰”åˆ°listé‡Œé¢å†å‡ºæ¥ è¿™é¢˜ä¹Ÿå¤ªå‚»æ¯”äº†=ã€‚=æ— è®ºæ€Žä¹ˆæ ·éƒ½è¦è‡ªå·±æ‰‹æ‰“è¿™ä¹ˆå¤šä¸œè¥¿ # 68 text justificationéœ€è¦æŠŠè¿™ä¸€è¡Œå­—å·¦å³å¯¹é½1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution: def fullJustify(self, words: List[str], maxWidth: int) -&gt; List[str]: # æ¯ä¸€è¡Œå¡«æ»¡ï¼Œå¦‚æžœå¡«ä¸æ»¡çš„æ—¶å€™ï¼Œè¯çš„ä¸­é—´çš„ç©ºæ ¼å°½é‡å¹³å‡ # æœ€åŽä¸€è¡Œå³è¾¹åŠ ç©ºæ ¼ # æ¯è¯»ä¸€ä¸ªå•è¯åŽé¢éœ€è¦åŠ ä¸€è¡Œ space = 0 line = [0] # æ¯ä¸€è¡Œå¼€å¤´çš„å•è¯çš„åæ ‡ for i, word in enumerate(words): if space + len(word) &lt; maxWidth: space += len(word) + 1 elif space + len(word) == maxWidth and i != len(words) - 1: space = 0 line.append(i + 1) elif space + len(word) &gt; maxWidth: space = len(word) + 1 #æ³¨æ„è¿™é‡Œçš„é•¿åº¦å˜åŒ–äº† line.append(i) output = [] for i in range(len(line)): if i &lt; len(line) - 1: s = "" this_line = words[line[i]:line[i+1]] length = -1 # æœ€åŽä¸€ä¸ªå•è¯ä¸å¸¦ç©ºæ ¼ for w in this_line: length += len(w) + 1 if len(this_line) == 1: s = this_line[0] + (maxWidth - len(this_line[0])) * " " else: space_len = (maxWidth - length) // (len(this_line) - 1) extra_space = (maxWidth - length) % (len(this_line) - 1) for i,w in enumerate(this_line): if i &lt; len(this_line) - 1: s = s + w + " " + space_len*" " if i &lt;= extra_space - 1: s = s + " " else: s = s + w output.append(s) else: this_line = words[line[i]:] s = " ".join(this_line) s = s + " "*(maxWidth-len(s)) output.append(s) return output æ€è·¯ å…ˆåˆ†å¼€å•è¯ å†å¾€é‡Œæ’ç©ºæ ¼ 6æŠŠæ•´æ•°è½¬è¿‡æ¥12345678910111213141516171819202122class Solution: def reverse(self, x: int) -&gt; int: Positive = True x2 = [] if str(x)[0] == "-": Positive = False x = int(x - x * 2) while x &gt;= 10: num = x % 10 x = x // 10 x2.append(str(num)) x2.append(str(x)) output = "".join(x2) output = int(output) if Positive: output = int(output) else: output = int(output) - 2 * int(output) if output &gt; 2**31 - 1 or output &lt; -2**31: return 0 else: return output æ³¨æ„å•Š2çš„31æ¬¡æ–¹ä¸æ˜¯2e31å•Šå•Šæˆ‘åœ¨å¹²ä»€ä¹ˆ 165. Compare Version Numbers æ¯”è¾ƒä¸¤ä¸ªç‰ˆæœ¬å·ï¼Œéœ€è¦å¿½ç•¥é‡Œé¢çš„0 123456789101112131415161718192021222324252627282930313233343536class Solution: def compareVersion(self, version1: str, version2: str) -&gt; int: v1 = version1.split(".") v2 = version2.split(".") v1 = [int(x) for x in v1] v2 = [int(x) for x in v2] # å¯ä»¥ç®€åŒ–ä¸ºä¸¤è¡Œ # versions1 = [int(v) for v in version1.split(".")] # versions2 = [int(v) for v in version2.split(".")] if len(v1) &gt; len(v2): length = len(v2) else: length = len(v1) for i in range(length): c1,c2 = v1[i],v2[i] if c1 &gt; c2: return 1 elif c1 &lt; c2: return -1 end = i rest1,rest2 = v1[i+1:],v2[i+1:] if sum(rest1) == sum(rest2): return 0 elif sum(rest1) &gt; sum(rest2): return 1 elif sum(rest1) &lt; sum(rest2): return -1 # å¦ä¸€ç§æ–¹æ³•ï¼Œæ›´ç®€æ´ # for i in range(max(len(versions1),len(versions2))): # v1 = versions1[i] if i &lt; len(versions1) else 0 # v2 = versions2[i] if i &lt; len(versions2) else 0 # if v1 &gt; v2: # return 1 # elif v1 &lt; v2: # return -1; # return 0; éœ€è¦è€ƒè™‘çš„ä¸»è¦å°±æ˜¯é•¿åº¦ä¸ä¸€æ ·çš„æƒ…å†µå’Œå¡ž0çš„æƒ…å†µï¼Œæˆ‘çš„æƒ³æ³•æ˜¯å–æ¯”è¾ƒå°çš„æ€»é•¿åº¦ï¼Œç„¶åŽå†æ¯”è¾ƒå‰©ä½™çš„ å¤§ä½¬çš„æƒ…å†µæ˜¯æ¯”è¾ƒçš„æ‰€æœ‰çš„é•¿åº¦ï¼Œå¦‚æžœè¶…è¿‡äº†çŽ°åœ¨çš„é•¿åº¦å°±ç›´æŽ¥è®¾ç½®ä¸º0ï¼Œè¿™æ ·ä¸ä¼šå½±å“æ¯”è¾ƒã€‚æœ€åŽéƒ½æ¯”å®Œéƒ½æ²¡å·®å°±æ˜¯0 66Given a non-empty array of digits representing a non-negative integer, plus one to the integer. The digits are stored such that the most significant digit is at the head of the list, and each element in the array contain a single digit. You may assume the integer does not contain any leading zero, except the number 0 itself. Example 1: Input: [1,2,3]Output: [1,2,4]Explanation: The array represents the integer 123. 12345678910111213class Solution: def plusOne(self, digits: List[int]) -&gt; List[int]: n = len(digits) for i in range(n-1,-1,-1): digits[i] += 1 if digits[i] &lt; 10: return digits digits[i] = 0 if digits[0] == 0: digits.append(0) for j in range(n,0,-1): digits[j] = digits[j-1] digits[0] = 1 return digits æ²¡å•¥å¥½å¤šè¯´çš„ï¼Œæ‰€æœ‰æƒ…å†µéƒ½è€ƒè™‘äº†å°±è¡Œäº† ä½†æ˜¯å…¶å®žï¼Œå¦‚æžœä¼šäº§ç”Ÿè¿›ä½ï¼Œåªæœ‰å¯èƒ½æ˜¯å› ä¸ºæœ€åŽä¸€ä½æ˜¯9ï¼Œæ‰€ä»¥æˆ‘è¿™ä¸ªåˆ¤æ–­æ¡ä»¶ç¨å¾®æœ‰ä¸€ç‚¹æ²¡æƒ³æ¸…æ¥šçš„æ„Ÿè§‰ ä¸‹é¢è¿™ä¸ªå†™å‡ºæ¥æ›´åŠ ä¼˜é›…12345678910111213141516class Solution: def plusOne(self, digits): """ :type digits: List[int] :rtype: List[int] """ if len(digits) == 1 and digits[0] == 9: return [1, 0] if digits[-1] != 9: digits[-1] += 1 return digits else: digits[-1] = 0 digits[:-1] = self.plusOne(digits[:-1]) return digits 258 ä¸€ä¸ªæ•°å­—çš„é€ä½ç›¸åŠ ï¼Œç›´åˆ°å°äºŽ91234567891011class Solution: def addDigits(self, num: int) -&gt; int: if num &lt; 10: return num Sum = 0 for i in str(num): Sum += int(i) return self.addDigits(Sum) # if num == 0 : return 0 # else:return (num - 1) % 9 + 1 ä¸Šé¢é‚£ç§æ–¹æ³•æ˜¯æˆ‘å†™çš„ï¼Œå¤æ‚åº¦æ˜¯n ä¸‹é¢çš„æ–¹æ³•æ˜¯æ•°å­¦è§„å¾‹ï¼Œå¤æ‚åº¦æ˜¯1 144 Binary Tree Preorder TraversalGiven a binary tree, return the preorder traversal of its nodesâ€™ values. Example: Input: [1,null,2,3] 1 \ 2 / 3 Output: [1,2,3] æ³¨æ„å®¡é¢˜ï¼šè¿™é“é¢˜å¹¶ä¸æ˜¯æŒ‰å·¦å°å³å¤§çš„é¡ºåºæŽ’åˆ—çš„ï¼Œè€Œä¸”preorder traversalæŒ‡çš„å°±æ˜¯å…ˆè®¿é—®rootï¼Œå†ä»Žå·¦åˆ°å³è®¿é—®rootçš„å­èŠ‚ç‚¹ éœ€è¦æ³¨æ„è¾“å…¥ä¸ºç©ºçš„æƒ…å†µ recursiveå’Œiterateéƒ½å¯ä»¥å®Œæˆ åœ¨recursiveé‡Œé¢ï¼Œå› ä¸ºéœ€è¦æŠŠå†…å®¹å‚¨å­˜åœ¨listé‡Œé¢ï¼Œæ‰€ä»¥éœ€è¦æ–°å»ºä¸€ä¸ªå‡½æ•°12345678910111213class Solution: def preorderTraversal(self, root: TreeNode) -&gt; List[int]: result = [] if root: self.preorder(root,result) return result def preorder(self,root,result): if root: result.append(root.val) if root.left: self.preorder(root.left,result) if root.right: self.preorder(root.right,result) 1234567891011class Solution: def preorderTraversal(self, root: TreeNode) -&gt; List[int]: stack = [root] result = [] while stack: current = stack.pop() if current: result.append(current.val) stack.append(current.right) stack.append(current.left) return result æ³¨æ„å› ä¸ºæ˜¯æŠŠå†…å®¹æ”¾åœ¨stacké‡Œé¢ï¼Œæ‰€ä»¥è¦å…ˆæ”¾rightæ‰èƒ½è®©ä»–åŽå‡ºæ¥ éœ€è¦åˆ¤æ–­currentæ˜¯ä¸æ˜¯ä¸ºç©º popé»˜è®¤çš„å°±æ˜¯æœ€åŽä¸€ä½ 145 Binary Tree Postorder Traversal å’Œä¸Šä¸€é“é¢˜ååº æ³¨æ„è™½ç„¶æ˜¯postï¼Œä½†æ˜¯è¿˜æ˜¯éœ€è¦å…ˆè®¿é—®å·¦childï¼Œå†è®¿é—®å³child 1234567891011121314class Solution: def postorderTraversal(self, root: TreeNode) -&gt; List[int]: res = [] if root: self.post(root,res) return res def post(self,root,res): if root.left: self.post(root.left,res) if root.right: self.post(root.right,res) if root: res.append(root.val) 1234567891011class Solution: def postorderTraversal(self, root: TreeNode) -&gt; List[int]: stack = [root] res = [] while stack: current = stack.pop() if current: res.append(current.val) stack.append(current.left) stack.append(current.right) return res[::-1] iterativeçš„æ–¹æ³•å¯ä»¥é‡‡ç”¨å…ˆå¤„ç†å³è¾¹çš„ç‚¹ï¼Œå†å¤„ç†å·¦è¾¹çš„ç‚¹ã€‚å› ä¸ºå³è¾¹çš„åŽæ”¾è¿›stackæ‰€ä»¥å…ˆå‡ºæ¥å…ˆè¿›resé‡Œé¢ æœ€åŽå†æŠŠç»“æžœå€’åºï¼ˆç‰›é€¼ï¼‰ 102Given a binary tree, return the level order traversal of its nodesâ€™ values. (ie, from left to right, level by level). For example:Given binary tree [3,9,20,null,null,15,7], 3 / \ 9 20 / \ 15 7return its level order traversal as:[ [3], [9,20], [15,7]] 12345678910111213141516171819202122232425262728293031323334# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def levelOrder(self, root: TreeNode) -&gt; List[List[int]]:# self.levels = []# self.find(root,0)# return self.levels # def find(self,node, level):# if node:# if len(self.levels) &lt;= level:# self.levels += [[node.val]]# else:# self.levels[level] += [node.val]# self.find(node.left, level + 1)# self.find(node.right,level + 1) if not root: return [] stack, queue, nCount, res = [root],[],1,[[root.val]] while stack: temp = stack.pop(0) if temp.left: stack.append(temp.left) if temp.right: stack.append(temp.right) nCount -= 1 if nCount == 0: queue = [x.val for x in stack] if queue: res += [queue] nCount = len(stack) #å¾—åˆ°çš„æ˜¯ä¸‹ä¸€å±‚çš„ä¸ªæ•° return res ä¸¤ç§æ–¹æ³•ï¼Œé‡ç‚¹æ˜¯æ‰¾åˆ°å¦‚ä½•é‡æ–°è®¡æ•°levelçš„å±‚çº§ï¼Œç¬¬ä¸€ç§æ–¹æ³•ä¸æ˜¯é¡ºç€ä¸€æ­¥ä¸€æ­¥å†™è¿›ç»“æžœé‡Œçš„ï¼Œæ˜¯è·³ç€å†™è¿›åŽ»çš„ã€‚ç¬¬äºŒä¸ªæ–¹æ³•æ˜¯ç›´æŽ¥å†™è¿›åŽ»çš„ 103 æŠŠæ ‘æŒ‰å±‚zigzagæŽ’åˆ—Given a binary tree, return the zigzag level order traversal of its nodesâ€™ values. (ie, from left to right, then right to left for the next level and alternate between). For example:Given binary tree [3,9,20,null,null,15,7], 3 / \ 9 20 / \ 15 7return its zigzag level order traversal as:[ [3], [20,9], [15,7]]12345678910111213141516171819class Solution: def zigzagLevelOrder(self, root: TreeNode) -&gt; List[List[int]]: if not root: return [] levels = [] self.Find(root,0,levels) return levels def Find(self, node, level, levels): if node: if len(levels) &lt;= level: levels.append([node.val]) elif level%2: levels[level].insert(0,node.val) elif not level%2: levels[level].append(node.val) self.Find(node.left,level+1,levels) self.Find(node.right,level+1,levels) ç›´æŽ¥åˆ¤æ–­å±‚æ•°å°±å¯ä»¥å®žçŽ°ï¼Œå¦‚æžœç”¨ä¸€ä¸ªflagè¡¨ç¤ºæ²¡æ³•åœ¨ä¸€æ•´å±‚çš„å±‚é¢ä¸Šå®žçŽ° listæ˜¯å¯ä»¥ä¸¤ç«¯æ’å…¥çš„ 100 åˆ¤æ–­ä¸¤ä¸ªtreeæ˜¯ä¸æ˜¯ä¸€æ ·çš„12345678910111213141516171819class Solution: def isSameTree(self, p: TreeNode, q: TreeNode) -&gt; bool: # if (not p and q) or (not q and p): # return False # if p and q: # if p.val != q.val: return False # else: # return self.isSameTree(p.left,q.left) and self.isSameTree(p.right,q.right) # return p == q # if p and q: # return p.val == q.val and self.isSameTree(p.left,q.left) and self.isSameTree(p.right,q.right) # return p == q if p and q: if p.val != q.val: return False return self.isSameTree(p.left,q.left) and self.isSameTree(p.right,q.right) return p == q æ„Ÿè§‰è‡ªå·±å†™recursiveæ€»æ˜¯æœ‰ç‚¹é—®é¢˜ï¼Œéœ€è¦åˆ¤æ–­å¥½ç»ˆæžæ¡ä»¶ 226 æŠŠä¸€ä¸ªäºŒå‰æ ‘å¯¹ç§°å˜æ¢123456789101112131415# ä¸éœ€è¦å˜æ¢æ ‘çš„valï¼Œå¯ä»¥ç›´æŽ¥å˜æ¢nodeclass Solution: def invertTree(self, root: TreeNode) -&gt; TreeNode: # def invert(L,R): # if L and R: # L.val, R.val = R.val, L.val # invert(L.left,R.right) # invert(L.right,R.left) if root: invert = self.invertTree root.right, root.left = invert(root.left), invert(root.right) return root éœ€è¦æ¢nodeè€Œä¸æ˜¯æ¢val 257Given a binary tree, return all root-to-leaf paths. Note: A leaf is a node with no children. Example: Input: 1 / \2 3 \ 5 Output: [â€œ1-&gt;2-&gt;5â€, â€œ1-&gt;3â€] Explanation: All root-to-leaf paths are: 1-&gt;2-&gt;5, 1-&gt;312345678910111213141516class Solution: def binaryTreePaths(self, root: TreeNode) -&gt; List[str]: if not root: return [] stack = [(root,"")] result = [] while stack: current,ls = stack.pop() if not current.left and not current.right: result.append(ls+str(current.val)) if current.right: stack.append((current.right,ls+str(current.val)+"-&gt;")) if current.left: stack.append((current.left,ls+str(current.val)+"-&gt;")) return result dfsçš„æ–¹æ³•ï¼Œç»ˆæ­¢æ¡ä»¶æ˜¯çŽ°åœ¨çš„ç‚¹æ²¡æœ‰ä»»ä½•childäº†ã€‚è‡ªå·±æžé”™çš„åœ°æ–¹ä¸»è¦æ˜¯éœ€è¦stringè·Ÿç€stackä¸€èµ·èµ°ï¼Œè€Œä¸æ˜¯ä¸¤ä¸ªåˆ†åˆ«åˆ¤æ–­ã€‚ åŒæ ·çš„åˆ°åº•å¯ä»¥å†™å‡ºæ¥ç¬¬112é¢˜ï¼Œæœ¬è´¨ä¸Šæ˜¯ä¸€æ ·çš„ï¼Œå°±æ˜¯æŠŠæ±‚è·¯å¾„æ¢æˆäº†è¿™ä¸ªè·¯å¾„çš„å’Œ åŒç†å†™å‡ºæ¥113ï¼Œåœ¨tupleé‡Œé¢å†åŠ ä¸Šè·¯å¾„çš„è®¡ç®—å°±å¯ä»¥äº† 129ä¹ŸåŒç†ï¼ä½†æ˜¯129å¯ä»¥ç›´æŽ¥åœ¨æ¯æ¬¡recursioné‡Œé¢æŠŠä¸Šä¸€ä½æ•°ä¹˜10ï¼Œç„¶åŽåŠ ä¸Šè¿™ä¸€ä½æ•°ï¼Œè¿™æ ·ä¼šæ¯”å¾—åˆ°æ‰€æœ‰è·¯å¾„å†è®¡ç®—çš„é€Ÿåº¦å¿«å¾ˆå¤š 111 æ‰¾å‡ºè¿™ä¸ªtreeçš„æœ€å°depth å¯ä»¥ç”¨BFSä¹Ÿå¯ä»¥ç”¨DFSï¼Œä½†æ˜¯æ³¨æ„çš„æ˜¯ä¸¤ä¸ªreturnçš„ä¸œè¥¿çš„æ¡ä»¶æ˜¯ä¸ä¸€æ ·çš„ã€‚DFSçš„æ—¶å€™å¿…é¡»æŠŠå·¦å³æ ‘æ¯”å¤§å°123456789101112131415161718class Solution: def minDepth(self, root: TreeNode) -&gt; int: if not root: return 0 # stack = [(root,1)] # while stack: # current,depth = stack.pop(0) # if not current.left and not current.right: # return depth # if current.left: # stack.append((current.left,depth+1)) # if current.right: # stack.append((current.right,depth+1)) # dfs if root.left is None or root.right is None: return max(self.minDepth(root.left),self.minDepth(root.right))+1 else: return min(self.minDepth(root.left),self.minDepth(root.right))+1 104 å¯»æ‰¾æœ€æ·±çš„å±‚ ä¸ç”¨åˆ¤æ–­æ¡ä»¶ï¼Œç›´æŽ¥dfsæ¯æ¬¡åŠ ä¸€å°±å¯ä»¥å®žçŽ°äº†12345class Solution: def maxDepth(self, root: TreeNode) -&gt; int: if not root: return 0 # if not root.left and not root.right: return max(self.maxDepth(root.left),self.maxDepth(root.right)) + 1 110 åˆ¤æ–­æ˜¯ä¸æ˜¯å¹³è¡¡æ ‘ recursionçš„æ–¹æ³•ï¼Œæ³¨æ„çš„æ˜¯æ¯æ¬¡è¿”å›žçš„æ—¶å€™è¿žå¸¦ç€å­æ ‘æ˜¯å¦å¹³è¡¡ä¸€èµ·è¿”å›žçš„ï¼Œæ•´ä½“æ€è·¯å’Œä¹‹å‰çš„å¸¦ç€æ·±åº¦ä¸€èµ·è¿”å›žçš„æ„Ÿè§‰å·®ä¸å¤š æˆ–è€…ä¹Ÿå¯ä»¥ç›´æŽ¥è®¾ç½®ä¸€ä¸ªå‡½æ•°ï¼Œè®¡ç®—å‡ºå„ä¸ªéƒ¨åˆ†çš„heightï¼Œç„¶åŽå†æ”¾åˆ°isBalanceé‡Œé¢ä»Žä¸Šåˆ°ä¸‹è®¡ç®—123456789class Solution: def isBalanced(self, root: TreeNode) -&gt; bool: return self.dfs(root)[1] def dfs(self,root): if not root: return (0, True) #depth, if_balance l_depth, l_balance = self.dfs(root.left) r_depth, r_balance = self.dfs(root.right) return max(l_depth,r_depth)+1, l_balance and r_balance and abs(l_depth-r_depth) &lt;= 1 337/213éƒ½æ˜¯è´¼å·ä¸œè¥¿ï¼Œä¸èƒ½è¿žç€å·ä¸¤å®¶ã€‚ç®€å•çš„åŠ¨æ€è§„åˆ’é—®é¢˜ã€‚è¿™ä¸ªé—®é¢˜çš„ä¸»è¦æ€è·¯å¦‚ä¸‹ï¼š å¯¹äºŽæ¯ä¸€å®¶ï¼Œå…¶å®žéƒ½æœ‰ä¸¤ç§æƒ…å†µï¼šå·è¿™å®¶å’Œä¸å·è¿™å®¶æƒ…å†µä¸‹å¾—åˆ°çš„é’± å·è¿™å®¶çš„æ—¶å€™ï¼Œå·åˆ°çš„é’±ç­‰äºŽï¼šè¿™å®¶çš„é’±+å‰ä¸€å®¶ï¼ˆchildnodeï¼‰ä¸å·æ—¶å€™å¾—åˆ°çš„é’± ä¸å·è¿™å®¶çš„æ—¶å€™ï¼Œå·åˆ°å¾—é’±ç­‰äºŽï¼šmaxï¼ˆå·å‰ä¸€å®¶ï¼Œä¸å·å‰ä¸€å®¶ï¼‰ æ³¨æ„è¿™ç§æƒ…å†µä¸‹ï¼Œå‰ä¸€å®¶å¯ä»¥å·å¯ä»¥ä¸å·ï¼Œå–å†³äºŽæœ‰å¤šå°‘é’±ä¸‰ä¸ªé¢˜å¦‚ä¸‹ï¼š æœ€ç®€å•çš„æƒ…å†µæ˜¯æ•°ç»„ ä¸­ç­‰æƒ…å†µæ˜¯ä¸€ä¸ªçŽ¯ï¼Œå³æ•°ç»„çš„æ”¶å°¾ä¸èƒ½è¿žç€å·ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹å…¶å®žå°±æ˜¯è®¡ç®—ä¸¤æ¬¡ï¼Œä¸€æ¬¡ä¸å·ç¬¬ä¸€å®¶ï¼Œä¸€æ¬¡ä¸å·æœ€åŽä¸€å®¶ï¼Œçœ‹å“ªç§æƒ…å†µå¤š æœ€åŽçš„æƒ…å†µæ˜¯äºŒå‰æ ‘çš„æƒ…å†µï¼Œè¿™ç§æƒ…å†µä¸‹å¯ä»¥ç»™æ¯ä¸ªç‚¹éƒ½è§„å®šä¸€ä¸ªtupleåˆ†åˆ«è¡¨ç¤ºå·äº†å’Œæ²¡å·çš„ç»“æžœ 1234567891011class Solution: #ç¬¬äºŒç§æƒ…å†µä¸‹ def rob(self, nums: List[int]) -&gt; int: if len(nums) == 0: return 0 if len(nums) == 1: return nums[0] return max(self.simple_rob(nums[1:]),self.simple_rob(nums[:-1])) def simple_rob(self,nums): rob,not_rob = 0,0 for n in nums: rob,not_rob = not_rob+n, max(not_rob,rob) return max(rob,not_rob) 12345678910class Solution: #ç¬¬ä¸‰ç§æƒ…å†µä¸‹ def rob(self, root: TreeNode) -&gt; int: return max(self.dfs(root)) def dfs(self,root): if not root: return (0,0) # [0]steal this node, [1] don't steal this node left = self.dfs(root.left) right = self.dfs(root.right) return (root.val + left[1] + right[1],max(left[0],left[1]) + max(right[0],right[1])) 235 Lowest Common Ancestor of a Binary Search Tree æ‰¾åˆ°ç»™çš„ä¸¤ä¸ªç‚¹çš„æœ€ä½Žçš„å…¬å…±çš„ç¥–å…ˆï¼ˆparentï¼‰ å…¶å®žéœ€è¦æ³¨æ„è¿™ä¸ªæ€è·¯ï¼Œæ€è·¯å°±æ˜¯å½“è¿™ä¸¤ä¸ªç‚¹éƒ½æ¯”çŽ°åœ¨çš„rootå°çš„æ—¶å€™ï¼Œé‚£è¿™ä¸ªå…¬å…±ç‚¹åœ¨rootçš„å·¦è¾¹ï¼Œå¦‚æžœéƒ½å°çš„æ—¶å€™å°±åœ¨å³è¾¹ã€‚ å› ä¸ºè¿™é‡Œè¦æ‰¾çš„æ˜¯æœ€lowçš„å…¬å…±ç‚¹ï¼Œä¹Ÿå°±æ˜¯ç¦»rootæœ€è¿œçš„ç‚¹ 123456789class Solution: def lowestCommonAncestor(self, root: 'TreeNode', p: 'TreeNode', q: 'TreeNode') -&gt; 'TreeNode': if not root or not p or not q: return None if max(p.val,q.val) &lt; root.val: return self.lowestCommonAncestor(root.left,p,q) if min(p.val,q.val) &gt; root.val: return self.lowestCommonAncestor(root.right,p,q) return root 236 ä¾ç„¶æ˜¯æ‰¾å…¬å…±ç¥–å…ˆï¼Œä½†æ˜¯ä¸æ˜¯åœ¨BSTé‡Œé¢æ‰¾è€Œæ˜¯æ™®é€šçš„äºŒå‰æ ‘é‡Œé¢æ‰¾äº†ï¼Œæ‰€ä»¥ä¹Ÿå°±æ˜¯ä¸èƒ½ç”¨BSTçš„æ€§è´¨äº†123456789class Solution: def lowestCommonAncestor(self, root: 'TreeNode', p: 'TreeNode', q: 'TreeNode') -&gt; 'TreeNode': if root is None or root==p or root ==q: return root left = self.lowestCommonAncestor(root.left,p,q) right = self.lowestCommonAncestor(root.right,p,q) if left and right: return root return left or right 108 Convert Sorted Array to Binary Search Tree æ³¨æ„ï¼Œå·²ç»ç»™äº†æŽ’å¥½åºçš„arrayäº†ï¼Œè€Œä¸”éœ€è¦çš„ç»“æžœæ˜¯height-balanceçš„ï¼Œè¿™é‡Œå¯ä»¥ç›´æŽ¥å–è¿™ä¸ªarrayæœ€ä¸­é—´çš„ä½œä¸ºrootï¼Œç„¶åŽå·¦å³åˆ†åˆ«recursion å¦‚æžœç”¨å¹³å¸¸çš„æ’å…¥æ–¹æ³•ï¼Œæ’å…¥è¿›æ¥çš„æ ‘ä¸ä¸€å®šæ˜¯å¹³è¡¡çš„12345678910class Solution: def sortedArrayToBST(self, nums: List[int]) -&gt; TreeNode: if not nums: return None mid = len(nums) // 2 root = TreeNode(nums[mid]) root.left = self.sortedArrayToBST(nums[:mid]) root.right = self.sortedArrayToBST(nums[mid+1:]) return root 77 å›žæº¯æ³•ï¼Œåˆ—ä¸¾æ‰€æœ‰ç»„åˆ å›žæº¯æ³•éœ€è¦æ³¨æ„ä¸‰ä¸ªé˜¶æ®µ å¯ä»¥é€‰æ‹©çš„æ¡ä»¶æ˜¯ä»€ä¹ˆï¼ˆéœ€è¦åœ¨è¿™äº›æ¡ä»¶é‡Œè¿­ä»£) å¯¹æ¡ä»¶çš„é™åˆ¶æ˜¯ä»€ä¹ˆã€‚æ¯”å¦‚åœ¨è¿™ä¸ªä¾‹å­é‡Œé¢ï¼Œå¦‚æžœä¸€ä¸ªæ•°å­—ç”¨è¿‡äº†å°±ä¸èƒ½å†ç”¨äº†ã€‚ä¸èƒ½å®žçŽ°æˆ–è€…å·²ç»å®žçŽ°çš„æ¡ä»¶éœ€è¦å¼¹å‡º ç›®æ ‡ï¼šéœ€è¦å¾—åˆ°ä¸€ä¸ªbase caseã€‚æ¯”å¦‚è¿™ä¸ªé¢˜é‡Œé¢ï¼Œå­—ç¬¦ä¸²çš„é•¿åº¦åˆ°äº†kï¼Œå°±éœ€è¦è¾“å…¥äº† ç”¨äºŽé—®é¢˜ç§ç±»ï¼šè®¡ç®—æˆ–è€…åˆ—ä¸¾å…¨éƒ¨çš„å¯èƒ½ è¿™é“é¢˜çš„pythonçš„é—®é¢˜ï¼Œåœ¨listé‡Œé¢appendä¹‹åŽpopæ˜Žæ˜¾ä¼šå‡ºçŽ°ä¸€äº›é—®é¢˜1234567891011121314151617181920class Solution: def combine(self, n: int, k: int) -&gt; List[List[int]]: all_res = [] self.search(1,n,k,[],all_res) return all_res def search(self,index,n,k,res,all_res): #start, n, choose num, all result if len(res) == k: all_res.append(res) # print(all_res) return for i in range(index,n+1): # res.append(i) # print("before",res) # print(i+1,res,all_res) self.search(i+1,n,k,res+[i],all_res) # del(res[-1]) # print("after",res) return 39 æ‰€æœ‰èƒ½åˆ°targetæ•°å­—çš„ç»„åˆ å›žæº¯Input: candidates = [2,3,6,7], target = 7,A solution set is:[ [7], [2,2,3]]123456789101112131415161718class Solution: def combinationSum(self, candidates: List[int], target: int) -&gt; List[List[int]]: def solver(nums,target,index,path,res): if target &lt; 0: return if target == 0: # path.sort() # if path not in res: res.append(path) return for i in range(index,len(nums)): solver(nums,target-nums[i],i,path+[nums[i]],res) res = [] solver(candidates,target,0,[],res) return res æ³¨æ„è¿™é‡Œéœ€è¦æ¯æ¬¡ä»Žiå¼€å§‹è¿›è¡Œä¸‹ä¸€è½®ï¼Œä¹Ÿå°±æ˜¯å¦‚æžœç¬¬ä¸€ä¸ª2å¯ä»¥åŠ è¿›åŽ»ï¼Œç¬¬äºŒæ¬¡è¿˜æ˜¯ä»Ž2å¼€å§‹å¾€é‡Œè¯•ç€åŠ ã€‚è¦æ˜¯2åŠ ä¸è¿›åŽ»äº†ï¼Œå°±åªä¼šå¾€2åŽé¢çš„indexèµ°ï¼ˆä¹Ÿå°±æ˜¯é»˜è®¤ç»™ä½ çš„listå·²ç»æ˜¯æŽ’å¥½åºçš„äº†ï¼‰ æ•´ä½“æ€è·¯å’Œå‰é¢å‡ é“é¢˜å·®ä¸å¤šã€‚é‡ç‚¹å°±æ˜¯ç¡®è®¤åœæ­¢çš„æ¡ä»¶ï¼Œç„¶åŽæ¯æ¬¡å…ˆåˆ¤æ–­åœæ­¢æ¡ä»¶ï¼Œå¦‚æžœä¸ç¬¦åˆå†è¿›è¡Œrecursionã€‚æ³¨æ„recursionçš„æ¯è½®çš„æ¡ä»¶åˆ¤å®š 40 æ•°å­—ä¸æ˜¯æŒ‰é¡ºåºæŽ’å¥½çš„äº†ï¼Œæ•°å­—ä¼šé‡å¤å‡ºçŽ°äº† æˆ‘é€‰æ‹©çš„æ–¹æ³•æ˜¯åœ¨æ¯æ¬¡åŠ å…¥æ–°çš„pathä¹‹å‰ï¼ŒæŽ’åºï¼Œç„¶åŽæ¯”å¯¹è¿™ä¸ªæ˜¯å¦åœ¨å·²ç»ç®—å‡ºæ¥çš„ç»“æžœé‡Œé¢ï¼ˆè™½ç„¶å¥½åƒä¸å¿«ï¼‰ 123456789101112131415class Solution: def combinationSum2(self, candidates: List[int], target: int) -&gt; List[List[int]]: def solver(nums,target,index,path,res): if target &lt; 0: return if target == 0: path.sort() if path not in res: res.append(path) for i in range(index,len(nums)): solver(nums,target-nums[i],i+1,path+[nums[i]],res) res = [] solver(candidates,target,0,[],res) return res åˆ«äººçš„æ–¹æ³•ä¸»è¦å¢žåŠ äº†ä¸¤ä¸ªæ–°çš„åˆ¤æ–­ï¼Œç¬¬ä¸€ä¸ªæ˜¯å¦‚æžœåœ¨foré‡Œé¢ï¼ŒçŽ°åœ¨çš„æ•°å­—å·²ç»æ¯”éœ€è¦çš„targetå¤§äº†ï¼Œé‚£ä¹ˆå°±ä¸éœ€è¦ç»§ç»­æœç´¢åŽé¢æ‰€æœ‰çš„éƒ¨åˆ†äº†ï¼ˆï¼Ÿï¼‰ã€‚å› ä¸ºçŽ°åœ¨æ‰€æœ‰çš„æ•°å­—éƒ½æ˜¯positiveçš„ æœ€é‡è¦çš„æ˜¯ï¼Œå¦‚æžœè¿™ä¸ªæ•°å­—ä¸æ˜¯ç¬¬ä¸€ä¸ªæ”¾è¿›åŽ»çš„æ•°å­—ï¼Œå¹¶ä¸”è¿™ä¸ªæ•°å­—å’Œä¹‹å‰çš„æ•°å­—ç›¸åŒï¼Œé‚£ä¹ˆè¿™ä¸ªæ•°å­—åº”è¯¥ç›´æŽ¥è¢«ignore 12345678910111213141516171819class Solution: def combinationSum2(self, candidates: List[int], target: int) -&gt; List[List[int]]: def solver(nums,target,index,path,res): if target &lt; 0: return if target == 0: print(path) res.append(path) for i in range(index,len(nums)): if i &gt; index and nums[i]==nums[i-1]: continue if nums[i] &gt; target: break solver(nums,target-nums[i],i+1,path+[nums[i]],res) res = [] candidates.sort() solver(candidates,target,0,[],res) return res ä»¥ 1ï¼Œ1ï¼Œ2ï¼Œ5ï¼Œ6ï¼Œ7ï¼Œ10å‡‘8ä¸ºä¾‹å­ å½“å–ç¬¬ä¸€ä¸ª1çš„æ—¶å€™ï¼Œèƒ½ç»„å‡ºæ¥116ï¼Œ125ï¼Œ17ï¼Œä¸‰ä¸ªç»“æžœã€‚è¿™æ—¶å€™è¿™ä¸‰ä¸ªç»“æžœéƒ½åœ¨ç¬¬ä¸€å±‚çš„i=0çš„æ—¶å€™çš„å‡ºæ¥çš„ç»“æžœã€‚å½“è¿™ä¸€å±‚æ‰€æœ‰çš„ç»“æžœå–è¿‡ä¹‹åŽï¼Œå°±ä¼šä»Žç¬¬ä¸€ä¸ª1é€€å‡ºæ¥ï¼Œè¿›åˆ°ç¬¬äºŒä¸ª1. ä½†æ˜¯å¦‚æžœç›´æŽ¥ç®—ç¬¬2ä¸ª1ï¼Œä¹Ÿèƒ½ç»„ç²—125å’Œ17ï¼Œä»Žç»“æžœä¸Šè¯´è¿™ä¸¤ä¸ª1æ˜¯é‡å¤çš„ï¼Œæ‰€ä»¥ä»£ç åœ¨è¿™éƒ¨åˆ†ç›´æŽ¥continueäº†ï¼Œæ²¡æœ‰è®¡ç®—ç¬¬äºŒä¸ª1ï¼Œè€Œæ˜¯ç›´æŽ¥è·³åˆ°äº†ç¬¬ä¸‰ä¸ªæ•°å­—2 è¿™æ ·è®¡ç®—é‡å¤çš„æ–¹æ³•æ¯”æˆ‘å†sortä¸€æ¬¡ç„¶åŽsearchä¸€æ¬¡æ¶ˆè€—çš„æ—¶é—´å°‘å¾ˆå¤š 216 å›žæº¯ ä»Ž1-9é‡Œé€‰kä¸ªæ•°å­—ç»„åˆï¼Œå¾—åˆ°ç›®æ ‡æ•°å­— å¾ˆç®€å•ï¼Œæ²¡å•¥å¯æžçš„1234567891011121314151617181920class Solution: def combinationSum3(self, k: int, n: int) -&gt; List[List[int]]: def Solver(nums,k,n,index,path,res): if len(path) == k: if n &lt;0: return if n == 0: res.append(path) return for i in range(index,9): if i &gt; n: break Solver(nums,k,n-nums[i],i+1,path+[nums[i]],res) nums = [i for i in range(1,10)] res = [] Solver(nums,k,n,0,[],res) return res 377 è™½ç„¶æ”¾åœ¨ä¸Šé¢çš„ç³»åˆ—é‡Œäº†ä½†æ˜¯æ˜¯DPGiven an integer array with all positive numbers and no duplicates, find the number of possible combinations that add up to a positive integer target. Example: nums = [1, 2, 3]target = 4 The possible combination ways are:(1, 1, 1, 1)(1, 1, 2)(1, 2, 1)(1, 3)(2, 1, 1)(2, 2)(3, 1) Note that different sequences are counted as different combinations. Therefore the output is 7. 123456789class Solution: def combinationSum4(self, nums: List[int], target: int) -&gt; int: nums.sort() com = [1] + [0]*target for i in range(target+1): for num in nums: if num &gt; i: break com[i] += com[i-num] return com[target] 46 æ‰¾å‡ºæ‰€æœ‰çš„æŽ’åˆ—ç»„åˆGiven a collection of distinct integers, return all possible permutations. Example: Input: [1,2,3]Output:[ [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1]] è¿™é‡Œæ¯ä¸ªæ•°å­—ä¸æ­¢ç”¨ä¸€æ¬¡ï¼Œæ‰€ä»¥éœ€è¦ä¸€ä¸ªæ–¹æ³•æ¥è®°å½•å·²ç»visitçš„æ•°å­—ï¼Œæˆ–è€…æŠŠnumsçš„å¤§å°æ”¹å˜ï¼ˆæ¯”å¦‚æ¯ä¸€æ¬¡æ–°è¾“å…¥çš„numséƒ½è·³è¿‡çŽ°åœ¨ä½¿ç”¨çš„æ•°å­—ï¼‰ æ³¨æ„è¿™é‡Œé¢æ²¡æœ‰é‡å¤çš„æ•°å­— æˆ‘è¿™ä¸ªæ–¹æ³•ä¹Ÿå¯ä»¥ 12345678910111213141516class Solution: def permute(self, nums: List[int]) -&gt; List[List[int]]: def Solver(nums,index,path,res): if len(path) == len(nums): res.append(path) return for i in nums: if i not in path: Solver(nums,i+1,path+[i],res) res = [] Solver(nums,0,[],res) return res 47åœ¨ä¸Šé¢çš„åŸºç¡€ä¸Šæœ‰äº†é‡å¤çš„æ•°å­— é¦–å…ˆä¿è¯äº†æ•°ç»„å¿…é¡»è¦æ˜¯sortçš„ï¼Œè¿™æ ·æ‰èƒ½ç¡®å®šç›¸åŒçš„æ•°å­—æŒ¨åœ¨ä¸€èµ· æ ¸å¿ƒæ€æƒ³å°±æ˜¯ï¼Œæ¯æ¬¡å–å‡ºä¸€ä¸ªæ•°å­—çš„æ—¶å€™ï¼ŒæŠŠåŽŸæ¥numsçš„è¿™ä¸ªæ•°ç›´æŽ¥åŽ»æŽ‰ï¼Œä¸‹æ¬¡å†ä»Ž0å¼€å§‹æ‰¾ï¼Œè¿™æ ·å°±èƒ½å¾—åˆ°æ‰€æœ‰çš„æ•°æ®äº† åœ¨recursionåˆ¤æ–­æ¡ä»¶ä¸Šï¼Œå› ä¸ºå·²ç»ç¡®å®šäº†æ•°ç»„æœ‰åºï¼Œæ‰€æœ‰æ¯æ¬¡è®°å½•ä¸€ä¸ªtempï¼Œæ¥è¡¨ç¤ºä¸Šä¸€ä¸ªæ•°å­—ï¼Œåªæœ‰å½“è¿™ä¸ªæ•°å­— ç¬¬ä¸€æ¬¡è¢«æ‹¿å‡ºæ¥ï¼ˆindex==0ï¼‰orè¿™ä¸ªæ•°å­—å’Œä¸Šä¸€ä¸ªæ•°å­—ä¸ç›¸ç­‰orä¸Šä¸€ä¸ªè¿˜æ²¡æœ‰æ•°å­—çš„æ—¶å€™ï¼Œæ‰èƒ½è¿›å…¥recursion12345678910111213141516class Solution: def permuteUnique(self, nums: List[int]) -&gt; List[List[int]]: def Solver(nums,temp,path,res): if len(nums) == 0: res.append(path) return for i in range(0,len(nums)): if temp is None or nums[i] != temp or i == 0: temp = nums[i] Solver(nums[:i]+nums[i+1:],temp,path+[nums[i]],res) nums.sort() res = [] Solver(nums,None,[],res) return res 60The set [1,2,3,â€¦,n] contains a total of n! unique permutations. By listing and labeling all of the permutations in order, we get the following sequence for n = 3: â€œ123â€â€œ132â€â€œ213â€â€œ231â€â€œ312â€â€œ321â€Given n and k, return the kth permutation sequence. æ—¶é—´å¤ªé•¿äº†ï¼Œä¸èƒ½ç”¨backtrackingæ¥åš æ€è·¯ï¼Œå‰ï¼ˆn-1ï¼‰ï¼ä¸ªæ•°å­—çš„å¼€å¤´æ˜¯1ï¼Œç„¶åŽn-1ï¼ä¸ªæ˜¯2ï¼Œç„¶åŽæ˜¯3ï¼Œä»¥æ­¤ç±»æŽ¨ä¸€ç›´åˆ°æœ€åŽã€‚å› ä¸ºä¸€å…±nä¸ªæ•°å­—ï¼Œn-1ï¼xnä¹Ÿå°±æ˜¯nï¼äº† åœ¨ç¡®å®šç¬¬ä¸€ä¸ªæ•°å­—ä¹‹åŽï¼Œç¬¬äºŒä¸ªæ•°å­—çš„å‰n-2ï¼ä¸ªæ˜¯2ï¼Œç„¶åŽæ˜¯3ï¼Œç„¶åŽä»¥æ­¤ç±»æŽ¨]]></content>
      <categories>
        <category>ç®—æ³•</category>
        <category>Leetcode</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment2ä¹‹Pytorch]]></title>
    <url>%2F2019%2F05%2F07%2FCS231nassignment2Pytorch%2F</url>
    <content type="text"><![CDATA[è¿™éƒ¨åˆ†éœ€è¦åœ¨torchå’ŒTensorFlowä¸¤ä¸ªframeworké‡Œé¢é€‰ä¸€ä¸ªã€‚ PyTorchWhat åŠ å…¥äº†Tensorçš„objectï¼ˆç±»ä¼¼äºŽnarrayï¼‰ï¼Œä¸éœ€è¦æ‰‹åŠ¨çš„backpropäº† Why åœ¨GPUä¸Šé¢è·‘ï¼Œä¸éœ€è¦CUDAå°±å¯ä»¥åœ¨è‡ªå·±çš„GPUä¸Šé¢è·‘NN functionså¾ˆå¤š ç«™åœ¨å·¨äººçš„è‚©è†€ä¸Šï¼ åœ¨å®žé™…ä½¿ç”¨ä¸­åº”è¯¥å†™çš„æ·±åº¦å­¦ä¹ ä»£ç  å­¦ä¹ èµ„æ–™ Justin Johnson has made an excellenttutorial for PyTorch. DetailedAPI doc If you have other questions that are not addressed by the API docs, the PyTorch forum is a much better place to ask than StackOverflow. æ•´ä½“ç»“æž„ ç¬¬ä¸€éƒ¨åˆ†ï¼Œå‡†å¤‡ï¼Œä½¿ç”¨dataset ç¬¬äºŒéƒ¨åˆ†ï¼Œabstraction level1ï¼Œç›´æŽ¥åœ¨æœ€åº•å±‚çš„Tensorsä¸Šé¢æ“ä½œ ç¬¬ä¸‰éƒ¨åˆ†ï¼Œabstraction level2ï¼Œnn.Moduleå®šä¹‰ä¸€ä¸ªä»»æ„çš„NNç»“æž„ ç¬¬å››éƒ¨åˆ†ï¼Œabstraction level3ï¼Œnn.Sequentialï¼Œå®šä¹‰ä¸€ä¸ªç®€å•çš„çº¿æ€§feed - backç½‘ç»œ ç¬¬äº”éƒ¨åˆ†ï¼Œè‡ªå·±è°ƒå‚ï¼Œå°½é‡è®©CIFAR - 10çš„ç²¾åº¦å°½å¯èƒ½é«˜ Part 1.Preparationpytorché‡Œé¢æœ‰ä¸‹è½½datasetï¼Œé¢„å¤„ç†å¹¶ä¸”è¿­ä»£æˆminibatchçš„åŠŸèƒ½ import torchvision.transforms as T è¿™ä¸ªåŒ…åŒ…æ‹¬äº†é¢„å¤„ç†ä»¥åŠå¢žå¼ºdataçš„åŠŸèƒ½ï¼Œåœ¨è¿™é‡Œé€‰æ‹©äº†å‡åŽ»å¹³å‡çš„RGBå¹¶ä¸”é™¤ä»¥æ ‡å‡†å·® ç„¶åŽå¯¹ä¸åŒçš„éƒ¨åˆ†åˆ†åˆ«æž„å»ºäº†ä¸€ä¸ªdataset objectï¼ˆè®­ç»ƒï¼Œæµ‹è¯•ï¼Œvalï¼‰ï¼Œè¿™ä¸ªdatasetä¼šè½½å…¥ä¸€æ¬¡training exampleï¼Œå¹¶ä¸”åœ¨DataLoaderéƒ¨åˆ†æž„å»ºminibatch 1234567891011121314151617181920212223242526272829NUM_TRAIN = 49000# The torchvision.transforms package provides tools for preprocessing data# and for performing data augmentation; here we set up a transform to# preprocess the data by subtracting the mean RGB value and dividing by the# standard deviation of each RGB value; we've hardcoded the mean and std.transform = T.Compose([ T.ToTensor(), T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])# We set up a Dataset object for each split (train / val / test); Datasets load# training examples one at a time, so we wrap each Dataset in a DataLoader which# iterates through the Dataset and forms minibatches. We divide the CIFAR-10# training set into train and val sets by passing a Sampler object to the# DataLoader telling how it should sample from the underlying Dataset.cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True, transform=transform)loader_train = DataLoader(cifar10_train, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True, transform=transform)loader_val = DataLoader(cifar10_val, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, transform=transform)loader_test = DataLoader(cifar10_test, batch_size=64) éœ€è¦ä¸€ä¸ªæ˜¯å¦ä½¿ç”¨GPUçš„flagï¼Œå¹¶ä¸”setåˆ°trueã€‚åœ¨è¿™ä¸ªä½œä¸šé‡Œé¢ä¸æ˜¯å¿…é¡»ç”¨GPUè·‘ï¼Œä½†æ˜¯å¦‚æžœç”µè„‘ä¸èƒ½enableCUDAçš„è¯ï¼Œå°±ä¼šè‡ªåŠ¨è¿”å›žCPUæ¨¡å¼ã€‚ é™¤æ­¤ä¹‹å¤–ï¼Œå»ºç«‹äº†ä¸¤ä¸ªglobal varï¼Œdtypeä»£è¡¨float32ï¼Œdeviceä»£è¡¨ç”¨å“ªä¸ª å› ä¸ºmacæœ¬èº«ä¸æ”¯æŒCUDAï¼Œè€Œä¸”å¥½åƒæ–°ç‰ˆæœ¬çš„ç³»ç»Ÿè¿˜ä¸èƒ½å®‰è£…Nå¡çš„éƒ¨åˆ†ï¼Œæ‰€ä»¥çŽ°åœ¨ç”¨çš„CPU 12345678910111213USE_GPU = Truedtype = torch.float32 # we will be using float throughout this tutorialif USE_GPU and torch.cuda.is_available(): device = torch.device('cuda')else: device = torch.device('cpu')# Constant to control how frequently we print train lossprint_every = 100print('using device:', device) Part2 Barebones PyTorch è™½ç„¶æœ‰å¾ˆå¤šé«˜å±‚çš„APIå·²ç»æœ‰äº†å¾ˆå¤šåŠŸèƒ½ï¼Œä½†æ˜¯è¿™éƒ¨åˆ†ä»Žæ¯”è¾ƒåº•å±‚çš„éƒ¨åˆ†æ¥è¿›è¡Œ å»ºç«‹ä¸€ä¸ªç®€å•çš„fc - relu netï¼Œä¸¤ä¸ªä¸­é—´å±‚ï¼Œæ²¡æœ‰bias ç”¨Tensorçš„methodæ¥è®¡ç®—forwardï¼Œå¹¶ä¸”ç”¨è‡ªå¸¦çš„autogradæ¥è®¡ç®—back å¦‚æžœè®¾å®šäº†requires_grad = Trueï¼Œé‚£ä¹ˆåœ¨è®¡ç®—çš„æ—¶å€™ä¸ä»…ä¼šè®¡ç®—å€¼ï¼Œè¿˜ä¼šç”Ÿæˆè®¡ç®—backçš„graph if x is a Tensor with x.requires_grad == True then after backpropagation x.grad will be another Tensor holding the gradient of x with respect to the scalar loss at the end PyTorch Tensors: Flatten Function Tensorsæ˜¯ä¸€ä¸ªå’Œnarrayå¾ˆåƒçš„ä¸œè¥¿ï¼Œå®šä¹‰äº†å¾ˆå¤šæ¯”è¾ƒå¥½ç”¨çš„åŠŸèƒ½ï¼Œæ¯”å¦‚flattenæ¥reshape image data åœ¨Tensoré‡Œé¢ä¸€ä¸ªå›¾ç‰‡çš„å½¢çŠ¶æ˜¯NxCxHxW datapointçš„æ•°é‡ channels feature mapçš„Hå’ŒW ä½†æ˜¯åœ¨affineé‡Œé¢æˆ‘ä»¬å¸Œæœ›ä¸€ä¸ªdatapointå¯ä»¥è¡¨çŽ°æˆä¸€ä¸ªå•ç‹¬çš„vectorï¼Œè€Œä¸æ˜¯channelå’Œå®½å’Œé«˜ æ‰€ä»¥åœ¨è¿™é‡Œç”¨flattenæ¥é¦–å…ˆè¯»å–NCHWçš„æ•°æ®ï¼Œç„¶åŽè¿”å›žè¿™ä¸ªdataçš„viewï¼ˆç›¸å½“äºŽarrayé‡Œé¢çš„reshapeï¼ŒæŠŠå®ƒæ”¹æˆäº†Nxï¼Ÿï¼Ÿï¼Œå…¶ä¸­ï¼Ÿï¼Ÿå¯ä»¥æ˜¯ä»»ä½•å€¼ï¼‰ 123456def flatten(x): N = x.shape[0] # read in N, C, H, W # "flatten" the C * H * W values into a single vector per image return x.view(N, -1) Barebones PyTorch: Two-Layer Networkå½“å®šä¹‰ä¸€ä¸ª two_layer_fcçš„æ—¶å€™ï¼Œä¼šæœ‰ä¸¤å±‚çš„ä¸­é—´å¸¦reluçš„forwardï¼Œåœ¨å†™å¥½äº†forwardä¹‹åŽéœ€è¦ç¡®ä¿è¾“å‡ºçš„å½¢çŠ¶æ˜¯å¯¹çš„å¹¶ä¸”æ²¡æœ‰ä»€ä¹ˆé—®é¢˜(æœ€è¿‘å¥½åƒå¯¹è¿™ä¸ªå¤§å°å·²ç»æ²¡æœ‰ä»€ä¹ˆç–‘é—®äº†) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import torch.nn.functional as F # useful stateless functionsdef two_layer_fc(x, params): """ A fully-connected neural networks; the architecture is: NN is fully connected -&gt; ReLU -&gt; fully connected layer. Note that this function only defines the forward pass; PyTorch will take care of the backward pass for us. The input to the network will be a minibatch of data, of shape (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units, and the output layer will produce scores for C classes. Inputs: - x: A PyTorch Tensor of shape (N, d1, ..., dM) giving a minibatch of input data. - params: A list [w1, w2] of PyTorch Tensors giving weights for the network; w1 has shape (D, H) and w2 has shape (H, C). Returns: - scores: A PyTorch Tensor of shape (N, C) giving classification scores for the input data x. """ # first we flatten the image x = flatten(x) # shape: [batch_size, C x H x W] w1, w2 = params # Forward pass: compute predicted y using operations on Tensors. Since w1 and # w2 have requires_grad=True, operations involving these Tensors will cause # PyTorch to build a computational graph, allowing automatic computation of # gradients. Since we are no longer implementing the backward pass by hand we # don't need to keep references to intermediate values. # you can also use `.clamp(min=0)`, equivalent to F.relu() x = F.relu(x.mm(w1)) x = x.mm(w2) return xdef two_layer_fc_test(): hidden_layer_size = 42 # minibatch size 64, feature dimension 50 x = torch.zeros((64, 50), dtype=dtype) w1 = torch.zeros((50, hidden_layer_size), dtype=dtype) w2 = torch.zeros((hidden_layer_size, 10), dtype=dtype) scores = two_layer_fc(x, [w1, w2]) print(scores.size()) # you should see [64, 10]two_layer_fc_test() Barebones PyTorch: Three-Layer ConvNet ä¸Šä¸‹è¿™ä¸¤ä¸ªéƒ½æ˜¯ï¼Œåœ¨æµ‹è¯•çš„æ—¶å€™å¯ä»¥ç›´æŽ¥pass 0æ¥æµ‹è¯•tensorçš„å¤§å°æ˜¯ä¸æ˜¯å¯¹çš„ ç½‘ç»œçš„ç»“æž„ conv with biasï¼Œchannel_1 filtersï¼ŒKW1xKH1ï¼Œ2 zero - padding RELU conv with biasï¼Œchannel_2 filtersï¼ŒKW2xKH2ï¼Œ1 zero - padding RELU fc with biasï¼Œè¾“å‡ºC class æ³¨æ„ï¼åœ¨è¿™é‡Œfcä¹‹åŽæ²¡æœ‰softmaxçš„æ¿€æ´»å±‚ï¼Œå› ä¸ºåœ¨åŽé¢è®¡ç®—lossçš„æ—¶å€™ä¼šæä¾›softmaxï¼Œè®¡ç®—èµ·æ¥æ›´åŠ æœ‰æ•ˆçŽ‡ æ³¨æ„2ï¼åœ¨conv2dä¹‹å‰ä¸éœ€è¦flattenï¼Œåœ¨fcä¹‹å‰æ‰éœ€è¦flatten 123456789101112131415161718192021222324252627282930313233343536373839404142434445def three_layer_convnet(x, params): """ Performs the forward pass of a three-layer convolutional network with the architecture defined above. Inputs: - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images - params: A list of PyTorch Tensors giving the weights and biases for the network; should contain the following: - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights for the first convolutional layer - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first convolutional layer - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving weights for the second convolutional layer - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second convolutional layer - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you figure out what the shape should be? (N,channel_2*H*W) - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you figure out what the shape should be? (C,) Returns: - scores: PyTorch Tensor of shape (N, C) giving classification scores for x """ conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params scores = None ################################################################################ # TODO: Implement the forward pass for the three-layer ConvNet. # ################################################################################ # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x = nn.functional.conv2d(x, conv_w1, bias=conv_b1, padding=2) x = nn.functional.conv2d(F.relu(x), conv_w2, bias=conv_b2, padding=1) x = flatten(x) x = x.mm(fc_w) + fc_b scores = x # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ################################################################################ # END OF YOUR CODE # ################################################################################ return scores Barebones PyTorch: Initialization random_weight(shape) initializes a weight tensor with the Kaiming normalization method. -&gt; ä½¿ç”¨äº†KAIMING normal zero_weight(shape) initializes a weight tensor with all zeros. Useful for instantiating bias parameters. 123456789101112131415161718192021222324252627def random_weight(shape): """ Create random Tensors for weights; setting requires_grad=True means that we want to compute gradients for these Tensors during the backward pass. We use Kaiming normalization: sqrt(2 / fan_in) """ if len(shape) == 2: # FC weight fan_in = shape[0] else: # conv weight [out_channel, in_channel, kH, kW] fan_in = np.prod(shape[1:]) # randn is standard normal distribution generator. w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in) w.requires_grad = True return wdef zero_weight(shape): return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)# create a weight of shape [3 x 5]# you should see the type `torch.cuda.FloatTensor` if you use GPU.# Otherwise it should be `torch.FloatTensor`random_weight((3, 5)) Barebones PyTorch: Check Accuracy åœ¨è¿™éƒ¨åˆ†ä¸éœ€è¦è®¡ç®—gradï¼Œæ‰€ä»¥è¦å…³ä¸Štorch.no_grad()é¿å…æµªè´¹ è¾“å…¥ ä¸€ä¸ªDataLoaderæ¥ç»™æˆ‘ä»¬æƒ³è¦checkçš„dataåˆ†å— ä¸€ä¸ªè¡¨ç¤ºæ¨¡åž‹åˆ°åº•æ˜¯ä»€ä¹ˆæ ·å­çš„model_fnï¼Œæ¥è®¡ç®—é¢„æµ‹çš„scores è¿™ä¸ªmodeléœ€è¦çš„å‚æ•° æ²¡æœ‰è¿”å›žå€¼ä½†æ˜¯ä¼šprintå‡ºæ¥acc 12345678910111213141516171819202122232425262728def check_accuracy_part2(loader, model_fn, params): """ Check the accuracy of a classification model. Inputs: - loader: A DataLoader for the data split we want to check - model_fn: A function that performs the forward pass of the model, with the signature scores = model_fn(x, params) - params: List of PyTorch Tensors giving parameters of the model Returns: Nothing, but prints the accuracy of the model """ split = 'val' if loader.dataset.train else 'test' print('Checking accuracy on the %s set' % split) num_correct, num_samples = 0, 0 with torch.no_grad(): for x, y in loader: x = x.to(device=device, dtype=dtype) # move to device, e.g. GPU y = y.to(device=device, dtype=torch.int64) scores = model_fn(x, params) _, preds = scores.max(1) num_correct += (preds == y).sum() num_samples += preds.size(0) acc = float(num_correct) / num_samples print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc)) BareBones PyTorch: Training Loop ç”¨stochastic gradient descent without momentumæ¥trainï¼Œå¹¶ä¸”ç”¨torch.functional.cross_entropyæ¥è®¡ç®—loss è¾“å…¥ model_fc params learning_rate æ²¡æœ‰è¾“å‡º è¿›è¡Œçš„æ“ä½œ æŠŠdataç§»åŠ¨åˆ°GPUæˆ–è€…CPU è®¡ç®—scoreå’Œloss loss.backward() update paramsï¼Œè¿™éƒ¨åˆ†ä¸éœ€è¦è®¡ç®—grad BareBones PyTorch: Training a ConvNet éœ€è¦ç½‘ç»œ Convolutional layer(with bias) with 32 5x5 filters, with zero - padding of 2 ReLU Convolutional layer(with bias) with 16 3x3 filters, with zero - padding of 1 ReLU Fully - connected layer(with bias) to compute scores for 10 classes éœ€è¦è‡ªå·±åˆå§‹åŒ–å‚æ•°ï¼Œä¸éœ€è¦tune hypers æ³¨æ„1ï¼šfcçš„wçš„å¤§å°æ˜¯D,Cï¼Œè·Ÿæ•°æ®æ— å…³éœ€è¦ä»Žä¸Šä¸€å±‚çš„è¾“å‡ºæ±‚ convä¹‹åŽçš„å›¾ç‰‡å¤§å°ä»Ž32-&gt; 30 12345678910111213141516171819202122232425262728293031learning_rate = 3e-3channel_1 = 32channel_2 = 16conv_w1 = Noneconv_b1 = Noneconv_w2 = Noneconv_b2 = Nonefc_w = Nonefc_b = None################################################################################# TODO: Initialize the parameters of a three-layer ConvNet. ################################################################################## *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****conv_w1 = random_weight((channel_1, 3, 5, 5))conv_b1 = zero_weight(channel_1)conv_w2 = random_weight((channel_2, channel_1, 5, 5))conv_b2 = zero_weight(channel_2)fc_w = random_weight((channel_2 * 30 * 30, 10))fc_b = zero_weight(10)# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****################################################################################# END OF YOUR CODE #################################################################################params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]train_part2(three_layer_convnet, params, learning_rate) Part3 PyTorch Module API ä¸Šé¢çš„æ‰€æœ‰è¿‡ç¨‹æ˜¯æ‰‹ç®—æ¥trackæ•´ä¸ªè¿‡ç¨‹çš„ï¼Œä½†æ˜¯åœ¨æ›´å¤§çš„neté‡Œé¢å°±æ²¡æœ‰ä»€ä¹ˆç”¨äº† nn.Moduleæ¥å®šä¹‰ç½‘ç»œï¼Œå¹¶ä¸”å¯ä»¥é€‰optmiçš„æ–¹æ³• Subclass nn.Module. Give your network class an intuitive name like TwoLayerFC. __init__()é‡Œé¢å®šä¹‰è‡ªå·±éœ€è¦çš„æ‰€æœ‰å±‚. nn.Linear and nn.Conv2d éƒ½åœ¨æ¨¡å—é‡Œè‡ªå¸¦äº†. nn.Module will track these internal parameters for you. Refer to the doc to learn more about the dozens of builtin layers. Warning: donâ€™t forget to call the super().__init__() first!ï¼ˆè°ƒç”¨çˆ¶ç±»ï¼‰ In the forward() method, define the connectivity of your network. ç›´æŽ¥ç”¨inité‡Œé¢åˆå§‹åŒ–å¥½çš„æ–¹æ³•æ¥forwardï¼Œä¸è¦å†forwardé‡Œé¢å¢žåŠ æ–°çš„æ–¹æ³• ç”¨ä¸Šé¢çš„æ–¹æ³•æ¥å†™ä¸€ä¸ªä¸‰å±‚çš„layer æ³¨æ„éœ€è¦åˆå§‹åŒ–wå’Œbçš„å‚æ•°ï¼Œç”¨kaimingçš„æ–¹æ³• 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class ThreeLayerConvNet(nn.Module): def __init__(self, in_channel, channel_1, channel_2, num_classes): super().__init__() ######################################################################## # TODO: Set up the layers you need for a three-layer ConvNet with the # # architecture defined above. # ######################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** self.conv_1 = nn.Conv2d(in_channel,channel_1,5,stride=1, padding=2,bias=True) nn.init.kaiming_normal_(self.conv_1.weight) nn.init.constant_(self.conv_1.bias, 0) self.conv_2 = nn.Conv2d(channel_1,channel_2,3,stride=1, padding=1,bias=True) nn.init.kaiming_normal_(self.conv_2.weight) nn.init.constant_(self.conv_2.bias, 0) self.fc_3 = nn.Linear(channel_2 * 32 * 32 , num_classes) nn.init.kaiming_normal_(self.fc_3.weight) nn.init.constant_(self.fc_3.bias, 0) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ######################################################################## # END OF YOUR CODE # ######################################################################## def forward(self, x): scores = None ######################################################################## # TODO: Implement the forward function for a 3-layer ConvNet. you # # should use the layers you defined in __init__ and specify the # # connectivity of those layers in forward() # ######################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x = self.conv_1(x) x = self.conv_2(F.relu(x)) x = flatten(F.relu(x)) x = self.fc_3(x) scores = x # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ######################################################################## # END OF YOUR CODE # ######################################################################## return scoresdef test_ThreeLayerConvNet(): x = torch.zeros((64, 3, 32, 32), dtype=dtype) # minibatch size 64, image size [3, 32, 32] model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=8, num_classes=10) scores = model(x) print(scores.size()) # you should see [64, 10]test_ThreeLayerConvNet() Module API: Check Accuracy ä¸ç”¨æ‰‹åŠ¨passå‚æ•°äº†ï¼Œç›´æŽ¥å°±å¯ä»¥å¾—åˆ°æ•´ä¸ªnetçš„acc Module API: Training Loop ç”¨optimizerè¿™ä¸ªobjectæ¥update weights è¾“å…¥ model optimizer epochï¼Œå¯é€‰ æ²¡æœ‰returnï¼Œä½†æ˜¯ä¼šæ‰“å°å‡ºæ¥trainingæ—¶å€™çš„acc å…¶å®žå°±æ˜¯è®¾ç½®å¥½modelå’Œoptimizerå°±å¯ä»¥äº† Part4 PyTorch Sequential API nn.Sequentialæ²¡æœ‰ä¸Šé¢çš„çµæ´»ï¼Œä½†æ˜¯å¯ä»¥é›†æˆä¸Šé¢çš„ä¸€ä¸²åŠŸèƒ½ éœ€è¦æå‰å®šä¹‰ä¸€ä¸ªåœ¨forwardé‡Œé¢èƒ½ç”¨çš„flatten 123456789101112131415161718192021# We need to wrap `flatten` function in a module in order to stack it# in nn.Sequentialclass Flatten(nn.Module): def forward(self, x): return flatten(x)hidden_layer_size = 4000learning_rate = 1e-2model = nn.Sequential( Flatten(), nn.Linear(3 * 32 * 32, hidden_layer_size), nn.ReLU(), nn.Linear(hidden_layer_size, 10),)# you can use Nesterov momentum in optim.SGDoptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)train_part34(model, optimizer) å®žçŽ°ä¸‰å±‚ï¼Œæ³¨æ„éœ€è¦åˆå§‹åŒ–å‚æ•° è¿™é‡Œé‡åˆ°äº†ä¸€ä¸ªé—®é¢˜æ˜¯å½“ç”¨random_weightå®žçŽ°çš„æ—¶å€™ï¼Œaccä¼šç‰¹åˆ«ä½Ž ä»Žè¿™é‡Œå‘çŽ°å¯ä»¥é‡æ–°å®šä¹‰å¦ä¸€ä¸ªè®¡ç®—æ–¹æ³•ä¸åŒçš„weights ä»Žè¿™é‡Œå¾—çŸ¥å¦‚ä½•ç»™moduleå¢žåŠ æ–°çš„function 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657def xavier_normal(shape): """ Create random Tensors for weights; setting requires_grad=True means that we want to compute gradients for these Tensors during the backward pass. We use Xavier normalization: sqrt(2 / (fan_in + fan_out)) """ if len(shape) == 2: # FC weight fan_in = shape[1] fan_out = shape[0] else: fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW] fan_out = shape[0] * shape[2] * shape[3] # randn is standard normal distribution generator. w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / (fan_in + fan_out)) w.requires_grad = True return wchannel_1 = 32channel_2 = 16learning_rate = 1e-2model = Noneoptimizer = None################################################################################# TODO: Rewrite the 2-layer ConvNet with bias from Part III with the ## Sequential API. ################################################################################## *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****model = nn.Sequential( nn.Conv2d(3, channel_1,5,stride = 1,padding = 2), nn.ReLU(), nn.Conv2d(channel_1, channel_2,3,stride = 1,padding = 1), nn.ReLU(), Flatten(), nn.Linear(32*32*channel_2, 10),)def init_weights(m): print(m) if type(m) == nn.Linear: m.weight.data = xavier_normal(m.weight.size()) m.bias.data = zero_weight(m.bias.size())model.apply(init_weights)optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****################################################################################# END OF YOUR CODE ################################################################################train_part34(model, optimizer) Part5 æ¥è®­ç»ƒCIFAR-10å§ï¼è‡ªå·±æ‰¾netçš„ç»“æž„ï¼Œhyperï¼Œlossï¼Œoptimizersæ¥æŠŠCIFAR-10çš„val_accåœ¨10ä¸ªepochä¹‹å†…å‡åˆ°70%ä»¥ä¸Šï¼ Layers in torch.nn package: http://pytorch.org/docs/stable/nn.html Activations: http://pytorch.org/docs/stable/nn.html#non-linear-activations Loss functions: http://pytorch.org/docs/stable/nn.html#loss-functions Optimizers: http://pytorch.org/docs/stable/optim.html ä¸€äº›å¯èƒ½çš„æ–¹æ³•ï¼š Filter size: Above we used 5x5; would smaller filters be more efficient? Number of filters: Above we used 32 filters. Do more or fewer do better? Pooling vs Strided Convolution: Do you use max pooling or just stride convolutions? Batch normalization: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster? Network architecture: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include: [conv-relu-pool]xN -&gt; [affine]xM -&gt; [softmax or SVM] [conv-relu-conv-relu-pool]xN -&gt; [affine]xM -&gt; [softmax or SVM] [batchnorm-relu-conv]xN -&gt; [affine]xM -&gt; [softmax or SVM] Global Average Pooling: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in Googleâ€™s Inception Network (See Table 1 for their architecture). Regularization: Add l2 weight regularization, or perhaps use Dropout. ä¸€äº›tipsï¼š åº”è¯¥ä¼šåœ¨å‡ ç™¾ä¸ªiteré‡Œé¢å°±çœ‹åˆ°è¿›æ­¥ï¼Œå¦‚æžœparams work well tune hyperçš„æ—¶å€™ä»Žä¸€å¤§ç‰‡rangeå’Œå°çš„trainå¼€å§‹ï¼Œæ‰¾åˆ°å¥½ä¸€äº›çš„ä¹‹åŽå†å›´ç»•è¿™ä¸ªèŒƒå›´æ‰¾ï¼ˆå¤šè®­ä¸€ç‚¹ï¼‰ åœ¨æ‰¾hyperçš„æ—¶å€™åº”è¯¥ç”¨val set 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647model = Noneoptimizer = None# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****channel_1 = 16channel_2 = 32channel_3 = 64channel_4 = 64fc_1 = 1024num_classes = 10model = nn.Sequential( nn.Conv2d(3, channel_1,3,stride = 1,padding = 1), nn.BatchNorm2d(channel_1), nn.ReLU(), nn.MaxPool2d(kernel_size = 2), nn.Conv2d(channel_1, channel_2,3,stride = 1,padding = 1), nn.BatchNorm2d(channel_2), nn.ReLU(), nn.MaxPool2d(kernel_size = 2), nn.Conv2d(channel_2, channel_3,3,stride = 1,padding = 1), nn.BatchNorm2d(channel_3), nn.ReLU(), nn.Conv2d(channel_3, channel_4,3,stride = 1,padding = 1), nn.BatchNorm2d(channel_4), nn.ReLU(), nn.MaxPool2d(kernel_size = 2), Flatten(), nn.Linear(4*4*channel_4, num_classes)# nn.Linear(fc_1,num_classes) )learning_rate = 1e-3optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****################################################################################# END OF YOUR CODE ################################################################################# You should get at least 70% accuracytrain_part34(model, optimizer, epochs=10) ç¬¬å››å±‚convè¯•è¿‡ksize=1ï¼Œæ•ˆæžœä¸æ˜¯å¾ˆå¥½ BNå¥½åƒæ•ˆæžœå¾ˆå¥½ maxpoolå¤šä¸€äº›ï¼Œè®¡ç®—è´Ÿæ‹…å°‘è€Œä¸”æ•ˆæžœå¥½åƒæ¯”è¾ƒå¥½ æœ€ç»ˆval_accåœ¨77-79å·¦å³ï¼Œtest_acc = 76.22]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
        <category>CS231nä½œä¸š</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽpythonç”ŸæˆåŠ¨æ€å˜é‡å]]></title>
    <url>%2F2019%2F05%2F07%2F%E5%85%B3%E4%BA%8Epython%E7%94%9F%E6%88%90%E5%8A%A8%E6%80%81%E5%8F%98%E9%87%8F%E5%90%8D%2F</url>
    <content type="text"><![CDATA[åŠ¨æ€ç”Ÿæˆå˜é‡åå¦‚æžœæƒ³è¦ç”Ÿæˆä¸€ç³»åˆ—çš„a0ï¼Œa1ï¼Œâ€¦.a20è¿™ç§å˜é‡åï¼Œç›´æŽ¥æ‰‹å†™å¤ªéº»çƒ¦äº† localslocal()ï¼Œä»¥å­—å…¸çš„ç±»åž‹è¿”å›žå½“å‰ä½ç½®çš„å…¨éƒ¨å±€éƒ¨å˜é‡ 1234arrange_list = locals()for i in range(10): arrange_list['list_' + str(i)] = [] è°ƒç”¨åŠ¨æ€å˜é‡ï¼Œå¯ä»¥ç”¨å­—å…¸çš„getæ–¹æ³•å¾—åˆ°å˜é‡çš„å€¼ 1234arrange_list = locals()for i in range(10): print(arrange_list.get('var'+str(i)), end = " ") åˆ©ç”¨execè¿›è¡Œèµ‹å€¼12for i in range(5): exec('var&#123;&#125; = &#123;&#125;'.format(i, i)) è°ƒç”¨åŠ¨æ€å˜é‡12for i in range(5): exec('print(var&#123;&#125;, end = " ")'.format(i))]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>åŠ¨æ€ç”Ÿæˆå˜é‡å</tag>
        <tag>å˜é‡å</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽå¤šç»´æ•°ç»„çš„è½¬ç½®å’Œå¢žåŠ æ–°çš„ç»´åº¦]]></title>
    <url>%2F2019%2F04%2F25%2F%E5%85%B3%E4%BA%8E%E5%A4%9A%E7%BB%B4%E6%95%B0%E7%BB%84%E7%9A%84%E8%BD%AC%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[åœ¨äºŒç»´è½¬ç½®çš„æ—¶å€™ï¼Œa[i][j] = a[j][i]åœ¨å¤šç»´æ•°ç»„è½¬ç½®çš„æ—¶å€™ï¼Œéœ€è¦äº¤æ¢ä»–ä»¬çš„ä¸‹æ ‡æ¯”å¦‚åŽŸæ¥çš„æ•°ç»„æ˜¯(X,Y,Z)ï¼Œè½¬ç½®ä¹‹åŽæ˜¯(Z,X,Y)è¿™æ—¶å€™åº”è¯¥ç”¨çš„æ˜¯np.transpose(A,(2,0,1)) np.newaxis -&gt; å¢žåŠ æ–°çš„ç»´åº¦åŽŸæ¥æ˜¯ï¼ˆ6ï¼Œï¼‰çš„æ•°ç»„ï¼Œåœ¨è¡Œä¸Šå¢žåŠ ç»´åº¦å˜æˆï¼ˆ1,6ï¼‰çš„äºŒç»´æ•°ç»„ï¼Œåœ¨åˆ—ä¸Šå¢žåŠ ç»´åº¦å˜ä¸º(6,1)çš„äºŒç»´æ•°ç»„]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>narray</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å­¦ä¹ OpenCVåå…«ç« _Camera models & calibration]]></title>
    <url>%2F2019%2F04%2F22%2FOpenCVCameracalibration%2F</url>
    <content type="text"><![CDATA[camera models &amp; calibrationç‰©ä½“ä¼šå¸æ”¶ä¸€éƒ¨åˆ†çš„å…‰ï¼Œç„¶åŽåå°„ä¸€éƒ¨åˆ†çš„å…‰ï¼Œåå°„çš„å…‰å°±æ˜¯ä»–è‡ªå·±çš„é¢œè‰²ï¼Œè¿™ä¸ªå…‰è¢«æˆ‘ä»¬çš„çœ¼ç›ï¼ˆæˆ–è€…ç›¸æœºï¼‰æŽ¥æ”¶ï¼Œç„¶åŽæŠ•å½±åˆ°æˆ‘ä»¬çš„è§†ç½‘è†œï¼ˆæˆ–è€…ç›¸æœºçš„å›¾ç‰‡ï¼‰ä¸Šï¼Œè¿™ä¹‹é—´çš„å‡ ä½•å…³ç³»åœ¨CVä¸Šé¢éžå¸¸é‡è¦ å…¶ä¸­ä¸€ä¸ªéžå¸¸ç®€å•çš„æ¨¡åž‹å°±æ˜¯pinhole camera modelã€‚å…‰ç©¿è¿‡ä¸€é¢å¢™ä¸Šçš„ä¸€ä¸ªå°çš„apertureï¼Œè¿™ä¸ªæ˜¯è¿™ç« çš„æ¨¡åž‹çš„å¼€å§‹ï¼Œä½†æ˜¯çœŸå®žpinholeæ¨¡åž‹ä¸æ˜¯å¾ˆå¥½å› ä¸ºä»–ä¸èƒ½å¿«é€Ÿæ›å…‰ï¼ˆèšé›†çš„å…‰ä¸å¤Ÿï¼‰-&gt; çœ¼ç›ä¼šæ›´åŽ‰å®³ä¸€ç‚¹ï¼Œä½†æ˜¯lenè¿˜ä¼šdistortå›¾ç‰‡ã€‚ è¿™ç« çš„ç›®çš„ï¼š å¦‚ä½•camera calibration çº æ­£æ™®é€šçš„pinholeæ¨¡åž‹çš„lençš„åå·® calibrationä¹ŸåŒæ ·æ˜¯èŽ·å–ä¸‰ç»´ä¸–ç•Œçš„ä¸»è¦æ–¹å¼ï¼Œå› ä¸ºä¸€ä¸ªåœºæ™¯ä¸ä»…ä»…æ˜¯ä¸‰ç»´ï¼Œä»–ä»¬è¿˜æœ‰ç‰©ç†çš„ç©ºé—´å’Œä½“ç§¯ï¼Œæ‰€ä»¥èŽ·å–pixelå’Œä¸‰ç»´è¯—å¥åæ ‡çš„å…³ç³»ä¹Ÿå¾ˆé‡è¦ 18ç« çº æ­£çš„æ˜¯lençš„distortionï¼Œ19ç« æž„å»ºæ•´ä¸ª3Dçš„ç»“æž„ homography transform -&gt; ä¸€ä¸ªéžå¸¸é‡è¦çš„è¦ç´  camera model æŠ•å½±åˆ°image planeä¸Šé¢ï¼Œç»“æžœåœ¨è¿™ä¸ªplaneä¸Šé¢æ€»æ˜¯å¯¹ç„¦çš„focusï¼Œå›¾ç‰‡çš„å¤§å°å’Œè¿™ä¸ªç„¦è·çš„é•¿åº¦æœ‰å…³ å¯¹äºŽç†æƒ³çš„pinholeæ¥è¯´ï¼Œimage planeåˆ°pinholeçš„è·ç¦»å°±æ˜¯å‡†ç¡®çš„ç„¦è· ä»Žè¿™ä¸ªåŸºç¡€çš„æ¨¡åž‹ä¸Š -&gt; å¾—åˆ°ä¸€ä¸ªè®¡ç®—èµ·æ¥æ›´åŠ ç®€å•çš„æ¨¡åž‹ äº¤æ¢pinholeå’Œprojection planeçš„ä½ç½® çŽ°åœ¨pinholeçš„ä½ç½®å˜æˆäº†projective planeçš„ä¸­å¿ƒ æ¯ä¸€ä¸ªç¦»å¼€ç‰©ä½“è¡¨é¢ï¼ˆQï¼‰çš„å…‰çº¿éƒ½æœç€projection centerèµ° åœ¨æ¨ªè½´å’ŒæŠ•å½±é¢ä¸Šçš„äº¤ç‚¹è¢«å®šä¹‰ä¸ºprincipal point è¿™ä¸ªæ–°çš„å¹³é¢å’Œä»¥å‰çš„projectiveå¹³é¢ä¸€æ ·ï¼Œä¸Šé¢æŠ•å½±ä¸Šçš„ç‰©ä½“ä¹Ÿéƒ½æ˜¯å’ŒåŽŸæ¥ä¸€æ ·çš„å°ºå¯¸ æ¢äº†æ¨¡åž‹ä¹‹åŽæ²¡æœ‰äº†è´Ÿå·ï¼šx/f = X/Z åœ¨ç†æƒ³çš„æ¨¡åž‹é‡Œå¯èƒ½è§‰å¾—è¿™ä¸ªprincipal pointå°±æ˜¯imageçš„ä¸­å¿ƒï¼Œä½†æ˜¯å®žé™…ä¸Šä¸­å¿ƒä¸ä¼šåœ¨æ¨ªè½´å’ŒæŠ•å½±é¢çš„äº¤ç‚¹ä¸Š å¼•å…¥äº†ä¸¤ä¸ªæ–°çš„å‚æ•° cx å’Œ cy è¿™ä¸¤ä¸ªå‚æ•°å®žé™…ä¸Šå°±æ˜¯ä¸­å¿ƒç‚¹çš„åå·®ï¼ˆå¹³é¢ä¸Šçš„åå·®ï¼‰ï¼Œæ‰€ä»¥å¾—åˆ°æŠ•å½±åœ¨image planeä¸Šé¢çš„å®žé™…åæ ‡å¦‚ä¸‹ åœ¨ä¸Šé¢çš„å…¬å¼é‡Œé¢ç”¨äº†ä¸¤ä¸ªä¸åŒçš„fï¼Œfxå’Œfyï¼Œè¿™æ˜¯å› ä¸º åœ¨å®žé™…çš„å›¾ç‰‡é‡Œæ¥è¯´ï¼Œå…¶å®žæ¯ä¸ªåƒç´ æ ¼ä¸æ˜¯æ­£æ–¹å½¢è€Œæ˜¯é•¿æ–¹å½¢çš„ fx = å®žé™…çš„focal length * sxï¼ˆæ¯ä¸ªmmé‡Œé¢çš„åƒç´ æ•°é‡ï¼‰ -&gt; æœ€ç»ˆå¾—åˆ°çš„fxæ˜¯åƒç´ æ ¼ æ³¨æ„ï¼š sxå’Œsyåœ¨calibrationçš„æ—¶å€™å¹¶ä¸èƒ½ç›´æŽ¥æµ‹é‡ physical focal lengthä¹Ÿä¸èƒ½è¢«å®žé™…æµ‹é‡ æˆ‘ä»¬åªèƒ½å¾—åˆ°è¿™ä¸¤ä¸ªä¸œè¥¿çš„ä¹˜ç§¯ï¼Œf basic of projective geometry projective transform -&gt; æŠŠphysical worldé‡Œé¢çš„ä¸€ç»„ç‚¹Qiï¼ˆXi,Yi,Ziï¼‰mapåˆ°ä¸€å¼ å›¾ç‰‡ä¸Šé¢(xi,yi)çš„è¿‡ç¨‹ ç”¨è¿™ä¸ªä¸œè¥¿çš„æ—¶å€™ï¼Œä¸€ä¸ªæ¯”è¾ƒæ–¹ä¾¿çš„æ–¹æ³•æ˜¯ç”¨homogeneous coordinates associâ€ ated with a point in a projective space of dimension n are typically expressed as an (n + 1)-dimensional vector (e.g., x, y, z becomes x, y, z, w), with the additional restricâ€ tion that any two points whose values are proportional are, in fact, equivalent points æŠ•å½±å¹³é¢ä¸Šé¢çš„ç»´åº¦æ˜¯ä¸¤ç»´ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå®ƒè¡¨ç¤ºæˆä¸‰ç»´çš„ä¸œè¥¿ -&gt; æŠŠçŽ°åœ¨å­˜åœ¨ç»´åº¦çš„æ•°å­—é™¤ä»¥å¢žåŠ çš„ç»´åº¦çš„å€¼å°±å¯ä»¥å¾—åˆ°ä»¥å‰çš„å€¼ ç”¨è¿™ç§åŠžæ³•ï¼Œå¯ä»¥æŠŠä¹‹å‰çš„fxï¼Œfy,cx,cyé‡æ–°ç»„ç»‡æˆä¸€ä¸ªçŸ©é˜µï¼šcamera intrinsics matrix ä¸‹é¢è¿™ä¸ªå½¢å¼é‡æ–°ä¹˜å›žæ¥å°±æ˜¯ä¹‹å‰çš„å…³ç³» åœ¨opencvé‡Œé¢ä¹Ÿæœ‰å¾—åˆ°homogeneous coordinateså’Œç”±ç»“æžœåæŽ¨å›žæ¥çš„å‡½æ•° æ³¨æ„ï¼Œåœ¨pinholeé‡Œé¢çš„æˆåƒé€Ÿåº¦æ˜¯éžå¸¸æ…¢çš„ï¼Œå¦‚æžœéœ€è¦æ›´å¿«é€Ÿåœ°å½¢æˆå›¾ç‰‡ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡lensæ¥èšç„¦éžå¸¸å¹¿èŒƒå›´é‡Œé¢çš„å…‰ -&gt; ä½†æ˜¯ç»“æžœå°±æ˜¯lensä¼šäº§ç”Ÿdistortion Rodrigues Transform åœ¨ä¸‰ç»´çš„èŒƒå›´é‡Œï¼Œç»å¸¸ä¼šä½¿ç”¨ä¸€ä¸ª3x3çš„çŸ©é˜µæ¥è¡¨ç¤ºä¸€ä¸ªç‰©ä½“çš„æ—‹è½¬ åªè¦æŠŠéœ€è¦æ—‹è½¬çš„vectorä¹˜ä¸Šè¿™ä¸ªmatå°±å¯ä»¥å¾—åˆ°ç›¸åº”çš„ç»“æžœ ä½†æ˜¯ä¸æ˜¯å¾ˆå¥½ç›´è§‚çš„å¾—åˆ°è¿™ä¸ªæ—‹è½¬çŸ©é˜µ ä»‹ç»ä¸€ç§åœ¨opencvé‡Œé¢çš„è¡¨ç¤ºæ–¹æ³• -&gt; æ›´å®¹æ˜“ç›´è§‚çš„ç†è§£æ„æ€ æœ¬è´¨ä¸Šæ¥è¯´å°±æ˜¯ç”¨ä¸€ä¸ªvectorè¡¨ç¤ºæ¯ä¸ªè§’åº¦ä¸Šéœ€è¦æ—‹è½¬å¤šå°‘ Rodrigues TransformæŒ‡çš„å°±æ˜¯çŸ©é˜µè¡¨ç¤ºæ³•å’Œå‘é‡è¡¨ç¤ºæ³•ä¹‹é—´çš„å…³ç³» æ•°å­¦åŽŸç†ï¼šä½™å¼¦å®šç†ï¼Ÿï¼ˆçŸ¥é“ä¸¤ä¸ªå‘é‡å¯ä»¥æ±‚å‡ºæ¥ä»–ä»¬ä¹‹é—´çš„è§’åº¦ï¼‰ è¿™ä¸¤ä¸ªå…³ç³»ä¹‹é—´å¯ä»¥å¾ˆè½»æ˜“çš„äº’ç›¸è½¬åŒ–ï¼Œopencvé‡Œé¢ä¹Ÿæœ‰ç›¸åº”çš„åº“ lens distortion åœ¨å®žé™…ä½¿ç”¨ä¸­å› ä¸ºåˆ¶é€ çƒå½¢çš„é•œå¤´æ›´å®¹æ˜“ä¸€äº›ï¼Œå¹¶ä¸”å¾ˆéš¾æµ‹é‡æ˜¯ä¸æ˜¯å¹³çš„ï¼Œæ‰€ä»¥lenséƒ½ä¼šäº§ç”Ÿdistortion åœ¨è¿™éƒ¨åˆ†ä»‹ç»äº†ä¸¤ç§ä¸»è¦å¾—distortionï¼Œhow to model radial distortion -&gt; é•œç‰‡çš„å½¢çŠ¶äº§ç”Ÿçš„ tangential distortion -&gt; ç»„è£…æ•´ä¸ªç›¸æœºçš„æ—¶å€™äº§ç”Ÿçš„ radial ç›¸æœºçš„distortionä¸€èˆ¬éƒ½ä¼šäº§ç”Ÿåœ¨æŽ¥è¿‘imagerè¾¹ç¼˜çš„éƒ¨åˆ†ï¼ˆfisheye effectï¼‰ è¿œç¦»lensä¸­å¿ƒçš„éƒ¨åˆ†æ¯”èµ·ä¸­å¿ƒéƒ¨åˆ†ä¼šæŠ˜å æ›´å¤šï¼Œæ‰€ä»¥å¦‚æžœæŠ•å½±ä¸€ä¸ªæ­£æ–¹å½¢ï¼Œè¾¹çš„éƒ¨åˆ†éƒ½ä¼šé¼“èµ·æ¥ å¦‚æžœç›¸æœºæ¯”è¾ƒä¾¿å®œçš„è¯ï¼ˆweb cameraï¼‰ï¼Œå‘¨å›´çš„æŠ˜å ä¼šæ›´å¤šï¼Œè€Œå¥½çš„ç›¸æœºä¼šæ›´æ³¨é‡å‡å°‘radial distortionçš„æ•ˆæžœ å¯¹äºŽè¾å°„çš„ç•¸å˜æ¥è¯´ï¼Œdistortionä¼šéšç€æŽ¥è¿‘è¾¹è¾¹è€Œå¢žåŠ  åœ¨å®žé™…ä¸­è¿™ä¸ªç•¸å˜å¾ˆå°ï¼Œæ‰€ä»¥å¯ä»¥ç”¨æ³°å‹’çº§æ•°çš„r=0é™„è¿‘å±•å¼€æ¥è§£å†³ å¯¹äºŽæ¯”è¾ƒä¾¿å®œçš„web cameraï¼Œå¯ä»¥é€‰ç”¨k1æˆ–è€…k2 å¯¹äºŽé±¼çœ¼è¿™ç§ç•¸å˜å¾ˆå¤§çš„ï¼Œå¯ä»¥ç”¨k3 åœ¨distortä¹‹åŽçš„ä½ç½®å¯ä»¥ç”¨ä»¥ä¸‹çš„å…¬å¼è¡¨ç¤º (x,y)æ˜¯åŽŸæ¥çš„ä½ç½®ï¼Œcorrectedæ˜¯æ•™æ”¿æ²»å’Œçš„ä½ç½® ræ˜¯ç¦»å¼€ä¸­å¿ƒçš„åŠå¾„ tangential åœ¨åˆ¶é€ ç›¸æœºçš„æ—¶å€™ï¼Œlenså’Œimage planeæ²¡æœ‰å®Œå…¨å¹³è¡Œå¯¼è‡´çš„ï¼Œæ‰€ä»¥æŠ•å½±ä¸ŠåŽ»ä¼šæ˜¯ä¸€ä¸ªå‡ ä½•å˜æ¢ è¿™ä¸ªdistortionåŸºæœ¬æ˜¯ç”±ä¸¤ä¸ªå‚æ•°ç»„æˆï¼šp1å’Œp2 æ€»ç»“ä¸‹æ¥ï¼Œåœ¨ç›¸æœºçš„distortioné‡Œä¸€å…±æœ‰äº”ä¸ªå‚æ•°ï¼Œk1k2k3p1p2ï¼Œè¿™äº”ä¸ªå‡½æ•°æž„æˆäº†ä¸€ä¸ªdistortion vector(5x1) è™½ç„¶åœ¨å›¾åƒé‡Œé¢è¿˜æœ‰ä¸€äº›å…¶ä»–çš„ç•¸å˜ï¼Œä½†æ˜¯å› ä¸ºå½±å“æ²¡æœ‰è¿™ä¸¤ä¸ªå¤§æ‰€ä»¥opencvæ²¡æœ‰è€ƒè™‘è¿™éƒ¨åˆ† calibration ä¸Šä¸€éƒ¨åˆ†å¾—åˆ°äº†å¦‚ä½•è¡¨ç¤ºç›¸æœºçš„å‚æ•°ä»¥åŠdistortionçš„å‚æ•° è¿™éƒ¨åˆ†è€ƒè™‘å¦‚ä½•è®¡ç®—è¿™äº›å‚æ•° å…¶ä¸­ä¸€ä¸ªå‡½æ•°clibrationCamera() ç”¨ç›¸æœºåŽ»ç…§ä¸€ä¸ªå·²ç»çŸ¥é“ç»“æž„çš„ä¸œè¥¿ï¼Œé‡Œé¢æœ‰å¾ˆå¤šå·²ç»å®šä¹‰å¥½äº†çš„ç‚¹ é€šè¿‡è¿™ä¸ªå¯ä»¥å¾—åˆ°ç›¸æœºçš„ç›¸å¯¹ä½ç½®å’Œè§’åº¦ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥å¾—åˆ°intrinsic parameters å¹³ç§»çŸ©é˜µå’Œæ—‹è½¬çŸ©é˜µ å¯¹äºŽæ¯å¼ ç…§çš„å›¾ç‰‡çš„ç‰©ä½“ï¼Œè¿™ä¸ªç‰©ä½“çš„poseå¯ä»¥ç”¨ä¸€ä¸ªæ—‹è½¬çŸ©é˜µ+ä¸€ä¸ªå¹³ç§»çŸ©é˜µæè¿°ï¼Œä¹Ÿå°±æ˜¯ç”¨è¿™ä¸ªçŸ©é˜µæŠŠçŽ°å®žä¸–ç•Œä¸­çš„ç‚¹è½¬åŒ–åˆ°æŠ•å½±å¹³é¢ä¸Š æ—‹è½¬çŸ©é˜µ æ—‹è½¬è¿åŠ¨æ— è®ºåœ¨å¤šå°‘ç»´éƒ½å¯ä»¥è¢«æè¿°ä¸ºï¼šä¸€ä¸ªåæ ‡çš„vectorä¹˜å¯¹åº”å¤§å°çš„æ–¹é˜µ -&gt; ç”¨ä¸€ä¸ªæ–°çš„åæ ‡ç³»æ¥æè¿°è¿™ä¸ªç‚¹çš„ä½ç½® -&gt; å…¶å®žä¹Ÿå°±æ˜¯æ”¹æˆäº†æžåæ ‡ç³»ï¼Ÿ ä¸‰ç»´èŒƒå›´é‡Œé¢çš„æ—‹è½¬å¯ä»¥ç”¨ä¸¤ä¸ªè§’åº¦è¡¨ç¤º ç»•ç€xï¼Œyï¼Œzä¸‰ä¸ªæ–¹å‘æ—‹è½¬çš„è§’åº¦ä»¥åŠå¯¹åº”çš„çŸ©é˜µæ˜¯è¿™ä¸ªæ ·å­çš„ è¿™ä¸‰ä¸ªæ–¹å‘çš„Rä¹˜åœ¨ä¸€èµ·å°±æ˜¯æœ€åŽçš„æ—‹è½¬çŸ©é˜µRï¼Œä½†æ˜¯è¿™ä¸ªçš„æ–¹å‘æ˜¯åç€çš„ï¼Œæ‰€ä»¥è¿˜éœ€è¦ä¸€ä¸ªtransposeè½¬å›žæ¥ å¹³ç§»çŸ©é˜µ å¹³ç§»çŸ©é˜µç”¨æ¥æè¿°æ€Žä¹ˆä»Žä¸€ä¸ªåæ ‡ç³»ç»Ÿshiftåˆ°å¦ä¸€ä¸ªåæ ‡ç³»ç»Ÿ -&gt; ä¹Ÿå°±æ˜¯ä¸€ä¸ªä»Žç¬¬ä¸€ä¸ªåæ ‡ç³»åŽŸç‚¹åˆ°ç¬¬äºŒä¸ªåæ ‡ç³»åŽŸç‚¹çš„offset åœ¨calibrationçš„æ—¶å€™ï¼Œå°±æ˜¯ä»Žç‰©ä½“åæ ‡ç³»çš„åŽŸç‚¹åˆ°äº†ç›¸æœºåæ ‡ç³»çš„åŽŸç‚¹ å¹³ç§»çŸ©é˜µï¼š Tâ†’ = origin_object âˆ’ origin_camera. ç»¼åˆ ç»“åˆä¸Šé¢ä¸¤ä¸ªçŸ©é˜µæ¥è¯´ï¼Œä»Žobjectä¸Šé¢çš„ä¸€ä¸ªç‚¹æŠ•å½±åˆ°camera planeä¸Šé¢çš„ä¸€ä¸ªç‚¹çš„å…³ç³»ä¸º Pcâ†’ =Râ‹…(Poâ†’ âˆ’Tâ†’) æ³¨æ„åˆ†æ¸…æ¥šè¿™é‡Œé¢çš„çŸ©é˜µå’Œå‘é‡ æŠŠä¸Šé¢çš„è¿™ä¸ªå…¬å¼ï¼Œå†åŠ ä¸Šcameraè‡ªå·±çš„intrinsic-correctionã€‚æ•´ä½“å°±æ˜¯opencvé‡Œé¢éœ€è¦æ±‚çš„æ‰€æœ‰éƒ¨åˆ† æ‰€æ±‚å‚æ•° ä¸‰ç»´çš„æ—‹è½¬ç”¨ä¸‰ä¸ªè§’åº¦è¡¨ç¤ºï¼Œä¸‰ç»´çš„å¹³ç§»ç”¨ä¸‰ä¸ªparameterè¡¨ç¤º(x,y,z) -&gt; çŽ°åœ¨å¾—åˆ°äº†6ä¸ªå‚æ•° ç›¸æœºçš„intrinsic mat(fx,fy,cx,cy) -&gt; ä¸€å…±å››ä¸ªå‚æ•° çŽ°åœ¨ä¸€å…±éœ€è¦æ±‚10ä¸ªå‚æ•°ï¼ˆä½†æ˜¯ç›¸æœºçš„intrinsicæ˜¯ä¸å˜çš„ï¼‰ æ±‚å‚æ•° -&gt; åœ¨æ±‚è§£çš„æ—¶å€™ï¼Œå¦‚æžœä½¿ç”¨ä¸€ä¸ªå¹³é¢ç‰©ä½“ï¼Œé‚£ä¹ˆæ¯å¼ å›¾ç‰‡éƒ½å¯ä»¥å¾—åˆ°8ä¸ªå‚æ•°ï¼ˆä½ç½®çš„6ä¸ªä¼šéšç€å›¾ç‰‡å˜åŒ– + åªèƒ½ç”¨ä¸¤ä¸ªå‚æ•°æ¥æ±‚intrinsicï¼‰ è‡³å°‘éœ€è¦2å¼ å›¾ç‰‡æ¥å¾—åˆ°æ‰€æœ‰çš„å‚æ•° calibration boards ä»ŽåŽŸåˆ™ä¸Šæ¥è¯´ï¼Œä»»ä½•æœ‰ç‰¹å¾çš„ä¸œè¥¿éƒ½å¯ä»¥è¢«ç”¨æ¥calibrationï¼ŒåŒ…æ‹¬æ£‹ç›˜ï¼Œåœ†æ ¼ï¼Œrandpatternï¼ŒarUcoç­‰ç­‰,æœ‰äº›æ–¹æ³•æ˜¯åŸºäºŽä¸‰ç»´çš„ç‰©ä½“çš„åŸºç¡€ä¸Šçš„ï¼Œä½†æ˜¯äºŒç»´å¹³é¢çš„ç‰©ä½“æ›´å¥½æ“ä½œ åœ¨è¿™é‡Œä¸»è¦é€‰æ‹©çš„æ˜¯ç”¨æ£‹ç›˜è¿›è¡Œcalibration å…³äºŽchessboardçš„å‡½æ•°cv::findChessboardCorners() å¯ä»¥ç”¨è¿™ä¸ªå‡½æ•°æ‰¾åˆ°æ£‹ç›˜çš„cornersï¼Œ param éœ€è¦è¾“å…¥8bitå›¾ç‰‡ éœ€è¦è¾“å…¥è¿™ä¸ªæ£‹ç›˜æ¯è¡Œæ¯åˆ—åº”è¯¥æœ‰çš„æ ¼å­æ•°ï¼ˆè®¡ç®—çš„æ˜¯å†…éƒ¨ç‚¹ï¼‰ è¾“å‡ºçš„æ˜¯è¿™ä¹ˆcornerçš„åæ ‡ å¯é€‰flagå†³å®šéœ€ä¸éœ€è¦å¤šä½™çš„filter cv::cornerSubPix() ä¸Šé¢ä¸€æ­¥æ‰¾åˆ°çš„åªæ˜¯cornerçš„å¤§æ¦‚ä½ç½® åœ¨find corneré‡Œé¢è‡ªåŠ¨calläº†è¿™ä¸ªå‡½æ•°ï¼Œä¸ºäº†èƒ½å¾—åˆ°æ›´ç²¾ç¡®çš„ç»“æžœ å¦‚æžœéœ€è¦å¾—åˆ°æ›´ç²¾ç¡®çš„ç»“æžœï¼Œå¯ä»¥é‡å¤çš„callè¿™ä¸ªå‡½æ•°ï¼Œä½†æ˜¯ä¼šæœ‰tighter termination criteria cv::drawChessboardCorners() ä¸ºdebugç”¨ï¼Œæ›´æ˜Žç¡®çš„ç”»å‡ºæ¥æ‰¾åˆ°çš„corner å¦‚æžœæ²¡æœ‰æ‰¾åˆ°æ‰€æœ‰çš„ï¼Œä¼šæŠŠå…¶ä»–å¯èƒ½çš„ç”¨çº¢è‰²circleç”»å‡ºæ¥ï¼Œå¦‚æžœæ‰¾åˆ°äº†ï¼Œæ¯ä¸€è¡Œçš„é¢œè‰²ä¼šä¸ä¸€æ · ä¸‹ä¸€æ­¥è½¬åˆ°perspective transformï¼Œè¿™ä¸ªtransformä¼šå½¢æˆä¸€ä¸ª3x3çš„homography mat å…³äºŽcircle gridçš„å‡½æ•°cv::findCirclesGrid() å’Œä¸Šé¢çš„æ£‹ç›˜æ²¡æœ‰ä»€ä¹ˆæœ¬è´¨çš„åŒºåˆ«ï¼Œä¸»è¦å°±æ˜¯ç”»å‡ºæ¥ä¸€ä¸ªæ˜¯é»‘ç™½æ ¼ï¼Œå¦ä¸€ä¸ªæ˜¯ç™½è‰²çš„èƒŒæ™¯ä¸Šé¢æœ‰é»‘è‰²çš„åœ†ç‚¹ï¼Œè¾“å‡ºå°åœ†ç‚¹çš„ä½ç½® è¿™ä¸ªæ–¹æ³•éœ€è¦åœ†ç‚¹æ˜¯å¯¹ç§°çš„ï¼Œä¸Šä¸‹ä¸€ç»„ç®—åšä¸€è¡Œï¼Œç«–ç€ä¸€åˆ—ç®—ä¸€åˆ—ï¼Œæ€Žä¹ˆæ•°éžå¸¸é‡è¦ Homography planar homographyæ˜¯ä¸€ä¸ªå¹³é¢åˆ°å¦ä¸€ä¸ªå¹³é¢çš„projection mappingï¼Œæ‰€ä»¥ä»Žä¸€ä¸ª2Då¹³é¢åˆ°ç›¸æœºå¹³é¢çš„è¿‡ç¨‹å°±æ˜¯ä¸€ä¸ªplanar homography ç”¨çŸ©é˜µçš„ä¹˜æ³•å°±å¯ä»¥è¡¨ç¤ºè¿™ä¸ªè¿‡ç¨‹ å…¶ä¸­Qæ˜¯çŽ°å®žä¸­çš„ç‚¹ï¼Œqæ˜¯æˆåƒå™¨ä¸Šé¢çš„ç‚¹ï¼Œæ•´ä½“å…³ç³»ä¸ºï¼šqâ†’ = s â‹… H â‹… Qâ†’ sï¼Œä¸€ä¸ªéšæ„çš„scaleå‚æ•°ï¼Œhomographyå°±æ˜¯ç”±ç€ä¸€ä¸ªå‚æ•°å†³å®šçš„ conventionally factored H, Hç”±ä¸¤ä¸ªéƒ¨åˆ†ç»„æˆ physicalä¸Šé¢çš„transformationï¼Œå®žé™…å°±æ˜¯æˆ‘ä»¬çœ‹åˆ°çš„è¿™ä¸ªç‰©ä½“çš„ä½ç½®W = [R,tâ†’] projectionï¼Œå–å†³äºŽç›¸æœºçš„intrinsic qâ†’ = s â‹… M â‹… W â‹… Qâ†’ï¼Œå…¶ä¸­Mæ˜¯ç›¸æœºçš„intrinsic mat æˆ‘ä»¬å¸Œæœ›Qä¸æ˜¯ç»™æ‰€æœ‰ç©ºé—´å®šä¹‰çš„ç‚¹ï¼Œè€Œæ˜¯ä¸€ä¸ªå®šä¹‰åœ¨æˆ‘ä»¬çœ‹çš„å¹³é¢ä¸Šé¢çš„åæ ‡ï¼Œè¿™æ ·è®¡ç®—èµ·æ¥ä¼šæ–¹ä¾¿ï¼ˆä¸‰ç»´è½¬äºŒç»´ï¼‰ æ‰€ä»¥æŠŠQé‡Œé¢çš„Zçš„åæ ‡æ”¹æˆäº†0ï¼Œè¿™æ ·æ—‹è½¬çŸ©é˜µå°±ä¼šè¢«ç®€åŒ–ä¸ºä¸€ä¸ª3x1çš„åˆ— å¹¶ä¸”ç¬¬ä¸‰ä¸ªåˆ—ä¹˜äº†Zçš„0ä¹‹åŽå°±è¢«æ¶ˆæŽ‰äº† æœ€åŽå°±å¯ä»¥æŠŠHè¡¨ç¤ºå‡ºæ¥äº† -&gt; 3x3 = intrinsic(3x3) x (rota + trans)(1x3) åœ¨è®¡ç®—homography matçš„æ—¶å€™ï¼Œç”¨äº†å¤šå¼ åŒæ ·å†…å®¹çš„ä¸œè¥¿æ¥è®¡ç®—translationå’Œintrinsic ä¸‰ä¸ªæ—‹è½¬ï¼Œä¸‰ä¸ªå¹³ç§» -&gt; æ¯å¼ å›¾ç‰‡æœ‰6ä¸ªæœªçŸ¥çš„å‚æ•° æ¯å¼ å›¾ç‰‡å¯ä»¥å¾—åˆ°8ä¸ªç­‰å¼ æŠŠä¸€ä¸ªæ­£æ–¹å½¢mappingæˆä¸€ä¸ªå››è¾¹å½¢å¯ä»¥å¾—åˆ°4ä¸ªä¸åŒçš„(x,y) points æ‰€ä»¥æ¯å¤šä¸€å¼ å›¾ç‰‡å°±å¯ä»¥å¤šå‡ºæ¥è®¡ç®—ä¸¤ä¸ªæ–°çš„å‚æ•°çš„æœºä¼š è¿™æ ·çœ‹ï¼Œpdstâ†’ = H * psrcâ†’ï¼Œåç€ä¹Ÿå¯ä»¥æŽ¨å›žæ¥ï¼Œè¿™æ ·æˆ‘ä»¬å°±ç®—ä¸çŸ¥é“Mä¹Ÿå¯ä»¥è®¡ç®—Hï¼Œæˆ–è€…è¯´æˆ‘ä»¬æ˜¯ç”¨Hæ¥è®¡ç®—M åœ¨opencvé‡Œé¢ï¼Œcv::findHomography()å¯ä»¥ç”¨takeä¸€å †æœ‰å…³ç³»çš„ç‚¹ç„¶åŽè¿”å›žä»–ä»¬ä¹‹é—´çš„homo matï¼Œç‚¹è¶Šå¤šè®¡ç®—çš„è¶Šå‡†ç¡® è™½ç„¶æœ‰å…¶ä»–çš„æ–¹æ³•å¯ä»¥è®¡ç®—ç»“æžœï¼Œä½†æ˜¯å¯¹æµ‹é‡è¯¯å·®ä¸æ˜¯å¾ˆå‹å¥½ three robust fitting methods method to cv::RANSAC éšæœºçš„é€‰æ‹©æä¾›çš„ç‚¹çš„subsetï¼Œç„¶åŽåªç”¨è¿™äº›subsetæ¥è®¡ç®—homo mat ç„¶åŽæŠŠå‰©ä¸‹çš„æ•°æ®æ‹¿æ¥è®¡ç®—ä¸€ä¸‹é è°±å’Œä¸é è°±çš„ æœ€åŽä¿å­˜æœ€æœ‰æ½œåŠ›çš„inliers åœ¨çŽ°å®žä¸­æ¯”è¾ƒå¥½ç”¨ï¼Œå¯ä»¥è¿‡æ»¤æŽ‰ä¸€éƒ¨åˆ†å™ªéŸ³ LMeDS algorithm å‡å°‘median error ä¸éœ€è¦æ›´å¤šçš„infoå’Œdataæ¥è¿è¡Œ ä½†æ˜¯it will perform well only if the inliers constitute at least a majority of the data points RHO algorithm åŠ æƒçš„ç¬¬ä¸€ç§æ–¹æ³•ï¼Œè¿è¡Œé€Ÿåº¦æ›´å¿« camera calibrationæ£‹ç›˜cornerä¸ªæ•° åˆ°åº•æœ‰å¤šå°‘å‚æ•° camera intrinsic å››ä¸ª distortionäº”ä¸ªï¼ˆæˆ–è€…æ›´å¤šï¼‰ä¸‰ä¸ªè¾å°„ï¼ˆå¯ä»¥å¢žåŠ åˆ°6ä¸ªï¼‰ + ä¸¤ä¸ªå¹³ç§» è¿™äº”ä¸ªå‚æ•°æ˜¯ä»Ž2D -&gt; 2Dçš„ ä¸‰ä¸ªcorner pointså¯ä»¥å¾—åˆ°6ä¸ªä¿¡æ¯ï¼Œè¶³å¤Ÿå¤„ç†è¿™äº”ä¸ªå‚æ•° æ‰€ä»¥ä¸€å¼ å›¾å°±å¤Ÿäº†ï¼ˆåªæ˜¯åŽŸåˆ™ä¸Šè¿™ä¹ˆè¯´ï¼‰ extrinsic parametersï¼Œè¿™ä¸ªä¸œè¥¿çš„å®žé™…ä½ç½® ä½†æ˜¯å› ä¸ºintrinsicå’Œextrinsicä¹‹é—´æœ‰å¯¹åº”çš„å…³ç³»ï¼Œä¸€å¼ å›¾ç‰‡å¹¶ä¸å¤Ÿ -&gt; å› ä¸ºåœ¨ä¸€å¼ å›¾ç‰‡é‡Œè¿˜éœ€è¦è®¡ç®—extrinsicçš„éƒ¨åˆ† å‡è®¾æœ‰Nä¸ªcornerï¼Œä¸€å…±æœ‰Kä¸ªimagesï¼ˆä¸åŒçš„positionï¼‰ ä¸€å…±ä¼šæœ‰ 2 N Kä¸ªï¼Œ2æ˜¯x,yçš„åæ ‡ä¼šæœ‰ä¸¤ä¸ªï¼Œç„¶åŽNä¸ªcornerï¼ŒKä¸ªå›¾ç‰‡ æš‚æ—¶å¿½ç•¥distortionçš„å‚æ•°ï¼Œè¿™æ ·éœ€è¦4ä¸ªinå’Œ6Kä¸ªexï¼ˆå› ä¸ºæ¯å¼ å›¾ç‰‡çš„exéƒ½æ˜¯ä¸ä¸€æ ·çš„ï¼‰ 2NK &gt;= 6K + 4 å¦‚æžœN = 5ï¼Œåªéœ€è¦ä¸€å¼ å›¾ç‰‡å°±å¯ä»¥è§£å†³ã€‚ä½†æ˜¯ä¸ºäº†å¾—åˆ°homo matï¼Œè‡³å°‘éœ€è¦ä¸¤ä¸ªK(ä¹‹å‰è¯´åˆ°è¿‡çš„) æ— è®ºæ£€æµ‹åˆ°å¤šå°‘cornerï¼Œå¾—åˆ°çš„æœ‰ç”¨ä¿¡æ¯å°±æ˜¯å››ä¸ªè§’ -&gt; ç”±æ­¤æŽ¨æµ‹è‡³å°‘ä¸¤ä¸ªK åœ¨å®žé™…çš„åº”ç”¨é‡Œé¢ï¼Œä¸€èˆ¬éœ€è¦7x8ï¼Œè‡³å°‘åå¼ å›¾ï¼Œè¿™æ ·å—åˆ°noiseçš„å½±å“æ›´å° å…·ä½“çš„æ•°å­¦è®¡ç®— ä¸ºäº†ç®€å•ï¼Œé¦–å…ˆå‡è®¾åœ¨calibrationçš„æ—¶å€™æ ¹æœ¬æ²¡æœ‰distortion å¯¹äºŽæ¯ä¸ªviewï¼Œä¼šå¾—åˆ°ä¸€ä¸ªHomo matï¼ŒæŠŠè¿™ä¸ªmatæ‹†æˆä¸€ä¸ªåˆ—å‘é‡(3x1) åœ¨å‰é¢ä¹ŸçŸ¥é“Hå¯ä»¥æ‹†æˆMå’Œä¸€ä¸ª[r1,r2,t]çš„å‘é‡ç›¸ä¹˜ï¼Œå†ä¹˜ä¸Šä¸€ä¸ªscale s H=[h1,h2,h3] =sâ‹…Mâ‹…[r1,r2,t],å…¶ä¸­landaæ˜¯1/s: æ—‹è½¬å‘é‡çš„åŸºåº•(orthogonal)æ˜¯äº’ç›¸åž‚ç›´çš„ï¼Œå› ä¸ºå·²ç»æŠŠscaleè¿™ä¸ªå‚æ•°æå‡ºåŽ»äº†ï¼Œæ‰€ä»¥å¯ä»¥ç›´æŽ¥è®¤ä¸ºr1å’Œr2æ˜¯åŸºäº†ï¼Œè¿™æ ·çš„è¯ä»–ä»¬çš„ç‚¹ä¹˜æ˜¯0 æŠŠr1å’Œr2ç”¨Må’Œhæ¥è¡¨ç¤ºï¼Œè¿™æ ·çš„è¯r1r2ç­‰äºŽ0å°±å¯ä»¥è½¬åŒ–æˆä¸€ä¸ªhMçš„å…¬å¼ r1å’Œr2çš„æ¨¡ä¹Ÿç›¸ç­‰ï¼Œæ‰€ä»¥å¯ä»¥ç»§ç»­å¾—åˆ°ä¸€ä¸ªç­‰å¼ è®¾ç½®ä¸€ä¸ªçŸ©é˜µBç­‰äºŽM.-T * M-1ï¼Œè¿™æ ·å¯ä»¥è®¡ç®—å‡ºæ¥Bçš„å€¼(Bç®—å‡ºæ¥æ˜¯å¯¹ç§°çš„) æŠŠBå¸¦å›žåŽŸæ¥çš„ç­‰å¼ï¼ŒåŒ–ç®€ï¼Œç„¶åŽæŠŠKä¸ªç­‰å¼å åŠ åœ¨ä¸€èµ· è¿™æ ·å°±å¯ä»¥æŽ¨å‡ºæ¥å‡ ä¸ªå‚æ•°çš„è¡¨è¾¾å¼ calibrationçš„å‡½æ•°cv::calibrateCamera().æ¥è§£å†³calibrationçš„é—®é¢˜ å¾—åˆ°çš„ç»“æžœåŒ…æ‹¬in mat, dis_co, æ—‹è½¬å‘é‡å’Œå¹³ç§»å‘é‡ è¾“å‡ºçš„in matçš„å¤§å°æ˜¯3x3 è¾“å‡ºçš„dis_coçš„å¤§å°å–å†³äºŽç”¨å¤šå°‘çº§çš„distortionï¼Œä¸€èˆ¬æ¥è¯´æ˜¯4ï¼Œ5ä¸ªçš„å·²ç»å¯¹fisheyeè¶³å¤Ÿäº†ï¼Œ8ä¸ªçš„è¯calibrationçš„ç²¾åº¦å°±ç‰¹åˆ«é«˜äº† å¦‚æžœéœ€è¦é«˜ç²¾åº¦çš„calibrationçš„è¯ï¼Œéœ€è¦çš„å›¾ç‰‡æ•°é‡ä¹Ÿä¼šç–¯ç‹‚å¢žåŠ  è¾“å…¥çš„éƒ¨åˆ†åŒ…æ‹¬ ç‰©ä½“çš„åæ ‡ï¼ŒæŒ‡çš„æ˜¯åœ¨chessboardä¸Šé¢çš„åæ ‡ç‚¹ï¼Œæ˜¯äºŒç»´çš„ç‚¹ï¼Œå…¶å®žä¹Ÿå°±æ˜¯ç¬¬å‡ ä¸ªæ ¼å­ï¼Ÿ æ³¨æ„è¿™é‡Œï¼Œç»Ÿè®¡çš„å•ä½æ˜¯æ ¼å­ï¼Œæ‰€ä»¥å¦‚æžœæƒ³è¦å¾—åˆ°physicalä¸Šçš„è·ç¦»ï¼Œéœ€è¦åœ¨calibration boardä¸Šé‡å‡ºæ¥ä¸€ä¸ªæ ¼å­çš„é•¿åº¦ï¼Œç„¶åŽä¹˜è¿™ä¸ªæ ¼å­çš„æ•°é‡ imageä¸Šé¢çš„åæ ‡ï¼Œcorners ä¸€å£æ°”è®¡ç®—æ‰€æœ‰çš„å‚æ•°ä¸æ˜¯å¾ˆå¥½å®žçŽ°ï¼Œä¸€èˆ¬ä½¿ç”¨çš„æ–¹æ³•æ˜¯å…ˆå›ºå®šä¸€éƒ¨åˆ†è®¡ç®—å¦ä¸€éƒ¨åˆ†ï¼Œç„¶åŽå†å›ºå®šå¦ä¸€éƒ¨åˆ†è®¡ç®—è¿™ä¸€éƒ¨åˆ†ã€‚å½“æ‰€æœ‰çš„ä¸œè¥¿éƒ½ä¼°è®¡çš„å·®ä¸å¤šäº†ï¼Œå†ä¸€èµ·è®¡ç®— æœ€åŽè¿˜æœ‰ä¸€ä¸ªå‚æ•°æ˜¯termination criteriaï¼Œç»ˆæ­¢çš„åŸºå‡† -&gt; epsilon ä¼šæ ¹æ®ä¸€ä¸ªerroræ¥è®¡ç®—æ˜¯å¦ç»ˆæ­¢ åªè®¡ç®—extrinsiccv::slovePnP() æœ‰çš„æ—¶å€™æˆ‘ä»¬å·²ç»å¾—åˆ°äº†ç›¸æœºçš„intrinsicï¼Œåªå¸Œæœ›å¾—åˆ°objectçš„ä½ç½® å¤§éƒ¨åˆ†å†…å®¹å’Œä¸Šé¢éƒ½æ˜¯ä¸€æ ·çš„ï¼Œé™¤äº† ç‰©ä½“çš„ä½ç½®åªéœ€è¦ä¸€ä¸ªview distCoå’Œintrinsicéƒ½æ˜¯è‡ªå·±è®¾ç½®å¥½çš„ï¼Œä¸éœ€è¦è®¡ç®— cv::solvePnPRansac() ä¸Šé¢çš„å‡½æ•°å¯¹äºŽoutliersçš„robustæ•ˆæžœä¸æ˜¯å¾ˆå¥½ï¼Œå¯¹äºŽchessboardæ¥è¯´ï¼Œè¿™ä¸ªrobustä¸æ˜¯å¾ˆé‡è¦ï¼Œå› ä¸ºæ£‹ç›˜è‡ªå·±æœ¬èº«å·²ç»å¾ˆå¯é äº†ã€‚ä½†æ˜¯å¯¹äºŽçŽ°å®žä¸–ç•Œä¸­çš„ç‰©ä½“æ¥è¯´ä¸æ˜¯è¿™ä¹ˆå¯é  åŠ å…¥äº†RANSACéƒ¨åˆ†ï¼Ÿ Undistortion åœ¨calibrationé‡Œé¢æœ‰ä¸¤ä¸ªéœ€è¦è§£å†³çš„äº‹æƒ…ï¼Œä¸€ä¸ªæ˜¯distortionï¼Œä¸€ä¸ªæ˜¯ä¸‰ç»´è¡¨è¾¾çš„æ­£ç¡®æ€§ opencvè‡ªå·±æœ‰ä¸€ä¸ªå¯ä»¥ç”¨çš„æ–¹æ³• cv::undistor() -&gt; å¯ä»¥ä¸€çž¬é—´å®Œæˆ cv::initUndistortRectifyMap() + cv::remap() -&gt; åœ¨videoä¸Šé¢ä½¿ç”¨çš„æ—¶å€™æ•ˆçŽ‡æ›´é«˜ä¸€äº› undistortion map åœ¨æŠŠä¸€å¼ å›¾ç‰‡undistortçš„æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦æŠŠæ¯ä¸ªåƒç´ éƒ½å¯¹åº”åˆ°outputé‡Œé¢å¯¹åº”çš„åœ°æ–¹åŽ»ï¼Œæœ‰å‡ ç§ä¸åŒçš„è¡¨è¾¾æ–¹æ³• 2-channel float æœ‰ä¸€ä¸ªå¯¹äºŽNxMçš„remappingï¼Œè¡¨ç¤ºæˆNxMçš„arrayï¼Œæœ‰ä¸¤ä¸ªchannelï¼ˆåˆ†åˆ«å¯¹åº”Xå’ŒYæ–¹å‘çš„remapï¼‰ï¼Œé‡Œé¢æ˜¯æµ®ç‚¹æ•° å¯¹äºŽæ¯ä¸€ä¸ªè¾“å…¥çš„åƒç´ ä½ç½®(i,j)ï¼Œæœ‰ä¸€ä¸ªå¯¹äºŽè¿™ä¸¤ä¸ªä½ç½®çš„å‘é‡ï¼Œæ¥è¡¨è¾¾è¿™ä¸¤ä¸ªé‡åº”è¯¥å“ªé‡ŒåŽ» å¦‚æžœè®¡ç®—å‡ºæ¥çš„ç»“æžœä¸æ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œé‚£ä¹ˆç”¨interpolationæ¥è®¡ç®—æœ€åŽåº”è¯¥å çš„æ ¼å­çš„æ•°é‡ ç¬¬äºŒç§è¡¨è¾¾å¼æ˜¯ 2-array floatï¼Œæ¯ä¸€ä¸ªarrayæ˜¯ä¸€ä¸ªchannelçš„ç§»åŠ¨ ç¬¬ä¸‰ç§æ˜¯fixed pointï¼Œè®¡ç®—çš„é€Ÿåº¦æ›´å¿«ä¸€ç‚¹ï¼Œä½†æ˜¯éœ€è¦æä¾›çš„ä¿¡æ¯çš„ç²¾ç¡®åº¦æ›´é«˜ cv::convertMaps() å› ä¸ºæœ‰ä¸Šé¢çš„ä¸‰ç§ä¸åŒçš„è¡¨è¾¾å½¢å¼ï¼Œæ‰€ä»¥è¿™ä¸ªå‡½æ•°ç”¨æ¥åœ¨å„ä¸ªå½¢å¼ä¹‹é—´è½¬å˜ cv::initUndistortRectifyMap() ä»Žåˆšæ‰çš„éƒ¨åˆ†çŸ¥é“äº†åˆ°åº•ä»€ä¹ˆæ˜¯undistortion mapï¼ŒçŽ°åœ¨å¼€å§‹è®¨è®ºå¦‚ä½•è®¡ç®—è¿™ä¸ªmap çŽ°åœ¨å…ˆä»Žå•ç›®ç›¸æœºå¼€å§‹monocularï¼Œå¦‚æžœåŒç›®çš„è¯å¯ä»¥ç›´æŽ¥è®¡ç®—depthï¼ˆä¸‹ä¸€ç« ï¼‰ æ­¥éª¤ï¼Œåˆ†å¼€æ˜¯å› ä¸ºè®¡ç®—mapåªéœ€è¦ä¸€æ¬¡ å…ˆè®¡ç®—undistortion map cv::initUndistortRectifyMap() è¾“å…¥çš„å‚æ•°æ˜¯intrinsic matå’Œdistortion coefficientï¼ˆä»Žcamera calibrationå¾—åˆ°çš„ï¼‰ å¯ä»¥å¾—åˆ°ä¸€ä¸ªæ–°çš„camera matï¼Œè¿™æ ·çš„è¯å³ä½¿ä¸undistortionä¹Ÿå¯ä»¥å¾—åˆ°æ­£ç¡®çš„å›¾ç‰‡ï¼ˆåœ¨å¤šä¸ªç›¸æœºçš„calibrationçš„æ—¶å€™æ¯”è¾ƒé‡è¦ï¼‰ æœ€åŽä¼šè¾“å‡ºä¸¤å¼ map ç„¶åŽåœ¨å›¾ç‰‡ä¸Šundistort cv::remap() å½“è®¡ç®—äº†ä¸Šé¢çš„mapä¹‹åŽï¼Œå°±å¯ä»¥ç”¨remapè¿™ä¸ªå‡½æ•°è¿›è¡Œæ ¡æ­£äº† è¾“å…¥çš„mapçš„ç§ç±»ä¹Ÿæ˜¯ä¸Šé¢æåˆ°çš„ä¸‰ç§éƒ½å¯ä»¥ cv::undistort() å¦‚æžœåªæœ‰ä¸€å¼ å›¾ç‰‡ï¼Œæˆ–è€…å¯¹äºŽæ¯å¼ å›¾ç‰‡éƒ½éœ€è¦é‡æ–°è®¡ç®—mapçš„æ—¶å€™ï¼Œå°±éœ€è¦ç”¨è¿™ä¸ªå‡½æ•°äº†ï¼ˆæ‰€ä»¥åœ¨é¡¹ç›®é‡Œé¢ç”¨è¿™ä¸ªçš„é€Ÿåº¦ä¼šå˜æ…¢ï¼‰ sparse undistortion cv::distortionPoints() å¦‚æžœæˆ‘æ²¡æœ‰æ•´å¼ å›¾ç‰‡ï¼Œåªæœ‰ä¸€äº›å›¾ç‰‡ä¸Šçš„ç‚¹ï¼Œç„¶åŽæˆ‘åªå…³å¿ƒè¿™äº›å›¾ç‰‡ä¸Šçš„ç‚¹ï¼Œå¯ä»¥ç”¨è¿™ä¸ªå‡½æ•°è®¡ç®—è¿™å¼ å›¾ç‰‡ä¸Šé¢å…³æ³¨ç‚¹çš„ä½ç½®]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>OpenCV</category>
        <category>Calibration</category>
      </categories>
      <tags>
        <tag>camera</tag>
        <tag>calibration</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nassignment2CNN]]></title>
    <url>%2F2019%2F04%2F18%2FCS231nassignment2CNN%2F</url>
    <content type="text"><![CDATA[target ä¹‹å‰å·²ç»å®žè·µäº†fcçš„ç›¸å…³ä¸œè¥¿ï¼Œä½†æ˜¯åœ¨å®žé™…çš„ä½¿ç”¨é‡Œå¤§å®¶ä½¿ç”¨çš„éƒ½æ˜¯CNN æ‰€ä»¥è¿™éƒ¨åˆ†å°±å¼€å§‹å®žè·µCNNäº† convolution: Native forward pass CNNçš„æ ¸å¿ƒéƒ¨åˆ†å°±æ˜¯å·ç§¯ in cs231n/layers.pyï¼Œconv_forward_naive é¦–å…ˆè¿™æ—¶å€™ä¸ç”¨è€ƒè™‘æ•ˆçŽ‡é—®é¢˜ï¼Œæœ€è½»æ¾çš„å†™å°±å¯ä»¥äº† è¾“å…¥çš„æ•°æ®æ˜¯Nä¸ªdataï¼Œæ¯ä¸ªæœ‰Cä¸ªchannelï¼ŒHçš„é«˜åº¦å’ŒWçš„å®½åº¦ æ¯ä¸ªè¾“å…¥å’ŒFä¸ªä¸åŒçš„filteråšå·ç§¯ï¼Œæ¯ä¸ªå·ç§¯æ ¸å¯¹æ‰€æœ‰çš„channelä½œç”¨ï¼Œå·ç§¯æ ¸çš„å¤§å°æ˜¯HHxWW input x, (N,C,H,W) w, fliter weights of shape (F,C,HH,WW) b, bias, (F,) conv_param: dict â€œstrideâ€ æ­¥é•¿ â€œpadâ€ zero-paddingçš„å¤§å° æ³¨æ„åœ¨paddingçš„æ—¶å€™ä¸è¦è°ƒæ•´xï¼Œè€Œæ˜¯å¾—åˆ°ä¸€ä¸ªpaddingä¹‹åŽçš„æ–°çš„ä¸œè¥¿ output out, (N,F,Hâ€™,Wâ€™) Hâ€™ = 1 + (H + 2 * pad - HH) / stride Wâ€™ = 1 + (W + 2 * pad - WW) / stride cache: (x,w,b,conv_param) implement é¦–å…ˆéœ€è¦å¯¹è¾“å…¥çš„å›¾ç‰‡è¿›è¡Œpadding np.pad è¾“å…¥çš„array padçš„å®½åº¦ï¼Œå¦‚æžœé»˜è®¤çš„è¯å°±æ˜¯å‰åŽéƒ½åŠ ï¼Œç„¶åŽæ˜¯è¿™ä¸ªæ•°å­—çš„å®½åº¦ -&gt; æ³¨æ„è¿™é‡Œçš„æ—¶å€™å› ä¸ºä¸€å…±æœ‰å››ä¸ªç»´åº¦ï¼Œå‰ä¸¤ä¸ªç»´åº¦æ˜¯ä¸ç”¨padçš„ mode = â€˜constantâ€™ constant_valuesï¼Œè¡¨ç¤ºçš„æ˜¯padè¿›åŽ»çš„å€¼ï¼Œå¯ä»¥å‰åŽpadçš„ä¸ä¸€æ ·ï¼Œå› ä¸ºè¿™é‡Œæ˜¯0-paddingæ‰€ä»¥è¿™é‡Œæ˜¯0 è¦å¯¹æ‰€æœ‰å›¾ç‰‡è¿›è¡Œå¤„ç†ï¼Œéœ€è¦åœ¨Nä¸ªå›¾ç‰‡é‡Œé€‰æ‹©ä¸€ä¸ª åœ¨filterçš„æ‰€æœ‰é‡Œé¢é€‰æ‹©ä¸€ä¸ª è€ƒè™‘åœ¨Hæ–¹å‘å’ŒWæ–¹å‘çš„ç§»åŠ¨æ­¥æ•°ï¼Œç„¶åŽé€šè¿‡è¿™ä¸ªæ­¥æ•°å’Œæ­¥é•¿çš„ä¹˜ç§¯åœ¨åŽŸå›¾é‡Œé¢å–éœ€è¦åšå·ç§¯çš„éƒ¨åˆ† æ³¨æ„è¿™é‡Œå¯ä»¥ä¸ç”¨è€ƒè™‘channelï¼Œå› ä¸ºå›¾ç‰‡å’Œfilterçš„channelæ˜¯åŒæ ·çš„å±‚æ•°ï¼Œæ‰€ä»¥ç›´æŽ¥å¯ä»¥boardcast ç„¶åŽè¿™ä¸ªéƒ¨åˆ†å’Œå·ç§¯æ ¸ç›¸ä¹˜ï¼ˆç›´æŽ¥ä¹˜ï¼‰ï¼Œæ±‚å’Œï¼ŒåŠ ä¸Šbiasï¼Œå°±æ˜¯è¿™ä¸ªåƒç´ ç‚¹ä¸Šåº”è¯¥çš„æ•°å€¼ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162def conv_forward_naive(x, w, b, conv_param): """ A naive implementation of the forward pass for a convolutional layer. The input consists of N data points, each with C channels, height H and width W. We convolve each input with F different filters, where each filter spans all C channels and has height HH and width WW. Input: - x: Input data of shape (N, C, H, W) - w: Filter weights of shape (F, C, HH, WW) - b: Biases, of shape (F,) - conv_param: A dictionary with the following keys: - 'stride': The number of pixels between adjacent receptive fields in the horizontal and vertical directions. - 'pad': The number of pixels that will be used to zero-pad the input. During padding, 'pad' zeros should be placed symmetrically (i.e equally on both sides) along the height and width axes of the input. Be careful not to modfiy the original input x directly. Returns a tuple of: - out: Output data, of shape (N, F, H', W') where H' and W' are given by H' = 1 + (H + 2 * pad - HH) / stride W' = 1 + (W + 2 * pad - WW) / stride - cache: (x, w, b, conv_param) """ out = None ########################################################################### # TODO: Implement the convolutional forward pass. # # Hint: you can use the function np.pad for padding. # ########################################################################### stride = conv_param['stride'] pad = conv_param['pad'] N, C, H, W = x.shape F, _, HH, WW = w.shape H_out = 1 + (H + 2 * pad - HH) // stride W_out = 1 + (W + 2 * pad - WW) // stride out = np.zeros((N, F, H_out, W_out)) x_pad = np.pad(x, ((0,), (0,), (pad,), (pad,)), 'constant', constant_values=0) # å¯¹åŽŸå›¾ç‰‡çš„æ¯å±‚è¿›è¡Œå·ç§¯ for pics in range(N): image = x_pad[pics] for filters in range(F): for H_move in range(H_out): for W_move in range(W_out): image_conv = image[:, stride * H_move: stride * H_move + HH, stride * W_move: stride * W_move + WW] filter_conv = w[filters, :] out_pixel = np.sum(image_conv * filter_conv) + b[filters] out[pics, filters, H_move, W_move] = out_pixel ########################################################################### # END OF YOUR CODE # ########################################################################### cache = (x, w, b, conv_param) return out, cache å¯è§†åŒ–ä¸­é—´çš„å›¾åƒè¿‡ç¨‹ è¿™é‡Œè¾“å…¥äº†ä¸¤ä¸ªä¸åŒçš„è¾“å…¥å›¾ç‰‡ åˆ†åˆ«å¯è§†åŒ–äº†è¿™ä¸ªå›¾ç‰‡çš„ä¸åŒweights Convolution: Naive backward passæ„‰å¿«çš„ç®€å•è®¡ç®—backçš„è¿‡ç¨‹ï¼Œå…ˆä¸ç”¨è€ƒè™‘cost input dout cacheï¼ˆx,w,b,conv_param) -&gt; å‚æ•°æ˜¯padding å’Œ stride output dx dw db å®žçŽ°ï¼šconvæ˜¯æ€Žä¹ˆæ±‚å¯¼çš„ï¼Ÿå…¶å®žæŽ’é™¤ä½ç½®çš„æ”¹å˜ä¹‹å¤–ï¼Œforwardåªè¿›è¡Œäº†ä¸‰ä¸ªæ“ä½œ æŠŠx paddingä¸ºx_pad wx_pad_conv + b -&gt; æ±‚å‡ºä¸€ä¸ªå¤§å°å’Œfilterç›¸åŒçš„çŸ©é˜µ æŠŠæ±‚å‡ºæ¥çš„ä¸€ä¸ª(HH,WW)çš„çŸ©é˜µçš„æ‰€æœ‰å€¼æ±‚sum backwardçš„æ€è·¯ é¦–å…ˆï¼Œæ¯ä¸€å¼ å›¾ç‰‡çš„æ¯ä¸€ä¸ªchannelçš„ï¼Œdoutçš„å¤§å°å’Œè¾“å‡ºå›¾ç‰‡çš„å¤§å°ä¸€æ · åº”è¯¥æ˜¯H_out = 1 + (H + 2 * pad - HH) // strideè¿™æ ·æ±‚å‡ºæ¥çš„ç»“æžœ æ•´ä¸ªdoutçš„sizeæ˜¯(N,F,Hout,Wout)ï¼Œå…¶ä¸­Næ˜¯ä¹‹å‰å›¾ç‰‡çš„æ•°é‡ï¼ŒFæ˜¯æ–°å½¢æˆçš„å›¾ç‰‡çš„channel æ‰€ä»¥åœ¨forå¾ªçŽ¯ä¸­ï¼Œdoutä¸­é€‰ä¸­[n,f,hout,wout]ï¼Œå°±å¯ä»¥å¾—åˆ°è¿™ä¸ªç‰¹ç‚¹å®šçš„å€¼ï¼Œç§°ä¸ºdf dfçš„å¾—åˆ°æ–¹æ³•æ˜¯wx+bå¾—åˆ°ä¸€ä¸ªçŸ©é˜µï¼Œç„¶åŽå†å¯¹è¿™ä¸ªçŸ©é˜µæ±‚å’Œ å› ä¸ºæ±‚å’Œå®žé™…å°±æ˜¯ç´¯åŠ ï¼Œæ±‚å¯¼æ•°çš„æ—¶å€™åªè¦æŠŠæ¯ä¸€ä¸ªæ ¼å­çš„dxï¼Œdwï¼Œdbå¯¼æ•°æ±‚å‡ºæ¥ï¼Œç„¶åŽåŠ åœ¨ä¸€èµ·å°±è¡Œäº† å› ä¸ºå…¬å¼å°±æ˜¯wx + bï¼Œæ‰€ä»¥dxæ˜¯wï¼Œdwæ˜¯xï¼Œdbæ˜¯å¸¸æ•° -&gt; ç„¶åŽå†æŠŠæ¯ä¸ªæ ¼å­æ±‚å‡ºæ¥çš„åŠ åœ¨ä¸€èµ·ï¼Œæ³¨æ„å„ä¸ªçŸ©é˜µçš„å¤§å°ï¼Œdxåº”è¯¥æ˜¯åœ¨xçŸ©é˜µé‡Œå–åšå·ç§¯çš„éƒ¨åˆ†ï¼Œè¿™éƒ¨åˆ†çš„å¯¼æ•°ç­‰äºŽwä¹˜dfçš„å’Œ æœ€åŽï¼Œå› ä¸ºxè¢«paddingäº†ï¼Œdxåº”è¯¥åŽ»dx_padä¸­æ²¡æœ‰è¢«paddingçš„éƒ¨åˆ†ï¼Œä¹Ÿå°±æ˜¯ä»Ž[pad:pad + H] ä»£ç å¦‚ä¸‹123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051def conv_backward_naive(dout, cache): """ A naive implementation of the backward pass for a convolutional layer. Inputs: - dout: Upstream derivatives. - cache: A tuple of (x, w, b, conv_param) as in conv_forward_naive Returns a tuple of: - dx: Gradient with respect to x - dw: Gradient with respect to w - db: Gradient with respect to b """ dx, dw, db = None, None, None ########################################################################### # TODO: Implement the convolutional backward pass. # ########################################################################### x, w, b, conv_param = cache N, C, H, W = x.shape F, _, HH, WW = w.shape _, _, H_dout, W_dout = dout.shape stride = conv_param['stride'] pad = conv_param['pad'] x_pad = np.pad(x, ((0,), (0,), (pad,), (pad,)), 'constant', constant_values=0) db = np.zeros_like(b) dw = np.zeros_like(w) dx_pad = np.zeros_like(x_pad) # print(dx_pad.shape) for pics in range(N): for filters in range(F): for H_move in range(H_dout): for W_move in range(W_dout): # f=sum(wx_pad + b) (df is a number now) df = dout[pics, filters, H_move, W_move] # d for sum, size (HH,WW) # dsum = df * np.ones((HH, WW)) db[filters] += df dx_pad[pics, :, H_move * stride: H_move * stride + HH, W_move * stride: W_move * stride + WW] += df * w[filters] dw[filters] += x_pad[pics, :, stride * H_move: stride * H_move + HH, stride * W_move: stride * W_move + WW] * df dx = dx_pad[:, :, pad:pad + H, pad:pad + W] ########################################################################### # END OF YOUR CODE # ########################################################################### return dx, dw, db Max-Poolingï¼šNative forwardinput x, (N,C,H,W) pool_param -&gt; dict â€˜pool_heightâ€™ â€˜pool_widthâ€™ â€˜strideâ€™ ä¸éœ€è¦è¿›è¡Œpadding output out, (N,C,Hâ€™,Wâ€™) Hâ€™ = 1 + (H - pool_height) / stride Wâ€™ = 1 + (W - pool_width) / stride cache(x,pool_param) å®žçŽ° ç›´æŽ¥æ‰¾åˆ°ç›¸åº”çš„å—ç„¶åŽæ±‚max æ³¨æ„æ±‚maxçš„æ—¶å€™è¦æ³¨æ„axis,æˆ‘ä»¬éœ€è¦æ±‚å¾—æ˜¯åœ¨ä¸€å¼ å›¾ç‰‡æ¯ä¸ªchannelä¸Šé¢çš„æœ€å¤§å€¼ï¼Œåœ¨è¿™ä¸ªå¼å­é‡Œé¢å› ä¸ºå·²ç»ç¡®å®šäº†picsçš„å€¼ï¼Œå®žé™…ä¸Šçš„outå…¶å®žæ˜¯ä¸€ä¸ªä¸‰ç»´çš„æ•°ç»„ï¼Œæ‰€ä»¥åº”è¯¥æ±‚axis = (1,2)ä¸Šé¢çš„æœ€å¤§å€¼ï¼Œè€Œä¸æ˜¯æ±‚(2,3ä¸Šé¢çš„) ä»£ç 12345678910111213141516171819202122232425262728293031323334353637383940def max_pool_forward_naive(x, pool_param): """ A naive implementation of the forward pass for a max-pooling layer. Inputs: - x: Input data, of shape (N, C, H, W) - pool_param: dictionary with the following keys: - 'pool_height': The height of each pooling region - 'pool_width': The width of each pooling region - 'stride': The distance between adjacent pooling regions No padding is necessary here. Output size is given by Returns a tuple of: - out: Output data, of shape (N, C, H', W') where H' and W' are given by H' = 1 + (H - pool_height) / stride W' = 1 + (W - pool_width) / stride - cache: (x, pool_param) """ out = None ########################################################################### # TODO: Implement the max-pooling forward pass # ########################################################################### N, C, H, W = x.shape pool_height, pool_width, stride = pool_param['pool_height'], pool_param['pool_width'], pool_param['stride'] H_out = 1 + (H - pool_height) // stride W_out = 1 + (W - pool_width) // stride out = np.zeros((N,C,H_out,W_out)) for pics in range(N): for h_out in range(H_out): for w_out in range(W_out): out[pics,:,h_out,w_out] = np.max(x[pics,:,stride * h_out: stride* h_out + pool_height,stride* w_out: stride*w_out + pool_width],axis = (1,2)) ########################################################################### # END OF YOUR CODE # ########################################################################### cache = (x, pool_param) return out, cache Max-pooling: Native backwardinput dout, size = (N,C,W_out,W_out) cache output dx, size = (N,C,W,H) å®žçŽ° maxçš„å€¼åœ¨å®žé™…ä¸Šæ˜¯ä¸€ä¸ªrouterï¼Œlocal gradientå¯¹äºŽæœ€å¤§çš„å€¼çš„åœ°æ–¹æ˜¯1ï¼Œå…¶ä»–å€¼çš„åœ°æ–¹å½±å“æ˜¯0 éœ€è¦æ‰¾åˆ°xé‡Œé¢å€¼ç­‰äºŽæœ€å¤§å€¼çš„åæ ‡ï¼Œç„¶åŽæŠŠè¿™ä¸ªåæ ‡çš„dxæ”¹æˆå¯¹åº”doutçš„å€¼ï¼ˆå› ä¸ºé“¾å¼æ³•åˆ™åº”è¯¥dout * 1ï¼‰ï¼Œå…¶ä»–åœ°æ–¹çš„dxéƒ½æ˜¯0 å…³äºŽæ‰¾åˆ°è¿™ä¸ªç‚¹çš„åæ ‡ æˆ‘ç”¨äº†æ˜¾å¾—å¾ˆå‚»çš„æ–¹æ³•ï¼Œåœ¨xçš„èŒƒå›´é‡Œé¢æ‰¾åˆ°è¿™ä¸ªèŒƒå›´é‡Œæœ€å¤§çš„åæ ‡ï¼Œç”¨äº†å¾ˆå¤šåœˆå¾ªçŽ¯ å®žé™…ä¸Šå¯ä»¥ä»Žmaxçš„å€¼æ‰¾åˆ°åŽŸæ¥çš„åæ ‡ numpy.unravel_index(indices, dims) ç»“åˆnp.argmaxï¼Œè¿”å›žæœ€å¤§å€¼çš„åæ ‡ -&gt; ind = np.unravel_index(np.argmax(a, axis=None), a.shape) è¿™æ ·çš„è¯æ‰¾åˆ°çš„æ˜¯åœ¨æ¯ä¸ªmaxçš„æ¡†æ¡†é‡Œæœ€å¤§å€¼çš„åæ ‡ï¼Œåœ¨è¿™ä¸ªæ¡†æ¡†çš„èŒƒå›´é‡Œæ‰¾åˆ°è¿™ä¸ªåæ ‡å°±æ˜¯éœ€è¦æ”¹å˜çš„åœ°æ–¹ 1234567891011121314151617181920212223242526272829303132333435363738def max_pool_backward_naive(dout, cache): """ A naive implementation of the backward pass for a max-pooling layer. Inputs: - dout: Upstream derivatives - cache: A tuple of (x, pool_param) as in the forward pass. Returns: - dx: Gradient with respect to x """ dx = None ########################################################################### # TODO: Implement the max-pooling backward pass # ########################################################################### x, pool_param = cache N, C, H, W = x.shape pool_height, pool_width, stride = pool_param['pool_height'], pool_param['pool_width'], pool_param['stride'] _,_,H_out,W_out = dout.shape dx = np.zeros_like(x) for pics in range(N): for channels in range(C): for h_out in range(H_out): for w_out in range(W_out): # for H in range(stride * h_out, stride* h_out + pool_height): # for W in range(stride * w_out, stride * w_out + pool_width): # if x[pics,channels,H,W] == np.max(x[pics,channels,stride * h_out: stride* h_out + pool_height,stride* w_out: stride*w_out + pool_width]): # dx[pics,channels,H,W] = dout[pics,channels,h_out,w_out] ind = np.unravel_index(np.argmax(x[pics,channels,stride * h_out: stride* h_out + pool_height,stride* w_out: stride*w_out + pool_width]), (pool_height,pool_width)) dx[pics,channels,stride * h_out: stride* h_out + pool_height,stride* w_out: stride*w_out + pool_width][ind] = dout[pics,channels,h_out,w_out] # print(ind) ########################################################################### # END OF YOUR CODE # ########################################################################### return dx Fast layers åœ¨cs231n/fast_layers.pyé‡Œé¢ç›´æŽ¥æä¾›äº†æ¯”è¾ƒå¿«ç‰ˆæœ¬çš„è®¡ç®—æ–¹æ³• The fast convolution implementation depends on a Cython extension; to compile it you need to run the following from the cs231n directory: 1python setup.py build_ext --inplace è®°å¾—é‡å¯ä¸€ä¸‹jupter 12345678910111213141516171819202122232425Testing conv_forward_fast:Naive: 5.283360sFast: 0.014807sSpeedup: 356.809600xDifference: 4.926407851494105e-11Testing conv_backward_fast:Naive: 9.893734sFast: 0.015421sSpeedup: 641.578958xdx difference: 1.949764775345631e-11dw difference: 5.155328198575201e-13db difference: 3.481354613192702e-14Testing pool_forward_fast:Naive: 0.212025sfast: 0.002980sspeedup: 71.143680xdifference: 0.0Testing pool_backward_fast:Naive: 0.391351sfast: 0.012568sspeedup: 31.138711xdx difference: 0.0 å¯ä»¥å‘çŽ°fastç‰ˆæœ¬convçš„é€Ÿåº¦ä¼šå¿«300å€ï¼Œè€Œpoolingä¹Ÿä¼šå¿«å‡ åå€ conv sandwich layer -&gt; å·²ç»å†™å¥½äº†ï¼Œconv + relu + poolThree-layer ConvNetcs231n/classifiers/cnn.py,implementä¸€ä¸ªä¸‰å±‚çš„CNNç»“æž„ conv - relu - 2x2 maxpool - affine1 - relu - affine2 - softmax è¾“å…¥å›¾ç‰‡çš„minibatchä¸º(N,C,H,W) init input_dim: (C,H,W)æ˜¯æ¯å¼ å›¾ç‰‡é•¿ä»€ä¹ˆæ ·å­ num_filters: convå±‚é‡Œé¢filterçš„ä¸ªæ•° filters_sizeï¼Œç›´æŽ¥æŠŠé«˜å’Œå®½ç»Ÿä¸€æˆä¸€ä¸ªæ•°å­—äº†ï¼Œåæ­£éƒ½æ˜¯æ–¹å½¢çš„ hidden_dimï¼šç”¨fcå±‚çš„æ•°é‡ num_classes: æœ€åŽè¾“å‡ºçš„classçš„æ•°é‡ weight_scaleï¼šåˆå§‹åŒ–çš„æ—¶å€™çš„scale regï¼šL2 dtypeï¼šè®¡ç®—æ‰€ç”¨çš„datatypeï¼ˆå¦‚ np.float32) loss + gradient éœ€è¦åˆå§‹åŒ–ä¸‰å±‚çš„å‚æ•°ï¼ŒW123å’Œb123 åˆå§‹åŒ–weightsï¼ˆæ­£æ€åˆ†å¸ƒï¼‰å’Œbiasï¼ˆå…¨æ˜¯0ï¼‰ -&gt; æ³¨æ„fcå’Œconvå±‚çš„ä¸ä¸€æ · å› ä¸ºåœ¨lossä¸­æœ‰å¸®åŠ©inputçš„å¤§å°ä¿æŒçš„æ“ä½œï¼Œæ‰€ä»¥ç¬¬äºŒå±‚çš„å›¾ç‰‡å¯ä»¥ä¸è€ƒè™‘paddingå’Œstrideçš„å˜åŒ– W1çš„å¤§å°æ˜¯filterçš„å¤§å°(F,C,HH,WW)ï¼Œéœ€è¦filterçš„æ•°é‡ï¼Œchannelçš„æ•°é‡ï¼Œä»¥åŠæ¯ä¸ªfilterçš„å¤§å°ï¼Œb1æ˜¯(filter,) conv_reluä¹‹åŽè¿›è¡Œäº†ä¸€æ¬¡max poolï¼Œæ‰€ä»¥å›¾ç‰‡çš„å¤§å°ç¼©å°äº†ä¸€åŠ åŽé¢ä¸¤ä¸ªaffineçš„å¤§å°å°±è·Ÿè¾“å…¥ï¼Œhidden_numå’Œæœ€åŽçš„num_classesæœ‰å…³ç³»äº†ï¼Œbçš„å¤§å°è·Ÿè¾“å‡ºèµ° æ³¨æ„ç¬¬äºŒä¸ªaffineä¹‹åŽä¸éœ€è¦relu lossç”¨ä¹‹å‰å†™å¥½çš„softmax æ³¨æ„éœ€è¦regularization ç›´æŽ¥ç”¨ä¹‹å‰å†™å¥½çš„æŠŠgradient backå›žåŽ»å°±å¯ä»¥äº† Sanity check lossÂ¶åœ¨å»ºç«‹ä¸€ä¸ªæ–°çš„netçš„æ—¶å€™ï¼Œç¬¬ä¸€ä»¶äº‹å°±åº”è¯¥æ˜¯è¿™ä¸ª ç”¨softmaxçš„æ—¶å€™ï¼Œæˆ‘ä»¬å¸Œæœ›random weightï¼Œæ²¡æœ‰regçš„ç»“æžœæ˜¯log(C) å¦‚æžœåŠ ä¸Šäº†regï¼Œè¿™ä¸ªæ•°é‡ä¼šè½»å¾®å¢žåŠ ä¸€ç‚¹ overfit small data ç›´æŽ¥ç”¨éžå¸¸å°‘çš„æ•°æ®æ¥è®­ç»ƒä¸€ä¸ªæ–°çš„ç½‘ç»œï¼Œåº”è¯¥èƒ½åœ¨è¿™ä¸ªä¸Šé¢overfit åº”è¯¥ä¼šäº§ç”Ÿä¸€ä¸ªéžå¸¸é«˜çš„è®­ç»ƒç²¾åº¦å’Œéžå¸¸ä½Žçš„valç²¾åº¦ æ³¨æ„åœ¨lossé‡Œé¢çš„æ—¶å€™éœ€è¦è®°å½•ä¸‹æ¥scoresï¼Œæˆ‘å°±æ˜¯å› ä¸ºå˜é‡åå†™é”™äº†æ‰€ä»¥ä¸€ç›´bug æœ€åŽè®­ç»ƒå‡ºæ¥çš„train_accæŽ¥è¿‘100%ï¼Œè€Œval_accåªæœ‰ç™¾åˆ†ä¹‹20 1234567891011121314151617181920np.random.seed(231)num_train = 100small_data = &#123; 'X_train': data['X_train'][:num_train], 'y_train': data['y_train'][:num_train], 'X_val': data['X_val'], 'y_val': data['y_val'],&#125;model = ThreeLayerConvNet(weight_scale=1e-2)solver = Solver(model, small_data, num_epochs=15, batch_size=50, update_rule='adam', optim_config=&#123; 'learning_rate': 1e-3, &#125;, verbose=True, print_every=1)solver.train() è®­ç»ƒè¿™ä¸ªä¸‰å±‚çš„ç½‘ç»œ ç›´æŽ¥ç”¨æ‰€æœ‰æ•°æ®è®­ç»ƒè¿™ä¸ªç½‘ç»œï¼Œåº”è¯¥å¾—åˆ°çš„train_accåº”è¯¥åœ¨40% æœ€åŽè®­ç»ƒäº†1ä¸ªepochï¼Œ980æ¬¡iter1(Epoch 1 / 1) train acc: 0.496000; val_acc: 0.489000 å¯è§†åŒ–ç¬¬ä¸€å±‚çš„filter Spatial Batch Normalization åœ¨ä¹‹å‰æˆ‘ä»¬å·²ç»çœ‹åˆ°BNå¯¹äºŽè®­ç»ƒNNå¾ˆæœ‰ç”¨äº†ï¼Œæ ¹æ®15å¹´çš„ä¸€ä¸ªè®ºæ–‡ï¼ŒCNNé‡Œé¢ä¹Ÿå¯ä»¥ç”¨BN -&gt; SBN æ™®é€šçš„BNä¼šæŽ¥æ”¶(N,D)å¤§å°çš„inputï¼Œå¹¶ä¸”outputæ˜¯åŒæ ·çš„å¤§å°ï¼Œnormalçš„æ—¶å€™ç”¨dataçš„æ€»æ•°N CNNé‡Œé¢ï¼Œinputä¸º(N,C,H,W)ï¼Œoutputå¤§å°ç›¸åŒï¼ˆä¹Ÿå°±æ˜¯å’ŒXåŒæ ·å°ºå¯¸ï¼‰ å¦‚æžœç”¨å·ç§¯å¾—åˆ°çš„ç‰¹å¾mapï¼Œwe expect the statistics of each feature channel to be relatively consistent both between different imagesand different locations within the same image -&gt; æ‰€ä»¥åœ¨SBNé‡Œé¢ï¼Œè®¡ç®—å¯¹æ¯ä¸ªCé‡Œé¢çš„ç‰¹å¾è®¡ç®—meanå’Œvar Spatial batch normalization: forwardcs231n/layers.pyinput: x,(N,C,H,W) gamma,scale parameter (C,) beta,shift param (C,) bn_param: dict mode: train/test eps momentum running_mean running_varoutput out,(N,C,H,W) cache, backçš„æ—¶å€™éœ€è¦çš„ä¸œè¥¿ æ³¨æ„ï¼Œå¯ä»¥è°ƒç”¨ä¹‹å‰å†™çš„å…³äºŽ batchnorm_forward çš„å†…å®¹ï¼Œä»£ç åº”è¯¥å°‘äºŽäº”è¡Œ è¿™é‡Œéœ€è¦ç”¨åˆ°å¤šç»´æ•°ç»„çš„è½¬ç½®ï¼Œéœ€è¦æŠŠçŸ©é˜µå˜æˆï¼ˆN H Wï¼‰ * Cçš„æ ¼å¼ï¼Œç„¶åŽåœ¨æ±‚å®Œbnä¹‹åŽå†è½¬å›žåŽ» ä¹‹å‰fcé‡Œé¢ä½¿ç”¨çš„æ—¶å€™çš„å¤§å°æ˜¯(N,D)ï¼Œè¿™æ ·çš„è¯æ˜¯åœ¨æ‰€æœ‰çš„Nä¸Šé¢å–å¹³å‡ è¿™é‡Œçš„Cä»£æ›¿äº†ä»¥å‰çš„Dï¼ŒNHWä»£æ›¿äº†ä»¥å‰çš„N(æŠŠæ¯å¼ ç‰¹å¾å›¾çœ‹åšä¸€ä¸ªç‰¹å¾å¤„ç†ï¼ˆä¸€ä¸ªç¥žç»å…ƒï¼‰ï¼Œè¿™é‡Œçš„ç‰¹å¾å›¾æŒ‡çš„æ˜¯ä¸€å±‚çš„ä¸œè¥¿) è¿™é‡Œç”¨åˆ°çš„æ˜¯ä¸€å¼ ç‰¹å¾å›¾é‡Œé¢çš„æ‰€æœ‰ç¥žç»å…ƒçš„å‚æ•°å…±äº« Spatial batch normalization: backward è¾“å…¥dout(N,C,H,W)å’Œcacheï¼Œè¾“å‡ºdxï¼Œdgammaå’Œdbeta åŒæ ·ä¹Ÿæ˜¯ç›´æŽ¥è°ƒç”¨ä¹‹å‰çš„ï¼Œå˜å½¢æ–¹æ³•å’Œä¹‹å‰ä¸€æ · Group Normalization åŒæ ·åŽŸç†ï¼ŒæŠŠç»´åº¦å˜åŒ–ä¹‹åŽä½¿ç”¨ np.newaxis()]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
        <category>CS231nä½œä¸š</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nassignment2ä¹‹Dropout]]></title>
    <url>%2F2019%2F04%2F18%2FCS231nassignment2Dropout%2F</url>
    <content type="text"><![CDATA[Target regularization NN randomly setting some features to 0 during forward pass Geoffrey E. Hinton et al, â€œImproving neural networks by preventing co-adaptation of feature detectorsâ€, arXiv 2012 Dropout forward + backwardin cs231n/layers.py IO input x,input data, of any shape dropout_params pï¼Œæ¯ä¸ªneuronæ˜¯ä¸æ˜¯ä¿ç•™çš„å¯èƒ½æ€§æ˜¯p modeï¼šâ€™trainâ€™çš„æ—¶å€™ä¼šè¿›è¡Œdropoutï¼Œâ€˜testâ€™çš„æ—¶å€™ä¼šç›´æŽ¥return input seedï¼šç”¨æ¥generate random number for dropout output out, å’ŒxåŒæ ·å¤§å° cache, tuple(dropout_params, mask). In training, mask is used to multiply the input åœ¨å®žçŽ°ä¸­ä¸æŽ¨èç”¨vanillaçš„æ–¹æ³• 123456NOTE: Please implement **inverted** dropout, not the vanilla version of dropout.See http://cs231n.github.io/neural-networks-2/#reg for more details.NOTE 2: Keep in mind that p is the probability of **keep** a neuronoutput; this might be contrary to some sources, where it is referred toas the probability of dropping a neuron output. å®žçŽ° åœ¨è®­ç»ƒçš„æ—¶å€™åœ¨hiddå±‚éƒ½dropäº†ä¸€éƒ¨åˆ†ï¼Œå¦‚æžœæ„¿æ„çš„è¯ä¹Ÿå¯ä»¥åœ¨inputå±‚å°±drop åœ¨predictçš„æ—¶å€™ä¸å†dropäº†ï¼ä½†æ˜¯éœ€è¦æ ¹æ®dropçš„æ¯”ä¾‹å¯¹outputçš„æ•°é‡è¿›è¡Œscale -&gt; æ‰€ä»¥è¿™æ ·å°±ä¼šå˜å¾—å¾ˆéº»çƒ¦ï¼ˆvanillaçš„æ–¹æ³•ï¼‰ æ¯”å¦‚æ¯”ä¾‹æ˜¯pï¼Œdropä¹‹åŽå‰©ä¸‹äº†px é‚£åœ¨testçš„æ—¶å€™xçš„å¤§å°ä¹Ÿåº”è¯¥å˜æˆpx(x -&gt; px) inverted dropoutï¼Œåœ¨è®­ç»ƒçš„æ—¶å€™å°±å¯¹å¤§å°è¿›è¡Œæ”¾ç¼©ï¼Œåœ¨testçš„æ—¶å€™ä¸æŽ¥è§¦forward pass 12H1 = np.maximum(0, np.dot(W1, X) + b1)U1 = (np.random.rand(*H1.shape) &lt; p) / p # /p!!! backçš„å®žçŽ°æ›´å®¹æ˜“äº†ï¼Œå¦‚æžœè¿™ä¸ªç‚¹è¢«dropäº†çš„è¯å¯¹å†å¾€å‰çš„dxå°±æ²¡æœ‰å½±å“ï¼Œå¦‚æžœè¿™ä¸ªç‚¹æ²¡æœ‰è¢«dropçš„è¯å¯¹ä¹‹å‰çš„å½±å“å°±æ˜¯å¸¸æ•° code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081def dropout_forward(x, dropout_param): """ Performs the forward pass for (inverted) dropout. Inputs: - x: Input data, of any shape - dropout_param: A dictionary with the following keys: - p: Dropout parameter. We keep each neuron output with probability p. - mode: 'test' or 'train'. If the mode is train, then perform dropout; if the mode is test, then just return the input. - seed: Seed for the random number generator. Passing seed makes this function deterministic, which is needed for gradient checking but not in real networks. Outputs: - out: Array of the same shape as x. - cache: tuple (dropout_param, mask). In training mode, mask is the dropout mask that was used to multiply the input; in test mode, mask is None. NOTE: Please implement **inverted** dropout, not the vanilla version of dropout. See http://cs231n.github.io/neural-networks-2/#reg for more details. NOTE 2: Keep in mind that p is the probability of **keep** a neuron output; this might be contrary to some sources, where it is referred to as the probability of dropping a neuron output. """ p, mode = dropout_param['p'], dropout_param['mode'] if 'seed' in dropout_param: np.random.seed(dropout_param['seed']) mask = None out = None if mode == 'train': ####################################################################### # TODO: Implement training phase forward pass for inverted dropout. # # Store the dropout mask in the mask variable. # ####################################################################### mask = (np.random.randn(*x.shape) &lt; p) / p out = x * mask ####################################################################### # END OF YOUR CODE # ####################################################################### elif mode == 'test': ####################################################################### # TODO: Implement the test phase forward pass for inverted dropout. # ####################################################################### out = x ####################################################################### # END OF YOUR CODE # ####################################################################### cache = (dropout_param, mask) out = out.astype(x.dtype, copy=False) return out, cachedef dropout_backward(dout, cache): """ Perform the backward pass for (inverted) dropout. Inputs: - dout: Upstream derivatives, of any shape - cache: (dropout_param, mask) from dropout_forward. """ dropout_param, mask = cache mode = dropout_param['mode'] dx = None if mode == 'train': ####################################################################### # TODO: Implement training phase backward pass for inverted dropout # ####################################################################### dx = dout * mask ####################################################################### # END OF YOUR CODE # ####################################################################### elif mode == 'test': dx = dout return dx FC with DP åº”è¯¥åœ¨æ¯å±‚çš„reluä¹‹åŽï¼Œå¢žåŠ dropoutçš„éƒ¨åˆ† åœ¨ä¹‹å‰å®šä¹‰çš„functioné‡Œé¢åŠ ä¸Šæ–°çš„dropoutéƒ¨åˆ†ï¼Œå› ä¸ºå€”å¼ºçš„æƒ³åŠ åœ¨å®šä¹‰å¥½çš„å‡½æ•°é‡Œé¢ï¼Œæ‰€ä»¥äº§ç”Ÿäº†ä¸€äº›å¥‡æ€ªçš„å»¶ä¼¸é—®é¢˜ å¦‚æžœæƒ³è¦å¯é€‰å‚æ•°ï¼Œåœ¨def functioné‡Œé¢ç›´æŽ¥å®šä¹‰å¥½å°±è¡Œäº† å¦‚æžœè¿”å›žå€¼ä¸éœ€è¦ï¼Œç›´æŽ¥åœ¨è¿”å›žçš„æ—¶å€™_å°±å¥½äº† æ³¨æ„åœ¨fc_neté‡Œé¢å¦‚æžœdropout = 1 çš„è¯ï¼Œå®žé™…ä¸Šçš„flagæ˜¯æ²¡æœ‰æ„ä¹‰çš„ 1234567891011121314151617181920212223242526272829303132333435363738def affine_Normal_relu_dropout_forward(self, x, w, b, mode, gamma=None, beta=None, bn_params=None): Normal_cache = None dp_cache = None a, fc_cache = affine_forward(x, w, b) if mode == "batchnorm": mid, Normal_cache = batchnorm_forward(a, gamma, beta, bn_params) elif mode == "layernorm": mid, Normal_cache = layernorm_forward(a, gamma, beta, bn_params) else: mid = a dp, relu_cache = relu_forward(mid) if self.use_dropout: out, dp_cache = dropout_forward(dp, self.dropout_param) else: out = dp cache = (fc_cache, Normal_cache, relu_cache, dp_cache) return out, cachedef affine_Normal_relu_dropout_backward(self, dout, cache, mode): fc_cache, Normal_cache, relu_cache, dp_cache = cache dgamma = 0.0 dbeta = 0.0 if self.use_dropout: ddp = dropout_backward(dout, dp_cache) else: ddp = dout da = relu_backward(ddp, relu_cache) if mode == "batchnorm": dmid, dgamma, dbeta = batchnorm_backward_alt(da, Normal_cache) elif mode == "layernorm": dmid, dgamma, dbeta = layernorm_backward(da, Normal_cache) else: dmid = da dx, dw, db = affine_backward(dmid, fc_cache) return dx, dw, db, dgamma, dbeta regularization experiment è®­ç»ƒä¸€ä¸ª2å±‚çš„ç½‘ç»œï¼Œ500ä¸ªtrainingï¼Œä¸€ä¸ªæ²¡æœ‰dropoutï¼Œå¦ä¸€ä¸ª0.25çš„dp å¹¶ä¸”å¯è§†åŒ–äº†æœ€ç»ˆçš„ç»“æžœ ä»Žç»“æžœä¸Šæ¥çœ‹æ„Ÿè§‰ï¼Œå¦‚æžœepochæ¯”è¾ƒå°‘çš„è¯ï¼Œdropoutçš„æ•ˆæžœä¼šæ›´å¥½ åŠ ä¸Šdropoutï¼Œnormalizationï¼Œçš„fcç½‘ç»œå…¨éƒ¨ä»£ç 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260class FullyConnectedNet(object): """ A fully-connected neural network with an arbitrary number of hidden layers, ReLU nonlinearities, and a softmax loss function. This will also implement dropout and batch/layer normalization as options. For a network with L layers, the architecture will be &#123;affine - [batch/layer norm] - relu - [dropout]&#125; x (L - 1) - affine - softmax where batch/layer normalization and dropout are optional, and the &#123;...&#125; block is repeated L - 1 times. Similar to the TwoLayerNet above, learnable parameters are stored in the self.params dictionary and will be learned using the Solver class. """ def __init__(self, hidden_dims, input_dim=3 * 32 * 32, num_classes=10, dropout=1, normalization=None, reg=0.0, weight_scale=1e-2, dtype=np.float32, seed=None): """ Initialize a new FullyConnectedNet. Inputs: - hidden_dims: A list of integers giving the size of each hidden layer. - input_dim: An integer giving the size of the input. - num_classes: An integer giving the number of classes to classify. - dropout: Scalar between 0 and 1 giving dropout strength. If dropout=1 then the network should not use dropout at all. - normalization: What type of normalization the network should use. Valid values are "batchnorm", "layernorm", or None for no normalization (the default). - reg: Scalar giving L2 regularization strength. - weight_scale: Scalar giving the standard deviation for random initialization of the weights. - dtype: A numpy datatype object; all computations will be performed using this datatype. float32 is faster but less accurate, so you should use float64 for numeric gradient checking. - seed: If not None, then pass this random seed to the dropout layers. This will make the dropout layers deteriminstic so we can gradient check the model. """ self.normalization = normalization self.use_dropout = dropout != 1 self.reg = reg self.num_layers = 1 + len(hidden_dims) self.dtype = dtype self.params = &#123;&#125; ############################################################################ # TODO: Initialize the parameters of the network, storing all values in # # the self.params dictionary. Store weights and biases for the first layer # # in W1 and b1; for the second layer use W2 and b2, etc. Weights should be # # initialized from a normal distribution centered at 0 with standard # # deviation equal to weight_scale. Biases should be initialized to zero. # # # # When using batch normalization, store scale and shift parameters for the # # first layer in gamma1 and beta1; for the second layer use gamma2 and # # beta2, etc. Scale parameters should be initialized to ones and shift # # parameters should be initialized to zeros. # ############################################################################ pr_num = input_dim # can't use enumerate beacuse I need the number more than the size of hidden_dims for layer in range(self.num_layers): layer += 1 weights = 'W' + str(layer) bias = 'b' + str(layer) # è¿™æ—¶å€™æ˜¯æœ€åŽä¸€å±‚(the last layer) if layer == self.num_layers: self.params[weights] = np.random.randn( hidden_dims[len(hidden_dims) - 1], num_classes) * weight_scale self.params[bias] = np.zeros(num_classes) # other layers else: hidd_num = hidden_dims[layer - 1] self.params[weights] = np.random.randn( pr_num, hidd_num) * weight_scale self.params[bias] = np.zeros(hidd_num) pr_num = hidd_num if self.normalization in ["batchnorm", "layernorm"]: self.params['gamma' + str(layer)] = np.ones(hidd_num) self.params['beta' + str(layer)] = np.zeros(hidd_num) # print(len(self.params)) # print(self.params) ############################################################################ # END OF YOUR CODE # ############################################################################ # When using dropout we need to pass a dropout_param dictionary to each # dropout layer so that the layer knows the dropout probability and the mode # (train / test). You can pass the same dropout_param to each dropout layer. self.dropout_param = &#123;&#125; if self.use_dropout: self.dropout_param = &#123;'mode': 'train', 'p': dropout&#125; if seed is not None: self.dropout_param['seed'] = seed # With batch normalization we need to keep track of running means and # variances, so we need to pass a special bn_param object to each batch # normalization layer. You should pass self.bn_params[0] to the forward pass # of the first batch normalization layer, self.bn_params[1] to the forward # pass of the second batch normalization layer, etc. self.bn_params = [] if self.normalization == 'batchnorm': self.bn_params = [&#123;'mode': 'train'&#125; for i in range(self.num_layers - 1)] if self.normalization in ["batchnorm", "layernorm"]: self.bn_params = [&#123;&#125; for i in range(self.num_layers - 1)] # Cast all parameters to the correct datatype for k, v in self.params.items(): self.params[k] = v.astype(dtype) def loss(self, X, y=None): """ Compute loss and gradient for the fully-connected net. Input / output: Same as TwoLayerNet above. """ X = X.astype(self.dtype) mode = 'test' if y is None else 'train' # Set train/test mode for batchnorm params and dropout param since they # behave differently during training and testing. if self.use_dropout: self.dropout_param['mode'] = mode if self.normalization == 'batchnorm': for bn_param in self.bn_params: bn_param['mode'] = mode scores = None ############################################################################ # TODO: Implement the forward pass for the fully-connected net, computing # # the class scores for X and storing them in the scores variable. # # # # When using dropout, you'll need to pass self.dropout_param to each # # dropout forward pass. # # # # When using batch normalization, you'll need to pass self.bn_params[0] to # # the forward pass for the first batch normalization layer, pass # # self.bn_params[1] to the forward pass for the second batch normalization # # layer, etc. # ############################################################################ cache = &#123;&#125; temp_out = X for i in range(self.num_layers): w = self.params['W' + str(i + 1)] b = self.params['b' + str(i + 1)] if i == self.num_layers - 1: scores, cache['cache' + str(i + 1)] = affine_forward(temp_out, w, b) else: if self.normalization in ["batchnorm", "layernorm"]: gamma = self.params['gamma' + str(i + 1)] beta = self.params['beta' + str(i + 1)] temp_out, cache['cache' + str(i + 1)] = self.affine_Normal_relu_dropout_forward( temp_out, w, b, self.normalization, gamma, beta, self.bn_params[i]) else: # temp_out, cache['cache' + # str(i + 1)] = affine_relu_forward(temp_out, w, b) temp_out, cache['cache' + str(i + 1)] = self.affine_Normal_relu_dropout_forward( temp_out, w, b, mode=self.normalization) ############################################################################ # END OF YOUR CODE # ############################################################################ # If test mode return early if mode == 'test': return scores loss, grads = 0.0, &#123;&#125; ############################################################################ # TODO: Implement the backward pass for the fully-connected net. Store the # # loss in the loss variable and gradients in the grads dictionary. Compute # # data loss using softmax, and make sure that grads[k] holds the gradients # # for self.params[k]. Don't forget to add L2 regularization! # # # # When using batch/layer normalization, you don't need to regularize the scale# # and shift parameters. # # # # NOTE: To ensure that your implementation matches ours and you pass the # # automated tests, make sure that your L2 regularization includes a factor # # of 0.5 to simplify the expression for the gradient. # ############################################################################ loss, dscores = softmax_loss(scores, y) reg_loss = 0.0 pre_dx = dscores # dgamma = self.params['gamma'] for i in reversed(range(self.num_layers)): i = i + 1 reg_loss = np.sum(np.square(self.params['W' + str(i)])) loss += reg_loss * 0.5 * self.reg # æœ€åŽä¸€å±‚ if i == self.num_layers: pre_dx, dw, db = affine_backward( pre_dx, cache['cache' + str(i)]) else: if self.normalization in ["batchnorm", "layernorm"]: pre_dx, dw, db, dgamma, dbeta = self.affine_Normal_relu_dropout_backward( pre_dx, cache['cache' + str(i)], self.normalization) grads['gamma' + str(i)] = dgamma grads['beta' + str(i)] = dbeta else: pre_dx, dw, db, _, _ = self.affine_Normal_relu_dropout_backward( pre_dx, cache['cache' + str(i)], self.normalization) dw += self.reg * self.params['W' + str(i)] db += self.reg * self.params['b' + str(i)] grads['W' + str(i)] = dw grads['b' + str(i)] = db ############################################################################ # END OF YOUR CODE # ############################################################################ return loss, grads def affine_Normal_relu_dropout_forward(self, x, w, b, mode, gamma=None, beta=None, bn_params=None): Normal_cache = None dp_cache = None a, fc_cache = affine_forward(x, w, b) if mode == "batchnorm": mid, Normal_cache = batchnorm_forward(a, gamma, beta, bn_params) elif mode == "layernorm": mid, Normal_cache = layernorm_forward(a, gamma, beta, bn_params) else: mid = a dp, relu_cache = relu_forward(mid) if self.use_dropout: out, dp_cache = dropout_forward(dp, self.dropout_param) else: out = dp cache = (fc_cache, Normal_cache, relu_cache, dp_cache) return out, cache def affine_Normal_relu_dropout_backward(self, dout, cache, mode): fc_cache, Normal_cache, relu_cache, dp_cache = cache dgamma = 0.0 dbeta = 0.0 if self.use_dropout: ddp = dropout_backward(dout, dp_cache) else: ddp = dout da = relu_backward(ddp, relu_cache) if mode == "batchnorm": dmid, dgamma, dbeta = batchnorm_backward_alt(da, Normal_cache) elif mode == "layernorm": dmid, dgamma, dbeta = layernorm_backward(da, Normal_cache) else: dmid = da dx, dw, db = affine_backward(dmid, fc_cache) return dx, dw, db, dgamma, dbeta]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
        <category>CS231nä½œä¸š</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>Drop out</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGLç¬”è®°]]></title>
    <url>%2F2019%2F04%2F16%2FOpenGL%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Learn OpenGl on Modern OpenGL. -&gt; ä»Žgraphicsçš„programmingå¼€å§‹è®²çš„ Getting StartOPENGL æ˜¯ä¸€ä¸ªè¿›è¡Œå›¾åƒå¤„ç†çš„å·¥å…· å¯ä»¥è¢«è®¤ä¸ºæ˜¯APIï¼Œä½†æ˜¯å®žé™…ä¸Šæ˜¯specification æ˜Žç¡®è¯´æ˜Žäº†æ¯ä¸ªfunctionåº”è¯¥çš„è¾“å…¥å’Œè¾“å‡ºï¼Œä»¥åŠå¦‚ä½•perform ç”¨æˆ·åœ¨ç”¨è¿™ä¸ªè¯´æ˜Žæ¥è§£å†³é—®é¢˜ï¼Œå› ä¸ºæ²¡æœ‰ç»™å‡ºæ˜Žç¡®çš„implementçš„è¿‡ç¨‹ï¼Œæ‰€ä»¥åªè¦ç»“æžœç¬¦åˆè§„åˆ™ï¼Œæ€Žä¹ˆimplementéƒ½å¯ä»¥ Core-profile vs Immediate mode ä»¥å‰çš„ç‰ˆæœ¬ç”¨çš„æ˜¯immediate mode æ¯”è¾ƒå¥½ç”¨æ¥ç”»å›¾ å…·ä½“çš„æ˜¯å®žçŽ°éƒ½åœ¨libé‡Œé¢ï¼Œdeveloperä¸æ˜¯å¾ˆå¥½çš„èƒ½çœ‹åˆ°å¦‚ä½•è®¡ç®— æ•ˆçŽ‡è¶Šæ¥è¶Šä½Ž Core-profile åœ¨3.2ç‰ˆæœ¬ä¹‹åŽæ”¹æˆäº†è¿™ä¸ª å¼ºåˆ¶ä½¿ç”¨modern practicesï¼Œå¦‚æžœæƒ³è¦ç”¨è¢«åˆ†å‡ºåŽ»çš„functionå°±ä¼šç›´æŽ¥æŠ¥é”™ æ•ˆçŽ‡é«˜ï¼Œæ›´çµæ´»ï¼Œæ›´éš¾å­¦ extensions æ”¯æŒextensionsï¼Œåªè¦æ£€æŸ¥æ”¯ä¸æ”¯æŒgraphic cardå°±å¯ä»¥çŸ¥é“èƒ½ä¸èƒ½ç”¨ å¯ä»¥ç›´æŽ¥ç”¨æ¯”è¾ƒæ–°çš„ä¸œè¥¿ï¼Œä¸ç”¨ç­‰ç€OPENGLæ›´æ–°æ–°çš„åŠŸèƒ½ éœ€è¦åœ¨ç”¨ä¹‹å‰åˆ¤æ–­ä»–æ˜¯ä¸æ˜¯availableçš„ï¼Œå¦‚æžœä¸æ˜¯éœ€è¦ç”¨åŽŸæ¥çš„æ–¹æ³•æž State Machine OpenGLè‡ªå·±å°±æ˜¯ä¸€ä¸ªState Machineï¼šä¸€ä¸ªvarçš„é›†åˆï¼Œæ¥åˆ¤æ–­ä»–çŽ°åœ¨åº”è¯¥å¦‚ä½•æ“ä½œ state -&gt; context æ”¹å˜stateï¼šè®¾å®šä¸€äº›optionsï¼Œæ“ä½œä¸€äº›bufferï¼Œåœ¨çŽ°åœ¨çš„contextæ¥render ä¾‹å­ï¼š å¦‚æžœæˆ‘æƒ³ç”»ä¸‰è§’å½¢ï¼Œè€Œä¸æ˜¯ç”»çº¿äº†ï¼Œå°±æ”¹å˜drawçš„state åªè¦è¿™ä¸ªæ”¹å˜ä¼ è¾¾åˆ°äº†ï¼Œä¸‹ä¸€æ¡çº¿å°±ç”»çš„æ˜¯ä¸‰è§’å½¢äº† state-changingç”¨æ¥æ”¹å˜contextï¼Œstate-usingåœ¨çŽ°åœ¨çš„stateä¸Šé¢å¼€å§‹è¿›è¡Œæ“ä½œ Objects ä¸€ä¸ªé›†åˆæ¥è¡¨çŽ°OpenGLçš„subsetçš„state æ¯”å¦‚å¯ä»¥ç”¨ä¸€ä¸ªobjectæ¥è¡¨ç¤ºå¯¹windowçš„è®¾å®šï¼Œå¯ä»¥è®¾ç½®å¤§å°ï¼Œè®¾ç½®æ”¯æŒçš„é¢œè‰²ç­‰ç­‰123456// The State of OpenGLstruct OpenGL_Context &#123; ... object_name* object_Window_Target; ... &#125;; 12345678910// create objectunsigned int objectId = 0;glGenObject(1, &amp;objectId);// bind object to contextglBindObject(GL_WINDOW_TARGET, objectId);// set options of object currently bound to GL_WINDOW_TARGETglSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_WIDTH, 800);glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_HEIGHT, 600);// set context target back to defaultglBindObject(GL_WINDOW_TARGET, 0); æµç¨‹ é¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ªobjectï¼Œé‡Œé¢å­˜äº†ä¸€ä¸ªrefæ˜¯è¿™ä¸ªobjectçš„id ç„¶åŽæŠŠè¿™ä¸ªobjectå’Œcontextçš„ç›®æ ‡ä½ç½®bindåœ¨äº†ä¸€èµ· è®¾ç½®äº†è¿™äº›windowçš„å‚æ•° æœ€åŽun-bindè¿™ä¸¤ä¸ªä¸œè¥¿ï¼ŒæŠŠwindow targetæ”¹å›žåŽŸæ¥çš„å€¼ è¿™æ ·çš„è¯æˆ‘ä»¬å¯ä»¥åˆ›å»ºå¾ˆå¤šobjectï¼Œæå‰è®¾ç½®å¥½é‡Œé¢çš„é‡ï¼Œç­‰åˆ°éœ€è¦ç”¨çš„æ—¶å€™å°±ç›´æŽ¥bindå°±å¯ä»¥ç”¨äº† æ¯”å¦‚æˆ‘ä»¬æœ‰ä¸€å †objectåŒ…å«äº†å°äººï¼Œå°é©¬ï¼Œå°é¹¿ æƒ³ç”»å“ªä¸ªå°±æŠŠå“ªä¸ªç»‘å®šåˆ°drawé‡Œé¢ï¼Œå°±å¯ä»¥ç›´æŽ¥ç”»å‡ºæ¥äº† Crateing a windowå› ä¸ºæ“ä½œç³»ç»Ÿçš„é—®é¢˜ï¼Œæ‰€æœ‰æ“ä½œç³»ç»Ÿä¸Šé¢ä¸æ˜¯å¾ˆä¸€æ ·ã€‚ä½†æ˜¯å·²ç»æœ‰ä¸€äº›æä¾›è¿™äº›åŠŸèƒ½çš„å‡½æ•°äº†ï¼Œè¿™é‡Œç”¨çš„æ˜¯GLFW GLFW ä¸€ä¸ªlibï¼Œç”¨Cå†™çš„ï¼Œä¸»è¦ç›®çš„æ˜¯æä¾›æŠŠä¸œè¥¿æ¸²æŸ“åˆ°å±å¹•çš„åŠŸèƒ½ å¯ä»¥åˆ›å»ºä¸€ä¸ªcontextï¼Œå®šä¹‰çª—å£çš„paramsï¼Œå¤„ç†ç”¨æˆ·çš„è¾“å…¥ å·²ç»ä¸€å£æ°”é…ç½®å¥½äº†è¿™äº›ï¼https://www.jianshu.com/p/25d5fbf792a2è®°å¾—åœ¨link libé‡Œé¢æŠŠopenGLçš„frameworkåŠ è¿›åŽ»ï¼ï¼ï¼ï¼ï¼ GLAD å› ä¸ºopenGLè¿˜éœ€è¦ä¸åŒç‰ˆæœ¬çš„driverçš„æ”¯æŒï¼Œéœ€è¦æœ‰ä¸œè¥¿æ¥å¤„ç†è¿™éƒ¨åˆ†çš„å†…å®¹ å’Œå…¶ä»–çš„ä¸œè¥¿ä¸åŒï¼ŒGLADç”¨çš„æ˜¯web service åœ¨è¿™ä¸ªç½‘é¡µä¸Šé€‰æ‹©å¥½è¯­è¨€ï¼Œç‰ˆæœ¬å·ï¼Œç¡®ä¿profileæ˜¯coreï¼Œç„¶åŽç”Ÿæˆ ç›´æŽ¥ä¸‹è½½ä¸‹æ¥å¯¹åº”çš„zipï¼Œç„¶åŽæŠŠincludeæ”¾è¿›includeé‡Œé¢ï¼Œ.cæ–‡ä»¶æ”¾åœ¨projecté‡Œé¢ èŽ«åå…¶å¦™å¹¶ä¸éœ€è¦è¿™ä¸€æ­¥ï¼Œç¥žå¥‡ï¼Œå¯èƒ½æ˜¯æˆ‘åœ¨includeé‡Œé¢å·²ç»æžè¿›æ¥äº†ï¼ï¼ Hello Windowåˆå§‹åŒ–12345678910int main()&#123; glfwInit(); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); //glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); return 0;&#125; é¦–å…ˆè¿›è¡Œäº†åˆå§‹åŒ– ç„¶åŽconfigureäº†GLFWï¼Œè®¾ç½®äº†a large enum of possible options prefixed with GLFW_. ï¼ˆç¬¬ä¸‰è¡Œå°±æ˜¯æœ€å°ï¼‰ -&gt; å¤§æ¦‚æ˜¯è®¾ç½®è¦ç”¨GLFWçš„ç‰ˆæœ¬å· ç„¶åŽä¹Ÿå‘Šè¯‰äº†ä»–æƒ³ç”¨core ç„¶åŽéœ€è¦ä½¿ç”¨glfwCreateWindowè¿™ä¸ªå‡½æ•°ï¼Œæ¥åˆ›å»ºè¿™ä¸ªGLFWwindow* windowçš„å˜é‡ åˆ›å»ºçš„å‡½æ•°éœ€è¦çª—å£çš„é•¿å®½ çª—å£å åˆ›å»ºå®Œä¹‹åŽå°±å¯ä»¥æŠŠè¿™ä¸ªçª—å£è®¾ç½®æˆglfwMakeContextCurrent(window);ä¹Ÿå°±æ˜¯è¯´è®¾ç½®æˆäº†çŽ°åœ¨çš„threadé‡Œé¢12345678GLFWwindow* window = glfwCreateWindow(800, 600, "LearnOpenGL", NULL, NULL);if (window == NULL)&#123; std::cout &lt;&lt; "Failed to create GLFW window" &lt;&lt; std::endl; glfwTerminate(); return -1;&#125;glfwMakeContextCurrent(window); GLAD GLADæ˜¯ä¸ºOpenGLæ¥ç®¡ç†è¿™äº›å‡½æ•°çš„ï¼Œåœ¨ä½¿ç”¨è¿™äº›å‡½æ•°ä¹‹å‰éœ€è¦åˆå§‹åŒ–GLAD12345if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress))&#123; std::cout &lt;&lt; "Failed to initialize GLAD" &lt;&lt; std::endl; return -1;&#125; viewpoint åœ¨å¼€å§‹renderä¹‹å‰æˆ‘ä»¬è¿˜éœ€è¦å‘Šè¯‰GLæ¸²æŸ“çª—å£çš„å¤§å°ï¼Œç”¨åˆ°äº†glViewportè¿™ä¸ªå‡½æ•° å‰é¢ä¸¤ä¸ªå‚æ•°å®šä¹‰äº†è¿™ä¸ªçª—å£å·¦ä¸‹è§’çš„åæ ‡ åŽé¢ä¸¤ä¸ªå‚æ•°å®šä¹‰äº†éœ€è¦renderçš„çª—å£çš„å¤§å° æ¯æ¬¡è°ƒæ•´windowçš„å¤§å°çš„æ—¶å€™viewportä¹Ÿéœ€è¦è¢«è°ƒæ•´ engines æˆ‘ä»¬å¸Œæœ›è¿™ä¸ªengineå¯ä»¥ä¸€ç›´æŒç»­ç”»å›¾ï¼Œç›´åˆ°æœ€åŽæˆ‘ä»¬å‘Šè¯‰è¿™ä¸ªçª—å£è¦å…³é—­ï¼Œæ‰€ä»¥è¦å»ºç«‹ä¸€ä¸ªå¾ªçŽ¯ 12345while(!glfwWindowShouldClose(window))&#123; glfwSwapBuffers(window); glfwPollEvents(); &#125; åœ¨è¿™ä¸ªå¾ªçŽ¯é‡Œé¢ï¼Œpolleventæ˜¯æ¥æ£€æŸ¥æ˜¯ä¸æ˜¯æœ‰triggerè¿›æ¥çš„äº‹æƒ…ï¼ˆæ¯”å¦‚é”®ç›˜è¾“å…¥ï¼‰ï¼Œæ›´æ–°çª—å£çš„çŠ¶æ€ï¼Œå¹¶ä¸”callç›¸åº”çš„å‡½æ•° swapbufferï¼Œä¼šäº¤æ¢color bufferï¼ˆåŒ…æ‹¬æ¯ä¸ªåƒç´ ç‚¹é¢œè‰²çš„bufferï¼‰ï¼Œç„¶åŽshowåœ¨çª—å£é‡Œé¢ last thing glfwTerminateé€€å‡ºè¿™ä¸ªå¾ªçŽ¯ä¹‹åŽï¼Œéœ€è¦æ¸…é™¤è¿™äº›ç›¸å…³çš„èµ„æºï¼Œç”¨è¿™ä¸ªå‡½æ•°æ”¾åœ¨æœ€åº•ä¸‹ input éœ€è¦ä¸€äº›é”®ç›˜ä¸Šçš„æ“ä½œæ¥è°ƒæ•´çš„æ—¶å€™ï¼Œå†™äº†ä¸€ä¸ªprocessInputçš„å‡½æ•° æ¯”å¦‚ä¸‹é¢è¿™ä¸ªå‡½æ•°å°±æ˜¯æ£€æµ‹äº†æœ‰æ²¡æœ‰æŒ‰ä¸‹åŽ»escï¼Œå¦‚æžœæŒ‰äº†çš„è¯å°±å…³é—­çª—å£ å†™å®Œä¹‹åŽæŠŠè¿™ä¸ªå‡½æ•°åœ¨whileå¾ªçŽ¯é‡Œé¢è°ƒç”¨12345void processInput(GLFWwindow *window)&#123; if(glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) glfwSetWindowShouldClose(window, true);&#125; rendering å¸Œæœ›åœ¨ä¸€ä¸ªloopé‡Œé¢æ”¾ä¸ŠåŽ»æ‰€æœ‰çš„renderingçš„å‘½ä»¤ï¼Œæ•´ä¸ªå¾ªçŽ¯çœ‹èµ·æ¥åº”è¯¥æ˜¯è¿™ä¸ªæ ·å­çš„12345678910111213// render loopwhile(!glfwWindowShouldClose(window))&#123; // input processInput(window); // rendering commands here ... // check and call events and swap the buffers glfwPollEvents(); glfwSwapBuffers(window);&#125; hello triangleopenglé‡Œé¢æ‰€æœ‰ä¸œè¥¿éƒ½æ˜¯åœ¨3Dçš„ç©ºé—´é‡Œçš„ï¼Œä½†æ˜¯å±å¹•ä¸Šæ˜¾ç¤ºçš„ä¸œè¥¿æ˜¯2Dçš„ã€‚æ•´ä¸ªè¿™ä¸ªè½¬æ¢çš„è¿‡ç¨‹å«åšgraphics pipelineï¼Œå¯ä»¥åˆ†æˆä¸¤ä¸ªæ­¥éª¤ï¼šç¬¬ä¸€ä¸ªæ˜¯æŠŠç‰©ä½“çš„3Dåæ ‡è½¬åŒ–æˆ2Dçš„åæ ‡ï¼Œç¬¬äºŒä¸ªæ˜¯æŠŠ2Dçš„åæ ‡è½¬åŒ–æˆpixelä¸Šé¢çš„å…·ä½“å€¼ pipeline æ‰€æœ‰çš„è½¬åŒ–æ­¥éª¤éƒ½å¯ä»¥parallelçš„è¿›è¡Œï¼ŒçŽ°åœ¨çš„æ˜¾å¡æœ‰å¾ˆå¤šå°çš„coreæ¥è¿›è¡Œ -&gt; shaders åœ¨æœ€å¼€å§‹çš„æ—¶å€™passè¿›åŽ»äº†ä¸€ä¸ªlistçš„3Dåæ ‡ ï¼ˆVertex Dataï¼‰ ç¬¬ä¸€æ­¥ï¼švertex shader æŠŠ3Dçš„åæ ‡è½¬åŒ–æˆä¸åŒçš„3Dåæ ‡ï¼ˆç›¸å½“äºŽæŠŠæ•°æ®è½¬åŒ–æˆç‚¹ï¼Ÿï¼‰ primitive assembly ä»Žä¸Šä¸€æ­¥å¾—åˆ°çš„å·¦å³çš„ç‚¹å¾—åˆ°è¾“å…¥ ç„¶åŽå½¢æˆä¸€ä¸ªåŸºæœ¬çš„å›¾å½¢ geometry shader æ ¹æ®æ–°ç»™çš„ç‚¹ï¼Œå½¢æˆæ–°çš„ä¸åŒçš„å½¢çŠ¶ï¼Œæ¯”å¦‚åœ¨ä¾‹å­é‡Œé¢å½¢æˆäº†æ–°çš„ä¸€æ¡çº¿ rasterization stage æŠŠä¸Šé¢å¾—åˆ°çš„primitives mapåˆ°æœ€åŽçš„å±å¹•ä¸Šé¢çš„ç›¸åº”çš„pixelä¸Šé¢ Clipping è¿™ä¸€æ­¥ä¸¢æŽ‰äº†æ‰€æœ‰åœ¨è§†çº¿å¤–é¢çš„fragmentsï¼Œæå‡æ€§èƒ½ fragment shader è®¡ç®—è¿™ä¸ªpixelæœ€åŽçš„é¢œè‰²ï¼Œä¼šåœ¨è¿™ä¸€æ­¥è®¡ç®—å…‰å½±ï¼Œä»¥åŠå…‰çº¿çš„é¢œè‰²ç­‰ç­‰ä¸œè¥¿ å½“æ¯ä¸ªåƒç´ çš„é¢œè‰²å†³å®šäº†ä»¥åŽï¼Œè¿™ä¸ªobjectä¼šè¢«é€åˆ°alpha testå’Œblending è¿™ä¸€æ­¥ä¼šæµ‹è¯•æ·±åº¦åŽŸå› ï¼Œåˆ¤æ–­fragmentæ˜¯åœ¨ç‰©ä½“çš„å‰é¢è¿˜æ˜¯åŽé¢ è¿˜ä¼šè€ƒè™‘é€æ˜Žåº¦çš„é—®é¢˜è™½ç„¶ä¸Šé¢çš„ä¸œè¥¿å¾ˆå¤æ‚ï¼Œä½†æ˜¯åœ¨å®žé™…åº”ç”¨çš„æ—¶å€™åªéœ€è¦è¦è€ƒè™‘vertexå’Œfragment shader vertex input openGLæ˜¯3Dçš„ä¸œè¥¿ï¼Œæ‰€æœ‰çš„ç‚¹è®¾ç½®inputçš„æ—¶å€™éƒ½éœ€è¦è®¾ç½®ä¸‰ç»´çš„åæ ‡ xyz åªæœ‰åœ¨åæ ‡åœ¨ -1 åˆ° 1 ä¸­é—´çš„æ—¶å€™ï¼Œæ‰ä¼šå¤„ç†è¿™äº›åæ ‡ï¼Œè¿™ä¸ªèŒƒå›´é‡Œé¢çš„æ•°å­—æ˜¯æ ¹æ®å±å¹•çš„æ¯”ä¾‹å¾—å‡ºæ¥çš„normalized device coordinates æ¯”å¦‚åœ¨è¿™ä¸ªä¾‹å­é‡Œé¢ï¼Œéœ€è¦çš„æ¸²æŸ“ä¸€ä¸ªä¸‰è§’å½¢ï¼Œé‚£ä¹ˆéœ€è¦è¿™ä¸ªä¸‰è§’å½¢çš„ä¸‰ä¸ªç‚¹çš„åæ ‡ã€‚æ³¨æ„è¿™ä¸ªä¾‹å­é‡Œé¢æ ¹æœ¬æ²¡æœ‰è€ƒè™‘æ·±åº¦ï¼Œè€Œæ˜¯ç›´æŽ¥ç”»åœ¨äº†å¹³é¢ä¸Šé¢ 12345float vertices[] = &#123; -0.5f, -0.5f, 0.0f, 0.5f, -0.5f, 0.0f, 0.0f, 0.5f, 0.0f&#125;; åœ¨å®šä¹‰å¥½åæ ‡ä¹‹åŽéœ€è¦æŠŠè¿™ä¸ªä¸œè¥¿æ”¾è¿›vertex shaderé‡Œé¢ï¼Œéœ€è¦åœ¨GPUé‡Œé¢åˆ›å»ºä¸€éƒ¨åˆ†å†…å­˜æ¥å­˜å‚¨è¿™ä¸ªæ•°æ®ï¼Œå¹¶ä¸”éœ€è¦åœ¨GPUé‡Œé¢å­˜å‚¨å¤§é‡çš„æ•°æ®ï¼ˆè¿™æ ·ä¸ç”¨æ¯æ¬¡éƒ½é€äº†ï¼‰ æ¯ä¸ªéƒ¨åˆ†çš„objectéƒ½ä¼šæœ‰ä¸€ä¸ªè‡ªå·±çš„buffer idï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢çš„æ–¹æ³•ç”Ÿæˆä¸€ä¸ªidã€‚ä¹Ÿå¯ä»¥æŠŠä¸€ä¸²arrayç»‘åˆ°è¿™ä¸ªidä¸Šé¢12unsigned int VBO;glGenBuffers(1, &amp;VBO);]]></content>
      <categories>
        <category>OpenGl</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment2ä¹‹Batch Normalization]]></title>
    <url>%2F2019%2F04%2F15%2FCS231Nassignment2BN%2F</url>
    <content type="text"><![CDATA[target ä¹‹å‰çš„å†…å®¹è®²äº†lrçš„ä¼˜åŒ–æ–¹æ³•ï¼Œæ¯”å¦‚Adamï¼Œå¦ä¸€ç§æ–¹æ³•æ˜¯æ ¹æ®æ”¹å˜ç½‘ç»œçš„ç»“æž„ï¼Œmake it easy to train -&gt; batch normalization æƒ³åŽ»æŽ‰ä¸€äº›uncorrelated features(ä¸ç›¸å…³çš„ç‰¹å¾)ï¼Œå¯ä»¥åœ¨è®­ç»ƒæ•°æ®ä¹‹å‰preprocessï¼Œå˜æˆ0-centeredåˆ†å¸ƒï¼Œè¿™æ ·ç¬¬ä¸€å±‚æ˜¯æ²¡æœ‰é—®é¢˜çš„ï¼Œä½†æ˜¯åŽé¢çš„å±‚é‡Œè¿˜æ˜¯ä¼šå‡ºé—®é¢˜ æ‰€ä»¥æŠŠnormalizationçš„éƒ¨åˆ†åŠ å…¥äº†DNé‡Œé¢ï¼ŒåŠ å…¥äº†ä¸€ä¸ªBNå±‚ï¼Œä¼šä¼°è®¡meanå’Œstandard deviation of each featureï¼Œè¿™æ ·é‡æ–°centreå’Œnormalized learnable shift and scale parameters for each feature dimension æ ¸å¿ƒæ€æƒ³ï¼šç²—æš´çš„ç”¨BNæ¥è§£å†³weightsåˆå§‹åŒ–çš„é—®é¢˜ refï¼šhttps://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html Batch normalization: forwardè¿™ä¸ªä¸œè¥¿çš„è¦ä¹‰å°±æ˜¯NNé‡Œé¢çš„ä¸€å±‚ï¼Œä¸å¯¹ç»´åº¦æ”¹å˜ï¼Œä½†æ˜¯ä¼šæ”¹å˜è¿™äº›å€¼çš„åˆ†å¸ƒ é¦–å…ˆsetupï¼Œå¹¶ä¸”è½½å…¥å¥½äº†preprocessçš„æ•°æ®cs231n/layers.py -&gt; batchnorm_forward keep exp decay æ¥è¿è¡Œmean &amp; variance of each feature -&gt; åœ¨testçš„æ—¶å€™åŽ»normalize data test-time: è®¡ç®—sample meanå’Œvarienceçš„æ—¶å€™ç”¨å¤§é‡çš„è®­ç»ƒæ•°æ®è€Œä¸æ˜¯ç”¨æ‰€æœ‰å›¾ç‰‡çš„å¹³å‡å€¼ï¼Œä½†æ˜¯åœ¨ä½œä¸šé‡Œé¢ç”¨çš„æ˜¯å¹³å‡å€¼ï¼Œå› ä¸ºå¯ä»¥çœåŽ»ä¸€æ­¥estimateï¼ˆtorch7 ä¹Ÿç”¨çš„æ˜¯å¹³å‡å€¼ï¼‰ 12running_mean = momentum * running_mean + (1 - momentum) * sample_meanrunning_var = momentum * running_var + (1 - momentum) * sample_var I/O input xï¼Œdata(N,D) gammaï¼šscale parameter(D,) betaï¼šshift parameter(D,) bn_param: ä¸€ä¸ªdict modeï¼šâ€˜trainâ€™ or â€˜testâ€™ epsï¼šä¸ºäº†æ•°å­—ä¸Šçš„ç¨³å®šæ€§çš„ä¸€ä¸ªå¸¸æ•° momentumï¼šåœ¨è®¡ç®—meanå’Œvarianceä¸Šé¢çš„ä¸€ä¸ªå¸¸æ•° running meanï¼š(D,)ï¼Œæ˜¯running mean running varï¼š(D,) output outï¼š(N,D) cache:åœ¨backçš„æ—¶å€™ç”¨ todo ç”¨minibatchçš„ç»Ÿè®¡æ¥è®¡ç®—meanå’Œvarianceï¼Œç”¨è¿™ä¸¤ä¸ªå€¼æŠŠdata normalizeï¼Œå¹¶ä¸”ç”¨gammaå’Œbetaæ‹‰ä¼¸è¿™ä¸ªå€¼ï¼Œä»¥åŠshiftè¿™äº›å€¼çš„ä½ç½® åœ¨åˆ†å¸ƒçš„ä¸Šé¢ï¼Œè™½ç„¶æ±‚å¾—æ˜¯running varianceï¼Œä½†æ˜¯éœ€è¦normalizeçš„æ—¶å€™è€ƒè™‘çš„æ˜¯standardï¼ˆä¹Ÿå°±æ˜¯å¹³æ–¹æ ¹ï¼‰ implement å…¶å®žæ˜¯å’Œå¦‚ä½•è®¡ç®—æ¯æ¯ç›¸å…³çš„ï¼ŒçŸ¥é“è¾“å…¥ï¼Œæ±‚è¿™ä¸ªçŽ©æ„çš„normalçš„æ­¥éª¤å¦‚ä¸‹ï¼ˆå…¶ä¸­çš„xå°±æ˜¯è¿™ä¸ªminibatchçš„å…¨éƒ¨æ•°æ®ï¼‰ æ±‚muï¼Œä¹Ÿå°±æ˜¯xçš„meanï¼ˆæ³¨æ„è¿™é‡Œè¦å¯¹åˆ—æ±‚meanï¼Œä¹Ÿå°±æ˜¯æŠŠæ‰€æœ‰å›¾ç‰‡çš„åƒç´ å‡åŒ€åˆ†å¸ƒï¼Œæœ€åŽå¾—åˆ°çš„ç»“æžœæ˜¯Dä¸ªä¸æ˜¯Nä¸ªï¼‰ æ±‚varï¼ŒçŸ¥é“è¿™ä¸ªä¸œè¥¿ï¼Œå¯ä»¥ç›´æŽ¥ç”¨ np.var(x, axis = 0)æ¥æ±‚æ–¹å·® æ±‚normalizeï¼š x - x.mean / np.sqrt(x.var + eps) å…¶ä¸­åˆšå¼€å§‹æ±‚å‡ºæ¥çš„varå°±æ˜¯æ–¹å·®ï¼Œä¹Ÿå°±æ˜¯æ ‡å‡†å·®çš„å¹³æ–¹ epsæ˜¯åå·®å€¼ï¼Œè¿™ä¸ªå€¼åŠ ä¸Šæ–¹å·®å¼€æ–¹æ˜¯æ ‡å‡†å·® scaleå’Œshiftï¼Œä¹˜scaleçš„ç³»æ•°ï¼ŒåŠ shiftçš„ç³»æ•° æœ€åŽéœ€è¦è®¡ç®—ä»€ä¹ˆcacheå’Œbackçš„æŽ¨å¯¼æ¯æ¯ç›¸å…³ Batch normalization: backward å¯ä»¥ç›´æŽ¥ç”»å‡ºæ¥è®¡ç®—normalçš„è·¯å¾„ï¼Œç„¶åŽæ ¹æ®è¿™ä¸ªè·¯å¾„back è¦ä¹‰å°±æ˜¯ä¸€æ­¥ä¸€æ­¥çš„æ±‚å¯¼ï¼ä¸€æ­¥ä¸€æ­¥çš„é“¾å¼æ³•åˆ™ æ³¨æ„çš„å°±æ˜¯æ±‚meanå›žæ¥çš„å¯¼æ•°ï¼Œç†è§£ä¸Šæ¥è¯´å°±æ˜¯è¿™ä¸ªçŸ©é˜µåœ¨æ±‚å¯¼çš„è¿‡ç¨‹ä¸­å‡ç»´äº†ï¼Œä»Ž(D,)å˜æˆäº†(N,D)ï¼Œè€Œåœ¨æœ€å¼€å§‹æ±‚å¾—æ—¶å€™æ‰€æœ‰çš„æ•°å­—çš„è´¡çŒ®éƒ½æ˜¯1ï¼Œæ‰€ä»¥å¾€å›žèµ°çš„æ—¶å€™ä¹˜ä¸€ä¸ªï¼ˆNï¼ŒDï¼‰çš„å…¨æ˜¯1çš„çŸ©é˜µï¼Œå¹¶ä¸”1/Nçš„å¸¸æ•°è¿˜åœ¨ Batch normalization: alternative backward åœ¨sigmoidçš„backçš„è¿‡ç¨‹ä¸­æœ‰ä¸¤ç§ä¸åŒçš„æ–¹æ³• ä¸€ç§æ˜¯å†™å‡ºæ¥æ•´ä½“è®¡ç®—çš„å›¾ï¼ˆæ‹†åˆ†æˆå„ç§å°çš„è®¡ç®—ï¼‰ï¼Œç„¶åŽæ ¹æ®è¿™å¼ å›¾çš„å†backå›žåŽ» å¦ä¸€ç§æ˜¯åœ¨çº¸ä¸Šå…ˆç®€åŒ–äº†æ•´ä½“çš„è®¡ç®—è¿‡ç¨‹ï¼Œç„¶åŽå†ç›´æŽ¥å®žçŽ°ï¼Œè¿™æ ·ä»£ç ä¼šæ¯”è¾ƒç®€å• ref:https://kevinzakka.github.io/2016/09/14/batch_normalization/ æœ€ç»ˆç›®æ ‡ f: BNä¹‹åŽçš„æ•´ä½“è¾“å‡ºç»“æžœ yï¼šå¯¹normalä¹‹åŽçš„çº¿æ€§å˜æ¢ï¼ˆgamma + betaï¼‰ xâ€™ï¼šnormalçš„input muï¼šbatch mean varbatch vatiance éœ€è¦æ±‚ df/dx,df/dgamma,df/dbeta -&gt; æœ€ç»ˆç»“æžœæ•´ä½“é€Ÿåº¦æ¯”ä»¥å‰å¿«äº†x2.5å·¦å³ï¼Œè¿™ä¸€æ­¥çš„ä¸»è¦ç›®çš„å°±æ˜¯ç”¨æ¥æé€Ÿçš„ å¯ä»¥æŠŠæ•´ä½“çš„è®¡ç®—åˆ†ä¸ºä»¥ä¸‹çš„ä¸‰ä¸ªæ­¥éª¤ è¿™ä¸‰éƒ¨åˆ†çš„ä»£ç å¦‚ä¸‹123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208def batchnorm_forward(x, gamma, beta, bn_param): """ Forward pass for batch normalization. During training the sample mean and (uncorrected) sample variance are computed from minibatch statistics and used to normalize the incoming data. During training we also keep an exponentially decaying running mean of the mean and variance of each feature, and these averages are used to normalize data at test-time. At each timestep we update the running averages for mean and variance using an exponential decay based on the momentum parameter: running_mean = momentum * running_mean + (1 - momentum) * sample_mean running_var = momentum * running_var + (1 - momentum) * sample_var Note that the batch normalization paper suggests a different test-time behavior: they compute sample mean and variance for each feature using a large number of training images rather than using a running average. For this implementation we have chosen to use running averages instead since they do not require an additional estimation step; the torch7 implementation of batch normalization also uses running averages. Input: - x: Data of shape (N, D) - gamma: Scale parameter of shape (D,) - beta: Shift paremeter of shape (D,) - bn_param: Dictionary with the following keys: - mode: 'train' or 'test'; required - eps: Constant for numeric stability - momentum: Constant for running mean / variance. - running_mean: Array of shape (D,) giving running mean of features - running_var Array of shape (D,) giving running variance of features Returns a tuple of: - out: of shape (N, D) - cache: A tuple of values needed in the backward pass """ mode = bn_param['mode'] eps = bn_param.get('eps', 1e-5) momentum = bn_param.get('momentum', 0.9) N, D = x.shape running_mean = bn_param.get('running_mean', np.zeros(D, dtype=x.dtype)) running_var = bn_param.get('running_var', np.zeros(D, dtype=x.dtype)) out, cache = None, None if mode == 'train': ####################################################################### # TODO: Implement the training-time forward pass for batch norm. # # Use minibatch statistics to compute the mean and variance, use # # these statistics to normalize the incoming data, and scale and # # shift the normalized data using gamma and beta. # # # # You should store the output in the variable out. Any intermediates # # that you need for the backward pass should be stored in the cache # # variable. # # # # You should also use your computed sample mean and variance together # # with the momentum variable to update the running mean and running # # variance, storing your result in the running_mean and running_var # # variables. # # # # Note that though you should be keeping track of the running # # variance, you should normalize the data based on the standard # # deviation (square root of variance) instead! # # Referencing the original paper (https://arxiv.org/abs/1502.03167) # # might prove to be helpful. # ####################################################################### mean = np.mean(x, axis=0) xmu = x - mean sq = np.square(xmu) var = np.var(x, axis=0) sqrtvar = np.sqrt(var + eps) ivar = 1. / sqrtvar normalize_raw = xmu * ivar normalize_result = gamma * normalize_raw + beta out = normalize_result running_mean = momentum * running_mean + \ (1 - momentum) * mean running_var = momentum * running_var + (1 - momentum) * var cache = (normalize_raw, gamma, xmu, ivar, sqrtvar, var, eps) ####################################################################### # END OF YOUR CODE # ####################################################################### elif mode == 'test': ####################################################################### # TODO: Implement the test-time forward pass for batch normalization. # # Use the running mean and variance to normalize the incoming data, # # then scale and shift the normalized data using gamma and beta. # # Store the result in the out variable. # ####################################################################### x_normalize = (x - running_mean) / (np.sqrt(running_var + eps)) out = x_normalize * gamma + beta ####################################################################### # END OF YOUR CODE # ####################################################################### else: raise ValueError('Invalid forward batchnorm mode "%s"' % mode) # Store the updated running means back into bn_param bn_param['running_mean'] = running_mean bn_param['running_var'] = running_var return out, cachedef batchnorm_backward(dout, cache): """ Backward pass for batch normalization. For this implementation, you should write out a computation graph for batch normalization on paper and propagate gradients backward through intermediate nodes. Inputs: - dout: Upstream derivatives, of shape (N, D) - cache: Variable of intermediates from batchnorm_forward. Returns a tuple of: - dx: Gradient with respect to inputs x, of shape (N, D) - dgamma: Gradient with respect to scale parameter gamma, of shape (D,) - dbeta: Gradient with respect to shift parameter beta, of shape (D,) """ dx, dgamma, dbeta = None, None, None ########################################################################### # TODO: Implement the backward pass for batch normalization. Store the # # results in the dx, dgamma, and dbeta variables. # # Referencing the original paper (https://arxiv.org/abs/1502.03167) # # might prove to be helpful. # ########################################################################### normalize_raw, gamma, xmu, ivar, sqrtvar, var, eps = cache N, D = dout.shape dbeta = np.sum(dout, axis=0) dgammax = dout dgamma = np.sum(dgammax * normalize_raw, axis=0) dnormalize_raw = dgammax * gamma divar = np.sum(dnormalize_raw * xmu, axis=0) dxmu = dnormalize_raw * ivar dsqrtvar = -1. / (sqrtvar ** 2) * divar dvar = 0.5 * 1. / np.sqrt(var + eps) * dsqrtvar dsq = 1. / N * np.ones((N, D)) * dvar dxmu2 = 2 * xmu * dsq dx1 = (dxmu + dxmu2) dmu = -1 * np.sum(dxmu + dxmu2, axis=0) dx2 = 1. / N * np.ones((N, D)) * dmu dx = dx1 + dx2 ########################################################################### # END OF YOUR CODE # ########################################################################### return dx, dgamma, dbetadef batchnorm_backward_alt(dout, cache): """ Alternative backward pass for batch normalization. For this implementation you should work out the derivatives for the batch normalizaton backward pass on paper and simplify as much as possible. You should be able to derive a simple expression for the backward pass. See the jupyter notebook for more hints. Note: This implementation should expect to receive the same cache variable as batchnorm_backward, but might not use all of the values in the cache. Inputs / outputs: Same as batchnorm_backward """ dx, dgamma, dbeta = None, None, None ########################################################################### # TODO: Implement the backward pass for batch normalization. Store the # # results in the dx, dgamma, and dbeta variables. # # # # After computing the gradient with respect to the centered inputs, you # # should be able to compute gradients with respect to the inputs in a # # single statement; our implementation fits on a single 80-character line.# ########################################################################### normalize_raw, gamma, xmu, ivar, sqrtvar, var, eps = cache N, D = dout.shape dbeta = np.sum(dout, axis=0) dgamma = np.sum(dout * normalize_raw, axis=0) # intermediate partial derivatives dxhat = dout * gamma # final partial derivatives dx = (1. / N) * ivar * (N * dxhat - np.sum(dxhat, axis=0) - normalize_raw * np.sum(dxhat * normalize_raw, axis=0)) ########################################################################### # END OF YOUR CODE # ########################################################################### return dx, dgamma, dbeta Fully Connected Nets with Batch Normalizationin cs231n/classifiers/fc_net.py, add the BN layers into the net. åº”è¯¥åœ¨æ¯ä¸ªreluä¹‹å‰åŠ ä¸ŠBNï¼Œæ‰€ä»¥åœ¨è¿™é‡Œä¸èƒ½ç›´æŽ¥ç”¨ä¹‹å‰çš„affineï¼Œreluçš„è¿‡ç¨‹ï¼Œå› ä¸ºä¸­é—´åˆæ’äº†ä¸€ä¸ªæ–°çš„BNå±‚ï¼Œæ‰€ä»¥è¦å†™ä¸€ä¸ªæ–°çš„function æœ€åŽä¸€å±‚ä¹‹åŽçš„è¾“å‡ºä¸åº”è¯¥BN(åº”è¯¥æ˜¯æ¶‰åŠåˆ°å¾ªçŽ¯çš„é—®é¢˜) å®žçŽ°ä¸­é‡åˆ°çš„é—®é¢˜ self.bn_paramsçš„å‚æ•°ç±»åž‹ä¸æ˜¯dictè€Œæ˜¯listï¼Œä»£è¡¨çš„æ˜¯æ‰€æœ‰å±‚é‡Œé¢çš„å‚æ•°çš„æ‰€æœ‰å’Œï¼Œå½“è¿›å…¥åˆ°æ¯å±‚çš„æ—¶å€™å…·ä½“å¯¹åº”çš„æ‰æ˜¯è¿™é‡Œçš„dict å½“æŠŠaffine_BN_reluç»“åˆåœ¨ä¸€èµ·çš„æ—¶å€™ï¼Œæ³¨æ„æœ€åŽä¸€å±‚è¾“å‡ºçš„åœ°æ–¹æ²¡æœ‰BNï¼Œæ‰€ä»¥æ²¡æœ‰ä»–çš„cacheï¼Œéœ€è¦åˆ†å¼€è®¨è®ºï¼Œä¸ç„¶cacheçš„æ•°é‡ä¸å¯¹ æ³¨æ„è¿™ä¸ªfc_netçš„classå› ä¸ºéœ€è¦å®žçŽ°å¤šç§ä¸åŒçš„åŠŸèƒ½ï¼Œæ‰€ä»¥å¯¹äºŽæ˜¯ä¸æ˜¯BNè¦åŠ ä¸Šæ¡ä»¶åˆ¤æ–­ ç¡®å®žéžå¸¸åƒæ­ä¹é«˜äº†ï¼ï¼ è¿™é‡Œä¸»è¦ï¼Œå†™åˆ°è¿™æ‰å‘çŽ°æœ€åŽä¸€å±‚çš„æ—¶å€™å¥½åƒæ˜¯ä¸éœ€è¦reluä¹Ÿä¸éœ€è¦batchnorm å®šä¹‰å¥½çš„å‡½æ•°å—123456789101112131415def affine_BN_relu_forward(self, x, w, b, gamma, beta, bn_params): a, fc_cache = affine_forward(x, w, b) mid, BN_cache = batchnorm_forward(a, gamma, beta, bn_params) out, relu_cache = relu_forward(mid) cache = (fc_cache, BN_cache, relu_cache) return out, cache def affine_BN_relu_backward(self, dout, cache): fc_cache, BN_cache, relu_cache = cache da = relu_backward(dout, relu_cache) dmin, dgamma, dbeta = batchnorm_backward_alt(da, BN_cache) dx, dw, db = affine_backward(dmin, fc_cache) return dx, dw, db, dgamma, dbeta ç»“è®º å¯è§†åŒ–ä¹‹åŽå¯ä»¥å‘çŽ°åŠ äº†normçš„è¯å¥½åƒä¼šä¸‹é™çš„å¿«ä¸€ç‚¹ Batch normalization and initialization è¿›è¡Œè¯•éªŒï¼Œäº†è§£BNå’Œweight initializationçš„å…³ç³» è®­ç»ƒä¸€ä¸ªå…«å±‚çš„ç½‘ç»œï¼ŒåŒ…æ‹¬å’Œä¸åŒ…æ‹¬BNï¼Œç”¨ä¸åŒçš„weight initialization plotå‡ºæ¥train acc, val_acc,train_losså’Œweight initializationçš„å…³ç³» BNçš„ä½œç”¨ä»Žå›¾ä¸­å¯ä»¥çœ‹å‡ºæ¥ï¼Œæœ‰äº†BNä»¥åŽï¼Œweight initå¯¹æœ€ç»ˆç»“æžœçš„å½±å“æ˜Žæ˜¾ä¼šé™ä½Žï¼š weightçš„åˆå§‹åŒ–å¯¹æœ€ç»ˆç»“æžœå½±å“å¾ˆä¸¥é‡ï¼Œæ¯”å¦‚å¦‚æžœå…¨æ˜¯0çš„è¯ï¼Œå¾—åˆ°çš„æ‰€æœ‰neuronçš„åŠŸèƒ½éƒ½æ˜¯ä¸€æ ·çš„ BNå…¶å®žå°±æ˜¯åœ¨å®žé™…ä¸­è§£å†³weight initçš„åŠžæ³•ï¼Œè¿™æ ·å¯ä»¥å‡å°‘åˆå§‹åŒ–å‚æ•°çš„å½±å“ æ ¸å¿ƒæ€æƒ³å°±æ˜¯å¦‚æžœä½ éœ€è¦æ›´å¥½çš„åˆ†å¸ƒï¼Œä½ å°±åŠ ä¸€å±‚è®©ä»–å˜æˆæ›´å¥½çš„åˆ†å¸ƒ åœ¨è®¡ç®—çš„è¿‡ç¨‹ä¸­è¶Šä¹˜è¶Šå°ï¼ˆæˆ–è€…è¶Šå¤§ï¼‰ï¼Œæ‰€ä»¥è®¡ç®—å‡ºæ¥çš„ç»“æžœè¶Šæ¥è¶ŠæŽ¥è¿‘0 æ‰€ä»¥è¿™æ—¶å€™å¦‚æžœæŠŠä¸€äº›inputé‡æ–°åˆ†å¸ƒäº†ï¼Œå°±ä¼šå‡å°‘è¿™ä¸ªæŽ¥è¿‘0çš„å¯èƒ½æ€§ Batch normalization and batch size è¯•éªŒéªŒè¯BNå’Œbatch sizeçš„å…³ç³» è®­ç»ƒ6-layerçš„ç½‘ç»œï¼Œåˆ†åˆ«withå’Œwithout BNï¼Œä½¿ç”¨ä¸åŒçš„batch size By increasing batch size your steps can be more accurate because your sampling will be closer to the real population. If you increase the size of batch, your batch normalisation can have better results. The reason is exactly like the input layer. The samples will be closer to the population for inner activations. Layer Normalizationï¼ˆLNï¼‰ å‰é¢çš„æ‰€æœ‰çš„BNå·²ç»å¯ä»¥è®©Netæ›´å¥½çš„è¢«è®­ç»ƒäº†ï¼Œä½†æ˜¯BNçš„å¤§å°å’Œbatchçš„å¤§å°æœ‰å…³ï¼Œæ‰€ä»¥åœ¨å®žé™…åº”ç”¨çš„æ—¶å€™ä¼šå—åˆ°ä¸€äº›é™åˆ¶ åœ¨å¤æ‚çš„ç½‘ç»œé‡Œé¢çš„æ—¶å€™ï¼Œbatch_sizeæ˜¯è¢«ç¡¬ä»¶æœºèƒ½é™åˆ¶çš„ æ¯ä¸ªminibatchçš„æ•°æ®åˆ†å¸ƒå¯èƒ½ä¼šæ¯”è¾ƒæŽ¥è¿‘ï¼Œæ‰€ä»¥è®­ç»ƒä¹‹å‰è¦shuffleï¼Œå¦åˆ™ç»“æžœä¼šå·®å¾ˆå¤š å…¶ä¸­ä¸€ç§è§£å†³çš„æ–¹æ³•å°±æ˜¯layer normalization ä¸æ˜¯åœ¨batchä¸Šé¢normal åœ¨layerä¸Šé¢normal each feature vector corresponding to a single datapoint is normalized based on the sum of all terms within that feature vector. Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. â€œLayer Normalization.â€ stat 1050 (2016): 21. LN ç»¼åˆä¸€å±‚çš„æ‰€æœ‰ç»´åº¦çš„è¾“å…¥ï¼Œè®¡ç®—è¯¥å±‚çš„å¹³å‡è¾“å…¥å’Œå¹³å‡æ–¹å·® ç„¶åŽç”¨åŒä¸€ä¸ªè§„èŒƒåŒ–æ“ä½œè½¬æ¢å„ä¸ªç»´åº¦çš„è¾“å…¥ ç›¸å½“äºŽä»¥å‰æˆ‘ä»¬å¸Œæœ›å¯ä»¥æ­£åˆ™åˆ°è¿™ä¸ªminibatché‡Œé¢çš„å¤§å®¶éƒ½å·®ä¸å¤šï¼ŒçŽ°åœ¨æˆ‘ä»¬ä¸ç®¡batchäº†ï¼Œè€Œæ˜¯è°ƒæ•´åˆ°ä¸€å¼ å›¾ç‰‡é‡Œé¢çš„æ‰€æœ‰æ•°æ®éƒ½æ˜¯normalçš„ implementcs231n/layers.py -&gt; layernorm_backward forward + back input x, (N,D) gamma, scale beta,shift ln_params: eps output output,(N,D) cache å®žçŽ°æ–¹æ³• -&gt; å®žé™…ä¸Šå°±æ˜¯ä»Žå¯¹ä¸€åˆ—çš„æ“ä½œå˜æˆäº†å¯¹ä¸€è¡Œçš„æ“ä½œ æ¯”å¦‚ä¹‹å‰å¯¹xå–meanå°±æ˜¯æ±‚æ¯åˆ—çš„meanï¼ŒçŽ°åœ¨å˜æˆäº†å–æ¯è¡Œçš„mean åœ¨æ‰€æœ‰normalä¹‹åŽå¹¶ä¸”scaleä¹‹å‰ï¼ŒæŠŠè¿™ä¸ªçŸ©é˜µåœ¨tranposeå›žæ¥ back æŠŠéœ€è¦å‚ä¸Žè®¡ç®—çš„ä¸œè¥¿éƒ½tranpose ç„¶åŽæŠŠè®¡ç®—å®Œçš„dx tranposeå›žæ¥ fc_netsåœ¨fc_netsé‡Œé¢ç¨åŠ æ”¹åŠ¨ï¼Œåœ¨normalizationé‡Œé¢å¢žåŠ BN_NORMå’ŒLayer_NORMçš„é€‰é¡¹å°±å¯ä»¥äº†ï¼Œæ•´ä½“æ”¹åŠ¨ä¸å¤§123456789101112131415161718192021def affine_Normal_relu_forward(self, x, w, b, gamma, beta, bn_params, mode): a, fc_cache = affine_forward(x, w, b) if mode == "batchnorm": mid, Normal_cache = batchnorm_forward(a, gamma, beta, bn_params) elif mode == "layernorm": mid, Normal_cache = layernorm_forward(a, gamma, beta, bn_params) out, relu_cache = relu_forward(mid) cache = (fc_cache, Normal_cache, relu_cache) return out, cache def affine_Normal_relu_backward(self, dout, cache, mode): fc_cache, Normal_cache, relu_cache = cache da = relu_backward(dout, relu_cache) if mode == "batchnorm": dmid, dgamma, dbeta = batchnorm_backward_alt(da, Normal_cache) elif mode == "layernorm": dmid, dgamma, dbeta = layernorm_backward(da, Normal_cache) dx, dw, db = affine_backward(dmid, fc_cache) return dx, dw, db, dgamma, dbeta å¯ä»¥ä»Žå›¾åƒçœ‹å‡ºæ¥ï¼Œlayernormä¸­ï¼Œbatchsizeçš„å½±å“å˜å°äº†]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
        <category>CS231nä½œä¸š</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>Batch Normalization</tag>
        <tag>Layer Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CppPrimerç¬”è®°]]></title>
    <url>%2F2019%2F04%2F15%2FCppPrimer%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ç¬¬ä¸€éƒ¨åˆ† Basics C++åœ¨ç¼–è¯‘çš„æ—¶å€™å°±ä¼šæ£€æŸ¥ç±»åž‹ allow programmers to define types that include operations as well as data ç¬¬äºŒç«  varibles and basic type2.1 bulid-inåŸºç¡€ç±»åž‹åŒ…æ‹¬ç®—æ•°ç±»åž‹ï¼ˆarithmtic typeï¼‰å’Œvoidç±»åž‹ï¼Œvoidç”¨äºŽæ²¡æœ‰è¿”å›žå€¼çš„å‡½æ•° 2.1.1 ç®—æ•°ç±»åž‹includeï¼šintergalï¼ˆbool&amp; charï¼‰/ float ä¸åŒçš„é•¿åº¦çš„å«æ³•ä¸åŒï¼š char -&gt; wchar_t, char16_t, char32_t(åŽé¢ä¸¤ä¸ªfor unicodeï¼Œè‡ªç„¶è¯­è¨€é‡Œé¢) int -&gt; short, long, long long float -&gt; double, long double æ‰©å±•ï¼šåœ¨å‚¨å­˜ä¿¡æ¯æ–¹é¢ï¼Œå‚¨å­˜åœ¨æ¯ä¸ªbyteé‡Œé¢ï¼Œæ˜¯æœ€å°çš„è®¡é‡å•ä½ï¼ˆ8bitsï¼‰ã€‚åœ¨å†…å­˜ä¸­ï¼Œæ¯ä¸ªbyteæ‹¥æœ‰ä¸€ä¸ªaddressï¼Œéœ€è¦çŸ¥é“åœ°å€å’Œç±»åž‹æ‰çŸ¥é“åˆ°åº•å­˜å‚¨çš„æ˜¯ä»€ä¹ˆä¸œè¥¿ã€‚ signed &amp; unsignedï¼ˆé™¤äº†boolï¼‰ï¼š signedï¼šåŒ…æ‹¬0çš„æ­£æ•°å’Œè´Ÿæ•° unsignedï¼šå¤§äºŽç­‰äºŽé›¶ æ²¡æœ‰å†™unsignedçš„è¯å°±æ˜¯signedçš„ å¯¹äºŽcharæ¥è¯´ï¼Œsignedï¼Œunsiginedå’Œcharä¸‰ç§ charåˆ°åº•ç®—ä¸ç®—unsignedæ˜¾ç¤ºå–å†³äºŽç¼–è¯‘å™¨ unsignedä»Ž0-255 signedä¸€èˆ¬æ˜¯-128 ï½ž 127 å…³äºŽåˆ°åº•æ€Žä¹ˆç”¨ï¼š å½“ç¡®å®šä¸å¯èƒ½æ˜¯è´Ÿå€¼çš„æ—¶å€™ç”¨unisgned shortå¤ªçŸ­äº†ï¼Œlongå¤ªé•¿äº†ï¼Œå¹³å¸¸ç”¨intï¼Œintä¸å¤Ÿç”¨long long å¦‚æžœç”¨charï¼Œä¸ºäº†è€ƒè™‘åˆ°ä¸åŒç¼–è¯‘çš„ç»“æžœä¸åŒï¼Œç¡®å®šå¥½ç”¨signedè¿˜æ˜¯unsigned ç”¨doubleï¼Œfloatçš„ç²¾åº¦ä¸å¤Ÿï¼Œlong doubleå°å·å†…å­˜ 2.1.2 ç±»åž‹è½¬æ¢ï¼ˆconversionsï¼‰åœ¨æŠŠä¸€ä¸ªä¸œè¥¿åŠ åˆ°å¦ä¸€ä¸ªçš„è¿‡ç¨‹ä¸­ï¼Œæ”¯æŒè‡ªåŠ¨çš„ç±»åž‹è½¬æ¢ å½“boolè¢«èµ‹å€¼ä¸ºéž0æ—¶ï¼Œä¸ºtrueï¼Œ0æ—¶ä¸ºfalse ç»™intèµ‹å€¼doubleï¼Œè‡ªåŠ¨å˜æˆæ•´æ•°ï¼›ç»™doublèµ‹å€¼intï¼Œå˜æˆæ•´æ•°åŽé¢.0 å½“unsignedè¶…å‡ºç•Œé™æ—¶ï¼Œthe result is the remainder of the value modulo the number of values the target type can hold. å½“signedè¶…å‡ºç•Œé™çš„æ—¶å€™ï¼Œç»“æžœæ˜¯undefinedã€‚ä¸çŸ¥é“ä¼šå‘ç”Ÿä»€ä¹ˆäº‹ã€‚ åœ¨å†™ä»£ç çš„æ—¶å€™å°½é‡é¿å…æ²¡æœ‰å®šä¹‰çš„ï¼Œæˆ–è€…åœ¨implementä¸­æ‰å®šä¹‰çš„è¡Œä¸ºï¼Œå› ä¸ºè¿™æ ·å®¹æ˜“å¯¼è‡´åœ¨è¿™ä¸ªç”µè„‘ä¸Šè¡Œå¾—é€šä½†æ˜¯æ¢ä¸ªåœ°æ–¹æ²¡å‡†å°±è¡Œä¸é€šäº† ä¸€äº›å¼•èµ·çš„é—®é¢˜ï¼š intå’Œunsignedç›¸åŠ ï¼Œä¼šå¼•èµ·wrap around ä¸¤ä¸ªunsignedç›¸å‡å¦‚æžœå°äºŽé›¶ä¼šå‡ºé—®é¢˜ åœ¨forå¾ªçŽ¯çš„æ¡ä»¶é‡Œï¼Œunsigedä½œä¸ºå˜é‡çš„è¯æ°¸è¿œä¸ä¼šå°äºŽé›¶ æ±‚æ±‚ä½ äº†åæ­£ä¸è¦æ··ç€ç”¨ 2.1.3 literalsæ¯ä¸ªliteraléƒ½æœ‰ä¸€ä¸ªtypeï¼Œè¿™æ˜¯ç”±formå’Œvalueå†³å®šçš„ã€‚ æ•´æ•°ç±»åž‹çš„ 0å¼€å¤´çš„æ•´æ•°æ˜¯å…«è¿›åˆ¶ï¼Œ0xæ˜¯16è¿›åˆ¶ è´Ÿå·ä¸æ˜¯literalçš„ä¸€éƒ¨åˆ†ï¼Œæ¯”å¦‚ -42ï¼Œ42æ˜¯literalï¼Œè´Ÿå·æ˜¯operator floatç±»åž‹çš„ åè¿›åˆ¶å¸¦å°æ•°ç‚¹çš„æ•°å­— ç”¨exponentï¼ŒEæˆ–è€…eï¼ŒeåŽé¢çš„ä¸œè¥¿å°±æ˜¯åçš„å¤šå°‘æ¬¡æ–¹ character stringçš„ç±»åž‹æ˜¯ä¸€ä¸ªcharçš„arrayï¼Œcomplierä¼šåœ¨æ¯ä¸ªstring åŽé¢åŠ ä¸Šâ€˜\0â€™ï¼ˆnull characterï¼‰ escape -&gt; ä¸€äº›å¸¦æœ‰å¥‡æ€ªæ„ä¹‰çš„\nï¼Œ\t,\â€™ç­‰ç­‰ å¦‚æžœåœ¨\åŽé¢è·Ÿç€å¤šäºŽä¸‰ä¸ªæ•°å­—ï¼Œåªä¼šè¯»å–å‰ä¸‰ä¸ª \xä¼šè¯»å–è·Ÿåœ¨å¥¹åŽé¢çš„æ‰€æœ‰hex digits å•ç‹¬æ”¹å˜ä¸€ä¸ªliteralï¼Œåœ¨æ•°å­—åŽé¢åŠ åŽç¼€suffix Uï¼šunsigned type Lï¼šlong ULLï¼šunsigned long long ä½†æ˜¯å¦‚æžœä½ è¦ç»™1024åŽé¢åŠ ä¸ªfå°±ä¸è¡Œï¼Œå› ä¸º1024æ˜¯æ•´å½¢ï¼ˆè¿™æ—¶å€™åˆå¼€å§‹æ€€å¿µpythonï¼‰ bool 2.2 å˜é‡ Variableså˜é‡æä¾›çš„æ˜¯ï¼šå‘½åå¥½çš„å­˜å‚¨ç©ºé—´ï¼Œç¨‹åºå¯ä»¥å¯¹ä»–æ‰§è¡Œï¼Œæ¯ä¸ªå˜é‡éƒ½æœ‰typeï¼ˆå…¶å®žä¹Ÿå°±æ˜¯classæˆ–è€…objectå—ï¼‰ 2.2.1 å˜é‡çš„å®šä¹‰ assignment(èµ‹å€¼)å’Œinitialize(åˆå§‹åŒ–)åœ¨c++é‡Œé¢æ˜¯ä¸ä¸€æ ·çš„ï¼Œåˆå§‹åŒ–æ˜¯åœ¨åˆ›å»ºçš„æ—¶å€™èµ‹äºˆçš„å€¼ï¼Œèµ‹å€¼æ˜¯ä¹‹åŽæ”¹å˜è¿™ä¸ªå˜é‡çš„å€¼ listçš„åˆå§‹åŒ–ï¼šå°–æ‹¬å·ã€‚ åœ¨ä½¿ç”¨bulit-inçš„æ—¶å€™ï¼Œå¯èƒ½æ— æ³•liståˆå§‹åŒ–è¿™ä¸ªå˜é‡ï¼Œå› ä¸ºä¼šä¸¢å¤±ä¸€äº›ä¿¡æ¯ã€‚æ¯”å¦‚æŠŠä¸€ä¸ªdoubleæ‰”åˆ°inté‡Œé¢ æ˜¯å¦å¯ä»¥ä¸åˆå§‹åŒ–å°±ä½¿ç”¨å–å†³äºŽclassçš„å®šä¹‰ã€‚æ¯”å¦‚è¦æ˜¯intæ²¡æœ‰åˆå§‹åŒ–çš„æ—¶å€™æ˜¯0ï¼Œstringæ²¡æœ‰åˆå§‹åŒ–çš„æ—¶å€™æ˜¯ç©ºå­—ç¬¦ä¸² 2.2.2 å˜é‡declarationï¼ˆå£°æ˜Žï¼Ÿï¼‰å’Œå®šä¹‰ åœ¨åˆ†å¼€ç¼–å†™ä»£ç çš„æ—¶å€™ï¼Œéœ€è¦çŸ¥é“è°ƒç”¨çš„å‡½æ•°ä»Žå“ªé‡Œæ¥ã€‚æ³¨æ„ï¼šä¸åˆå§‹åŒ–å˜é‡å®¹æ˜“å‡ºé—®é¢˜ï¼Œå»ºè®®åˆå§‹åŒ–æ¯ä¸ªbulit-in declarationï¼šè®©ç¨‹åºçŸ¥é“å‡½æ•°çš„åå­— åœ¨å‰é¢åŠ ä¸Šexternï¼Œå°±å¯ä»¥declareä½†æ˜¯ä¸define ä½†æ˜¯å¦‚æžœå·²ç»åˆå§‹åŒ–äº†å‡½æ•°ï¼Œå°±ä¸èƒ½åŠ externäº†ï¼Œä¼šå¼•èµ·é”™è¯¯ åœ¨å…¶ä»–å‡½æ•°çš„åœ°æ–¹è°ƒç”¨çš„æ—¶å€™ï¼ˆuse a varible in multiple filesï¼‰ï¼Œä¸éœ€è¦å†defineäº†ï¼Œä½†æ˜¯éœ€è¦å£°æ˜Ž definationï¼šåˆ›å»ºç›¸åº”çš„å®žä½“ é™¤äº†å¹²declarationçš„äº‹æƒ…ï¼Œä»–è¿˜åˆ†é…å†…å­˜ï¼Œæˆ–è€…æä¾›åˆå§‹å€¼ å˜é‡è¢«defineä¸€æ¬¡ï¼Œä½†æ˜¯å¯ä»¥è¢«declarationæ— æ•°æ¬¡ã€‚ 2.2.3 identifiersï¼ˆå®šä¹‰çš„åå­—ï¼‰ è¦æ±‚ æ•°å­—ï¼Œå­—æ¯ï¼Œä¸‹åˆ’çº¿underscore å¯¹å¤§å°å†™æœ‰åŒºåˆ† ä¸èƒ½ä½¿ç”¨C++çš„å…³é”®è¯ ä¸èƒ½å«æœ‰ä¸¤ä¸ªç›¸è¿žçš„ä¸‹åˆ’çº¿ 2.2.4 åå­—çš„scope ä½¿ç”¨çš„æ„ä¹‰ï¼šåŒä¸€ä¸ªåå­—å¯èƒ½ä¼šåœ¨ç¨‹åºçš„å…¶ä»–åœ°æ–¹è¢«ä½¿ç”¨ï¼Œæ‰€ä»¥è¦ç”¨scopeç¡®å®šè¿™ä¸ªåå­—åœ¨å“ªä¸ªèŒƒå›´é‡Œé¢æœ‰æ„ä¹‰ï¼ˆä¸æ˜¯namespaceå•Šå•Šå•Šå•Šå•Šç«Ÿç„¶æ˜¯å¤§æ‹¬å·æˆ‘éœ‡æƒŠï¼‰ nested scope åœ¨å¤–å±‚è¢«å®šä¹‰çš„åå­—å¯ä»¥åœ¨å†…å±‚è¢«é‡æ–°å®šä¹‰ æ¸©æƒ…å»ºè®®ï¼šå±€éƒ¨å˜é‡å’Œå…¨å±€å˜é‡ä¸è¦ä½¿ç”¨ä¸€ä¸ªåå­— 2.3 compound typesï¼ˆæœ‰èŒƒå›´çš„ç±»åž‹ï¼Ÿï¼‰å°±æ˜¯å®šä¹‰åœ¨å…¶ä»–ç±»åž‹ä¹‹ä¸Šçš„ç±»åž‹ã€‚åœ¨c++é‡Œé¢æœ‰ä¸¤ä¸ªï¼Œpointerå’Œreference 2.3.1 referenceï¼ˆlvalue referenceï¼‰åœ¨åˆ›å»ºçš„æ—¶å€™ï¼Œcopyçš„ä¸æ˜¯å¯¹è±¡çš„å€¼ï¼Œè€Œæ˜¯æŠŠreferå’Œå€¼ç»‘åœ¨äº†ä¸€èµ·ï¼Œåœ¨åˆ›å»ºä¹‹åŽä¸èƒ½å†å’Œåˆ«çš„ä¸œè¥¿ç»‘åœ¨ä¸€èµ·ã€‚referenceå¿…é¡»åˆå§‹åŒ–ã€‚ ä¸æ˜¯å¯¹è±¡ï¼Œæ˜¯ä¸€ä¸ªå·²ç»å­˜åœ¨çš„å¯¹è±¡çš„å¦ä¸€ä¸ªåå­— ç»™referèµ‹å€¼çš„æ—¶å€™ï¼Œå®žé™…ä¸Šæ˜¯èµ‹å€¼ç»™referæ‰€ç»‘å®šçš„å¯¹è±¡ å½“ç»™ä¸€ä¸ªreferèµ‹å€¼å¦ä¸€ä¸ªreferçš„æ—¶å€™ï¼Œå…¶å®žæ˜¯ç»‘åˆ°äº†åŒä¸€ä¸ªå¯¹è±¡ï¼ˆä½†æ˜¯ä¸åº”è¯¥è¿™ä¹ˆå®šä¹‰ï¼‰ å®šä¹‰ åœ¨referçš„åå­—ä¹‹å‰åŠ ä¸Š&amp;ï¼Œä½†æ˜¯åœ¨åŽç»­ä½¿ç”¨çš„æ—¶å€™å¯ä»¥ä¸å¸¦äº† referåªèƒ½åˆå§‹åŒ–æˆä¸€ä¸ªå¯¹è±¡ï¼Œä¸èƒ½æ˜¯ä¸€ä¸ªå…·ä½“çš„å€¼ ç±»åž‹è¦æ­£ç¡® 2.3.2 pointerå’Œreferä¸åŒï¼ŒæŒ‡é’ˆæ˜¯ä¸€ä¸ªobjectï¼Œä»–ä»¬å¯ä»¥è¢«assignæˆ–è€…copyï¼Œåœ¨å®šä¹‰çš„æ—¶å€™ä¸å¿…é¡»åˆå§‹åŒ–ï¼Œä¸€ä¸ªæŒ‡é’ˆå¯ä»¥æŒ‡å‘ä¸åŒçš„ä¸œè¥¿ã€‚åœ¨å®šä¹‰çš„æ—¶å€™ç”¨ * æ¥è¡¨ç¤º å–å€ pointerå¯ä»¥å¾—åˆ°å¦ä¸€ä¸ªå¯¹è±¡çš„addressã€‚&amp;ä¹Ÿå¯ä»¥ä½œä¸ºå–å€ç¬¦å·å¾—åˆ°ä¸€ä¸ªå¯¹è±¡çš„åœ°å€ï¼ˆå’Œreferä¸ä¸€æ ·ï¼ï¼ï¼‰ ç±»åž‹å¿…é¡»åŒ¹é… pointerçš„å€¼ï¼ˆå¯ä»¥æ˜¯ä»¥ä¸‹å››ä¸ªä¹‹ä¸€ï¼‰ æŒ‡å‘ä¸€ä¸ªå¯¹è±¡ æŒ‡å‘ä¸€ä¸ªåœ¨å¯¹è±¡ä¸­æœ«å°¾çš„ä½ç½®ï¼ˆæ²¡æœ‰ä½¿ç”¨çš„å®žé™…æ„ä¹‰ï¼‰ nullæŒ‡é’ˆï¼Œè¡¨ç¤ºè¿˜æ²¡æœ‰å’Œå…¶ä»–çš„ç»‘å®š æ— æ•ˆçš„ï¼Ÿï¼Ÿå¦‚æžœæ˜¯æ— æ•ˆçš„è¯æ˜¯ä¸èƒ½è®¿é—®çš„ è®¿é—®å¯¹è±¡ å½“ä¸€ä¸ªpointeræŒ‡å‘å¯¹è±¡çš„æ—¶å€™ï¼Œä½¿ç”¨dereferenceï¼ˆ ï¼‰æ¥å¾—åˆ°å¥¹çš„å€¼ã€‚ï¼ˆpointer pæ˜¯ä¸€ä¸ªåœ°å€ï¼Œ pæ˜¯ä»–è¿™ä¸ªåœ°å€ä¸Šçš„å€¼ ç©ºæŒ‡é’ˆNULL ä½¿ç”¨nullptrå®šä¹‰ assignä¸€ä¸ªintå˜é‡ç»™pointeræ˜¯éžæ³•çš„ï¼Œå³ä½¿è¿™ä¸ªæ•°æ˜¯0ï¼ˆèµ‹å€¼çš„æ—¶å€™ç»™çš„æ˜¯å˜é‡çš„åœ°å€ï¼Œå¸¦&amp;çš„ï¼‰ çœŸè¯šå»ºè®®ï¼šåˆå§‹åŒ–æ‰€æœ‰çš„pointerï¼Œæ²¡æœ‰åˆå§‹åŒ–çš„å¾ˆéš¾åˆ†è¾¨å‡ºæ¥åˆ°åº•è¿™ä¸ªåœ°å€æ˜¯æœ‰æ•ˆè¿˜æ˜¯æ— æ•ˆ assignment å†™æˆ pi = &amp;valçš„æ—¶å€™ï¼Œæ”¹å˜çš„æ˜¯piçš„å€¼ï¼Œä»–æŒ‡å‘äº†val å†™æˆ * pi = 0 çš„æ—¶å€™ï¼Œæ”¹å˜çš„æ˜¯valçš„å€¼ï¼Œvalå˜æˆäº†0 void* Pointers void* æ˜¯ä¸€ä¸ªå¾ˆç‰›é€¼çš„æŒ‡é’ˆï¼Œå¯ä»¥holdæ‰€æœ‰å¯¹è±¡çš„åœ°å€ ä½œç”¨ï¼šå¯ä»¥ä¼ åˆ°å‡½æ•°æˆ–è€…ä½œä¸ºå‡½æ•°çš„è¿”å›žå€¼ï¼Œå¯ä»¥å’Œå…¶ä»–æŒ‡é’ˆæ¯”è¾ƒï¼Œå¯ä»¥èµ‹å€¼ç»™å¦ä¸€ä¸ªvoid* æŒ‡é’ˆï¼Œä½†æ˜¯ä¸èƒ½æ“æŽ§å¯¹è±¡çš„åœ°å€ 2.3.3 ç†è§£ å®šä¹‰å¤šä¸ªå˜é‡ è™½ç„¶åœ¨å®šä¹‰æŒ‡é’ˆçš„æ—¶å€™å¯ä»¥åŠ ç©ºæ ¼ï¼Œä½†æ˜¯ int* p1ï¼Œp2ä¹‹ä¸­ï¼Œp1æ˜¯æŒ‡é’ˆï¼Œp2æ˜¯int pointeråˆ°pointer å†™æˆä¸€ä¸²æ˜Ÿå·å¯ä»¥è¡¨ç¤ºä»Žpointeråˆ°pointer referåˆ°pointer &amp;rå¯ä»¥å®šä¹‰æˆä¸€ä¸ªpointerï¼ˆæŒ‡é’ˆå†™åœ¨=å³è¾¹ï¼‰ 2.4 ä¿®é¥°è¯ const ä½œç”¨ï¼šå¸Œæœ›å®šä¹‰ä¸€ä¸ªvariableï¼Œvalueä¸å¯ä»¥è¢«æ”¹å˜ï¼Œè¿™æ—¶å€™å°±ç”¨ä¸Šäº†constã€‚åœ¨åˆ›å»ºçš„æ—¶å€™å¿…é¡»åˆå§‹åŒ– åœ¨å®žé™…æ“ä½œçš„æ—¶å€™ï¼Œåˆ°åº•æ˜¯ä¸æ˜¯constå¯¹æ•°å€¼æ²¡æœ‰å½±å“ï¼Œå¯ä»¥ç”¨éžconstæ¥åˆå§‹åŒ–constæˆ–è€…ç”¨constæ¥åˆå§‹åŒ–å…¶ä»–çš„ åœ¨åˆ›å»ºä¹‹åŽï¼Œç¼–è¯‘çš„æ—¶å€™æ‰€æœ‰çš„å˜é‡åéƒ½ä¼šæ¢æˆå˜é‡çš„å€¼ constå¯¹æ¯ä¸ªfileæ¥è¯´æ˜¯localçš„ å¦‚æžœå¸Œæœ›å®šä¹‰ä¸€ä¸ªåœ¨æ‰€æœ‰fileé‡Œé¢éƒ½å¯ä»¥ç”¨çš„ï¼Œç„¶åŽåœ¨å…¶ä»–ä½¿ç”¨çš„æ—¶å€™å£°æ˜Žï¼Œè¿™æ—¶å€™ç”¨extern constï¼ˆåœ¨å®šä¹‰å’ŒåŽç»­å£°æ˜Žçš„æ—¶å€™éƒ½éœ€è¦ä½¿ç”¨ï¼‰ 2.4.1 refer to const å¯ä»¥referåˆ°ä¸€ä¸ªconstï¼Œä½†æ˜¯ä¹‹åŽå°±ä¸èƒ½é€šè¿‡referæ¥æ”¹å˜å˜é‡çš„å€¼ï¼Œä¹Ÿä¸èƒ½æŠŠä¸€ä¸ªconstçš„å˜é‡èµ‹å€¼ç»™ä¸€ä¸ªéžconstçš„refer const referçš„æ„æ€æ˜¯è¿™ä¸ªreferä¸èƒ½è¢«ç”¨æ¥æ”¹å˜å˜é‡ï¼Œä½†æ˜¯è¢«ç»‘çš„å˜é‡æœ¬èº«å¯ä»¥æ”¹å˜ã€‚æ¯”å¦‚const int &amp;r2 = iï¼Œè¿™æ—¶å€™æ”¹å˜iæ˜¯åˆæ³•çš„ 2.4.2 pointer and const pointer to constä¸èƒ½è¢«ç”¨äºŽæ”¹å˜æŒ‡å‘çš„ä¸œè¥¿ ä½†æ˜¯pointeræ˜¯constçš„å’Œå˜é‡è‡ªå·±æ”¹ä¸æ”¹æ²¡å…³ç³»ã€‚å˜é‡æ˜¯constçš„è¯æŒ‡é’ˆå¿…é¡»æ˜¯constçš„ const pointer æŒ‡é’ˆæœ¬èº«å°±æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œæ‰€ä»¥æŒ‡é’ˆè‡ªå·±ä¹Ÿå¯ä»¥æ˜¯constçš„ å¿…é¡»è¢«åˆå§‹åŒ–ï¼Œä¸€æ—¦åˆå§‹åŒ–äº†ï¼Œä»–çš„å†…å®¹ï¼ˆæ‰€æŒ‡å‘çš„åœ°å€ï¼‰å°±ä¸èƒ½æ”¹å˜äº†ã€‚ å®šä¹‰çš„æ—¶å€™ç”¨ int * const cpr = &amp;num ï¼ˆconstçš„ä½ç½®æ”¹å˜äº†ï¼‰ ä½†æ˜¯å¯ä»¥ç”¨const pointeræ¥æ”¹å˜æ‰€æŒ‡å‘ä¸œè¥¿çš„å€¼ï¼ï¼ï¼åªæ˜¯è¿™ä¸¤ä¸ªä¸œè¥¿ç»‘å®šäº†ä¸èƒ½æ”¹äº†è€Œå·² 2.4.3 top-level å¯ä»¥åˆ†å¼€è€ƒè™‘pointerå’Œå¯¹è±¡ top-levelï¼špointerè‡ªå·±æ˜¯ä¸€ä¸ªconst -&gt; æœ¬èº«å°±æ˜¯constçš„ï¼Œå¯ä»¥å‡ºçŽ°åœ¨ä»»ä½•çš„å¯¹è±¡é‡Œé¢ low-levelï¼šæŒ‡å‘ä¸€ä¸ªconst -&gt; åªå‡ºçŽ°åœ¨referå’Œpointeré‡Œé¢ å½“copyä¸€ä¸ªå¯¹è±¡çš„æ—¶å€™ï¼Œtop-levelæ˜¯è¢«å¿½ç•¥çš„å¸¸é‡æŒ‡é’ˆå°±æ˜¯ä¸€ä¸ªå¸¸é‡ï¼Œä¸èƒ½æŠŠå¸¸é‡ç»™æ™®é€šä½†æ˜¯å¯ä»¥æŠŠæ™®é€šç»™å¸¸é‡ 2.4.4 constexpr å¸¸é‡è¡¨è¾¾å¼æ˜¯ç¼–è¯‘çš„æ—¶å€™ä¸èƒ½æ”¹å˜çš„ï¼Œconst objectæˆ–è€…literaléƒ½æ˜¯å¸¸é‡è¡¨è¾¾å¼ã€‚åªæœ‰åœ¨åˆå§‹åŒ–çš„æ—¶å€™çŸ¥é“äº†çš„å€¼æ‰æ˜¯å¸¸é‡è¡¨è¾¾å¼ã€‚å¦‚æžœæ˜¯ä¸ªconst intä½†æ˜¯ä¸ç¡®å®šåˆ°åº•æ˜¯ä»€ä¹ˆï¼Œé‚£ä¹ˆå°±è¿˜ä¸ç®— åœ¨å‰é¢åŠ ä¸Š constexprï¼Œè¿™æ—¶å€™åªæœ‰å½“åŽé¢çš„å˜é‡æ˜¯å¸¸é‡çš„æ—¶å€™æ‰èƒ½ç”¨ å¯ä»¥åœ¨compileçš„æ—¶å€™åˆ¤å®š å½“è¿™ä¸ªç±»åž‹ä¸æ˜¯literalçš„æ—¶å€™ï¼Œä¸èƒ½å®šä¹‰æˆå¸¸é‡è¡¨è¾¾å¼ï¼ˆliteralåŒ…æ‹¬ç®—æ•°ï¼Œpointerå’Œreferï¼‰ åœ¨å‡½æ•°å†…å®šä¹‰çš„å˜é‡ä¸€èˆ¬ä¸ä¼šå‚¨å­˜åœ¨å›ºå®šçš„åœ°å€ï¼Œæ‰€ä»¥è¿™æ—¶å€™æŒ‡é’ˆä¸èƒ½æ˜¯constexprï¼ˆ6.1.1ï¼‰ å½“ä½¿ç”¨constexprçš„æ—¶å€™ï¼Œä½œç”¨åœ¨çš„æ˜¯æŒ‡é’ˆä¸Šè€Œä¸æ˜¯æŒ‡å‘çš„ä¸œè¥¿ä¸Š1const int *p = nullptr; // p is a pointer to a const int constexpr int *q = nullptr; // q is a const pointer to int 2.5 types ç±»åž‹2.5.1 type aliases å³ä¸ºå¯¹å¦ä¸€ä¸ªtypeçš„åŒ–å -&gt; ç®€åŒ–æ¯”è¾ƒå¤æ‚çš„typeï¼Œæ›´å¥½ä½¿ç”¨ å®šä¹‰æ–¹æ³•1ï¼š 12typedef double wages; // wages is a synonym for doubletypedef wages base, *p; // base is a synonym for double, p for double* æ–¹æ³•2: using SI = Sales_itemï¼› å’Œpointerä»¥åŠconst -&gt; ç”¨çš„æ—¶å€™ç›´æŽ¥æ›¿ä»£ä¼šå‡ºé—®é¢˜123typedef char *pstring;const pstring cstr = 0; // cstr is a constant pointer to charconst pstring *ps; // ps is a pointer to a constant pointer to char 2.5.2 auto ä½œç”¨ï¼šæœ‰çš„æ—¶å€™æ²¡æ³•å®šä¹‰å˜é‡çš„typeï¼Œè¿™æ—¶å€™å¯ä»¥ç”¨autoï¼Œç¼–è¯‘çš„æ—¶å€™ä¼šè‡ªåŠ¨æŒ‡å‡ºå˜é‡çš„ç±»åž‹ï¼ˆä»Žåˆå§‹åŒ–çš„ç»“æžœæŽ¨æ–­å‡ºæ¥çš„ï¼‰ å†™æˆä¸€è¡Œå®šä¹‰çš„æ—¶å€™ï¼Œautoä¸èƒ½åŒ…æ‹¬ä¸åŒçš„ç±»åž‹ï¼ˆå¦‚intå’Œdoubleï¼‰ æŒ‡é’ˆreferï¼Œconstå’Œauto å½“ç”¨autoç„¶åŽç”¨ä¸€ä¸ªreferåˆå§‹åŒ–çš„æ—¶å€™ï¼Œå¾—åˆ°çš„ç»“æžœæ˜¯referç»‘å®šçš„object å¦‚æžœéœ€è¦autoä¹‹åŽçš„ç»“æžœè¿˜æ˜¯constçš„ï¼Œéœ€è¦åœ¨autoå‰é¢åŠ ä¸Šconst1234const int ci = i, &amp;cr = ci;auto b = ci; // b is an int (top-level const in ci is dropped)auto c = cr; // c is an int (cr is an alias for ci whose const is top-level) autod=&amp;i; // d isan int*(&amp; ofan int objectis int*)auto e = &amp;ci; // e is const int*(&amp; of a const object is low-level const) 2.5.3 decltype ä½œç”¨ï¼šä»Žexpré‡Œé¢æŽ¨æ–­å‡ºæ¥typeï¼Œä½†æ˜¯ä¸ç”¨è¿™ä¸ªexpræ¥åˆå§‹åŒ–çš„æ—¶å€™ã€‚è¿™æ—¶å€™ç”¨decltype(fun())ï¼Œè¿™æ—¶å€™funç”¨æ¥åˆ¤æ–­å˜é‡çš„ç±»åž‹ï¼Œä½†æ˜¯ä¸call å¦‚æžœæ˜¯å¿…é¡»åˆå§‹åŒ–çš„ä¸œè¥¿ï¼ˆæ¯”å¦‚pointeræˆ–è€…referï¼‰å¿…é¡»åˆå§‹åŒ– decltype(* p) is int&amp;, not plain int decltype((variable))è‚¯å®šæ˜¯ä¸€ä¸ªreferï¼Œä½†æ˜¯decltype(variable)åªæœ‰å½“variableæ˜¯referçš„æ—¶å€™æ‰æ˜¯ ç¬¬ä¸‰ç«  stringï¼Œvectorï¼Œarrayç¬¬äºŒç« è¯´çš„æ˜¯c++é‡Œé¢çš„built-inç±»åž‹ï¼Œé™¤æ­¤ä¹‹å¤–è¿˜æœ‰å¾ˆå¤šlibraryçš„ç±»åž‹ï¼ˆæ ‡å‡†åº“ï¼‰ï¼Œå®šä¹‰äº†å¾ˆå¤šé«˜äºŽè®¡ç®—æœºå†…éƒ¨ç›´æŽ¥è®¿é—®çš„æ•°å­—å’Œå­—æ¯çš„ç±»åž‹ã€‚ 3.1 namespaceå£°æ˜Ž æ¯æ¬¡éƒ½å£°æ˜Žå‡½æ•°çš„namespaceæ¯”è¾ƒéº»çƒ¦ï¼Œå¯ä»¥åœ¨æ‰€æœ‰çš„å¼€å§‹ä¹‹å‰ç”¨using namespace :: nameæ¥å£°æ˜Žä½¿ç”¨çš„ç‰¹å®šçš„å‡½æ•°çš„namespaceã€‚æˆ–è€…ç›´æŽ¥ç”¨ä»–ä»£è¡¨æ‰€æœ‰çš„ã€‚ å¤´æ–‡ä»¶é‡Œé¢ä¸åº”è¯¥ç”¨usingï¼Œå› ä¸ºincludeçš„æ—¶å€™å°±åŠ åˆ°æ‰€æœ‰çš„ä¸œè¥¿é‡Œé¢äº†ï¼Œé‚£å°±æ²¡æœ‰æ„ä¹‰äº† 3.2 stringstringå®šä¹‰åœ¨stdçš„namespaceé‡Œé¢ 3.2.1 å®šä¹‰å’Œåˆå§‹åŒ– ä¸€ä¸ªä¸çŸ¥é“çš„åˆå§‹åŒ–æ–¹æ³•ï¼š string s(n,â€™bâ€™)ï¼Œè¾“å‡ºç»“æžœæ˜¯nä¸ªb ä½¿ç”¨s(â€œhiyaâ€)å’Œs=â€hiyaâ€ä¸€ä¸ªæ˜¯directçš„åˆå§‹åŒ–æ–¹æ³•ï¼Œå¦ä¸€ä¸ªæ˜¯copyçš„åˆå§‹åŒ–æ–¹æ³•ã€‚æ¯”è¾ƒå®¹æ˜“è¯»çš„æ–¹æ³•æ˜¯åˆ›å»ºï¼š string s = string(10,â€™bâ€™) 3.2.2 stringçš„æ“ä½œ stringçš„è¯»å’Œå†™ï¼Œcoutå’Œcinï¼ˆiostreamåº“ï¼‰ å½“é”®ç›˜æœ‰è¾“å…¥çš„æ—¶å€™ï¼Œwhile(cin &gt;&gt; word)è¿™ç§æ„Ÿè§‰çš„ä¸œè¥¿å½“æ¡ä»¶ï¼Œcinæ˜¯ä¼šè¯†åˆ«ç©ºæ ¼ç„¶åŽåˆ†å¼€çš„ï¼ï¼ï¼ getline()å¯ä»¥è¯»å–ä¸€æ•´è¡Œï¼Œå­˜åœ¨ç¬¬äºŒä¸ªå‚æ•°é‡Œé¢ï¼Œå¹¶ä¸”å¸®å¿™è·³åˆ°æ–°çš„ä¸€è¡Œ .empty()å’Œ.size()å¯ä»¥åˆ¤å®šæ˜¯å¦ä¸ºç©ºï¼Œä»¥åŠstringé‡Œé¢çš„charçš„æ•°é‡ string:: size_type sizeçš„è¿”å›žå€¼çš„ç±»åž‹æ˜¯size_type æ³¨æ„ï¼šå› ä¸ºè¿”å›žå€¼ç±»åž‹ä¸åŒï¼Œæ‰€ä»¥å½“æ¯”è¾ƒsizeçš„æ—¶å€™ï¼Œå¦‚æžœå’Œä¸€ä¸ªintçš„è´Ÿæ•°æ¯”è¾ƒï¼Œintä¼šè¢«è½¬æ¢æˆunisgnedçš„ä¸€ä¸ªå·¨å¤§çš„æ•°å­—ï¼Œä»Žè€Œå¯¼è‡´æ¯”è¾ƒçš„å¤±è´¥ -&gt; æ‰€ä»¥åœ¨ä½¿ç”¨sizeçš„è¯­å¥é‡Œé¢ï¼Œä¸ç”¨intæ¯”è¾ƒå¥½ï¼ˆäº²èº«è¯æ˜Žç¡®å®žå¦‚æ­¤ï¼Œæ¢æˆdoubleå°±æ²¡äº‹äº†ï¼‰ æ¯”è¾ƒå­—ç¬¦ä¸² == æˆ–è€… ï¼= æ¥æ¯”è¾ƒä¸¤ä¸ªæ˜¯å¦ç›¸ç­‰ï¼Œéœ€è¦æ˜¯ç›¸åŒçš„é•¿åº¦ä¸”åŒ…æ‹¬ç›¸åŒçš„å­—æ¯ æ¯”è¾ƒä¸¤ä¸ªçš„å¤§å°æ—¶ å¦‚æžœé•¿åº¦ä¸åŒï¼Œå¦‚æžœçŸ­çš„æ¯ä¸ªçš„å­—æ¯éƒ½å’Œé•¿çš„ç›¸åŒï¼Œé‚£çŸ­çš„æ¯”è¾ƒå° å¦‚æžœä»»ä½•ä¸€ä½ä¸Šé¢çš„charä¸åŒï¼Œé‚£å°±æ˜¯ç¬¬ä¸€ä¸ªä¸åŒçš„charæ¯”è¾ƒçš„ç»“æžœ add å­—ç¬¦ä¸²å¯ä»¥ç›´æŽ¥ç›¸åŠ ï¼ˆæŒ‡s1+s2ï¼‰ å¯ä»¥æŠŠstringå’Œliteralæ··ç€åŠ ï¼Œä½†æ˜¯ä¸¤ä¸ªå¸¦å¼•å·çš„ä¸èƒ½è¿žåœ¨ä¸€èµ·ç›´æŽ¥åŠ ï¼ˆè¿™æ˜¯ä»€ä¹ˆè„‘æ®‹è§„åˆ™ï¼‰ ç»ƒä¹  å¯ä»¥ç›´æŽ¥é€šè¿‡ç´¢å¼•vectorçš„æ–¹æ³•ç´¢å¼•stringé‡Œé¢çš„charï¼ˆä½†æ˜¯ä¸€ä¸ªè¯ä¸€ä¸ªè¯è¯»å–ç›´æŽ¥ç”¨cin&gt;&gt; sä¹Ÿæ˜¯å¯ä»¥çš„ï¼ˆæˆ‘æ˜¯å‚»é€¼å—ï¼‰ï¼‰ äºŒæ‹©çš„åˆ¤æ–­æ¡ä»¶å¯ä»¥å†™æˆ ((str1.size() &gt; str2.size()) ? str1 : str2) 3.2.3 stringé‡Œé¢çš„chars æœ‰æ—¶å€™éœ€è¦å¤„ç†æ¯ä¸€ä¸ªå­—æ¯ï¼Œæœ‰çš„æ—¶å€™éœ€è¦å¤„ç†ç‰¹æ®Šçš„ä¸€äº›å­—æ¯ï¼Œå®šä¹‰åœ¨å‡½æ•°cctypeé‡Œé¢]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Cpp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽnumpyé‡Œé¢random.randå’Œrandnçš„åŒºåˆ«]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%85%B3%E4%BA%8Erandomrand%E5%92%8Crandn%2F</url>
    <content type="text"><![CDATA[pythoné‡Œé¢å¸¸ç”¨çš„ä¸¤ä¸ªäº§ç”Ÿéšæœºæ•°çš„å‡½æ•°ï¼Œä¸¤ä¸ªä¸å¤ªä¸€æ · å…¶ä¸­ np.random.rand()æ˜¯ç”¨æ¥äº§ç”Ÿ0-1ä¹‹é—´çš„éšæœºæ•°çš„ï¼Œè¿™ä¸ªæœ€è¿‘åº”ç”¨æœ€å¤šçš„åœ°æ–¹æ˜¯åœ¨äº§ç”Ÿä¸€ä¸ªä»Ža-bèŒƒå›´é‡Œé¢çš„æ•°å­—ï¼Œè¿™æ—¶å€™å¯ä»¥å…ˆäº§ç”Ÿä¸€ä¸ªå·¨å¤§çš„éšæœº0-1çš„çŸ©é˜µï¼Œç„¶åŽå†ä¹˜ä»¥aå’Œbä¹‹é—´çš„å·® np.random.randn()äº§ç”Ÿçš„æ˜¯éšæœºæ­£æ€åˆ†å¸ƒçš„æ ‡å‡†å€¼ï¼Œå¤–é¢å¯ä»¥ä¹˜ä¸Šstdå°±æ˜¯éœ€è¦çš„æ­£æ€åˆ†å¸ƒï¼Œè¿™æ ·å¯ä»¥ç”¨æ¥åˆå§‹åŒ–æ·±åº¦ç½‘ç»œçš„weightsï¼Œæ‹¬å·é‡Œå¡«çš„éƒ½æ˜¯ç”Ÿæˆçš„ä¸œè¥¿çš„ç»´åº¦ å¦å¤–ä¸€ä¸ªé—®é¢˜ï¼Œrandnçš„å‚æ•°éœ€è¦çš„æ˜¯interï¼Œæ‰€ä»¥åœ¨è¾“å…¥çš„æ—¶å€™è¦ä¸æ˜¯é€‰æ‹© np.random.randn(x0.shape[0], x0.shape[1]) np.random.randn(*x0.shape)]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>random</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment2ä¹‹FCnet]]></title>
    <url>%2F2019%2F04%2F11%2FCS231Nassignment2FCnet%2F</url>
    <content type="text"><![CDATA[This part is from the assignment 2018:stanford cs231n assignment2 ç›®æ ‡ ä¹‹å‰å·²ç»å®žçŽ°äº†ä¸¤å±‚çš„fc netï¼Œä½†æ˜¯åœ¨è¿™ä¸ªç½‘ç»œé‡Œé¢çš„losså’Œgradientçš„è®¡ç®—ç”¨çš„æ˜¯æ•°å­¦æ–¹æ³• è¿™æ ·çš„è®¡ç®—å¯ä»¥åœ¨ä¸¤å±‚çš„ç½‘ç»œé‡Œå®žçŽ°ï¼Œä½†æ˜¯å¤šå±‚çš„æƒ…å†µä¸‹å®žçŽ°èµ·æ¥å¤ªå›°éš¾äº† æ‰€ä»¥åœ¨è¿™é‡ŒæŠŠç”µè„‘åˆ†æˆäº†forward passå’Œbackward pass forwardçš„è¿‡ç¨‹ä¸­ï¼ŒæŽ¥å—æ‰€æœ‰çš„inputï¼Œweightsï¼Œå’Œå…¶ä»–çš„å‚æ•°ï¼Œè¿”å›žoutputå’Œcacheï¼ˆå­˜å‚¨backçš„æ—¶å€™éœ€è¦çš„ä¸œè¥¿ï¼‰ 12345678910def layer_forward(x, w): """ Receive inputs x and weights w """ # Do some computations ... z = # ... some intermediate value # Do some more computations ... out = # the output cache = (x, w, z, out) # Values we need to compute gradients return out, cache backçš„æ—¶å€™ä¼šæŽ¥å—derivativeå’Œä¹‹å‰å­˜å‚¨çš„cacheï¼Œç„¶åŽè®¡ç®—æœ€åŽçš„gradient 12345678910111213def layer_backward(dout, cache): """ Receive dout (derivative of loss with respect to outputs) and cache, and compute derivative with respect to inputs. """ # Unpack cache values x, w, z, out = cache # Use values in cache to compute derivatives dx = # Derivative of loss with respect to x dw = # Derivative of loss with respect to w return dx, dw è¿™æ ·å°±å¯ä»¥ç»„åˆå„ä¸ªéƒ¨åˆ†è¾¾åˆ°æœ€ç»ˆéœ€è¦çš„æ•ˆæžœäº†ï¼Œæ— è®ºå¤šæ·±éƒ½å¯ä»¥å®žçŽ°äº† è¿˜éœ€è¦ä¸€éƒ¨åˆ†çš„ä¼˜åŒ–éƒ¨åˆ†ï¼ŒåŒ…æ‹¬Dropoutï¼ŒBatch/Layerçš„Normalization Affine layerï¼šforwardinput xï¼šå¤§å°ï¼ˆNï¼Œd_1â€¦d_k)ï¼Œminibatch of Nï¼Œæ¯å¼ å›¾ç‰‡çš„ç»´åº¦æ˜¯d_1åˆ°d_kï¼Œæ‰€ä»¥æ‹‰æˆä¸€é•¿æ¡çš„ç»´åº¦æ˜¯ d_1 d_2â€¦ d_k wï¼šweightsï¼Œ(D,M)ï¼ŒæŠŠè¿™ä¸ªé•¿åº¦æ˜¯dçš„å›¾ç‰‡ï¼Œè¾“å‡ºçš„æ—¶å€™å°±å˜æˆMäº† b:bias,(M,) -&gt; è¿™ä¸ªbiasä¼šè¢«broadcaståˆ°all lines ï¼ˆbiasçš„å€¼æ˜¯æœ€ç»ˆåˆ†ç±»çš„classçš„å€¼ï¼Œåœ¨ä¸æ˜¯æœ€åŽä¸€å±‚çš„æ—¶å€™å°±æ˜¯outputçš„å€¼ï¼‰ï¼Œç›¸å½“äºŽä¸€ä¸ªclassåˆ†ä¸€ä¸ªbiasï¼ˆä¸€åˆ—ï¼‰ output output,(N,M) cache:(x,w,b) implement è¿™é‡Œçš„å®žçŽ°ç›´æŽ¥reshapeå°±å¯ä»¥äº†ï¼Œ-1çš„æ„æ€æ˜¯è¿™ä¸ªç»´åº¦ä¸Šä¸çŸ¥é“æœ‰å¤šå°‘åæ­£ä½ è‡ªå·±ç»™æˆ‘ç®—ç®—çš„æ„æ€ï¼Œä½†æ˜¯éœ€è¦Nè¡Œæ˜¯ç¡®å®šäº†çš„ æ³¨æ„è¿™é‡ŒéªŒè¯çš„æ—¶å€™è™½ç„¶inputçš„æ˜¯sizeï¼Œä½†æ˜¯å®žé™…ä¸Šæ˜¯æŠŠæ•°å­—å¡«åˆ°è¿™ä¸ªé‡Œé¢çš„ï¼Œæ‰€ä»¥å–Nçš„æ—¶å€™å®žé™…ä¸Šæ˜¯x.shape[0] Affine layer:backwardinput dout: upstream derivative, shape(N,M) cache: Tuple x w b return dx: (N,d1,d2â€¦,dk) dw:(D,M) db:(M,) implement æ³¨æ„è¿™é‡Œç”¨åˆ°çš„æ˜¯é“¾å¼æ³•åˆ™ï¼šdf/dx = df/dq * dq/dx è¿™é‡Œçš„df/dqå°±æ˜¯å·²ç»æ±‚å‡ºæ¥çš„dout qçš„å¼å­æ˜¯ Wx + bï¼Œå¯¹è¿™ä¸‰ä¸ªå˜é‡åˆ†åˆ«æ±‚å¯¼ï¼Œæ±‚å‡ºæ¥å¤§å®¶çš„ï¼Œåˆ«å¿˜äº†æ±‚å¯¼ä¹‹åŽçš„ä¸œè¥¿éœ€è¦å†ä¹˜dout ç»“æžœåˆ°åº•æ€Žä¹ˆç®—åº”è¯¥æŒ‰æ¯ä¸ªçŸ©é˜µçš„shapeæ¥æŽ¨å‡ºæ¥ ReLU activationforward inputï¼šxï¼Œéšä¾¿ä»€ä¹ˆå°ºå¯¸éƒ½å¯ä»¥ï¼Œè¿™éƒ¨åˆ†åªæ˜¯è®¡ç®—reluè¿™ä¸ªå‡½æ•° output outï¼Œè®¡ç®—å‡ºæ¥çš„ç»“æžœ cacheï¼Œå‚¨å­˜xï¼Œç”¨æ¥backçš„è¿ç®— implement -&gt; ç›´æŽ¥æŠŠå°äºŽ0çš„éƒ¨åˆ†è®¾ç½®æˆ0å°±å¯ä»¥äº† backward input è¿”å›žå›žæ¥çš„dout cache outputï¼š è®¡ç®—å‡ºæ¥çš„xçš„æ¢¯åº¦ implement: æ±‚å¯¼ï¼Œå½“åŽŸæ¥çš„xå¤§äºŽ0çš„æ—¶å€™ï¼Œå¯¼æ•°æ˜¯1ï¼Œé“¾å¼æ³•åˆ™æ˜¯doutã€‚å°äºŽç­‰äºŽ0çš„æ—¶å€™æ˜¯dout æ‰€ä»¥ç›´æŽ¥å¯¹doutè¿›è¡Œæ“ä½œå°±å¯ä»¥äº† 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107def affine_forward(x, w, b): """ Computes the forward pass for an affine (fully-connected) layer. The input x has shape (N, d_1, ..., d_k) and contains a minibatch of N examples, where each example x[i] has shape (d_1, ..., d_k). We will reshape each input into a vector of dimension D = d_1 * ... * d_k, and then transform it to an output vector of dimension M. Inputs: - x: A numpy array containing input data, of shape (N, d_1, ..., d_k) - w: A numpy array of weights, of shape (D, M) - b: A numpy array of biases, of shape (M,) Returns a tuple of: - out: output, of shape (N, M) - cache: (x, w, b) """ out = None ########################################################################### # TODO: Implement the affine forward pass. Store the result in out. You # # will need to reshape the input into rows. # ########################################################################### out = x.reshape(x.shape[0], -1).dot(w) + b ########################################################################### # END OF YOUR CODE # ########################################################################### cache = (x, w, b) return out, cachedef affine_backward(dout, cache): """ Computes the backward pass for an affine layer. Inputs: - dout: Upstream derivative, of shape (N, M) - cache: Tuple of: - x: Input data, of shape (N, d_1, ... d_k) - w: Weights, of shape (D, M) - b: Biases, of shape (M,) Returns a tuple of: - dx: Gradient with respect to x, of shape (N, d1, ..., d_k) - dw: Gradient with respect to w, of shape (D, M) - db: Gradient with respect to b, of shape (M,) """ x, w, b = cache dx, dw, db = None, None, None ########################################################################### # TODO: Implement the affine backward pass. # ########################################################################### dx = dout.dot(w.T).reshape(x.shape) dw = (x.reshape(x.shape[0], -1).T).dot(dout) db = np.sum(dout, axis=0) ########################################################################### # END OF YOUR CODE # ########################################################################### return dx, dw, dbdef relu_forward(x): """ Computes the forward pass for a layer of rectified linear units (ReLUs). Input: - x: Inputs, of any shape Returns a tuple of: - out: Output, of the same shape as x - cache: x """ out = None ########################################################################### # TODO: Implement the ReLU forward pass. # ########################################################################### out = x.copy() out[out &lt;= 0] = 0.0 ########################################################################### # END OF YOUR CODE # ########################################################################### cache = x return out, cachedef relu_backward(dout, cache): """ Computes the backward pass for a layer of rectified linear units (ReLUs). Input: - dout: Upstream derivatives, of any shape - cache: Input x, of same shape as dout Returns: - dx: Gradient with respect to x """ dx, x = None, cache ########################################################################### # TODO: Implement the ReLU backward pass. # ########################################################################### dout[x &lt;= 0] = 0 dx = dout ########################################################################### # END OF YOUR CODE # ########################################################################### return dx sandwich layeråœ¨æ–‡ä»¶cs231n/layer_utils.pyé‡Œé¢ï¼Œæœ‰ä¸€äº›æ¯”è¾ƒå¸¸è§çš„ç»„åˆï¼Œå¯ä»¥é›†æˆæˆæ–°çš„å‡½æ•°ï¼Œè¿™æ ·ç”¨çš„æ—¶å€™å°±å¯ä»¥ç›´æŽ¥è°ƒç”¨ä¸ç”¨è‡ªå·±å†™äº† loss layer -&gt; å’Œassignment1é‡Œé¢å†™çš„å†…å®¹æ˜¯ä¸€æ ·çš„two-layer networkcs231n/classifiers/fc_net.py TwoLayerNet init__ éœ€è¦åˆå§‹åŒ–weightså’Œbiasï¼Œweightsåº”è¯¥æ˜¯0.0ä¸­å¿ƒçš„é«˜æ–¯ï¼ˆ=weight_scaleï¼‰ï¼Œbiasåº”è¯¥æ˜¯0ï¼Œéƒ½å­˜åœ¨self.paraçš„å­—å…¸é‡Œé¢ï¼Œç¬¬å‡ å±‚çš„åå­—å°±å«ç¬¬å‡  input å›¾ç‰‡çš„size hiddençš„ä¸ªæ•° classçš„æ•°é‡ weight scaleï¼Œçœ‹åˆå§‹çš„weightsæ€Žä¹ˆåˆ†å¸ƒ regï¼Œregularizationæ—¶å€™çš„æƒé‡ forward ç”¨å‰é¢å·²ç»å†™å¥½çš„ä¸œè¥¿è®¡ç®—å‰å‘ æœ€åŽå¾—åˆ°scores å†ç”¨scoresè®¡ç®—lossï¼Œæ³¨æ„ è®¡ç®—lossä¹Ÿæ˜¯ä¸€å±‚ è®¡ç®—lossçš„æ—¶å€™æ³¨æ„ä»–è¿™é‡Œlossçš„å‚æ•°æ˜¯scoreså’Œlable backward backçš„æ—¶å€™ä¸è¦å¿˜è®°äº†lossä¹Ÿæ˜¯ä¸€å±‚ï¼Œæ‰€ä»¥è¾“å…¥ç¬¬äºŒä¸ªsandwichçš„æ—¶å€™è¾“å…¥çš„åº”è¯¥æ˜¯dscoresè€Œä¸æ˜¯scoresï¼Ÿï¼ï¼ï¼ï¼ è®¡ç®—gradientï¼Œæ³¨æ„ä»–çš„functioné‡Œé¢å·²ç»é™¤äº†æ€»æ•°ï¼ åˆ«å¿˜äº†åŠ ä¸ŠL2çš„regularization SolveræŠŠä¹‹å‰é‚£äº›è®­ç»ƒå•Šï¼ŒéªŒè¯å•Šï¼Œè®¡ç®—accuracyä¹‹ç±»çš„éƒ¨åˆ†å…¨éƒ½æ‰”åˆ°ä¸€ä¸ªclassé‡Œé¢å«åšsolverï¼Œæ‰“å¼€cs231n/solver.py ä½œç”¨ solveréƒ¨åˆ†åŒ…æ‹¬æ‰€æœ‰è®­ç»ƒåˆ†ç±»æ‰€éœ€è¦çš„é€»è¾‘éƒ¨åˆ†ï¼Œåœ¨optim.pyé‡Œé¢è¿˜ç”¨äº†ä¸åŒçš„updateæ–¹æ³•æ¥å®žçŽ°SGD è¿™ä¸ªclassæŽ¥å—trainingå’Œvalidationçš„æ•°æ®å’Œlabelsï¼Œæ‰€ä»¥å¯ä»¥æ£€æŸ¥åˆ†ç±»çš„å‡†ç¡®çŽ‡ï¼Œæ˜¯å¦overfitting éœ€è¦å…ˆæž„æˆä¸€ä¸ªsolverçš„instanceï¼ŒæŠŠéœ€è¦çš„modelï¼Œdatasetï¼Œå’Œä¸åŒçš„ä¸œè¥¿ï¼ˆlearning rateï¼Œbatchï¼Œetcï¼‰æ”¾è¿›åŽ» å…ˆç”¨train()æ¥è®­ç»ƒï¼Œç„¶åŽmodelçš„paraéƒ½å­˜ç€æ‰€æœ‰è®­ç»ƒå®Œçš„å‚æ•° è®­ç»ƒçš„è¿‡ç¨‹ä¹Ÿä¼šè®°å½•ä¸‹æ¥ï¼ˆaccuracyçš„æ”¹å˜å•¥çš„ï¼‰ æœ€åŽè®­ç»ƒçš„ç»“æžœå¤§çº¦åœ¨50%12345678910111213141516171819model = TwoLayerNet()solver = None############################################################################### TODO: Use a Solver instance to train a TwoLayerNet that achieves at least ## 50% accuracy on the validation set. ###############################################################################solver = Solver(model, data, update_rule = 'sgd', optim_config=&#123;'learning_rate': 1e-3,&#125;, lr_decay=0.95, num_epochs=10, batch_size=100, print_every=100)solver.train()############################################################################### END OF YOUR CODE ######################################################################## å¯è§†åŒ–è¿™ä¸ªæœ€ç»ˆçš„ç»“æžœï¼Œlosséšç€epochçš„å˜åŒ–å’Œtraining accä»¥åŠval accçš„å˜åŒ–12345678910111213141516# Run this cell to visualize training loss and train / val accuracyplt.subplot(2, 1, 1)plt.title('Training loss')plt.plot(solver.loss_history, 'o')plt.xlabel('Iteration')plt.subplot(2, 1, 2)plt.title('Accuracy')plt.plot(solver.train_acc_history, '-o', label='train')plt.plot(solver.val_acc_history, '-o', label='val')plt.plot([0.5] * len(solver.val_acc_history), 'k--')plt.xlabel('Epoch')plt.legend(loc='lower right')plt.gcf().set_size_inches(15, 12)plt.show() è®°ä¸‹æ¥äº†è¿™ä¸ªlosså’Œaccçš„historyï¼Œæ‰€ä»¥å°±å¯ä»¥ç›´æŽ¥ç”¨æ¥å¯è§†åŒ–äº†ï¼ Multilayer networkçŽ°åœ¨å¼€å§‹å®žçŽ°æœ‰å¤šå±‚çš„net éœ€è¦æ³¨æ„çš„é—®é¢˜ä¸»è¦æ˜¯æ•°æ•°æ•°å¯¹äº†ï¼Œæ³¨æ„æ•°å­—å’Œlayerçš„æ•°é‡çš„å…³ç³» ä¸ºäº†ä¿è¯éªŒè¯çš„å‡†ç¡®ï¼Œéœ€è¦æŠŠlossçš„regularizationç®—å¯¹æ‰å¯ä»¥ åå‘å¾€å›žæŽ¨çš„æ—¶å€™ï¼Œå¯ä»¥ç”¨ reversed(range(a))è¿™ä¸ªä¸œè¥¿æ¥è¿›è¡Œ æ€»ä½“æ¥è¯´å’Œä¸¤å±‚çš„å·®ä¸å¤šï¼Œå°±æ˜¯åŠ è¿›æ¥äº†forå¾ªçŽ¯ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202class FullyConnectedNet(object): """ A fully-connected neural network with an arbitrary number of hidden layers, ReLU nonlinearities, and a softmax loss function. This will also implement dropout and batch/layer normalization as options. For a network with L layers, the architecture will be &#123;affine - [batch/layer norm] - relu - [dropout]&#125; x (L - 1) - affine - softmax where batch/layer normalization and dropout are optional, and the &#123;...&#125; block is repeated L - 1 times. Similar to the TwoLayerNet above, learnable parameters are stored in the self.params dictionary and will be learned using the Solver class. """ def __init__(self, hidden_dims, input_dim=3 * 32 * 32, num_classes=10, dropout=1, normalization=None, reg=0.0, weight_scale=1e-2, dtype=np.float32, seed=None): """ Initialize a new FullyConnectedNet. Inputs: - hidden_dims: A list of integers giving the size of each hidden layer. - input_dim: An integer giving the size of the input. - num_classes: An integer giving the number of classes to classify. - dropout: Scalar between 0 and 1 giving dropout strength. If dropout=1 then the network should not use dropout at all. - normalization: What type of normalization the network should use. Valid values are "batchnorm", "layernorm", or None for no normalization (the default). - reg: Scalar giving L2 regularization strength. - weight_scale: Scalar giving the standard deviation for random initialization of the weights. - dtype: A numpy datatype object; all computations will be performed using this datatype. float32 is faster but less accurate, so you should use float64 for numeric gradient checking. - seed: If not None, then pass this random seed to the dropout layers. This will make the dropout layers deteriminstic so we can gradient check the model. """ self.normalization = normalization self.use_dropout = dropout != 1 self.reg = reg self.num_layers = 1 + len(hidden_dims) self.dtype = dtype self.params = &#123;&#125; ############################################################################ # TODO: Initialize the parameters of the network, storing all values in # # the self.params dictionary. Store weights and biases for the first layer # # in W1 and b1; for the second layer use W2 and b2, etc. Weights should be # # initialized from a normal distribution centered at 0 with standard # # deviation equal to weight_scale. Biases should be initialized to zero. # # # # When using batch normalization, store scale and shift parameters for the # # first layer in gamma1 and beta1; for the second layer use gamma2 and # # beta2, etc. Scale parameters should be initialized to ones and shift # # parameters should be initialized to zeros. # ############################################################################ pr_num = input_dim # can't use enumerate beacuse I need the number more than the size of hidden_dims for layer in range(self.num_layers): layer += 1 weights = 'W' + str(layer) bias = 'b' + str(layer) # è¿™æ—¶å€™æ˜¯æœ€åŽä¸€å±‚(the last layer) if layer == self.num_layers: self.params[weights] = np.random.randn( hidden_dims[len(hidden_dims) - 1], num_classes) * weight_scale self.params[bias] = np.zeros(num_classes) # other layers else: hidd_num = hidden_dims[layer - 1] self.params[weights] = np.random.randn( pr_num, hidd_num) * weight_scale self.params[bias] = np.zeros(hidd_num) pr_num = hidd_num if self.normalization in ["batchnorm", "layernorm"]: self.params['gamma' + str(layer)] = np.ones(hidd_num) self.params['bata' + str(layer)] = np.zeros(hidd_num) # print(len(self.params)) # print(self.params) ############################################################################ # END OF YOUR CODE # ############################################################################ # When using dropout we need to pass a dropout_param dictionary to each # dropout layer so that the layer knows the dropout probability and the mode # (train / test). You can pass the same dropout_param to each dropout layer. self.dropout_param = &#123;&#125; if self.use_dropout: self.dropout_param = &#123;'mode': 'train', 'p': dropout&#125; if seed is not None: self.dropout_param['seed'] = seed # With batch normalization we need to keep track of running means and # variances, so we need to pass a special bn_param object to each batch # normalization layer. You should pass self.bn_params[0] to the forward pass # of the first batch normalization layer, self.bn_params[1] to the forward # pass of the second batch normalization layer, etc. self.bn_params = [] if self.normalization == 'batchnorm': self.bn_params = [&#123;'mode': 'train'&#125; for i in range(self.num_layers - 1)] if self.normalization == 'layernorm': self.bn_params = [&#123;&#125; for i in range(self.num_layers - 1)] # Cast all parameters to the correct datatype for k, v in self.params.items(): self.params[k] = v.astype(dtype) def loss(self, X, y=None): """ Compute loss and gradient for the fully-connected net. Input / output: Same as TwoLayerNet above. """ X = X.astype(self.dtype) mode = 'test' if y is None else 'train' # Set train/test mode for batchnorm params and dropout param since they # behave differently during training and testing. if self.use_dropout: self.dropout_param['mode'] = mode if self.normalization == 'batchnorm': for bn_param in self.bn_params: bn_param['mode'] = mode scores = None ############################################################################ # TODO: Implement the forward pass for the fully-connected net, computing # # the class scores for X and storing them in the scores variable. # # # # When using dropout, you'll need to pass self.dropout_param to each # # dropout forward pass. # # # # When using batch normalization, you'll need to pass self.bn_params[0] to # # the forward pass for the first batch normalization layer, pass # # self.bn_params[1] to the forward pass for the second batch normalization # # layer, etc. # ############################################################################ cache = &#123;&#125; temp_out = X for i in range(self.num_layers): w = self.params['W' + str(i + 1)] b = self.params['b' + str(i + 1)] if i == self.num_layers - 1: scores, cache['cache' + str(i + 1)] = affine_relu_forward(temp_out, w, b) else: temp_out, cache['cache' + str(i + 1)] = affine_relu_forward(temp_out, w, b) ############################################################################ # END OF YOUR CODE # ############################################################################ # If test mode return early if mode == 'test': return scores loss, grads = 0.0, &#123;&#125; ############################################################################ # TODO: Implement the backward pass for the fully-connected net. Store the # # loss in the loss variable and gradients in the grads dictionary. Compute # # data loss using softmax, and make sure that grads[k] holds the gradients # # for self.params[k]. Don't forget to add L2 regularization! # # # # When using batch/layer normalization, you don't need to regularize the scale # # and shift parameters. # # # # NOTE: To ensure that your implementation matches ours and you pass the # # automated tests, make sure that your L2 regularization includes a factor # # of 0.5 to simplify the expression for the gradient. # ############################################################################ loss, dscores = softmax_loss(scores, y) reg_loss = 0.0 pre_dx = dscores for i in reversed(range(self.num_layers)): i = i + 1 reg_loss = np.sum(np.square(self.params['W' + str(i)])) loss += reg_loss * 0.5 * self.reg pre_dx, dw, db = affine_relu_backward( pre_dx, cache['cache' + str(i)]) dw += self.reg * self.params['W' + str(i)] db += self.reg * self.params['b' + str(i)] grads['W' + str(i)] = dw grads['b' + str(i)] = db ############################################################################ # END OF YOUR CODE # ############################################################################ return loss, grads æ£€æµ‹ç½‘ç»œæ˜¯å¦overfitting é€‰æ‹©äº†ä¸€ä¸ªä¸‰å±‚çš„ç½‘ç»œï¼Œå°å¹…åº¦æ”¹å˜learning rateå’Œinit scale å°è¯•åŽ»overfittingå‡ºçŽ°äº†ä¸€äº›é—®é¢˜ä¸æ˜¯å¤ªèƒ½overfittingæˆ‘ä¸çŸ¥é“ä¸ºä»€ä¹ˆ update rulesåœ¨å¾—åˆ°äº†backå‡ºæ¥çš„dwä¹‹åŽï¼Œå°±éœ€è¦ç”¨è¿™ä¸ªdwå¯¹wè¿›è¡Œupdateï¼Œè¿™é‡Œæœ‰ä¸€äº›æ¯”è¾ƒå¸¸è§çš„updateæ–¹æ³• æ™®é€šçš„update ä»…ä»…æ²¿ç€gradientæ”¹å˜çš„åæ–¹å‘è¿›è¡Œ(åæ–¹å‘æ˜¯å› ä¸ºè®¡ç®—å‡ºæ¥çš„gradientæ˜¯ä¸Šå‡çš„æ–¹å‘)x += - learning_rate * dx SGD + momentumhttp://cs231n.github.io/neural-networks-3/#sgd æ˜¯å¯¹è¿™ä¸ªupdateä¸€ç‚¹ç‰©ç†ä¸Šæ¯”è¾ƒç›´è§‚çš„ç†è§£ï¼ˆå…¶å®žåå­—å«åšåŠ¨é‡ï¼‰ å¯ä»¥ç†è§£ä¸ºè¿™ä¸ªä¸œè¥¿æ˜¯åœ¨ä¸€ä¸ªå¹³åŽŸä¸Šè·‘çš„ä¸€ä¸ªçƒï¼Œæˆ‘ä»¬éœ€è¦æ±‚çš„wæ˜¯è¿™ä¸ªçƒçš„é€Ÿåº¦ï¼Œå¾—åˆ°çš„dwæ˜¯è¿™ä¸ªçƒçš„åŠ é€Ÿåº¦ï¼Œè€Œè¿™ä¸ªçƒçš„åˆé€Ÿåº¦æ˜¯0 å¯ä»¥ç†è§£ä¸ºè¿™ä¸ªçƒæ‰¾æœ€ä½Žç‚¹çš„æ—¶å€™ï¼Œé™¤äº†æ¯æ­¥æŒ‰dw updateï¼Œè¿˜åœ¨ä¸Šé¢åŠ ä¸Šäº†å‰é¢é€Ÿåº¦çš„å½±å“ï¼Œä¹Ÿå°±æ˜¯åŠ ä¸Šäº†æƒ¯æ€§ï¼123# Momentum updatev = mu * v - learning_rate * dx # integrate velocityx += v # integrate position Nesterov Momentum(NAG) åœ¨åŽŸæ¥çš„åŸºç¡€ä¸Šï¼šçœŸå®žç§»åŠ¨æ–¹å‘ = é€Ÿåº¦çš„å½±å“ï¼ˆmomentumï¼‰+ æ¢¯åº¦çš„å½±å“ ï¼ˆgradientï¼‰ çŽ°åœ¨ï¼šæ—¢ç„¶æˆ‘ä»¬å·²ç»çŸ¥é“äº†è¦å¾€å‰èµ°åˆ°åŠ¨é‡çš„å½±å“çš„ä½ç½®ï¼Œé‚£ä¹ˆæˆ‘æ ¹æ®é‚£ä¸ªä½ç½®çš„æ¢¯åº¦å†è¿›è¡Œupdateï¼Œå²‚ä¸æ˜¯è·‘çš„æ›´å¿«ï¼ æ€»çš„æ¥è¯´å°±æ˜¯è€ƒè™‘åˆ°äº†å‰é¢çš„å¡åº¦ï¼ˆäºŒé˜¶å¯¼æ•°ï¼‰ï¼Œå¦‚æžœå‰é¢çš„å¡åº¦ç¼“çš„è¯æˆ‘å°±å†è·‘å¿«ç‚¹ï¼Œå¦‚æžœé™¡çš„è¯å°±è·‘æ…¢ç‚¹123v_prev = v # back this upv = mu * v - learning_rate * dx # velocity update stays the samex += -mu * v_prev + (1 + mu) * v # position update changes form cs231n/optim.py åŠ å…¥äº†æ–°çš„è®¡ç®—updateçš„æ–¹æ³• å…·ä½“çš„åŽŸç†è¿˜æ²¡æœ‰çœ‹ï¼Œä½†æ˜¯è®¡ç®—å°±æ˜¯è¿™æ ·è®¡ç®—çš„ 12345678910111213141516171819202122232425262728293031def sgd_momentum(w, dw, config=None): """ Performs stochastic gradient descent with momentum. config format: - learning_rate: Scalar learning rate. - momentum: Scalar between 0 and 1 giving the momentum value. Setting momentum = 0 reduces to sgd. - velocity: A numpy array of the same shape as w and dw used to store a moving average of the gradients. """ if config is None: config = &#123;&#125; config.setdefault('learning_rate', 1e-2) config.setdefault('momentum', 0.9) v = config.get('velocity', np.zeros_like(w)) next_w = None ########################################################################### # TODO: Implement the momentum update formula. Store the updated value in # # the next_w variable. You should also use and update the velocity v. # ########################################################################### v = config['momentum'] * v - config['learning_rate'] * dw w += v next_w = w ########################################################################### # END OF YOUR CODE # ########################################################################### config['velocity'] = v return next_w, config å¯ä»¥çœ‹å‡ºæ¥æœ€ç»ˆçš„ç»“æžœä¼šæ¯”æ™®é€šçš„SGDä¸Šå‡çš„æ›´å¿« åˆ†åˆ«åˆå°è¯•äº†RMSProp and Adam]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
        <category>CS231nä½œä¸š</category>
      </categories>
      <tags>
        <tag>Fully Connected Net</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽç©ºé—´æŠ•å½±å¢žå¼ºï¼ˆSARï¼‰çš„è®ºæ–‡]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%85%B3%E4%BA%8E%E7%A9%BA%E9%97%B4%E6%8A%95%E5%BD%B1%E5%A2%9E%E5%BC%BA%E7%9A%84%E8%AE%BA%E6%96%87%2F</url>
    <content type="text"><![CDATA[ç›¸å…³ä»‹ç»é“¾æŽ¥koike lab roomAlive å…³äºŽopencvçš„fisheye calibrationï¼šhttp://ninghang.blogspot.com/2012/08/fish-eye-camera-calibration.html å…³äºŽcalibrationçš„è§†è§’çš„é—®é¢˜ï¼Œmatlabå¯ä»¥æ‰¾åˆ°å…¨éƒ¨è§†è§’ï¼šhttps://www.mathworks.com/help/vision/ug/fisheye-calibration-basics.html DeepCalib: A Deep Learning Approach for Automatic Intrinsic Calibration of Wide Field-of-View Camerasï¼ˆCVMP â€˜18ï¼‰ä½¿ç”¨æ·±åº¦å­¦ä¹ å¯¹fish eyeç›¸æœºçš„è§†é‡Žè¿›è¡Œè¡¥å…¨ã€‚ æ–‡ç« ä¸­å…¬å¼€çš„codeå’Œå…¶ä»–èµ„æ–™ Abstract å¹¿è§’ç›¸æœºçš„calibrationåœ¨å„ç§å„æ ·çš„åœ°æ–¹éƒ½æœ‰åº”ç”¨ 3Dé‡å»º image undistortion AR camera motion estimation çŽ°åœ¨å­˜åœ¨çš„calibrationéƒ½éœ€è¦å¤šå¼ å›¾ç‰‡è¿›è¡Œæ ¡å‡†ï¼ˆchessboardï¼‰ æå‡ºäº†ä¸€ç§å®Œå…¨è‡ªåŠ¨çš„æ ‡å®šæ–¹æ³•ï¼ŒåŸºäºŽCNN åœ¨ç½‘ä¸Šæ‰¾äº†éžå¸¸å¤šçš„omnidirectionalçš„å›¾ç‰‡è¿›è¡Œè®­ç»ƒï¼Œç”Ÿæˆäº†å…·æœ‰100å¤šä¸‡å¼ å›¾ç‰‡çš„dataset Intro å¹¿è§’ç›¸æœºçš„calibrationæœ€é‡è¦çš„æ˜¯æµ‹é‡ intrinsic parameters ä¸¤ä¸ªwide FOVçš„é‡è¦å‚æ•°ï¼šfocal length &amp; distortion parameter çŽ°å­˜çš„calibrationæ–¹æ³•æœ‰å¾ˆå¤šé™åˆ¶ï¼š éœ€è¦ä¸€ä¸ªobjectçš„å¤šä¸ªè§’åº¦çš„è§‚å¯Ÿ éœ€è¦è§‚å¯Ÿä¸€ä¸ªç‰¹å®šçš„structures åœ¨å¤šå¼ å›¾ç‰‡ä¸­è§‚å¯Ÿç›¸æœºçš„ç§»åŠ¨ çŽ°åœ¨æœ€æœ‰åçš„æ–¹æ³•æ˜¯chessboard ä»–ä»¬æå‡ºçš„æ–¹æ³•å¯ä»¥è§£å†³ä¸Šè¿°çš„é—®é¢˜ï¼Œå¹¶ä¸”é’ˆå¯¹ç½‘ä¸Šä¸‹ä¸‹æ¥çš„ç…§ç‰‡ä¹Ÿå¯ä»¥ç”¨ ä¸»è¦æ–¹æ³• ä¸€ä¸ªCNN with Inception-V3 architecture ç›®æ ‡ æ”¶é›†å…·æœ‰ä¸åŒintrinsic parametersçš„å›¾ç‰‡ï¼Œç„¶åŽè‡ªåŠ¨ç”Ÿæˆå…·æœ‰ä¸åŒçš„focal lengthå’Œdistortionçš„å›¾ç‰‡ï¼ˆæ²¡æ‡‚ï¼‰ å¯¹æ¯”ä¸åŒçš„CNNç»“æž„ related work ä»¥å‰å­˜åœ¨çš„calibrationæ–¹æ³•ä¸»è¦å¯ä»¥åˆ†æˆå››ä¸ªä¸åŒçš„éƒ¨åˆ† æœ€å¸¸ä½¿ç”¨çš„å°±æ˜¯æ£‹ç›˜ä¸€ç±»çš„ï¼Œéœ€è¦è§‚å¯Ÿä¸€å¼ å›¾ç‰‡çš„ä¸åŒéƒ¨åˆ†ï¼Œä»Žè€Œå¾—åˆ°ç»“æžœã€‚é—®é¢˜ä¸»è¦æ˜¯å‡ºåœ¨æ¯”ä»·éº»çƒ¦ï¼Œè€Œä¸”æ— æ³•å¯¹é‡Žç”Ÿçš„ç…§ç‰‡è¿›è¡Œcalibration åŸºäºŽå›¾ç‰‡ä¸Šé¢çš„geometric structureï¼Œlineï¼Œæ¶ˆå¤±çš„ç‚¹ç­‰ã€‚ä¸èƒ½å¤„ç†general environments self-calibrationï¼ˆè‡ªèº«è¿˜æœ‰ä¸€äº›å®¹æ˜“æ”¶åˆ°å½±å“çš„é—®é¢˜ï¼‰ éœ€è¦å¤šå¼ å›¾ç‰‡ éœ€è¦camera motion estimation åŸºäºŽDLçš„ï¼Œä½†æ˜¯éƒ½æ˜¯è§£å†³äº†éƒ¨åˆ†é—®é¢˜ æ²¡æœ‰æŠŠå‚æ•°å…¨éƒ½ä¼°è®¡å‡ºæ¥ datasetæ˜¯ä»Žprespectiveçš„å›¾ç‰‡ç”Ÿæˆå›žæ¥çš„ï¼Œä¼šæœ‰ä¸å®Œæ•´çš„éƒ¨åˆ†ï¼ˆä½†æ˜¯ä»–ä»¬çš„å¾ˆå®Œæ•´è€Œä¸”ä¼šæœ‰å¾ˆå¤šåº”ç”¨ï¼‰ Approaché€‰æ‹©model -&gt; è‡ªåŠ¨ç”Ÿæˆlarge-scale dataset -&gt; networkçš„structure Projection &amp; distrotion modelï¼ˆè€ƒè™‘ç”Ÿæˆdatasetçš„æœºå™¨ï¼‰ å¹¿è§’ç›¸æœºéœ€è¦å…·ä½“çš„projection modelæŠŠ3Dçš„ä¸–ç•Œmapåˆ°å›¾ç‰‡é‡Œé¢åŽ» è€ƒè™‘äº†å‡ ä¸ªmodel Brown-Conradyâ€™s model(1971) åœ¨å®žé™…åº”ç”¨é‡Œé¢ä¸é€‚åˆå¹¿è§’ç›¸æœºçš„å¤§çš„distortion hardly reversible division model [Fitzgibbon 2001] åªæ˜¯ä¸ºäº†fisheyeè®¾è®¡çš„ï¼Œå¯¹ç›¸æœºæ²¡æœ‰æ™®é€‚æ€§ impossible to revert è¿™ç¯‡æ–‡ç« é‡Œé¢çš„model unified spherical model [Barreto 2006; Mei and Rives 2007] åŽŸå›  fully reversible å¯ä»¥è§£å†³å¾ˆå¤§çš„distortion projectionå’Œback-projectionéƒ½admit closed-form solution -&gt; è®¡ç®—æ•ˆçŽ‡éžå¸¸é«˜ï¼ˆæ²¡æ€Žä¹ˆçœ‹æ‡‚ï¼‰ generation dataset å› ä¸ºæ ¹æœ¬åšä¸åˆ°å¹¶ä¸”è¿˜æ²¡æœ‰é‚£ä¹ˆå¤§çš„datasetï¼Œæ‰€ä»¥ä»–ä»¬æ‰“ç®—äººå·¥åˆæˆä¸€äº›(synthetically) æ²¡æœ‰é€‰æ‹©ç”¨prspectiveçš„å›¾ç‰‡ç”Ÿæˆ åœ¨æ™®é€šçš„å›¾ç‰‡é‡Œé¢åŠ ä¸Šdistortionä¼šæŠŠå›¾ç‰‡é‡Œåº”è¯¥çœ‹ä¸åˆ°çš„åœ°æ–¹çœ‹åˆ°ï¼ˆè¾¹ç¼˜éƒ½ä¼šå˜æˆé»‘è‰²çš„ï¼‰ -&gt; ç”Ÿæˆçš„å›¾ç‰‡ä¸çœŸå®ž ä½¿ç”¨panoramaså¾—åˆ°å›¾ç‰‡ å› ä¸ºå…¨æ™¯å›¾éƒ½æ˜¯360åº¦çš„ï¼Œé‚£ä¹ˆå¤šå°‘åº¦çš„å¹¿è§’éƒ½èƒ½é©¾é©­ å¯ä»¥å‡è®¾æŠŠç›¸æœºæ”¾åœ¨ä»»ä½•åœ°æ–¹ å¯¹äºŽç»™çš„ä¸€å¼ å…¨æ™¯å›¾ï¼Œå¯ä»¥è‡ªåŠ¨ç”Ÿæˆä¸åŒç„¦è·ï¼Œä¸åŒdistortionçš„å›¾ç‰‡ï¼Œè¿™æ ·å°±å¾—åˆ°äº†å¾ˆå¤§çš„dataset network architecture Inception-V3 structure åŸºäºŽä¸Šé¢çš„ï¼Œå®žè·µäº†ä¸‰ç§ä¸åŒçš„ç½‘ç»œ ä¸€å±‚ç½‘ç»œï¼Œè¾“å‡ºä¸¤ä¸ªä¸åŒçš„ç»“æžœï¼Œä¸€ä¸ªæ˜¯fä¸€ä¸ªæ˜¯distortion DualNetï¼Œç”±ä¸¤ä¸ªç‹¬ç«‹ç½‘ç»œç»„æˆï¼Œä¸€ä¸ªè¾“å‡ºfï¼Œä¸€ä¸ªè¾“å‡ºdistortionï¼Œè¿™ä¸¤ä¸ªå€¼æ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚ SeqNetï¼Œä¸¤ä¸ªè¿žåœ¨ä¸€èµ·çš„ç½‘ç»œï¼Œå…ˆä»ŽAç½‘ç»œé‡Œå¾—åˆ°fï¼Œå†æŠŠå›¾ç‰‡å’Œfæ”¾è¿›Bå¾—åˆ°æœ€ç»ˆçš„distortion è§£å†³é—®é¢˜ï¼š classification regression resultnetçš„å‚æ•° netåœ¨imageNetä¸Šé¢pre-trainäº†ï¼Œç„¶åŽå†è¿›è¡Œäº†è¿›ä¸€æ­¥çš„è®­ç»ƒ evaluationå¯¹æ¯”ä¸Šé¢ä¸åŒä¸‰ä¸ªç½‘ç»œçš„performance user studyä¼°è®¡å‡ºæ¥çš„ç»“æžœå¾ˆéš¾è¯´æ˜Žåˆ°åº•æ˜¯ä¸æ˜¯æˆåŠŸçš„undistortäº†ï¼Œæ‰€ä»¥è®¾è®¡äº†user study Combining Multiple Depth Cameras and Projectors for Interactions On, Above, and Between Surfacesï¼ˆâ€˜2010ï¼‰æ„Ÿè§‰ç®—æ˜¯æ¯”è¾ƒæœ€æ—©çš„SARçš„éƒ¨åˆ†ï¼Œé‡ç‚¹å°±æ˜¯ç”¨å¤šä¸ªè§†è§’çš„depth cameraæ¥æ•æ‰ç”¨æˆ·çš„åŠ¨ä½œï¼Œå®Œæˆç›¸åº”çš„äº¤äº’ï¼Œä¸çŸ¥é“åœ¨æ¡Œå­ä¸Šçš„æŠ•å½±å’Œåœ¨å¢™ä¸Šçš„æŠ•å½±æ˜¯æ€Žä¹ˆå®žçŽ°çš„ abstract å¯ä»¥äº¤äº’çš„displayså’Œsurface å¯ä»¥æŠ•å½±åˆ°éžå¸¸è§„çš„æŠ•å½±è¡¨é¢ä¸Šé¢åŽ» å¯ä»¥æŠŠè¿™äº›ä¸œè¥¿æ‰”æ¥æ‰”åŽ»ï¼Œä¹‹ç±»çš„ Intro the user may touch to manipulate a virtual object projected on an un-instrumented tableï¼ˆè¿™ä¸ªçŽ°åœ¨å·²ç»ä¸æ–°é²œäº†ï¼‰ office size room depth cameraçš„å¦™ç”¨ è¿™ä¸ªç©ºé—´çš„ä»»ä½•åœ°æ–¹éƒ½æ˜¯surfaceï¼Œéƒ½å¯ä»¥æŠ•å½± æ•´ä¸ªç©ºé—´æ˜¯ä¸€ä¸ªå¤§çš„ç”µè„‘ å¯ä»¥æŠ•å½±åˆ°userè‡ªå·±çš„èº«ä¸ŠåŽ»-&gt; å¯ä»¥æŠ•å½±åˆ°ç”¨æˆ·çš„æ‰‹ä¸Š 3D mesh data ç¡¬ä»¶æž„æˆï¼šmultiplyçš„depth camera&amp; projector æ”¯æŒçš„interaction å¯ä»¥äº¤äº’çš„éžæ˜¾ç¤ºå™¨éƒ¨åˆ†ï¼ˆæ¯”å¦‚å¢™å£æˆ–è€…æ¡Œå­ï¼‰ æ‰€æœ‰çš„éƒ¨åˆ†å¯ä»¥è¿žæŽ¥æˆä¸€ä¸ªå¯äº¤äº’çš„éƒ¨åˆ†ï¼Œå¯ä»¥é€šè¿‡è‚¢ä½“æ¥è¿›è¡Œä¸¤ä¸ªå±å¹•ä¹‹é—´çš„äº¤äº’ï¼ˆåŒæ—¶æ‘¸è¿™ä¸¤ä¸ªä¸œè¥¿ä»–å°±ä¼šæ¢ä½ç½®ï¼‰ å¯ä»¥ä»Ždisplayä¸Šé¢pick upå‡ºä¸œè¥¿æ¥ æ£€æµ‹å‡ºç”¨æˆ·çš„åŠ¨ä½œæ¥ï¼Œæ”¯æŒåŠ¨ä½œçš„äº¤äº’ implement åœ¨å¤©èŠ±æ¿ä¸Šè£…äº†ä¸‰ä¸ªdepth cameraå’Œä¸‰ä¸ªprojectorï¼Œå¯ä»¥çœ‹åˆ°äº¤äº’çš„åœ°æ–¹ï¼Œä¸éœ€è¦ç‰¹åˆ«ç²¾å‡†çš„calibration PrimeSense cameraï¼Œæœ‰IRå’ŒRGBcamera depth imageå¯ä»¥ç”¨æ¥åˆ†ç¦»é™æ­¢çš„ç‰©ä½“ calibration both the cameras and the projectors are registered with the real world. camera a fixed grid of retro-reflective dots 3D camera pose estimation de- scribed by Horn[13] interactive space calibrationä¹‹åŽcameraå°±å¯ä»¥æ•æ‰real timeçš„3D mesh model å› ä¸ºcameraå’Œprojectorä¸€èµ·æ ¡å‡†è¿‡äº†ï¼Œæ‰€ä»¥æŠ•å½±å°±å¯ä»¥æ­£ç¡®çš„æŠ•å½±åœ¨ç›¸åº”çš„åœ°æ–¹äº† æ ¹æ®mesh modelå¯ä»¥å¾—åˆ°æ‰‹çš„ä¸‰ç»´å›¾å½¢ï¼Œæ ¹æ®è¿™ä¸ªå›¾å½¢å°±å¯ä»¥çŸ¥é“æ‰‹åœ¨touchå“ªä¸ªåœ°æ–¹äº† åœ¨trackingä¸Šé¢ç”¨äº†æ›´ç®€å•çš„ç®—æ³•ï¼š[28] [29] ç›´æŽ¥å¯¹3Dçš„meshè¿›è¡Œæ“ä½œæ¯”è¾ƒå¤æ‚ï¼Œæ‰€ä»¥å¯¹2Dçš„ç”»é¢è¿›è¡Œäº†æ“ä½œ virtual camera first transforming each point in every depth camera image from local camera to world coordinates, and then to virtual camera coordinates by virtual camera view and projection matrices. zæ–¹å‘çš„åæ ‡ç”±xyå†™å‡ºæ¥ -&gt; æŠŠä¸€å¼ æ·±åº¦å›¾ç‰‡åŽ‹æˆäº†ä¸€ä¸ª2Dçš„å›¾ç‰‡ ç»“åˆå¤šä¸ªè§’åº¦åˆ¤æ–­ç”¨æˆ·çš„æœ€ç»ˆåŠ¨ä½œ ç”¨ä¸Šæ–¹çš„æ‘„åƒæœºçš„å›¾ç‰‡åˆ¤æ–­ç”¨æˆ·æ˜¯ä¸æ˜¯åŒæ—¶æŽ¥è§¦ä¸¤ä¸ªä¸œè¥¿äº† ç©ºé—´é‡Œçš„mene -&gt; åœ¨ç‰¹æ®Šçš„ä¸€ä¸ªåœ°æ–¹æœ‰æŠ•å½± RoomAlive: Magical Experiences Enabled by Scalable, Adaptive Projector-Camera Units(UIST â€˜14)æ„Ÿè§‰æ˜¯ä¸€ä¸ªæ¯”è¾ƒå®Œå…¨çš„å±‹å†…æŠ•å½±çš„ä¾‹å­äº† Abstract å¯ä»¥åŠ¨æ€çš„é€‚åº”ä»»ä½•çš„å±‹å­ touch, shoot, stomp, dodge, steeræŠ•å½±ä¸ŠåŽ»çš„ä¸œè¥¿ï¼Œä»¥åŠå’Œç‰©ç†çš„çŽ¯å¢ƒäº¤äº’ projector-depth camera unit -&gt; æ‰€ä»¥å°±ä¸éœ€è¦ç‰¹åˆ«å¤šçš„calibrationï¼ˆå¯ä»¥é‡ç‚¹çœ‹çœ‹è¿™ä¸ªunitæ˜¯æ€Žä¹ˆåˆ¶ä½œçš„ï¼‰ Intro åšäº†ä¸€ä¸ªæ¸¸æˆç³»ç»Ÿ projectorå’Œdepth cameraä¸€ä½“çš„ä¸œè¥¿ cover the roomâ€™s walls and furniture with input/output pixels trackç”¨æˆ·çš„åŠ¨ä½œï¼Œå¹¶ä¸”æ ¹æ®åŠ¨ä½œåœ¨å±‹å­é‡Œé¢ç”Ÿæˆå¯¹åº”çš„ä¸œè¥¿ capture &amp; analyzeå±‹å­é‡Œçš„ç»“æž„ï¼Œå¾—åˆ°æˆ¿é—´é‡Œé¢çš„å¢™ä»¥åŠåœ°æ¿ä¹‹ç±»çš„ç‰¹å¾ a distributed framework for tracking body movement and touch detection using optical-flow based particle tracking [4,15], and pointing using an infrared gun [19]. -&gt; å…¶å®žè¿˜ä¸æ˜¯æ²¡æœ‰ä¾æ®è§†è§‰æ¥æ•æ‰è¿™ä¸ªä¸œè¥¿ å±…ç„¶è£…äº†6ä¸ªç›¸æœº-æŠ•å½±ä»ªçš„unit ï¼ˆprocamï¼‰ related workSpatial Augmented Reality (SAR) use light to change appearance physical objects illumiroom -&gt; éžå¸¸å–œæ¬¢è¿™ä¸ªidea projection mappingå¾ˆå¤šéƒ½éœ€è¦åœ¨ç‰¹å®šçš„ä¸œè¥¿ä¸Šé¢mapping -&gt; ä½†æ˜¯è¿™ä¸ªå¯ä»¥åœ¨æ•´é—´å±‹å­çš„ä»»æ„éƒ¨åˆ†mapping System unit -&gt; color camera + IR camera emitter + wide FOV projector + computer in a large living room (è¯´æ˜Žè¿™ç§ç ”ç©¶é‡Œé¢å±‹å­çš„å¤§å°ä¹Ÿéžå¸¸çš„é‡è¦) + 6 units plug-in to the Unity3D commercial game engine ï¼ˆæ€ªä¸å¾—èƒ½åšæ¸¸æˆ ç¡¬ä»¶ wide field of view projectors æ¯ä¸ªéƒ¨åˆ†connected toä»–è‡ªå·±ç‰¹å®šçš„ç”µè„‘ æ‰€æœ‰çš„éƒ¨åˆ†éƒ½è£…åœ¨æˆ¿é—´çš„å±‹é¡¶ä¸Š auto calibration å¹¶ä¸éœ€è¦calibrationæ‰€æœ‰çš„ç›¸æœº åœ¨unitsä¹‹é—´æœ‰ä¸€éƒ¨åˆ†çš„overlapï¼Œæ‰€ä»¥ä¸œè¥¿åœ¨æ ¡å‡†çš„æ—¶å€™è§‚å¯ŸåŒä¸€ä¸ªä¸œè¥¿å°±è¡Œäº†ï¼Ÿ ç”¨opencvçš„æ ¡å‡†function chain togetheræ‰€æœ‰çš„éƒ¨åˆ†ç„¶åŽå¾—åˆ°äº†å„ä¸ªç›¸æœºçš„å…³ç³» auto scene analysis æ‰€æœ‰çš„unitå¾—åˆ°çš„æ·±åº¦ä¿¡æ¯ï¼Œç”Ÿæˆä¹‹åŽå¯»æ‰¾è¿žç»­çš„å¹³é¢ï¼ˆå¢™ï¼Œåœ°æ¿ç­‰ç­‰ï¼‰ Hough transformï¼ˆå¹¶ä¸ä¼šè¿™ä¸ªä¸œè¥¿ï¼‰ æ¸¸æˆ unity3Dçš„plug-in æ¸¸æˆè®¾è®¡è€…åªéœ€è¦åœ¨è®¾è®¡ç•Œé¢é‡Œæ·»åŠ ä¸œè¥¿å°±è¡Œäº† mapping äº‹å®žæ¸²æŸ“æ•´ä¸ªä¸œè¥¿çš„ä»»åŠ¡æ²¡æœ‰å®Œå…¨è§£å†³ 4ä¸ªæŠ€æœ¯ content in a uniformly random way å“ˆã€‚ã€‚ã€‚å±…ç„¶æ˜¯éšæœºæŠ•å½±å‡ºæ¥çš„ é’ˆå¯¹ä¸åŒç±»åž‹çš„è¢«æŠ•å½±çš„ä¸œè¥¿ï¼Œä¼šæ ¹æ®ä¸åŒçš„åŽŸç†å‡ºçŽ°åœ¨ä¸åŒçš„åœ°æ–¹ï¼ˆæ¯”å¦‚çŸ³å¤´åªä¼šå‡ºçŽ°åœ¨åœ°é¢ä¸Šï¼‰ æŠ•å½±çš„ä¸œè¥¿é’ˆå¯¹ç”¨æˆ·çŽ°åœ¨çš„ä½ç½®ï¼ŒåªæŠ•åœ¨ç”¨æˆ·è‡ªå·±çœ‹å¾—åˆ°çš„åœ°æ–¹ åœ¨ç§»åŠ¨å±‹å­é‡Œçš„ç‰©ç†ç‰©å“çš„æ—¶å€™ï¼Œæ”¹å˜å±‹å­çš„éƒ¨åˆ† tracking user interface body movement, touching, stomping, pointing/shooting and traditional controller input [4,15]æ•æ‰äº†depth map -&gt; â€˜proxy particlesâ€™,å°±æ˜¯åŠ¨ä½œæ¸¸æˆé‡Œé¢çš„ä½“æ„Ÿæ•æ‰çš„ç®—æ³• -&gt; tracked by using a depth-aware optical flow algorithm gunçš„inputé€‰æ‹©äº†çº¢å¤–æžª ä¹Ÿæ”¯æŒå¯»å¸¸çš„æ¸¸æˆæ‰‹æŸ„ rendering RoomAlive tracks the playerâ€™s head position and renders all virtual content with a two-pass view dependent rendering è¿™éƒ¨åˆ†ä¸»è¦è®²æ¸¸æˆæ€Žä¹ˆè®¾è®¡çš„limitation calibration errorsï¼è¿™æ ·åœ¨äº¤å çš„åœ°æ–¹ä¼šå‡ºçŽ°é‡å½± system latency å»¶è¿ŸQAQ åœ¨overlapçš„sensorsä¸Šé¢è§£å†³tracking issues Peripheral Expansion of Depth Information via Layout Estimation with Fisheye Camera( â€˜16)ä»ŽRGBDé±¼çœ¼ç›¸æœºæå–æ·±åº¦ä¿¡æ¯ï¼ˆä½†æ˜¯è¿™ä¸ªç”¨äº†å¤šä¸ªç›¸æœºçš„systemï¼‰ abstract ä¸€ä¸ªæ™®é€šçš„RGBç›¸æœºå’Œä¸€ä¸ªfish eyeï¼ŒæŠŠè§†è§’æ‰©å±•åˆ°äº†180Â° developed a new method to generate scaled layout hypotheses from relevant corners, combining the extraction of lines in the fisheye image and the depth information overcome severe occlusions. intro ä¸»è¦å°±æ˜¯æŠŠçŽ°æœ‰çš„RGB fisheye cameraå’ŒDepth cameraç»“åˆèµ·æ¥ï¼Œå¾—åˆ°é±¼çœ¼çš„æ·±åº¦ä¿¡æ¯ Pedestrian Detection in Fish-eye Images using Deep Learning: Combine Faster R-CNN with an effective Cutting Method(SPML â€˜18)ç”¨é±¼çœ¼ç›¸æœºå’ŒRCNNæ¥æ£€æµ‹è¡Œäººï¼ˆæ„Ÿè§‰è¿™ä¸ªæ£€æµ‹çš„ç›®æ ‡æ¯”è¾ƒå°ï¼‰ -&gt; æ€Žä¹ˆæ„Ÿè§‰æŒºæ°´çš„ abstract é±¼çœ¼ç›¸æœºçš„è¾¹ç¼˜æ‰­æ›²é—®é¢˜ -&gt; rotary cutting to solve the problem æŠŠç›¸æœºåˆ†æˆäº†è¾¹ç¼˜éƒ¨åˆ†å’Œä¸­é—´éƒ¨åˆ† Method è£å‰ªå›¾ç‰‡ ç»•ç€é±¼çœ¼ç›¸æœºçš„ä¸­å¿ƒæ—‹è½¬ï¼Œ30åº¦ï¼Œ12æ¬¡ æ¯æ¬¡æ—‹è½¬å®Œæˆªå–ä¸‰ç»„å›¾ç‰‡ï¼Œåˆ†åˆ«æ˜¯é è¾¹ç¼˜çš„å’Œé ä¸­å¿ƒçš„ -&gt; æ›´å¥½æ£€æµ‹äººç¾¤ï¼ˆåž‚ç›´çš„ï¼‰ ä½¿ç”¨è¿™äº›è£å‰ªçš„å›¾ç‰‡training]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>projection mapping</tag>
        <tag>space augumented</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019 1Q ARç¬”è®°]]></title>
    <url>%2F2019%2F04%2F09%2F2019Q1AR%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[æ•´ä½“æ­¥éª¤ æ£€æµ‹marker ä¸ºä»–è®¡ç®—è®¡ç®—6DOF pose render 3D å›¾ç‰‡ æŠŠå›¾ç‰‡å’Œmarkerç»„åˆåœ¨ä¸€èµ· slideså­¦ä¹ opengl(å­¦ä¹ è€å¸ˆçš„cppä»£ç é£Žæ ¼) Ex1:æ£€æµ‹markerçš„å››ä¸ªåŸºç¡€ç‚¹æ‰“å¼€ç›¸æœº æ³¨æ„åˆå§‹åŒ– videocapture åº”è¯¥æ˜¯åœ¨whileçš„å¾ªçŽ¯ä¹‹å‰çš„ thresholding å‡½æ•° cv::threshold(â€¦) src dst thresçš„å€¼ï¼Œä¹Ÿå°±æ˜¯é˜ˆå€¼çš„è¾¹ç•Œå€¼ double maxvalï¼Œåœ¨æœ€åŽä¸€ä¸ªå‚æ•°æ˜¯binaryçš„æ—¶å€™ï¼Œç¡®å®šbinaryçš„æœ€å¤§å€¼ typeï¼ŒäºŒå€¼å›¾ï¼ŒåäºŒå€¼å›¾ï¼Œä¿ç•™åŽŸè‰²ç­‰ä¹±ä¸ƒå…«ç³Ÿçš„ æ³¨æ„binaryä¹‹å‰è¦å…ˆ cvtcoloråˆ°ç°åº¦å›¾ï¼ï¼ï¼ cv::adaptiveThreshold &lt;- è¯•è¯•è¿™ä¸ªå‡½æ•°çš„ä½œç”¨ï¼Œä¸ç”¨è‡ªå·±è®¾ç½®thresholdäº† å¹¶ä¸æƒ³setè¿™äº›hypers manully é™¤äº†å¯»å¸¸éœ€è¦è®¾ç½®çš„ä¸œè¥¿ä¹‹å¤–ï¼Œè¿˜éœ€è¦ adaptiveMethod block sizeï¼ˆéœ€è¦è¢«ç”¨æ¥è®¡ç®—thresholdçš„valueï¼‰ Cï¼šéœ€è¦è¢«ä»Žæ•´ä½“ä¸­å‡åŽ»çš„ä¸€ä¸ªconstant æœ‰äº›å˜é‡çš„åœ°æ–¹ç”¨åˆ°äº†const &lt;- æ„Ÿè§‰åº”è¯¥å­¦å­¦è€å¸ˆçš„ç¼–ç¨‹é£Žæ ¼detect connected componentscv::findContours å‡½æ•° å›¾ç‰‡ contours vector&lt;std::vector&lt;cv::Point&gt; &gt; hierarchy vector&lt;cv::Vec4i&gt;ï¼Œcontourçš„æ‹“æ‰‘å­¦ä¿¡æ¯ mode ï¼ˆæ³¨æ„åœ¨è¿™é‡Œé€‰æ‹©è¦å¤–è½®å»“è¿˜æ˜¯å†…å¤–éƒ½è¦ï¼‰ methodï¼šä¼°è®¡contourçš„æ–¹æ³• offsetï¼ˆå½“ä»ŽROIæå–è½®å»“ç„¶åŽåœ¨æ•´å¼ å›¾ç‰‡é‡Œé¢åˆ†æžçš„æƒ…å†µï¼‰ åŽ»é™¤è¿‡å°çš„contour12345678910vector&lt;vector&lt;Point&gt;&gt; :: iterator itc = contours.begin(); while(itc != contours.end())&#123; if(itc -&gt; size() &lt; 60)&#123; itc = contours.erase(itc); &#125; else&#123; itc++; &#125; &#125; è€å¸ˆçš„ä»£ç é‡Œé¢æ˜¯å…ˆè¿›è¡Œäº†ä¼°è®¡ï¼Œè®¡ç®—äº†boundçš„é¢ç§¯ï¼Œç„¶åŽæ ¹æ® é¢ç§¯å¤§å°ï¼Œå æ•´å¼ å›¾ç‰‡çš„ç™¾åˆ†æ¯” å‡ ä¸ªè§’ cv::isContourConvex ï¼šæ£€æŸ¥è¿™ä¸ªmarkerçš„å‡¸æ€§ï¼Œæ¯•ç«Ÿå½¢çŠ¶ä¸èƒ½æ˜¯å‡¹çš„ï¼Œç›´æŽ¥è¾“å…¥è¿™ä¸ªå¤šè¾¹å½¢çš„arrayï¼Œè¾“å‡ºçš„å°±æ˜¯bool ä¼°è®¡contourçš„å¤šè¾¹å½¢ approxPolyDP è¢«ä¼°è®¡çš„contour ä¼°è®¡å‡ºæ¥çš„çš„å¤šè¾¹å½¢ ä¼°è®¡çš„å‚æ•°ï¼Œå½±å“ä¼°è®¡çš„ç²¾åº¦ -&gt; const auto epsilon = 0.05 * cv::arcLength(contour, true); è®¡ç®—ä¸€ä¸ªcurveçš„é•¿åº¦ closedï¼Œä¼°è®¡å‡ºæ¥çš„å¤šè¾¹å½¢æ˜¯ä¸æ˜¯å°é—­çš„ ç”»å‡ºæ¥åªæœ‰å››ä¸ªè§’çš„å¤šè¾¹å½¢ drawContours() å›¾ç‰‡ éœ€è¦ç”»çš„è½®å»“s ï¼ˆæ³¨æ„è¿™æ˜¯è¿™å¼ å›¾ç‰‡é‡Œé¢çš„æ‰€æœ‰è½®å»“ï¼‰ éœ€è¦ç”»çš„index thickness çº¿çš„ çº¿å¾—ç§ç±» Optional information about hierarchy. maxLevel Maximal level for drawn contours. If it is 0, only the specified contour is drawn. If it is 1, the function draws the contour(s) and all the nested contours. If it is 2, the function draws the contours, all the nested contours, all the nested-to-nested contours, and so on. This parameter is only taken into account when there is hierarchy available. offsetï¼šå¯é€‰ è€å¸ˆç”¨çš„æ–¹æ³•æ˜¯è®¡ç®—äº†å„ä¸ªç‚¹å’Œè®¡ç®—äº†å„ä¸ªè¾¹ï¼Œæ‰€ä»¥å¯ä»¥ç”»å‡ºæ¥è¾¹ä¸Šè¿˜æœ‰å¥½å¤šç‚¹çš„ç»“æžœ ä¸€ç§ç¥žå¥‡çš„å®šä¹‰é¢œè‰²çš„æ–¹å¼ï¼Œç›´æŽ¥éšæœºå‡ºæ¥ const cv::Scalar kEdgeColor(rand() &amp; 255, rand() &amp; 255, rand() &amp; 255); -&gt; è¿™æ ·çš„è¯å‡ºæ¥çš„æ¯ä¸€å¸§çš„æ¡†çš„é¢œè‰²éƒ½ä¼šæ”¹å˜![] ç”¨cv::polylinesæ¥ç”»å‡ºæ¥polysçš„curveï¼Œå¹¶ä¸”è¦ç”»closedçš„ ç”»å‡ºæ¥å›¾ç‰‡çš„delimiters(ä¸ºä¸‹ä¸€æ­¥åšå‡†å¤‡) ç›®çš„ï¼šä»Žä¸€ä¸ªcorneråˆ°å¦ä¸€ä¸ªcornerçš„æ–¹å‘vector æ­¥éª¤ é¦–å…ˆåœ¨cornerä¸Šé¢ç”¨circleç”»å‡ºæ¥ æ£€æŸ¥æ¯ä¸ªedge æ¯ä¸ªedgeä¸Šæœ‰6ä¸ªç‚¹ï¼Œç„¶åŽè®¡ç®—ä¸¤ä¸ªcornerä¹‹é—´çš„dxå’Œdyçš„æ–¹å‘ï¼Œé™¤ä»¥éƒ¨åˆ†çš„æ•°é‡ï¼ˆ7ï¼‰å°±æ˜¯æ¯ä¸ªå°å—çš„æ–¹å‘ï¼Œç„¶åŽæŠŠè¿™ä¸ªå°å—é‡å¤6æ¬¡12const double dx = (double)(contour_approx[(i+1)%kNumOfCorners].x-contour_approx[i].x)/(double)(kNumOfEdgePoints+1);const double dy = (double)(contour_approx[(i+1)%kNumOfCorners].y-contour_approx[i].y)/(double)(kNumOfEdgePoints+1); ç¬¬ä¸€éƒ¨åˆ†ç»“æŸåŽçš„å®Œæ•´ä»£ç 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#include "ARdetection.hpp"ARDetection::ARDetection(void)&#123; &#125;Mat ARDetection:: SearchMarkers(Mat frame)&#123; Mat img_gray; Mat dst; // thresholdä¹‹å‰è¦å…ˆæ”¹æˆç°åº¦å›¾ cvtColor(frame, img_gray, CV_BGR2GRAY); adaptiveThreshold(img_gray, dst, 255, ADAPTIVE_THRESH_MEAN_C, THRESH_BINARY, 33, 5);// threshold(img_gray, dst, 104, 255, THRESH_BINARY); imshow("lalala", dst); waitKey(1); // æ¯ä¸ªç‚¹ï¼Œä¸€åœˆç‚¹äº‹æ˜¯ä¸€ä¸ªcontourï¼Œä¸€å †kcontours vector&lt;vector&lt;Point&gt;&gt; contours; vector&lt;Vec4i&gt; hierarchy; findContours(dst, contours, hierarchy, RETR_LIST , CHAIN_APPROX_NONE); // æ£€æµ‹å›¾ç‰‡è¿‡å°éƒ¨åˆ†// vector&lt;vector&lt;Point&gt;&gt; :: iterator itc = contours.begin();//// while(itc != contours.end())&#123;// if(itc -&gt; size() &lt; 60)&#123;// itc = contours.erase(itc);// &#125;// else&#123;// itc++;// &#125;// &#125; vector&lt;vector&lt;Point&gt;&gt; polys(contours.size()); for(int i=0; i &lt; contours.size(); i++ )&#123; // æ ¹æ®æ¯ä¸ªè½®å»“è°ƒèŠ‚è¿™ä¸ªå‚æ•°çš„å¤§å° const auto epsilon = 0.05*cv::arcLength(contours[i], true); approxPolyDP(contours[i], polys[i], epsilon, true); // if(polys[i].size() == 4)&#123;//// ç”¨è¿™ä¸ªå‡½æ•°ç”»ä¸å‡ºæ¥æ–œçš„ä¸œè¥¿//// rectangle(frame, polys[i][0],polys[i][2], Scalar(0,255,0));// drawContours(frame, polys, i, Scalar(255,0,0), 5, 8, vector&lt;Vec4i&gt;(), 0, Point());// &#125; Rect rect = boundingRect(polys[i]); const int marker_size = rect.area(); const int ImageSize = img_gray.cols * img_gray.rows; const int marker_size_min = int(ImageSize * 0.02); const int marker_size_max = int(ImageSize * 0.95); const int marker_corners_num = 4; const bool is_vaild = (marker_size &gt; marker_size_min) &amp;&amp; (marker_size &lt; marker_size_max) &amp;&amp; (polys[i].size() == marker_corners_num) &amp;&amp; isContourConvex(polys[i]); if (is_vaild == false) continue; // è¿™æ ·ç”»å‡ºæ¥çš„æ˜¯éšæœºçš„é¢œè‰²çš„ const Scalar EdgeColor(rand() &amp; 255, rand() &amp; 255, rand() &amp; 255); polylines(frame, polys[i], true, EdgeColor,5); // ä¸‹é¢éœ€è¦æŠŠæ¯ä¸ªè¾¹åˆ†æˆ6ä¸ªéƒ¨åˆ† for(int j = 0; j &lt; marker_corners_num; ++j)&#123; const int edge_point_num = 6; const int circle_size = 5; circle(frame, polys[i][j], circle_size, Scalar(0,255,0),FILLED); const double dx = (double)(polys[i][(j+1)%marker_corners_num].x - polys[i][j].x)/(double)(edge_point_num + 1); const double dy = (double)(polys[i][(j+1)%marker_corners_num].y - polys[i][j].y)/(double)(edge_point_num + 1); for(int k = 0; k&lt; edge_point_num; ++k)&#123; const double edge_point_x = (double)(polys[i][j].x) + (double)(k+1)*dx; const double edge_point_y = (double)(polys[i][j].y) + (double)(k+1)*dy; Point edge_point((int)edge_point_x,(int)edge_point_y); circle(frame, edge_point, circle_size, Scalar(0,0,255),-1); &#125; &#125; &#125; return frame;&#125; ç¬¬ä¸€éƒ¨åˆ†è¿è¡Œä¹‹åŽçš„ç»“æžœ Ex2. find marker precisely çŽ°åœ¨æœ‰cornerï¼Œcornerä¹‹é—´çš„lineï¼Œè¿™ä¸ªlineè¿˜è¢«åˆ†æˆ6ä¸ªéƒ¨åˆ†ï¼ˆ~å› ä¸ºå¤§å°æ˜¯6x6ï¼Ÿçš„= ä¸¤ä¸ªè¾¹ + ä¸­é—´å››ä¸ªæ ¼ï¼Ÿï¼Ÿ~ï¼‰ å…‰æ£€æµ‹è¾¹ç¼˜æ˜¯ä¸å¤Ÿçš„ï¼Œæƒ³çŸ¥é“è¿™ä¸ªè¾¹ç¼˜å®žé™…æ˜¯ä»€ä¹ˆæ ·å­çš„ çŽ°åœ¨åªçŸ¥é“è™šçº¿çš„éƒ¨åˆ†æ˜¯ä»€ä¹ˆæ ·å­çš„ å¹¶ä¸”çŽ°åœ¨å·²ç»æŠŠæ¯ä¸ªè¾¹éƒ½åˆ†éƒ¨åˆ†äº† -&gt; ç”»å‡ºæ¥åž‚ç›´çš„åˆ†å—çš„çº¿ï¼Œæ‰¾åˆ°è¿™ä¸ªçº¿å’Œé¢œè‰²çªå˜çš„äº¤ç‚¹ï¼Œé‡æ–°ç”»å‡ºæ¥æ–°çš„çº¿ï¼ˆå®žçº¿ï¼‰ å¸Œæœ›æ‰¾åˆ°é¢œè‰²çªå˜çš„åœ°æ–¹ ä½†æ˜¯å®žé™…ä¸Šçš„é¢œè‰²ä¸æ˜¯çªå˜çš„ï¼Œæ˜¯ç™½ -&gt; ç° -&gt; é»‘ æ“ä½œæ­¥éª¤ é¢„å‡†å¤‡ åœ¨æ¯ä¸ªsideæ‰¾å…­ä¸ªç‚¹ åœ¨è¾¹ä¸Šæå–ä¸‰ä¸ªåƒç´ å®½åº¦çš„stride cv::GetQuadrangleSubPix() -&gt; ä¸ä¼šç”¨ï¼ ä»Žè¾“å…¥çš„arrayå¾—åˆ°å››è¾¹å½¢ srcè¾“å…¥å›¾åƒ dstæå–å‡ºæ¥çš„å››è¾¹å½¢ å˜æ¢çš„çŸ©é˜µ Sober operator å›¾åƒå¤„ç†é‡Œé¢çš„å¸¸ç”¨ç®—å­ -&gt; ä¸»è¦ç”¨äºŽè¾¹ç¼˜æ£€æµ‹ï¼Œç”¨æ¥è¿ç®—ä¸Žç°åº¦çš„ç›¸ä¼¼å€¼ åŒ…å«ä¸¤ç»„3x3çš„çŸ©é˜µï¼Œä¸­é—´çš„3x1çš„0ï¼Œåˆ†åˆ«ä¸ºæ¨ªå‘å’Œçºµå‘ï¼Œå¦å¤–ä¸¤é¢å¯¹ç§° ç„¶åŽä¸Žå›¾ç‰‡åšå·ç§¯ï¼Œåˆ†åˆ«è®¡ç®—xæ–¹å‘å’Œyæ–¹å‘çš„ç°åº¦å€¼ ç„¶åŽæŠŠGxå’ŒGyæ±‚å¹³æ–¹å’Œçš„æ ¹ï¼Œæœ€åŽå¾—å‡ºæ¥è¿™ä¸ªåƒç´ ç‚¹çš„ç°åº¦å€¼ï¼ˆæˆ–è€…æœ‰çš„æ—¶å€™ä¹Ÿå¯ä»¥ç”¨ç»å¯¹å€¼æ¥è®¡ç®—ï¼Œè¿™æ ·è®¡ç®—çš„æ¶ˆè€—å°ä¸€ç‚¹ï¼‰ æ­¥éª¤ åœ¨æ¯ä¸ªstripeé‡Œæ‰¾åˆ°æœ€é«˜çš„change å¯¹è¿™ä¸ªchangeå’Œå¥¹å‘¨å›´çš„ç‚¹ï¼ˆåœ¨åŽŸæ¥çš„æ›²çº¿ä¸Šï¼‰ï¼Œæ‰¾åˆ°ä¸€ä¸ªæ–°çš„äºŒæ¬¡æ›²çº¿ æ‰¾åˆ°è¿™ä¸ªæ›²çº¿çš„é¡¶ç‚¹ï¼ˆä¸€é˜¶å¯¼æ•°ï¼‰ å¦‚ä½•å¾—åˆ°å›¾ç‰‡çš„subpixel colorä¸æ˜¯åŽŸæ¥çš„æ–¹æ–¹æ­£æ­£çš„ï¼Œè€Œæ˜¯æ²¿ç€é‚£ä¸ªç›´çº¿æ–¹å‘çš„æ–°çš„æ–¹æ–¹æ­£æ­£ å°±æ˜¯å–å„ä¸ªé¢œè‰²åœ¨é¢ç§¯ä¸Šçš„å¹³å‡ï¼Œ è€å¸ˆçš„ä»£ç  sublixSampleSafe -&gt; è¿™ä¸ªå‡½æ•°è¾“å…¥æµ‹è¯•çš„å›¾ç‰‡ï¼ˆgrayå’Œå·²ç»å¾—åˆ°çš„subpixç‚¹ æŠŠè¿™ä¸ªç‚¹æ±‚floorï¼Œintï¼Œå¾—åˆ°åŸºå‡†ç‚¹ï¼Œç„¶åŽæ£€æŸ¥æ˜¯ä¸æ˜¯åœ¨å›¾ç‰‡é‡Œé¢ï¼ˆä¸æ˜¯çš„è¯è¿”å›žgrayï¼Œ127ï¼‰ å¦‚æžœåœ¨å›¾ç‰‡é‡Œé¢çš„è¯è®¡ç®—å‡ºæ¥å®žé™…çš„åæ ‡ ç¡®å®šmarkerçš„id corner detection exact sides æ‰¾åˆ°æ²¿ç€åˆšæ‰è®¡ç®—å‡ºæ¥6ä¸ªç‚¹çš„ä¸€æ¡çº¿fitLine precise corner ä»Žå„ä¸ªè¾¹çš„äº¤ç‚¹è®¡ç®—ç²¾ç¡®çš„cornerï¼ˆå› ä¸ºå„ä¸ªè¾¹å·²ç»å¾ˆç²¾ç¡®äº†ï¼‰ Marker Rectification åˆ›å»ºä¸€ä¸ª6x6 pixçš„IDå›¾ç‰‡ (-0.5,-0.5) to (5.5,5.5) ä»ŽåŽŸå›¾ç‰‡çš„perspective warpåˆ°Id image cv::getPerspectiveTransform or cv::warpPerspective éœ€è¦æ‰¾åˆ°çš„æ˜¯linear transformation]]></content>
      <categories>
        <category>AR</category>
        <category>ä¸Šè¯¾ç¬”è®°</category>
      </categories>
      <tags>
        <tag>AR</tag>
        <tag>OpenCV</tag>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Notes for papers about smart kitchen]]></title>
    <url>%2F2019%2F04%2F08%2Fkitchen%2F</url>
    <content type="text"><![CDATA[Choptop: An Interactive Chopping Board2018 abstract ä¸€ä¸ªå¯äº¤äº’çš„æ¡ˆæ¿ å¯ä»¥ç»™ç”¨æˆ·èœè°±çš„æŒ‡å¯¼ï¼Œæ‰¿é‡ï¼Œè®¡æ—¶ ç”¨æˆ·å¯ä»¥é€šè¿‡æŒ‰æ¡ˆæ¿æ¥è¿›è¡Œå¯¹ç”»é¢çš„æ“ä½œ ä¸Šé¢å°±æ˜¯é•¿æˆä¸Šå›¾çš„æ ·å­ï¼Œæ¡ˆæ¿åº•ä¸‹å……æ»¡äº†å„ç§ä¼ æ„Ÿå™¨ã€‚ Intro é’ˆå¯¹å­¦ç”Ÿä¸ä¼šè‡ªå·±åšé¥­ï¼Œä¸åƒæ–°é²œçš„é¥­çš„é—®é¢˜ï¼Œç¼ºæ—¶é—´ -&gt; ä¸€æ­¥ä¸€æ­¥çš„æŠŠæ€Žä¹ˆåšé¥­å†™å‡ºæ¥äº†ï¼ŒåŒ…æ‹¬å›¾ç‰‡åŠ¨ç”»ç­‰ä¸œè¥¿ built-in timerç”¨æ¥æ¯ä¸€æ­¥è®¡æ—¶ ä½¿ç”¨mobile deviceæ¥æé«˜èœå•çš„äº¤äº’æ€§ è€ƒè™‘åˆ°æ‰‹çš„è„ç­‰é—®é¢˜ï¼Œæ‰€ä»¥ä¸æ˜¯æŒ‰å±å¹•è€Œæ˜¯æŒ‰æ¡ˆæ¿ï¼ˆè¿™é‡Œè€ƒè™‘èƒ½ä¸èƒ½åƒpac pacä¸€æ ·ï¼Œç”¨æ‰‹åŠ¿æ“ä½œï¼‰ load sensorsï¼Œå¯ä»¥è§£å†³ç§°é‡çš„é—®é¢˜ æ€è·¯ ä¸»è¦ç›®çš„æ˜¯ä¸€ç§æ–°çš„å­¦ä¹ åšé¥­çš„æ–¹æ³• ï¼ˆä½œä¸ºåšé¥­æœ‰å¤©èµ‹çš„äººï¼Œæˆ‘è®¤ä¸ºè¿™æ ·æ²¡æœ‰çµé­‚ï¼ï¼‰ related work smart kitchen Research has aimed to improve the cook- ing process, promote healthier eating and make it simpler to procure ingredientsï¼Œå¤§å®¶éƒ½ä»Žä¸åŒçš„è§’åº¦å®žçŽ°æ™ºèƒ½åŽ¨æˆ¿ ä»–è¿™ä¸ªè®ºæ–‡çš„ä¸œè¥¿æˆæœ¬ä¸æ˜¯ç‰¹åˆ«é«˜ä¹Ÿä¸æ˜¯ç‰¹åˆ«å¤§ï¼ˆæ˜¯åœ¨å˜²è®½æˆ‘å—ï¼‰ load sensing ä¹‹å‰å·²ç»ç”¨äº†å¾ˆå¤šforceçš„ä¼ æ„Ÿå™¨ ä¹‹å‰ä¹Ÿæœ‰ç”¨è¿‡å¸¦é‡é‡ä¼ æ„Ÿå™¨çš„æ¡ˆæ¿ï¼Œä»¥åŠå¸¦æ‰­çŸ©ä¼ æ„Ÿå™¨çš„åˆ€[9] ä»–ä»¬è®¤ä¸ºcameraæ²¡æœ‰ä»€ä¹ˆç”¨ï¼Œå¹¶ä¸”æŠŠæ‰€æœ‰çš„ç¡¬ä»¶éƒ½è—èµ·æ¥äº† è£…è¿™ä¸ªsenserçš„æ–¹æ³•å‚è€ƒäº†[12] Designç¡¬ä»¶ æ•´ä¸ªç¡¬ä»¶æ˜¯self-containedçš„ å±å¹•æ˜¯å•ç‰‡æœºæŽ§åˆ¶çš„ åŠ›é‡ä¼ æ„Ÿç³»ç”¨ æ£€æµ‹æŒ‰åŽ‹ç”¨çš„æ˜¯edge detection -&gt; é˜²æ­¢æ£€æµ‹åˆ°å…¶ä»–ä¸œè¥¿ï¼ˆåŽŸç†ä¸æ˜¯å¤ªæ‡‚ï¼‰ UI The interface updates based on the information delivered from the recognition engine æˆåŠŸä¹‹åŽè¿˜ä¼šæœ‰å£°éŸ³ æŒ‰æ¡ˆæ¿çš„ä¸åŒéƒ¨åˆ†å°±å¯ä»¥å¾€ä¸åŒçš„æ–¹å‘ç§»åŠ¨ user study æ‰¾äº†åä¸‰ä¸ªäººï¼Œå‡†å¤‡ä¸€é“æ²™æ‹‰ [3]é‡Œé¢æ‰¾åˆ°äº†ä¸€ä¸ªè°ƒæŸ¥é—®å·System Usability Scale future SVMè®­ç»ƒäº†74%çš„æµ‹è¯•çŽ‡ï¼ˆå¥½ä½Žï¼‰ï¼Œæé«˜æ­£ç¡®çŽ‡ æé«˜è‡ªåŠ¨ç¿»é¡µï¼ˆï¼Ÿ ç”¨ç”¨æˆ·çš„æ‰‹æœºæ¥è¾¾åˆ°å±å¹•çš„ä½œç”¨ è¿›ä¸€æ­¥åˆ†user study CookTab: Smart cutting board for creating recipe with real-time feedback2012 abstract è€ƒè™‘åˆ°å¾ˆå¤šåŽ¨å¸ˆåšé¥­éšå¿ƒæ‰€æ¬²ï¼Œè€Œä¸”ä¸ä¼šè®°å½•ä¸‹æ¥ç²¾å‡†çš„ç”¨é‡ ä¸€ä¸ªå¯ä»¥è®°å½•ä¸‹æ¥ç”¨é‡çš„æ¡ˆæ¿ intro ä¸“é—¨é’ˆå¯¹åˆ‡èœéƒ¨åˆ†çš„è®°å½•çš„è½¯ä»¶ è®°å½•ç”¨çš„ææ–™çš„åå­—ï¼Œèœé‡ï¼Œè§†é¢‘å’Œè°ƒå‘³æ–¹æ³•ï¼Œç„¶åŽä¼šæœ‰real-timeçš„feedback related work [3]å¯ä»¥è®°å½•è§†é¢‘ï¼Œå£°éŸ³ï¼Œç”¨çš„cameraå’Œmic åŠ é‡é‡æ„Ÿåº”çš„ï¼Œ [2]å››ä¸ªæ‰¿é‡çš„æ¨¡å—ï¼ŒåŠ é€Ÿåº¦ä¼ å®‰çª ä½†æ˜¯ä»–ä»¬çš„ç³»ç»Ÿä¼šæœ‰real-timeçš„feedback ä¸å¥½æ„æ€å¥½åƒå°±æ˜¯åœ¨padä¸Šåˆ‡èœ Enabling Nutrition-Aware Cooking in a Smart KitchenCHI 2007ï¼ˆå¤§æ¦‚åªèƒ½çœ‹ä¸ªæ¦‚å¿µäº†ï¼‰ abstract ç›®æ ‡ï¼šhealth cookingï¼ˆæ˜¯ä¸æ˜¯å¤§å®¶çš„ç›®æ ‡éƒ½æ˜¯é‚£ä¹ˆä¼Ÿå¤§ï¼‰ sensorsï¼Œdetect cooking activities, and digtail feedback intro ä¸»è¦ç›®æ ‡å°±æ˜¯å¦‚æžœäººåŠ ä¸œè¥¿å‡çš„è¿‡é‡äº†æˆ–è€…æ€Žä¹ˆç€ï¼Œå°±ä¼šæé†’ Smart Kitchens for People with Cognitive Impairments: A Qualitative Study of Design RequirementsCHI-2018]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>Smart Kitchen</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽmacæ¶ˆåŽ»åˆ†åŒº]]></title>
    <url>%2F2019%2F04%2F08%2F%E5%85%B3%E4%BA%8Emac%E6%B6%88%E5%8E%BB%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[æœ€è¿‘åˆšæŽ¥æ‰‹äº†åˆ«äººçš„mbpï¼Œä»–å› ä¸ºè£…åŒç³»ç»Ÿåˆ†åŒºä¹‹åŽï¼Œwindowsåˆ†åŒºæ— æ³•æ¶ˆåŽ»ã€‚è¯•äº†ä¸€åœˆä¹‹åŽå‘çŽ°åªè¦å†æ–°å»ºä¸€ä¸ªåˆ†åŒºï¼Œç„¶åŽå†ä¸€èµ·åˆå¹¶å°±å¯ä»¥äº†ã€‚]]></content>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽPythonçš„å­—å…¸å¤škeyï¼Œvalueè¿”å›žkey]]></title>
    <url>%2F2019%2F04%2F05%2F%E5%85%B3%E4%BA%8EPython%E7%9A%84%E5%AD%97%E5%85%B8%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF%2F</url>
    <content type="text"><![CDATA[å¤šä¸ªkeys1dict = &#123;(key11,key12): value&#125; å¤§æ¦‚å°±æ˜¯é•¿è¿™ä¸ªæ ·å­çš„ï¼Œkeyçš„ä¸ªæ•°å¤šå°‘æ²¡æœ‰é™åˆ¶ï¼Œè®¿é—®valueçš„æ—¶å€™1dict[(key11,key12)] å¤šä¸ªvalue1dict = &#123;key1:(value1, value2)&#125; è®¿é—®çš„æ—¶å€™å¤§æ¦‚å°±æ˜¯è¿™ä¹ˆå–å€¼12dict[key]dict[key][index] ä»Žvalueæ‰¾åˆ°key å…ˆé€šè¿‡list(dict.key())èŽ·å¾—æ‰€æœ‰çš„keyï¼Œå˜æˆä¸€ä¸ªlist list(dict.value())å¾—åˆ°æ‰€æœ‰çš„valueçš„list ä¸Šé¢è¿™ä¸¤ä¸ªlistçš„indexç›¸åŒï¼Œå…ˆèŽ·å–valueçš„indexï¼Œç„¶åŽå†ä½œä¸ºkeyçš„indexåŽ»keyé‡Œæ‰¾ ä¾‹å­ï¼š12dict = &#123;'a': 1, 'b': 2&#125;list(dict.key())[list(dict.value()).index('1')]]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>å­—å…¸</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Human Computer Interactionç¬”è®°]]></title>
    <url>%2F2019%2F04%2F04%2FHCI%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Introduction 50% å‡ºå‹¤å’Œ 50% report koikeæ£®æ£®è¿˜æœ‰assignment History 1945 Vannevar Bush memexçš„æ¦‚å¿µï¼ŒäºŒæˆ˜æœ«æå‡ºäº†ä¸€ç§ä¿¡æ¯æœºå™¨çš„è®¾æƒ³ï¼ˆä¸ªäººå›¾ä¹¦é¦†ï¼‰ è¿™ç§æœºå™¨å†…éƒ¨ç”¨å¾®ç¼©èƒ¶å·ï¼ˆmicrofilmï¼‰å­˜å‚¨ä¿¡æ¯ï¼Œä¹Ÿå°±æ˜¯è‡ªåŠ¨ç¿»æ‹ï¼Œå¯ä»¥ä¸æ–­å¾€é‡Œé¢æ·»åŠ æ–°çš„ä¿¡æ¯ï¼›æ¡Œé¢ä¸Šæœ‰é˜…è¯»å±ï¼Œç”¨æ¥æ”¾å¤§é˜…è¯»å¾®ç¼©èƒ¶å·ï¼›è¿˜æœ‰è®¸å¤šä¸ªæŒ‰é’®ï¼Œæ¯ä¸€ä¸ªæŒ‰é’®ä»£è¡¨ä¸€ä¸ªä¸»é¢˜ï¼Œåªè¦æŒ‰ä¸€ä¸‹ï¼Œç›¸åº”çš„å¾®ç¼©èƒ¶å·å°±ä¼šæ˜¾ç¤ºå‡ºæ¥ã€‚æ¯ä¸€ä¸ªèƒ¶å·å†…éƒ¨è¿˜è®°å½•ç€ç›¸å…³çš„å…¶ä»–èƒ¶å·çš„ç¼–å·ï¼Œå¯ä»¥æ–¹ä¾¿åœ°åˆ‡æ¢ï¼Œå½¢æˆåŒä¸»é¢˜é˜…è¯»ã€‚åœ¨Bushåšå£«çš„è®¾æƒ³ä¸­ï¼Œè¿™ç§æœºå™¨è¿˜å¯ä»¥ä¸Žå›¾ä¹¦é¦†è”ç½‘ã€‚é€šè¿‡æŸç§æœºåˆ¶ï¼Œå°†å›¾ä¹¦é¦†æ”¶è—çš„èƒ¶å·ï¼Œè‡ªåŠ¨è£…è½½åˆ°æœ¬åœ°æœºå™¨ä¸Šã€‚å› æ­¤ï¼Œåªé€šè¿‡è¿™ä¸€ä¸ªæœºå™¨ï¼Œå°±å¯ä»¥å®žçŽ°æµ·é‡çš„ä¿¡æ¯æ£€ç´¢ã€‚from ç™¾åº¦ç™¾ç§‘ as we may thinkï¼šåŒæ—¶æå‡ºäº†wearableç”µè„‘ 1946 Eniac ç¬¬ä¸€ä¸ªè®¡ç®—æœº æ²¡æœ‰keyboardå’Œdisplayï¼Œåªèƒ½æ‰‹åŠ¨ 1951 UNIVAC å¯ä»¥I/O å…ˆåœ¨çº¸æ¡ä¸Šæ‰“å­”ï¼Œç„¶åŽå†æ”¾è¿›åŽ»è¯» Ivan Sutherland 1963 SketchPadï¼Œdisplayä¸Šé¢æœ‰å›¾åƒäº†ï¼Œå¹¶ä¸”å¯ä»¥å¯¹ç”»é¢è¿›è¡Œæ“ä½œ å¯ä»¥ç”¨å…‰ç¬”æ“ä½œï¼Œä¸æ˜¯ç”¨é”®ç›˜æ“ä½œäº† CADé¼»ç¥– ç¬¬ä¸€ä¸ªVRè®¾å¤‡å±…ç„¶ä¹Ÿæ˜¯ä»–åšå‡ºæ¥çš„ Sword of Damocles(1968) Douglas Engelbart å±…ç„¶å‡ºçŽ°äº†é¼ æ ‡ï¼Œè£…äº†rotatory wheelsï¼ˆç«–ç€çš„é‚£ç§ï¼‰ï¼Œå¯ä»¥åœ¨ä¸¤ä¸ªæ–¹å‘ç§»åŠ¨ï¼ˆæ‰€ä»¥è£…äº†ä¸¤ä¸ªå—ï¼Ÿï¼‰ Alan Kay PCä¹‹çˆ¶ 1972 Dynabookï¼Œcard boardåšçš„ï¼Œå› ä¸ºCPUå’ŒGPuå¤ªå¤§äº†ï¼Œå±å¹•ä¹Ÿæ²¡æœ‰ï¼Œå¹¶ä¸æ˜¯çœŸçš„ 1996å¹´ä¸œèŠåšäº†ä¸ªå«è¿™ä¸ªåå­—çš„PC 1973 Xerox Alto real working machine 1981 Xerox Star å‡ºçŽ°äº†æ¡Œé¢ç³»ç»Ÿ GUI Ted Nelson Hypertext Editing System -&gt; pen to jumo to another page Steve Jobs &amp; Bill Atkinson HyperCard 1987ï¼ŒåŒç±»çš„ä¿¡æ¯éƒ½åœ¨åŒä¸€å¼ å¡ä¸Šï¼Œç„¶åŽæ‰€ä»¥çš„å¡éƒ½è¿žåœ¨ä¸€èµ·ï¼Œå¯ä»¥åœ¨å¡ä¸­é—´jumpã€‚äº‹æƒ…å°±å˜å¾—éžå¸¸ç®€å•äº† Tim Berners-Lee father of WWW ï¼ˆWorld Wide Webï¼‰ Richard Bold put that thereå¯ä»¥ç”¨æ‰‹åŠ¿äº¤äº’ï¼Œè¯­è¨€äº¤äº’ éžå¸¸å¤§çš„ä¸€ä¸ªdisplayå’Œprojector Mark Weiser father of the concept of Ubiquitous conputing(1991) é¢„è¨€äº†ä»¥åŽå¤§å®¶å®¶å®¶æœ‰ç”µè„‘ Jaron Lanier VPL data glove &amp; HMD 1989ï¼Œæ‰‹å¥—é‡Œé¢æœ‰çº¤ç»´ I/Oçš„ç¡¬ä»¶å¦‚ä½•ç»„åˆ -&gt; æ–°çš„HCIæ–¹å¼ design &amp; evaluationACM SIGCHI Whatâ€™s HCI CS design æ˜¯ä¸€ä¸ªäº¤å‰å­¦ç§‘ å­¦ä¼š CHI -&gt; æ›´æ³¨é‡æƒ³æ³•ï¼Œå’Œè½¬åŒ–æˆå®žçŽ° UIST -&gt; æ›´æ³¨é‡implement IEEE/ACM Ubicomp CSCM é‡è¦æ€§ ä¿è¯å®‰å…¨æ€§ï¼Œæå‡ç”Ÿæ´»è´¨é‡ åœ¨å•†ä¸šä¸Šçš„äº§å“åŒ– æŽ¨èä¹¦ The Design of Everyday things æ ¸å¿ƒæ€æƒ³Affordence: äººæƒ³è±¡çš„è¿™ä¸ªä¸œè¥¿çš„ç”¨é€”å’Œå®žé™…çš„ç”¨é€”ï¼Œè®©ç”¨æˆ·çœ‹åˆ°è¿™ä¸ªä¸œè¥¿å°±çŸ¥é“æ˜¯å¹²ä»€ä¹ˆç”¨çš„ æ¯”å¦‚å‚»å±Œçš„çœ‹è§æŒ‰é”®ä¸çŸ¥é“æŒ‰å“ªä¸ªçš„ç“¦æ–¯ç‚‰ æ–¹å‘ä¸åŒçš„è½¦åº§é èƒŒè°ƒèŠ‚ æ ¹æœ¬ä¸çŸ¥é“å“ªä¸ªæ˜¯å“ªä¸ªçš„ç”µç¯å¼€å…³ æƒ³æ³• mapping ui to real layout design is stupid ä¸ƒä¸ªå‡†åˆ™ by Norman 8 golden rules by. Shneiderman consistencyï¼ˆä¸€è‡´æ€§ï¼‰ -&gt; æ¯”å¦‚macçš„pull downæœ€ä¸‹é¢éƒ½æ˜¯quitï¼Œå¤§å®¶çš„ä½ç½®éƒ½å·®ä¸å¤š Short-term memory æ¯”å¦‚èœå•é‡Œé¢çš„ä¸ªæ•° 7+-2 magic number Bringing Design to software T.Winograd GUI &amp; hypermediaGUI CUI -&gt; GUI CUI: I: keyboard O: charracters in display GUI I: keyboard + mouse O: bitmap in display desktop like a real office emvironment (metaphor) document,folder,trash å¯¹äºŽæ²¡æœ‰ç”¨è¿‡ç”µè„‘çš„äººæ¥è¯´éžå¸¸å®¹æ˜“ç†è§£ visualizing to icons operating mouse Jobså±…ç„¶copyäº†è¿™ä¸ªä¸œè¥¿ è·ŸçŽ°åœ¨çš„ä¹Ÿæ²¡æœ‰å¤ªå¤šæ¦‚å¿µï¼ˆstandard interface for computer) pros visual by iconï¼Œå› ä¸ºè§†è§‰çœ‹å‡ºæ¥çš„ä¸œè¥¿æ¯”è¾ƒå¥½ç†è§£ direct manipulation interaction abstract by folders cons number of icons make user confused more computing more physical space typing is faster with keyboard å…¶ä»–çš„ä¸€äº›æƒ³æ³• room metaphor[henderson86] different romms for different task multiply desk (å°±åƒmbpçš„å¤šä¸ªæ¡Œé¢ä¸€æ ·) based on user studys &lt;- how they use each applications å¹¶æ²¡æœ‰å˜æˆä¸»æµï¼Œå“­å“­ è¶…æ•´ç†æ³• super-organizing metaphor å¦‚ä½•æ•´ç†ç‰©ç†æ–‡ä»¶ organize by time, not name sequentially, not hierarchically implemented by Freeman -&gt; Lifestream GUIçš„ä¸€ä¸ªç‰¹å¾WIMPwindow, icon, menu, pointerï¼ˆlike mouseï¼‰ æ•´ä½“æ¥çœ‹ è‹¹æžœæŠŠpull downåœ¨å·¦ä¸Šè§’ï¼Œå› ä¸ºä»Žå·¦å¾€å³æ‹‰æ¯”è¾ƒå®¹æ˜“ windows: å› ä¸ºä¸æƒ³å’Œappleä¸€æ ·æ‰€ä»¥æ‰”åˆ°åº•ä¸‹äº† difficult for icon æ¯”å¦‚è·¯ä¸Šçš„æ ‡å¿—è®¾è®¡çš„å°±å¾ˆè¿·ï¼Œå¤§å®¶éƒ½ä¸çŸ¥é“æ˜¯å¹²å•¥çš„ direct manipulation æ¯”å¦‚åœ¨åˆ é™¤ä¸œè¥¿çš„æ—¶å€™CHIéœ€è¦è‡ªå·±è¾“å…¥ï¼Œä½†æ˜¯GUIå¯ä»¥ç›´æŽ¥æ‹–è¿›trashé‡Œé¢ WYSIWYGwhat you see is what you get PUI?I: recognizationO: large/ small displays PUI(perceptual)GUI -&gt; PUI PUI: using various input(sensors) GUI: mouse&amp; keyboard, not intuitive vision-based HCIwhy? natural &amp; intuitive? not special device, unwired multimodel application recognition detection &amp; recognition object &lt;-(detect) - object detection system(find the thing in the real world) object database &lt;-recognition- objection recognition system(know what it is) detect the hand colorsï¼ˆshapes?ï¼‰ infrared camera near infrared -&gt; vedio cameras(capture near infrared light to the object) far infrared -&gt; capture the heat hand location(æ‰‹æŒ‡åœ¨å“ªï¼Œæ‰‹åœ¨å“ª) hand regions find the centre -&gt; morphlogical operation fingers -&gt; pattern matching(æœ‰å¾ˆå¤šä¸åŒçš„æ–¹æ³•) tracking gesture recognition difficult segmentation of hands/body -&gt; depth camera recognition of 3D pose(occlusion) å¦‚æžœç”¨æˆ·è½¬èº«äº†ï¼Œæ‰‹ä¼šè¢«å…¶ä»–çš„ä¸œè¥¿æŒ¡ä½ detecting begin/end of gestures ä¸€ä¸ªéžå¸¸é‡è¦çš„é—®é¢˜ï¼ high-speed gestures (systems) pacï¼pacï¼ as many hands as possible advantages robust against light conditions real-time with 40 people with 2 hands No instruction necessary 3D gestures(for navigation in VR) 2 cameras recognise hand shapes pattern classification(NN) object recognition tag-based pre-registration of objects difficult to attached on something(unbralla, gloveâ€¦) unnartual overlook based on color information(â€˜1991) 3D histogram(RGB) translation/rotation invariant(å¦‚æžœå›¾ç‰‡æ”¹å˜äº†æ–¹å‘æˆ–è€…å˜äº†ï¼Œä½†æ˜¯é¢œè‰²ä¿¡æ¯è¿˜æ²¡å˜) ä½†æ˜¯é¢œè‰²ç›¸ä¼¼çš„æ—¶å€™æ²¡æ³•åˆ†è¾¨ PTAM(â€˜2007) recgonize feature positions features &amp; markers gaze recognition infrared cameras &amp; LEDs pattern matching corners of eyes,mouse,shaping triangle -&gt; face direction 4/18interactive surface ä¾‹å­ handheld:phone, tablet horizantal: desk vertical: wall digital desk(â€˜93) overhead projector + camera + desk metaDesk(â€˜97) -&gt; ç”¨ä¸¤ä¸ªå¥‡æ€ªçš„æ–¹å—ï¼Œå¯¹è¿™ä¸ªmapè¿›è¡Œæ“ä½œ LCD tabletop LCD -&gt; larger, thinner,lighter,higher resolusion, less expensive before that use projectors(dark) use as window? real glass is expensive then LCD principles of polarization æ»¤å…‰å—ï¼Œä¸¤ä¸ªæ–¹å‘çš„ï¼ˆåæŒ¯ç‰‡ï¼‰ è¿™æ ·å¯ä»¥ç”¨æ¥æ£€æµ‹æ‰‹ï¼ŒæŠŠæ‰‹ä¹‹åŽçš„èƒŒæ™¯å…‰æ»¤æŽ‰ éžå¸¸å¥½ç”¨ å¯ä»¥ç”¨æ¥æ£€æµ‹æ‰‹ AR markerè¿™æ ·çš„ä¸œè¥¿å®žåœ¨æ˜¯å¤ªä¸‘äº† design invisiable markers æŠŠåæŒ¯å…‰ç‰‡å‡æˆäº†ar markerçš„æ ·å­ï¼Œäººçœ‹ä¸åˆ°ä½†æ˜¯æœºå™¨å¯ä»¥è¯†åˆ« background &amp; motivation traditional surfaces are planar &amp; regid difficult to make 3D surface photoelasricity -&gt; é€æ˜Žçš„ææ–™å¯¹ä¸åŒè½½è·ä¸‹é¢œè‰²ä¸åŒ -&gt; ä¹Ÿå¯ä»¥ç”¨æ¥ä½œä¸ºå½±å“åæŒ¯å…‰çš„å› ç´ ï¼Œå¯ä»¥ç”¨æ¥æŒ‰ï¼ŒæŒ‰ä¸‹åŽ»å…‰å°±èƒ½è¿‡åŽ»æƒ¹ electrical shock ä¸ºä»€ä¹ˆä¼šæœ‰è¿™ç§ç”µäººçš„displayå•Šï¼ï¼ˆBIRIBIRIï¼‰ beyond 2D surfaceCaytrick surface(â€˜18)4/22 information visualizationæ›´å¿«ï¼Œæ›´ç²¾å‡†çš„ç†è§£info(shape/ colors -&gt; information) SciVis &amp; InfoVis Sci ç”¨æˆ·æ¯”è¾ƒä¸“ä¸š ç”¨æ¥ç†è§£ä¸“ä¸šçš„çŽ°è±¡ physical data, measured data, simulation data Info abstract data ç»™äººæ°‘ç¾¤ä¼—çœ‹çš„ï¼Œæ„Ÿè§‰æ›´åŠ ç›´è§‚ how to layout the data three issues scalability å¦‚æžœæˆ‘ä»¬æƒ³è¦vis infoï¼Œå¦‚æžœdataçš„é‡å¤ªå¤§äº†ï¼Œæœ‰äº›ä¸œè¥¿çœ‹èµ·æ¥å°±å¾ˆå¤æ‚(eg.trees) limited display size human cant understand tech layout scalability filiter layout graph drawing å¥½çœ‹ï¼Œeconomicallyï¼ˆå¤šçº§åŒ–çš„ï¼Œä¸­å¿ƒè¾å°„ï¼Œå¼•åŠ›åž‹ -&gt; ä¸åŒå…³ç³»çš„ç›¸æ–¥ï¼Œåœ†çŽ¯çŠ¶ï¼‰ tree structure TreeMap 5/9 Cognitive processwhy important çœ‹åˆ°çš„ä¸ä¸€å®šå°±æ˜¯çœŸå®žçš„ é€šè¿‡æ”¹å˜HCIï¼Œå¯ä»¥æ”¹å˜çœ‹åˆ°çš„ä¸œè¥¿çš„ Seven Stage Model]]></content>
      <categories>
        <category>HCI</category>
        <category>ä¸Šè¯¾ç¬”è®°</category>
      </categories>
      <tags>
        <tag>HCI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Xcodeçš„breakpoint1.1é—®é¢˜ä»¥åŠæ‰“å¼€æ‘„åƒå¤´]]></title>
    <url>%2F2019%2F04%2F04%2FXcodebreakpoint%2F</url>
    <content type="text"><![CDATA[æœ€è¿‘ä¸Šè¯¾åˆè¦æ¡èµ·æ¥c++äº†ï¼ŒåŠå¹´å‰æ‰æ¢çš„macç”¨xcodeæ²¡vsé¡ºæ‰‹ï¼Œå¥½å‡ æ¬¡é‡åˆ°äº†æŒºç¥žå¥‡çš„é”™è¯¯ã€‚ thread 1 breakpoint 1.1è¿™ä¸ªé—®é¢˜å…¶å®žå°±æ˜¯ä½ åœ¨ä»£ç é‡Œé¢è‡ªå·±åŠ ä¸Šäº†æ–­ç‚¹(breakpoint)ï¼Œä¼°è®¡æ˜¯ä¸å°å¿ƒç‚¹åˆ°çš„ã€‚å–æ¶ˆäº†æ–­ç‚¹å°±è¡Œ å…³äºŽXcodeå…è®¸ç›¸æœºxcodeçš„ç›¸æœºè®¸å¯æˆ‘ä¹‹å‰æŠ˜è…¾äº†ä¸€ä¸ªä¸‹åˆæ‰å‘çŽ°æ€Žä¹ˆæžã€‚ é¦–å…ˆï¼Œéœ€è¦æœ‰ä¸€ä¸ªå…è®¸ç›¸æœºçš„Info.plistæ–‡ä»¶ï¼Œæ–‡ä»¶å†…å®¹å¦‚ä¸‹ 1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;&lt;plist version="1.0"&gt;&lt;dict&gt;&lt;key&gt;NSCameraUsageDescription&lt;/key&gt;&lt;string&gt;Used to capture new image for photo effect&lt;/string&gt;&lt;key&gt;CFBundleName&lt;/key&gt;&lt;string&gt;$&#123;OPENCV_APPLE_BUNDLE_NAME&#125;&lt;/string&gt;&lt;key&gt;CFBundleIdentifier&lt;/key&gt;&lt;string&gt;$&#123;OPENCV_APPLE_BUNDLE_ID&#125;&lt;/string&gt;&lt;key&gt;CFBundleVersion&lt;/key&gt;&lt;string&gt;$&#123;OPENCV_LIBVERSION&#125;&lt;/string&gt;&lt;key&gt;CFBundleShortVersionString&lt;/key&gt;&lt;string&gt;$&#123;OPENCV_LIBVERSION&#125;&lt;/string&gt;&lt;key&gt;CFBundleSignature&lt;/key&gt;&lt;string&gt;????&lt;/string&gt;&lt;key&gt;CFBundlePackageType&lt;/key&gt;&lt;string&gt;FMWK&lt;/string&gt;&lt;/dict&gt;&lt;/plist&gt; å…¶ä¸­ï¼ŒNSCameraUsageDescriptionè¿™éƒ¨åˆ†å°±æ˜¯æ‰“å¼€ç›¸æœºçš„è®¸å¯ã€‚ ä½†æ˜¯è¿™ä¸ªæ–‡ä»¶ç›´æŽ¥æ”¾åœ¨é¡¹ç›®é‡Œæ˜¯ä¸è¡Œçš„ï¼Œéœ€è¦å¤åˆ¶ä¸‹æ¥ï¼Œæ‰“å¼€productsçš„è·¯å¾„ï¼Œç„¶åŽå¤åˆ¶åˆ°è¿™ä¸ªè·¯å¾„é‡Œé¢ï¼Œæ‰å¯ä»¥æˆåŠŸçš„æ‰“å¼€ç›¸æœº]]></content>
      <categories>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>Xcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽSVMçš„ç†è§£]]></title>
    <url>%2F2019%2F04%2F03%2F%E5%85%B3%E4%BA%8ESVM%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[æœ¬æ–‡å‚è€ƒæ”¯æŒå‘é‡æœºé€šä¿—å¯¼è®ºå†…å®¹ SVMåˆ°åº•æ˜¯å•¥support vecttor machineï¼Œæ¯”å¦‚åœ¨äºŒç»´å¹³é¢ä¸Šï¼Œè¦æŠŠä¸€ä¸ªä¸œè¥¿åˆ†æˆä¸¤ç±»ï¼ŒSVMå°±æ˜¯å¹³é¢ä¸Šçš„ä¸€æ¡ç›´çº¿ï¼Œå¹¶ä¸”åœ¨è¿™ä¸¤ç±»çš„æ­£ä¸­é—´ï¼Œç¦»ä¸¤è¾¹ä¸€æ ·è¿œã€‚æ¢å¥è¯è¯´ï¼Œå­¦ä¹ ç­–ç•¥æ˜¯æŠŠé—´éš”æœ€å¤§åŒ–ï¼Œä»Žè€Œå¾—åˆ°å‡¸äºŒæ¬¡è§„åˆ’é—®é¢˜çš„è§£ï¼ˆè™½ç„¶ä¸æ˜¯å¾ˆç†è§£ï¼Œä½†æ˜¯å‡¸é—®é¢˜åº”è¯¥æ˜¯æ¯”è¾ƒå¥½æ±‚è§£ï¼‰ åˆ†ç±»æ ‡å‡† logistic regression çº¿æ€§åˆ†ç±»å™¨ï¼šxè¡¨ç¤ºæ•°æ®ï¼Œyè¡¨ç¤ºç±»åˆ«ï¼Œåˆ†ç±»å™¨åˆ™éœ€è¦åœ¨nç»´æ‰¾åˆ°ä¸€ä¸ªè¶…å¹³é¢hyper planeï¼Œè¶…å¹³é¢çš„æ–¹ç¨‹å°±æ˜¯W.T ä¹Ÿå°±æ˜¯ W.T.dot(x) + b = 0 (ä»¤äººéœ‡æƒŠwå±…ç„¶æ˜¯è¶…å¹³é¢çš„æ–¹ç¨‹) é€»è¾‘å›žå½’ é€»è¾‘å›žå½’å°±æ˜¯ä»Žç‰¹å¾é‡Œé¢å­¦åˆ°ä¸€ä¸ª0/1çš„åˆ†ç±»æ¨¡åž‹ æ¨¡åž‹çš„çº¿æ€§ç»„åˆä½œä¸ºè‡ªå˜é‡ï¼Œå–å€¼èŒƒå›´æ˜¯è´Ÿæ— ç©·åˆ°æ­£æ— ç©·ï¼Œæ‰€ä»¥ä½¿ç”¨logisticå‡½æ•°ï¼ˆç«Ÿç„¶å°±æ˜¯simoidå‡½æ•°æŠŠä»–ä»¬æŠ•å½±åˆ°ï¼ˆ0ï¼Œ1ï¼‰ä¸Šé¢ï¼Œå¾—åˆ°çš„å€¼å°±æ˜¯y = 1çš„æ¦‚çŽ‡ çº¿æ€§åˆ†ç±»å™¨å¦‚æžœæŠŠåˆ†ç±»çš„ä¸¤ç±»æ”¹æˆ -1å’Œ1ï¼ˆåªæ˜¯ä¸ºäº†æ–¹ä¾¿é€‰äº†è¿™ä¸ªæ•°å­—ï¼‰ï¼Œå…¶å®žå°±æ˜¯æŠŠwxåŠ äº†b è¿™æ—¶å€™çš„ç‚¹çš„ä½ç½®å¯ä»¥ç”¨ f(x) = wx + bè¡¨ç¤ºï¼Œå¦‚æžœf(x)ç­‰äºŽ0ï¼Œé‚£ä¹ˆè¿™ä¸ªç‚¹åœ¨è¶…å¹³é¢ä¸Šï¼Œå¦‚æžœå¤§äºŽ0å°±æ˜¯åœ¨1çš„ç±»åž‹é‡Œï¼Œå°äºŽ0åœ¨-1çš„ç±»åž‹é‡Œ è¿™æ—¶å€™é—®é¢˜å˜æˆäº†å¯»æ‰¾é—´éš”æœ€å¤§çš„è¶…å¹³é¢ function marginï¼Œgeometrical marginå‡½æ•°è·ç¦» å½“å¹³é¢ä¸Šçš„ç‚¹æ˜¯ wx+b = 0 ç¡®å®šäº†ä»¥åŽï¼Œ wx+bçš„ç»å¯¹å€¼å°±æ˜¯ç‚¹xåˆ°è¶…å¹³é¢çš„è·ç¦» åŒæ—¶ wx+b çš„ç¬¦å·å’Œ yï¼ˆåˆ†ç±»æ ‡ç­¾ï¼‰çš„ç¬¦å·å¯¹æ¯”ï¼Œå¦‚æžœä¸€è‡´çš„è¯æ˜¯ä¸€ä¸ªç±»åˆ«ï¼Œä¸ä¸€è‡´çš„è¯æ˜¯å¦ä¸€ä¸ª -&gt; y(wx+ b)çš„æ­£è´Ÿæ¥è¡¨ç¤ºåˆ†ç±»çš„æ­£ç¡®ä¸Žå¦ ï¼ˆä¹Ÿå°±æ˜¯ä¸¤ä¸ªä¸œè¥¿åŒå·å¾—æ­£åˆ†ç±»æ­£ç¡®ï¼‰ å¼•å‡ºå‡½æ•°é—´éš”çš„å®šä¹‰ï¼ˆè¿™é‡Œçš„yæ˜¯ä¹˜ä¸Šå¯¹åº”ç±»åˆ«çš„yï¼Œæ‰€ä»¥èƒ½å¾—åˆ°ç»å¯¹å€¼ï¼‰ åœ¨è®­ç»ƒé›†ä¸­ï¼Œæ‰€æœ‰ç‚¹åˆ°è¶…å¹³é¢çš„è·ç¦»çš„æœ€å°ç‚¹å°±æ˜¯function margin å‡ ä½•è·ç¦» ä½†æ˜¯å¦‚æžœå•çº¯è¿™ä¹ˆè¯„å®šï¼Œå½“wå’Œbæˆæ¯”ä¾‹æ”¹å˜çš„æ—¶å€™ï¼Œå‡½æ•°é—´éš”ä¹Ÿä¼šæ”¹å˜ï¼Œæ‰€ä»¥è¿˜éœ€è¦å‡ ä½•é—´éš”ä¸Šé¢çš„å¼å­ä¹˜ä»¥yï¼ˆå¯¹åº”ç±»åˆ«çš„æ ‡ç­¾ï¼‰å°±å¯ä»¥å¾—åˆ°ç»å¯¹å€¼äº†ã€‚ ä¹Ÿå°±æ˜¯è¯´å‡ ä½•marginçš„ä¸»è¦éƒ¨åˆ†å°±æ˜¯æŠŠä¹‹å‰çš„å†…å®¹é™¤äº†ä¸€ä¸ªwçš„èŒƒæ•°ï¼Œå˜æˆäº†æ ‡å‡†åŒ–ä¹‹åŽçš„é•¿åº¦ æœ€å¤§é—´éš”åˆ†ç±»å™¨ max margin classifierå¯¹äºŽä¸€ç»„æ•°æ®æ¥è¯´ï¼Œè¶…å¹³é¢å’Œæ•°æ®ç‚¹çš„è·ç¦»è¶Šå¤§ï¼Œè¿™ä¸ªæ•°æ®çš„åˆ†ç±»ç¡®ä¿¡åº¦ï¼ˆconfidenceï¼‰å°±è¶Šé«˜ æœ€å¤§çš„é—´è·çš„ç›®æ ‡å‡½æ•°å³ï¼š max\gamaï¼Œ å…¶ä¸­gamaæ˜¯æ¯”æ‰€æœ‰å…¶ä»–é—´éš”éƒ½çŸ­çš„å‡½æ•°é—´éš” å¦‚æžœè®©æœ€å°çš„å‡½æ•°é—´éš”ç­‰äºŽ1ï¼ˆä¸ºäº†æ–¹ä¾¿è®¡ç®—ï¼‰ï¼Œç„¶åŽæ±‚å‡ ä½•é—´éš”ï¼Œå¯ä»¥å¾—çŸ¥éœ€è¦çš„ç›®æ ‡å‡½æ•°å˜ä¸ºæœ€å¤§åŒ– 1/||w||ï¼Œå…¶ä¸­wæ˜¯è¶…å¹³é¢ æ·±å…¥SVMçº¿æ€§å¯åˆ†å’Œä¸å¯åˆ†åŽŸå§‹é—®é¢˜å’Œå¯¹å¶é—®é¢˜duality ä¹‹å‰çš„ç›®æ ‡å‡½æ•°æ˜¯ 1/||w||ï¼Œæ‰€ä»¥æ±‚è¿™ä¸ªçš„æœ€å¤§å€¼ï¼Œå°±æ˜¯æ±‚1/2*||w||^2çš„æœ€å°å€¼ï¼ˆè¿™é‡Œæ±‚æœ€å¤§å€¼å°±æ˜¯æ±‚å€’æ•°çš„æœ€å°å€¼ï¼Œç„¶åŽ1/2å’Œå¹³æ–¹éƒ½æ˜¯ä¸ºäº†æ–¹ä¾¿åŠ çš„ï¼‰ ç›®æ ‡å‡½æ•°å˜æˆäºŒæ¬¡çš„ï¼Œçº¦æŸæ¡ä»¶æ˜¯çº¿æ€§çš„ï¼Œå‡¸äºŒæ¬¡é—®é¢˜ï¼Œå¯ä»¥ç”¨QPï¼ˆä¸€ä¸ªå†™çš„å·®ä¸å¤šçš„åŒ…ï¼‰ -&gt; ç›®æ ‡æœ€ä¼˜çš„æ—¶å€™loss ç”±äºŽè¿™ä¸ªé—®é¢˜çš„ç»“æž„ï¼Œå¯ä»¥è½¬æ¢æˆå¯¹å¶é—®é¢˜æ±‚è§£ ç»™æ¯ä¸€ä¸ªçº¦æŸæ¡ä»¶åŠ ä¸Šä¸€ä¸ªæ‹‰æ ¼æœ—æ—¥ä¹˜å­ alpha æŠŠè¿™ä¸ªèžåˆè¿›å…¥ç›®æ ‡å‡½æ•°é‡Œé¢ å½“æ‰€æœ‰çš„çº¦æŸæ¡ä»¶éƒ½æ»¡è¶³çš„æ—¶å€™ï¼Œç›®æ ‡å‡½æ•°çš„ç»“æžœå°±æ˜¯ä¹‹å‰éœ€è¦æ±‚çš„ç›®æ ‡å‡½æ•°ã€‚ å†å¯¹è¿™ä¸ªç›®æ ‡å‡½æ•°ï¼ˆæ–°çš„ï¼‰æ±‚æœ€å°å€¼ï¼Œå¾—åˆ°çš„ç»“æžœå°±æ˜¯æœ¬æ¥éœ€è¦æ±‚çš„æœ€å°å€¼ æœ€åŽï¼Œå› ä¸ºä¸Šé¢çš„é—®é¢˜ä¸æ˜¯å¾ˆå¥½æ±‚è§£ï¼ŒæŠŠå®ƒçš„maxå’Œminäº¤æ¢äº†ä¸€ä¸‹ï¼Œå…ˆæ±‚æ‰€æœ‰çš„é—´éš”çš„æœ€å°å€¼ï¼Œç„¶åŽå†æ±‚è¿™é‡Œé¢alphaæ¡ä»¶å¯ä»¥æ»¡è¶³çš„æœ€å¤§å€¼ï¼Œè¿™ä¸¤ä¸ªé—®é¢˜å°±æ˜¯å¯¹å¶é—®é¢˜ d &lt;= p ï¼Œåœ¨æŸäº›æ¡ä»¶æ»¡è¶³çš„æƒ…å†µä¸‹è¿™ä¸¤ä¸ªå€¼ç›¸ç­‰ï¼Œè¿™æ—¶å€™æ±‚å‡ºæ¥å¯¹å¶é—®é¢˜å°±å¯ä»¥æ±‚å‡ºæ¥åŽŸå§‹é—®é¢˜çš„è§£ è½¬æ¢å¯¹å¶é—®é¢˜çš„åŽŸå› ï¼š å¯¹å¶é—®é¢˜æ›´å®¹æ˜“æ±‚è§£ å¯ä»¥å¼•å…¥æ ¸å‡½æ•°ï¼Œè¿™æ ·å¯ä»¥ç›´æŽ¥å¼•å…¥éžçº¿æ€§é—®é¢˜ K.K.Tæ¡ä»¶ ä¸Šä¸€æ®µè¯´çš„ï¼Œæ»¡è¶³å¯¹å¶é—®é¢˜çš„è§£ç­‰ä»·çš„æ¡ä»¶å°±æ˜¯KKTæ¡ä»¶ KTTæ¡ä»¶çš„æ„ä¹‰ï¼šéžçº¿æ€§è§„åˆ’é—®é¢˜ï¼ˆnonlinear processingï¼‰èƒ½æœ‰æœ€ä¼˜åŒ–è§£æ³•çš„å……è¦æ¡ä»¶ è¿™éƒ¨åˆ†æ²¡æœ‰å†™è¯æ˜Žï¼Œä½†æ˜¯ä¸Šé¢çš„æ±‚æœ€å€¼çš„é—®é¢˜å¯ä»¥è¢«è¯æ˜Žæ˜¯æ»¡è¶³KKTæ¡ä»¶çš„é—®é¢˜ï¼Œæ‰€ä»¥å¯ä»¥ç”¨è§£å†³å¯¹å¶é—®é¢˜çš„æ–¹å¼æ¥æ±‚è§£ã€‚ å¯¹å¶é—®é¢˜çš„æ±‚è§£æ­¥éª¤å‚è€ƒå†…å®¹ https://www.zhihu.com/question/21094489 https://blog.csdn.net/v_JULY_v/article/details/7624837]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Machine Learning</category>
        <category>SVM</category>
      </categories>
      <tags>
        <tag>SVM</tag>
        <tag>åˆ†ç±»å™¨</tag>
        <tag>æœºå™¨å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment1ä¹‹Image Features]]></title>
    <url>%2F2019%2F04%2F03%2FCS231Nassignment1Feature%2F</url>
    <content type="text"><![CDATA[ç›®æ ‡ ä¹‹å‰å®žçŽ°çš„éƒ½æ˜¯å†™å¥½äº†ä¸€ä¸ªlinear classifierç„¶åŽç›´æŽ¥å¯¹è¾“å…¥å›¾ç‰‡çš„raw pixelè¿›è¡Œåˆ†ç±» è¿™éƒ¨åˆ†æ˜¯å…ˆä»Žraw dataå¾—åˆ°ç›¸åº”çš„å›¾ç‰‡ç‰¹å¾ï¼Œç„¶åŽå†å¯¹ç‰¹å¾è¿›è¡Œåˆ†ç±» å‰é¢çš„ç®€å•çš„setupå’Œload dataéƒ½å’Œä¹‹å‰çš„ä¸€æ ·ã€‚ Extract Features å¯¹æ¯å¼ å›¾ç‰‡è®¡ç®—HOGä»¥åŠåœ¨HSVçš„color spaceä¸Šé¢çš„hue channelã€‚ï¼ˆè¿™æ˜¯ä¸¤ä¸ªä¸åŒçš„åŠŸèƒ½ï¼‰ HOGå¯ä»¥æå–å›¾ç‰‡çš„textureçš„ç‰¹å¾ï¼Œå¿½ç•¥é¢œè‰²çš„å½±å“ã€‚è€Œé¢œè‰²çš„histogramè¡¨ç¤ºçš„æ˜¯é¢œè‰²è€Œå¿½ç•¥textureï¼Œé¢œè‰²çš„ç‰¹å¾ä¼šæ‹‰æˆä¸€ä¸ªæ–°çš„vectorç„¶åŽè¿›è¡Œåˆ†ç±»ã€‚ å¦‚æžœæˆ‘ä»¬æŠŠè¿™ä¸¤ä¸ªä¸œè¥¿ç»“åˆå¯èƒ½ä¼šæœ‰æ›´å¥½çš„ç»“æžœã€‚ åœ¨è¿™éƒ¨åˆ†çš„ä»£ç é‡Œé¢ï¼Œç›´æŽ¥ç»™å‡ºæ¥äº†æå–hog featureå’Œcolor histogramçš„ä¸¤ä¸ªfunctionï¼Œç”¨è¿™ä¸¤ä¸ªç›´æŽ¥æå–å‡ºäº†ç‰¹å¾ç„¶åŽæž„æˆäº†ä¸€ä¸ªæ–°çš„extract_featuresï¼Œç”±å›¾ç‰‡å†…å®¹å’Œç‰¹å¾ç»„æˆã€‚ ç„¶åŽé¢„å¤„ç†äº†ç‰¹å¾ï¼Œå‡åŽ»å¹³å‡å€¼ï¼Œé™¤ä»¥stdï¼ˆè¿™æ ·å¤§å®¶éƒ½åœ¨åŒä¸€ä¸ªscaleé‡Œé¢ï¼‰ï¼Œæœ€åŽåŠ ä¸Šäº†ä¸€ä¸ªbiasçš„dim 12345678910111213141516171819202122232425from cs231n.features import *num_color_bins = 10 # Number of bins in the color histogramfeature_fns = [hog_feature, lambda img: color_histogram_hsv(img, nbin=num_color_bins)]X_train_feats = extract_features(X_train, feature_fns, verbose=True)X_val_feats = extract_features(X_val, feature_fns)X_test_feats = extract_features(X_test, feature_fns)# Preprocessing: Subtract the mean featuremean_feat = np.mean(X_train_feats, axis=0, keepdims=True)X_train_feats -= mean_featX_val_feats -= mean_featX_test_feats -= mean_feat# Preprocessing: Divide by standard deviation. This ensures that each feature# has roughly the same scale.std_feat = np.std(X_train_feats, axis=0, keepdims=True)X_train_feats /= std_featX_val_feats /= std_featX_test_feats /= std_feat# Preprocessing: Add a bias dimensionX_train_feats = np.hstack([X_train_feats, np.ones((X_train_feats.shape[0], 1))])X_val_feats = np.hstack([X_val_feats, np.ones((X_val_feats.shape[0], 1))])X_test_feats = np.hstack([X_test_feats, np.ones((X_test_feats.shape[0], 1))]) è®­ç»ƒSVMæ¥å¤„ç†featuresç”¨å¤„ç†å¤šä¸ªç±»åˆ«çš„SVMæ¥ç»™è¿™äº›ç‰¹å¾åˆ†ç±»ï¼Œå¾—åˆ°çš„ç»“æžœåº”è¯¥æ¯”ç›´æŽ¥åˆ†ç±»å¾—åˆ°çš„ç»“æžœå¥½ã€‚å¤§æ¦‚ç»“æžœä¸º0.44å·¦å³ï¼Œæ³¨æ„è¿™é‡Œé¢ç”¨çš„æ˜¯grid searchè€Œä¸æ˜¯random search 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# Use the validation set to tune the learning rate and regularization strengthfrom cs231n.classifiers.linear_classifier import LinearSVMlearning_rates = [1e-9, 1e-8, 1e-7]regularization_strengths = [5e4, 5e5, 5e6]results = &#123;&#125;best_val = -1best_svm = None################################################################################# TODO: ## Use the validation set to set the learning rate and regularization strength. ## This should be identical to the validation that you did for the SVM; save ## the best trained classifer in best_svm. You might also want to play ## with different numbers of bins in the color histogram. If you are careful ## you should be able to get accuracy of near 0.44 on the validation set. #################################################################################for lr in learning_rates: for rs in regularization_strengths: svm = LinearSVM() svm.train(X_train_feats, y_train, learning_rate = lr, reg = rs, num_iters = 1000, verbose = True) y_pred_val = svm.predict(X_val_feats) y_pred_train = svm.predict(X_train_feats) train_acc = np.mean(y_pred_train) val_acc = np.mean(y_pred_val == y_val) results[(lr, rs)] = (train_acc,val_acc) if val_acc &gt; best_val: best_val = val_acc best_svm = svm################################################################################# END OF YOUR CODE ################################################################################## Print out results.for lr, reg in sorted(results): train_accuracy, val_accuracy = results[(lr, reg)] print('lr %e reg %e train accuracy: %f val accuracy: %f' % ( lr, reg, train_accuracy, val_accuracy)) print('best validation accuracy achieved during cross-validation: %f' % best_val) åŒæ—¶ä¹Ÿå¯è§†åŒ–äº†ä¸æ˜¯è¿™ä¸ªç±»åˆ«å´è¢«åˆ†åˆ°è¿™ä¸ªç±»åˆ«çš„é”™è¯¯sampleï¼š123456789101112131415161718# An important way to gain intuition about how an algorithm works is to# visualize the mistakes that it makes. In this visualization, we show examples# of images that are misclassified by our current system. The first column# shows images that our system labeled as "plane" but whose true label is# something other than "plane".examples_per_class = 8classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']for cls, cls_name in enumerate(classes): idxs = np.where((y_test != cls) &amp; (y_test_pred == cls))[0] idxs = np.random.choice(idxs, examples_per_class, replace=False) for i, idx in enumerate(idxs): plt.subplot(examples_per_class, len(classes), i * len(classes) + cls + 1) plt.imshow(X_test[idx].astype('uint8')) plt.axis('off') if i == 0: plt.title(cls_name)plt.show() ï¼ˆæ„Ÿè§‰è‡ªå·±è®­ç»ƒäº†ä¸€ä¸ªå‚»å­ï¼‰ ç”¨ä¸¤å±‚çš„nerual netè¯•è¯•çœ‹ é¦–å…ˆåŽ»é™¤ä¸Šæ–‡ä¸­biasçš„dim ç„¶åŽäº¤å‰è®­ç»ƒï¼Œæ‰¾åˆ°æœ€å¥½çš„å‚æ•° è¿™éƒ¨åˆ†åŠå¤©lossä¸‹ä¸åŽ»çš„åŽŸå› ä¸»è¦æ˜¯lré€‰çš„å¤ªå°äº† 1234567891011121314151617181920212223242526272829303132333435363738394041424344from cs231n.classifiers.neural_net import TwoLayerNetinput_dim = X_train_feats.shape[1]hidden_dim = 500num_classes = 10hidden_size = [300,400,500,600]learning_rate = [1,1e-1,1e-2]reg = [1e-4,1e-3,1e-2]# net = TwoLayerNet(input_dim, hidden_dim, num_classes)best_net = Nonebest_acc = -1result = &#123;&#125;################################################################################# TODO: Train a two-layer neural network on image features. You may want to ## cross-validate various parameters as in previous sections. Store your best ## model in the best_net variable. #################################################################################for lr in learning_rate: for hidd in hidden_size: for rs in reg: net = TwoLayerNet(input_size, hidden, num_class) status = net.train(X_train_feats, y_train, X_val_feats, y_val, num_iters=1200, batch_size=400, learning_rate=lr, learning_rate_decay=0.95, reg=rs, verbose= True) val_acc = (net.predict(X_val_feats) == y_val).mean() result[(lr, rs, hidd)] = (val_acc) if val_acc &gt; best_acc: best_acc = val_acc best_net = net# print(result)# for lr, rs, hidd in sorted(result):# val_accuracy = result[(lr, rs, hidd)]# print('lr %e reg %e hidden_units %e val accuracy: %f' % (# lr, rs, hidd , val_accuracy))print('best validation accuracy achieved during cross-validation: %f' % best_acc)print('best parameter is :',list (result.keys()) [list (result.values()).index (best_acc)])################################################################################# END OF YOUR CODE ################################################################################# best validation accuracy achieved during cross-validation: 0.605000best parameter is : (1, 0.0001, 500) ä¸€ç‚¹æ„Ÿè§‰ æ„Ÿè§‰è¦æ˜¯lrå¤ªå°çš„è¯ï¼Œå³ä½¿å¢žåŠ iterationçš„æ¬¡æ•°ï¼ŒåŽé¢çš„æ”¹å˜ä¹Ÿä¸å¤§ lræœ€åŸºç¡€çš„èŒƒå›´åº”è¯¥å…ˆå®šä¸‹æ¥ æœ€åŽæ¢äº†æ¢å‚æ•°å±…ç„¶è®­å‡ºæ¥äº†60%çš„valæ­£ç¡®çŽ‡ testçš„æ­£ç¡®çŽ‡åœ¨55.8å·¦å³]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
        <category>CS231nä½œä¸š</category>
      </categories>
      <tags>
        <tag>Image Feature</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment1ä¹‹two_layer_net]]></title>
    <url>%2F2019%2F04%2F02%2FCS231Nassignment1twolayernet%2F</url>
    <content type="text"><![CDATA[ç›®æ ‡ Implement a neural network with fc layers for classifiction Test it on CIFAR-10 dataset åˆå§‹åŒ–auto-reloading external modules å®šä¹‰relative error123def rel_error(x, y): """ returns relative error """ return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y)))) è¿™é‡Œæ’å…¥ä¸€ä¸‹np.maxå’Œnp.maximumçš„åŒºåˆ« maxæ˜¯æ±‚åºåˆ—çš„æœ€å€¼ï¼Œå¯ä»¥è¾“å…¥ä¸€ä¸ªå‚æ•°ï¼Œaxisè¡¨ç¤ºçš„æ˜¯æ±‚æœ€å€¼çš„æ–¹å‘ maximumè‡³å°‘è¾“å…¥ä¸¤ä¸ªå‚æ•°ï¼Œä¼šæŠŠä¸¤ä¸ªå‚æ•°é€ä½æ¯”è¾ƒï¼Œç„¶åŽè¾“å‡ºæ¯”è¾ƒå¤§çš„é‚£ä¸ªç»“æžœ ä½†æ˜¯å¥½åƒåœ¨è¿™é‡Œçš„ä½¿ç”¨ä¸Šé¢ï¼Œè¯´æ˜Žxå’Œyä¸æ˜¯ä¸€ä¸ªå•ç‹¬çš„å€¼ï¼Œåº”è¯¥æ˜¯ä¸¤ä¸ªæ•°ç»„ 12345&gt;&gt; np.max([-4, -3, 0, 0, 9])9&gt;&gt; np.maximum([-3, -2, 0, 1, 2], 0)array([0, 0, 0, 1, 2]) ä¸æ˜¯å¾ˆç†è§£è¿™é‡Œä¸ºä»€ä¹ˆè¦é™¤ä»¥x+y è®¾ç½®å‚æ•°cs231n/classifiers/neural_net.pyself.paramså‚¨å­˜äº†éœ€è¦çš„å‚æ•°ï¼Œå‚æ•°éƒ½è¢«å­˜å‚¨åœ¨dicté‡Œé¢ï¼Œä¸€ä¸ªåå­—å¯¹åº”ä¸€ä¸ªå†…å®¹ ä¸¤å±‚ç¥žç»ç½‘ç»œçš„å‚æ•°å¦‚ä¸‹ï¼š W1ï¼Œç¬¬ä¸€å±‚çš„weightsï¼Œï¼ˆDï¼ŒHï¼‰ï¼Œå…¶ä¸­Hæ˜¯ç¬¬äºŒå±‚çš„neruonçš„ä¸ªæ•°ã€‚å› ä¸ºåªæœ‰ä¸€å±‚çš„æ—¶å€™ï¼ŒDä¸ªè¾“å…¥å¯¹åº”Cä¸ªè¾“å‡ºï¼ŒçŽ°åœ¨æœ‰ä¸¤å±‚çš„fcï¼Œå¯¹åº”çš„è¾“å‡ºå°±æ˜¯ç¬¬äºŒå±‚çš„unitsä¸ªæ•° b1ï¼Œç¬¬ä¸€å±‚çš„biasï¼Œï¼ˆHï¼Œï¼‰ W2ï¼Œç¬¬äºŒå±‚çš„weightsï¼Œï¼ˆHï¼ŒCï¼‰ b2ï¼Œç¬¬äºŒå±‚çš„biasbiaséƒ½éœ€è¦åˆå§‹åŒ–ä¸ºç›¸åº”å¤§å°çš„0ï¼Œweightsåˆå§‹åŒ–æˆ0-1ä¹‹é—´çš„æ¯”è¾ƒå°çš„æ•°å­— Forward pasaè®¡ç®—scores è¿™éƒ¨åˆ†éžå¸¸ç®€å•ï¼Œä¸¤æ¬¡Wx+bï¼Œå¹¶ä¸”åœ¨ç¬¬ä¸€æ¬¡ä¹‹åŽè®°å¾—æ¿€æ´»å°±å¯ä»¥äº† æ¿€æ´»å‡½æ•°ç”¨çš„reluï¼Œå†…å®¹å°±æ˜¯scoreå°äºŽ0çš„éƒ¨åˆ†è®©ä»–ç›´æŽ¥ç­‰äºŽ0 è®¡ç®—loss è¿™é‡Œç”¨çš„æ˜¯softmaxè®¡ç®—lossï¼Œå’Œsoftmaxçš„ä½œä¸šå†…å®¹ä¸€æ ·ï¼Œå°†æ‰€æœ‰çš„scores expï¼Œæ±‚å çš„ç™¾åˆ†æ¯”ï¼Œæ±‚å‡ºæ¥çš„éƒ¨åˆ†-logï¼Œç„¶åŽæŠŠæ‰€æœ‰çš„æ±‚å’Œ è¿™é‡Œç”¨åˆ°äº†boardcastingçš„é—®é¢˜ï¼Œæ³¨æ„ï¼ˆ100ï¼Œ1ï¼‰è¿™æ ·çš„æ‰å¯ä»¥boardcastingï¼Œï¼ˆ100ï¼Œï¼‰çš„æ˜¯ä¸€ç»´æ•°ç»„ï¼Œéœ€è¦æŠŠå®ƒreshapeæˆå‰é¢çš„æ ·å­æ‰å¯ä»¥ è¿™é‡Œæœ€åŽçš„ç»“æžœè¿˜æ€»æ˜¯å·®ä¸€ç‚¹ï¼Œæœ€åŽå‘çŽ°æ˜¯å› ä¸ºregularzationçš„æ—¶å€™å¤šä¹˜äº†0.5ï¼Œçœ‹é¢˜å‘œå‘œå‘œ Backward pass ç”±äºŽbæ˜¯çº¿æ€§æ¨¡åž‹çš„biasï¼Œåå¯¼æ•°æ˜¯1ï¼Œç›´æŽ¥å¯¹classçš„å†…å®¹æ±‚å’Œç„¶åŽé™¤ä»¥Nå°±æ˜¯æœ€ç»ˆç»“æžœ å¯¹Wæ±‚å¯¼çš„æ—¶å€™éœ€è¦ç”¨åˆ°é“¾å¼æ³•åˆ™ï¼Œç„¶åŽç›´æŽ¥ä»£ç å®žçŽ°ä¸€ä¸‹å°±è¡Œäº† è¿™é‡Œé‡åˆ°çš„ä¸»è¦é—®é¢˜æ˜¯lossçš„å€¼ä¼šå½±å“ä»–ä¼°è®¡çš„å€¼ï¼Œå› ä¸ºlossçš„regularzationæ”¹äº†ï¼Œæ‰€ä»¥ç­”æ¡ˆä¸€ç›´å¯¹ä¸ä¸Šã€‚ Training predict è®­ç»ƒå’Œä¹‹å‰å†™çš„å·®ä¸å¤šï¼Œè®­ç»ƒç½‘ç»œï¼Œä¸»è¦åŒ…æ‹¬å†™trainingéƒ¨åˆ†çš„éšæœºmini-batchå’Œæ›´æ–°weightsï¼Œè®°å¾—lræ›´æ–°çš„æ—¶å€™è¦å¸¦è´Ÿå· é¢„æµ‹ä¹Ÿå·®ä¸å¤šï¼Œç®—å‡ºæ¥scoresï¼Œæ‰¾åˆ°æœ€å¤§çš„scoreå°±æ˜¯åˆ†ç±»çš„ç»“æžœã€‚æ³¨æ„æ‰¾æœ€å¤§çš„æ—¶å€™è¦ç”¨argmaxï¼Œæ‰¾åˆ°çš„æ˜¯æœ€å¤§çš„ä¸œè¥¿çš„indiceï¼Œä¸ç„¶å¾—åˆ°çš„æ˜¯å¾—åˆ†12345678910111213net = init_toy_model()stats = net.train(X, y, X, y, learning_rate=1e-1, reg=5e-6, num_iters=100, verbose=False)print('Final training loss: ', stats['loss_history'][-1])# plot the loss historyplt.plot(stats['loss_history'])plt.xlabel('iteration')plt.ylabel('training loss')plt.title('Training Loss history')plt.show() ä½¿ç”¨å†™å¥½çš„æ¥è®­ç»ƒCIFAR-101234567891011121314input_size = 32 * 32 * 3hidden_size = 50num_classes = 10net = TwoLayerNet(input_size, hidden_size, num_classes)# Train the networkstats = net.train(X_train, y_train, X_val, y_val, num_iters=1000, batch_size=200, learning_rate=1e-4, learning_rate_decay=0.95, reg=0.25, verbose=True)# Predict on the validation setval_acc = (net.predict(X_val) == y_val).mean()print('Validation accuracy: ', val_acc) è¿™æ—¶å€™å¾—åˆ°çš„å‡†ç¡®åº¦åº”è¯¥åœ¨28%å·¦å³ï¼Œå¯ä»¥ä¼˜åŒ– è¿›ä¸€æ­¥ä¼˜åŒ– ä¸€ç§å¯è§†åŒ–çš„æ–¹æ³•æ˜¯å¯è§†åŒ–loss functionå’Œå‡†ç¡®çŽ‡çš„å…³ç³»ï¼Œåˆ†åˆ«åœ¨è®­ç»ƒå’Œvalé›†ä¸Šé¢ å¦ç§æ˜¯å¯è§†åŒ–ç¬¬ä¸€å±‚çš„weights ä¸¤ç§æ–¹æ³•çš„ç»“æžœå¦‚ä¸‹ï¼š debugæ¨¡åž‹ é—®é¢˜ losså¤§ä½“ä¸Šéƒ½æ˜¯linearlyçš„ä¸‹é™çš„ï¼Œè¯´æ˜Žlrå¯èƒ½å¤ªä½Žäº† åœ¨trainingå’Œvalçš„å‡†ç¡®çŽ‡ä¸Šæ²¡æœ‰gapï¼Œè¯´æ˜Žmodelçš„å®¹é‡å¤ªå°çš„ï¼Œéœ€è¦å¢žå¤§size å¦‚æžœå®¹é‡è¿‡å¤§è¿˜ä¼šå¯¼è‡´overfiitingï¼Œè¿™æ—¶å€™gapå°±ä¼šå¾ˆå¤§ tuning hypers é¢˜ç›®é‡Œé¢çš„å»ºè®®æ˜¯tuningå‡ ä¸ªhyperï¼Œè¿˜æ˜¯å’Œä¹‹å‰ä¸€æ ·ï¼Œç›´æŽ¥randomï¼Œsearch è¿™é‡Œé€‰äº†ä¸‰ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯unitsçš„æ•°é‡ï¼Œlearning rateå’Œregçš„å¼ºåº¦ï¼Œéšä¾¿è®¾ç½®äº†ä¸€ä¸‹ç•Œé™ æœ€ç»ˆè®¡ç®—å‡ºæ¥çš„valå‡†ç¡®çŽ‡æ˜¯ï¼š49.5% ç§€ç§€ç§€ï¼ï¼ å¯è§†åŒ–weighä¹‹åŽçš„ç»“æžœæ˜¯ éœ‡æƒŠï¼Œå±…ç„¶æœ€åŽçš„æµ‹è¯•æ­£ç¡®çŽ‡ä¹Ÿè¾¾åˆ°äº†49.4ï¼ï¼ï¼ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051best_net = None # store the best model into this ################################################################################## TODO: Tune hyperparameters using the validation set. Store your best trained ## model in best_net. ## ## To help debug your network, it may help to use visualizations similar to the ## ones we used above; these visualizations will have significant qualitative ## differences from the ones we saw above for the poorly tuned network. ## ## Tweaking hyperparameters by hand can be fun, but you might find it useful to ## write code to sweep through possible combinations of hyperparameters ## automatically like we did on the previous exercises. ##################################################################################best_acc = -1learning_rates = [1e-3, 1e-2]regularization_strengths = [1e-2, 6e-1]hidden_size = [50, 150]random_search = np.random.rand(30, 3)random_search[:, 0] = random_search[:, 0] * \ (learning_rates[1] - learning_rates[0]) + learning_rates[0]random_search[:, 1] = random_search[:, 1] * \ (regularization_strengths[1] - regularization_strengths[0] ) + regularization_strengths[0]random_search[:, 2] = random_search[:, 2] * \ (hidden_size[1] - hidden_size[0]) + hidden_size[0]for lr, rs, hidd in random_search: input_size = 32 * 32 * 3 hidden = int(hidd) num_class = 10 net = TwoLayerNet(input_size, hidden, num_class) status = net.train(X_train, y_train, X_val, y_val, num_iters=1000, batch_size=200, learning_rate=lr, learning_rate_decay=0.95, reg=rs, verbose=True) val_acc = (net.predict(X_val) == y_val).mean() if val_acc &gt; best_acc: best_acc = val_acc best_net = netprint("best net is with val acc", best_acc)################################################################################## END OF YOUR CODE ################################################################################## ä»£ç éƒ¨åˆ†nerual_net.pyéƒ¨åˆ†çš„å®Œæ•´ä»£ç å¦‚ä¸‹ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289from __future__ import print_functionimport numpy as npimport matplotlib.pyplot as pltclass TwoLayerNet(object): """ A two-layer fully-connected neural network. The net has an input dimension of N, a hidden layer dimension of H, and performs classification over C classes. We train the network with a softmax loss function and L2 regularization on the weight matrices. The network uses a ReLU nonlinearity after the first fully connected layer. In other words, the network has the following architecture: input - fully connected layer - ReLU - fully connected layer - softmax The outputs of the second fully-connected layer are the scores for each class. """ def __init__(self, input_size, hidden_size, output_size, std=1e-4): """ Initialize the model. Weights are initialized to small random values and biases are initialized to zero. Weights and biases are stored in the variable self.params, which is a dictionary with the following keys: W1: First layer weights; has shape (D, H) b1: First layer biases; has shape (H,) W2: Second layer weights; has shape (H, C) b2: Second layer biases; has shape (C,) Inputs: - input_size: The dimension D of the input data. - hidden_size: The number of neurons H in the hidden layer. - output_size: The number of classes C. """ self.params = &#123;&#125; self.params['W1'] = std * np.random.randn(input_size, hidden_size) self.params['b1'] = np.zeros(hidden_size) self.params['W2'] = std * np.random.randn(hidden_size, output_size) self.params['b2'] = np.zeros(output_size) def loss(self, X, y=None, reg=0.0): """ Compute the loss and gradients for a two layer fully connected neural network. Inputs: - X: Input data of shape (N, D). Each X[i] is a training sample. - y: Vector of training labels. y[i] is the label for X[i], and each y[i] is an integer in the range 0 &lt;= y[i] &lt; C. This parameter is optional; if it is not passed then we only return scores, and if it is passed then we instead return the loss and gradients. - reg: Regularization strength. Returns: If y is None, return a matrix scores of shape (N, C) where scores[i, c] is the score for class c on input X[i]. If y is not None, instead return a tuple of: - loss: Loss (data loss and regularization loss) for this batch of training samples. - grads: Dictionary mapping parameter names to gradients of those parameters with respect to the loss function; has the same keys as self.params. """ # Unpack variables from the params dictionary W1, b1 = self.params['W1'], self.params['b1'] W2, b2 = self.params['W2'], self.params['b2'] N, D = X.shape # Compute the forward pass scores = None ############################################################################# # TODO: Perform the forward pass, computing the class scores for the input. # # Store the result in the scores variable, which should be an array of # # shape (N, C). # ############################################################################# # first layer, shape(N,H) X1 = X.dot(W1) + b1 # è¿™é‡ŒåŠ äº†ä¸€ä¸ªç¬¬ä¸€å±‚ä¹‹åŽçš„reluæ¿€æ´» relu = np.maximum(0, X1) # final result, shape(N,C) scores = relu.dot(W2) + b2 ############################################################################# # END OF YOUR CODE # ############################################################################# # If the targets are not given then jump out, we're done if y is None: return scores # Compute the loss loss = None ############################################################################# # TODO: Finish the forward pass, and compute the loss. This should include # # both the data loss and L2 regularization for W1 and W2. Store the result # # in the variable loss, which should be a scalar. Use the Softmax # # classifier loss. # ############################################################################# num_train = N scores = scores - np.reshape(np.max(scores, axis=1), (num_train, -1)) scores = np.exp(scores) scores_sum = np.sum(scores, axis=1).reshape(N, 1) # scores_sum = np.sum(scores, axis=1, keepdims=True) p = scores / scores_sum loss = np.sum(-np.log(p[np.arange(N), y])) loss /= num_train # è¿™é‡Œä¸è¦ä¹˜0.5çš„ç³»æ•° # loss += reg * np.sum(W1 * W1) + reg * np.sum(W2 * W2) loss += 0.5 * reg * np.sum(W1 * W1) + 0.5 * reg * np.sum(W2 * W2) # ############################################################################# # # END OF YOUR CODE # # ############################################################################# # # Backward pass: compute gradients grads = &#123;&#125; # ############################################################################# # # TODO: Compute the backward pass, computing the derivatives of the weights # # # and biases. Store the results in the grads dictionary. For example, # # # grads['W1'] should store the gradient on W1, and be a matrix of same size # # ############################################################################# dscores = p dscores[range(N), y] -= 1.0 # dscores /= N # shape dW2(CxN) x(NxH) -&gt; (CxH) # dW2 = np.dot(relu.T, p) dW2 = np.dot(relu.T, dscores) # print(dW2) # æ¯ä¸ªclassä¼šæœ‰ä¸€ä¸ªbï¼Œå¯¹bæ±‚å¯¼æ˜¯1 # shape db2 (C,) db2 = np.sum(p, axis=0) # (NxC) x (HxC).T -&gt; (N,H) dW_relu = np.dot(dscores, W2.T) dW_relu[relu &lt;= 0] = 0 # (NxD).T x (N,H) -&gt; (D,H) dW1 = (X.T).dot(dW_relu) db1 = np.sum(dW_relu, axis=0) dW2 /= N dW1 /= N dW2 += reg * W2 dW1 += reg * W1 db1 /= N db2 /= N grads['W1'] = dW1 grads['b1'] = db1 grads['W2'] = dW2 grads['b2'] = db2 ############################################################################# # END OF YOUR CODE # ############################################################################# return loss, grads def train(self, X, y, X_val, y_val, learning_rate=1e-3, learning_rate_decay=0.95, reg=5e-6, num_iters=100, batch_size=200, verbose=False): """ Train this neural network using stochastic gradient descent. Inputs: - X: A numpy array of shape (N, D) giving training data. - y: A numpy array f shape (N,) giving training labels; y[i] = c means that X[i] has label c, where 0 &lt;= c &lt; C. - X_val: A numpy array of shape (N_val, D) giving validation data. - y_val: A numpy array of shape (N_val,) giving validation labels. - learning_rate: Scalar giving learning rate for optimization. - learning_rate_decay: Scalar giving factor used to decay the learning rate after each epoch. - reg: Scalar giving regularization strength. - num_iters: Number of steps to take when optimizing. - batch_size: Number of training examples to use per step. - verbose: boolean; if true print progress during optimization. """ num_train = X.shape[0] iterations_per_epoch = max(num_train / batch_size, 1) # Use SGD to optimize the parameters in self.model loss_history = [] train_acc_history = [] val_acc_history = [] for it in range(num_iters): X_batch = None y_batch = None ######################################################################### # TODO: Create a random minibatch of training data and labels, storing # # them in X_batch and y_batch respectively. # ######################################################################### rand_mini = np.random.choice(num_train, batch_size, replace=True) X_batch = X[rand_mini] y_batch = y[rand_mini] ######################################################################### # END OF YOUR CODE # ######################################################################### # Compute loss and gradients using the current minibatch loss, grads = self.loss(X_batch, y=y_batch, reg=reg) loss_history.append(loss) ######################################################################### # TODO: Use the gradients in the grads dictionary to update the # # parameters of the network (stored in the dictionary self.params) # # using stochastic gradient descent. You'll need to use the gradients # # stored in the grads dictionary defined above. # ######################################################################### self.params['W1'] -= learning_rate * grads['W1'] self.params['W2'] -= learning_rate * grads['W2'] self.params['b1'] -= learning_rate * grads['b1'] self.params['b2'] -= learning_rate * grads['b2'] ######################################################################### # END OF YOUR CODE # ######################################################################### if verbose and it % 100 == 0: print('iteration %d / %d: loss %f' % (it, num_iters, loss)) # Every epoch, check train and val accuracy and decay learning rate. if it % iterations_per_epoch == 0: # Check accuracy train_acc = (self.predict(X_batch) == y_batch).mean() val_acc = (self.predict(X_val) == y_val).mean() train_acc_history.append(train_acc) val_acc_history.append(val_acc) # Decay learning rate learning_rate *= learning_rate_decay return &#123; 'loss_history': loss_history, 'train_acc_history': train_acc_history, 'val_acc_history': val_acc_history, &#125; def predict(self, X): """ Use the trained weights of this two-layer network to predict labels for data points. For each data point we predict scores for each of the C classes, and assign each data point to the class with the highest score. Inputs: - X: A numpy array of shape (N, D) giving N D-dimensional data points to classify. Returns: - y_pred: A numpy array of shape (N,) giving predicted labels for each of the elements of X. For all i, y_pred[i] = c means that X[i] is predicted to have class c, where 0 &lt;= c &lt; C. """ y_pred = None ########################################################################### # TODO: Implement this function; it should be VERY simple! # ########################################################################### W1 = self.params['W1'] W2 = self.params['W2'] b1 = self.params['b1'] b2 = self.params['b2'] scores = X.dot(W1) + b1 scores[scores &lt; 0] = 0.0 scores = scores.dot(W2) + b2 y_pred = np.argmax(scores, axis=1) ########################################################################### # END OF YOUR CODE # ########################################################################### return y_pred]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
        <category>CS231nä½œä¸š</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽNormalizationçš„æ–¹æ³•ä»¥åŠå®žçŽ°]]></title>
    <url>%2F2019%2F04%2F01%2FNormalize%2F</url>
    <content type="text"><![CDATA[åœ¨å¤„ç†æ•°æ®çš„æ—¶å€™ï¼Œå› ä¸ºæ•°æ®çš„å¤§å°å·®åˆ«ä¼šæ¯”è¾ƒå¤§ï¼Œä¸ºäº†é¿å…æ•°æ®çš„ç‰¹å¾è¢«å…¶ä»–ç‰¹å¾åƒæŽ‰ï¼Œéœ€è¦å¯¹æ•°æ®è¿›è¡Œnormalizationçš„å¤„ç† (0,1) æ ‡å‡†åŒ–æ‰¾åˆ°æœ€å¤§å€¼å’Œæœ€å°å€¼ï¼Œä»¥æœ€å¤§å€¼ä¸º1ï¼Œæœ€å°å€¼ä¸º0ï¼Œè®¡ç®—å…¶ä»–æ•°æ®åœ¨0åˆ°1ä¹‹é—´çš„åˆ†å¸ƒã€‚ 12def normal0_1(x,Max,Min): return (x-Min)/(Max-Min) ä½¿ç”¨np.max()ï¼Œnp.minæ¥æ‰¾æœ€å¤§å€¼å’Œæœ€å°å€¼ æ­£æ€åˆ†å¸ƒè¾“å…¥åŽŸå§‹æ•°æ®çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œå¯¹æ•°æ®å¤„ç†ï¼Œå¤„ç†ä¹‹åŽçš„æ•°æ®æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼ˆå‡å€¼æ˜¯0ï¼Œæ ‡å‡†å·®æ˜¯1ï¼‰ 12def Normalization(x, mu, sigma): return (x-mu) / sigma ä½¿ç”¨np.average()å’Œnp.std()æ‰¾åˆ°å‡å€¼å’Œæ ‡å‡†å·® Sigmoidå‡½æ•°sigmoidå‡½æ•°å…³äºŽï¼ˆ0ï¼Œ 0.5ï¼‰ä¸­å¿ƒå¯¹ç§°ï¼Œåœ¨ä¸­å¿ƒé™„è¿‘æ–œçŽ‡è¾ƒå¤§ï¼Œåœ¨è´Ÿæ— ç©·æŽ¥è¿‘0ï¼Œæ­£æ— ç©·æŽ¥è¿‘1 12def sigmood(x): return 1.0/(1+np.exp(-float(x)))]]></content>
      <categories>
        <category>æ•°å­¦é—®é¢˜</category>
      </categories>
      <tags>
        <tag>Normalize</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231Nä½œä¸šassignment1ä¹‹softmax]]></title>
    <url>%2F2019%2F04%2F01%2FCS231Nassignment1softmax%2F</url>
    <content type="text"><![CDATA[Softmaxè¿™éƒ¨åˆ†ä¸»è¦æ˜¯softmaxçš„lossè¦å¦‚ä½•è®¡ç®—Assignment From: Assignment1 ç›®æ ‡ implement a fully-vectorized loss function for the Softmax classifier implement the fully-vectorized expression for its analytic gradient check your implementation with numerical gradient use a validation set to tune the learning rate and regularization strength optimize the loss function with SGD visualize the final learned weights é¢„å¤„ç†ï¼ˆå’Œä¹‹å‰ä¸€æ ·ï¼ˆ è½½å…¥æ•°æ® åˆå§‹åŒ–æ•°æ® æ‹‰é•¿ normalize åˆ†æˆè®­ç»ƒé›†æµ‹è¯•é›†validationç­‰ç­‰ softmax classifiernaive_softmax_lossä¸­å¿ƒæ€æƒ³ï¼šæŠŠå¾—åˆ°çš„scoreï¼ˆWx + bï¼‰å…ˆexpï¼Œç„¶åŽnormalizeï¼Œæœ€åŽæ±‚-log è¾“å…¥ï¼š Wï¼šå¤§å°(D,C)ï¼Œweights Xï¼šå¤§å°(N,D)ï¼Œè¾“å…¥çš„mini-batch yï¼šå¤§å°(N,)ï¼Œæ ‡ç­¾ regï¼šregularizationçš„ç³»æ•° è¾“å‡ºï¼š loss dWï¼Œå³æ”¹å˜çš„gradient è®¡ç®—loss å…ˆå°†æ‰€æœ‰çš„scoresåšexpï¼ˆè¿™ä¸€æ­¥å¯ä»¥å…ˆè¿›è¡Œï¼‰ï¼Œè¿™æ ·æ‰€æœ‰çš„scoreéƒ½ä¼šå˜æˆæ­£æ•° ç„¶åŽå¯¹ä¸åŒclassçš„scoreåˆ†åˆ«æ±‚normalizeï¼ˆè™½ç„¶è¯´æ˜¯normalizeï¼Œå®žé™…æ±‚çš„æ˜¯è¿™ä¸ªç§ç±»çš„scoreåœ¨æ‰€æœ‰çš„scoreé‡Œé¢æ‰€å çš„æ¯”ä¾‹ï¼‰ ç„¶åŽå°†æ­£ç¡®çš„ç±»åž‹æ‰€å çš„æ¯”ä¾‹æ±‚logï¼Œå†æ±‚è´Ÿå·ï¼Œå¾—å‡ºæ¥çš„å°±æ˜¯æ¯ä¸ªå›¾ç‰‡çš„lossï¼ˆè¿™é‡Œæ³¨æ„0çš„logæ˜¯æ— ç©·ï¼Œè®¡ç®—ä¸å‡ºæ¥ï¼‰ æ‰€æœ‰å›¾ç‰‡çš„lossæ±‚å’Œï¼Œç„¶åŽé™¤ä»¥å›¾ç‰‡æ€»æ•°ï¼Œregularzationï¼Œå¾—å‡ºæ¥çš„å°±æ˜¯æœ€ç»ˆçš„ç»“æžœ è®¡ç®—dW å¯ä»¥è¿™æ ·ç†è§£ Wæ˜¯ä¸€ä¸ªå‚æ•°çŸ©é˜µï¼Œè¿™ä¸ªçŸ©é˜µçš„å˜åŒ–ç”±ä¸¤ä¸ªéƒ¨åˆ†ç»„æˆ ç¬¬ä¸€éƒ¨åˆ†æ˜¯å¾€ä»€ä¹ˆæ–¹å‘å˜ï¼Œè¿™ä¸ªå–å†³äºŽæœ€åŽç®—å‡ºæ¥çš„lossçš„åˆ†å¸ƒ ç¬¬äºŒéƒ¨åˆ†æ˜¯å˜å¤šå°‘åˆé€‚ï¼Œè¿™æ—¶å€™è¿˜éœ€è¦ä¹˜ä¸€ä¸ªç³»æ•°X[i] æ‰€ä»¥å½“ç®—å‡ºæ¥losså¹¶ä¸”y[i] = jçš„æ—¶å€™ï¼Œå®žé™…ä¸Šå°±æ˜¯è¿™å¼ å›¾æ­£ç¡®åˆ†ç±»æƒ…å†µä¸‹çš„é”™è¯¯åˆ†ç±»çš„æ¦‚çŽ‡ï¼Œæ‰€ä»¥Wçš„æ”¹å˜æ–¹å‘åº”è¯¥æ˜¯è¿™ä¸ªçš„åæ–¹å‘ è¿™å¼ å›¾çš„å…¶ä»–classçš„lossåˆ™åº”è¯¥æ˜¯æ”¹å˜çš„æ–¹å‘ è¿™æ ·å°±å¯ä»¥çœ‹å‡ºæ¥ SVMå’Œsoftmaxçš„ä¸åŒä¹‹å¤„äº† å¯¹äºŽSVMæ¥è¯´ï¼Œä»…ä»…é€šè¿‡ä¸Ž0æ¯”å¤§å°å¾—å‡ºä¸€ä¸ªå€¼ï¼Œç›¸å½“äºŽä¸€ä¸ª0ï¼Œ1çš„å¼€å…³ï¼Œåªèƒ½æ ¹æ®ç»“æžœå¾—åˆ°ä¸€ä¸ªç§»åŠ¨çš„æ–¹å‘ ä½†æ˜¯å¯¹äºŽsoftmaxæ¥è¯´ï¼Œä¸ä»…å¾—åˆ°äº†æ–¹å‘ï¼Œè¿˜å¾—åˆ°äº†è¿™ä¸ªæ–¹å‘çš„å æ¯”ï¼Œæ‰€ä»¥lossè¶Šå¤§çš„æ•°å½±å“å°±ä¼šè¶Šå¤§ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657def svm_loss_naive(W, X, y, reg): """ Structured SVM loss function, naive implementation (with loops). Inputs have dimension D, there are C classes, and we operate on minibatches of N examples. Inputs: - W: A numpy array of shape (D, C) containing weights. - X: A numpy array of shape (N, D) containing a minibatch of data. - y: A numpy array of shape (N,) containing training labels; y[i] = c means that X[i] has label c, where 0 &lt;= c &lt; C. - reg: (float) regularization strength Returns a tuple of: - loss as single float - gradient with respect to weights W; an array of same shape as W """ dW = np.zeros(W.shape) # initialize the gradient as zero # compute the loss and the gradient num_classes = W.shape[1] # æœ‰å¤šå°‘éœ€è¦è®­ç»ƒçš„ä¸ªæ•° num_train = X.shape[0] loss = 0.0 for i in range(num_train): scores = X[i].dot(W) correct_class_score = scores[y[i]] for j in range(num_classes): # å¦‚æžœè¿™ä¸ªç±»åž‹æ˜¯æ­£ç¡®çš„ï¼Œé‚£å°±ä¸ç”¨ç®¡äº† if j == y[i]: continue margin = scores[j] - correct_class_score + 1 # note delta = 1 if margin &gt; 0: loss += margin dW[:, y[i]] += -X[i] dW[:, j] += X[i] # Right now the loss is a sum over all training examples, but we want it # to be an average instead so we divide by num_train. loss /= num_train dW /= num_train # Add regularization to the loss. # regæ˜¯lanbda loss += reg * np.sum(W * W) dW += 2 * reg * W ############################################################################# # TODO: # # Compute the gradient of the loss function and store it dW. # # Rather that first computing the loss and then computing the derivative, # # it may be simpler to compute the derivative at the same time that the # # loss is being computed. As a result you may need to modify some of the # # code above to compute the gradient. # ############################################################################# return loss, dW softmax_loss_vectorizedæé«˜è®¡ç®—é€Ÿåº¦ è·Ÿsvméƒ¨åˆ†çš„è®¡ç®—æ€è·¯ä¸€æ ·ï¼Œç›´æŽ¥ä½¿ç”¨çŸ©é˜µè¿ç®— åœ¨æ±‚æ•´ä¸ªscoreçŸ©é˜µçš„å˜åŒ–çš„æ—¶å€™ï¼Œæ­£ç¡®åˆ†ç±»çš„lossåº”è¯¥è¢«å‡æŽ‰ï¼Œä½†æ˜¯çŽ°åœ¨æ˜¯è¢«åŠ ä¸Šçš„ï¼Œæ‰€ä»¥éœ€è¦åœ¨æ­£ç¡®åˆ†ç±»çš„åœ°æ–¹åŠ ä¸€ä¸ª-1 debugäº†å¾ˆä¹…çš„åœ°æ–¹æ˜¯ï¼šè®¡ç®—dWçš„æ—¶å€™ä¸éœ€è¦è®¡ç®—logï¼Œå› ä¸ºæ²¡æœ‰logä¹‹å‰å·²ç»æ˜¯è¿™ä¸ªlossæ‰€å çš„ç™¾åˆ†æ¯”äº†ï¼šæ±‚logæ˜¯ä¸ºäº†å˜æˆå‡¸å‡½æ•°ï¼Œlossæ²¡æœ‰æ±‚logä¹‹å‰å¹¶ä¸æ˜¯å‡¸å‡½æ•°ï¼Œä½†æ˜¯å‡¸å‡½æ•°å®¹æ˜“æ‰¾åˆ°æœ€å€¼çš„ä¼˜åŒ–é—®é—®é¢˜ï¼Œæ‰€ä»¥è¦æ±‚logã€‚ä½†æ˜¯åœ¨è®¡ç®—dWçš„æ—¶å€™å’Œlogæ²¡å…³ç³» 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def softmax_loss_vectorized(W, X, y, reg): """ Softmax loss function, vectorized version. Inputs and outputs are the same as softmax_loss_naive. """ # Initialize the loss and gradient to zero. loss = 0.0 dW = np.zeros_like(W) num_class = W.shape[1] num_train = X.shape[0] ############################################################################# # TODO: Compute the softmax loss and its gradient using no explicit loops. # # Store the loss in loss and the gradient in dW. If you are not careful # # here, it is easy to run into numeric instability. Don't forget the # # regularization! # ############################################################################# # sizeï¼ˆNï¼ŒCï¼‰ scores = X.dot(W) scores = np.exp(scores) # å¯¹æ¯è¡Œæ±‚å’Œ scores_sum = np.sum(scores, axis=1) scores_sum = np.repeat(scores_sum, num_class) scores_sum = scores_sum.reshape(num_train, num_class) # true_divideè¿”å›žæµ®ç‚¹æ•°ï¼Œæ™®é€šçš„è¿”å›žæ­£æ•°ï¼Œsizeï¼ˆNï¼ŒCï¼‰ percent = np.true_divide(scores, scores_sum) # åªæœ‰æ­£ç¡®ç§ç±»éœ€è¦æ±‚loss Li = -np.log(percent[np.arange(num_train), y]) loss = np.sum(Li) # æ³¨æ„è¿™é‡Œä¸éœ€è¦æ±‚log dS = percent.copy() dS[np.arange(num_train), y] += -1 dW = (X.T).dot(dS) loss /= num_train loss += reg * np.sum(W * W) dW /= num_train dW += reg * W ############################################################################# # END OF YOUR CODE # ############################################################################# return loss, dW éªŒè¯ï¼Œé€‰hyperå’ŒSVMçš„éƒ¨åˆ†ä¸€æ ·ï¼Œéšæœºæœç´¢hyperï¼ŒéªŒè¯ç»“æžœï¼Œè®­ç»ƒè¿­ä»£500æ¬¡ï¼Œæœ€ç»ˆçš„å‡†ç¡®çŽ‡åœ¨36%å·¦å³1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# Use the validation set to tune hyperparameters (regularization strength and# learning rate). You should experiment with different ranges for the learning# rates and regularization strengths; if you are careful you should be able to# get a classification accuracy of over 0.35 on the validation set.from cs231n.classifiers import Softmaxresults = &#123;&#125;best_val = -1best_softmax = Nonelearning_rates = [1e-7, 5e-7]regularization_strengths = [2.5e4, 5e4]################################################################################# TODO: ## Use the validation set to set the learning rate and regularization strength. ## This should be identical to the validation that you did for the SVM; save ## the best trained softmax classifer in best_softmax. #################################################################################hyper_values = np.random.rand(50,2)hyper_values[:,0] = (learning_rates[1] - learning_rates[0]) * hyper_values[:,0] + learning_rates[0]hyper_values[:,1] = (regularization_strengths[1] - regularization_strengths[0]) * hyper_values[:,1] + regularization_strengths[0]for lr, rs in hyper_values: softmax = Softmax() softmax.train(X_train,y_train,lr,rs,num_iters = 500,verbose = True) train_pred = softmax.predict(X_train) train_acc = np.mean(y_train == train_pred) val_pred = softmax.predict(X_val) val_acc = np.mean(y_val == val_pred) results[(lr,rs)] = (train_acc,val_acc) if val_acc &gt; best_val: best_val = val_acc best_softmax = softmax################################################################################# END OF YOUR CODE ################################################################################# # Print out results.for lr, reg in sorted(results): train_accuracy, val_accuracy = results[(lr, reg)] print('lr %e reg %e train accuracy: %f val accuracy: %f' % ( lr, reg, train_accuracy, val_accuracy)) print('best validation accuracy achieved during cross-validation: %f' % best_val) å¯ä»¥çœ‹å‡ºæ¥æ„Ÿè§‰softmaxæ¯”SVMçš„æ•ˆæžœå¥½ä¸€äº›ï¼Ÿå¯è§†åŒ–æœ€ç»ˆçš„ä¼˜åŒ–çš„weight123456789101112131415# Visualize the learned weights for each classw = best_softmax.W[:-1,:] # strip out the biasw = w.reshape(32, 32, 3, 10)w_min, w_max = np.min(w), np.max(w)classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']for i in range(10): plt.subplot(2, 5, i + 1) # Rescale the weights to be between 0 and 255 wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min) plt.imshow(wimg.astype('uint8')) plt.axis('off') plt.title(classes[i])]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
        <category>CS231nä½œä¸š</category>
      </categories>
      <tags>
        <tag>Softmax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽæ ‡é‡ï¼Œå‘é‡ï¼ŒçŸ©é˜µæ±‚å¯¼]]></title>
    <url>%2F2019%2F03%2F30%2F%E5%85%B3%E4%BA%8E%E6%A0%87%E9%87%8F%E5%90%91%E9%87%8F%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[å‚è€ƒæ–‡ç« ï¼šhttps://blog.csdn.net/u010976453/article/details/54381248 å…³äºŽlayoutåœ¨æ±‚å¯¼çš„æ—¶å€™æœ‰ï¼Œå› ä¸ºåˆ†å­å’Œåˆ†æ¯å¯èƒ½çš„ç»´åº¦ä¸å¤ªä¸€æ ·ï¼Œæ‰€ä»¥ä¸¤ç§ä¸åŒçš„å¸ƒå±€ï¼Œåˆ†åˆ«æ˜¯åˆ†å­å¸ƒå±€å’Œåˆ†æ¯å¸ƒå±€å‡è®¾yï¼ˆå‘é‡ï¼‰å¯¹xï¼ˆæ ‡é‡ï¼‰æ±‚å¯¼ï¼š åˆ†å­å¸ƒå±€ï¼Œå³å’ŒåŽŸæ¥çš„yç›¸åŒ åˆ†æ¯å¸ƒå±€ï¼Œä¸ºåˆ†å­å¸ƒå±€çš„tranpose å¯¹æ ‡é‡çš„å¯¼æ•°scalarå¯¹scalaræ±‚å¯¼å³æœ€ç®€å•çš„æ±‚å¯¼ vectorå¯¹scalaræ±‚å¯¼æ¯”å¦‚ä¸€ä¸ªåˆ—å‘é‡yï¼Œå¯¹xæ±‚å¯¼ï¼Œç»“æžœæ˜¯yé‡Œé¢çš„æ¯ä¸ªå€¼éƒ½å¯¹xæ±‚å¯¼ matrixå¯¹scalræ±‚å¯¼çŸ©é˜µé‡Œé¢çš„æ¯ä¸ªå€¼éƒ½å¯¹xæ±‚å¯¼ å¯¹å‘é‡çš„å¯¼æ•°scalarå¯¹vector æ ‡é‡yå’Œå‘é‡xï¼Œæ±‚å‡ºæ¥çš„ç»“æžœæ˜¯yå¯¹æ¯ä¸ªx(x1,x2 â€¦.xn)æ±‚å¯¼ ç»“æžœä¸ºæ¢¯åº¦å‘é‡ï¼Œæ˜¯æ ‡é‡yåœ¨ç©ºé—´Rnçš„æ¢¯åº¦ï¼Œç©ºé—´ä»¥xä¸ºåŸº æ³¨æ„ï¼Œxæ˜¯åˆ—å‘é‡çš„è¯ï¼Œæœ€åŽæ±‚å‡ºæ¥çš„æ˜¯è¡Œçš„ç»“æžœ vectorå¯¹vectory = [y1,y2 â€¦. ym]x = [x1,x2 â€¦. xn]æœ€åŽæ±‚å‡ºæ¥çš„ç»“æžœæ˜¯ä¸€ä¸ªmè¡Œnåˆ—çš„çŸ©é˜µï¼ŒjacobiançŸ©é˜µ matrixå¯¹vectorçŸ©é˜µy =[[y11,y12â€¦y1n],[y21,y22 â€¦y2n],â€¦[yn1,yn2 â€¦ynn]]å‘é‡x = [x1,x2â€¦xn]Tæœ€ç»ˆçš„ç»“æžœæ˜¯æ¯ä¸€è¡Œåˆ†åˆ«å¯¹è¿™ä¸ªxçš„å‘é‡æ±‚å¯¼ï¼Œæ‰€ä»¥çŸ©é˜µçš„åˆ—æ•°å’Œå‘é‡çš„è¡Œæ•°åº”è¯¥å…ˆé€š å¯¹äºŽçŸ©é˜µä¸€èˆ¬åªè€ƒè™‘æ ‡é‡å¯¹çŸ©é˜µ(å‰©ä¸‹çš„æƒ…å†µå’Œä¸Šé¢ç±»ä¼¼)æœ€ç»ˆç»“æžœæ˜¯è¿™ä¸ªæ ‡é‡å¯¹æ‰€æœ‰çš„çŸ©é˜µå†…å®¹æ±‚å¯¼ï¼Œæ±‚å‡ºæ¥çš„æ˜¯æ¢¯åº¦çŸ©é˜µ]]></content>
      <categories>
        <category>æ•°å­¦é—®é¢˜</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CS231Nä½œä¸šassignment1ä¹‹SVMéƒ¨åˆ†]]></title>
    <url>%2F2019%2F03%2F29%2FCS231Nassignment1SVM%2F</url>
    <content type="text"><![CDATA[Assignment from: http: // cs231n.github.io / assignments2018 / assignment1/ ç›®æ ‡ï¼š a fully - vectorized loss function for the SVM fully - vectorized expression for its analytic gradient use a validation set to tune the learning rate and regularization strength optimize the loss function with SGD visualize the final learned weights Set upéƒ¨åˆ†1234567891011121314151617181920# Run some setup code for this notebook.from __future__ import print_functionimport randomimport numpy as npfrom cs231n.data_utils import load_CIFAR10import matplotlib.pyplot as plt# This is a bit of magic to make matplotlib figures appear inline in the# notebook rather than in a new window.%matplotlib inlineplt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'# Some more magic so that the notebook will reload external python modules;# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython%load_ext autoreload%autoreload 2 è¯»å–CIFAR-10çš„æ•°æ®ï¼Œé¢„å¤„ç†123456789101112131415161718# Load the raw CIFAR-10 data.cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)try: del X_train, y_train del X_test, y_test print('Clear previously loaded data.')except: passX_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)# As a sanity check, we print out the size of the training and test data.print('Training data shape: ', X_train.shape)print('Training labels shape: ', y_train.shape)print('Test data shape: ', X_test.shape)print('Test labels shape: ', y_test.shape) ç»“æžœï¼š1234Training data shape: (50000, 32, 32, 3)Training labels shape: (50000,)Test data shape: (10000, 32, 32, 3)Test labels shape: (10000,) å¯è§†åŒ–dataset ä»Žç±»åž‹ä¸­1234567891011121314151617# Visualize some examples from the dataset.# We show a few examples of training images from each class.classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']num_classes = len(classes)samples_per_class = 7for y, cls in enumerate(classes): idxs = np.flatnonzero(y_train == y) idxs = np.random.choice(idxs, samples_per_class, replace=False) for i, idx in enumerate(idxs): plt_idx = i * num_classes + y + 1 plt.subplot(samples_per_class, num_classes, plt_idx) plt.imshow(X_train[idx].astype('uint8')) plt.axis('off') if i == 0: plt.title(cls)plt.show() 1np.flatnonzero(y_train == y) è¿”å›žå†…å®¹éž0çš„indexã€‚è¿™å¥æ˜¯è¿”å›žplaneç±»åˆ«é‡Œé¢çš„ï¼ˆy_train == yï¼‰æ‰€æœ‰éž0çš„å†…å®¹ã€‚ç„¶åŽä»Žè¿™äº›é‡Œé¢éšæœºé€‰æ‹©7ä¸ªå†…å®¹ï¼Œç”»å‡ºæ¥ã€‚ ç»“æžœå¦‚ä¸‹ï¼š è¿›ä¸€æ­¥åˆ†ä¸ºå‡ éƒ¨åˆ†123456789101112131415161718192021222324252627282930313233343536373839# Split the data into train, val, and test sets. In addition we will# create a small development set as a subset of the training data;# we can use this for development so our code runs faster.num_training = 49000num_validation = 1000num_test = 1000# ç”¨è¿™éƒ¨åˆ†æ¥ä¼˜åŒ–ä»£ç num_dev = 500# Our validation set will be num_validation points from the original# training set.mask = range(num_training, num_training + num_validation)X_val = X_train[mask]y_val = y_train[mask]# Our training set will be the first num_train points from the original# training set.mask = range(num_training)X_train = X_train[mask]y_train = y_train[mask]# We will also make a development set, which is a small subset of# the training set.mask = np.random.choice(num_training, num_dev, replace=False)X_dev = X_train[mask]y_dev = y_train[mask]# We use the first num_test points of the original test set as our# test set.mask = range(num_test)X_test = X_test[mask]y_test = y_test[mask]print('Train data shape: ', X_train.shape)print('Train labels shape: ', y_train.shape)print('Validation data shape: ', X_val.shape)print('Validation labels shape: ', y_val.shape)print('Test data shape: ', X_test.shape)print('Test labels shape: ', y_test.shape) 12mask = range(num_test)X_test = X_test[mask] æ„Ÿè§‰è¿™æ˜¯ä¸€ç§ä»Žä¸€ä¸ªæ•´ä½“ä¸­é€‰å–å…¶ä¸­ä¸€éƒ¨åˆ†çš„ä»£ç  å°†imageæ‹‰æˆrow1234567891011# Preprocessing: reshape the image data into rowsX_train = np.reshape(X_train, (X_train.shape[0], -1))X_val = np.reshape(X_val, (X_val.shape[0], -1))X_test = np.reshape(X_test, (X_test.shape[0], -1))X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))# As a sanity check, print out the shapes of the dataprint('Training data shape: ', X_train.shape)print('Validation data shape: ', X_val.shape)print('Test data shape: ', X_test.shape)print('dev data shape: ', X_dev.shape) å½“æƒ³æŠŠæ— è®ºä»»ä½•å¤§å°çš„ä¸œè¥¿æ‹‰æˆä¸€æ•´è¡Œçš„æ—¶å€™ï¼Œç”¨a.reshape(x, -1)ã€‚ X_train.shape[0]è¡Œï¼Œåˆ—æ•°æœªçŸ¥ï¼Œä½†æ˜¯æ‹‰å¹³äº† å¦‚æžœæƒ³æ‹‰æˆä¸€æ•´åˆ—çš„æ—¶å€™ï¼Œç”¨a.reshape(-1, x)ã€‚ åˆ—æ•°ä¸ºxï¼Œæ¯åˆ—æœ‰å¤šå°‘ä¸œè¥¿æœªçŸ¥ é¢„å¤„ç†éƒ¨åˆ†ï¼šå‡åŽ»mean image ç¬¬ä¸€æ­¥ï¼Œæ±‚å‡ºè®­ç»ƒé›†çš„meanå¹¶ä¸”å¯è§†åŒ– 12345678# Preprocessing: subtract the mean image# first: compute the image mean based on the training datamean_image = np.mean(X_train, axis=0)print(mean_image[:10]) # print a few of the elementsplt.figure(figsize=(4, 4))plt.imshow(mean_image.reshape((32, 32, 3)).astype( 'uint8')) # visualize the mean imageplt.show() ç¬¬äºŒæ­¥ï¼Œä»Žtrainå’Œtesté‡Œé¢å‡åŽ»å¹³å‡æ•°æ® 12345# second: subtract the mean image from train and test dataX_train -= mean_imageX_val -= mean_imageX_test -= mean_imageX_dev -= mean_image ç¬¬ä¸‰æ­¥ï¼ŒæŠŠé¢„å¤„ç†å¥½çš„æ‰€æœ‰å›¾ç‰‡çš„æœ«å°¾ï¼ˆæ‹‰æˆè¡Œä¹‹åŽçš„æœ€åŽï¼‰åŠ äº†ä¸€ä¸ª1ï¼ˆbiasçš„dimï¼‰ 12345678# third: append the bias dimension of ones (i.e. bias trick) so that our SVM# only has to worry about optimizing a single weight matrix W.X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape) np.hstack()ï¼Œæ²¿ç€æ°´å¹³æ–¹å‘æŠŠæ•°ç»„å èµ·æ¥ã€‚äºŽæ­¤ç›¸åŒï¼Œnp.vstack()ï¼Œæ˜¯æ²¿ç€åž‚ç›´æ–¹å‘æŠŠæ•°ç»„å èµ·æ¥ã€‚ SVM classifier1cs231n / classifiers / linear_svm.py. svm_loss_naive æœ‰ä¸‰ä¸ªè¾“å…¥ Xï¼šä¸€ä¸ªæœ‰Nä¸ªå…ƒç´ çš„minibatchï¼Œæ¯ä¸ªå…ƒç´ çš„å†…å®¹æ˜¯D(N, D) W: weightsï¼Œ(D, C), å›¾ç‰‡çš„å†…å®¹æ˜¯Dï¼Œä¸€å…±Cä¸ªclassï¼Œæ‰€ä»¥ç”¨çš„æ—¶å€™è·Ÿæ™®éæƒ³æ³•çš„Wæ˜¯tranposeçš„ y: æ ‡ç­¾ï¼Œå¤§å°(N,) ä¸€å…±Nå¼ ç…§ç‰‡ï¼Œæ¯å¼ ç…§ç‰‡æœ‰ä¸€ä¸ªæ ‡ç­¾ æœ€ç»ˆç»“æžœ ä¸€ä¸ªfloatçš„ç»“æžœï¼šloss Wçš„gradient dW æ³¨æ„ï¼ŒWxæ±‚å‡ºæ¥çš„å°±æ˜¯ä¸åŒåˆ†ç±»çš„ç§¯åˆ† dWçš„è®¡ç®—(https://blog.csdn.net/zt_1995/article/details/62227201) å½¢çŠ¶å¾ˆå¥‡æ€ªçš„1(x)æŒ‡çš„æ˜¯ï¼Œå½“xä¸ºçœŸçš„æ—¶å€™ç»“æžœæ˜¯1ï¼Œå½“xä¸ºå‡çš„æ—¶å€™ç»“æžœå–0 ç¬¬ä¸€ä¸ªå¼å­è¡¨ç¤ºç¬¬iä¸ªè¢«æ­£ç¡®åˆ†ç±»çš„æ¢¯åº¦ æœ‰å¤šå°‘ä¸ªWjè®©è¿™ä¸ªè¾¹ç•Œå€¼ä¸è¢«æ»¡è¶³ï¼Œå°±å¯¹æŸå¤±èµ·äº†å¤šå°‘è´¡çŒ® ä¹˜ä»¥xiæ˜¯å› ä¸ºxiåŒ…å«äº†æ ·æœ¬çš„å…¨éƒ¨ç‰¹å¾ï¼Œæ‰€ä»¥å‰é¢ä¹˜ä»¥ä¸€ä¸ªç³»æ•°1å°±å¯ä»¥äº† ç¬¦å·æ˜¯å› ä¸ºSGDé‡‡ç”¨è´Ÿæ¢¯åº¦è¿ç®— ç¬¬äºŒä¸ªå¼å­è¡¨ç¤ºä¸æ­£ç¡®åˆ†ç±»çš„æ¢¯åº¦ï¼Œåªæœ‰åœ¨yi == jçš„æ—¶å€™æ‰æœ‰è´¡çŒ®ï¼Œæ‰€ä»¥æ²¡æœ‰æ±‚å’Œã€‚ä½†æ˜¯æ³¨æ„ï¼Œåœ¨æ¯å¼ å›¾é‡Œé¢ï¼Œè¿™ä¸ªéƒ½ä¼šåœ¨j == yiçš„æ—¶å€™å‘ç”Ÿä¸€æ¬¡ï¼Œæ‰€ä»¥æ¯å¼ å›¾çš„jéƒ¨åˆ†éœ€è¦åŠ ä¸Šè¿™ä¸ªå€¼ æœ€ç»ˆçš„ç»“æžœéœ€è¦ï¼Œé™¤ä»¥N åˆ«å¿˜äº†æ­£åˆ™åŒ–ï¼è€Œä¸”ç”¨2\lanmdaWæ¥æ­£åˆ™åŒ–çš„æ•ˆæžœæ›´å¥½ä¸€äº› 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051def svm_loss_naive(W, X, y, reg): """ Structured SVM loss function, naive implementation (with loops). Inputs have dimension D, there are C classes, and we operate on minibatches of N examples. Inputs: - W: A numpy array of shape (D, C) containing weights. - X: A numpy array of shape (N, D) containing a minibatch of data. - y: A numpy array of shape (N,) containing training labels; y[i] = c means that X[i] has label c, where 0 &lt;= c &lt; C. - reg: (float) regularization strength Returns a tuple of: - loss as single float - gradient with respect to weights W; an array of same shape as W """ dW = np.zeros(W.shape) # initialize the gradient as zero # compute the loss and the gradient num_classes = W.shape[1] # æœ‰å¤šå°‘éœ€è¦è®­ç»ƒçš„ä¸ªæ•° num_train = X.shape[0] loss = 0.0 for i in range(num_train): scores = X[i].dot(W) correct_class_score = scores[y[i]] for j in range(num_classes): # å¦‚æžœè¿™ä¸ªç±»åž‹æ˜¯æ­£ç¡®çš„ï¼Œé‚£å°±ä¸ç”¨ç®¡äº† if j == y[i]: continue margin = scores[j] - correct_class_score + 1 # note delta = 1 if margin &gt; 0: loss += margin dW[:, y[i]] += -X[i] dW[:, j] += X[i] # Right now the loss is a sum over all training examples, but we want it # to be an average instead so we divide by num_train. loss /= num_train dW /= num_train # Add regularization to the loss. # regæ˜¯lanbda loss += reg * np.sum(W * W) dW += 2 * reg * W return loss, dW svm_loss_vectorizedé€šè¿‡å‘é‡åŒ–æ¥æé«˜è®¡ç®—é€Ÿåº¦ è®¡ç®—losséƒ¨åˆ† Wæ˜¯ä¸€ä¸ª(D, C)çš„å‘é‡ï¼ŒXæ˜¯(N, D)çš„ï¼Œæ‰€ä»¥ä¸¤è€…ç›¸ä¹˜å¯ä»¥å¾—åˆ°ä¸€ä¸ª(N, C)çš„çŸ©é˜µï¼ŒNä¸ºå›¾ç‰‡æ•°é‡ï¼ŒCæ˜¯æ¯å¼ å›¾ç‰‡å¯¹äºŽä¸åŒåˆ†ç±»çš„score åœ¨scoreä¸­å–æ¯ä¸€è¡Œçš„yä¸­labeléƒ¨åˆ†å°±æ˜¯è¿™å¼ å›¾æ­£ç¡®ç±»åž‹çš„è¯„åˆ† æŠŠæ•´ä½“çš„scoreçŸ©é˜µçš„æ‰€æœ‰é¡¹å‡åŽ»æ­£ç¡®è¯„åˆ†çš„çŸ©é˜µï¼ˆåº”è¯¥å¯ä»¥å¹¿æ’­ä½†æ˜¯æˆ‘åˆšå¼€å§‹ç”¨repeatå’Œreshapeå¤åˆ¶äº†ä¸€ä¸‹ï¼‰ï¼Œå‡åŽ»çš„ç»“æžœå°±æ˜¯svmä¸­éœ€è¦å’Œ0æ¯”çš„å€¼ï¼ˆmarginï¼‰ ä¸ºäº†æ±‚lossï¼ŒæŠŠå°äºŽ0çš„é¡¹ç›®å’Œæ­£ç¡®çš„é¡¹é™¤åŽ»ï¼ˆéƒ½è®¾ç½®æˆ0ï¼‰ ç„¶åŽè¡Œæ±‚å’Œï¼Œåˆ—æ±‚å’Œï¼Œé™¤ä»¥æ•´ä½“çš„ä¸ªæ•°ï¼Œregularzation è®¡ç®—dWéƒ¨åˆ† X.Tç‚¹ä¹˜marginå¾—åˆ°çš„å°±æ˜¯æœ€ç»ˆçš„lossï¼Œæ‰€ä»¥éœ€è¦æŠŠæ¯ä¸ªmarginé‡Œé¢ç¬¦åˆæ¡ä»¶çš„æ•°å¯¹äº† æ‰€æœ‰æ¯”0å¤§çš„æ—¶å€™éƒ½ç®—1ï¼ˆæ ¹æ®å¯¼æ•°çš„è®¡ç®—ç»“æžœï¼‰ å½“åº”è¯¥åˆ¤æ–­æ­£ç¡®çš„ç±»åž‹æ¯”0å¤§çš„æ—¶å€™ï¼Œè¿™ä¸ªä¸œè¥¿ä¼šåœ¨æ¯æ¬¡è®¡ç®—å¯¼æ•°çš„æ—¶å€™éƒ½ç®—ä¸Šä¸€æ¬¡ï¼Œæ‰€ä»¥æ˜¯è¡Œçš„åˆ æœ€åŽä¹˜å®Œä¹‹åŽé™¤ä»¥æ€»çš„ä¸ªæ•°ï¼Œå†regularzation1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def svm_loss_vectorized(W, X, y, reg): """ Structured SVM loss function, vectorized implementation. Inputs and outputs are the same as svm_loss_naive. """ loss = 0.0 dW = np.zeros(W.shape) # initialize the gradient as zero ############################################################################# # TODO: # # Implement a vectorized version of the structured SVM loss, storing the # # result in loss. # ############################################################################# num_train = X.shape[0] num_classes = W.shape[1] scores = X.dot(W) # è¿™é‡Œæ˜¯å–ç¬¬Nè¡Œï¼ˆå›¾ç‰‡è¡Œï¼‰çš„ç¬¬Cä¸ªï¼ˆclassåˆ—ï¼‰ï¼Œå¾—åˆ°çš„æ˜¯ï¼ˆ500ï¼Œï¼‰çš„æ­£ç¡®ç±»çš„scoreçš„çŸ©é˜µ correct_class_score = scores[np.arange(num_train), y] # correct_class_score = np.repeat(correct_class_score, num_classes) # correct_class_score = correct_class_score.reshape(num_train, num_classes) # DxC margin = scores - correct_class_score + 1.0 margin[np.arange(num_train), y] = 0.0 margin[margin &lt;= 0] = 0.0 loss += np.sum(np.sum(margin, axis=1)) / num_train # loss /= num_train loss += 0.5 * reg * np.sum(W * W) margin[margin &gt; 0] = 1.0 calculate_times = np.sum(margin, axis=1) margin[np.arange(num_train), y] = - calculate_times dW = np.dot(X.T, margin) / num_train dW += 2 * reg * W ############################################################################# # END OF YOUR CODE # ############################################################################# return loss, dW çŽ°åœ¨å¾—åˆ°äº†dWå’Œlossï¼Œä½¿ç”¨SGDæ¥å‡å°‘lossè®­ç»ƒ å°†æ•´ä½“åˆ†æˆä¸åŒçš„minibatchï¼Œä½¿ç”¨np.random.choiceï¼Œæ³¨æ„åŽé¢çš„replceå¯ä»¥é€‰Trueï¼Œè¿™æ ·ä¼šé‡å¤é€‰æ‹©å…ƒç´ ä½†æ˜¯ç»“æžœé€Ÿåº¦å¥½åƒæ˜¯æ›´å¿«äº† å°†minibatchçš„ç»“æžœè®¡ç®—losså’Œgradientï¼Œç„¶åŽgrad * learning rateæ¥updateæ•°æ® 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100, batch_size=200, verbose=False): """ Train this linear classifier using stochastic gradient descent. Inputs: - X: A numpy array of shape (N, D) containing training data; there are N training samples each of dimension D. - y: A numpy array of shape (N,) containing training labels; y[i] = c means that X[i] has label 0 &lt;= c &lt; C for C classes. - learning_rate: (float) learning rate for optimization. - reg: (float) regularization strength. - num_iters: (integer) number of steps to take when optimizing - batch_size: (integer) number of training examples to use at each step. - verbose: (boolean) If true, print progress during optimization. Outputs: A list containing the value of the loss function at each training iteration. """ num_train, dim = X.shape # assume y takes values 0...K-1 where K is number of classes num_classes = np.max(y) + 1 if self.W is None: # lazily initialize W self.W = 0.001 * np.random.randn(dim, num_classes) # Run stochastic gradient descent to optimize W loss_history = [] for it in range(num_iters): X_batch = None y_batch = None ######################################################################### # TODO: # # Sample batch_size elements from the training data and their # # corresponding labels to use in this round of gradient descent. # # Store the data in X_batch and their corresponding labels in # # y_batch; after sampling X_batch should have shape (dim, batch_size) # # and y_batch should have shape (batch_size,) # # # # Hint: Use np.random.choice to generate indices. Sampling with # # replacement is faster than sampling without replacement. # ######################################################################### indices = np.random.choice(num_train, batch_size, replace=True) X_batch = X[indices] y_batch = y[indices] ######################################################################### # END OF YOUR CODE # ######################################################################### # evaluate loss and gradient loss, grad = self.loss(X_batch, y_batch, reg) loss_history.append(loss) # perform parameter update ######################################################################### # TODO: # # Update the weights using the gradient and the learning rate. # ######################################################################### self.W += - learning_rate * grad ######################################################################### # END OF YOUR CODE # ######################################################################### if verbose and it % 100 == 0: print('iteration %d / %d: loss %f' % (it, num_iters, loss)) return loss_history é¢„æµ‹ç»“æžœ å·²ç»æœ‰äº†å‰é¢çš„åˆ°çš„è®­ç»ƒè¿‡çš„Wï¼ˆself.Wï¼‰ Wxç®—å‡ºæ¥çš„å°±æ˜¯åˆ†æ•° ä»Žæ¯ä¸€è¡Œé‡Œé¢é€‰æ‹©æœ€å¤§çš„åˆ†æ•°å°±æ˜¯é¢„æµ‹çš„ç»“æžœ123456789101112131415161718192021222324252627def predict(self, X): """ Use the trained weights of this linear classifier to predict labels for data points. Inputs: - X: A numpy array of shape (N, D) containing training data; there are N training samples each of dimension D. Returns: - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional array of length N, and each element is an integer giving the predicted class. """ y_pred = np.zeros(X.shape[0]) ########################################################################### # TODO: # # Implement this method. Store the predicted labels in y_pred. # ########################################################################### scores = X.dot(self.W) y_pred = np.argmax(scores, axis=1) # print(labels.shape) # print(labels) ########################################################################### # END OF YOUR CODE # ########################################################################### return y_pred äº¤å‰éªŒè¯ åœ¨ä½œä¸šé‡Œï¼Œéœ€è¦é€‰æ‹©ä¸¤ä¸ªhyperçš„å€¼ï¼Œåˆ†åˆ«æ˜¯å­¦ä¹ çŽ‡å’Œregularzationçš„å‚æ•°ï¼Œæ²¡æœ‰é‡‡ç”¨äº¤å‰éªŒè¯ï¼Œä½†æ˜¯é‡‡ç”¨äº†éšæœºæœç´¢ï¼Œä¼šæ¯”grid searchæ›´å‡†ç¡®ä¸€äº› é‡‡ç”¨ä¸åŒçš„å‚æ•°ç»„åˆåˆ†åˆ«è®­ç»ƒè¿™ä¸ªæ¨¡åž‹ï¼Œç„¶åŽå¾—åˆ°å„è‡ªåœ¨validationä¸Šé¢çš„å‡†ç¡®çŽ‡ï¼Œè¿™ä¸ªå¾—åˆ°å‡†ç¡®çŽ‡æœ€å¤§çš„ç»„åˆçš„å‚æ•° æ³¨æ„ï¼Œåœ¨éªŒè¯çš„è¿‡ç¨‹ä¸­åº”è¯¥é€‰æ‹©iterçš„æ¬¡æ•°å°‘ä¸€ç‚¹ï¼Œä¸ç„¶è®­ç»ƒçš„æ—¶é—´ä¼šéžå¸¸é•¿ åœ¨è¿™ä¸ªä»£ç é‡Œç”¨äº†randæ¥å¾—åˆ°0åˆ°1ä¹‹é—´çš„éšæœºæ•°ï¼Œè¿™ä¸ªæ•°ä¹˜ä»¥hyperçš„èŒƒå›´çš„å·®ï¼Œç„¶åŽå†åŠ ä¸Šä¸‹é™ï¼Œå°±æ˜¯éšæœºå¾—åˆ°çš„æœ€ç»ˆç»“æžœ 1234567891011121314rand_turple = np.random.rand(50,2)rand_turple[:,0] = rand_turple[:,0]*(learning_rates[1]-learning_rates[0]) + learning_rates[0]rand_turple[:,1] = rand_turple[:,1]*(regularization_strengths[1]-regularization_strengths[0])+regularization_strengths[0]for lr,rs in rand_turple: svm = LinearSVM() svm.train(X_train, y_train, learning_rate=lr, reg=rs,num_iters=1500, verbose=True) y_train_pred = svm.predict(X_train) train_acc = np.mean(y_train == y_train_pred) y_val_pred = svm.predict(X_train) val_acc = np.mean(y_train == y_val_pred) results[(lr,rs)] = (train_acc,val_acc) if (val_acc &gt; best_val): best_val = val_acc best_svm = svm ç»“æžœå¯è§†åŒ–123456789101112131415# Visualize the learned weights for each class.# Depending on your choice of learning rate and regularization strength, these may# or may not be nice to look at.w = best_svm.W[:-1,:] # strip out the biasw = w.reshape(32, 32, 3, 10)w_min, w_max = np.min(w), np.max(w)classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']for i in range(10): plt.subplot(2, 5, i + 1) # Rescale the weights to be between 0 and 255 wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min) plt.imshow(wimg.astype('uint8')) plt.axis('off') plt.title(classes[i])]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
        <category>CS231nä½œä¸š</category>
      </categories>
      <tags>
        <tag>SVM</tag>
        <tag>SGD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TypeError:'method' object is not subscriptable]]></title>
    <url>%2F2019%2F03%2F26%2Fmethod%E4%B8%8D%E6%98%AFsubscripatable%2F</url>
    <content type="text"><![CDATA[é­é‡é—®é¢˜TypeError: â€˜methodâ€™ object is not subscriptableæ˜¯å› ä¸ºæˆ‘æœ¬æ¥å†™äº†ä¸€ä¸ªclassçš„method123def get_page(self, num):num = int(num)return self.pages[num] ä½†æ˜¯åœ¨è°ƒç”¨çš„æ—¶å€™æˆ‘ç”¨äº†12get_page[i]get_page(i) #è¿™æ ·æ‰æ˜¯æ­£ç¡®çš„ æ‰¾åˆ°æŠ¥é”™æ”¹æ‹¬å·å°±è¡Œäº†ï¼]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[enumerateæžšä¸¾]]></title>
    <url>%2F2019%2F03%2F25%2Fenumerate%E6%9E%9A%E4%B8%BE%2F</url>
    <content type="text"><![CDATA[enumerate()æžšä¸¾å¯¹å¯è¿­ä»£çš„æ•°æ®è¿›è¡Œæ ‡å·å¹¶å°†å…¶é‡Œé¢çš„æ•°æ®å’Œæ ‡å·ä¸€å¹¶æ‰“å°å‡ºæ¥ã€‚1enumerate(iterable, start=0) iterable: å¯è¿­ä»£çš„æ•°æ®ï¼Œæ¯”å¦‚list start: æ‰“å°çš„åˆå§‹å€¼ï¼Œé»˜è®¤ä»Ž0å¼€å§‹æ‰“å° 123test = [[11], [21], [31], [41]]for i, cnt in enumerate(test):print(i, cnt) ç»“æžœä¸º12340 [11]1 [21]2 [31]3 [41]]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Pythonçš„Noneå’Œifçš„ç†è§£]]></title>
    <url>%2F2019%2F03%2F25%2FPython%E7%9A%84None%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[pythonå¯¹å˜é‡Noneçš„åˆ¤æ–­Noneæ˜¯ä¸€ç§æ•°æ®ç±»åž‹ï¼ï¼ï¼12&gt;&gt;&gt;type(None)&lt;class 'NoneType'&gt; è¯´æ˜Žè¯¥å€¼æ˜¯ä¸€ä¸ªç©ºçš„å¯¹è±¡ï¼Œæ˜¯Pythoné‡Œé¢çš„ç‰¹æ®Šçš„å€¼ï¼Œè·ŸNULLä¸ä¸€æ ·ï¼Œè·Ÿ0ä¹Ÿä¸ä¸€æ · 123456a = Noneb = []if a is None or b is None:print("yahaha")else:print("wocao") ç»“æžœä¸ºâ€œyahahaâ€ æ³¨æ„ï¼šåœ¨ifçš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨Noneæœ‰æ—¶å€™å¯ä»¥èµ·åˆ°å¾ˆå¥½çš„ä½œç”¨1if a is None: ä¸Žè¿™ä¸ªå·®ä¸å¤šçš„ç”¨æ³•æ˜¯1if not a: åœ¨pythoné‡Œé¢ï¼ŒNoneï¼Œç©ºåˆ—è¡¨[]ï¼Œå­—å…¸{},tuple()ï¼Œ0ç­‰éƒ½ä¼šè¢«è½¬åŒ–æˆfalseï¼Œå‰©ä¸‹çš„ä¸ºtrueæ¯”å¦‚ï¼š12345a = Noneif a:print("yahaha")else:print("wocao") è¿™æ—¶å€™çš„è¾“å‡ºæ˜¯wocaoï¼Œå› ä¸ºaè¢«è®¤ä¸ºæ˜¯false]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[np.deleteåˆ é™¤æ•°ç»„å†…å®¹]]></title>
    <url>%2F2019%2F03%2F25%2Fnp-delete%E5%88%A0%E9%99%A4%E6%95%B0%E7%BB%84%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[np.deletenumpy.delete(arr, obj, axis=None) è¿”å›žä¸€ä¸ªæ–°çš„arrayï¼Œåˆ é™¤æŽ‰objï¼Œæ²¿ç€axisæ–¹å‘ axis : int, optional The axis along which to delete the subarray defined by obj. If axis is None, obj is applied to the flattened array.(å¦‚æžœä¸åŠ ä¸Šaxisçš„è¯ä¼šè‡ªåŠ¨æŠŠè¿™ä¸ªarrayæ‹‰å¹³) axis = 0ï¼šåˆ é™¤æ•°ç»„çš„è¡Œ axis = 1: åˆ é™¤æ•°ç»„çš„åˆ— axis = none: æŠŠæ•´ä¸ªæ•°ç»„å¹³é“ºä¹‹åŽæŒ‰ç´¢å¼•åˆ é™¤ 123456789101112import numpy as npids = [[3], [34], [5]]ids_o = [[3], [31]]remove_list = filter(lambda i: i not in ids, ids_o)# print(np.asarray(ids))for i in remove_list:index = np.where(np.asarray(ids_o) == i)[0]print("index = ", index)ids = np.delete(ids, index, axis = 0)print("new ids = \n", ids) ç»“æžœï¼š1234index = [1]new ids = [[3][5]] å¦‚æžœæŠŠä¸Šé¢æ”¹æˆ1ids = np.delete(ids, 0, axis = 1) å³ä¸ºåˆ é™¤æ•°ç»„çš„ç¬¬0åˆ—ï¼Œç»“æžœæ˜¯ [ ] ï¼ˆå› ä¸ºåªæœ‰ä¸€åˆ—ï¼‰ å¦‚æžœæ”¹æˆ1ids = np.delete(ids, index, axis = None) ç»“æžœä¸ºï¼š12new ids = [3 5]]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[np.whereæŸ¥æ‰¾ç´¢å¼•]]></title>
    <url>%2F2019%2F03%2F25%2Fnp-where%E6%9F%A5%E6%89%BE%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[np.wherenp.where(condition, x, y)æ»¡è¶³æ¡ä»¶(condition)ï¼Œè¾“å‡ºxï¼Œä¸æ»¡è¶³è¾“å‡ºyã€‚123np.where([[True,False], [True,True]], # å®˜ç½‘ä¸Šçš„ä¾‹å­[[1,2], [3,4]],[[9,8], [7,6]]) è¾“å‡º12array([[1, 8],[3, 4]]) ä¸Šé¢è¿™ä¸ªä¾‹å­çš„æ¡ä»¶ä¸º[[True,False], [True,False]]ï¼Œåˆ†åˆ«å¯¹åº”æœ€åŽè¾“å‡ºç»“æžœçš„å››ä¸ªå€¼ã€‚ç¬¬ä¸€ä¸ªå€¼ä»Ž[1,9]ä¸­é€‰ï¼Œå› ä¸ºæ¡ä»¶ä¸ºTrueï¼Œæ‰€ä»¥æ˜¯é€‰1ã€‚ç¬¬äºŒä¸ªå€¼ä»Ž[2,8]ä¸­é€‰ï¼Œå› ä¸ºæ¡ä»¶ä¸ºFalseï¼Œæ‰€ä»¥é€‰8ï¼ŒåŽé¢ä»¥æ­¤ç±»æŽ¨è¿™é‡Œçš„trueæŒ‡çš„å°±æ˜¯é€‰å‰é¢çš„ï¼Œfalseå°±æ˜¯æŒ‡é€‰åŽé¢çš„ 1234567&gt;&gt;&gt; a = 10&gt;&gt;&gt; np.where([[a &gt; 5,a &lt; 5], [a == 10,a == 7]],[["chosen","not chosen"], ["chosen","not chosen"]],[["not chosen","chosen"], ["not chosen","chosen"]])array([['chosen', 'chosen'],['chosen', 'chosen']], dtype='&lt;U10') np.where(condition)åªæœ‰æ¡ä»¶ (condition)ï¼Œæ²¡æœ‰xå’Œyï¼Œåˆ™è¾“å‡ºæ»¡è¶³æ¡ä»¶ (å³éž0) å…ƒç´ çš„åæ ‡ï¼ˆæ³¨æ„è¿™é‡Œè¿”å›žçš„æ˜¯åæ ‡ï¼‰12345&gt;&gt;&gt; a = np.array([2,4,6,8,10])&gt;&gt;&gt; np.where(a &gt; 5) # è¿”å›žç´¢å¼•(array([2, 3, 4]),) &gt;&gt;&gt; a[np.where(a &gt; 5)] # ç­‰ä»·äºŽ a[a&gt;5]array([ 6, 8, 10]) 123456789101112131415161718&gt;&gt;&gt; a = np.arange(27).reshape(3,3,3)&gt;&gt;&gt; aarray([[[ 0, 1, 2],[ 3, 4, 5],[ 6, 7, 8]],[[ 9, 10, 11],[12, 13, 14],[15, 16, 17]],[[18, 19, 20],[21, 22, 23],[24, 25, 26]]])&gt;&gt;&gt; np.where(a &gt; 5)(array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]),array([2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2]),array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])) æ³¨æ„è¿™é‡Œçš„æœ€ç»ˆç»“æžœçš„åæ ‡æ˜¯è¦ç«–ç€çœ‹çš„ï¼Œå³ï¼ˆ0ï¼Œ2ï¼Œ0ï¼‰ï¼Œï¼ˆ0ï¼Œ2ï¼Œ1ï¼‰â€¦. è¿™ä¸ªæ–¹æ³•åªèƒ½ç”¨åœ¨arrayä¸Šé¢ï¼Œå¦‚æžœéœ€è¦listçš„è¯éœ€è¦np.asarray 12345678910import numpy as npids = [[3], [34], [5]]ids_o = [[3]]remove_list = filter(lambda i: i not in ids_o, ids)print(np.asarray(ids))for i in remove_list:index = np.where(np.asarray(ids) == i)print(index) ç»“æžœ123456[[ 3][34][ 5]](array([1]), array([0]))(array([2]), array([0]))[Finished in 0.2s]]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pythonçš„filterå‡½æ•°]]></title>
    <url>%2F2019%2F03%2F25%2FPython%E7%9A%84filter%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[python filterfilter() å‡½æ•°ç”¨äºŽè¿‡æ»¤åºåˆ—ï¼Œè¿‡æ»¤æŽ‰ä¸ç¬¦åˆæ¡ä»¶çš„å…ƒç´ ï¼Œè¿”å›žç”±ç¬¦åˆæ¡ä»¶å…ƒç´ ç»„æˆçš„æ–°åˆ—è¡¨ã€‚ è¯¥æŽ¥æ”¶ä¸¤ä¸ªå‚æ•°ï¼Œç¬¬ä¸€ä¸ªä¸ºå‡½æ•°ï¼Œç¬¬äºŒä¸ªä¸ºåºåˆ—ï¼Œåºåˆ—çš„æ¯ä¸ªå…ƒç´ ä½œä¸ºå‚æ•°ä¼ é€’ç»™å‡½æ•°è¿›è¡Œåˆ¤ï¼Œç„¶åŽè¿”å›ž True æˆ– Falseï¼Œæœ€åŽå°†è¿”å›ž True çš„å…ƒç´ æ”¾åˆ°æ–°åˆ—è¡¨ä¸­ã€‚ è¿”å›žå€¼æ˜¯fliterçš„ç±»åž‹1remove_list = filter(lambda i: i not in ids_o,ids_u) å¯¹äºŽä¸åœ¨ids_oé‡Œé¢çš„iï¼Œæ˜¯ä¸æ˜¯åœ¨ids_ué‡Œé¢ï¼Œå¦‚æžœæ˜¯çš„è¯å°±éœ€è¦removeè¿™éƒ¨åˆ†ä¸œè¥¿]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tuple,array,listçš„å¤§å°é—®é¢˜]]></title>
    <url>%2F2019%2F03%2F22%2Ftuple-array-list%E7%9A%84%E5%A4%A7%E5%B0%8F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[æ¯æ¬¡åœ¨ä½¿ç”¨è¿™ç¾¤ä¹±ä¸ƒå…«ç³Ÿçš„æ•°æ®ç»“æž„çš„æ—¶å€™æˆ‘éƒ½ä¸æ˜Žç™½åˆ°åº•ç”¨å“ªä¸ªå‡½æ•°æ±‚é•¿åº¦ï¼Œè€Œä¸”å„ä¸ªç»“æž„çš„è¡¨ç¤ºæ–¹æ³•æ¯æ¬¡éƒ½è®©æˆ‘æ„Ÿè§‰å¾ˆè¿·èŒ«ï¼Œæ‰€ä»¥æœ‰äº†è¿™ç¯‡æ–‡ç« ã€‚ å¥½åƒåªæœ‰arrayå¯ä»¥ç”¨shapeæ¥æ±‚ï¼å…¶ä»–çš„éƒ½æ²¡æœ‰shapeï¼Œarrayçš„shapeå¯èƒ½æ˜¯å¤šç»´çš„ã€‚ æ•°ç»„array æ•°ç»„çš„è¡¨ç¤ºæ–¹æ³•ä¸ºæœ€å¤–é¢æ˜¯æ‹¬å·ï¼Œé‡Œé¢æ˜¯æ–¹æ‹¬å·ï¼Œä¸åŒçš„æ–¹æ‹¬å·ä»£è¡¨ä¸åŒçš„ç»´åº¦ï¼Œnpæ“ä½œçš„éƒ½æ˜¯arrayçš„éƒ¨åˆ† å¦‚æžœæ˜¯ä¸€ç»´æ•°ç»„ï¼Œæ˜¾ç¤ºå‡ºæ¥çš„sizeåº”è¯¥æ˜¯(1,)è¿™ä¸ªæ ·å­çš„ sizeæ–¹æ³•1a.size 1np.size(a) lenä¸å¯ä»¥å¾—åˆ°æ•´ä¸ªçš„å¤§å°ï¼Œä½†æ˜¯å¯ä»¥å¾—åˆ°æ•°ç»„çš„è¡Œæ•°ï¼Œç›¸å½“äºŽa.shape[0]1len(a) 1a.shape[çœ‹çœ‹æ±‚çš„æ˜¯ç¬¬å‡ ç»´] åˆ—è¡¨ åˆ—è¡¨æœ€å¤–é¢æ˜¯æ–¹æ‹¬å·ï¼Œä¸æ˜¯åœ†æ‹¬å·ï¼ ä¸å¯ä»¥ç›´æŽ¥ç”¨ a.size æ±‚ï¼Œâ€™listâ€™ object has no attribute â€˜sizeâ€™ 1np.size(List) 1len(List) å…ƒç»„ å…ƒç»„çš„æœ€å¤–é¢æ˜¯åœ†æ‹¬å· ä¸å¯ä»¥é€šè¿‡ t.size æ¥è®¿é—® å¯ä»¥é€šè¿‡ Tuple[]ç›´æŽ¥è®¿é—®å…ƒç´  1np.size(Tuple) 1len(Tuple) å­—å…¸ å¤–é¢æ˜¯å¤§æ‹¬å·ï¼Œé‡Œé¢æ˜¯value-keyçš„é…å¯¹ sizeä¸å¯ä»¥ç”¨ï¼Œnp.sizeæ— æ³•èŽ·å¾—çœŸå®žçš„å¤§å° 1len(Dict)]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[åœ¨pythonä¸­è°ƒç”¨å¦å¤–çš„æ–‡ä»¶]]></title>
    <url>%2F2019%2F03%2F22%2F%E5%9C%A8python%E4%B8%AD%E8%B0%83%E7%94%A8%E5%8F%A6%E5%A4%96%E7%9A%84%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[å…³äºŽå¦‚ä½•åœ¨pythonä¸­è°ƒç”¨å…¶ä»–çš„æ–‡ä»¶åœ¨cppé‡Œé¢æ˜¯ä½¿ç”¨å¤´æ–‡ä»¶æ¥å¯¼å…¥çš„ï¼Œä½†æ˜¯æåˆ°pythonçªç„¶æ²¡æƒ³èµ·æ¥æ˜¯æ€Žä¹ˆå¯¼å…¥çš„ã€‚å‡è®¾æœ‰æ–‡ä»¶a.pyå’Œb.py åœ¨åŒä¸€ç›®å½•ä¸‹12import aa.func() æˆ–è€…å¼•ç”¨æ¨¡å—ä¸­çš„å‡½æ•°123from a import funcfunc() ` æ³¨æ„ï¼šå‰é¢ä¸€ç§æ–¹æ³•å¯¼å…¥çš„æ—¶å€™éœ€è¦åŠ ä¸Šæ¨¡å—çš„åç§°é™å®šï¼Œä½†æ˜¯åŽé¢çš„å¯¼å…¥å°±ä¸ç”¨ã€‚å¦‚æžœæ€•éº»çƒ¦å¯ä»¥å¯¼å…¥çš„æ—¶å€™ä½¿ç”¨1from a import * åœ¨ä¸åŒç›®å½•ä¸‹sys.pathèŽ·å–æŒ‡å®šæ¨¡å—æœç´¢è·¯å¾„çš„å­—ç¬¦ä¸²é›†åˆï¼Œå¯ä»¥å°†å†™å¥½çš„æ¨¡å—æ”¾åœ¨å¾—åˆ°çš„æŸä¸ªè·¯å¾„ä¸‹ï¼Œå°±å¯ä»¥åœ¨ç¨‹åºä¸­importæ—¶æ­£ç¡®æ‰¾åˆ°1234import syssys.path.append('aæ‰€åœ¨çš„è·¯å¾„')import aa.func() sysæ˜¯ä»€ä¹ˆ sysæ˜¯pythonç¨‹åºç”¨æ¥è¯·æ±‚è§£é‡Šå™¨è¡Œä¸ºçš„interfaceï¼Œæ¯”å¦‚è°ƒè¯•ï¼Œå®žæ—¶è¿è¡ŒçŽ¯å¢ƒç­‰ sys.argv ä»Žå¤–éƒ¨å‘ç¨‹åºå†…éƒ¨ä¼ é€’å‚æ•°12345#!/usr/bin/env pythonimport sysprint sys.argv[0]print sys.argv[1] è¿è¡Œï¼š123# python sys.py argv1sys.pyargv1 sys.exit() éœ€è¦ä¸­é€”é€€å‡ºçš„æ—¶å€™å¯ä»¥è°ƒç”¨ï¼Œå¯ä»¥è¿”å›žå‚æ•°ï¼ˆ0æ˜¯æ­£å¸¸é€€å‡ºï¼Œå…¶ä»–æ˜¯å¼‚å¸¸ï¼‰12345678910111213141516#!/usr/bin/env pythonimport sysdef exitfunc(value): print value sys.exit(0)print "hello"try: sys.exit(1)except SystemExit,value: exitfunc(value)print "come?" 123# python exit.pyhello1]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å…³äºŽhexoå’Œgitpageçš„åšå®¢æ­å»ºä»¥åŠè®¾ç½®]]></title>
    <url>%2F2019%2F03%2F20%2F%E5%85%B3%E4%BA%8Ehexo%E5%92%8Cgitpage%E7%9A%84%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%8F%8A%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[åœ¨commitäº†40å¤šæ¬¡ä¹‹åŽç»ˆäºŽæŠŠè‡ªå·±çš„åšå®¢æ­å¥½äº†ï¼Œä¸­é—´ç”»é‡åˆ°äº†ä¸€äº›å¥‡æ€ªçš„é—®é¢˜è®°å½•ä¸€ä¸‹ githubéƒ¨åˆ† åœ¨ä¸€äº›åœ°æ–¹çœ‹åˆ°çš„è¯´ç½‘ç«™çš„åå­—å¿…é¡»å’Œgithubçš„åå­—ä¸€æ ·ï¼Œä¸çŸ¥é“æ˜¯ä¸æ˜¯å¿…é¡»çš„ä½†æ˜¯è¿˜æ˜¯è¿™ä¹ˆè®¾ç½®äº† ç½‘ç«™éœ€è¦é€‰æ‹©åœ¨master hexoéƒ¨åˆ†åŸºæœ¬åŠŸèƒ½ï¼šç”Ÿæˆç½‘é¡µ1hexo g ä¼ åˆ°githubä¸Šé¢1hexo d ç”Ÿæˆæ–°çš„md1hexo new &lt;title&gt; éœ€è¦æŠŠç”Ÿæˆçš„å…¨éƒ¨æ¸…é™¤1hexo clean æ·»åŠ ä¸»é¢˜ æŠŠç›¸åº”çš„ä¸»é¢˜cloneä¸‹æ¥ï¼Œç„¶åŽä¿®æ”¹åšå®¢æ ¹ç›®å½•çš„ _config.yml æ–‡ä»¶ é‡åˆ°404æˆ–è€…ä¸æ˜¾ç¤ºæ¨¡æ¿çš„æ—¶å€™åŸºæœ¬å°±æ˜¯æ²¡å¥—å¯¹ ä¸»é¢˜å†…å®¹åœ¨ä¸»é¢˜çš„configä¿®æ”¹è¿™éƒ¨åˆ†é‡åˆ°çš„ä¸»è¦é—®é¢˜æ˜¯ä¸¤ä¸ªï¼šæ ¹ç›®å½•configå¿˜è®°æ·»åŠ ä¸€éƒ¨åˆ†123456789101112131415161718jsonContent: meta: false pages: false posts: title: true date: true path: true text: false raw: false content: false slug: false updated: false comments: false link: false permalink: false excerpt: false categories: false tags: true hexoçš„urlå’Œrootéƒ¨åˆ†è®¾ç½®ä¸å¯¹ githubçš„deploy åœ°å€åº”è¯¥æ˜¯cloneæ—¶å€™çš„ç½‘å€ urléƒ¨åˆ†åº”è¯¥æ˜¯https://bigphess.github.io/ï¼Œrootéƒ¨åˆ†æ˜¯/ mdæ–‡ä»¶å¢žåŠ å›¾ç‰‡åœ¨configé‡Œé¢è®¾ç½®ï¼Œç”Ÿæˆæ–°çš„æ–‡ç« çš„æ—¶å€™å°±ä¼šç”Ÿæˆå¯¹åº”çš„æ–‡ä»¶å¤¹1post_asset_folder: true ç„¶åŽæŠŠç›¸åº”çš„å›¾ç‰‡æ”¾åœ¨æ–‡ä»¶å¤¹é‡Œï¼Œå¼•ç”¨çš„æ—¶å€™ç›´æŽ¥mdæ ¼å¼å¼•ç”¨ï¼š1![å›¾ç‰‡çš„åå­—](ç›¸å¯¹è·¯å¾„)]]></content>
      <categories>
        <category>åšå®¢ç›¸å…³</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[StanfordCS231Nç¬”è®°]]></title>
    <url>%2F2019%2F03%2F20%2FStanfordCS231N%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Introduction Image Classification pipelinechallenges å›¾ç‰‡æ˜¯ç”±æ— æ•°æ•°å­—å—ç»„æˆçš„ è§†è§’çš„è½¬å˜ï¼Œäº®åº¦çš„å˜åŒ–ï¼Œå˜å½¢éƒ½ä¼šäº§ç”Ÿéžå¸¸å¤§çš„å˜åŒ– viewpoint illumination deformation occlusion background clutter intraclass variation image classifer input:image output: class_label data-driven approach å…¶ä»–æ–¹æ³•ä¸è¡Œ attempts: è¾¹ç¼˜æ£€æµ‹ï¼Œçº¹ç†ç­‰ç­‰ï¼ˆä½†æ˜¯å¤ªè¿‡å…·ä½“ï¼‰ ä»¥æ•°æ®ä¸ºå¯¼å‘çš„æ–¹æ³• def train(image, label) def predict(model, test_image) KNNNN å¯¹äºŽæ¯ä¸€ä¸ªæµ‹è¯•çš„dataï¼Œåœ¨æ•°æ®åº“é‡Œé¢æ‰¾åˆ°ç¦»ä»–æœ€è¿‘çš„å›¾ç‰‡ï¼ˆé€‰æ‹©ä¸€å…±æ‰¾å¤šå°‘å¼ ï¼Œè¿™ä¹ˆå¤šå¼ é‡Œé¢æŠ•ç¥¨ï¼‰ å®šä¹‰è·ç¦»ï¼ˆhyperparameterï¼‰ æ›¼å“ˆé¡¿è·ç¦» L1: ä¸¤å¼ å›¾ç›¸å‡æ±‚ç»å¯¹å€¼ï¼Œç„¶åŽæŠŠæ•´å¼ ç…§ç‰‡æ±‚å’Œ æ¬§å‡ é‡Œå¾—è·ç¦» L2: è·ç¦»çš„å¹³æ–¹å’Œå¼€æ–¹ å®žçŽ° trainingï¼šè®°ä½æ¯ä¸ªå›¾ç‰‡çš„å†…å®¹å’Œlabel imageï¼šNâœ–Dï¼Œæ¯è¡Œæ˜¯ä¸€å¼ å›¾ç‰‡ï¼ˆæ‹‰æˆä¸€è¡Œï¼‰ï¼Œä¸€å…±Nå¼  labelï¼š1-dæ•°ç»„ï¼ŒsizeN predictï¼šè®¡ç®—è·ç¦»æ‰¾åˆ°æœ€å°çš„è§’æ ‡ï¼ˆnp.argmin) é€Ÿåº¦ï¼šlinearly to size of dataset ç¼ºç‚¹ï¼š é¢„æµ‹çš„æ—¶é—´å¤ªé•¿äº†ï¼ˆexpensiveï¼‰ ä½†æ˜¯æˆ‘ä»¬å¸Œæœ›è®­ç»ƒçš„æ—¶é—´é•¿ä½†æ˜¯æµ‹è¯•çš„æ—¶é—´çŸ­ï¼ˆCNNï¼‰ KNN æ‰¾åˆ°æœ€è¿‘çš„Kä¸ªï¼ŒæŠ•ç¥¨ å½“Kå¢žåŠ çš„æ—¶å€™ï¼Œæ•´ä¸ªå›¾ç‰‡çš„è¾¹ç¼˜å˜å¾—å¹³æ»‘äº† Kçš„æ•°é‡ä¹Ÿæ˜¯ä¸€ä¸ªhyperparameter éœ€è¦é€‰æ‹©çš„hyperï¼ˆå¹¶ä¸èƒ½å¾ˆå¥½çš„æ‰¾åˆ°æœ€ä¼˜è§£ï¼‰ K ç”¨ä»€ä¹ˆdistance å¦‚ä½•é€‰æ‹©æœ€å¥½çš„å‚æ•° æ€»ä¸èƒ½å°è¯•æ‰€æœ‰çš„å‚æ•°å§2333 ä¸èƒ½ä½¿ç”¨test dataï¼Œè¯·åœ¨è®­ç»ƒçš„æ—¶å€™å¿˜è®°è‡ªå·±æ‹¥æœ‰å®ƒ æŠŠtrain data foldæˆä¸åŒçš„éƒ¨åˆ†ï¼ŒæŠŠå…¶ä¸­çš„ä¸€éƒ¨åˆ†å½“æˆæµ‹è¯•æ•°æ®ï¼ˆvalidation dataï¼‰ï¼Œç„¶åŽæµ‹è¯•è®­ç»ƒçš„ç»“æžœå¯»æ‰¾hyper äº¤å‰éªŒè¯ï¼ˆcross-validationï¼‰ï¼Œå¾ªçŽ¯å½“validation foldç„¶åŽaverage result ä½†æ˜¯æ ¹æœ¬ä¸ç”¨å‘¢ åœ¨test timeçš„performanceå¤ªå·®äº† ä¸¤ä¸ªå›¾ç‰‡ä¹‹é—´çš„è·ç¦»å¤ªä¸ç›´è§‚äº†ï¼Œä½ æ ¹æœ¬ä¸çŸ¥é“å›¾ç‰‡é—´çš„è·ç¦»ä¼šæ€Žä¹ˆå˜ linear classificationparametric approach è¾“å…¥ï¼š32x32x3çš„å›¾ç‰‡ï¼Œarray of numbers 0,1,â€¦3072 f(x,W) = Wx + b ï¼ˆåœ¨çº¿æ€§åˆ†ç±»çš„æƒ…å†µä¸‹ï¼‰ ï¼ˆ10x1ï¼‰ x: image ï¼ˆ3072x1 -&gt; æ‹‰ç›´äº†ï¼‰ W: parametersï¼Œweights ï¼ˆ10x3027ï¼‰ bï¼š bias ï¼ˆ10x1ï¼‰ï¼Œä¸æ˜¯è¿™ä¸ªå‡½æ•°çš„å‚æ•°ï¼Œåªæ˜¯ç”¨æ¥å†³å®šæ¯”å¦‚çŒ«çš„æ•°é‡ç‰¹åˆ«å¤šï¼Œåå‘çŒ«çš„biaså¯èƒ½å°±æ¯”è¾ƒå¤§ è¾“å‡ºï¼š10ä¸ªæ•°å­—ï¼Œè¡¨ç¤ºæ¯ä¸ªclassçš„scores æ³¨æ„ Wæ˜¯æŠŠä¸åŒåˆ†ç±»çš„classiferæ‹¼åœ¨äº†ä¸€èµ·ï¼ˆä¹é«˜ä¸€æ ·ï¼‰ï¼Œæ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªä¸åŒçš„classçš„åˆ†ç±»å™¨ï¼Œç‚¹ä¹˜è¿™ä¸ªå›¾ç‰‡ä¸Šé¢çš„åƒç´ ï¼ŒåŠ ä¸Šbiaså°±æ˜¯è¿™ä¸ªå›¾ç‰‡æœ€ç»ˆçš„å¾—åˆ† resizeæ‰€æœ‰çš„å›¾ç‰‡åˆ°ä¸€ä¸ªå¤§å°ï¼ˆç›®å‰ï¼‰ å®žé™…ä¸Šæ¯ä¸ªclassçš„scoreå°±æ˜¯å›¾ç‰‡é‡Œé¢æ¯ä¸ªç‚¹çš„åŠ æƒæ±‚å’Œï¼Œå¯ä»¥æƒ³è±¡æˆåœ¨æ•°æ¯ä¸ªä¸åŒåœ°æ–¹çš„ç‚¹çš„é¢œè‰²ã€‚å¦‚æžœæŠŠWçŸ©é˜µè¿˜åŽŸï¼Œè¿˜åŽŸå‡ºæ¥çš„å°±æ˜¯è¿™ä¸ªclassçš„æ„Ÿè§‰ä¸Šçš„é¢œè‰² å¯ä»¥æƒ³è±¡åœ¨ä¸€ä¸ªå·¨é«˜dçš„spaceé‡Œé¢ï¼Œç”¨çº¿æ€§åˆ†ç±» hard part éƒ½ç”¨ç°åº¦å›¾ä¼šæœ‰é—®é¢˜ ç›¸ä¼¼çš„textureï¼ˆï¼Ÿ loss function optimizationtodoï¼š å®šä¹‰ä¸€ä¸ªloss functionæ¥å®šä¹‰è¿™ä¸ªscoreçš„å¥½å æ‰¾åˆ°ä¸€ä¸ªefficiently wayåŽ»æ‰¾åˆ°minimize è¿™ä¸ªloss SVM losså®šä¹‰ å‡è®¾å¦‚æžœåªæœ‰ä¸‰ä¸ªç§ç±»ï¼Œä¸€å¼ å›¾ç‰‡å¯¹ä¸‰ä¸ªclassåˆ†åˆ«ä¼šæœ‰ä¸åŒçš„scoreã€‚æ¯å¼ å›¾ç‰‡éƒ½å¯ä»¥è®¡ç®—å‡ºä¸€ä¸ªå¯¹åº”çš„loss SVM loss Li = sum maxï¼ˆ0ï¼Œsj - si + 1ï¼‰ si: æƒ³è¦è®¡ç®—è¿™ä¸ªçš„loss function çš„classçš„è¯„åˆ†ï¼ˆä¹Ÿå°±æ˜¯labelæ ‡æ³¨çš„classçš„è¯„åˆ†ï¼‰ sj: è¿™å¼ å›¾å¯¹äºŽæ‰€æœ‰å…¶ä»–ç§ç±»ï¼ˆé™¤äº†iï¼‰çš„è¯„åˆ† Li: æœ€ç»ˆè¿™å¼ å›¾ç‰‡çš„loss 1: æ˜¯ä¸€ä¸ªsafety marginï¼ˆä¹Ÿæ˜¯ä¸€ä¸ªhyper parameterï¼‰ã€‚å¯ä»¥é€‰æ‹©å…¶ä»–æ­£æ•°ï¼Œä½†æ˜¯é€‰0ä¼šå‡ºé—®é¢˜ Liçš„æ¯ä¸€é¡¹éƒ½åœ¨0å’Œå·®å€¼ä¹‹é—´æ‰¾æœ€å¤§å€¼ï¼Œç„¶åŽæŠŠæ¯ä¸€é¡¹çš„åŠ èµ·æ¥æ±‚å’Œ å¦‚ä½•ç†è§£è¿™ä¸ªå¼å­ï¼šæ—¢ç„¶å¯¹äºŽä¸åŒclassçš„è¯„åˆ†è¶Šé«˜å°±æ˜¯è¶Šå¯èƒ½ï¼Œé‚£ä¹ˆè¯„åˆ†æ˜¯è´Ÿæ•°çš„è¯å°±è¯´æ˜Žä¸å¯èƒ½ï¼Œè¿™æ ·å°±ç›´æŽ¥ç”¨0æŠŠè¿™ç§å¯èƒ½æ€§æŠ¹åŽ»äº†ã€‚å¦‚æžœå…¶ä»–ç§ç±»åœ¨æ­£çš„æ–¹é¢è¯„åˆ†è¶Šé«˜ï¼Œè¯´æ˜Žè¿™ä¸ªç§ç±»è·‘åäº†ï¼Œlossè¶Šå¤§ ###æ³¨æ„ç‚¹ åœ¨ä¸Šé¢è¿™å¼ å›¾é‡Œï¼Œå› ä¸ºè½¦çš„è¯„åˆ†å·²ç»æ˜¯æœ€é«˜äº†ï¼Œè®¡ç®—å‡ºæ¥çš„losså°±æ˜¯0 æœ€åŽå†æŠŠæ‰€æœ‰ç±»åž‹çš„lossæ±‚å’Œï¼Œé™¤ä»¥ç§ç±»å¾—åˆ°æœ€ç»ˆçš„loss ç”¨çš„æ˜¯æ±‚å’Œè€Œä¸æ˜¯meanä¹Ÿæ˜¯å–å†³äºŽè‡ªå·±çš„å†³å®š ä¹Ÿæœ‰çš„SVMé‡Œé¢ç”¨çš„æ˜¯maxä¹‹åŽå¹³æ–¹ï¼Œä½†æ˜¯ä¸å¹³æ–¹çš„ç”¨çš„æ›´å¤šä¸€ç‚¹ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªhyper parameter scale æœ€å°ï¼š0 æœ€å¤§ï¼šinfinite bug åœ¨å®žé™…åº”ç”¨é‡Œé¢æ²¡æœ‰é‚£ä¹ˆå¥½çš„æ•ˆæžœ Wä¸æ˜¯å”¯ä¸€çš„ï¼Œæ¯”å¦‚æŠŠè¿™ä¸ªWåŠ å€ï¼Œå¦‚æžœlossæ˜¯0çš„æ—¶å€™æ˜¯ä¸€æ ·çš„ -&gt; éœ€è¦å¾—åˆ°å”¯ä¸€çš„W weight regularizationï¼ˆè§£å†³ä¸Šé¢è¿™ä¸ªé—®é¢˜ï¼‰ åœ¨ä¹‹å‰çš„lossçš„åŸºç¡€ä¸ŠåŠ ä¸Šäº† \lambda R(W) \lambdaæ˜¯ä¸€ä¸ªhyper parameterï¼Œæ˜¯å–å†³äºŽè‡ªå·±çš„é€‰æ‹©çš„ Ræ˜¯ä¸€ä¸ªregularizationå‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯æŠµæŠ—ä¹‹å‰çš„lossã€‚å› ä¸ºä¹‹å‰çš„lossæ˜¯ä»Žè®­ç»ƒé›†ä¸Šå¾—åˆ°çš„ï¼Œæ¯”è¾ƒå»åˆè®­ç»ƒé›†ï¼Œæ‰€ä»¥éœ€è¦ä¸€ä¸ªæ¯”è¾ƒç‰¹åˆ«çš„Wæ¥å’Œä¹‹å‰çš„fightï¼Œè¿™æ ·çš„è¯ç»“æžœå¯èƒ½ä¼šåœ¨å®žé™…ä½¿ç”¨çš„æ—¶å€™æ›´å¥½ä¸€äº› ä¸»è¦åˆ†ç±» L2 regularizationï¼šWé‡Œé¢çš„æ‰€æœ‰é¡¹å¹³æ–¹ç„¶åŽæ±‚å’Œï¼ˆæœ€å¸¸è§ï¼‰ L1 regularizationï¼šWé‡Œé¢æ‰€æœ‰é¡¹ç»å¯¹å€¼ç„¶åŽæ±‚å’Œ -&gt; åœ¨ä¸€äº›å…¶ä»–åœ°æ–¹ä½¿ç”¨ elastic netï¼ˆL1+L2ï¼‰ï¼šæ‰€æœ‰é¡¹å¹³æ–¹ä¹˜å‚æ•°åŠ ç»å¯¹å€¼æ±‚å’Œ max norm regularization -&gt; åŽé¢è®² dropout ç†è§£L2 æ¯”å¦‚Xæ˜¯[1,1,1,1],ä¸¤ä¸ªWåˆ†åˆ«æ˜¯[1,0,0,0]å’Œ[0.25,0.25,0.25,0.25] è¿™æ ·ä¹˜å‡ºæ¥çš„æœ€ç»ˆç»“æžœéƒ½æ˜¯ä¸€æ ·çš„ï¼Œéƒ½æ˜¯1ã€‚ ä½†æ˜¯å¦‚æžœåŠ ä¸Šäº†L2çš„regularizationä¹‹åŽå°±å‘çŽ°ç¬¬äºŒç§æ–¹æ³•çš„lossæ›´å°‘ä¸€ç‚¹ã€‚å› ä¸ºä»–ç”¨åˆ°äº†æ›´å¤šçš„ç»´æ•°ï¼Œåœ¨å®žé™…åº”ç”¨ä¹‹ä¸­æ•ˆæžœæ›´å¥½ã€‚ softmaxï¼ˆç”¨èµ·æ¥æ›´å¥½ï¼‰ï¼ˆmultinomial logistic regressionï¼‰å®šä¹‰ scoresï¼šunnormalized log probabilities of the class éœ€è¦æŠŠscoreå…ˆexpå›žæ¥(è¿™æ ·æ‰€æœ‰çš„æ•°éƒ½å˜æˆæ­£æ•°äº†) å†normalizeï¼ˆé™¤ä»¥æ‰€æœ‰expä¹‹åŽçš„çš„å’Œï¼‰ æœ€ç»ˆï¼Œå¯¹äºŽæ­£ç¡®classçš„æœ€ç»ˆå¤„ç†å®Œçš„scoreæ¥è¯´ï¼Œmaxè¿™ä¸ªlogæˆ–è€…minï¼ˆloss functionï¼‰- logä¼šå¾—åˆ°æœ€ç»ˆæœ€å¥½çš„ç»“æžœ æœ€ç»ˆå¤„ç†å®Œçš„scoreå°±æ˜¯æ¯ä¸ªç±»åž‹æŽ¨æµ‹å‡ºæ¥çš„å æ¯”å¯èƒ½æ€§ï¼ˆå’Œä¸º1ï¼‰ è¿™é‡Œæ±‚å®Œ-logï¼ˆpï¼‰å…¶å®žå°±æ˜¯ä¿¡æ¯ç†µï¼Œä»£è¡¨å¯¹ä¸ç¡®å®šåº¦çš„åº¦é‡ ç›´æŽ¥æ¯”è¾ƒå¯èƒ½æ€§å’Œlogä¹‹åŽæ¯”è¾ƒå¯èƒ½æ€§åœ¨æœ¬è´¨ä¸Šæ˜¯æ²¡æœ‰åŒºåˆ«çš„ ä½†æ˜¯æ•°å­¦ä¸Šä¸€èˆ¬logä¹‹åŽçš„æ•°æ®ä¼šçœ‹èµ·æ¥å¥½ä¸€äº›å®žé™…æ“ä½œå¦‚ä¸‹ ä¸€äº›é—®é¢˜ æžå€¼ Liæœ€å°å€¼ï¼š0 -&gt; å¦‚æžœæ­£ç¡®ç±»åž‹çš„å¯èƒ½æ€§æ˜¯1ï¼Œæ±‚å‡ºæ¥çš„æœ€ç»ˆå€¼å°±æ˜¯0 Liæœ€å¤§å€¼ï¼šinfiniteï¼Œå¯èƒ½æ€§éžå¸¸ä½Žéžå¸¸æŽ¥è¿‘äºŽ0 å½“Wçš„åˆå§‹åŒ–å¾ˆå°ï¼Œæ‰€æœ‰scoreéƒ½æŽ¥è¿‘äºŽ0ï¼š scoreæ±‚expä¹‹åŽéƒ½æ˜¯1ï¼Œnormalizeä¹‹åŽæ˜¯1/numï¼ˆclassï¼‰ï¼Œæœ€åŽå†æ±‚log å¯ä»¥ç”¨äºŽå¼€å¤´çš„æ£€éªŒ SVMå’Œsoftmax å¦‚æžœè¾“å…¥æ˜¯[10,-100,-100]ï¼Œåœ¨è¿™ä¸ªèŒƒå›´é‡Œå¾®å°å˜åŒ–ï¼Œç¬¬ä¸€ä¸ªæ˜¯æ­£ç¡®çš„class å¯¹äºŽSVMæ¥è¯´ï¼ŒåŽé¢ä¸¤ä¸ªè´Ÿå€¼éƒ½éžå¸¸å°äº†ï¼Œæ ¹æœ¬ä¸ä¼šåŽ»ç®¡åŽé¢çš„ä¸¤ä¸ªä¸œè¥¿ï¼Œ-100å’Œ-200æ²¡å•¥åŒºåˆ« å¯¹äºŽsoftmaxæ¥è¯´ï¼ŒåŽé¢çš„-100è¿˜æ˜¯-200è¿˜æ˜¯ä¼šå¯¹lossæœ€ç»ˆçš„å€¼äº§ç”Ÿå½±å“ï¼Œsoftmaxå¸Œæœ›æ‰€æœ‰çš„å€¼éƒ½åœ¨æ­£ç¡®çš„classä¸Šé¢ï¼ŒåŽé¢å•¥éƒ½æ²¡æœ‰ã€‚æ‰€ä»¥æ›´å…·æœ‰robustnessã€‚ SVMä¼šæœ‰ä¸€ä¸ªä½ éœ€è¦çš„åŒºåŸŸï¼Œå‰©ä¸‹çš„æ ¹æœ¬ä¸è€ƒè™‘ï¼›è€Œsoftmaxä¼šè€ƒè™‘æ‰€æœ‰çš„åŒºåŸŸ ä¸Šæ–¹åŒºåŸŸæ€»ç»“ xï¼šè®­ç»ƒé›†é‡Œé¢çš„æ•°æ®ï¼Œæ”¾åœ¨å›¾ç‰‡é‡Œå°±æ˜¯æŠŠä¸€ä¸ªå›¾ç‰‡æ‹‰æˆä¸€ä¸ª1xNçš„å‘é‡ yï¼šè®­ç»ƒé›†çš„æ ‡ç­¾ï¼Œç”¨æ¥å’Œæœ€ç»ˆçš„ç»“æžœæ¯”å¯¹ W: weightsï¼Œéœ€è¦ä¼˜åŒ–çš„éƒ¨åˆ† Lï¼šlossï¼Œç”¨æ¥æƒè¡¡Wä¼˜åŒ–ç»“æžœçš„å¥½å åŸºæœ¬è¿‡ç¨‹ Wx+bå¾—åˆ°ç›®å‰çš„åˆ†ç±»å™¨çš„scoreï¼ˆscore functionï¼‰ yæ˜¯ç›®å‰åˆ†ç±»åº”è¯¥æœ‰çš„ç»“æžœï¼ˆlabelï¼‰ Rï¼ˆWï¼‰å¾—åˆ°regularzationçš„å€¼ åˆ†ç±»å™¨å¾—åˆ°scoreï¼ŒyçŸ¥é“æ­£ç¡®çš„åˆ†ç±»ï¼Œé€šè¿‡softmaxæˆ–è€…SVMå¾—åˆ°è¿™ä¸ªåˆ†ç±»å™¨ç›®å‰çš„lossï¼Œå†åŠ ä¸ŠRï¼ˆWï¼‰çš„éƒ¨åˆ†å¢žåŠ robustnessæœ€ç»ˆå¾—åˆ°æ•´ä¸ªåˆ†ç±»å™¨çš„loss optimization lossfollow the slope é€šè¿‡è®¡ç®—gradientæ¥æ‰¾åˆ°æœ€ä½Žç‚¹ æœ€åŸºç¡€çš„æƒ³æ³•ï¼šï¼ˆä»Žæ•°å­¦ä¸Šå…¥æ‰‹ï¼‰ å› ä¸ºæ¢¯åº¦æ˜¯lim f(x+,h)-f(x)/h æŠŠWä¸Šé¢çš„æ¯ä¸€ä¸ªç‚¹éƒ½åŠ ä¸Šä¸€ä¸ª0.00001ï¼ˆæŽ¥è¿‘äºŽ0ï¼‰ç„¶åŽå†æ±‚ä¸Šé¢çš„å¼å­ï¼Œå°±èƒ½å¾—åˆ°ç¬¬ä¸€æ¬¡æ“ä½œçš„æ¢¯åº¦ silly æ¯ä¸€æ­¥éƒ½éœ€è¦æ¯ä¸€ä¸ªç»´åº¦éƒ½ç®—ä¸€ä¸‹ï¼Œåœ¨CNNé‡Œé¢å‚æ•°é«˜è¾¾ç™¾ä¸‡ä¸ªï¼Œè®¡ç®—å¤ªæ…¢äº† å› ä¸ºç”¨çš„0.00001ï¼Œå…¶å®žå¹¶ä¸å‡†ç¡® æ„Ÿè°¢ç‰›é¡¿èŽ±å¸ƒå°¼å…¹å‘æ˜Žäº†å¾®ç§¯åˆ† -&gt; å¦‚ä½•å…·ä½“è®¡ç®—åœ¨ä¸‹ä¸€èŠ‚è¯¾ æŠŠlossçš„gradientæ”¹æˆäº†ä¸€ä¸ªå¼å­ å¿«é€Ÿï¼Œå‡†ç¡®ï¼Œç„¶æ˜¯å®¹æ˜“å‘ç”Ÿbugï¼ˆerror-proneï¼‰ practiceéœ€è¦è¿›è¡Œgradient check åœ¨å†™ä»£ç çš„æ—¶å€™ç”¨çš„è‚¯å®šéƒ½æ˜¯analytic gradient ä½†æ˜¯éœ€è¦åœ¨åº”ç”¨ä¹‹å‰ç”¨numerical gradientæ£€æŸ¥ä¸€ä¸‹ï¼Œç¡®ä¿ä¸¤è€…çš„ç»“æžœæ˜¯ä¸€æ ·çš„ï¼Œä¸ºäº†ä¿è¯ä»£ç é‡Œé¢å†™çš„ç§¯åˆ†æ˜¯æ­£ç¡®çš„ gradient descent mini-batch åœ¨å®žé™…åº”ç”¨çš„æ—¶å€™ï¼Œä¸ä¼šæŠŠæ•´ä¸ªçš„è®­ç»ƒé›†éƒ½æ‹¿æ¥ä¼˜åŒ–Wï¼Œè€Œæ˜¯ä¼šæŠŠä¸€éƒ¨åˆ†æ‹¿å‡ºæ¥ï¼ˆsample examplesï¼‰ ä¸€å°ç‚¹ä¸€å°ç‚¹çš„æ‹¿ç»“æžœä¸ä¼šéžå¸¸å‡†ç¡®ï¼Œä½†æ˜¯å¯ä»¥stepå¾ˆå¤šæ¬¡ï¼Œåœ¨å®žé™…åº”ç”¨é‡Œé¢ä¸€èˆ¬éƒ½ä¸ä¼šç”¨æ•´ä¸ªtraining setï¼Œä¸æ˜¯å¾ˆçŽ°å®žè€Œä¸”æ•ˆæžœä¸æ˜¯å¾ˆå¥½ã€‚ é€‰æ‹©çš„æ•°é‡ä¸Š 32/64/256ï¼Œè¿™ä¸ªä¸æ˜¯ä¸€ä¸ªå¾ˆé‡è¦çš„hyperparameterï¼Œä¸»è¦æ˜¯æ ¹æ®GPUçš„æ€§èƒ½æ¥å†³å®šçš„ æœ€ç»ˆç»“æžœçš„lossæ˜¯ä¼šä¸‹é™çš„ï¼Œè™½ç„¶noiseå¾ˆå¤šä½†æ˜¯æœ€ç»ˆä¼šgo dowm learning rate å›¾ç‰‡ä¸­ä½¿ç”¨linear classifierå› ä¸ºå›¾ç‰‡åƒç´ å¤ªå¤šäº†ï¼Œä¸å¯èƒ½å¯¹æ¯ä¸ªåƒç´ éƒ½ç”¨çº¿æ€§åˆ†ç±»ï¼Œæ‰€ä»¥ä¸€èˆ¬ä¼šå…ˆæå–ä¸€äº›ç‰¹å¾ç„¶åŽå¾—åˆ°æœ€ç»ˆçš„åˆ†ç±»ç»“æžœ color histogram å…ˆå¾—åˆ°ä¸€å¼ å›¾ç‰‡çš„é¢œè‰²ç‰¹å¾åˆ†å¸ƒ ç„¶åŽæŠŠæ•´ä¸ªç‰¹å¾åˆ†å¸ƒæ‹½æˆä¸€ä¸ªé•¿çš„vectorè¿›è¡Œåˆ†ç±» HOG/SIFT æ‰¾åˆ°è¾¹ç¼˜ç‰¹å¾ï¼Œåœ¨å›¾ç‰‡çš„å“ªä¸ªéƒ¨åˆ†æœ‰é‚£ç§æ ·å­çš„edge bag of words å…ˆæŠŠå›¾ç‰‡é‡Œé¢çš„ä¸€äº›ç‰¹å¾å½“ä½œä¸€ä¸ªvocabularyï¼Œç„¶åŽæ”¾è¿›ä¸€ä¸ªè¯å…¸é‡Œé¢ æ‰¾åˆ°è¯å…¸é‡Œæ¯ä¸ªè¯å‡ºçŽ°çš„é¢‘çŽ‡ç„¶åŽæ‹½æˆvector çº¿æ€§åˆ†ç±» æ€»ç»“ä¸€èˆ¬éƒ½æ˜¯å…ˆè¿›è¡Œç‰¹å¾æå–ç„¶åŽå†è¿›è¡Œçº¿æ€§åˆ†ç±» æ·±åº¦å­¦ä¹ ç‰¹å¾éƒ½æ˜¯è‡ªå·±æå– Backpropagation &amp; neural networkç›®çš„ï¼šæ±‚å‡ºæ¥loss functionçš„gradient backpropagationæœ€å³è¾¹çš„ç‚¹å› ä¸ºæ˜¯df/dfæ‰€ä»¥ç»“æžœå°±æ˜¯1 forward passï¼šçŸ¥é“å¼€å§‹ç„¶åŽä¸€ç›´é¡ºåˆ°ç»“æŸ åœ¨ä¸€ä¸ªnodeä¸Šé¢ï¼Œæ”¶åˆ°äº†xå’Œyçš„inputï¼Œå¯¹ä»–ä»¬è¿›è¡Œfæ“ä½œï¼Œå¾—åˆ°æœ€ç»ˆçš„ç»“æžœz zå†å¾€åŽæ“ä½œå¾—åˆ°æœ€åŽçš„lossï¼ˆä¸çŸ¥é“ä»€ä¹ˆæ“ä½œï¼‰ backward passï¼šä»ŽåŽåˆ°å‰ï¼Œé€šè¿‡é“¾å¼æ³•åˆ™å€’å›žæ¥ è™½ç„¶ä¸çŸ¥é“losså¯¹xæˆ–è€…yçš„gradientï¼Œä½†æ˜¯å¯ä»¥æ±‚å‡ºæ¥dz/dxå’Œdz/dyï¼ˆåªå’Œè¿™ä¸ªç‚¹æœ‰å…³ï¼‰ å¯ä»¥å¾—åˆ°dL/dzï¼Œç„¶åŽä¹˜ä»¥local gradient local gradient æ¯ä¸€ä¸ªnodeä¸Šé¢çš„gradientå¾€å‰æŽ¨çš„æ—¶å€™ï¼Œéƒ½å¯ä»¥é€šè¿‡é“¾å¼æ³•åˆ™ï¼ˆchain ruleï¼‰å˜æˆè¿™ä¸ªç‚¹è¾“å…¥çš„gradientå’Œè¿™ä¸ªç‚¹åˆ°ä¸Šä¸€ä¸ªç‚¹çš„gradientçš„ä¹˜ç§¯ã€‚ ç®—localçš„æ—¶å€™ï¼Œä¹˜çš„å‚æ•°æ˜¯è¾“å…¥è¿›åŽ»çš„å‚æ•°å•Šã€‚æ¯”å¦‚dL/dx = dL/dzï¼ˆè¿™ä¸ªå¸¦è¿™ä¸ªç‚¹backå›žæ¥çš„æ•°å­—ï¼‰ * dz/dx ï¼ˆè¿™ä¸ªé‡Œé¢çš„xå¸¦è¿™ä¸ªç‚¹è¾“å…¥è¿›æ¥xçš„å€¼ï¼‰ æƒ³ä¸æ˜Žç™½çš„æ—¶å€™æŠŠä¸åŒçš„ç‚¹å‡è®¾æˆä¸åŒåå­—ç„¶åŽæ±‚å¯¼ï¼ åœ¨è¿™ä¸ªç½‘ç»œé‡Œé¢ï¼Œå¦‚æžœgateæ˜¯åŠ æ³•ï¼ˆx + yï¼‰çš„è¯ä¸æ˜¯æ±‚åå¯¼ï¼Œå¦‚æžœæ±‚xçš„å¯¼æ•°çš„è¯yå¹¶ä¸æ˜¯å‚æ•°è€Œæ˜¯å¸¸æ•°ï¼Œæ‰€ä»¥æ±‚å‡ºæ¥çš„ç»“æžœæ˜¯1ï¼Œæ‰€ä»¥åŠ æ³•çš„gateå°±æ˜¯ç›´æŽ¥æŠŠè¿™ä¸ªå€¼ç›¸ç­‰çš„åˆ†å¼€ åŠ gateæ˜¯ä¸€ä¸ªgradient distributorï¼Œå½“ä¸€ä¸ªgradientè¿›æ¥çš„æ—¶å€™ä¼šè¢«ç›¸åŒçš„åˆ†å¼€æˆäº†ä¸¤ä»½ ä¹Ÿå¯ä»¥æŠŠä¸€äº›gateç»„æˆä¸€ä¸ªå¤§çš„gateï¼Œæ¯”å¦‚sigmoid æ³¨æ„ï¼Œæ±‚å‡ºæ¥çš„gradientå¦‚æžœæ˜¯æ­£çš„ï¼Œè¯´æ˜Žè¿™ä¸ªç‚¹å¯¹æœ€ç»ˆçš„lossæœ‰positiveçš„ä½œç”¨ patterns addï¼šgradient distributor maxï¼šrouter å‡è®¾fæ˜¯maxï¼ˆxï¼Œyï¼‰ local gradientå¯¹æœ€å¤§çš„é‚£ä¸ªå°±æ˜¯1ï¼Œå¯¹å…¶ä»–çš„éƒ½æ˜¯0 å› ä¸ºå¦‚æžœæ²¡èƒ½é€šè¿‡maxçš„gateçš„è¯æ ¹æœ¬å¯¹åŽé—¨çš„lossæ²¡æœ‰å½±å“ã€‚backçš„æ—¶å€™èµ°æœ€å¤§çš„ç‚¹å°±å¯ä»¥äº†ï¼Œå…¶ä»–çš„éƒ½ä¸ç”¨ç®¡äº† multiplyï¼šswitcherï¼ŒçœŸï¼Œä¸¤æžåè½¬ å½“å¾€å›žçš„æ—¶å€™ï¼Œä¸¤ä¸ªç‚¹æŒ‡å‘ä¸€ä¸ªç‚¹ï¼Œgradientéœ€è¦ç›¸åŠ ï¼ˆå¦‚ä¸‹å›¾ï¼‰ Implementationpsuedocode graph or net object forward: æŠŠinput passè¿›è¿™ä¸ªgateé‡Œé¢ï¼ˆå¿…é¡»åœ¨ä»£ç é‡Œé¢è®°ä½inputï¼‰ æŠŠæ•´ä¸ªcomputationalçš„garphå¾€å‰æŽ¨åŠ¨ æœ€åŽä¸€ä¸ªgateä¼šreturnè¿™ä¸ªç½‘ç»œçš„loss backward è¾“å…¥dzï¼Œç„¶åŽä¹˜ä¸åŒçš„xå’Œy ä¸åŒçš„gateåˆ†åˆ«æ˜¯ä¸åŒçš„æ–‡ä»¶ï¼ˆAPIï¼‰ï¼Œæ¯ä¸ªæ–‡ä»¶é‡Œé¢åŒ…æ‹¬åˆå§‹åŒ–ï¼Œforwardå’Œbackward æ¯æ¬¡updateçš„æ—¶å€™éƒ½éœ€è¦è¿›è¡Œforwardå’Œbackwardï¼Œforwardå¾—åˆ°gradientï¼Œbackwardå†å›žæ¥æ±‚æœ€ç»ˆçš„loss vectorized åœ¨å®žé™…çš„è®¡ç®—ä¸­xï¼Œyï¼Œzéƒ½æ˜¯çŸ©é˜µï¼Œdz/dxæ˜¯jacobiançŸ©é˜µï¼ˆå…¨éƒ¨éƒ½ç”±åå¯¼ç»„æˆçš„çŸ©é˜µï¼‰ æ¯”å¦‚ä¸€ä¸ªmaxçš„é—¨ï¼Œå¦‚æžœè¾“å…¥æ˜¯1x4096ï¼Œè¾“å‡ºä¹Ÿæ˜¯1x4096ï¼Œä½†æ˜¯æ±‚åå¯¼å‡ºæ¥çš„çŸ©é˜µæ˜¯4096x4096ï¼ˆå¤ªå¤§äº†ï¼‰ï¼ŒçŸ©é˜µä¸­é—´åªæœ‰å¯¹è§’çº¿éƒ¨åˆ†çš„æ˜¯éœ€è¦è€ƒè™‘çš„ï¼ˆè¿˜ä¼šæœ‰å¾ˆå¤š0ï¼‰ ç„¶åŽå¦‚æžœç”¨äº†minibatchçš„100ï¼Œå¾—åˆ°çš„ç»“æžœå°±æ˜¯409600äº†ï¼Œæ›´å¯æ€•äº† æ‰€ä»¥åœ¨æ¯æ¬¡APIçš„æ—¶å€™ï¼Œè‚¯å®šä¸èƒ½å†™å‡ºæ¥æ‰€æœ‰çš„é“¾å¼æ³•åˆ™ï¼Œåªç”¨å…¶ä¸­çš„ä¸€éƒ¨åˆ† ä½œä¸šçš„é‡ç‚¹å°±æ˜¯å¦‚ä½•è®©è¿™ä¸ªä¸œè¥¿è®¡ç®—å‡ºæ¥æ•ˆçŽ‡é«˜ neural networkä¸¤å±‚çš„NN è¾“å…¥æ˜¯å›¾ç‰‡ä¸€å…±çš„åæ ‡æ•°é‡ å…ˆé€šè¿‡ç¬¬ä¸€å±‚ï¼ˆmaxï¼‰å¾—åˆ°100çš„ä¸­é—´å±‚ï¼ˆhidden layerï¼‰-&gt; 100æ˜¯hyperparameterï¼Œè‡ªå·±å®šçš„ï¼Œä½†æ˜¯è¶Šå¤šè¶Šå¥½å§ ç„¶åŽé€šè¿‡W2å¾—åˆ°æœ€ç»ˆçš„åˆ†ç±»ç»“æžœï¼ˆåˆ†10ç±»ï¼‰ å…¶å®žå…·ä½“é‡Œé¢æ˜¯ä»€ä¹ˆä¸œè¥¿çœŸçš„æ˜¯ä¸çŸ¥é“çš„ï¼Ÿ ç¥žç»å…ƒ æ¯ä¸ªç¥žç»å…ƒçš„è¾“å…¥æ˜¯Wx+bï¼Œç„¶åŽç»è¿‡æ¿€æ´»å‡½æ•° è¾“å‡º æ¿€æ´»å‡½æ•° activation function sigmoid tanh ReLU å±‚çŠ¶ -&gt; å¯ä»¥æ›´åŠ efficient Neural network 2ï¼ˆtraining part1ï¼‰å‰æ–¹æç¤ºï¼š å°çš„datasetä¹Ÿå¯ä»¥æœ‰ç»“æžœ ç”µè„‘çš„æ€§èƒ½æœ‰é™ å›žé¡¾ä¸€ä¸‹åŽ†å² perceptron -&gt; æ¿€æ´»å‡½æ•°ï¼š0æˆ–è€…1ï¼Œä¸èƒ½back madalineÂ·Â·Â· activation functionï¼ˆä¸€ä¸ªhyerparameterï¼‰sigmoid ç‰¹ç‚¹ï¼š æŠŠæ‰€æœ‰çš„æ•°å€¼éƒ½åŽ‹åˆ°äº†0åˆ°1ä¹‹é—´ æ›¾ç»éžå¸¸å—æ¬¢è¿Žï¼Œå› ä¸ºsatratingçš„æ•ˆæžœæ¯”è¾ƒå¥½ é—®é¢˜ï¼š åœ¨saturateçš„æƒ…å†µä¸‹ï¼ˆéžå¸¸æŽ¥è¿‘0æˆ–è€…1ï¼‰ï¼Œä¼šæ€æ­»gradent -&gt; çœ‹å‡½æ•°çš„å›¾å°±èƒ½æ„Ÿè§‰å‡ºæ¥-10åšå“Ÿçš„å¯¼æ•°å°±æ˜¯0äº†ï¼Œbackå›žæ¥æ²¡æœ‰æ„ä¹‰ outputä¸æ˜¯ä»¥0ä¸ºä¸­å¿ƒçš„ï¼ˆé¢„å¤„ç†çš„æ—¶å€™å¸Œæœ›æ˜¯0ä¸­å¿ƒçš„ï¼‰ ä¸æ˜¯0ä¸­å¿ƒçš„é—®é¢˜ï¼šå¦‚æžœæ‰€æœ‰è¾“å…¥çš„xéƒ½æ˜¯positiveçš„è¯ï¼Œå¾—åˆ°çš„gradientè¦ä¸éƒ½æ˜¯positiveè¦ä¸éƒ½æ˜¯negative æœ€åŽèµ°å‡ºæ¥çš„è·¯å¾„éƒ½æ˜¯zig zagçš„ expï¼ˆï¼‰åœ¨è®¡ç®—ä¸Šæ¯”è¾ƒexpensive tanh æŠŠæ•°å­—ä»Ž-1åˆ°1ä¹‹é—´åˆ†å¸ƒï¼Œæ˜¯ä¸€ä¸ªä»¥0ä¸ºä¸­å¿ƒçš„sigmoidï¼ˆ0-centeredï¼‰ï¼Œæ‰€ä»¥sigmoidçš„ç¼ºç‚¹ï¼ˆsaturatedçš„ç‚¹ä¼škill gradientï¼‰çš„ç¼ºç‚¹è¿˜åœ¨ ReLU è¾“å…¥æ˜¯æ­£æ•°çš„æ—¶å€™ç›´æŽ¥passè¿™ä¸ªå€¼ï¼Œè¾“å…¥æ˜¯è´Ÿæ•°çš„æ—¶å€™ç›´æŽ¥kill å¯èƒ½çš„ä¼˜ç‚¹ï¼šï¼ˆå®žé™…åº”ç”¨çš„æ—¶å€™æ•ˆæžœéžå¸¸å¥½ä½†æ˜¯å…·ä½“è§£é‡Šèµ·æ¥ä¹Ÿæ²¡æœ‰é‚£ä¹ˆçŸ¥é“ä¸ºä»€ä¹ˆï¼‰ ä¸ä¼šsaturateï¼ˆä¸ä¼šæ¶ˆå¤±gradientï¼‰ è®¡ç®—æ•ˆçŽ‡é«˜ æ›´å®¹æ˜“ç›¸äº¤ é—®é¢˜ ä¸æ˜¯0-centered å¦‚æžœxå°äºŽ0ï¼ˆæ²¡æœ‰æ¿€æ´»ï¼‰ -&gt; kill gradientï¼‰ æ­»çš„æ—¶å€™ä¼šæ­»ä¸€å¤§ç‰‡ -&gt; æ‰€ä»¥ä¸€èˆ¬çš„æ—¶å€™ä¼šæŠŠreluåˆå§‹åŒ–çš„æ—¶å€™åŠ ä¸Šä¸€ä¸ªslightly positive bias æ³¨æ„learning rateï¼Œé€‰ä¸å¥½å®¹æ˜“æ­» leaky ReLU åœ¨å°äºŽ0çš„æ—¶å€™ä¼šæœ‰ä¸€ä¸ªå¾®å°çš„å€¼ï¼Œæ‰€ä»¥ä¸ä¼šdie åœ¨ä½¿ç”¨çš„æ—¶å€™convergesçš„é€Ÿåº¦æ¯”sigmoidå’Œtanhå¿«å¾ˆå¤š åŠ ä¸Šäº†ä¸€ä¸ªå‚æ•°ï¼Œå¯ä»¥åœ¨backçš„æ—¶å€™å­¦åˆ°ï¼Œè¿™ä¸ªå€¼å¯ä»¥ç¡®å®šä»–æ˜¯ä¸æ˜¯ReLUæˆ–è€…å…¶ä»–çš„ Maxout neuron æŠŠReLUå’Œleaky ReLUç»„åˆäº†èµ·æ¥ï¼Œæœ‰ä¸¤ä¸ªå‚æ•°ã€‚ç®—å‡ºæ¥ä¸¤ä¸ªåˆ†åˆ«çš„å€¼ç„¶åŽå–å…¶ä¸­å¤§çš„é‚£ä¸ª ä¸ä¼šå‘ç”Ÿsaturateæˆ–è€…dieçš„é—®é¢˜ é—®é¢˜åœ¨äºŽå‚æ•°éœ€è¦è®¡ç®—ä¸¤æ¬¡ æ­¥éª¤ï¼š é¢„å¤„ç†æ•°æ® -&gt; é€‰æ‹©architecturedata preprocessingML å¤„ç†æ•°æ®çš„æ—¶å€™é¦–å…ˆéœ€è¦0-center -&gt; å‡åŽ»å¹³å‡å€¼ï¼ˆä¸æ˜¯ç‰¹åˆ«éœ€è¦normalizeï¼ŒMLéœ€è¦ï¼‰ PCAï¼ŒWhiteningï¼Œå…¶å®žéƒ½åœ¨DLé‡Œä¸æ€Žä¹ˆå¸¸ç”¨ å®žé™…åº”ç”¨é‡Œï¼šåªéœ€è¦center æ¯”å¦‚ä¸€å¼ å›¾æ˜¯32x32x3çš„ å‡åŽ»mean imageï¼ˆ32x32x3ï¼‰ å‡åŽ»per-channel mean ï¼ˆæ¯ä¸ªchannelçš„meanï¼Œä¸€å…±æ˜¯ä¸‰ä¸ªæ•°å­—ï¼‰ weight initializationï¼ˆé‡è¦ï¼‰è¯·ä¸è¦è¿™ä¹ˆåšï¼šsetæ‰€æœ‰wéƒ½æ˜¯0ï¼Œå¾—åˆ°çš„ç»“æžœå°±æ˜¯æ¯ä¸ªç¥žç»å…ƒçš„åŠŸèƒ½éƒ½æ˜¯ä¸€æ ·çš„ small random numbers 0.01* np.random.randn(D,H) é—®é¢˜ï¼š åœ¨æ¯”è¾ƒå°çš„neté‡Œå¯ä»¥ä½¿ç”¨ åœ¨layerä¹‹é—´ä¼šå‘ç”Ÿnon-homogeneous distribution of activationçš„é—®é¢˜ æ‰€æœ‰çš„activationsä¼šå˜æˆ0 åœ¨backçš„æ—¶å€™æ‰€æœ‰çš„gradientéƒ½ä¼šå˜æˆ0 å¦‚æžœæŠŠ0ã€‚01å˜æˆäº†1ï¼Œè¿™æ—¶å€™å‘çŽ°æ‰€æœ‰çš„neuronså…¨éƒ½æ˜¯1æˆ–è€…-1 -&gt; gradientä¹Ÿå…¨éƒ½æ˜¯0ï¼Œæ­»äº¡ å…¶ä»–çš„ä¸€äº›è®ºæ–‡ä¹Ÿè®¨è®ºè¿‡å…¶ä»–æ–¹æ³• Xavier 2010 é™¤ä»¥inputçš„sqrt ReLUï¼Œ non-liearï¼Œä¼šbreakingã€‚æ¯å›žreluéƒ½ä¼šæ€æŽ‰ä¸€åŠçš„ä¸œè¥¿ï¼Œsetåˆ°0 He 2015 æŠŠinputé™¤ä»¥2ä»¥åŽsqrtäº† åœ¨å®žè·µä¸­å¾ˆæœ‰ç”¨ batch normalization -&gt; å®žé™…ä¸­è§£å†³wåˆå§‹åŒ–çš„æ–¹æ³• æ ¸å¿ƒæ€æƒ³ï¼šxè¶Šæ¥è¶ŠæŽ¥è¿‘0çš„åŽŸå› æ˜¯å› ä¸ºè¶Šä¹˜è¶Šå°ï¼ˆæˆ–è€…è¶Šå¤§ï¼‰ï¼Œè¿™ä¸ªæ—¶å€™æˆ‘ä»¬å°±å¸Œæœ›å¯ä»¥normalizeè¿™ä¸ªxçš„inputã€‚å› ä¸ºgaussiançš„normaliztionæ˜¯å¯ä»¥ç§¯åˆ†çš„ï¼Œæ‰€ä»¥å¯ä»¥æ”¾å›žåˆ°backé‡Œé¢ï¼Œåœ¨æ•´ä¸ªçš„ç½‘ç»œé‡Œé¢æ’å…¥ä¸€äº›normalizeçš„éƒ¨åˆ†å°±å¯ä»¥äº† æ’åœ¨FCæˆ–è€…CNNä¹‹åŽï¼Œç„¶åŽæ”¾åœ¨æ¿€æ´»å‡½æ•°ä¹‹å‰ ä¼˜ç‚¹ æé«˜neté‡Œé¢çš„gradient flow å…è®¸æ›´é«˜çš„å­¦ä¹ çŽ‡ å‡å°‘å¯¹åˆå§‹åŒ–å‚æ•°çš„å½±å“ form of regularization -&gt; å¯èƒ½å¯ä»¥å‡å°‘dropoutçš„éœ€æ±‚ babysitting &amp; learning processæ£€æŸ¥lossç®—çš„å¯¹ä¸å¯¹ åˆå§‹åŒ–è¿™ä¸ªnetï¼ŒåŽ»æŽ‰regularizationï¼Œæ£€æŸ¥æœ€åŽè¿”å›žçš„loss å› ä¸ºä»€ä¹ˆéƒ½æ²¡åšå‘¢ï¼Œæ‰€ä»¥lossåº”è¯¥æ˜¯æœ€ç»ˆçŸ¥é“çš„å€¼ï¼ˆ10 classæ˜¯2ã€‚3ï¼‰ å†åŠ ä¸Šregularizationï¼Œç»“æžœåº”è¯¥å°å°çš„å˜åŒ– å°è¯•è®­ç»ƒ overfitä¸€ä¸ªéžå¸¸å°çš„datasetï¼Œå…³æŽ‰regï¼Œå¾—åˆ°éžå¸¸å°çš„losså’Œå¾ˆé«˜çš„accuracy ä¸€ä¸ªå¯èƒ½æ€§ï¼šå»ºè®®ä»¥ä¸€ä¸ªå°çš„regå¼€å§‹ï¼Œæ‰¾åˆ°è®©losså˜å°çš„learning rateï¼ˆå¦‚æžœä¸å˜å°å¯èƒ½æ˜¯rateå¤ªå°äº†ï¼‰ costï¼šNaNï¼Œå¯èƒ½æ˜¯learning rateé«˜äº† å»ºè®®èŒƒå›´ï¼š 1e-3 ~ 1e-5 hyper optimizationäº¤å‰éªŒè¯ æ‰¾åˆ°å‡†ç¡®çŽ‡é«˜çš„éƒ¨åˆ†ï¼Œä½¿ç”¨å…¶ä¸­çš„hyper æœ€å¥½setåˆ°logçš„space å†è°ƒæ•´parameterï¼Œæ‰¾åˆ°æ›´å‡†ç¡®çš„å€¼ å¦‚æžœç»“æžœç‰¹åˆ«å¥½å¯èƒ½ä¹Ÿä¸å¯¹ï¼Œå¯èƒ½æ˜¯å·²ç»åˆ°äº†boundaryäº† å‚æ•°çš„é€‰æ‹©sample randomlyçš„ç»“æžœæ›´å¥½ï¼Œä¸è¦å›ºå®šä¸€ä¸ªé€‰å¦ä¸€ä¸ªï¼Œå¯èƒ½ä¸€ä¸ªå‚æ•°æ¯”å¦å¤–ä¸€ä¸ªé‡è¦å¾ˆå¤š å¦‚æžœè®­ç»ƒå’ŒéªŒè¯ä¹‹é—´çš„gapå¤ªå¤§ï¼Œè¯´æ˜Žoverfittingï¼Œéœ€è¦å¢žåŠ regçš„åŠ›åº¦ã€‚å¦‚æžœå¤ªå°å¯èƒ½éœ€è¦å¢žåŠ modelçš„å®¹é‡ ratio between the values and updates: ~ 0.0002 / 0.02 = 0.01 (about okay) éœ€è¦é€‰æ‹©çš„hyper net architecture learning rate. decay schedule and update type regularization(L2/Dropout) ##æ€»ä½“summary training Neural Net2parameter updateSGD ä»¥å‰æ˜¯ç›´æŽ¥ç”¨gradientæ¥updateï¼ŒçŽ°åœ¨å¸Œæœ›å˜å¾—å¤æ‚ä¸€ç‚¹ -&gt; SGDå¤ªæ…¢äº† ä¸ºä»€ä¹ˆSGDå¤ªæ…¢ï¼š å¦‚æžœåœ¨ä¸€ä¸ªlossçš„åˆ†å¸ƒä¸Šï¼Œä¸€ä¸ªç»´åº¦ç‰¹åˆ«å¯†é›†ï¼Œå¦ä¸€ä¸ªç»´åº¦ç‰¹åˆ«ç¨€ç–ï¼Œç›´æŽ¥ç”¨gradientæ”¹å˜å°±ä¼šåœ¨ä¸€ä¸ªæ–¹å‘è·‘å¤§äº† æœ€åŽå°±ä¼šå½¢æˆé‚£ç§zagçš„å½¢çŠ¶ momentum update åœ¨è®¡ç®—çš„æ—¶å€™å¼•å…¥äº†é€Ÿåº¦v = mu v - learning_rate dx ï¼ˆvåˆå§‹åŒ–ä¸º0ï¼‰ å‡è®¾è·¯çº¿å°±æ˜¯ä¸€ä¸ªçƒåœ¨lossçš„åœ†å¼§é‡Œé¢è¿åŠ¨ï¼Œmuæ˜¯ï½ž0.5ï¼Œ0.9ï¼Œ0.99ï¼ˆåªä½¿ç”¨ä¸€ä¸ªå€¼ï¼Œsingle numberï¼Œhyperï¼‰ å½¢æ€ï¼Œä»Žåˆå§‹ç‚¹å¼€å§‹èµ°ä¸€ä¸ªå¤§çš„åœ†å¼§ï¼Œä¼šè·‘è¿‡äº†ï¼Œä½†æ˜¯ä¼šå†å¿«é€Ÿçš„convergeå›žåŽ» ä¼˜ç‚¹ å¼•å…¥äº†é€Ÿåº¦ï¼Œå¯ä»¥åœ¨æ¯”è¾ƒshallowçš„æ–¹å‘ä¸Šé€Ÿåº¦é€æ¸å¢žåŠ  åœ¨æ¯”è¾ƒæ·±çš„ç»´åº¦ä¸Šé¢ï¼Œå°±åƒçƒåœ¨åœ†å¼§é‡Œé¢æ¥å›žæ»‘åŠ¨ ç†è§£ æ˜¯å¯¹è¿™ä¸ªupdateä¸€ç‚¹ç‰©ç†ä¸Šæ¯”è¾ƒç›´è§‚çš„ç†è§£ï¼ˆå…¶å®žåå­—å«åšåŠ¨é‡ï¼‰ å¯ä»¥ç†è§£ä¸ºè¿™ä¸ªä¸œè¥¿æ˜¯åœ¨ä¸€ä¸ªå¹³åŽŸä¸Šè·‘çš„ä¸€ä¸ªçƒï¼Œæˆ‘ä»¬éœ€è¦æ±‚çš„wæ˜¯è¿™ä¸ªçƒçš„é€Ÿåº¦ï¼Œå¾—åˆ°çš„dwæ˜¯è¿™ä¸ªçƒçš„åŠ é€Ÿåº¦ï¼Œè€Œè¿™ä¸ªçƒçš„åˆé€Ÿåº¦æ˜¯0 å¯ä»¥ç†è§£ä¸ºè¿™ä¸ªçƒæ‰¾æœ€ä½Žç‚¹çš„æ—¶å€™ï¼Œé™¤äº†æ¯æ­¥æŒ‰dw updateï¼Œè¿˜åœ¨ä¸Šé¢åŠ ä¸Šäº†å‰é¢é€Ÿåº¦çš„å½±å“ï¼Œä¹Ÿå°±æ˜¯åŠ ä¸Šäº†æƒ¯æ€§ï¼123# Momentum updatev = mu * v - learning_rate * dx # integrate velocityx += v # integrate position nesterov momentum update åœ¨ä¸Šé¢çš„æ–¹æ³•ä¹‹åŽ look a head äº†ä¸€æ­¥ï¼Œå¾—åˆ°çš„æ˜¯ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„å·® åœ¨å®žé™…èµ°çš„è¿‡ç¨‹å½“ä¸­ï¼Œå¼§åº¦ä¼šæ¯”monnumentçš„æ›´å¤§ä¸€äº›ï¼Œè·‘è¿‡çš„ä¼šæ›´å°ä¸€äº› ç†è§£ Nesterov Momentum(NAG) åœ¨åŽŸæ¥çš„åŸºç¡€ä¸Šï¼šçœŸå®žç§»åŠ¨æ–¹å‘ = é€Ÿåº¦çš„å½±å“ï¼ˆmomentumï¼‰+ æ¢¯åº¦çš„å½±å“ ï¼ˆgradientï¼‰ çŽ°åœ¨ï¼šæ—¢ç„¶æˆ‘ä»¬å·²ç»çŸ¥é“äº†è¦å¾€å‰èµ°åˆ°åŠ¨é‡çš„å½±å“çš„ä½ç½®ï¼Œé‚£ä¹ˆæˆ‘æ ¹æ®é‚£ä¸ªä½ç½®çš„æ¢¯åº¦å†è¿›è¡Œupdateï¼Œå²‚ä¸æ˜¯è·‘çš„æ›´å¿«ï¼ æ€»çš„æ¥è¯´å°±æ˜¯è€ƒè™‘åˆ°äº†å‰é¢çš„å¡åº¦ï¼ˆäºŒé˜¶å¯¼æ•°ï¼‰ï¼Œå¦‚æžœå‰é¢çš„å¡åº¦ç¼“çš„è¯æˆ‘å°±å†è·‘å¿«ç‚¹ï¼Œå¦‚æžœé™¡çš„è¯å°±è·‘æ…¢ç‚¹123v_prev = v # back this upv = mu * v - learning_rate * dx # velocity update stays the samex += -mu * v_prev + (1 + mu) * v # position update changes form adaGrad ï¼ˆparameter-adaptiveï¼‰ é¦–å…ˆå®šä¹‰äº†ä¸€ä¸ªcacheï¼Œè¿™ä¸ªcacheæ˜¯gradientçš„å¹³æ–¹çš„å’Œï¼Œåªæ˜¯positiveï¼Œå’Œparameterçš„ç»´åº¦æ˜¯ä¸€æ ·çš„ ç„¶åŽæŠŠSGDçš„å­¦ä¹ çŽ‡ï¼ˆå…¨å±€çš„learning rateï¼‰scaleäº†ä¸€ä¸ªè¿™ä¸ªæ•° -&gt; è¿™æ ·å¾—åˆ°çš„æ˜¯ä¸åŒå‚æ•°çš„å­¦ä¹ çŽ‡ â€œ Added element-wise scaling of the gradient based on the historical sum of squares in each dimensionâ€ ç»“æžœï¼šåœ¨è¶Šå¯†é›†çš„ç»´åº¦ä¸Šï¼Œupdateçš„æ­¥ä¼è¶Šå°ï¼Œè¶Šç¨€ç–çš„ä¸Šé¢updateè¶Šå¤§ï¼ˆå› ä¸ºå¹³ç¼“çš„åœ°æ–¹åŽ†å²gradientçš„å¹³æ–¹å’Œæ›´å°ï¼Œæ‰€ä»¥updateä¼šæ›´å¤§ï¼‰ é—®é¢˜ step sizeï¼šæ—¶é—´è¶Šé•¿learning rateä¼šæœ€ç»ˆå˜åˆ°0ï¼Œç„¶åŽå°±åœæ­¢å­¦ä¹  RMSPropï¼ˆä¸Šé¢ä¸€ä¸ªçš„å˜å½¢ï¼‰ æŠŠcacheçš„å®šä¹‰æ”¹å˜äº†ï¼Œå¢žåŠ äº†ä¸€ä¸ªdecay rateï¼ˆhyperï¼‰ adaGradä¼šè®¡ç®—çš„æ˜¯æ‰€æœ‰æ¢¯åº¦çš„å¹³æ–¹çš„å’Œï¼Œè€Œè¿™ä¸ªè®¡ç®—çš„æ˜¯gradientå¯¹åº”çš„å¹³å‡å€¼ï¼Œè¿™æ ·çš„è¯learning rateçš„ä¸‹é™ä¼šæ›´æ…¢ ä¾ç„¶èƒ½ä¿æŒå„ä¸ªç»´åº¦ä¸Šé¢çš„å¹³è¡¡ï¼Œä½†æ˜¯ä¸ä¼šè®©learning rateå˜åˆ°0 adam -&gt; å¦ä¸€ç§è‡ªé€‚åº”å­¦ä¹ çŽ‡çš„ç®—æ³• betaéƒ½æ˜¯hyper ç»“åˆäº†ä¸Šé¢çš„ä¸¤ç§æ–¹æ³• åˆ©ç”¨æ¢¯åº¦çš„ä¸€é˜¶çŸ©å’ŒäºŒé˜¶çŸ©ä¼°è®¡åŠ¨æ€è°ƒæ•´æ¯ä¸ªå‚æ•°çš„å­¦ä¹ çŽ‡ -&gt; æ¯æ¬¡è¿­ä»£å­¦ä¹ çŽ‡ä¼šæœ‰ä¸€ä¸ªèŒƒå›´ï¼Œè®©å‚æ•°æ¯”è¾ƒå¹³ç¨³ å¯¹æ¢¯åº¦çš„ä¸€é˜¶å’ŒäºŒé˜¶ä¼°è®¡ï¼ˆæœŸæœ›çš„è¿‘ä¼¼ï¼‰ å®žé™…ä½¿ç”¨ é»˜è®¤ç”¨adam åˆšå¼€å§‹ä½¿ç”¨é«˜çš„learning rate -&gt; è¿™æ ·è¿›å±•ä¼šéžå¸¸å¿« decay over time -&gt; åœ¨è¿›è¡Œåˆ°ä¸€å®šç¨‹åº¦çš„æ—¶å€™ä¼šæ²¡æœ‰åŠžæ³•æ›´ç»†è‡´çš„é€¼è¿‘minimum step decay: æ¯”å¦‚è¿‡ä¸€äº›epochä¹‹åŽå°±æŠŠlrå‡å°‘åˆ°ä¸€åŠ exponential decay 1/t decay secend order optimization methodï¼ˆmlï¼‰ åœ¨è®¡ç®—çš„æ—¶å€™ä¸ä»…éœ€è¦gradientï¼Œè¿˜éœ€è¦hessianæ¥å‘Šè¯‰ä½ æ›²é¢çš„curveç¨‹åº¦ï¼Œä»¥æ­¤æ¥ç¡®å®šå¦‚ä½•å‰è¿›ï¼ˆç‰›é¡¿methodï¼‰ é€Ÿåº¦æ›´å¿«ï¼Œhyperæ›´å°‘ ä½†æ˜¯åœ¨deep netsé‡Œé¢ä¸å¤ªèƒ½ä½¿ç”¨ï¼Œå› ä¸ºå‚æ•°å¤ªå¤šæƒ¹ BFGSï¼ˆapproximate inverse Hessian with rank 1 updates over time (O(n^2) each). L-BFGS work well in full batch mini-batchä¸æ˜¯å¾ˆé€‚ç”¨ evaluationï¼šmodel ensembles å¯ä»¥ä¸ç”¨è®­ç»ƒå¾ˆå¤šä¸ªmodelï¼Œè€Œæ˜¯è®­ç»ƒä¸€ä¸ªç„¶åŽåœ¨å…¶ä¸­é€‰å–ä¸ä¸€æ ·çš„check point trackä¸€ä¸ªå‚æ•°vectorçš„running averageå¯èƒ½ä¼šå¾—åˆ°æ›´å¥½çš„æ•ˆæžœ regularizationï¼ˆDROPOUTï¼‰ åœ¨forwardçš„æ—¶å€™ï¼Œéšæœºçš„æŠŠä¸€äº›neruonçš„å€¼è®¾ç½®æˆ0ï¼ˆæ¯”å¦‚æ€æŽ‰ä¸€åŠï¼‰ ä¸ºä»€ä¹ˆè¦ä½¿ç”¨ï¼š ä¸ºäº†æ±‚å‡ºæ¥çš„ç»“æžœæ›´åŠ çš„å‡†ç¡®ï¼Œæ¯ä¸ªç‰¹å®šçš„ç‰¹å¾éƒ½ä¸èƒ½å®Œå…¨ä¾èµ–ï¼Œå› ä¸ºè¿™ä¸ªfeatureå¯èƒ½å°±è¢«dropæŽ‰äº† è®¡ç®—ä¸€ä¸ªå¤§çš„netçš„å…¶ä¸­ä¸€å°éƒ¨åˆ†ï¼Œè¢«dropæŽ‰çš„éƒ¨åˆ†åœ¨backçš„æ—¶å€™ä¹Ÿä¸ä¼šå†è®¡ç®—äº†ï¼Œå°±å½»åº•å…³æŽ‰äº†ã€‚ç›¸å½“äºŽåœ¨neté‡Œé¢å–äº†ä¸€éƒ¨åˆ†sample test time åœ¨æµ‹è¯•çš„æ—¶å€™å¸Œæœ›å¯ä»¥æŠŠæ‰€æœ‰çš„neuronéƒ½æ‰“å¼€ï¼ˆå°±è¿›è¡Œä¸€æ¬¡ï¼‰ scaleï¼ï¼ï¼ï¼ éœ€è¦æ³¨æ„çš„é—®é¢˜ï¼š è®¡ç®—è®­ç»ƒæ—¶å€™çš„æœŸæœ›ï¼Œå°±å‘çŽ°dropoutä¹‹åŽçš„æœŸæœ›æ˜¯æµ‹è¯•çš„å®žé™…å€¼çš„1/2ï¼ˆå› ä¸ºdropäº†ä¸€åŠï¼‰ å› ä¸ºä»¥å‰netæ²¡è§è¿‡è¿™ä¹ˆå¤§çš„outputï¼Œä¼šç›´æŽ¥æ­»æŽ‰ï¼Œæ‰€ä»¥éœ€è¦æŠŠæµ‹è¯•æ—¶å€™çš„ç»“æžœå†ç¼©å°ä¸€åŠï¼ˆæˆ–è€…dropçš„æ¯”ä¾‹ï¼Œ* pï¼‰ æœ€ç»ˆç»“æžœï¼šæµ‹è¯•æ—¶å€™çš„è¾“å‡º = è®­ç»ƒæ—¶å€™çš„æœŸæœ›è¾“å‡º å¦ä¸€ç§æ–¹æ³• inverted dropout åœ¨trainçš„æ—¶å€™ / p åœ¨æµ‹è¯•çš„æ—¶å€™å°±ä¸ç”¨æ”¹å˜äº† gradient checkingï¼ˆå¹¶æ²¡æœ‰è®²ï¼‰CNNå¼€å§‹å•¦å·ç§¯å±‚ï¼ˆæ ¸å¿ƒéƒ¨åˆ†ï¼‰ å¯¹ä¸€å¼ å›¾ç‰‡æ“ä½œï¼š æ‹¥æœ‰ä¸€å¼ å›¾åƒ32x32x3 æ‹¥æœ‰å·ç§¯æ ¸5x5x3ï¼ˆè¿™ä¸¤ä¸ªä¸œè¥¿å¿…é¡»ç»´åº¦ä¸€æ ·ï¼‰ -&gt; å¥‡æ•°å°ºå¯¸çš„æ•ˆæžœæ›´å¥½ kernalåšå·ç§¯ï¼ˆæ‰€æœ‰çš„channelï¼‰ï¼Œå¾—åˆ°ä¸€ä¸ª28x28x1çš„activaton map å†å¯¹è¿™å¼ å›¾ç‰‡ä½¿ç”¨ä¸‹ä¸€ä¸ªä¸åŒçš„å·ç§¯æ ¸ï¼ˆå·ç§¯æ ¸çš„æ•°é‡æ˜¯ä¸€ä¸ªhyperï¼‰ è¿™æ ·ä¸€ä¸ª32x32x3å˜æˆäº†ä¸€ä¸ª28x28x6ï¼ˆ6æ˜¯é€‰æ‹©çš„hyperçš„æ•°é‡ï¼‰ å½“æŠŠè¿™äº›å±‚å¯è§†åŒ–äº†ä¹‹åŽï¼Œå‘çŽ°è¶Šæ·±å›¾ç‰‡çš„featureè¶Šé«˜çº§ï¼ˆä»Žä¸Šä¸€çº§çš„ç‰¹å¾å¾—åˆ°çš„æ–°çš„ç‰¹å¾ï¼‰ å¤§è‡´å¸ƒå±€ å·ç§¯å±‚ RELUå±‚ -&gt; é»‘ç™½åŒ– poolingå±‚ æœ€åŽåŠ ä¸Šfcå±‚ å…·ä½“è®¡ç®—stride æ¯æ¬¡å·ç§¯æ ¸ç§»åŠ¨çš„æ—¶å€™çš„æ­¥é•¿ æ³¨æ„åœ¨ä¸åŒå›¾ç‰‡å¤§å°ï¼Œä¸åŒå·ç§¯æ ¸å¤§å°å’Œä¸åŒæ­¥é•¿å¯èƒ½ä¸åŒ¹é… ï¼ˆå›¾ç‰‡ - å·ç§¯æ ¸ï¼‰/æ­¥é•¿ + 1 æ˜¯ä¸æ˜¯æ•´æ•°ï¼Œç»“æžœæ˜¯è¾“å‡ºå›¾ç‰‡çš„å°ºå¯¸ padding å¯ä»¥åœ¨å›¾ç‰‡å‘¨å›´ä¸€åœˆåŠ ä¸Šä¸€åœˆ0ï¼Œè¿™æ ·å›¾ç‰‡å·ç§¯ä¹‹åŽçš„å¤§å°å°±ä¸å˜äº† 0-paddingçš„å¤§å°å’Œå·ç§¯æ ¸çš„å¤§å°æœ‰å…³ï¼Œå¤§å°æ˜¯ï¼ˆå·ç§¯æ ¸ -1ï¼‰/2 å¦‚æžœä¸è¿›è¡Œpaddingï¼Œå›¾ç‰‡ä¼šè¶Šæ¥è¶Šå° å‚æ•°æ•°é‡ å¯¹ä¸€ä¸ªå·ç§¯æ ¸ï¼šå·ç§¯æ ¸çš„å¤§å° * æ·±åº¦ + 1 ï¼ˆåŠ ä¸€æ˜¯åŠ äº†ä¸€ä¸ªbiasï¼‰ ä¸€å±‚çš„å‚æ•°ï¼š å·ç§¯æ ¸æ•°é‡ * ä¸€ä¸ªå·ç§¯æ ¸ å››ä¸ªhyperï¼š Kï¼šfilterçš„æ•°é‡ï¼Œ2çš„æŒ‡æ•° -&gt; è®¡ç®—æ•ˆçŽ‡é«˜ Sï¼šæ­¥é•¿ Fï¼šå·ç§¯æ ¸å¤§å° Pï¼š0-padding 1x1çš„å·ç§¯ 1x1çš„å·ç§¯å±‚ï¼ˆstrideä¹Ÿæ˜¯1ï¼‰ä¼šæœ‰æ¯”è¾ƒå¥½çš„æ•ˆæžœ æ¯”å¦‚è¾“å…¥æ˜¯56x56x64ï¼Œfilteræ˜¯32ä¸ª1x1x64ã€‚å› ä¸ºæ•°æ®æ˜¯æœ‰æ·±åº¦çš„ï¼Œ1x1çš„æ—¶å€™æ˜¯æœ‰æ„ä¹‰çš„ï¼ˆåœ¨äºŒç»´ä¸Šé¢æ²¡æœ‰æ„ä¹‰ï¼‰ çŽ°åœ¨å¤„ç†çš„ä¸œè¥¿éƒ½æ˜¯æ–¹å½¢çš„ä»Žç¥žç»å…ƒçš„è§’åº¦æ¥çœ‹CNN å¯ä»¥æŠŠfilterè®¤ä¸ºæˆä¸€ä¸ªå›ºå®šä½ç½®çš„ç¥žç»å…ƒï¼Œè¿™ä¸ªç¥žç»å…ƒåªçœ‹åˆ°äº†å›¾ç‰‡ä¸Šé¢çš„ä¸€å°éƒ¨åˆ†ï¼Œæ²¡æœ‰å’Œå…¨éƒ¨çš„å›¾ç‰‡ç›¸è¿žï¼Œç„¶åŽè¿›è¡Œäº†wx+bçš„è¿ç®— å½“slideè¿™ä¸ªfilterçš„æ—¶å€™ï¼Œweightæ˜¯ä¸å˜çš„ï¼Œå¯ä»¥å‡è®¾æˆä¸€åœˆå…±äº«å‚æ•°çš„ç¥žç»å…ƒ å¯¹åŒä¸€å¼ å›¾ç‰‡çš„ä¸åŒçš„filterå¯ä»¥è®¤ä¸ºæˆä»–ä»¬æ˜¯åœ¨ä¸‰ç»´ä¸Šé¢æŽ’åˆ—çš„ä¸€ç»„ç¥žç»å…ƒï¼Œæ¯ä¸€å±‚ç¥žç»å…ƒéƒ½å’Œè¿™ä¸€å±‚å…±äº«å‚æ•°ï¼ˆä¸å¸Œæœ›å…¨éƒ¨éƒ½æ˜¯å…¨è”æŽ¥ï¼Œå› ä¸ºæµªè´¹äº†å¾ˆå¤šå‚æ•°ï¼‰ pooling åœ¨å·ç§¯çš„æ—¶å€™æ˜¯ä¸ä¼šæ”¹å˜å›¾ç‰‡çš„å¤§å°çš„ æ”¹å˜å›¾ç‰‡å¤§å°çš„æ“ä½œåœ¨pooling layeré‡Œé¢å®žçŽ° é•¿å®½ç¼©çŸ­ï¼Œæ·±åº¦ä¸å˜ max pooling 2x2poolï¼Œstride2 -&gt; æ¯4ä¸ªæ ¼å­é‡Œé¢é€‰æ‹©ä¸€ä¸ªæœ€å¤§çš„è¡¨ç¤º ä¸¤ä¸ªå‚æ•° pooling size F 2ï¼Œ3 stride S 2ï¼Œ2 ä¸ä¼šæ”¹å˜å›¾ç‰‡çš„æ·±åº¦ fully connected å°±è·Ÿæ™®é€šçš„ç¥žç»ç½‘ç»œä¸€æ ·ï¼Œæ‰€æœ‰ç¥žç»å…ƒä¹‹é—´éƒ½ä¼šè¿žæŽ¥ æŠŠæœ€åŽçš„å›¾ç‰‡å˜æˆä¸€ä¸ªåˆ—ï¼Œæ”¾è¿›åŽ»å¼€å§‹è®¡ç®— å®žé™…åº”ç”¨LeNet-5AlexNet ä¸¤å¤©ä¸åŒçš„çº¿ï¼Œå› ä¸ºå½“æ—¶çš„GPUçš„æ•ˆæžœä¸å¤Ÿ ä¼˜ç‚¹ï¼š ç¬¬ä¸€æ¬¡ä½¿ç”¨ReLU æŠŠdata normalizationäº†ï¼Œä½†æ˜¯çŽ°åœ¨çœ‹å…¶å®žå¹¶ä¸éœ€è¦ data augumenation -&gt; æœ‰ç”¨ï¼ dropout 0.5ï¼Œæœ€åŽå‡ å±‚ ZFNet åœ¨ç¬¬ä¸€å±‚ä¸Šæ¯”alexçš„strideçŸ­ï¼Œå› ä¸ºalexçš„æ­¥é•¿4è·³è¿‡äº†å¤ªå¤šå›¾ç‰‡ä¿¡æ¯ï¼Œè¿™é‡Œæ”¹æˆäº†æ­¥é•¿2 fliterçš„æ•°é‡æ›´å¤š VGGNet åªæœ‰3x3 s1 p1çš„å·ç§¯æ ¸ï¼Œå’Œ2x2 s2çš„max pooling ç»“æžœè¿˜ç‰¹åˆ«å¥½ å›¾åƒçš„å°ºå¯¸è¶Šæ¥è¶Šå°ï¼Œä½†æ˜¯æ·±åº¦è¶Šæ¥è¶Šé«˜ éœ€è¦çš„è®¡ç®—é‡ï¼š93MB/imageï¼ˆforwardï¼‰ -&gt; 200m/image(æ‰€æœ‰çš„è®¡ç®—åŠ èµ·æ¥) å¤§éƒ¨åˆ†çš„memoryéƒ½åœ¨å‰æœŸçš„å±‚é‡Œï¼Œå¤§éƒ¨åˆ†çš„å‚æ•°éƒ½åœ¨æœ€åŽçš„å…¨é“¾æŽ¥å±‚é‡Œé¢ï¼ˆæœ€åŽçš„è®¡ç®—é‡å¤ªå¤§ï¼ŒåŽé¢æœ‰æ›´å¥½çš„æ–¹æ³•ï¼‰ VGGä¹Ÿæœ‰ä½ç½®ç¡®å®šï¼Œä»–æ¯”overfeatçš„å±‚æ•°æ›´æ·± GoogLeNet æ˜¯ä¸€ä¸ªä¸€ä¸ªçš„å°ç»“æž„ç»„æˆå‡ºæ¥äº† å‚æ•°çš„æ•°é‡éžå¸¸å°‘ 5millionï¼Œå–æ¶ˆäº†fcå±‚ ä½¿ç”¨äº†average poolï¼ŒæŠŠ7x7x1024å˜æˆäº†1x1x1024 :æŠŠæ¯ä¸ªactivate mapå–å¹³å‡å€¼ ç”¨VGGçš„äººæ›´å¤šå› ä¸ºVGGçš„ç»“æž„æ¯”è¾ƒå¥½æƒ³2333 ResNet t5 erroré™åˆ°äº†3.å¤š å¹³å¸¸çš„åŠ æ·±å±‚æ•°è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸Šè¾¹çš„å‡†ç¡®çŽ‡å˜åŒ–ç»“æžœä¸ç»Ÿä¸€ï¼Œä½†æ˜¯resåšåˆ°äº†ç»Ÿä¸€ è™½ç„¶å±‚æ•°ç‰¹æ¯”å¤šï¼Œä½†æ˜¯é€Ÿåº¦è¿˜æ˜¯å¿« -&gt; åŠ å…¥äº†skipçš„éƒ¨åˆ†ï¼ŒæŠŠè¾“å…¥è·³è¿‡äº†å·ç§¯åˆåŠ äº†å›žåŽ»ï¼Œè¿™æ ·backçš„æ—¶å€™å°±ä¼šåˆ†æµ top-5 error åœ¨çœ‹ç»“æžœçš„æ—¶å€™ä¸å…‰çœ‹å‡†ç¡®çŽ‡ï¼Œè¿˜ä¼šçœ‹åˆ†ç±»å™¨è®¤ä¸ºçš„å‰5ä¸ªå¯èƒ½æ€§ï¼ˆå¯èƒ½æœ‰å‡ åƒä¸ªåˆ†ç±»ï¼‰ï¼Œå¦‚æžœè¿™5ä¸ªå¯èƒ½æ€§éƒ½ä¸å¯¹çš„è¯å°±æ˜¯æ±‚å‡ºæ¥çš„å°±æ˜¯top-5 error spatial localization and detectionè¿™ç« çš„ä¸»è¦å†…å®¹æ˜¯è¯†åˆ«å‡ºæ¥è¿™ä¸ªä¸œè¥¿ä¹‹åŽç”¨æ¡†æ¡†æ¡†å‡ºæ¥ åˆ†ç±»+å®šä½ï¼šLocalization as Regression å®žé™…ä¸Šå°±è·Ÿregressionå·®ä¸å¤š neurral netçš„è¾“å‡ºæ˜¯bounding boxï¼ˆ4ä¸ªæ•°å­—ï¼‰ï¼Œå·¦ä¸Šè§’çš„åæ ‡å’Œé•¿å®½ å®žé™…çš„å›¾ç‰‡æ ‡æ³¨çš„å†…å®¹ä¹Ÿæœ‰å·¦ä¸Šè§’åæ ‡å’Œé•¿å®½ï¼Œæ±‚å‡ºè¿™ä¸¤ä¸ªéƒ¨åˆ†çš„L2 distanceä½œä¸ºloss æ­¥éª¤ è®­ç»ƒï¼ˆä¸‹è½½ï¼‰ä¸€ä¸ªåˆ†ç±»çš„model åœ¨neté‡Œé¢åŠ ä¸Šfcçš„regression head ç”¨SGDå’ŒL2lossè®­ç»ƒregression headéƒ¨åˆ† testçš„æ—¶å€™åˆ†ç±»å’Œregressionéƒ½ç”¨ ç±»åˆ« å¹³å¸¸çš„åˆ†ç±»ï¼šæœ€ç»ˆçš„æ•°é‡å’Œclassçš„æ•°é‡ç›¸åŒ ä¸€ä¸ªboxé‡Œé¢ä¼šæœ‰4ä¸ªæ•°å­—ï¼Œä¸€å…±Cx4ä¸ªæ•°å­— åŠ åœ¨ä»€ä¹ˆåœ°æ–¹ conv layerä¹‹åŽ fcä¹‹åŽ å¤šä¸ªç›®æ ‡çš„æ£€æµ‹ï¼ˆAsideï¼‰ çŸ¥é“å‡†ç¡®çš„æ£€æµ‹ç›®æ ‡çš„æ•°é‡kï¼Œé‚£ä¹ˆæœ€ç»ˆçš„åˆ†ç±»æ•°é‡å°±æ˜¯4 * k åº”ç”¨ï¼šäººçš„åŠ¨ä½œæ£€æµ‹ -&gt; å¾—åˆ°å…³èŠ‚çš„ä½ç½® åˆ†ç±» + å®šä½ï¼šsliding windowï¼šoverfeat æ ¸å¿ƒideaï¼šåœ¨æ£€æµ‹çš„æ—¶å€™ç›´æŽ¥processå›¾ç‰‡ï¼Œä½†æ˜¯å¯¹ä¸€å¼ å›¾ç‰‡åœ¨ä¸åŒçš„åœ°æ–¹è¿›è¡Œå¤šæ¬¡æ“ä½œ æ“ä½œæ­¥éª¤ï¼š é¦–å…ˆå¯¹å›¾ç‰‡è¿›è¡Œconvå’Œpoolingï¼Œç„¶åŽå¯¹å¾—åˆ°çš„ç»“æžœè¿›è¡Œä¸¤ä¸ªä¸åŒçš„fcï¼Œ å¾—åˆ°çš„æ˜¯1000ä¸ªçš„åˆ†ç±»ç§ç±» å¦ä¸€ä¸ªçš„åˆ°çš„æ˜¯1000x4çš„bounding boxåæ ‡ åœ¨ä¸€å¼ å¤§çš„å›¾ç‰‡ä¸Šï¼Œåœ¨ä¸åŒåŒºåŸŸæ‰¾åˆ°éœ€è¦å¯»æ‰¾çš„ä¸œè¥¿ï¼ˆæ¯”å¦‚åˆ†æˆå››éƒ¨åˆ†ï¼Œè¿™å››éƒ¨åˆ†æ˜¯æœ‰é‡å çš„ï¼Œä¸æ˜¯poolingé‚£ä¸ªæ ·å­ï¼‰ å¾—åˆ°æ¯ä¸ªéƒ¨åˆ†å¯¹äºŽè¿™ä¸ªåˆ†ç±»çš„å¾—åˆ†ï¼Œä»¥åŠç›¸åº”éƒ¨åˆ†å¯¹åº”çš„bounding box æœ€åŽç”¨æ²¡æ€Žä¹ˆè®²çš„åŠžæ³•mergeäº†è¿™äº›æ¡†ï¼Œå¾—åˆ°äº†æœ€ç»ˆç»“æžœ è¿›ä¸€æ­¥ä¼˜åŒ– å› ä¸ºè¦å¯¹è¿™ä¸ªå›¾ç‰‡çš„ä¸åŒcropåšcnnï¼Œè®¡ç®—é‡ä¼šéžå¸¸å¤§ åœ¨fcå±‚å…¶å®žåªæ˜¯ä¸€ä¸ªå‘é‡1x4096ï¼ŒæŠŠè¿™ä¸ªçŽ©æ„æ‹‰æˆäº†ä¸€ä¸ªcnnï¼Œ4096x1x1ï¼Œç„¶åŽç›´æŽ¥conv1x1çš„å·ç§¯æ ¸ çŽ°åœ¨neté‡Œé¢å°±åªæœ‰convå’Œpoolingäº†ï¼Œæ‰€ä»¥å°±å¯ä»¥å¤„ç†ä¸åŒå°ºå¯¸çš„å›¾ç‰‡äº†ï¼ˆä¸åŒå°ºå¯¸çš„æ–¹å½¢ï¼‰ è€Œä¸”åœ¨å¤„ç†ä¸åŒåŒºåŸŸçš„æ—¶å€™æ˜¯å‚æ•°æ˜¯shareçš„ ç›®æ ‡æ£€æµ‹ ä¸»è¦ä¸åŒï¼šä¸èƒ½ç¡®å®šå›¾ç‰‡é‡Œé¢ç‰©ä½“çš„æ•°é‡ æ€è·¯ï¼š å°è¯•æ‰€æœ‰å¯èƒ½çš„windowç„¶åŽç”¨classifcationæ‰¾åˆ°éœ€è¦çš„éƒ¨åˆ† é—®é¢˜ï¼šéœ€è¦å¾ˆå¤šæ¬¡åˆ†ç±» åŽ†å²è§£å†³æ–¹æ³•ï¼šç”¨éžå¸¸å¿«çš„åˆ†ç±»å™¨ï¼Œå°è¯•æ‰€æœ‰ï¼ˆlinear classifierï¼‰ æ›´æƒ³ç”¨çš„æ–¹æ³•ï¼šç”¨cnnï¼Œåªæµ‹è¯•tiny subsets of possible locations region proposals è¾“å…¥ä¸€å¼ å›¾ç‰‡ï¼Œè¾“å‡ºæ‰€æœ‰å¯èƒ½æœ‰ç‰©ä½“çš„åŒºåŸŸ ä¸åœ¨æ„åˆ°åº•æ˜¯ä»€ä¹ˆç±»åž‹ ä¸åœ¨æ„ç²¾ç¡®åº¦ ä½†æ˜¯é€Ÿåº¦å¾ˆå¿« selective search ä»Žä¸€ä¸ªpixelå¼€å§‹ï¼Œå¦‚æžœç›¸é‚»çš„pixelæœ‰ä¸€æ ·çš„é¢œè‰²æˆ–è€…textureï¼Œmerge å½¢æˆè¿žæŽ¥åŒºåŸŸï¼Œå†è¿žæŽ¥ä¸åŒåŒºåŸŸï¼Œè¿™ä¸ªåŒºåŸŸä¹Ÿå¯ä»¥å†æ‰“æ•£ è¿˜æœ‰å¾ˆå¤šå…¶ä»–æ–¹æ³•ï¼šedge boxesï¼ˆæŽ¨èï¼‰ RCNNï¼ˆregion based CNNï¼‰ ä»Žè¾“å…¥å›¾ç‰‡é‡Œé¢ç”¨region proposalçš„æ–¹æ³•å¾—åˆ°ä¸€ç³»åˆ—çš„boundingsï¼ˆä¸åŒçš„ä½ç½®å’Œscaleï¼‰ å¯¹æ¯ä¸ªåŒºåŸŸcrropå’Œwrapè¿™ä¸ªåŒºåŸŸåˆ°fixed size cnnåˆ†ç±»ï¼Œregression head &amp; classifcation head è¿‡ç¨‹ ä¸‹è½½model fine-tune for detectionï¼šæ”¹å˜åˆ†ç±»çš„ç§ç±»ç­‰ extract features ä¸ºæ¯ä¸ªclassè®­ç»ƒä¸€ä¸ªSVMï¼ˆçœ‹è¿™ä¸ªåŒºåŸŸæ˜¯å¦åŒ…æ‹¬å¯»æ‰¾çš„ä¸œè¥¿ï¼‰ box regressionï¼šå¯¹æ¯ä¸ªç§ç±»ï¼Œè®­ç»ƒä¸€ä¸ªlinear regressionæ¥çº æ­£ä½ç½®çš„åå·®ï¼ˆå¤ªå·¦å¤ªå³ï¼Œç©ºéš™å¤ªå¤šï¼‰ï¼ˆdxï¼Œdyï¼Œdwï¼Œdhï¼‰ datast PASCAL VOC æ¯”è¾ƒå° ImageNet ä¸æ˜¯äº‹å¾ˆå¥½æ“ä½œï¼Œä½†æ˜¯ä¸€å¼ å›¾ä¸€åŠåªæœ‰ä¸€ä¸ªä¸œè¥¿ MS-COCO ä¸€å¼ å›¾å¤šä¸ªå†…å®¹ fast RCNN ï¼ˆæé€Ÿï¼‰ åœ¨æµ‹è¯•æ—¶çš„é€Ÿåº¦æ¯”è¾ƒæ…¢ -&gt; ä¸€å¼ å›¾é‡Œï¼Œåœ¨ä¸åŒçš„proposalsä¹‹é—´share convçš„è®¡ç®— è®­ç»ƒæ—¶ä¸æ˜¯ä¸€èµ·è®­ç»ƒçš„ï¼Œè®­ç»ƒçš„pipelineä¹Ÿå¾ˆå¤æ‚ -&gt; æŠŠæ•´ä¸ªç³»ç»Ÿç«¯å¯¹ç«¯å¯¹çš„è®­ç»ƒä¸€æ¬¡ ROI pooling åœ¨ç”¨çš„æ—¶å€™å¸Œæœ›æ„Ÿå…´è¶£åŒºåŸŸçš„åˆ†è¾¨çŽ‡æ¯”è¾ƒé«˜ï¼Œfcå±‚å¸Œæœ›æ›´ä½Žçš„conv feature åœ¨conv feature mapä¸Šé¢æŠ•å½±é«˜åˆ†è¾¨çŽ‡çš„region proposal æŠŠè¿™ä¸ªåŒºåŸŸåˆ†æˆå°æ ¼ï¼Œç„¶åŽå¯¹æ¯ä¸ªæ ¼å­è¿›è¡Œmax pooling(backçš„æ—¶å€™ä¹Ÿæ˜¯è¿™ä¹ˆå›žæ¥) è®­ç»ƒ8å€ï¼æµ‹è¯•146å€ï¼ç»“æžœæ›´å‡†ç¡®ï¼ faster RCNNï¼ˆå†æé€Ÿï¼‰ ä¹‹å‰çš„æµ‹è¯•é€Ÿåº¦è®¡ç®—éƒ½æ²¡æœ‰ç®—region proposalçš„æ—¶é—´ï¼Œæ‰€ä»¥æŠŠè¿™ä¸ªé—®é¢˜ä¹Ÿäº¤ç»™convåŽ»å¹² åœ¨æœ€åŽä¸€å±‚convåŽé¢åŠ å…¥region proposal net åœ¨feature mapä¸Šé¢çš„ç§»åŠ¨å®žé™…å°±æ˜¯å·ç§¯ è®­ç»ƒä¸€ä¸ªå°çš„ç½‘ç»œåˆ¤æ–­æ˜¯ä¸æ˜¯ä¸€ä¸ªç‰©ä½“å¹¶åˆ†ç±»ï¼Œä»¥åŠregressionæ¡†çš„ä½ç½® åœ¨æ¯ä¸ªä½ç½®ä½¿ç”¨äº†N anchor boxesï¼Œä¸åŒçš„anchoræœ‰scoreæ¥åˆ¤æ–­ä»–æ˜¯å¦å±žäºŽä¸€ä¸ªobjectï¼Œåœ¨ä¸åŒçš„å½¢çŠ¶ä¸Šæœ‰ä¸åŒçš„å¯èƒ½æ€§ï¼ˆï¼Ÿ åŽç»­çš„paperé‡Œé¢å¯ä»¥ä¸€å£æ°”trainäº† yolo æŠŠdetectionå˜æˆäº†regressionçš„é—®é¢˜ åˆ†æˆä¸åŒçš„å°å—ï¼Œåœ¨æ¯ä¸ªå—é‡Œé¢éƒ½åŠ å…¥ visualization, deep dream, neural styleå¯è§†åŒ–ï¼šè§‚å¯Ÿç¥žç»ç½‘ç»œå¦‚ä½•å·¥ä½œ å¯è§†åŒ–ä¸åŒä½ç½® å¯è§†åŒ–activationçš„ç¥žç»å…ƒ -&gt; å¤§é‡çš„å›¾ç‰‡æ‰”è¿›ç¥žç»å…ƒé‡Œé¢ï¼Œæ‰¾å‡ºæ¥ä¸€ä¸ªç¥žç»å…ƒæœ€æ„Ÿå…´è¶£çš„éƒ¨åˆ† å¯è§†åŒ–fliter -&gt; åªèƒ½åœ¨ç¬¬ä¸€å±‚è¿›è¡Œï¼ˆå…¶ä»–çš„å±‚å¯ä»¥ä½†æ˜¯æ„ä¹‰ä¸å¤§ï¼‰ ä½†æ˜¯å•¥ç®—æ³•éƒ½ä¼šå¾—å‡ºæ¥é•¿å¾—å·®ä¸å¤šçš„ å¯è§†åŒ–ç‰¹å¾ï¼ˆå…¨è”æŽ¥å±‚çš„ç‰¹å¾å‘é‡ï¼‰ -&gt; t-SNEï¼šEmbed high-dimensional points so that locally, pairwise distances are conservedï¼Œç‰¹å¾ç›¸ä¼¼çš„ä¸œè¥¿ä¼šèšç±» å¯¹å›¾ç‰‡è¿›è¡Œé®ç½©ï¼Œå¯ä»¥çœ‹å‡ºæ¥é®ä½ä¸åŒåœ°æ–¹è¿™å¼ å›¾ç‰‡è¢«è¯†åˆ«å‡ºæ¥çš„æ¦‚çŽ‡ deep convå’Œoptimazationçš„å¯è§†åŒ–å·¥å…·ï¼šhttp://yosinski.com/deepvis deconvå®žçŽ°é—®é¢˜1:å¦‚ä½•è®¡ç®—ä»»æ„ä¸€ä¸ªç¥žç»å…ƒçš„æ¢¯åº¦ï¼ˆä»£ç å®žçŽ°ï¼‰ æ‰¾åˆ°æƒ³è¦çš„ç¥žç»å…ƒï¼Œforwardçš„æ—¶å€™å°±åœåœ¨è¿™é‡Œ ç„¶åŽè¿›è¡Œbackï¼ŒæŠŠæ‰€æœ‰å…¶ä»–çš„ç¥žç»å…ƒçš„éƒ½è®¾ç½®æˆ0ï¼ŒåªæŠŠæ„Ÿå…´è¶£çš„ç¥žç»å…ƒè®¾ç½®æˆ1ï¼Œç„¶åŽè®¡ç®—backå‡ºæ¥çš„ç»“æžœ æœ€åŽçš„ç»“æžœçœ‹èµ·æ¥å¹¶ä¸æ˜¯å¾ˆå¥½ç†è§£ï¼Œæ‰€ä»¥æ”¹å˜äº†backçš„æ–¹æ³•ï¼Œå¾—åˆ°æ›´å¥½çš„ç»“æžœï¼ˆâ€œguided backâ€ï¼‰ guided backçš„è®¡ç®—æ–¹æ³• åœ¨æ™®é€šçš„è®¡ç®—ä¸­ï¼Œbackçš„æ—¶å€™ä½¿ç”¨reluï¼Œä¼šæŠŠæ‰€æœ‰è´Ÿå€¼éƒ½è½¬åŒ–æˆ0 åœ¨guideçš„è®¡ç®—é‡Œï¼Œåœ¨æ¿€æ´»ä¹‹åŽçš„ä¸œè¥¿backå›žåŽ»çš„æ—¶å€™ï¼Œå¦‚æžœinputçš„ä¸œè¥¿æ˜¯è´Ÿæ•°çš„è¯ï¼Œä¹Ÿä¼šæŠŠè¿™ä¸ªä¸œè¥¿killæˆ0ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸€ä¸ªæ˜¯block backçš„æ—¶å€™çš„gradientçš„å€¼ï¼Œå¦ä¸€ä¸ªè¿˜ä¼šé™„åŠ blockè¾“å…¥è¿›æ¥çš„å€¼ å‘ç”Ÿäº†ä»€ä¹ˆï¼šæŠŠè¾“å…¥è¿›åŽ»ReLUçš„è´Ÿçš„å½±å“ä¹Ÿå–æ¶ˆæŽ‰äº†ã€‚å¦‚æžœä¸å–æ¶ˆçš„è¯ï¼Œè¿™äº›æ­£è´Ÿå°±ä¼šäº’ç›¸fightï¼Œå‘ˆçŽ°æ›´å¥‡æ€ªçš„å›¾ç‰‡ã€‚ä½†æ˜¯åŽ»æŽ‰è´Ÿçš„ä¹‹åŽå˜å¾—å°±æ›´æ¸…æ™°äº†ã€‚ deconvï¼šç›´æŽ¥æ— è§†æŽ‰reluçš„å­˜åœ¨äº† ç¬¬äºŒä¸ªé—®é¢˜ï¼šå›¾åƒä¼˜åŒ– how to find an image maximize some class scoreï¼Œä½†æ˜¯æ•´ä¸ªç½‘ç»œä¸å˜ è¾“å…¥ä¸€å¼ å…¨0çš„å›¾ç‰‡ åœ¨backçš„æ—¶å€™æŠŠscoreè®¾ç½®æˆ[0,0,0,1,0,0,â€¦]ï¼Œåªæœ‰æ„Ÿå…´è¶£çš„æ˜¯1 backå›žåŽ»ï¼Œæ‰¾åˆ°å¯¹å›¾ç‰‡ä¼šäº§ç”Ÿä»€ä¹ˆå½±å“ ä¸åœçš„é‡å¤è¿™ä¸ªæ­¥éª¤ï¼Œæ›´æ–°çš„æ˜¯å›¾ç‰‡ä¸æ˜¯weight æ•ˆæžœ æ‰¾åˆ°å¯ä»¥è®©ä¸€ä¸ªç±»åž‹åˆ†æ•°æœ€é«˜çš„å›¾ç‰‡ï¼ˆå›¾ç‰‡æ˜¯æ ¹æ®ç½‘ç»œç”Ÿæˆçš„ï¼‰ å¯è§†åŒ–dataçš„æ¢¯åº¦ -&gt; å¾—åˆ°äº†ä¸€ä¸ªç±»ä¼¼çƒ­é‡å›¾çš„ä¸œè¥¿ï¼Œè¿™æ ·å¯¹é»‘è‰²çš„éƒ¨åˆ†æ”¹å˜å¯¹è¿™ä¸ªä¸œè¥¿çš„åˆ†ç±»æ²¡æœ‰å¾ˆå¤§çš„å½±å“ ä¸Šé¢çš„æ­¥éª¤å¯ä»¥å¯¹ä»»ä½•çš„ç¥žç»å…ƒè¿›è¡Œï¼ˆç”Ÿæˆä¸€å¼ å›¾ç‰‡ï¼‰ æ›´å¥½çš„regular å¿½è§†äº†æƒ©ç½šï¼Œåªmaxç¥žç»å…ƒ ä½†æ˜¯æ›´æ–°ä¹‹åŽbluräº†ä¸€ä¸‹å›¾åƒï¼Œè¿™æ ·å¯ä»¥é˜»æ­¢å›¾ç‰‡è¿›è¡Œé«˜é¢‘çŽ‡ç§¯ç´¯ ç¬¬ä¸‰ä¸ªé—®é¢˜ï¼ŒCNNçš„codeåŒ…å«å¤šå°‘ä¿¡æ¯ æ˜¯å¦å¯ä»¥é€šè¿‡netè¿˜åŽŸå‡ºæ¥åŽŸæ¥çš„å›¾ç‰‡ï¼ˆæ¶‰åŠåˆ°éšç§æ³„éœ²çš„é—®é¢˜ï¼‰ è¶Šå¾€åŽçš„æ—¶å€™é¢„æµ‹çš„å‡†ç¡®åº¦è¶Šä½Ž deep dream ä¸€ä¸ªéžå¸¸ç®€å•çš„è¿‡ç¨‹ï¼Œåªæœ‰å‡ ç™¾è¡Œä»£ç ï¼Œå°±æ˜¯optimazation image æ¯æ¬¡è°ƒç”¨make_stepå›¾ç‰‡éƒ½ä¼šå‘ç”Ÿå¾®å°çš„æ”¹å˜ æŠŠç½‘ç»œforwardåˆ°ä¸€ä¸ªä½ç½® æŠŠgradientè®¾ç½®æˆactivationè®¾ç½®æˆä¸€æ ·çš„ å†å¾€å›žä¼ å›žåŽ» å¯ä»¥å¼ºè°ƒå¯¹å›¾ç‰‡è´¡çŒ®æœ€å¤šçš„éƒ¨åˆ†ï¼Œä¸ç®¡æ¿€æ´»äº†ä»€ä¹ˆï¼Œéƒ½ä¼šæŠŠè¿™ä¸ªæ¿€æ´»åŠ å¼º deepart æŠŠç›®æ ‡çš„contentä¼ è¿›CNN æŠŠstyle contetä¹Ÿä¼ è¿›CNN æŠŠç›®æ ‡çš„losså’Œstyleçš„lossåŒ¹é…ï¼Œç„¶åŽå¾—åˆ°ç›¸åº”çš„opt image æ˜¯å¦å¯ä»¥ç”¨ç”Ÿæˆçš„å›¾ç‰‡åŽ»fool CNN æŠŠå›¾ç‰‡çš„gradientè®¾ç½®æˆå…¶ä»–çš„ä¸œè¥¿ï¼Œæœ¬æ¥å¸Œæœ›å¯ä»¥å¾—åˆ°æ··åˆçš„ç»“æžœï¼Œä½†æ˜¯å®žé™…ä¸Šå›¾ç‰‡çš„distortæ ¹æœ¬çœ‹èµ·æ¥ä¸å˜ æœ‰äº›å›¾ç‰‡äººç±»çœ‹èµ·æ¥å·®ä¸å¤šï¼Œä½†æ˜¯gradientï¼ˆæˆ–è€…HOGï¼‰ä¹‹ç±»çš„å¯èƒ½å½»åº•æ˜¯å…¶ä»–çš„ä¸œè¥¿ åŽŸå› ï¼š å›¾ç‰‡æœ‰å¾ˆé«˜ç»´åº¦çš„ç©ºé—´ å®žé™…è®­ç»ƒçš„å›¾åƒæœ‰ä¸€å°éƒ¨åˆ†è¢«çº¦æŸï¼Œæ”¾äº†ä¸€ä¸ªçº¿æ€§åˆ†ç±»ä¹‹ç±»åªè°ƒæ•´äº†å…¶ä¸­çš„ä¸€å°éƒ¨åˆ† åœ¨çº¿æ€§åˆ†ç±»é‡Œï¼Œå¦‚æžœåœ¨æ¯ä¸ªç»´åº¦ä¸Šé¢éƒ½æ”¹å˜äº†ä¸€ç‚¹ç‚¹ï¼Œå®žé™…ä¸Šçš„ç½®ä¿¡åŒºé—´ä¼šå‘ç”Ÿç‰¹åˆ«å¤§çš„æ”¹å˜ï¼ˆå¤§è§„æ¨¡çš„ç‚¹ç§¯è¿ç®—ï¼‰.ä¸‹å›¾åªåŠ è¿›åŽ»äº†ä¸€ç‚¹ç‚¹çš„é‡‘é±¼çš„å™ªéŸ³ï¼Œåˆ†ç±»å°±å˜æˆäº†100%çš„é‡‘é±¼ è¿™ä¸ªçŽ°è±¡ä¸ä»…ä»…å‘ç”Ÿåœ¨å›¾ç‰‡é‡Œé¢ï¼Œä¹Ÿå‘ç”Ÿåœ¨å…¶ä»–çš„åœ°æ–¹ RNNï¼ˆrecurrent neural networkï¼‰æ™®é€šçš„netsï¼šå¤§å°éƒ½æ˜¯å›ºå®šçš„ one to oneRNNï¼šå¯ä»¥æœ‰çµæ´»çš„å¯¹åº”ç»“æžœ ä¸€ç³»åˆ—çš„è¯æ¥æè¿°è¿™å¼ å›¾ machine translationï¼šseq of words -&gt; seq of words frame levelçš„è§†é¢‘classification RNNæ˜¯ä»€ä¹ˆ å¯ä»¥åœ¨ä»»ä½•æ—¶é—´æŽ¥å—ä¸€ä¸ªinputï¼ˆvectorï¼‰ï¼Œç„¶åŽå¯¹äºŽä¸åŒçš„stateäº§ç”Ÿä¸åŒçš„é¢„æµ‹ç»“æžœï¼Œç„¶åŽéœ€è¦åœ¨ä¸€äº›æ—¶é—´ä¸­é¢„æµ‹å‡ºæ¥vectorã€‚åªéœ€è¦ç‰¹å®šçš„æƒ…å†µï¼Œå…¶ä»–çš„æƒ…å†µè™½ç„¶æœ‰ä½†æ˜¯æ²¡æœ‰è®°å½•ä¸‹æ¥ è¿‡åŽ»çš„çŠ¶æ€ + æ–°çš„input + å‚æ•°w -&gt; é¢„æµ‹å‡ºæ¥æ–°çš„state æ³¨æ„ï¼šåŒæ ·çš„functioné‡Œé¢çš„weightæ˜¯å›ºå®šçš„ï¼Œåœ¨ä¸åŒæ—¶é—´ä½¿ç”¨ä½†æ˜¯weightæ˜¯ä¸€æ ·çš„ æ¯”å¦‚ä¾‹å­ï¼šhttps://gist.github.com/karpathy/d4dee566867f8291f086 è¾“å…¥ä¸€ä¸ªå­—æ¯çš„åºåˆ—h e l o é¢„æµ‹ä¸‹é¢çš„å­—æ¯æ˜¯ä»€ä¹ˆï¼Œè®­ç»ƒçš„æ¨¡åž‹æ˜¯hello æŠŠæ¯ä¸ªå­—æ¯åˆ†åˆ«feedè¿›åŽ»ï¼Œé¡ºç€è¿™ä¸ªå­—æ¯é¡ºåºæ¥ä¼˜åŒ–å‚æ•°çš„åºåˆ—ï¼Œå› ä¸ºçŸ¥é“ä¸‹ä¸€ä¸ªçš„ç»“æžœæ˜¯ä»€ä¹ˆäº†ï¼Œå°±å¯ä»¥æœç€è¿™ä¸ªç›®æ ‡æ¥åŠªåŠ› ç«Ÿç„¶å¯ä»¥ç”Ÿæˆå¥å­æ•°å­¦å…¬å¼ç”šè‡³ä»£ç  åœ¨å›¾ç‰‡ä¸­å¼€å§‹ä½¿ç”¨ ä»Žä¸€å¼ å›¾å¾—åˆ°ä¸€ç³»åˆ—çš„æ–‡å­— ä¸¤éƒ¨åˆ†ç»„æˆ CNNï¼šæŠŠtestå›¾ç‰‡è¾“å…¥åˆ°CNNï¼Œä¸€ç›´åˆ°æœ€åŽçš„fcï¼Œä½†æ˜¯ç„¶åŽä¸è¿›è¡Œåˆ†ç±»ï¼Œè¾“å…¥RNN RNNï¼šRNNä¸ä»…æ˜¯çŽ°åœ¨çš„è¾“å…¥ï¼Œè¿˜ä¼šåŠ å…¥äº†CNNé‡Œé¢å‡ºæ¥çš„è¾“å‡ºã€‚ç„¶åŽå¾—åˆ°çš„ç»“æžœï¼ˆå¾—åˆ°äº†æ²¡å‡†ä¸€ä¸ªè¯ï¼‰è¿›å…¥ä¸‹ä¸€ä¸ªå¾ªçŽ¯ï¼ˆå°±è·Ÿç”Ÿæˆè¯­ä¹‰çš„æ—¶å€™ä¸€æ ·ï¼‰ ç›´åˆ°åœ¨RNNé‡Œé¢æ‰¾åˆ°çš„tokenï¼Œç„¶åŽç»“æŸRNN LSTM long short term memoryï¼ˆå¤§æ¦‚æ˜¯ä¸ªç”Ÿç‰©é‡Œé¢çš„ä¸œè¥¿ï¼‰ RNNæœ‰å¥½å¤šå±‚ï¼Œæ¯å±‚è¿˜æœ‰å¾ˆå¤šä¸ªå‚æ•°æ¥å†³å®šè¿™å±‚å¾€å“ªèµ° æœ‰ä¸¤ä¸ªè¾“å…¥xå’Œhï¼Œç»„åˆåˆ°wä¸Šé¢ï¼Œç„¶åŽä¸åŒçš„ä¸œè¥¿ä¹˜ä¸åŒçš„æ¿€æ´»å‡½æ•° xæ¥è‡ªbelow hæ˜¯ä»Žä¸Šä¸€å›žæ¥çš„ åŸºäºŽgateå’Œfunctionï¼ˆforget gateï¼‰çš„ç±»åž‹ï¼Œä¼šæ›´æ–°cçš„å€¼ï¼ˆåæ­£éƒ½æ˜¯å‚æ•°çš„ï¼‰ è¿›è¡Œè¿™äº›å¥‡æ€ªçš„æ“ä½œçš„åŽŸå› å°±æ˜¯æ‰¾åˆ°ä¸€ä¸ªå¹³è¡¡å’Œæ›´å¥½çš„ç»“æžœ æ¯”è¾ƒ æ¯æ¬¡æ™®é€šçš„RNNéƒ½è¦ç»è¿‡f gateï¼Œä¼šå½»åº•æ”¹å˜ã€‚backçš„æ—¶å€™gradientä¼šæ¶ˆå¤±æˆ–è€…çˆ†ç‚¸ LSTMé‡Œé¢ç”¨åŠ æ³•è·³è¿‡äº†è¿™ä¸ªé—¨ï¼Œæœ‰ä¸€å®šçš„å½±å“ä½†æ˜¯æ²¡æœ‰å½»åº•æ”¹å˜ï¼Œgradientçš„æ¶ˆå¤±é—®é¢˜ä¼šè¢«æŽ§åˆ¶ä½ï¼ˆå› ä¸ºåªç”¨äº†åŠ ï¼Œä¸ä¼šdieï¼‰ gradient clippingå¯ä»¥æŽ§åˆ¶ä½gradientçˆ†ç‚¸ ä½œä¸šç›¸å…³å†…å®¹å®‰è£…anacondaï¼ï¼ï¼ conda activate cs231npython3 -m IPython notebook æ‰“å¼€ï¼ï¼assignment1knn ä¸¤æ¬¡å¾ªçŽ¯è®¡ç®—è·ç¦» ä¸éœ€è¦ä¸€ä¸ªåƒç´ ä¸€ä¸ªåƒç´ çš„è®¡ç®—ï¼Œç”¨Xç›´æŽ¥è¡¨ç¤ºiå¯¹åº”çš„é‚£è¡Œçš„åƒç´ å€¼çš„å’Œï¼Œç›´æŽ¥åšå·®ï¼ˆæ¯ä¸€é¡¹ä¹‹é—´ï¼Œå¹³æ–¹ï¼ˆæ¯ä¸€ä¸ªï¼Œæ±‚å’Œï¼ˆæ‰€æœ‰é¡¹ï¼‰ï¼Œå¼€æ–¹ã€‚ä¼šå¿«å¾ˆå¤šï¼ï¼ï¼ï¼ 12#distsæ˜¯ä¸€ä¸ª500x5000çš„çŸ©é˜µï¼ˆæµ‹è¯•æ•°é‡å’Œè®­ç»ƒæ•°é‡ï¼‰dists[i,j] = np.sqrt(np.sum(np.square(X[i] - self.X_train[j]))) åˆå§‹åŒ–æ•°ç»„çš„æ–¹æ³•æ˜¯ np.array([[],[]]) å¦‚æžœä¸€ä¸ªåƒç´ ä¸€ä¸ªåƒç´ çš„å¾ªçŽ¯ç»“æžœç®€ç›´å¤ªå¯æ€•äº†ï¼Œå®³æ€•]]></content>
      <categories>
        <category>å›¾åƒå¤„ç†</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
</search>
