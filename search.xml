<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[PythonÁöÑrequestÂ∫ì]]></title>
    <url>%2F2019%2F12%2F18%2FPython%E7%9A%84request%E5%BA%93%2F</url>
    <content type="text"><![CDATA[‰πãÂâçÂÅö‰∫Ü‰∏™Êó•Êú¨ÁöÑÁΩëÊµãÈ¢òÔºåÈ¢òÁõÆÁöÑÂÜÖÂÆπÊòØcall‰∏Ä‰∏™web‰∏äÈù¢ÁöÑapiÂπ∂‰∏îËøîÂõûÁªìÊûú„ÄÇ‰πãÂâç‰∏ÄÁõ¥‰∏çÁü•ÈÅìËøôÈÅìÈ¢òÊòØÂú®Âπ≤‰ªÄ‰πàÔºåËøô‰∏§Â§©Áªà‰∫éÊêûÊòéÁôΩ‰∫Ü ÂèÇËÄÉËµÑÊñô Âø´ÈÄü‰∏äÊâãrequestÊñáÊ°£ GET Âíå POST Âà∞Â∫ïÊúâ‰ªÄ‰πàÂå∫Âà´Ôºü ÂÖ≥‰∫éHTTPÂçèËÆÆÔºå‰∏ÄÁØáÂ∞±Â§ü‰∫Ü ÂÖ≥‰∫érequest‰∏Ä‰∏™PythonÁöÑÁ¨¨‰∏âÊñπÂ∫ìÔºåÁî®‰∫éËÆøÈóÆÁΩëÁªúËµÑÊ∫êÈúÄË¶ÅÂØºÂÖ•Ê®°Âùóimport requests Â∞èÁü•ËØÜÔºöhttpÂçèËÆÆÔºàÂ±ÖÁÑ∂Áé∞Âú®ÊâçÂèëÁé∞ÊàëËøûËøô‰∏™ÈÉΩ‰∏çÁü•ÈÅìÔºâ httpÊòØË∂ÖÊñáÊú¨‰º†ËæìÂçèËÆÆÁöÑÁº©ÂÜôÔºåÊòØ‰ªéwwwÊúçÂä°Âô®‰º†ËæìË∂ÖÊñáÊú¨Âà∞Êú¨Âú∞ÊµèËßàÂô®ÁöÑ‰º†ËæìÂçèËÆÆ httpÂçèËÆÆ‰ΩúÁî®‰∫éÂÆ¢Êà∑Á´Ø-ÊúçÂä°Âô®Êû∂ÊûÑ‰∏äÔºåÊµèËßàÂô®‰Ωú‰∏∫httpÁöÑÂÆ¢Êà∑Á´ØÔºåÈÄöËøáurlÂêëhttpÊúçÂä°Âô®Á´ØÔºàwebÊúçÂä°Âô®ÔºâÂèëÈÄÅÊâÄÊúâËØ∑Ê±ÇÔºåwebÊúçÂä°Âô®Âú®Êé•Âà∞ËØ∑Ê±ÇÂêéÔºåÂêëÂÆ¢Êà∑Á´ØÂèëÈÄÅÂìçÂ∫î ÁâπÁÇπ ÁÆÄÂçïÂø´Êç∑„ÄÇÂÆ¢Êà∑Á´ØËØ∑Ê±ÇÁöÑÊó∂ÂÄôÔºåÂè™ÈúÄË¶Årequest methodÔºàÂåÖÊã¨GETÔºåHEADÔºåPOSTÁ≠âÔºâÂíåurl„ÄÇÊØèÁßçÊñπÊ≥ïËßÑÂÆöÁöÑÂÆ¢Êà∑ÂíåÊúçÂä°Âô®ÁöÑËøûÊé•Á±ªÂûã‰∏çÂêå„ÄÇÂõ†‰∏∫ÂçèËÆÆÁÆÄÂçïÔºåÊâÄ‰ª•ÊúçÂä°Âô®ÁöÑÁ®ãÂ∫èËßÑÊ®°Â∞èÔºåÂèçÂ∫îÂø´ÈÄü ÁÅµÊ¥ªÔºöÂÖÅËÆ∏‰º†Ëæì‰ªªÊÑèÁ±ªÂûãÁöÑÂØπË±° Êó†ËøûÊé•ÔºöÈôêÂà∂ÊØèÊ¨°ËøûÊé•Âè™Â§ÑÁêÜ‰∏Ä‰∏™ËØ∑Ê±ÇÔºåÊî∂Âà∞ÂÆ¢Êà∑Á´ØÁöÑÂ∫îÁ≠îÂêéÊñ≠ÂºÄËøûÊé• Êó†Áä∂ÊÄÅÔºöÂØπ‰∫é‰∫ãÁâ©ÁöÑÂ§ÑÁêÜÊ≤°ÊúâËÆ∞ÂøÜËÉΩÂäõÔºåÊâÄ‰ª•Â¶ÇÊûúÂ§ÑÁêÜÁöÑÊó∂ÂÄôÈúÄË¶ÅÂÖàÂâçÁöÑ‰ø°ÊÅØÂ∞±ÈúÄË¶ÅÂÖ®ÈÉ®ÈáçÊñ∞‰º†Ëæì B/SÔºàÊµèËßàÂô®ÔºåÊúçÂä°Âô®-ÂπøÂüüÁΩëÔºâÔºåC/SÔºàÂÆ¢Êà∑Á´ØÔºåÊúçÂä°Âô®-Â±ÄÂüüÁΩëÔºâÊ®°Âºè URLÔºàUniform Resource LocatorÔºâhttp://www.aspxfans.com:8080/news/index.asp?boardID=5&amp;ID=24618&amp;page=1#name‰∏Ä‰∏™URLÂåÖÊã¨Âá†ÈÉ®ÂàÜÔºö ÂçèËÆÆÈÉ®ÂàÜÔºöhttp:ÔºåË°®Á§∫Áî®ÁöÑËøô‰∏™ÂçèËÆÆÔºàhttpsÊòØÂä†ÂØÜÁöÑÂçèËÆÆÔºâ ÂüüÂêçÈÉ®ÂàÜÔºöwww.aspxfans.comÔºå‰πüÂèØ‰ª•Áî®IPÂú∞ÂùÄ‰Ωú‰∏∫ÂüüÂêç Á´ØÂè£ÔºåÁî®ÂÜíÂè∑ÂàÜÂâ≤Ôºå‰∏çÊòØÂøÖÈ°ªÁöÑ ËôöÊãüÁõÆÂΩïÔºàendpointÔºâÔºå‰ªéÁ¨¨‰∏Ä‰∏™/Âà∞ÊúÄÂêé‰∏Ä‰∏™/Ôºå‰πü‰∏çÊòØÂøÖÈ°ªÁöÑ Êñá‰ª∂ÂêçÔºå‰ªéÊúÄÂêé‰∏Ä‰∏™/Âà∞?‰∏∫Ê≠¢„ÄÇÂ¶ÇÊûúÊ≤°ÊúâÔºüÂ∞±ÊòØÂà∞#„ÄÇÂ¶ÇÊûúÈÉΩÊ≤°ÊúâÂ∞±ÊòØÂà∞ÊúÄÂêé„ÄÇÂ¶ÇÊûúÁúÅÁï•ÁöÑËØùÂ∞±ÊòØÈªòËÆ§Êñá‰ª∂Âêç ÂèÇÊï∞ÈÉ®ÂàÜÔºö‰ªéÔºüÂà∞#Ôºå‰∏çÊòØÂøÖÈ°ªÁöÑ„ÄÇÁî®Êù•ÊêúÁ¥¢ÂíåÊü•ËØ¢„ÄÇÂèØ‰ª•ÊúâÂ§ö‰∏™ÂèÇÊï∞ÔºåÂèÇÊï∞‰πãÈó¥&amp;Áõ∏Èöî ÈîöÈÉ®ÂàÜÔºå‰ªé#ÂºÄÂßãÂà∞ÊúÄÂêéÔºå‰∏çÊòØÂøÖÈ°ªÁöÑ ÂÆ¢Êà∑Á´ØÂèëÈÄÅÁöÑrequestÂΩìÂÆ¢Êà∑Á´ØÂêëÊúçÂä°Âô®ÂèëÈÄÅËØ∑Ê±ÇÁöÑÊó∂ÂÄôÔºåÂåÖÊã¨‰ª•‰∏ãÁöÑÂõõ‰∏™ÈÉ®ÂàÜÔºörequest lineÔºåheaderÔºåempty lineÔºå request data ËØ∑Ê±ÇË°åÔºå‰ºöËØ¥ÊòémethodÔºàÊØîÂ¶ÇGETÔºâÔºåË¶ÅËÆøÈóÆÁöÑËµÑÊ∫êÔºåhttpÁâàÊú¨ ËØ∑Ê±ÇÂ§¥ÈÉ®ÔºöËØ¥ÊòéÊúçÂä°Âô®Ë¶Å‰ΩøÁî®ÁöÑÈôÑÂä†‰ø°ÊÅØÔºàÂ§öË°åÔºâ Á©∫Ë°åÔºöËØ∑Ê±ÇÂ§¥ÈÉ®ÂêéÈù¢ÈúÄË¶ÅÊúâÁ©∫Ë°å ËØ∑Ê±ÇÊï∞ÊçÆÔºà‰∏ª‰ΩìÔºâÔºåÂèØ‰ª•‰∏∫Á©∫ ÊúçÂä°Âô®ÂìçÂ∫îÁöÑresponseÂàÜ‰∏∫Áä∂ÊÄÅË°åÔºåÊ∂àÊÅØÊä•Â§¥ÔºåÁ©∫Ë°åÔºåÂíåÂìçÂ∫îÊ≠£Êñá Áä∂ÊÄÅË°åÔºöhttpÁöÑÁâàÊú¨Âè∑ÔºåÁä∂ÊÄÅÁ†ÅÔºà200ÔºâÔºåÁä∂ÊÄÅÊ∂àÊÅØÔºàokÔºâ Ê∂àÊÅØÊä•Â§¥ÔºöÂÆ¢Êà∑Á´ØÈúÄË¶Å‰ΩøÁî®ÁöÑÈôÑÂä†‰ø°ÊÅØ Á©∫Ë°å htmlÈÉ®ÂàÜ‰∏∫ÂìçÂ∫îÊ≠£Êñá ÂÖ≥‰∫éÁä∂ÊÄÅÁ†Å 200 ok ÊàêÂäü 3xx ÈáçÂÆöÂêëÔºåÂøÖÈ°ªÂÆåÊàêÊõ¥Ëøõ‰∏ÄÊ≠•ÁöÑÊìç‰Ωú 4xx ÂÆ¢Êà∑Á´ØÈîôËØØÔºåËØ∑Ê±ÇÊúâËØ≠Ê≥ïÈîôËØØÊàñËÄÖÊó†Ê≥ïÂÆûÁé∞ 5xx ÊúçÂä°Á´ØÈîôËØØÔºåÊúçÂä°Âô®Êú™ËÉΩÂÆûÁé∞ 1234567200 OK //ÂÆ¢Êà∑Á´ØËØ∑Ê±ÇÊàêÂäü400 Bad Request //ÂÆ¢Êà∑Á´ØËØ∑Ê±ÇÊúâËØ≠Ê≥ïÈîôËØØÔºå‰∏çËÉΩË¢´ÊúçÂä°Âô®ÊâÄÁêÜËß£401 Unauthorized //ËØ∑Ê±ÇÊú™ÁªèÊéàÊùÉÔºåËøô‰∏™Áä∂ÊÄÅ‰ª£Á†ÅÂøÖÈ°ªÂíåWWW-AuthenticateÊä•Â§¥Âüü‰∏ÄËµ∑‰ΩøÁî® 403 Forbidden //ÊúçÂä°Âô®Êî∂Âà∞ËØ∑Ê±ÇÔºå‰ΩÜÊòØÊãíÁªùÊèê‰æõÊúçÂä°404 Not Found //ËØ∑Ê±ÇËµÑÊ∫ê‰∏çÂ≠òÂú®ÔºåegÔºöËæìÂÖ•‰∫ÜÈîôËØØÁöÑURL500 Internal Server Error //ÊúçÂä°Âô®ÂèëÁîü‰∏çÂèØÈ¢ÑÊúüÁöÑÈîôËØØ503 Server Unavailable //ÊúçÂä°Âô®ÂΩìÂâç‰∏çËÉΩÂ§ÑÁêÜÂÆ¢Êà∑Á´ØÁöÑËØ∑Ê±ÇÔºå‰∏ÄÊÆµÊó∂Èó¥ÂêéÂèØËÉΩÊÅ¢Â§çÊ≠£Â∏∏ Â∑•‰ΩúÂéüÁêÜ ÂÆ¢Êà∑Á´ØÔºàÊµèËßàÂô®ÔºâËøûÊé•Âà∞ÊúçÂä°Âô®ÔºåÂíåÊúçÂä°Âô®ÁöÑhttpÁ´ØÂè£ÁÆÄÂéÜTCPËøûÊé•ÔºàTCPÔºö‰∏ÄÁßç‰º†ËæìÂçèËÆÆÔºâ ÂèëÈÄÅhttpËØ∑Ê±Ç ÊúçÂä°Âô®Êé•Êî∂Âπ∂ËøîÂõûÂìçÂ∫î ÈáäÊîæËøûÊé•TCPÔºåÂèØËÉΩ‰ºöÁî±ÊúçÂä°Âô®Êñ≠Á∫øÔºåÂèØËÉΩ‰ºö‰øùÊåÅ‰∏ÄÊÆµÊó∂Èó¥ ÂÆ¢Êà∑Á´ØËß£ÊûêhtmlÁöÑÂÜÖÂÆπÔºåÊòæÁ§∫ Â∞èÁü•ËØÜÔºöÂÖ≥‰∫épostÂíåget GETËØ∑Ê±ÇÔºåËØ∑Ê±ÇÊï∞ÊçÆ‰ºöÈôÑÂú®URLÂêéÈù¢ÔºåÁî®ÔºüÂàÜÂâ≤ÔºàÊØîÂ¶Ç‰º†ÂÖ•ÂèÇÊï∞ÁöÑÊó∂ÂÄôÔºâ Â¶ÇÊûúÊòØËã±ËØ≠ÊàñÊï∞Â≠óÔºåÂéüÊ†∑ Â¶ÇÊûúÊòØÁ©∫Ê†ºÊç¢Êàê+ Â¶ÇÊûúÊòØ‰∏≠ÊñáÊàñËÄÖÂÖ∂‰ªñÂ≠óÁ¨¶ÔºåÁõ¥Êé•ÊääÂ≠óÁ¨¶‰∏≤Âä†ÂØÜÂæóÂà∞16ËøõÂà∂ASCII ÊâÄ‰ª•GETÊèê‰∫§ÁöÑÊï∞ÊçÆ‰ºöÂú®Âú∞ÂùÄÊ†èÊòæÁ§∫Âá∫Êù•Ôºå‰ΩÜÊòØPOST‰ºöÊääÁªìÊûúÊîæÂú®ÂåÖ‰ΩìÈáåÈù¢Ôºå‰∏çÊîπÂèò ‰º†ËæìÊï∞ÊçÆÂ§ßÂ∞èÔºö URLÂØπÊï∞ÊçÆÁöÑÂ§ßÂ∞èÊ≤°ÊúâÈôêÂà∂Ôºå‰ΩÜÊòØÊúâ‰∫õÊµèËßàÂô®ÂèØËÉΩ‰ºöÈôêÂà∂URLÁöÑÂ≠óÁ¨¶ÈïøÂ∫¶ÔºåÂØºËá¥GET‰∏çË°å ÂÆâÂÖ®ÊÄßÔºö POSTÁöÑÂÆâÂÖ®ÊÄßÊõ¥È´ò„ÄÇ ‰ΩÜÊòØhttpÊú¨Ë∫´Â∞±ÊòØÊòéÊñáÂçèËÆÆÔºåÊâÄ‰ª•ÂÖ∂ÂÆûÂì™‰∏™ÈÉΩÂÆâÂÖ®ÊÄß‰∏çÈ´ò„ÄÇÊúÄ‰∏ªË¶ÅÁöÑÊñπÊ≥ïÊòØhttps ÂõûÂà∞requestÊú¨Ë∫´ÂèëÈÄÅËØ∑Ê±ÇÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®getÂëΩ‰ª§Ëé∑ÂèñÊüê‰∏™ÁΩëÈ°µÁöÑ‰ø°ÊÅØÔºåÁÑ∂Âêé‰ªéÂêçÂ≠ó‰∏∫rÁöÑÂØπË±°ÈáåÈù¢ÂæóÂà∞ÂêéÁª≠ÈúÄË¶ÅÁöÑ‰ø°ÊÅØÊàë‰ª¨ÂèØ‰ª•Áî®r.urlÊù•ÊâìÂç∞Áé∞Âú®ÁöÑurlÁ≠â1r = requests.get('https://api.github.com/events') ‰º†ÈÄíÂèÇÊï∞requestsÊîØÊåÅÁî®paramsÂÖ≥ÈîÆÂ≠óÊù•‰º†ËæìÂèÇÊï∞ÔºåÂèÇÊï∞ËÆæÁΩÆÂú®dictÈáåÈù¢12payload = &#123;'key1': 'value1', 'key2': 'value2'&#125;r = requests.get("http://httpbin.org/get", params=payload) ÂìçÂ∫îÂÜÖÂÆπÂìçÂ∫îÁöÑÂÜÖÂÆπÂèØ‰ª•Áî®r.textÊù•ÈôêÊó∂Ôºårequest‰ºöÊ†πÊçÆhttpÂ§¥ÈÉ®ÁöÑÁºñÁ†ÅÂØπÊñáÊú¨ËøõË°åËß£Á†ÅÔºåÂèØ‰ª•Áî®r.encodingÊù•Êü•ÁúãËß£Á†ÅÁ±ªÂûãÂπ∂‰∏îÊîπÂèò ‰∫åËøõÂà∂ÂìçÂ∫îÂÜÖÂÆπÂèØ‰ª•Áî®Â≠óËäÇÁöÑÊñπÂºèÊù•ËÆøÈóÆÂìçÂ∫î‰Ωìr.contentÔºå‰ºöËá™Âä®Ëß£Á†Å JsonÂìçÂ∫îÂÜÖÂÆπÂÜÖÁΩÆjsonËß£Á†ÅÂô®ÔºåÂèØ‰ª•Â§ÑÁêÜjsonÊï∞ÊçÆ„ÄÇr.json()Â¶ÇÊûúËß£Á†ÅÂ§±Ë¥•Ôºå‰ºöÊäõÂá∫ÂºÇÂ∏∏401 ÂéüÂßãÂìçÂ∫îÂÜÖÂÆπr.raw]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
        <category>Lib</category>
      </categories>
      <tags>
        <tag>Url</tag>
        <tag>Request</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫éÈìæË°®]]></title>
    <url>%2F2019%2F11%2F18%2F%E5%85%B3%E4%BA%8E%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[ËôΩÁÑ∂ÈìæË°®ÊòØ‰∏ÄÁßçÊØîËæÉÂü∫Á°ÄÁöÑÊï∞ÊçÆÁªìÊûÑÔºå‰ΩÜÊòØÂú®ÂÆûÈôÖÂ∫îÁî®ÁöÑÊó∂ÂÄôÁî®Â§ÑÊ≤°ÊúâÈÇ£‰πàÂ§ö ÈìæË°®ÊòØ‰∏ÄÁßçÁ∫øÊÄßÁöÑË°®Ôºå‰ΩÜÊòØ‰∏ç‰ºöÁ∫øÊÄßÁöÑÂ≠òÂÇ®Êï∞ÊçÆ Êï∞ÁªÑÂ≠òÂÇ®ÁöÑÊó∂ÂÄôÈúÄË¶ÅËøûÁª≠Â≠òÂÇ® ÂçïÂêëÈìæË°®Êúâ‰∏Ä‰∏™Â§¥ÁªìÁÇπheadÔºåÊåáÂêëÈìæË°®ÂÜÖÂ≠òÁöÑÈ¶ñÂú∞ÂùÄ„ÄÇÈìæË°®ÈáåÈù¢ÁöÑÊØè‰∏™ËäÇÁÇπÊúâ‰∏§‰∏™ÊàêÂëò ÈúÄË¶Å‰øùÂ≠òÁöÑÊï∞ÊçÆval ÊåáÂêë‰∏ã‰∏Ä‰∏™ÁªìÊûÑÁöÑÊåáÈíànext ÁâπÁÇπÔºö Êü•Êâæ ÂØπÂêÑ‰∏™ÁÇπÁöÑÊü•ÊâæÂøÖÈ°ª‰ªéÂ§¥ÊâæËµ∑ÔºåÂêéÁª≠ÁöÑÂú∞ÂùÄÊòØÂâçËäÇÁÇπÁªôÂá∫Êù•ÁöÑ„ÄÇÊó†ËÆ∫ËÆøÈóÆÂì™‰∏™ÁÇπÈÉΩÂøÖÈ°ª‰ªéÂ§¥Êù• Êó∂Èó¥Â§çÊùÇÂ∫¶nÔºåÂíåÊï∞ÁªÑÁõ∏Âêå ÊèíÂÖ•ÂíåÂà†Èô§Ôºà‰ºòÂäøÔºâ Áî±‰∫éÈìæË°®ÊòØ‰∏çËøûÁª≠ÁöÑÂ≠òÂÇ®ÔºåÊâÄ‰ª•Âú®ÊèíÂÖ•ÂíåÂà†Èô§ÁöÑÊó∂ÂÄôÔºåÈìæË°®‰∏çÈúÄË¶ÅÂ§ßÈáèÊàêÂëòÁöÑ‰ΩçÁßª Â§çÊùÇÂ∫¶1 ËØªÂèñÔºàÂä£ÂäøÔºâ Êï∞ÁªÑÂõ†‰∏∫ËøûÁª≠Â≠òÂÇ®ÔºåÊâÄ‰ª•ÂèØ‰ª•ÈÄöËøáÂØªÂùÄËøÖÈÄüÁöÑÂÆö‰Ωç„ÄÇ‰ΩÜÊòØÈìæË°®‰∏çËøûÁª≠ÔºåÊâÄ‰ª•ÂøÖÈ°ª‰æùÊçÆÊåáÈíàÊåÅÁª≠ÁöÑÈÅçÂéÜ Â∫îÁî® Áî±‰∫éÊúâÂèåÂêëÈìæË°®ÔºåÂçïÂêëÈìæË°®ÁöÑÂ∫îÁî®ÊØîËæÉÂ∞ë Êí§ÈîÄÂäüËÉΩÔºöÊñáÊú¨ÔºåÂõæÂΩ¢ÁºñËæëÂô®„ÄÇÁî®Âà∞‰∫ÜÈìæË°®ÁöÑÂà†Èô§ÁâπÊÄß ÂÆûÁé∞ÂõæÊàñËÄÖhashMapÁ≠âÈ´òÁ∫ßÊï∞ÊçÆÁªìÊûÑ ÂèåÂêëÈìæË°®Â¢ûÂä†‰∫Ü‰∏Ä‰∏™prevËäÇÁÇπÔºåÁõ∏ÂΩì‰∫éÂ§ö‰∫Ü‰∏Ä‰∏™ÊåáÈíàÔºåÊâÄ‰ª•Áî®ÂèåÂêëÈìæË°®Âç†ÁöÑÂÜÖÂ≠òÊõ¥Â§öÊØîÂ¶ÇÁºñËæëÂô®ÁöÑundo/redoÊìç‰ΩúÔºåÁî®ÂèåÂêëÈìæË°®Â∞±Êõ¥Â•Ω‰∏ÄÁÇπ„ÄÇÂ¶ÇÊûúÊòØÂçïÂêëÁöÑËØùÊó∂Èó¥‰ºöÊòØn Âæ™ÁéØÈìæË°®ÈìæË°®ÁöÑÊú´Â∞æÊåáÈíàÊåáÂêë‰∫ÜÈìæË°®ÂºÄÂ§¥ÊØîÂ¶ÇÂàÜÊó∂Ë£ÖÁΩÆ CPUÂ§ÑÁêÜÂ§ö‰∏™Áî®Êà∑ÁöÑËØ∑Ê±ÇÊó∂‰∫ßÁîüÊä¢Âç†ËµÑÊ∫êÁöÑÊÉÖÂÜµÔºåÈúÄË¶ÅÂàÜÊó∂Á≠ñÁï• ÊØè‰∏™Áî®Êà∑‰ª£Ë°®‰∏Ä‰∏™ËäÇÁÇπÔºå‰ºöÁªôÊØè‰∏™ËäÇÁÇπÂàÜÈÖç‰∏ÄÂÆöÁöÑÂ§ÑÁêÜÊó∂Èó¥ÔºåÁÑ∂ÂêéËøõÂÖ•‰∏ã‰∏Ä‰∏™ËäÇÁÇπ„ÄÇ LeetcodeÈìæË°®ÁªÉ‰π†È¢ò141 Âà§Êñ≠ÂçïÈìæË°®ÊòØÂê¶ÊúâcycleÊÄùË∑ØÔºö in-placeÁöÑÊñπÊ≥ïÔºåÂ¶ÇÊûú‰∏§‰∏™‰∫∫‰∏ÄËµ∑Ë∑ëÊ≠•Ôºå‰∏Ä‰∏™Âø´‰∏Ä‰∏™ÊÖ¢ÔºåÈÇ£‰πàÊÄªÊúâ‰∏Ä‰∏™Êó∂ÂàªÂø´ÁöÑ‰ºöÊääÊÖ¢ÁöÑÂ•óÂúà12345678910class Solution: def hasCycle(self, head: ListNode) -&gt; bool: fast = head slow = head while slow and fast and fast.next: slow = slow.next fast = fast.next.next if fast == slow: return True return False 24 ‰∫§Êç¢‰∏§‰∏™Áõ∏ÈÇªÁöÑnodeÊÄùË∑ØÔºö Ê≥®ÊÑèËøô‰∏™nodeÁöÑ‰∫§Êç¢Ôºå‰∏çÂçïÂíåÁõÆÂâçÁöÑÈÉ®ÂàÜÔºàÁõÆÂâçÊìç‰ΩúÁöÑ‰∏§‰∏™ÔºâÊúâÂÖ≥Á≥ªÔºåËøòÂíåÂâçÈù¢‰∏Ä‰∏™ÁÇπÊúâÂÖ≥Á≥ªÔºåÂõ†‰∏∫ÂâçÈù¢‰∏Ä‰∏™ÁÇπÁöÑnextÈúÄË¶ÅÊòØ‰∫§Êç¢‰πãÂâçÁöÑÂêé‰∏Ä‰∏™ÁÇπ Ê≥®ÊÑèwhileÊó∂ÂÄôÁöÑÊù°‰ª∂Âà§Êñ≠ÔºåÂøÖÈ°ª‰∏§‰∏™ÁÇπÈÉΩÂú®ÁöÑÊó∂ÂÄôÊâçËÉΩËøõË°å‰∫§Êç¢ Ê≥®ÊÑèdËøô‰∏™ÈôÑÂä†ÁöÑÁÇπÔºåÁî®Ëøô‰∏™ÁÇπÂèØ‰ª•Âø´ÈÄüÁöÑÂÆö‰ΩçheadÁÇπ 123456789101112131415161718class Solution: def swapPairs(self, head: ListNode) -&gt; ListNode: counter = 0 d = ListNode(-1) d.next = head prev_node = d while head and head.next: curr = head to_swap = head.next prev_node.next = to_swap curr.next = to_swap.next to_swap.next = curr prev_node = curr head = curr.next return d.next 328 ÊääÈìæË°®ÁöÑodd‰ΩçÈÉΩ‰∫§Êç¢Âà∞ÂâçÈù¢ÂéªÊÄùË∑ØÔºö Âà§Êñ≠Ëøô‰∏™ÁÇπÂ¶ÇÊûúÊòØoddÔºåÈÇ£‰πà‰∏ä‰∏Ä‰∏™oddÁöÑnextÊòØÁé∞Âú®ÁöÑÁÇπÔºåËøô‰∏™ÁÇπÁöÑ‰∏ã‰∏Ä‰∏™ÊåáÂêëevenÁöÑÂºÄÂßãÁÇπ Â¶ÇÊûúËøô‰∏™ÁÇπÊòØevenÔºåÈÇ£‰πà‰∏ä‰∏Ä‰∏™evenÁöÑnextÊòØÁé∞Âú®ÁöÑÁÇπÔºåËøô‰∏™ÁÇπÁöÑ‰∏ã‰∏Ä‰∏™ÊòØnull Ê≠ªÁ£ï‰∫Ü‰∏Ä‰∏™Â∞èÊó∂ÁöÑÂéüÂõ†Ôºö Ê≥®ÊÑèÊ∑±Êã∑Ë¥ùÂíåÊµÖÊã∑Ë¥ùÁöÑÈóÆÈ¢òÔºåÊµÖÊã∑Ë¥ùÁöÑÊó∂ÂÄôÔºåÊîπÂèòËøô‰∏™‰∏úË•øÁöÑÂêåÊó∂Ôºå‰πãÂâçÁöÑ‰πü‰ºöÊîπÂèò Ê≥®ÊÑèÂΩ¢ÊàêÁéØÁöÑÈóÆÈ¢òÔºå‰∏ÄÂÆöË¶ÅÊ≥®ÊÑèÊØè‰∏™ÁÇπÁöÑinputÂíåoutputÁöÑÊñπÂêëÈÉΩÁ°ÆÂÆö‰∫ÜÔºåËØ•ËµãÂÄº0ÁöÑÊó∂ÂÄôËµãÂÄº0 Ê≥®ÊÑèÊØèÊ¨°ÁöÑoddÁÇπÈÉΩÂ∫îËØ•ÊåáÂêëevenÁöÑËµ∑ÂßãÁÇπ Âú®‰∏ã‰∏Ä‰∏™ÁÇπ‰ºöÂèòÂåñÁöÑÊó∂ÂÄôÔºåËÆ∞ÂæóÂèäÊó∂‰øùÂ≠ò1234567891011121314151617181920212223242526272829303132333435class Solution: def oddEvenList(self, head: ListNode) -&gt; ListNode: start = ListNode(-1) even_start = ListNode(-1) start.next = head if (not head) or (not head.next): return head prev_odd = head prev_even = head.next even_start.next = prev_even counter = 1 while head: curr = head if counter &gt;=3: temp = curr.next if counter % 2 != 0: #odd prev_odd.next = curr curr.next = even_start.next if counter == 3: even_start.next.next = None prev_odd = curr elif counter % 2 == 0:#even prev_even.next = curr prev_even = curr curr.next = None head = temp else: head = curr.next counter += 1 return start.next]]></content>
      <categories>
        <category>Âü∫Á°Ä</category>
        <category>Êï∞ÊçÆÁªìÊûÑ</category>
      </categories>
      <tags>
        <tag>ÈìæË°®</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ËÆ°ÁÆóÊú∫ÁΩëÁªú]]></title>
    <url>%2F2019%2F11%2F05%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[Ê¶ÇËø∞ÁΩëÁ∫øÊää‰∏ªÊú∫ËøûÊé•Ëµ∑Êù•‰∫íËÅîÁΩëÊää‰∏çÂêåÁöÑÁΩëÁªúËøûÊé•Ëµ∑Êù• ISP‚Äú‰∫íËÅîÁΩëÊúçÂä°‰æõÂ∫îÂïÜ‚Äù‰ªé‰∫íËÅîÁΩëÁÆ°ÁêÜÊú∫ÊûÑËé∑ÂæóIPÂú∞ÂùÄÔºåÊã•ÊúâÈÄö‰ø°Á∫øË∑Ø‰ª•ÂèäË∑ØÁî±Âô®Á≠âËÅîÁΩëËÆæÂ§áÔºå‰∏™‰∫∫ÊàñÊú∫ÊûÑÁº¥Á∫≥‰∏ÄÂÆöÁöÑË¥πÁî®Â∞±ÂèØ‰ª•ËøûÂÖ•‰∫íËÅîÁΩë ‰∏ªÊú∫Èó¥ÁöÑÈÄö‰ø°ÊñπÂºè client-serverÔºöÂÆ¢Êà∑ÊòØÊúçÂä°ÁöÑËØ∑Ê±ÇÊñπÔºåÊúçÂä°Âô®ÊòØ‰æõÂ∫îÊñπ P2PÔºö‰∏çÂå∫ÂàÜÂÆ¢Êà∑ÂíåÊúçÂä°Âô® ÁîµË∑Ø‰∫§Êç¢ÂíåÂàÜÁªÑ‰∫§Êç¢ ÁîµË∑Ø‰∫§Êç¢ÔºöÁîµËØùÈÄö‰ø°Á≥ªÁªüÔºåÈúÄË¶ÅÂª∫Á´ãÁâ©ÁêÜÈìæ ÂàÜÁªÑ‰∫§Êç¢ÔºöÊØè‰∏™ÂàÜÁªÑÊúâÈ¶ñÈÉ®ÂíåÂ∞æÈÉ®ÔºåÂåÖÂê´‰∫ÜÊ∫êÂú∞ÂùÄÂíåÁõÆÁöÑÂú∞ÂùÄÁ≠â„ÄÇÂêå‰∏Ä‰∏™‰º†ËæìË∑ØÂæÑ‰∏ä‰∫íÁõ∏‰∏çÂèóÂΩ±Âìç Êó∂Âª∂ ÊéíÈòüÊó∂Âª∂ÔºöË∑ØÁî±Âô®ËæìÂÖ•ÂíåËæìÂá∫ÈòüÂàóÈó¥ÁöÑÁ≠âÂæÖÊó∂Èó¥ÔºåÂèñÂÜ≥‰∫éÈÄö‰ø°Èáè Â§ÑÁêÜÊó∂Âª∂Ôºö‰∏ªÊú∫ÊàñË∑ØÁî±Âô®ÂèóÂà∞ÂàÜÁªÑÊó∂ÁöÑÂ§ÑÁêÜÊó∂Èó¥ÔºàÂàÜÊûêÈ¶ñÈÉ®ÔºåÊèêÂèñÊï∞ÊçÆÔºåËøõË°åÂ∑ÆÈîôÊ£ÄÈ™åÁ≠âÔºâ ‰º†ËæìÊó∂Âª∂Ôºö‰º†ËæìÊâÄÁî®ÁöÑÊó∂Èó¥ ‰º†Êí≠Êó∂Âª∂ÔºöÂú®‰ø°ÈÅì‰∏≠‰º†Êí≠Áî®ÁöÑÊó∂Èó¥ ËÆ°ÁÆóÊú∫ÁΩëÁªú‰ΩìÁ≥ªÁªìÊûÑ ‰∫îÂ±Ç Â∫îÁî®Â±ÇÔºö‰∏∫ÁâπÂÆöÂ∫îÁî®Êèê‰æõÊï∞ÊçÆ‰º†ËæìÔºåHTTPÔºåDNSÁ≠âÂçèËÆÆÔºàÊä•ÊñáÔºâ ‰º†ËæìÂ±ÇÔºö‰∏∫ËøõÁ®ãÊèê‰æõÈÄöÁî®Êï∞ÊçÆ‰º†ËæìÊúçÂä°„ÄÇÁî±‰∫éÂ∫îÁî®Â±ÇÂçèËÆÆÂæàÂ§öÔºåÂÆö‰πâÈÄöÁî®ÁöÑ‰º†ËæìÂ±ÇÂçèËÆÆÂ∞±ÂèØ‰ª•ÊîØÊåÅ‰∏çÊñ≠Â¢ûÂ§öÁöÑÂ∫îÁî®Â±ÇÂçèËÆÆ„ÄÇËøêËæìÂ±ÇÂåÖÊã¨‰∏§ÁßçÂçèËÆÆÔºö‰º†ËæìÊéßÂà∂ÂçèËÆÆ TCPÔºåÊèê‰æõÈù¢ÂêëËøûÊé•„ÄÅÂèØÈù†ÁöÑÊï∞ÊçÆ‰º†ËæìÊúçÂä°ÔºåÊï∞ÊçÆÂçï‰Ωç‰∏∫Êä•ÊñáÊÆµÔºõÁî®Êà∑Êï∞ÊçÆÊä•ÂçèËÆÆ UDPÔºåÊèê‰æõÊó†ËøûÊé•„ÄÅÂ∞ΩÊúÄÂ§ßÂä™ÂäõÁöÑÊï∞ÊçÆ‰º†ËæìÊúçÂä°ÔºåÊï∞ÊçÆÂçï‰Ωç‰∏∫Áî®Êà∑Êï∞ÊçÆÊä•„ÄÇTCP ‰∏ªË¶ÅÊèê‰æõÂÆåÊï¥ÊÄßÊúçÂä°ÔºåUDP ‰∏ªË¶ÅÊèê‰æõÂèäÊó∂ÊÄßÊúçÂä°„ÄÇ ÁΩëÁªúÂ±ÇÔºö‰∏∫‰∏ªÊú∫Êèê‰æõÊï∞ÊçÆ‰º†ËæìÊúçÂä°ÔºåÁΩëÁªúÂ±ÇÊää‰º†ËæìÂ±Ç‰º†ÈÄí‰∏ãÊù•ÁöÑÊä•ÊñáÊÆµÊàñËÄÖÁî®Êà∑Êï∞ÊçÆÊä•Â∞ÅË£ÖÊàêÂàÜÁªÑ„ÄÇ Êï∞ÊçÆÈìæË∑ØÂ±ÇÔºöÁΩëÁªúÂ±ÇÈíàÂØπÁöÑËøòÊòØ‰∏ªÊú∫‰πãÈó¥ÁöÑÊï∞ÊçÆ‰º†ËæìÊúçÂä°ÔºåËÄå‰∏ªÊú∫‰πãÈó¥ÂèØ‰ª•ÊúâÂæàÂ§öÈìæË∑ØÔºåÈìæË∑ØÂ±ÇÂçèËÆÆÂ∞±ÊòØ‰∏∫Âêå‰∏ÄÈìæË∑ØÁöÑ‰∏ªÊú∫Êèê‰æõÊï∞ÊçÆ‰º†ËæìÊúçÂä°„ÄÇÊï∞ÊçÆÈìæË∑ØÂ±ÇÊääÁΩëÁªúÂ±Ç‰º†‰∏ãÊù•ÁöÑÂàÜÁªÑÂ∞ÅË£ÖÊàêÂ∏ß„ÄÇ Áâ©ÁêÜÂ±Ç OSI Ë°®Á§∫Â±ÇÔºöÊï∞ÊçÆÂéãÁº©ÔºåÂä†ÂØÜÔºåÊèèËø∞„ÄÇ‰∏çÂøÖÂÖ≥ÂøÉÂêÑÂè∞‰∏ªÊú∫Êï∞ÊçÆÂÜÖÈÉ®Ê†ºÂºè‰∏çÂêåÁöÑÈóÆÈ¢ò ‰ºöËØùÂ±ÇÔºöÂª∫Á´ãÂíåÁÆ°ÁêÜ‰ºöËØù TCP/IPÊï∞ÊçÆÈìæË∑ØÂ±ÇÂíåÁâ©ÁêÜÂ±ÇÂêàÂπ∂‰∏∫ÁΩëÁªúÊé•Âè£Â±Ç]]></content>
      <categories>
        <category>Âü∫Á°Ä</category>
        <category>ËÆ°ÁÆóÊú∫ÁΩëÁªú</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ËÆ°ÁÆóÊú∫Êìç‰ΩúÁ≥ªÁªü]]></title>
    <url>%2F2019%2F11%2F05%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Ê¶ÇËø∞Â§ßÁ∫≤Ôºö‰∏≠Êñ≠ÔºåÁ≥ªÁªüË∞ÉÁî®ÔºåÂÜÖÂ≠òÁÆ°ÁêÜÔºåËøõÁ®ãÁ∫øÁ®ãÔºåË∞ÉÂ∫¶ÔºåÂêåÊ≠•ÔºåÊñá‰ª∂Á≥ªÁªüÔºåI/O ‰ªÄ‰πàÊòØÊìç‰ΩúÁ≥ªÁªü ÂäüËÉΩ‰∏ä ÂØπÁî®Êà∑Êù•ËØ¥ÔºåOSÊòØÊéßÂà∂ ÁÆ°ÁêÜÂ∫îÁî®Á®ãÂ∫èÁöÑËøêË°å ‰∏∫Â∫îÁî®Á®ãÂ∫èÊèê‰æõÊúçÂä° ÊùÄÊ≠ªÂ∫îÁî®Á®ãÂ∫è ÂØπ‰∏ã ËµÑÊ∫êÂàÜÈÖçÔºåÁÆ°ÁêÜÔºåÂ§ñËÆæÁÆ°ÁêÜÔºàÂ§ö‰∏™ËµÑÊ∫êÁöÑÂçèË∞ÉÔºâ Êâø‰∏äÂêØ‰∏ãÁöÑ‰ΩúÁî®ÔºöÂ±ÇÊ¨°Êû∂ÊûÑ Á°¨‰ª∂‰πã‰∏ä Â∫îÁî®Á®ãÂ∫èÔºàÊØîÂ¶ÇÂäûÂÖ¨ËΩØ‰ª∂ÔºåËßÜÈ¢ëÊí≠ÊîæËΩØ‰ª∂Á≠âÁ≠âÔºâ‰πã‰∏ã OS‰∏∫Â∫îÁî®ËΩØ‰ª∂Êèê‰æõÊúçÂä°ÊîØÊíë ÂàÜ‰∏∫‰∏§ÈÉ®ÂàÜÔºöshellÈÉ®ÂàÜÔºåÂØπÂ§ñÁöÑÊé•Âè£„ÄÇkernelÈÉ®ÂàÜÔºå‰πüÂ∞±ÊòØOSÁöÑÊú¨Ë∫´ kernelÈÉ®ÂàÜ CPUÁÆ°ÁêÜÔºåËøõÁ®ãÁ∫øÁ®ã ÂÜÖÂ≠òÁÆ°ÁêÜÔºàÁâ©ÁêÜÂÜÖÂ≠òÔºåËôöÊãüÂÜÖÂ≠òÔºâ ËôöÊãüÂÜÖÂ≠òÔºöÁªô‰∏äÂ±ÇÂ∫îÁî®Êèê‰æõÂ∞ΩÂèØËÉΩÂ§ßÁöÑÂÜÖÂ≠òÁ©∫Èó¥ Êñá‰ª∂Á≥ªÁªüÁÆ°ÁêÜ ÔºàÂ∫ïÂ±ÇÁõ∏ÂÖ≥Ôºâ‰∏≠Êñ≠Â§ÑÁêÜÂíåËÆæÂ§áÈ©±Âä® -&gt; Áõ¥Êé•ÂíåÁ°¨‰ª∂Êâì‰∫§ÈÅì Êìç‰ΩúÁ≥ªÁªüÁöÑÁâπÂæÅ Âπ∂ÂèëconcurrencyÔºöÂêåÊó∂Â≠òÂú®Â§ö‰∏™ËøêË°åÁöÑÁ®ãÂ∫èÔºåÈúÄË¶ÅOSÁÆ°ÁêÜÂíåË∞ÉÂ∫¶ ‰∏ÄÊÆµÊó∂Èó¥ÂÜÖÔºåÂ§ö‰∏™Á®ãÂ∫è Âπ∂Ë°åparallelismÔºö‰∏Ä‰∏™Êó∂Èó¥ÁÇπ‰∏äÂ§ö‰∏™Á®ãÂ∫è„ÄÇ‰∏ÄËà¨Âπ∂Ë°åÁöÑÈúÄË¶ÅÊúâÂ§ö‰∏™CPU ÂÖ±‰∫´ÔºöÊúâÊïàËÆ©ËµÑÊ∫êÂÖ±‰∫´ÁªôÈúÄË¶ÅÁöÑÂ∫îÁî®Á®ãÂ∫è ÂØπ‰∫é‰∏Ä‰∏™ÂÜÖÂ≠òÂçïÂÖÉÔºö‰∏Ä‰∏™Êó∂Èó¥ÁÇπ‰∏äÂè™Êúâ‰∏Ä‰∏™Á®ãÂ∫èËÆøÈóÆ‰∏Ä‰∏™ËµÑÊ∫ê ÂêåÊó∂ËÆøÈóÆÔºü‰∫íÊñ•ÂÖ±‰∫´Ôºü ËôöÊãüÔºöËÆ©ÊØè‰∏™Áî®Êà∑ÈÉΩËßâÂæóÊúâ‰∏Ä‰∏™ËÆ°ÁÆóÊú∫‰∏ìÈó®‰∏∫‰ªñÊúçÂä° Êää‰∏ÄÂè∞Êú∫Âô®ËôöÊãüÊàêÂ§öÂè∞Êú∫Âô® ÂºÇÊ≠•ÔºàËôΩÁÑ∂ÊâßË°åÁöÑÊ≠•È™§‰∏çÂêåÔºå‰ΩÜÊòØÁªìÊûú‰πüÁõ∏ÂêåÔºâ ‰∏çÊòØ‰∏ÄË¥ØÂà∞Â∫ïÁöÑÔºåÊòØËµ∞Ëµ∞ÂÅúÂÅúÁöÑÔºåÂêëÂâçÊé®ËçêÁöÑÈÄüÂ∫¶‰∏çÂèØÁü• ‰ΩÜÊòØËøêË°åÁéØÂ¢ÉÁõ∏ÂêåÔºåOSË¶Å‰øùËØÅËøêË°åÁöÑÁªìÊûú‰πüÁõ∏Âêå ‰∏∫‰ªÄ‰πàÂ≠¶‰π†OS ÊïàÁéáÔºåÂèØÈù† -&gt; ÁÆóÊ≥ï Á°¨‰ª∂ ËâØÂ•ΩÁöÑÁ°¨‰ª∂ÁÆ°ÁêÜÔºåÂêàÁêÜÁöÑËµÑÊ∫êÂàÜÈÖç Á°¨‰ª∂ÂèØ‰ª•ÂÆåÊàêÂæàÂ§öOS‰ª•ÂâçÂÖ≥Ê≥®ÁöÑÈóÆÈ¢ò ÈúÄË¶ÅÊùÉË°° Êó∂Èó¥Á©∫Èó¥ ÊÄßËÉΩÂíåÂèØÈ¢ÑÊµã ÂÖ¨Âπ≥ÂíåÊÄßËÉΩ ÁªèÂÖ∏OS UNIX LinuxÔºöÁßªÂä®ÁªàÁ´ØÁöÑÂç†ÊúâÈáèÈùûÂ∏∏Â§ß Windows ÂéÜÂè≤]]></content>
      <categories>
        <category>Âü∫Á°Ä</category>
        <category>OS</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂâëÊåáoffer]]></title>
    <url>%2F2019%2F11%2F05%2F%E5%89%91%E6%8C%87offer%2F</url>
    <content type="text"><![CDATA[Èù¢ËØïÁöÑÊµÅÁ®ã ËÉΩÂÜôÂçïÂÖÉÊµãËØïÔºåÂä†ÂàÜ Á≠îÈùûÊâÄÈóÆÔºå‰∏çÊáÇË£ÖÊáÇÔºåÂ§ßÂøå ÂáÜÂ§áÂá†‰∏™ÈóÆÈ¢ò Èù¢ËØïÁöÑ‰∏â‰∏™ÁéØËäÇË°å‰∏∫Èù¢ËØï 5-10ÂàÜÈíü ÊÄßÊ†ºÁâπÁÇπ Ê∑±ÂÖ•‰∫ÜËß£È°πÁõÆÁªèÂéÜ È°πÁõÆ‰ªãÁªçÊñπÊ≥ï ÁÆÄÁü≠ÁöÑÈ°πÁõÆËÉåÊôØ Ëá™Â∑±ÂÆåÊàêÁöÑ‰ªªÂä°ÔºàÂèÇ‰∏é != Ë¥üË¥£Ôºâ ‰∏∫‰∫ÜÂÆåÊàê‰ªªÂä°Ëá™Â∑±ÊòØÊÄé‰πàÂÅöÁöÑ Ëá™Â∑±ÁöÑË¥°ÁåÆÔºåÊúÄÂ•ΩËÉΩÁî®Êï∞Â≠óÂä†‰ª•ËØ¥Êòé ËøΩÈóÆÈóÆÈ¢òÔºö ÈÅáÂà∞ÊúÄÂ§ßÁöÑÈóÆÈ¢òÊòØ‰ªÄ‰πàÔºåÊÄé‰πàËß£ÂÜ≥ Â≠¶Âà∞‰∫Ü‰ªÄ‰πà ÂíåÂÖ∂‰ªñÂõ¢ÈòüÊàêÂëòÊúâ‰ªÄ‰πàÂÜ≤Á™ÅÔºåÊÄé‰πàËß£ÂÜ≥ÁöÑ ÁÆÄÁü≠ÁöÑ‰ªãÁªç ÂØπÊäÄËÉΩÁöÑÂàÜÁ∫ß ‰∫ÜËß£ÔºöÂè™ÊòØÂ≠¶ËøáÔºå‰ΩÜÊòØÊ≤°ÊúâÂÅöËøáÂÆûÈôÖÁöÑÈ°πÁõÆ ÁÜüÊÇâÔºö Â§ßÈÉ®ÂàÜÁöÑÊäÄËÉΩ Á≤æÈÄö ‰∏çË¶ÅÈöè‰æøÁî® Â¶ÇÊûúÊúâ‰∫∫ËØ∑ÊïôËøô‰∏™ÊñπÈù¢ÁöÑÈóÆÈ¢òÊúâ‰ø°ÂøÉËß£ÂÜ≥ÔºåÊâçËÉΩÁî®Á≤æÈÄö ‰∏∫‰ªÄ‰πàË∑≥ÊßΩ NGÁ≠îÊ°à ËÄÅÊùøÂàªËñÑ Âêå‰∫ãÈöæÁõ∏Â§Ñ Âä†Áè≠È¢ëÁπÅ Â∑•ËµÑÂ§™‰Ωé ÂèØ‰ª•Â∞ùËØïÁöÑ ÂØπÁé∞Âú®ÁöÑÂ∑•‰ΩúÂ§±Âéª‰∫ÜÊøÄÊÉÖÔºåÈúÄË¶ÅÂØªÊâæ‰∏Ä‰ªΩÊúâÊåëÊàò ÊäÄÊúØÈù¢ËØï 40-50ÂàÜÈíü Âü∫Á°ÄÁü•ËØÜ Êï∞ÊçÆÁªìÊûÑÔºåÁÆóÊ≥ïÔºåÁºñÁ®ãËØ≠Ë®ÄÁ≠â ËÉΩÂÜôÂá∫Ê∏ÖÊô∞ÔºåÂÆåÊï¥ÁöÑ‰ª£Á†Å ËÉΩÊÄùË∑ØÊ∏ÖÊô∞ÁöÑËß£ÂÜ≥ÈóÆÈ¢ò ÁÆÄÂçïÈóÆÈ¢ò-&gt; Ê∏ÖÊô∞‰ª£Á†Å Â§çÊùÇÈóÆÈ¢ò-&gt; ÁîªÂõæÔºå‰∏æ‰æãÁ≠âÂàÜÊûê ËÉΩ‰ªéÊó∂Èó¥Á©∫Èó¥ÊñπÈù¢‰ºòÂåñ‰ª£Á†Å ‰∏ªÂä®ÊèêÈóÆÔºåÂºÑÊ∏ÖË¶ÅÊ±Ç Ê≤üÈÄöËÉΩÂäõÔºåÂ≠¶‰π†ËÉΩÂäõÔºåÂèëÊï£ÊÄùÁª¥ËÉΩÂäõ Âü∫Á°Ä ÂØπ‰∏ÄÈó®ÁºñÁ®ãËØ≠Ë®ÄÁöÑÊéåÊè° Êï∞ÊçÆÁªìÊûÑ ÈìæË°®ÔºåÊ†ëÔºåÊ†àÔºåÈòüÂàóÔºåÂìàÂ∏åË°® Â∞§ÂÖ∂ÊòØÈìæË°®Âíå‰∫åÂèâÊ†ë Êü•ÊâæÔºåÊéíÂ∫èÁÆóÊ≥ïÁ≠â È´òË¥®Èáè‰ª£Á†Å ËæπÁïåÊù°‰ª∂ÔºåÁâπÊÆäËæìÂÖ• ÁÆÄÂçïÁöÑÈóÆÈ¢òÈúÄË¶ÅÂÆåÊï¥ÁöÑËÄÉËôëÈóÆÈ¢òÔºåËÄÉËôëÁâπÊÆäÊù°‰ª∂ ‰ª£Á†ÅÊòØ‰∏çÊòØÂ§üÈ≤ÅÊ£í Ê∏ÖÊô∞ÁöÑÊÄùË∑Ø ‰∏æÂá†‰∏™ÁÆÄÂçïÁöÑ‰æãÂ≠êËÆ©Ëá™Â∑±ÁêÜËß£ÈóÆÈ¢ò ÂõæÂΩ¢ÊäΩË±°Êï∞ÊçÆÁªìÊûÑ ÊääÂ§çÊùÇÁöÑÈóÆÈ¢òÂàÜÊàêÁÆÄÂçïÁöÑÂ≠êÈóÆÈ¢ò ‰ºòÂåñÊïàÁéáÁöÑËÉΩÂäõ ‰∏çËÉΩÊîæÂºÉÊÄùËÄÉ ÈúÄË¶ÅÁü•ÈÅìÊÄé‰πàËÆ°ÁÆóÊïàÁéá ÊØîÂ¶ÇÊñêÊ≥¢ÈÇ£Â•ëÊï∞ÂàóÔºåÁî®top-downÂ∞±ÊØîbottom-upÁöÑÈáçÂ§çËÆ°ÁÆóÂ§öÂá∫ÂæàÂ§ö Áü•ÈÅìÂêÑÁßçÊï∞ÊçÆÁªìÊûÑÁöÑ‰ºòÁº∫ÁÇπ Â≠¶‰π†ËÉΩÂäõ ÊúÄËøëÂú®Áúã‰ªÄ‰πà‰π¶ÔºåÂ≠¶‰π†Âà∞‰∫Ü‰ªÄ‰πàÊñ∞ÊäÄÊúØ ÊäõÂá∫‰∏Ä‰∏™Êñ∞Ê¶ÇÂøµÔºåÁêÜËß£Âπ∂Ëß£ÂÜ≥Áõ∏ÂÖ≥ÁöÑÈóÆÈ¢ò ÊèêÈóÆÁéØËäÇ 5-10ÂàÜÈíü ‰∏çË¶ÅÈóÆÂíåËá™Â∑±ËÅå‰ΩçÊ≤°ÂÖ≥Á≥ªÁöÑÈóÆÈ¢ò ‰∏çË¶ÅÈóÆËñ™Ê∞¥ÔºàÊåáÊäÄÊúØÈù¢ËØïÔºâ ‰∏çË¶ÅÁ´ãÂç≥ÊâìÂê¨Èù¢ËØïÁöÑÁªìÊûú ‰∏éÂ∫îËÅòÁöÑËÅå‰ΩçÂíåÈ°πÁõÆÁõ∏ÂÖ≥ÁöÑÈóÆÈ¢ò ÊèêÂâç‰∫ÜËß£ÂÖ¨Âè∏‰ø°ÊÅØ Ê≥®ÊÑèÈù¢ËØïÊó∂ÂØπÊñπ‰ªãÁªçÁöÑÂÜÖÂÆπ Á¨¨‰∫åÁ´† Èù¢ËØïÁöÑÂü∫Á°ÄÁü•ËØÜÁºñÁ®ãËØ≠Ë®ÄÈ©±Âä®CÔºålinuxCppÔºåwindowsC#ÔºåË∑®Âπ≥Âè∞JavaÔºåËãπÊûúO-CÔºåÂ∞èÂûãÂ∫îÁî®PerlÔºåPython C++ sizeofÔºà‰πüÂ∞±ÊòØÊãøÁùÄÂáÜÂ§áÂ•ΩÁöÑÊ¶ÇÂøµÈ¢òÔºâ Á©∫Á±ªÂûãÁöÑsizeofÔºåinstanceÈúÄË¶ÅÂç†ÊçÆ‰∏ÄÂÆöÁ©∫Èó¥ÔºåÂç†Áî®Â§öÂ∞ëÁºñËØëÂô®ÂÜ≥ÂÆö Áªô‰∏ÄÊÆµ‰ª£Á†ÅÔºåÁúãÊòØÂê¶ËÉΩÂ§üËøêË°åÁ≠â ÂÆö‰πâ‰∏Ä‰∏™Á±ªÂûãÊàñÂÆûÁé∞Á±ªÂûã‰∏≠ÁöÑÊàêÂëòÂáΩÊï∞ Áõ∏ÂÖ≥‰π¶Á±ç Effective C++ÔºàÈù¢ËØï‰πãÂâçÁ™ÅÂáªÔºâ C++ PrimerÔºàËØ≠Ê≥ïÁöÑÂÖ®Èù¢‰∫ÜËß£Ôºâ Ê∑±Â∫¶ÊêúÁ¥¢C++ÂØπË±°Ê®°ÂûãÔºà‰∫ÜËß£ÂØπË±°ÂÜÖÈÉ®Ôºâ The C++ Programming LanguageÔºàÊ∑±ÂÖ•‰∫ÜËß£Ôºâ C\ ‰∏ªË¶Å‰ºöÈóÆC++ÂíåC#ÁöÑÂå∫Âà´ Áõ∏ÂÖ≥‰π¶Á±ç Professional C#ÔºàÂÜôÁªôÂ∑≤ÁªèÊúâÂÖ∂‰ªñÁªèÈ™åÁöÑÁ®ãÂ∫èÂëòÔºâ CLR Via C# Êï∞ÊçÆÁªìÊûÑ]]></content>
      <categories>
        <category>Â∞±ËÅå</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫édocker]]></title>
    <url>%2F2019%2F11%2F05%2F%E5%85%B3%E4%BA%8Edocker%2F</url>
    <content type="text"><![CDATA[Docker DockerÂÖ•Èó®ÊïôÁ®ã ÈÄö‰øóËß£ÈáäDockerÊòØ‰ªÄ‰πà Ëß£ÂÜ≥ÁöÑÈóÆÈ¢ò‰∏çÂêåÁöÑÊú∫Âô®Êúâ‰∏çÂêåÁöÑÊìç‰ΩúÁ≥ªÁªüÔºåÂ∫ìÂíåÁªÑ‰ª∂„ÄÇÊää‰∏Ä‰∏™Â∫îÁî®ÈÉ®ÁΩ≤Âà∞Â§öÂè∞Êú∫Âô®‰∏äÈúÄË¶ÅÂ§ßÈáèÁéØÂ¢ÉÈÖçÁΩÆÁöÑÊìç‰Ωú ‰∏ªË¶ÅÂ∞±ÊòØÂÆûÁé∞ÈöîÁ¶ªÊÄß„ÄÇ‰ΩÜÊòØÊØîËôöÊãüÊú∫ÁöÑÈöîÁ¶ªÊÄßÂ•ΩÂæàÂ§ö ‰∏ªË¶ÅËß£ÂÜ≥ÁöÑÈóÆÈ¢ò Á°¨‰ª∂ÊÄßËÉΩËøáÂâ©„ÄÇÂú®ÂæàÂ§öÊó∂ÂÄôÁ°¨‰ª∂Â§Ñ‰∫éÈó≤ÁΩÆÁä∂ÊÄÅ ËΩØ‰ª∂ÂÜ≤Á™Å ‰ΩÜÊòØÂú®‰∏äÈù¢ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂ¶ÇÊûú‰ΩøÁî®Â§öÂè∞ÁîµËÑëÊàêÊú¨ÂæàÈ´òÔºåÊâÄ‰ª•Âú®Á°¨‰ª∂Êú∫ËÉΩËøáÂâ©ÁöÑÊÉÖÂÜµ‰∏ãÔºåÁ°¨‰ª∂ËôöÊãüÂåñÁöÑÊôÆÂèäÂ∞±ÊèêÂá∫Êù•‰∫Ü 12ÁªùÂ§ßÈÉ®ÂàÜÂ∫îÁî®ÔºåÂºÄÂèëËÄÖÈÉΩÂèØ‰ª•ÈÄöËøádocker buildÂàõÂª∫ÈïúÂÉèÔºåÈÄöËøádocker push‰∏ä‰º†ÈïúÂÉèÔºåÁî®Êà∑ÈÄöËøádocker pull‰∏ãËΩΩÈïúÂÉèÔºåÁî®docker runËøêË°åÂ∫îÁî®„ÄÇÁî®Êà∑‰∏çÈúÄË¶ÅÂÜçÂéªÂÖ≥ÂøÉÂ¶Ç‰ΩïÊê≠Âª∫ÁéØÂ¢ÉÔºåÂ¶Ç‰ΩïÂÆâË£ÖÔºåÂ¶Ç‰ΩïËß£ÂÜ≥‰∏çÂêåÂèëË°åÁâàÁöÑÂ∫ìÂÜ≤Á™Å‚Äî‚ÄîËÄå‰∏îÈÄöÂ∏∏‰∏ç‰ºöÈúÄË¶ÅÊ∂àËÄóÊõ¥Â§öÁöÑÁ°¨‰ª∂ËµÑÊ∫êÔºå‰∏ç‰ºöÊòéÊòæÈôç‰ΩéÊÄßËÉΩ„ÄÇËøôÂ∞±ÊòØÂÖ∂‰ªñÁ≠î‰∏ªÊâÄËØ¥ÁöÑÊ†áÂáÜÂåñ„ÄÅÈõÜË£ÖÁÆ±ÁöÑÂéüÂõ†ÊâÄÂú®„ÄÇ DockerÊòØÂØπLinuxÂÆπÂô®ÔºàLinux ContainersÔºâÁöÑ‰∏ÄÁßçÂ∞ÅË£Ö dockerËß£ÂÜ≥ÁöÑÂ∞±ÊòØÁéØÂ¢ÉÈÖçÁΩÆÁöÑÈóÆÈ¢ò„ÄÇ ÂØπËøõÁ®ãÈöîÁ¶ªÔºåË¢´ÈöîÁ¶ªÁöÑËøõÁ®ãÁã¨Á´ã‰∫éÂÆø‰∏ªÁ≥ªÁªüÊàñËÄÖÂÖ∂‰ªñÈöîÁ¶ªËøõÁ®ã ÂèØ‰ª•‰∏ç‰øÆÊîπÁ®ãÂ∫è‰ª£Á†ÅÔºå‰∏çÈúÄË¶ÅÂ≠¶‰π†ÁâπÂÆöÁéØÂ¢ÉÁöÑÊäÄÊúØÔºåÂ∞±ËÉΩÂÆûÁé∞Â∫îÁî®Á®ãÂ∫èÈÉ®ÁΩ≤Âú®Êú∫Âô®‰∏ä Áî®ÈÄî Êèê‰æõ‰∏ÄÊ¨°ÊÄßÁöÑÁéØÂ¢É„ÄÇ Êú¨Âú∞ÊµãËØï‰ªñ‰∫∫ËΩØ‰ª∂ ÊåÅÁª≠ÈõÜÊàêÊó∂ÔºåÊèê‰æõÂçïÂÖÉÊµãËØïÂíåÊûÑÂª∫ÁéØÂ¢É ÊåÅÁª≠ÈõÜÊàêÊåá‰∏çÊñ≠ÁöÑÂ∞Ü‰ª£Á†ÅÈõÜÊàêÂà∞‰∏ªÂπ≤‰∏äÔºåËøôÊ†∑ËÉΩÊõ¥Âø´ÁöÑÂèëÁé∞ÈîôËØØ Âõ†‰∏∫‰ΩøÁî®ÁöÑÊó∂ÂÄôÂèØ‰ª•ÈöîÁ¶ªÔºåÈöèÊÑè‰∏ç‰ºöÂØπÂÖ∂‰ªñÁöÑ‰∫ßÁîüÂΩ±Âìç Êèê‰æõÂºπÊÄßÁöÑ‰∫ëÊúçÂä°ÔºöÂõ†‰∏∫ÂèØ‰ª•ÈöèÂºÄÈöèÂÖ≥ ÁªÑ‰ª∂ÂæÆÊúçÂä°Êû∂ÊûÑÔºö ÂèØ‰ª•Âú®Êú¨Êú∫Ê®°ÊãüÂá∫ÊúçÂä°Âô®Êû∂ÊûÑ ‰∏éËôöÊãüÊú∫ÁöÑÊØîËæÉËôöÊãüÊú∫ÊòØÈÄöËøáÊ®°ÊãüÁ°¨‰ª∂ÔºåÂú®Á°¨‰ª∂‰∏äÂÆâË£ÖÊìç‰ΩúÁ≥ªÁªü‰ªéËÄåÂÆûÁé∞ÁöÑ ÂêØÂä®ÈÄüÂ∫¶ ËôöÊãüÊú∫ÈúÄË¶ÅÂÖàÂêØÂä®ËôöÊãüÊú∫ÁöÑÊìç‰ΩúÁ≥ªÁªüÔºåÂÜçÂêØÂä®Â∫îÁî® dockerÁõ∏ÂΩì‰∫éÁõ¥Êé•ÂêØÂä®‰∏Ä‰∏™ËøõÁ®ãÔºåÈÄüÂ∫¶Âø´ Âç†Áî®ËµÑÊ∫ê ‰∏ÄÂè∞Êú∫Âô®Âè™ËÉΩÂºÄÂçÅÂá†‰∏™ËôöÊãüÊú∫ÔºåÊòØ‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÊìç‰ΩúÁ≥ªÁªüÔºåÈúÄË¶ÅÂç†Áî®Â§ßÈáèÁöÑÁ£ÅÁõòÔºåÂÜÖÂ≠òÂíåCPU dockerÂè™ÈúÄË¶ÅÁõ∏ÂÖ≥Â∫îÁî®ÂíåÁªÑ‰ª∂Ôºå‰∏ÄÂè∞Êú∫Âô®ÂèØ‰ª•ÂºÄÊàêÂçÉ‰∏ä‰∏á‰∏™ ‰ºòÂäø ÂÆπÊòìËøÅÁßªÔºöÊâìÂåÖÂ•ΩÁöÑÂ∫îÁî®Âú®‰∏çÂêåÁöÑÊú∫Âô®‰∏äËøÅÁßª ÂÆπÊòìÁª¥Êä§ÔºöÂàÜÂ±ÇÂíåÈïúÂÉèÔºåÂèØ‰ª•ÂÆπÊòìÂ§çÁî®ÈáçÂ§çÁöÑÈÉ®ÂàÜ„ÄÇ ÂÆπÊòìÊâ©Â±ïÔºöÂèØ‰ª•‰ΩøÁî®Âü∫Á°ÄÈïúÂÉèÊâ©Â±ïÂæóÂà∞Êñ∞ÁöÑÈïúÂÉè ÈïúÂÉè(imgae)ÂíåÂÆπÂô®ÈïúÂÉèÊòØ‰∏ÄÁßçÈùôÊÄÅÁöÑÁªìÊûÑÔºåÂèØ‰ª•ÁúãÊàêOOPÈáåÈù¢ÁöÑÁ±ª„ÄÇÂÆπÂô®ÊòØÈïúÂÉèÁöÑ‰∏Ä‰∏™instanceÈïúÂÉèÂåÖÂê´ÂÆπÂô®ËøêË°åÊó∂ÂÄôÈúÄË¶ÅÁöÑ‰ª£Á†Å‰ª•ÂèäÁªÑ‰ª∂ÔºåÊòØ‰∏Ä‰∏™ÂàÜÂ±ÇÁªìÊûÑÔºåÊØè‰∏ÄÂ±ÇÈÉΩÊòØÂè™ËØªÁöÑ„ÄÇÊûÑÂª∫ÈïúÂÉèÁöÑÊó∂ÂÄô‰ºö‰∏ÄÂ±Ç‰∏ÄÂ±ÇÁöÑÂàõÂª∫ÔºåÂâç‰∏ÄÂ±ÇÊòØÂêé‰∏ÄÂ±ÇÁöÑÂü∫Á°ÄÊûÑÂª∫ÂÆπÂô®ÁöÑÊó∂ÂÄôÔºåÂèØ‰ª•Âú®ÈïúÂÉèÈáåÂ¢ûÂä†writeable layerÔºå‰ªéËÄå‰øùÂ≠òÂÆπÂô®Âú®ËøêË°åËøáÁ®ã‰∏≠ÁöÑ‰øÆÊîπ ÂÆπÂô®Êñá‰ª∂ ÁîüÊàêÂÆπÂô®ÂêéÔºå‰ºöÂ≠òÂú®ÂÆπÂô®Êñá‰ª∂ÂíåimageÊñá‰ª∂„ÄÇÂÖ≥Èó≠ÂÆπÂô®‰∏ç‰ºöÂà†Èô§ÂÆπÂô®Êñá‰ª∂ Â¶ÇÊûúË¶ÅÂÆåÂÖ®ÁªàÊ≠¢ÔºåÂèØ‰ª•Âà†Èô§ÂÆπÂô®Êñá‰ª∂ imageÊñá‰ª∂ dockerÊääÂ∫îÁî®Á®ãÂ∫è‰ª•Âèä‰ªñÁöÑ‰æùËµñÔºåÊâìÂåÖÂú®imageÊñá‰ª∂Èáå„ÄÇÁªèËøáËøô‰∏™Êñá‰ª∂ÊâçËÉΩÁîüÊàêdockerÂÆπÂô®ÔºådockerÊ†πÊçÆËøô‰∏™Êñá‰ª∂ÁîüÊàêÂÆπÂô®ÁöÑÂÆû‰æã„ÄÇ imageÊòØ‰∫åËøõÂà∂Êñá‰ª∂ÔºåÂÆûÈôÖÂºÄÂèë‰∏≠ÔºåimageÊñá‰ª∂‰∏ÄËà¨ÈÉΩ‰ºöÁªßÊâøÂè¶‰∏Ä‰∏™imageÊñá‰ª∂ÔºåÂÜçÂä†‰∏ä‰∏Ä‰∫õ‰∏™ÊÄßÂåñËÆæÁΩÆ(imageÊñá‰ª∂ÊòØÈÄöÁî®ÁöÑ) Âà∂‰ΩúÂÆåÊàêÂêéÔºåÊñá‰ª∂ÂèØ‰ª•‰∏ä‰º†ÁΩë‰∏ä‰ªìÂ∫ìÔºåÊØîÂ¶ÇDockerHub]]></content>
      <categories>
        <category>Âü∫Á°Ä</category>
        <category>Â∑•ÂÖ∑</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PythonÂú®ÈÅçÂéÜÊó∂Âà†Èô§ÂÖÉÁ¥†]]></title>
    <url>%2F2019%2F10%2F30%2FPython%E5%9C%A8%E9%81%8D%E5%8E%86%E6%97%B6%E5%88%A0%E9%99%A4%E5%85%83%E7%B4%A0%2F</url>
    <content type="text"><![CDATA[PythonËØ≠Ê≥ïÁ≥ñ‚Äî‚ÄîÈÅçÂéÜÂàóË°®Êó∂Âà†Èô§ÂÖÉÁ¥† Filter ‰πãÂâçÂú®leetcodeÂà∑È¢òÁöÑÊó∂ÂÄôÔºåÂ¶ÇÊûúÁî®forÂæ™ÁéØÂà†Èô§listÁöÑÂÖÉÁ¥†Êó∂ÊÄª‰ºöÂèëÁîüÈóÆÈ¢ò„ÄÇÁî±Ê≠§Êù•ÊÄªÁªì‰∏Ä‰∏ãÈÅçÂéÜÂà†Èô§ÂÖÉÁ¥†ÁöÑÂêÑ‰∏™ÊñπÊ≥ï ÊàëÊØîËæÉÂ∏∏Áî®ÁöÑ‚Äî‚ÄîÂª∫Á´ãÊñ∞ÁöÑlistÁÆÄÂçïÁõ¥Êé•ÁöÑÊñπÊ≥ïÂèØ‰ª•Êå∫Â•ΩÁöÑËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÂª∫Á´ã‰∏Ä‰∏™Êñ∞ÁöÑlist„ÄÇÂ¶ÇÊûúÁªìÊûú‰∏çÁ¨¶ÂêàÔºåÂàôË∑≥ËøáËøô‰∏™ÂÖÉÁ¥†ÔºåÁ¨¶ÂêàÁöÑÊó∂ÂÄôÊääËøô‰∏™ÂÖÉÁ¥†Âä†ÂÖ•list„ÄÇËôΩÁÑ∂ËøôÊ†∑ÊòæÂæóÊØîËæÉË†¢Ôºå‰ΩÜÊòØÈÅáÂà∞ÈóÆÈ¢òÁöÑÊó∂ÂÄôÊØîËæÉÂÆπÊòìÊÉ≥Ëµ∑Êù• Âª∂‰º∏ÔºöÈÅçÂéÜÊã∑Ë¥ùÁöÑlist„ÄÇÊìç‰ΩúÂéüÂßãÁöÑlist123for i in lst[:]: if i == 0: lst.remove(i) Âú®ËøôÈáåÔºålst[:]Â∑≤ÁªèÊòØÊã∑Ë¥ù‰πãÂêéÁöÑÁªìÊûú‰∫ÜÔºå‰πüÂ∞±ÊòØËØ¥ÂØπÂéüÊù•ÁöÑlstÊìç‰Ωú‰∏ç‰ºöÂØπÊã∑Ë¥ùÁöÑÁªìÊûú‰∫ßÁîüÂΩ±Âìç filter ÊòæÂæóÊØîËæÉËÅ™ÊòéÁöÑ‰∏ÄÁßçÊñπÊ≥ï filterÊòØpythonÈáåÈù¢ÁöÑ‰∏Ä‰∏™ÂáΩÊï∞ÔºåÂåÖÊã¨‰∏§‰∏™ÂèÇÊï∞ functionÔºöÁî®‰∫éÊù°‰ª∂Âà§Êñ≠„ÄÇËøô‰∏™functionÂèØ‰ª•ÊòØ‰πãÂâçÂ∑≤ÁªèÁî®defÂÆö‰πâÂ•ΩÁöÑfunctionÔºå‰πüÂèØ‰ª•ÊòØÁî®lamndaÁÆÄÂÜôÁöÑfunction lstÔºöÁî®‰∫éËæìÂÖ•ÈúÄË¶Å‰øÆÊîπÁöÑlistÔºåÂèÇÊï∞ÊòØ‰∏Ä‰∏™ÂèØËø≠‰ª£ÁöÑÂØπË±°1lst = filter(lambda x: x != 0, lst) ‰πüÂ∞±ÊòØËØ¥Ôºå‰ºöÂÖàÂà§Êñ≠xÊòØÂê¶‰∏çÁ≠â‰∫é0ÔºåÂ¶ÇÊûúËøîÂõûÂÄºÊòØtrueÔºåÈÇ£‰πà‰øùÁïôËøô‰∏™ÂÖÉÁ¥†„ÄÇÂ¶ÇÊûúËøîÂõûÂÄºÊòØfalseÔºåÂàôÂà†Èô§Ëøô‰∏™ÂÖÉÁ¥†„ÄÇ ÂàóË°®Ëß£Êûê‰πüÂ∞±ÊòØÂú®1Ë°åÈáåÈù¢ÂÜôlistÁöÑÊñπÊ≥ï1lst = [x for x in lst if x != 0] whileÂà§Êñ≠12while 0 in lst: lst.remove(0) ÂÄíÂ∫èÂæ™ÁéØ Ëøô‰∏™ÊñπÊ≥ïÂç†Áî®ÁöÑÁ©∫Èó¥ÊúÄÂ∞ë ‰ΩÜÊòØÂèØËØªÊÄßÊØîËæÉÂ∑Æ 123for i in range(len(lst)-1,-1,-1): if lst[i] == 0: del lst[i]]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
        <category>list</category>
      </categories>
      <tags>
        <tag>ÈÅçÂéÜ</tag>
        <tag>Âà†Èô§</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫éGit]]></title>
    <url>%2F2019%2F10%2F27%2F%E5%85%B3%E4%BA%8EGit%2F</url>
    <content type="text"><![CDATA[Git ‰ªÄ‰πàÊòØÂàÜÊîØ GitÂ∏∏Áî®ÂëΩ‰ª§ ÈõÜ‰∏≠ÂºèÁ≥ªÁªüÂíåÂàÜÂ∏ÉÂºèÁ≥ªÁªüGitÂ±û‰∫éÂàÜÂ∏ÉÂºèÔºåSVNÔºàsubversionÔºâÊòØÈõÜ‰∏≠ÂºèÁöÑÁ≥ªÁªü ÈõÜ‰∏≠ÂºèÂè™ÊúâÂú®‰∏≠ÂøÉÊúçÂä°Âô®Êúâ‰∏Ä‰ªΩ‰ª£Á†ÅÔºåÂàÜÂ∏ÉÂºèÂú®ÊØè‰∏™‰∫∫ÁöÑÁîµËÑë‰∏äÈÉΩÊúâ‰∏Ä‰ªΩ‰ª£Á†Å ÈõÜ‰∏≠ÂºèÁâàÊú¨ÊéßÂà∂ÊúâÂÆâÂÖ®ÊÄßÈóÆÈ¢òÔºà‰∏≠ÂøÉÊúçÂä°Âô®ÊåÇ‰∫ÜÔºâ ÈõÜ‰∏≠ÂºèÈúÄË¶ÅËÅîÁΩëÊâçËÉΩÂ∑•‰Ωú„ÄÇ ÂàÜÂ∏ÉÂºèÊñ∞Âª∫ÂàÜÊîØÔºåÂêàÂπ∂ÂàÜÊîØÁöÑÊìç‰ΩúÊØîËæÉÂø´„ÄÇÈõÜ‰∏≠ÂºèÊñ∞Âª∫ÂàÜÊîØÁõ∏ÂΩì‰∫éÂ§çÂà∂‰∏Ä‰ªΩÂÆåÊï¥‰ª£Á†Å ‰∏≠ÂøÉÊúçÂä°Âô®Github‰Ωú‰∏∫‰∏≠ÂøÉÊúçÂä°Âô®Áî®‰∫é‰∫§Êç¢ÊØè‰∏™Áî®Êà∑ÁöÑ‰øÆÊîπÔºåÊ≤°Êúâ‰∏≠ÂøÉÊúçÂä°Âô®‰πüËÉΩÂ∑•‰ΩúÔºåÂÄíÊòØ‰∏≠ÂøÉÊúçÂä°Âô®24Â∞èÊó∂ÂºÄÂêØÊñπ‰æø‰∫§ÊµÅ„ÄÇ Â∑•‰ΩúÊµÅ Êñ∞Âª∫‰ªìÂ∫ì‰πãÂêéÔºåÁõÆÂâçÁöÑÁõÆÂΩïÂ∞±Êàê‰∏∫‰∫ÜÂ∑•‰ΩúÂå∫„ÄÇÂ∑•‰ΩúÂå∫Êúâ‰∏Ä‰∏™ÈöêËóèÁõÆÂΩï.gitÔºåÂ±û‰∫éGitÁöÑÁâàÊú¨Â∫ì Âú®ÁâàÊú¨Â∫ìÈáåÈù¢ÔºåÊúâ‰∏Ä‰∏™StageÁöÑÊöÇÂ≠òÂå∫Ôºå‰ª•ÂèäHistoryÁâàÊú¨Â∫ì„ÄÇÂú®HistoryÈáåÈù¢‰ºöÂÇ®Â≠òÊâÄÊúâÁöÑÂàÜÊîØÔºåÁÑ∂Âêé‰ºö‰ΩøÁî®HEADÊåáÈíàÊù•ÊåáÂêëÁõÆÂâçÂàÜÂå∫ ‰ΩøÁî® git add ‰ºöÊääÊñá‰ª∂Ê∑ªÂä†Âà∞ÊöÇÂ≠òÂå∫Ôºå‰πüÂ∞±ÊòØStage ‰ΩøÁî® git commit ‰ºöÊääÊöÇÂ≠òÂå∫ÁöÑ‰øÆÊîπÊèê‰∫§Âà∞ÂΩìÂâçÁöÑÂàÜÊîØÈáåÈù¢„ÄÇÊèê‰∫§‰πãÂêéÊöÇÂ≠òÂå∫Â∞±Ê∏ÖÁ©∫‰∫Ü ‰ΩøÁî® git reset ‚Äì ‰ºö‰ΩøÁî®Áé∞Âú®ÁöÑÂàÜÊîØÂÜÖÂÆπË¶ÜÁõñÊöÇÂ≠òÂå∫Ôºå‰πüÂ∞±ÊòØÊí§ÈîÄÊúÄÂêé‰∏ÄÊ¨°addÁöÑÊìç‰Ωú ‰ΩøÁî® git checkout ‚Äì ‰ºöÁî®StageÁöÑÂÜÖÂÆπË¶ÜÁõñÊú¨Âú∞ÂÜÖÂÆπÔºåÊí§ÈîÄÊúÄÂêé‰∏ÄÊ¨°Êú¨Âú∞‰øÆÊîπ‰πüÂèØ‰ª•Áî®Â§çÂêàÂëΩ‰ª§Êù•Ë∑≥ËøáStageÁöÑÈÉ®ÂàÜ Â¶ÇÊûú‰ΩøÁî® git commit -aÂèØ‰ª•Áõ¥Êé•ÊääÊñá‰ª∂ÁöÑ‰øÆÊîπÂÖàÂä†Âà∞ÊöÇÂ≠òÂå∫ÔºåÁÑ∂ÂêéÂÜçÊèê‰∫§ Â¶ÇÊûú‰ΩøÁî® git checkout HEAD ‚Äì ÂèØ‰ª•ÂèñÂá∫ÊúÄÂêé‰∏ÄÊ¨°‰øÆÊîπÔºå‰πüÂ∞±ÊòØÂØπÊú¨Âú∞Êñá‰ª∂ËøõË°åÂõûÊªöÊìç‰Ωú ÂàÜÊîØÁöÑÂÆûÁé∞Âú®GitÈáåÈù¢Ôºå‰ΩøÁî®‰∫ÜÊåáÈíàÊääÊØèÊ¨°ÁöÑÊèê‰∫§ÈÉΩËøûÊàê‰∏ÄÊù°Á∫øÔºåHEAD‰ºöÊåáÂêëÂΩìÂâçÁöÑÊåáÈíà Êñ∞Âª∫ÂàÜÊîØ‰ºöÂú®Êó∂Èó¥Á∫ø‰∏äÊúÄÂêé‰∏Ä‰∏™ËäÇÁÇπÊñ∞Âª∫ÂàÜÊîØÔºåÂπ∂‰∏îHEAD‰ºöÊåáÂêëÊñ∞ÁöÑÂàÜÊîØ„ÄÇËÄåÂØπÊñ∞ÁöÑÂàÜÊîØÁöÑÊØèÊ¨°Êèê‰∫§Âè™‰ºöËÆ©ÂΩìÂâçÁöÑÊåáÈíàÁßªÂä®ÔºåÂÖ∂‰ªñÁöÑÊåáÈíà‰∏ç‰ºöÁßªÂä® ÂêàÂπ∂ÁöÑÊó∂ÂÄôÊîπÂèòÁöÑ‰πüÊòØMasterÁöÑÊåáÈíà ÂÖ≥‰∫éGitÁöÑÂàÜÊîØ(branch)‰ªÄ‰πàÊòØÂàÜÊîØ ÂàÜÊîØÁöÑÊÑè‰πâÔºöÊääÁé∞Âú®ÁöÑÂ∑•‰Ωú‰ªé‰∏ªÁ∫ø‰∏äÂàÜÁ¶ªÂºÄÔºå‰ª•ÂÖçÂΩ±ÂìçÂºÄÂèë‰∏ªÁ∫øÔºàËøô‰πüÊòØGitÊúÄÂ§ßÁöÑ‰ºòÂäøÔºåÂõ†‰∏∫SVNÂºÄÂèëÊñ∞ÁöÑÂàÜÊîØÁõ∏ÂΩì‰∫éÂ§çÂà∂‰ª£Á†ÅÔºåÈÄüÂ∫¶ÈùûÂ∏∏ÊÖ¢Ôºâ ‰∏∫‰∫Ü‰∏çÂΩ±ÂìçÂÖ∂‰ªñ‰∫∫ÁöÑÂºÄÂèëÔºåÂèØ‰ª•Âú®‰∏ªÁ∫ø‰∏äÂª∫Á´ãËá™Â∑±ÁöÑÂàÜÊîØÔºåÂ∑•‰ΩúÂÆåÊàêÂêéÂêàÂπ∂Âà∞‰∏ªÂàÜÊîØ„ÄÇÊØè‰∏ÄÊ¨°ÁöÑÊèê‰∫§‰ºöË¢´‰øùÂ≠òÔºåËøôÊ†∑ÂèëÁîüÈóÆÈ¢òÊó∂ÂÄôÁöÑÂÆö‰ΩçÂ∞±Êõ¥Âä†ÂÆπÊòì‰∫Ü ÂàÜÊîØÁöÑÂ∫îÁî® mergeÂàÜÊîØÔºå‰∏∫‰∫ÜÂèØ‰ª•ÈöèÊó∂ÂèëÂ∏ÉreleaseËÄåÂàõÂª∫ÁöÑÂàÜÊîØ„ÄÇÈÄöÂ∏∏Â§ßÂÆ∂‰ºöÊäämasterÂΩìÊàêmergeÂàÜÊîØÊù•‰ΩøÁî® TopicÂàÜÊîØÔºö‰∏∫‰∫ÜÂºÄÂèëÊñ∞ÂäüËÉΩÊàñËÄÖ‰øÆÂ§çBugÁöÑÂàÜÊîØÔºå‰ªémergeÈáåÈù¢ÂàõÂª∫ÔºåÂÆåÊàê‰πãÂêéÈúÄË¶ÅÂêàÂπ∂Âà∞mergeÈáåÈù¢Âéª ÂàÜÊîØÁöÑÂêàÂπ∂ mergeÔºàÂéÜÂè≤ËÆ∞ÂΩï‰ºöÈùûÂ∏∏Â§çÊùÇÔºâ Â¶ÇÊûú‰ª•ÂâçÁöÑmasterÊ≤°ÊúâÊîπÂèòÔºåÂèØ‰ª•Áõ¥Êé•ÂêàÂπ∂Ôºàfast forwardÔºâ ÂèØ‰ª•Âú®ÂêàÂπ∂Êó∂Âä†‰∏ä‚Äìno-ffÊù•ËøõË°åFast forwardÔºåÂä†‰∏ä-mÁîüÊàê‰∏Ä‰∏™Êñ∞ÁöÑcommit Â¶ÇÊûúÁõ¥Êé•fast forwardÂèØËÉΩ‰ºö‰∏¢Â§±ÂàÜÊîØ‰ø°ÊÅØ Â¶ÇÊûú‰ª•ÂâçÁöÑÊúâ‰∫ÜÊñ∞ÁöÑÊõ¥Êñ∞ÔºåÈúÄË¶ÅÊää‰∏§‰∏™ÂàÜÊîØ‰øÆÊîπÁöÑÂÜÖÂÆπÁªìÂêàÔºåÁîüÊàê‰∏Ä‰∏™Êñ∞ÁöÑÊèê‰∫§ rebaseÔºàÂéÜÂè≤ËÆ∞ÂΩïÁÆÄÂçïÔºå‰ΩÜÊòØÂèØËÉΩ‰ºöÂØºËá¥ÂéüÊù•ÁöÑÂÜÖÂÆπÊó†Ê≥ïÊ≠£Â∏∏ËøêË°åÔºâ Â¶ÇÊûú‰ΩøÁî®Ëøô‰∏™ÊñπÊ≥ïÂêàÂπ∂ÔºåÊúÄÂêéÂæóÂà∞ÁöÑÁªìÊûú‰ºöÊòØ‰∏ÄÊù°Á∫øÊÄßÁöÑ„ÄÇÂ¶ÇÊûúÂú®Êèê‰∫§ÁöÑÊó∂ÂÄôXÂíåYÂèëÁîüÂÜ≤Á™ÅÔºåÈúÄË¶Å‰øÆÊîπÂÜ≤Á™ÅÁöÑÈÉ®ÂàÜ ÂàÜÊîØÁöÑÂÜ≤Á™ÅÂ¶ÇÊûú‰∏§‰∏™ÂàÜÊîØÂØπÂêå‰∏Ä‰∏™Êñá‰ª∂ÈÉΩËøõË°å‰∫Ü‰øÆÊîπÔºåÂêàÂπ∂ÁöÑÊó∂ÂÄôÂ∞±‰ºö‰∫ßÁîüÂÜ≤Á™Å„ÄÇÊää‰∏çÂêåÂàÜÊîØÁöÑÂÜÖÂÆπ‰øÆÊîπÊàê‰∏ÄÊ†∑ÁöÑÂ∞±ÂèØ‰ª•Ëß£ÂÜ≥Âú®GitÈáåÈù¢‰ºöÁî® &lt;&lt;&lt;&lt;&lt; ===== &gt;&gt;&gt;&gt;&gt;Êù•Ë°®Á§∫ ÂÇ®Ëóè StashingÂú®‰∏Ä‰∏™ÂàÜÊîØ‰∏äÊìç‰Ωú‰πãÂêéÔºåÂ¶ÇÊûúÊ≤°ÊúâÊèê‰∫§Ëøô‰∏™ÂàÜÊîØÂ∞±ËøõË°åÂàáÊç¢ÔºåÈÇ£‰πàÂú®Âè¶‰∏Ä‰∏™ÂàÜÊîØ‰∏ä‰πüËÉΩÁúãÂà∞‰øÆÊîπ„ÄÇÂõ†‰∏∫ÊâÄÊúâÁöÑÂàÜÊîØÈÉΩÂÖ¨Áî®‰∏Ä‰∏™Â∑•‰ΩúÂå∫Âüü„ÄÇ ÂèØ‰ª•‰ΩøÁî® git stashÊääÂΩìÂâçÁöÑÂàÜÊîØ‰øÆÊîπÂÇ®ËóèËµ∑Êù•ÔºåËøôÊ†∑Â∞±ÂèØ‰ª•ÂÆâÂÖ®ÁöÑÂàáÊç¢Âà∞ÂÖ∂‰ªñÂàÜÊîØ ÊØîÂ¶ÇÔºåÂ¶ÇÊûúÊ≠£Âú®devÂàÜÊîØ‰∏äÂºÄÂèëÔºåÊ≠§Êó∂Êúâmaster‰∏äÈù¢ÁöÑbugÈúÄË¶Å‰øÆÊîπÔºå‰ΩÜÊòØdevÁöÑÂºÄÂèëËøòÊ≤°ÊúâÂÆåÊàê„ÄÇËøôÊó∂ÂÄôÂèØ‰ª•Êñ∞Âª∫‰∏Ä‰∏™bugÂàÜÊîØÔºåÂπ∂‰∏îÂàáÊç¢Âà∞bug‰πãÂâçÂÖàÁî®stashÊääÁõÆÂâçdevÁöÑÂºÄÂèëËøõÂ∫¶ÂÇ®Â≠òËµ∑Êù• SSH‰º†ËæìËÆæÁΩÆGitÁöÑ‰ªìÂ∫ìÂíåGithubÁöÑ‰∏≠ÂøÉ‰ªìÂ∫ìÊòØÈÄöËøáSSHËøõË°åÂä†ÂØÜÁöÑ .gitignoreËøô‰∏™Êñá‰ª∂ÂèØ‰ª•ÂøΩÁï•‰ª•‰∏ãÁöÑÊñá‰ª∂Ôºö Êìç‰ΩúÁ≥ªÁªüËá™Âä®ÁîüÊàêÁöÑÊñá‰ª∂ÔºåÊØîÂ¶ÇÁº©Áï•Âõæ ÁºñËØëÁîüÊàêÁöÑ‰∏≠Èó¥Êñá‰ª∂ Ëá™Â∑±ÁöÑÊïèÊÑü‰ø°ÊÅØ„ÄÇÊØîÂ¶ÇÂ≠òÊîæÂè£‰ª§ÁöÑÈÖçÁΩÆÊñá‰ª∂ gitignore]]></content>
      <categories>
        <category>Âü∫Á°Ä</category>
        <category>Â∑•ÂÖ∑</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ê≠£ÂàôË°®ËææÂºè]]></title>
    <url>%2F2019%2F10%2F24%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[ÂèÇËÄÉËµÑÊñôÔºö ËØªÊáÇÊ≠£ÂàôË°®ËææÂºèÂ∞±ÊòØËøô‰πàÁÆÄÂçï Ê≠£ÂàôË°®ËææÂºè Ê≠£ÂàôË°®ËææÂºèÁΩëÁ´ô Âü∫Êú¨Ê¶ÇÂøµÊ≠£Ë¶èË°®ÁèæÔºà„Åõ„ÅÑ„Åç„Å≤„Çá„ÅÜ„Åí„Çì„ÄÅËã±: regular expressionÔºâÂΩ¢ÂºèË®ÄË™ûÂàÜÈáéÁî®‰∫éÊñáÊú¨ÂÜÖÂÆπÁöÑÊü•ÊâæÂíåÊõøÊç¢ÔºàÂ∑Æ„ÅóÊõø„Åà„ÇãÔºâÁî®‰∫éÂÖ∂‰ªñËØ≠Ë®ÄÊàñËÄÖ‰∫ßÂìÅËΩØ‰ª∂ÈáåÈù¢Âú®‰ΩøÁî®ÁöÑÊó∂ÂÄô‰∏ÄÂÆöË¶ÅÊ≥®ÊÑèËΩ¨‰πâÁ¨¶Âè∑\Ôºå‰∏ç‰ΩøÁî®Ëøô‰∏™Á¨¶Âè∑ÁöÑÊó∂ÂÄô‰ª£Ë°®ÁöÑÊòØÁúüÂÆûÁöÑÂÜÖÂÆπÔºå‰ΩøÁî®‰∫ÜÊâçÊúâÁõ∏Â∫îÁöÑÊÑèÊÄù Ê≠£ÂàôÂ≠óÁ¨¶ÂÖÉÁ¨¶Âè∑ Ë¢´ÂåπÈÖçÁöÑÂ≠óÁ¨¶Á¨¨‰∏Ä‰∏™ÂøÖÈ°ªÂíå^‰πãÂêéÁöÑ‰∏ÄÊ†∑ÔºåÊúÄÂêé‰∏Ä‰∏™ÂøÖÈ°ªÂíå$‰πãÂâçÁöÑ‰∏ÄÊ†∑ ‚Äú^‚ÄùÔºö ÂåπÈÖçË°åÊàñÂ≠óÁ¨¶‰∏≤ÁöÑËµ∑Âßã‰ΩçÁΩÆ Êï¥‰∏™ÊñáÊ°£ÁöÑËµ∑Âßã‰ΩçÁΩÆ ÔºÑÔºöË°åÊàñËÄÖÂ≠óÁ¨¶‰∏≤ÁöÑÁªìÂ∞æ \bÔºöÁî®‰∫éÂåπÈÖçËæπÁïåÔºå‰∏çÊ∂àËÄóÂ≠óÁ¨¶ÔºàBoundaryÔºâ \bis\b Áî®Êù•ËØÜÂà´isÁöÑ‰∏§ËæπÊòØÂê¶ÊòØËæπÁïå \dÔºöÂåπÈÖçÊï∞Â≠óÔºàdigitÔºâ ÊØîÂ¶Ç0ÂºÄÂ§¥Ôºå‰∫î‰ΩçÊï∞-&gt; ^0\d\d\d\d\d$ \wÔºöÂåπÈÖçÂ≠óÊØçÔºåÊï∞Â≠óÔºå‰∏ãÂàíÁ∫øÔºàÂü∫Êú¨ÂèØ‰ª•ÁêÜËß£‰∏∫Ê≥®ÂÜåÁî®Êà∑ÂêçÁöÑË¶ÅÊ±ÇÔºâ \sÔºöÂåπÈÖçÁ©∫Ê†ºÔºå\s+ÂèØ‰ª•ËÆ©Á©∫Ê†ºÈáçÂ§ç .ÔºöÂåπÈÖçÈô§‰∫ÜËΩ¨Ë°åÁ¨¶Âè∑‰ª•Â§ñÁöÑ‰ªª‰ΩïÂ≠óÁ¨¶„ÄÇ\wÁöÑÂä†Âº∫ÁâàÔºåÁõ∏ÂΩì‰∫éwÂä†‰∏äÁ©∫Ê†º []ÔºöÂåπÈÖçÂú®Á©∫Âè∑ÂÜÖÂÖÉÁ¥†ÁöÑÂ≠óÁ¨¶ÔºåÂè™ÂåπÈÖçÂ≠òÂú®‰∫éÊã¨Âè∑ÈáåÈù¢ÁöÑ„ÄÇÂèØ‰ª•ÂÜôÊàê[a-z] Âèç‰πâ‰∏äÈù¢ÁöÑË°®ËææÂÜôÊàêÂ§ßÂÜôÔºåÂ¶ÇÊûúÊòØ[]ÁöÑËØùÂèòÊàê[^]ÔºåË°®ËææÁöÑÊÑèÊÄùÊòØ‰∏çÂåÖÊã¨Ëøô‰∫õÁöÑÂ≠óÁ¨¶ ÈáèËØçÊúâÂÖ≥ÈáèËØçÁöÑ‰∏â‰∏™Ê¶ÇÂøµÔºö Ë¥™ÂøÉ * ‰ºöÈ¶ñÂÖàÂåπÈÖçÊï¥‰∏™Â≠óÁ¨¶‰∏≤Ôºå‰ºöÈÄâÊã©Â∞ΩÂèØËÉΩÂ§öÁöÑÂÜÖÂÆπÔºåÂ§±Ë¥•ÁöÑËØùÂ∞±backtrackingÔºàÊ∂àËÄóÊúÄÂ§ßÔºâ ÊáíÊÉ∞ Ôºü‰ªéËµ∑Âßã‰ΩçÁΩÆÂºÄÂßãÂ∞ùËØïÂåπÈÖçÔºåÊØèÊ¨°Ê£ÄÊü•‰∏Ä‰∏™ÂÜÖÂÆπÔºåÁõ¥Âà∞Ê£ÄÊü•ÂÆåÊâÄÊúâÁöÑÂÜÖÂÆπÔºàÁõ∏ÂΩì‰∫éÈÅçÂéÜÔºâ Âç†Êúâ + Ë¶ÜÁõñÊï¥‰∏™Â≠óÁ¨¶‰∏≤ÔºåÁÑ∂ÂêéÂØªÊâæ„ÄÇ‰ΩÜÊòØÂ∞±ËØï‰∏ÄÊ¨° Áõ∏ÂÖ≥ÈáèËØçÔºö Ë¥™ÂøÉ* ‰ºöÈáçÂ§ç0Ê¨°ÊàñËÄÖÊõ¥Â§ö ‚Äùaaaaa‚ÄúÈáåÈù¢ÂåπÈÖça* ÔºåÈÇ£‰πàÂæóÂà∞ÁöÑÊòØÊâÄÊúâÁöÑÂ≠óÁ¨¶a ÈáçÂ§ç‰∏ÄÊ¨°ÊàñÂ§öÊ¨°Ôºö ‚Äùaaaaa‚ÄúÔºåa+‰ºöÂèñÂ≠óÁ¨¶‰∏≠ÊâÄÊúâaÂÄºÔºå‰ΩÜÊòØ* ÂèØ‰ª•ÊòØ0Ê¨°Ôºå+‰∏çË°å ? ÈáçÂ§çÈõ∂Ê¨°Êàñ‰∏ÄÊ¨° ‚Äùaaaaa‚ÄúÔºåa?Âè™‰ºöÂåπÈÖç‰∏ÄÊ¨°ÔºåÁªìÊûú‰πüÊòØÂçï‰∏™Â≠óÁ¨¶a {n}ÔºåÈáçÂ§çnÊ¨°ÔºåÊØîÂ¶Ça{3}‰ºöÂåπÈÖçaaa {n,m} ÈáçÂ§çn-mÊ¨°ÔºåÊØîÂ¶Ça{3,4}ÂèØ‰ª•ÂåπÈÖçÂà∞aaaÊàñËÄÖaaaa {n,} ÈáçÂ§çnÊ¨°ÊàñÊõ¥Â§öÊ¨°Ôºå‰πüÂ∞±ÊòØËá≥Â∞ëÈáçÂ§çnÊ¨° ÊáíÊÉ∞ÈôêÂÆöÁ¨¶ÔºàÂ§ßÂÆ∂ÂíåÔºüÁöÑÊéíÂàóÁªÑÂêàÔºâ *Ôºü ÈáçÂ§ç‰ªªÊÑèÊ¨°Ôºå‰ΩÜÊòØÂ∞ΩÂèØËÉΩÂ∞ëÈáçÂ§ç ÊØîÂ¶Ç acbacbÔºåÊ≠£Âàô a.*?bÔºåÂè™‰ºöÂåπÈÖçacbÔºåÂõ†‰∏∫ÈúÄË¶Å.ÈáçÂ§çÁöÑÊï∞ÈáèÂ∞ΩÂèØËÉΩÂ∞ë +ÔºüÈáçÂ§ç1Ê¨°ÊàñËÄÖÊõ¥Â§öÊ¨°Ôºå‰ΩÜÊòØÂ∞ΩÂèØËÉΩÂ∞ëÈáçÂ§ç ?? ÈáçÂ§ç0Ê¨°Êàñ‰∏ÄÊ¨°Ôºå‰ΩÜÊòØÂ∞ΩÂèØËÉΩÂ∞ëÈáçÂ§ç {n,m}ÈáçÂ§çn-mÊ¨°Ôºå‰ΩÜÊòØÂ∞ΩÂèØËÉΩÂ∞ëÈáçÂ§ç„ÄÇÊØîÂ¶Ça{0,m}?ÂèñÂà∞ÁöÑÊòØÁ©∫ {n,}ÔºüËá≥Â∞ëÈáçÂ§çnÊ¨°ÔºåÂ∞ΩÂèØËÉΩÂ∞ëÈáçÂ§ç ËøõÈò∂ÊçïËé∑ÂàÜÁªÑÂ¶ÇÊûúÁªô‰∏ÄÈÉ®ÂàÜÁöÑÂÜÖÂÆπÂä†‰∏ä‰∫ÜÊã¨Âè∑ÔºåËøôÈÉ®ÂàÜÁöÑÂÜÖÂÆπÂ∞±Ë¢´Êäì‰Ωè‰∫Ü„ÄÇÁÑ∂ÂêéÂ¶ÇÊûúÂêéÈù¢Áî®Âà∞‰∫ÜÁõ∏ÂêåÂÜÖÂÆπÁöÑË°®ËææÂºèÔºåÂ∞±ÂèØ‰ª•Áõ¥Êé•Áî®‰∏Ä‰∏™Á¨¶Âè∑‰ª£ÊõøÔºåËÄå‰∏çÁî®ÁªßÁª≠ÂÜô‰∏Ä‰∏™‰∫Ü„ÄÇ‰∏çËÄÉËôëÈáçÂ§ç‰ΩøÁî®ÁöÑÊó∂ÂÄôÔºå‰πüÂèØ‰ª•ÂçïÁã¨Âè™Áî®‰∫éÂàÜÁªÑÔºåÂàÜÁªÑ‰πãÂêéÁöÑÂÜÖÂÆπÂèØ‰ª•Âä†‰∏ä+ * ÔºüÁ≠âÂÜÖÂÆπËøõË°åÈáçÂ§ç„ÄÇ‰ΩÜÊòØÊ≥®ÊÑèÂµåÂ•óÂ±ÇÊï∞ËøáÂ§ö‰ºöÂºïËµ∑Ê≠ß‰πâÂ∏∏Áî®ÂÜôÊ≥ï (exp)ÔºöÂåπÈÖçexp„ÄÇÊçïËé∑Âà∞Ëá™Âä®ÂëΩÂêçÁöÑÁªÑÈáåÈù¢Ôºå\1ËøôÊ†∑ÁöÑ (?exp)ÂåπÈÖçexp,ÊçïËé∑ÂÜÖÂÆπÂπ∂Ëá™Â∑±ÂëΩÂêçÔºåÂêéÈù¢ÂºïÁî®ÁöÑÊó∂ÂÄôÈúÄË¶Å ‚Äú\k‚Äú (?:exp)ÔºöÂåπÈÖçexpÔºå‰ΩÜÊòØ‰∏çÊçïËé∑Ôºå‰πü‰∏çÁªôËøô‰∏™ÁªÑÂàÜÈÖçÁºñÂè∑ (?=exp)ÔºöÂåπÈÖçexpÂâçÈù¢ÁöÑ‰ΩçÁΩÆ how are you doingÔºåÊ≠£Âàô(?.+(?=ing))ÔºåÂéªingÂâçÈù¢ÁöÑÂ≠óÁ¨¶ÔºåÂåπÈÖçÂá∫Êù•ÁöÑÊòØhow are you doÔºàÂåπÈÖçing‰πãÂâçÁöÑ.+Ôºâ (?&lt;=exp)ÔºöÂåπÈÖçÂêéÈù¢ÁöÑ‰ΩçÁΩÆ„ÄÇÊØîÂ¶Ç(?(?&lt;=how).+)ÔºåÂåπÈÖçÂêéÈù¢ÁöÑ‰ΩçÁΩÆÔºå‰πüÂ∞±ÊòØÂåπÈÖçhow‰πãÂêéÁöÑ.+ (?!exp)ÔºöÂåπÈÖçÂêéÈù¢‰∏çË∑üÁùÄexpÁöÑ‰ΩçÁΩÆ„ÄÇÊØîÂ¶Ç\d{3}(?!\d)ÂåπÈÖç‰∏â‰∏™Êï∞Â≠óÔºåÁÑ∂ÂêéÂêéÈù¢‰∏çÂÜçË∑üÊï∞Â≠ó‰∫Ü (?&lt;!exp)ÔºöÂåπÈÖçÂâçÈù¢‰∏çÊòØexpÁöÑ‰ΩçÁΩÆ„ÄÇ(?!&lt;[0-9])123ÔºåÂåπÈÖç123ÔºåÂπ∂‰∏î123ÂâçÈù¢‰∏çËÉΩÊòØÊï∞Â≠ó ‰æãÂ≠êÔºöÂàÜÁªÑ‰ΩøÁî®ÊØîÂ¶ÇÂåπÈÖçIPÂú∞ÂùÄÔºåIPÂú∞ÂùÄÁî±ÂõõÈÉ®ÂàÜÁªÑÊàêÔºåÊØè‰∏ÄÈÉ®ÂàÜÊòØ0-255ÁöÑÊï∞Â≠ó„ÄÇÂàôÂèØ‰ª•ÂàÜ‰∏∫‰ª•‰∏ãÁöÑÈÉ®ÂàÜË°®Á§∫ ‰∏Ä‰ΩçÊï∞Â≠ó ‰∏ç‰ª•0ÂºÄÂ§¥ÁöÑ‰∏§‰ΩçÊï∞ 2ÂºÄÂ§¥ÔºåÁ¨¨‰∫å‰ΩçÊòØ0-4ÁöÑ‰∏â‰ΩçÊï∞ 25ÂºÄÂ§¥ÔºåÁ¨¨‰∏â‰ΩçÊòØ0-5ÁöÑ‰∏â‰ΩçÊï∞1((25[0-5]|(2[0-4]\d)|(1\d&#123;2&#125;)|([1-9]\d)|(\d))\.)&#123;3&#125;(25[0-5]|(2[0-4]\d)|(1\d&#123;2&#125;)|([1-9]\d)|(\d)) ÂõûÊ∫ØÂºïÁî®ÊØîÂ¶ÇÂåπÈÖçHTMLÈáåÈù¢ÁöÑÊ†áÈ¢òÂÖÉÁ¥†1&lt;(h[1-6])&gt;\w*?&lt;\/\1&gt; ÂÖ∂‰∏≠Ôºåh[1-6]Ë¢´ÂàÜ‰∏∫‰∏ÄÁªÑÔºåËøô‰∏ÄÁªÑÁöÑÂêçÂ≠óÂè´ÂÅö\1Ôºå‰πüÂ∞±ÊòØËØ¥ÂâçÂêéÁöÑ‰∏§ÈÉ®ÂàÜÈúÄË¶Å‰∏ÄÊ†∑„ÄÇh1ÂØπh1Ôºåh2ÂØπh2ÊâçËÉΩÂåπÈÖç‰∏ä ÊõøÊç¢ÔºàÈúÄË¶Å‰∏§‰∏™regexpÔºâÊØîÂ¶Ç‰øÆÊîπÁîµËØùÂè∑Á†ÅÊ†ºÂºè313-555-1234 Êü•ÊâæÁöÑÊ≠£ÂàôÂºè(\d{3})(-)(\d{3})(-)(\d{4}) ÈúÄË¶ÅÊõøÊç¢Êàê‰∏∫ÁöÑÊ†ºÂºèÔºà$1Ôºâ$3-$5„ÄÇ‰πüÂ∞±ÊòØËØ¥ÊääÁ¨¨‰∏Ä‰∏™Ê≠£ÂàôÂºè‰∏≠ÁöÑÁ¨¨1Ôºå3Ôºå5‰∏™Êã¨Âè∑Áõ¥Êé•‰ª£ÂÖ•‰∫ÜÂêéÈù¢ÊõøÊç¢ÁöÑÊ†ºÂºèÈáåÈù¢ ÊõøÊç¢‰πãÂêéÁöÑÂÜÖÂÆπ (313)555-1234 Â§ßÂ∞èÂÜôËΩ¨Âèò \l ÊääÂêéÈù¢Ë∑üÈöèÁöÑÂçïÁã¨ÁöÑÂ≠óÁ¨¶ÊîπÊàêÂ∞èÂÜô \u ÊääÂçïÁã¨ÁöÑÂ≠óÁ¨¶ÊîπÊàêÂ§ßÂÜô \L ÊääL‰πãÂêéÔºåE‰πãÂâçÁöÑÂÖ®ÈÉΩÂèòÊàêÂ∞èÂÜô \U ÊääU‰πãÂêéÔºåE‰πãÂâçÁöÑÂÖ®ÈÉΩÂèòÊàêÂ§ßÂÜô \E ÁªìÊùüÁ¨¶Âè∑ Â¶ÇÔºåabcdÔºåÊü•Êâæ(\w)(\w{2})(\w)ÔºåÁÑ∂ÂêéÊîπ‰∏∫$1\U$2\E$3 ÂâçÂêéÊü•ÊâæËÆ¢Â•Ω‰∫ÜÂ∫îËØ•ÂåπÈÖçÁöÑÂÜÖÂÆπÁöÑÈ¶ñÂ∞æÂÜÖÂÆπÔºå‰ΩÜÊòØ‰∏çÂåÖÊã¨Ëøô‰∏™È¶ñÂ∞æÂÜÖÂÆπ„ÄÇ‰πüÂ∞±ÊòØÂâçÈù¢ËØ¥Âà∞ÁöÑÂêëÂâçÂåπÈÖçÔºü=ÂíåÂêëÂêéÂåπÈÖç?&lt;=.Ôºà‰ΩÜÊòØjs‰∏çÊîØÊåÅÂêëÂêéÂåπÈÖçÔºâ„ÄÇÂ¶ÇÊûúË¶ÅÊâæÈùûÁöÑÊù°‰ª∂ÁöÑÊó∂ÂÄôÔºåÈúÄË¶ÅÊää=Êç¢Êàê! ÊØîÂ¶ÇÂåπÈÖçÈÇÆÁÆ±ÁöÑ@ÂâçÈù¢ÁöÑÈÉ®ÂàÜ (\w+|.)+(?=@)ÔºàËøôÈáåÂä†‰∏ä‰∫Ü.ÔºåÂõ†‰∏∫ÊàëÁöÑÂ≠¶Ê†°ÈÇÆÁÆ±@ÂâçÈù¢‰πüÊòØÊúâ. ÁöÑÔºâ ÂåπÈÖçÁªìÊûúÔºö **xu.r.aa**@m.titech.ac.jp ÂµåÂÖ•Êù°‰ª∂ÂõûÊ∫ØÂºïÁî®Âà§Êñ≠Êüê‰∏™Ë°®ËææÂºèÊòØÂê¶ÂåπÈÖçÔºåÂ¶ÇÊûúÂåπÈÖçÁöÑËØùÁªßÁª≠ÂåπÈÖçÂêéÈù¢ÁöÑÊù°‰ª∂1(\()?abc(?(1)\)) ÂÖàÂåπÈÖçÂ∑¶Êã¨Âè∑Ôºà(ÔºâÔºåÔºüÊù•Âà§Êñ≠Â∑¶Êã¨Âè∑Êúâ0‰∏™ÊàñËÄÖ1‰∏™ Ôºü(1)ÊòØÂà§Êñ≠ÁöÑË°®ËææÂºèÔºå‰πüÂ∞±ÊòØËØ¥ËÉΩÂåπÈÖçÂà∞Â∑¶Êã¨Âè∑ÁöÑÊó∂ÂÄôÔºåÂÜçÂåπÈÖçÂè≥Êã¨Âè∑„ÄÇ ÂåπÈÖçÁªìÊûúÔºöabcÔºàabcÔºâÔºàabc ÂâçÂêéÊü•ÊâæÊù°‰ª∂‰∏∫È¶ñÂ∞æÊòØÂê¶ÂåπÈÖçÔºåÂ¶ÇÊûúÂåπÈÖçÁöÑËØùÁªßÁª≠ÔºàÊ≥®ÊÑèÈ¶ñÂ∞æ‰∏çÂåÖÊã¨Âú®ÂåπÈÖçÂÜÖÂÆπÈáåÈù¢Ôºâ1\d&#123;5&#125;(?(?=-)-\d&#123;4&#125;) È¶ñÂÖàÂåπÈÖç‰∫î‰ΩçÊï∞Â≠ó (?=-)Ë°®Á§∫ÂêëÂâçÊü•Êâæ-Ôºå‰πüÂ∞±ÊòØÂØπ-ÂêëÂâçÊü•ÊâæÔºå‰Ωú‰∏∫Êù°‰ª∂„ÄÇÂ¶ÇÊûúÂêëÂâçÊü•ÊâæÊàêÂäü‰∫ÜÔºåÈÇ£‰πàÁªßÁª≠ËøõË°åÂêéÈù¢ÁöÑÊìç‰ΩúÔºå‰πüÂ∞±ÊòØÂåπÈÖç‰∏Ä‰∏™-ÔºåÁÑ∂ÂêéÂåπÈÖç‰∏Ä‰∏™4‰ΩçÊï∞Â≠ó44444-444444444-66666]]></content>
      <categories>
        <category>Âü∫Á°Ä</category>
        <category>Â∑•ÂÖ∑</category>
      </categories>
      <tags>
        <tag>Ê≠£ÂàôË°®Ëææ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÁÆóÊ≥ïÔºöÂõûÊ∫ØBacktracking]]></title>
    <url>%2F2019%2F10%2F16%2F%E7%AE%97%E6%B3%95%EF%BC%9A%E5%9B%9E%E6%BA%AFBacktracking%2F</url>
    <content type="text"></content>
      <categories>
        <category>ÁÆóÊ≥ï</category>
        <category>ÂõûÊ∫Ø</category>
      </categories>
      <tags>
        <tag>backtracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UnityÁªÉ‰π†FlappyBird]]></title>
    <url>%2F2019%2F10%2F02%2FUnity%E7%BB%83%E4%B9%A0Flappy%2F</url>
    <content type="text"><![CDATA[ÊïôÁ®ãÂèäÁ¥†ÊùêÊ∫êËá™unityÂÆòÊñπÁöÑlearningËµÑÊñôFlappyBird Êï¥‰ΩìÊÄùË∑ØÔºöÂú®Ê∏∏ÊàèÈáåÁâ©‰ΩìÊú¨‰ΩìÊòØ‰∏ç‰ºöÁßªÂä®ÁöÑÔºåÂè™ÊúâÂêéÈù¢ÁöÑËÉåÊôØÊªöËΩ¥‰∏ÄÁõ¥Âú®ÁßªÂä®ÔºåÁÑ∂ÂêéÊØèÊ¨°Âú®Áé©ÂÆ∂ËßÜÈáéÂ§ñÁîüÊàêÈöèÊú∫È´òÂ∫¶ÁöÑÊü±Â≠ê„ÄÇÊü±Â≠êÂíåËÉåÊôØ‰∏ÄËµ∑ÊªöÂä®„ÄÇ ÁîüÊàêÈ∏üÁöÑÁâ©‰Ωìsprite spriteÊòØ‰∏ÄÁßçÂçäÈÄèÊòéÁöÑtexture„ÄÇ‰∏ç‰ºöÁõ¥Êé•Ë¢´Áî®‰∫émeshÔºåËÄåÊòØ‰ºöÁî®Âú®ÈïøÊñπÂΩ¢ÊàñËÄÖÊ≠£ÊñπÂΩ¢‰∏ä ‰øÆÊîπtexture typeÂ∞±ÂèØ‰ª•‰øÆÊîπ ‰∏écanvas renderÁöÑÂå∫Âà´ÔºöÂâçËÄÖÂøÖÈ°ªÊîæÂú®canvasÈáåÈù¢ÔºåËÄåÂêéËÄÖÂèØ‰ª•ÊîæÂú®hierarchyÁöÑ‰ªª‰ΩïÂú∞Êñπ spriteÊîØÊåÅÁΩëÊ†ºÊûÑÈÄ†ÔºåÂèØ‰ª•Ê∏ÖÈô§‰∏çÂøÖË¶ÅÁöÑÈÄèÊòéÂÖÉÁ¥†ÔºåÂèØ‰ª•‰∏ÄÂÆöÊÉÖÂÜµ‰∏ãÈÅøÂÖçoverdrawÁöÑÈóÆÈ¢ò sorting layer Âú®sprite renderÈáåÈù¢‰ºöÊúâ‰∏ÄÈ°πÂè´ÂÅösorting layerÔºåËøô‰∏™ÂäüËÉΩÂèØ‰ª•ÂÜ≥ÂÆöÁîªÈù¢ÁöÑÂâçÊôØÂíåÂêéÊôØÁöÑÈÅÆÊå°ÂÖ≥Á≥ª„ÄÇÂÜôÁöÑË∂äÈù†‰∏ãÁöÑË∂äÂâç rigidbody + collider ÈúÄË¶ÅËÆæÁΩÆÂàö‰ΩìÂíåÁ¢∞ÊíûÂÖ≥Á≥ª ËøôÈáåÈù¢ÁöÑÁ¢∞ÊíûÂô®ËÆæÁΩÆÁöÑÁßçÁ±ªÊòØÂ§öËæπÂΩ¢ÁöÑ animatorÔºàgetcomponentÔºâ Âú®Ëøô‰∏™Ê∏∏ÊàèÈáåÔºåÈ∏üÁöÑ‰∏çÂêåÂä®‰Ωú‰ºöËß¶Âèë‰∏çÂêåÁöÑÂä®ÁîªÔºåÊâÄ‰ª•ÈúÄË¶Å‰∏∫Ëøô‰∏™È∏üÊûÑÂª∫‰∏Ä‰∏™Âä®ÁîªÊù•Ë°®Áé∞ Âú®animationÈáåÈù¢ÔºåÂèØ‰ª•ÁªôÈ∏ü‰∏çÂêåÁöÑÂä®‰Ωú‰∏çÂêåÁöÑclip„ÄÇÂú®ËøêË°åÁä∂ÊÄÅ‰∏ã‰øÆÊîπÈ∏üÂú®‰∏çÂêåclipÈáåÈù¢ÁöÑrenderer„ÄÇ Âú®animatorÈáåÈù¢ÂèØ‰ª•ËÆæÁΩÆ‰∏çÂêåÂä®Áîª‰πãÈó¥ÂàáÊç¢ÁöÑÈÄªËæëÂÖ≥Á≥ª ‰∏ÄÁßçÊòØÊ†πÊçÆÊù°‰ª∂ÂàáÊç¢ÔºåÈúÄË¶Å‰∏∫‰∏çÂêåÁöÑÊù°‰ª∂ËÆæÁΩÆ‰∏çÂêåÁöÑparamterÔºàËøôÈáåËÆæÂÆöÁöÑÊòØtriggerÔºåËøô‰∏™Áä∂ÊÄÅÂèØ‰ª•Áõ¥Êé•Âú®scriptÈáåÈù¢setÔºåÊ≥®ÊÑèÊãºÂÜôÈúÄË¶Å‰∏ÄÊ†∑ÔºâÔºàÊ≠£Â∏∏ -Êåâ-&gt; Êå•Âä®ÁøÖËÜÄ/ Ê≠£Â∏∏ -ÊíûÂ¢ô-&gt; Ê≠ª‰∫°Ôºâ ‰∏ÄÁßçÊòØÊ†πÊçÆÊó∂Èó¥ÂàáÊç¢ÔºàÊå•Âä®ÁøÖËÜÄ -&gt; Ê≠£Â∏∏Áä∂ÊÄÅÔºâ È∏üÁöÑË°å‰∏∫ÈÄªËæë ËøêÂä®ÔºöÊú¨Ë∫´ÁöÑxËΩ¥‰∏ç‰ºöËøêÂä®ÔºåyËΩ¥Âú®ÊØèÊ¨°ÊåâÈº†Ê†áÁöÑÊó∂ÂÄô‰∏äÂçáÔºàaddForceÔºâÔºå‰∏çÊåâÁöÑÊó∂ÂÄôÈáçÂäõËá™Áî±ËêΩ‰ΩìÔºàÂØπÂ∫î‰∏äÂçáÂä®ÁîªÔºâ Á¢∞ÊíûÔºöÁ¢∞ÊíûÂà∞Âú∞Èù¢ÊàñËÄÖÊü±Â≠êÈÉΩ‰ºöÊ≠ª‰∫°ÔºàÂØπÂ∫îÊ≠ª‰∫°Âä®ÁîªÔºâ Âú®È∏üÊ≠ª‰∫°ÁöÑÊó∂ÂÄôÔºå‰ºöÂØπÂ∫îÈ∏üÁöÑÊ≠ª‰∫°Áä∂ÊÄÅÂú®controllerÈáåÈù¢ÁöÑÂàáÊç¢ UIÂà∂‰Ωú UI‰ΩøÁî®ÁöÑÂ∞±ÊòØÊôÆÈÄöÁöÑUIÊ®°ÂºèÔºåÊ≥®ÊÑèÊâÄÊúâtextÈÉΩÊòØÂú®canvasÈáåÈù¢ÁöÑ ÂØºÂÖ•Á¥†ÊùêÂåÖÂ≠ó‰ΩìÔºåÂèØ‰ª•ÁªôÂ≠ó‰ΩìÂä†Èò¥ÂΩ± UIÁöÑÂàÜÊï∞ÂèòÂåñÂú®gamecontrollerÈáåÈù¢ËøõË°åÊìç‰Ωú Â≠ó‰ΩìÈîöÁÇπ‰ΩçÁΩÆË∞ÉÊï¥ÈúÄË¶ÅÊåâalt/option gameControll ËÆæÂÆö‰∫Ü‰∏Ä‰∏™staticÁöÑGameControlÔºàËøôÊòØËøô‰∏™Ëá™Âª∫Á±ªÁöÑÂêçÂ≠óÔºâÁöÑobjectÔºåÂêçÂ≠óÊòØinstance„ÄÇËÆæÂÆöÊàêstatic‰πãÂêéÔºåÊó†ËÆ∫Âú®Âì™ÈáåÁöÑcodeÈáåÈù¢ÊÉ≥Ë¶ÅËÆøÈóÆËøô‰∏™instanceÔºåÂè™ÈúÄË¶ÅcallGameControl.instanceÂ∞±ÂèØ‰ª•‰∫Ü ‰∏∫‰∫Ü‰øùËØÅÈáåÈù¢Êã•ÊúâËøô‰∏™instanceÔºåÈúÄË¶ÅÂú®awakeÁöÑÊó∂ÂÄôËøõË°åÊ£ÄÊü• 1234567891011void Awake() &#123; if (instance == null) &#123; instance = this; &#125; else if(instance != this) &#123; Destroy(gameObject); &#125; &#125; Âú®gameControlÈáåÈù¢ËÆæÁΩÆÂ•Ω‰∫ÜÊ∏∏ÊàèÁªìÊùüÁöÑÂèòÈáèÔºåËøô‰∏™ÂèòÈáèÂèØ‰ª•Áõ¥Êé•Âú®birdÁöÑscriptÈáåÈù¢ËÆøÈóÆÔºåËøôÊ†∑Â∞±ÂèØ‰ª•Áõ¥Êé•Âú®birdÈáåÈù¢ÂÜ≥ÂÆöÊ∏∏ÊàèÁªìÊùüÊ≤°ÁªìÊùüÔºåÂÜçÂú®Áé∞Âú®ÁöÑcontrolÈáåÈù¢ÂÜ≥ÂÆöÂàÜÊï∞ÁöÑÂèòÂåñÔºåsceneÁöÑÂàáÊç¢Á≠â ‰πüÂèØ‰ª•Âú®ËøôÈáåÊìç‰ΩúÔºåÊ∏∏ÊàèÈáçÊñ∞ÂºÄÂßã1234567void Update() &#123; if (gameOver &amp;&amp; Input.GetMouseButtonDown(0)) &#123; SceneManager.LoadScene(SceneManager.GetActiveScene().buildIndex); &#125; &#125; Âú∞Èù¢ÔºàÂèäËÉåÊôØÔºö‰Ωú‰∏∫Âú∞Èù¢ÁöÑÂ≠êÁâ©‰ΩìÔºâ Âú∞Èù¢Â∫îËØ•ÊúâcolliderÔºåËøôÊ†∑È∏üÊíûÂà∞Âú∞Èù¢‰∏äÊâç‰ºöÊ≠ª„ÄÇÈúÄË¶ÅÁî®rd Âú∞Èù¢Â∫îËØ•Âú®startÂºÄÂßãÂ∞±ÊåâÁÖß‰∏Ä‰∏™ÈÄüÂ∫¶ËøõË°åË¥üÁßªÂä®ÔºåÂ¶ÇÊûúÊ∏∏ÊàèÁªìÊùüÁöÑËØùÔºåÂú∞Èù¢ÂÅúÊ≠¢ÁßªÂä® Âú∞Èù¢Â∫îËØ•Â§çÂà∂‰∏§‰ªΩÔºåÂΩìÊØèÊ¨°Á¨¨‰∏Ä‰ªΩÂø´Ë¶ÅÁßªÂä®Âà∞Â§¥ÁöÑÊó∂ÂÄôÔºåÁ¨¨‰∫å‰ªΩÁßªÂä®Âà∞Á¨¨‰∏Ä‰ªΩÂâçÈù¢ÂéªÔºàËøô‰∏™Ë∑ùÁ¶ªÂèØ‰ª•Áõ¥Êé•Áî®colliderÁöÑsizeÊù•ÂÜ≥ÂÆö Âú∞Èù¢ÁöÑrdÂ∫îËØ•ËÆæÁΩÆÊàêkinematicÔºå‰πüÂ∞±ÊòØÈô§‰∫ÜscriptËÆ©ÁßªÂä®ÔºåÂÖ∂‰ªñÁöÑÊñπÊ≥ï‰∏ç‰ºöËÆ©‰ªñÁßªÂä® ÈöúÁ¢çÁâ© ÈöúÁ¢çÁâ©Â∫îËØ•ËÆæÁΩÆÊàêprefabÔºåÂà∂‰ΩúÂ•ΩÁöÑ‰∏úË•øÁõ¥Êé•ÊãñËøõprefabÊñá‰ª∂Â§πÂ∞±ÂèØ‰ª•‰∫Ü„ÄÇÂú®Áî®ÁöÑÊó∂ÂÄôÂèØ‰ª•Áõ¥Êé•Âú®gamecontrolÁöÑÁâ©‰ΩìÈáåÈù¢Êìç‰ΩúËøô‰∏™prefabÔºåÁõ¥Êé•ÊãñËøõÂéªÂ∞±ÂèØ‰ª•‰∫Ü ÈöúÁ¢çÁâ©Êú¨Ë∫´Â∫îËØ•Â¢ûÂä†‰∫Ü‰∏Ä‰∏™box colliderÁöÑtriggerÔºåÁÑ∂ÂêéÂú®ÊØè‰∏™Êü±Â≠êÊú¨Ë∫´ÈáåÈù¢Âä†‰∏ä‰∫ÜOnTriggerEnter2D(Collider2D other)Ôºå‰πüÂ∞±ÊòØÂú®Ëøô‰∏™triggerÁöÑÂå∫ÂüüÈáåÈù¢ÈÅáÂà∞È∏üÁöÑÊó∂ÂÄôÔºå‰ºöcallÂä†ÂàÜÁöÑÂáΩÊï∞ pool ÁîüÊàêÊü±Â≠êÁöÑÊñπÊ≥ïÔºåÁõÆÂâçÁöÑÊñπÊ≥ïÊòØÊØèÊ¨°ÁîüÊàê‰∫î‰∏™Êü±Â≠êÔºåÂ≠òÂú®‰∏Ä‰∏™arrayÈáåÈù¢ÔºåÊØèÊ¨°Êó∂Èó¥Âà∞‰∫ÜÂ∞±ÈöèÊú∫Êñ∞ÁöÑÊü±Â≠êÁöÑ‰ΩçÁΩÆ„ÄÇÂ¶ÇÊûú‰∫î‰∏™Êü±Â≠êÈÉΩÁî®ÂÆå‰∫ÜÂ∞±ÈáçÂ§¥ÂºÄÂßãÔºå‰πüÂ∞±ÊòØ‰ªéindexÊòØ0ÁöÑÊü±Â≠êÂºÄÂßãÔºåÈáçÊñ∞ÂÆö‰ΩçÂùêÊ†á Âú®ÂàùÂßãÂåñ‰∫î‰∏™Êü±Â≠êÁöÑÊó∂ÂÄôÔºåÁî®‰∫ÜObject.InstantiateÔºå‰πüÂ∞±ÊòØÊääËøô‰∫î‰∏™Êü±Â≠êÂú®ÊåáÂÆöÁöÑ‰ΩçÁΩÆÂ§çÂà∂‰∫Ü‰∫îÊ¨°„ÄÇÂÖ∂‰∏≠rotationÁöÑÂèÇÊï∞ËÆæÁΩÆÁöÑÊòØQuaternion.identityÔºå‰πüÂ∞±ÊòØÊ≤°ÊúâÊóãËΩ¨ÁöÑÊÑèÊÄù 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647using System.Collections;using System.Collections.Generic;using UnityEngine;public class ColumnPool : MonoBehaviour&#123; public int ColumnSize = 5; public GameObject columnPrefab; public float SpwandRate = 4f; public float columnMin = -2f; public float columnMax = 2f; private GameObject[] columns; private Vector2 objectPoolPosition = new Vector2(-15f, -25f); private float timeSinceLastSpwand; private float spwandXPosition = 10f; private int currentColumn = 0; // Start is called before the first frame update void Start() &#123; columns = new GameObject[ColumnSize]; for (int i = 0; i &lt; ColumnSize; i++) &#123; columns[i] = (GameObject)Instantiate(columnPrefab, objectPoolPosition, Quaternion.identity); &#125; &#125; // Update is called once per frame void Update() &#123; timeSinceLastSpwand += Time.deltaTime; if (GameControl.instance.gameOver == false &amp;&amp; timeSinceLastSpwand &gt;= SpwandRate) &#123; timeSinceLastSpwand = 0; float spawnYposition = Random.Range(columnMin, columnMax); columns[currentColumn].transform.position = new Vector2(spwandXPosition, spawnYposition); currentColumn++; if(currentColumn == 4) &#123; currentColumn = 0; &#125; &#125; &#125;&#125; ‰ª•‰∏äÔºåÁÆÄÊòìÁâàÁöÑflappybirdÂ∞±Âà∂‰ΩúÂÆåÊØï‰∫Ü]]></content>
      <categories>
        <category>Unity</category>
        <category>ÁªÉ‰π†</category>
      </categories>
      <tags>
        <tag>Flappy Bird</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êó•ËØ≠Êï¨ËØ≠Â≠¶‰π†]]></title>
    <url>%2F2019%2F09%2F14%2F%E6%97%A5%E8%AF%AD%E6%95%AC%E8%AF%AD%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[‰ªéÂ§¥ÂºÄÂßã‰∫ÜËß£‰∏Ä‰∫õÁªèÂ∏∏Âê¨Âà∞ÁöÑÁî®Ê≥ï Êú¨Êó• Ôºù ‰ªäÊó• „Åæ„Åì„Å®„Å´ Ôºù Êú¨ÂΩì„Å´ „ÅîÊ°àÂÜÖÁî≥„Åó‰∏ä„Åí„Åæ„Åô Ôºù Áü•„Çâ„Åõ„Åæ„Åô „Åü„Å†„ÅÑ„Åæ Ôºù „ÅÑ„Åæ „Äú„Å´„Åä„Åç„Åæ„Åó„Å¶ Ôºù „Åß „Äú„Åß„Åî„Åñ„ÅÑ„Åæ„Åô Ôºù „Äú„Åß„Åô Êù•Â†¥„Åô„Çã Ôºù ‰ºöÂ†¥„Å´Êù•„Çã Êï¨ËØ≠ÁöÑÂàÜÁªÑ Â∞äÊï¨ËØ≠ÔºöÁî®Êù•ÊèèËø∞ÂØπÊñπÁöÑË°å‰∏∫ÔºåÁõ¥Êé•Ë°®Á§∫Êï¨ÊÑè Ë∞¶ËÆ©ËØ≠ÔºõÊèèËø∞Ëá™Â∑±ÂÅöÁöÑ‰∫ãÔºåË¥¨‰ΩéËá™Â∑±ÔºåÈó¥Êé•ÁöÑË°®Á§∫Êï¨ÊÑè ‰∏ÅÂÆÅËØ≠ÔºöËÆ©Êï¥‰∏™ÂØπËØùÁöÑÊ∞îÊ∞õÈÉΩÂèòÂæóÂæà‰∏ÅÂÆÅÔºåÊ∞îÊ∞õÊØîËæÉÈÉëÈáç Âü∫Êú¨Â∏∏ËØÜ ‰∏ÄËà¨Êù•ËØ¥ÔºåÁ§ºË≤åÁ®ãÂ∫¶ÂèØ‰ª•ÂàÜÊàê‰∏â‰∏™Èò∂Â±ÇÔºåÂàÜÂà´ÊòØÁñØÁãÇ‰ΩøÁî®Êï¨ËØ≠ÁöÑ -&gt; ‰ΩøÁî®„Åß„Åô„Åæ„ÅôÁöÑ -&gt; ‰ΩøÁî®ÊôÆÈÄöÂΩ¢ÊÄÅÁöÑÊúãÂèãÈó¥ÁöÑÂØπËØù ‰∏ÄËà¨Êù•ËØ¥ÔºåÂØπÂ§ñÁöÑ‰∫∫Áî®Êï¨ËØ≠ÔºåÂØπÂÜÖÁöÑ‰∫∫‰∏çÂêåÊï¨ËØ≠ ÊØîÂ¶ÇÊúâ‰∫∫ÊâìÁîµËØùÂà∞‰∫ÜÂÖ¨Âè∏ÔºåÈóÆ‰Ω†ÁöÑÈÉ®ÈïøÂú®‰∏çÂú®Ôºå‰Ω†Ëá™Â∑±ËØ¥ÈÉ®ÈïøÁöÑÊó∂ÂÄôÂ∞±‰∏çÁî®Áî®Êï¨ËØ≠‰∫Ü ‰∏ãÈù¢ÂºÄÂßãÊ†πÊçÆ‰∏çÂêåÁöÑÂú∫Âêà‰ΩøÁî®Êï¨ËØ≠ËÆøÈóÆËÆøÈóÆÊó∂ÂÄôÁöÑÁâπÂÆöÁî®ËØ≠ ÁéÑÂÖ≥Â§Ñ „Åî„ÇÅ„Çì„Åè„Å†„Åï„ÅÑ „Åô„ÅÑ„Åæ„Åõ„Çì ÈÉ®Â±ã„Å´ÂÖ•„ÇãÊôÇ „ÅäÈÇ™È≠î„Åó„Åæ„Åô Â§±Á§º„Åó„Åæ„Åô Â§±Á§º„ÅÑ„Åü„Åó„Åæ„Åô ÈÉ®Â±ã„ÇíÂá∫„ÇãÊôÇ Â§±Á§º„Åó„Åæ„Åô Â§±Á§º„ÅÑ„Åü„Åó„Åæ„Åô „ÅäÔºè„Åî„Äú„Åè„Å†„Åï„ÅÑ „Äú„Å¶„Åè„Å†„Åï„ÅÑÁöÑ‰∏ÅÂÆÅÁî®Ê≥ï masuÂûãÂéªmasuÂä†‰∏äÂêéÈù¢ÁöÑ„ÅäÔºåÊàñËÄÖsuruÂûãÁõ¥Êé•Âä†ÂêéÈù¢ÁöÑ„Åî ‰æãÂ≠ê „ÅäÂÖ•„Çä„Åè„Å†„Åï„ÅÑ „Åä‰∏ä„Çä„Åè„Å†„Åï„ÅÑ -&gt; ËØ∑ËøõÁöÑÊÑèÊÄù come in „Åä„Åã„Åë„Åè„Å†„Åï„ÅÑ -&gt; ËØ∑ÂùêÔºåÊØîÂ¶ÇÊ≤ôÂèëÔºåÊ§ÖÂ≠êÂï•ÁöÑ„ÄÇÂíåÊâìÁîµËØùÊ≤°ÊúâÂÖ≥Á≥ª Êó•Êú¨Ë™û„Åß„ÅäË©±„Åó„Åè„Å†„Åï„ÅÑ „ÅîÊ≥®ÊÑè„Åè„Å†„Åï„ÅÑ Ê≥®ÊÑèÔºöËøôÈáåÊ≤°ÊúâteÔºå‰∏çË¶ÅÈ°∫‰æøÂä†‰∏äteÔºåÊ≤°ÊúâteÔºåÊ≤°ÊúâÔºÅÔºÅÔºÅÔºÅÔºÅ „Å§„Åæ„Çâ„Å™„ÅÑ„ÇÇ„ÅÆ„Åß„Åô„Åå‚Ä¶ ‰∏ÄÁÇπÂ∞è‰∏úË•øÔºå‰∏çÊàêÊï¨ÊÑè Êõ¥ÈöèÊÑèÁöÑÊó∂ÂÄôÂèØ‰ª•ËØ¥ÔºàÁªôÂà´‰∫∫‰π∞‰∫ÜÂêÉÁöÑÁöÑËØùÔºâÔºöÁæéÂë≥„Åó„ÅÑ„ÅÆ„ÅßË≤∑„Å£„Å¶„Åç„Åæ„Åó„Åü „Åä„Äú„Å´„Å™„Çä„Åæ„Åô „Äú„Åæ„ÅôÁöÑ‰∏ÅÂÆÅËØ≠ÔºåsuruÁöÑÂä®ËØç‰∏çËÉΩÁî®Ëøô‰∏™Áî®Ê≥ï ‰πüÂ∞±ÊòØËØ¥‰∏ÄËà¨ÁöÑÂä®ËØçÔºåÂ¶ÇÊûú‰∏çÊòØÁâπÊÆäÂûãÁöÑËØùÔºåÂèØ‰ª•Áî®Ëøô‰∏™Áî®Ê≥ï‰ª£ÊõøÂπ≥Â∏∏Áõ¥Êé•Áî®masu ‰æã „Åì„ÅÆÊïôÁßëÊõ∏„ÅØÈà¥Êú®ÂÖàÁîü„Åå„ÅäÊõ∏„Åç„Å´„Å™„Çä„Åæ„Åô Á§æÈï∑„ÄÅ‰ªäÊúù„ÅÆÊñ∞ËÅû„Çí„ÅäË™≠„Å´„Å™„Çä„Åæ„Åó„Åü„Åã ‰∏äÈù¢ÁöÑÂ∞äÊï¨ËØ≠ÁöÑÁâπÂà´ÂèòÂΩ¢ È£ü„Åπ„Åæ„Åô -&gt; (üôÖ‚Äç‚ôÄx)„ÅäÈ£ü„Åπ„Å´„Å™„Çä„Åæ„Åô -&gt; (‚óè)Âè¨„Åó‰∏ä„Åå„Çä„Åæ„Åô „Åó„Åæ„Åô -&gt; (üôÖ‚Äç‚ôÄx)„Åä„Åó„Å´„Å™„Çä„Åæ„Åô -&gt; (‚óè)„Å™„Åï„ÅÑ„Åæ„Åô Ë¶ã„Åæ„Åô -&gt; (üôÖ‚Äç‚ôÄx)„ÅäË¶ã„Å´„Å™„Çä„Åæ„Åô -&gt; (‚óè)„ÅîË¶ß„Å´„Å™„Çä„Åæ„Åô ‰πüÂ∞±ÊòØËØ¥ÔºåÂ¶ÇÊûúÊòØ‰∏âÁ±ªÂä®ËØçÁöÑËØùÔºåÂêéÈù¢ÁöÑ„Åô„ÇãÁõ¥Êé•ÂèòÊàê„Å™„Åï„ÅÑ„Åæ„Åô Ê≥®ÊÑèÔºöÁâπÂà´ÂèòÂΩ¢Â¶ÇÊûúÊÉ≥Áî®„Åè„Å†„Åï„ÅÑÁöÑÊó∂ÂÄôÔºåÂèØ‰ª•Áõ¥Êé•Áî®ÁâπÂà´ÂèòÂΩ¢‰πãÂêéÁöÑÂä®ËØçÂä†‰∏ä„Å¶„Åè„Å†„Åï„ÅÑ„ÄÅÁé∞Âú®ËøôÈáåÊòØÊúâteÁöÑÔºåÊØîÂ¶Ç„Åä„Å£„Åó„ÇÉ„Å£„Å¶„Åè„Å†„Åï„ÅÑ ËØ∑ËØ¥ Ë¢´Âä®ÔºöÊõ¥Âä†ÁÆÄÂçï‰∏ÄÁÇπÁöÑÁî®Ê≥ï ‰ΩøÁî®ÂíåË¢´Âä®ÊÄÅÁõ∏ÂêåÁöÑÊñπÊ≥ïÊù•Ë°®Á§∫Â∞äÊï¨Ôºå‰∏çÁî®ÂÉè‰∏äÈù¢ÁöÑ„Åä„Äú„Å´„Å™„Çä„Åæ„ÅôËøô‰πàÈ∫ªÁÉ¶ÔºåÊ†πÊçÆ‰∏ä‰∏ãÊñáÂèØ‰ª•Êé®ÊµãÂÆûÈôÖÁöÑÊÑèÊÄù ‰æã Êõ∏„Åç„Åæ„Åô -&gt; Êõ∏„Åã„Çå„Åæ„ÅôÔºè Ë™≠„Åø„Åæ„Åô -&gt; Ë™≠„Åæ„Çå„Åæ„Åô Âá∫„Åæ„Åô -&gt; Âá∫„Çâ„Çå„Åæ„Åô „Åó„Åæ„Åô -&gt; „Åï„Çå„Åæ„ÅôÔºè Êù•„Åæ„Åô -&gt; Êù•„Çâ„Çå„Åæ„Åô Ê≥®ÊÑèÔºöËøôÁßçÁî®Ê≥ï‰∏çËÉΩÂíå„Åè„Å†„Åï„ÅÑ‰∏ÄËµ∑Áî®Ôºå‰∏çËÉΩÁî®Ë¢´Âä®ÂêéÈù¢Âä†„Åè„Å†„Åï„ÅÑÔºåË¶ÅÁî®„Åè„Å†„Åï„ÅÑÁöÑËØùËØ∑Áõ¥Êé•Áî®‰∏äÈù¢ÁöÑÈÇ£‰∏™Â∏¶„Åè„Å†„Åï„ÅÑÁöÑÊñπÊ≥ï Ê≥®ÊÑèÔºöË¢´Âä®Âûã ‰∏çË¶ÅÈ°∫Âò¥Âíå„Åï„ÅõËØ¥Ê∑∑ ÁâπÊÆäÊï¨ËØ≠ÊûÑÊàêË°® Âä®ËØç Â∞äÊï¨ËØ≠ Ë∞¶ËÆ©ËØ≠ Ë°å„Åç„Åæ„Åô „ÅÑ„Çâ„Åó„ÇÉ„ÅÑ„Åæ„ÅôÔºè„Åä„ÅÑ„Åß„Å´„Å™„Çä„Åæ„Åô ÂèÇ„Çä„Åæ„ÅôÔºè‰º∫„ÅÑ„Åæ„Åô Êù•„Åæ„Åô „ÅÑ„Çâ„Åó„ÇÉ„ÅÑ„Åæ„ÅôÔºè„Åä„ÅÑ„Åß„Å´„Å™„Çä„Åæ„Åô ÂèÇ„Çä„Åæ„Åô „ÅÑ„Åæ„Åô „ÅÑ„Çâ„Åó„ÇÉ„ÅÑ„Åæ„ÅôÔºè„Åä„ÅÑ„Åß„Å´„Å™„Çä„Åæ„Åô „Åä„Çä„Åæ„Åô Ë®Ä„ÅÑ„Åæ„Åô „Åä„Å£„Åó„ÇÉ„ÅÑ„Åæ„Åô ÔºàË®±„Å®ÔºâÁî≥„Åó„Åæ„ÅôÔºèÔºàÊÑèË¶ã„ÇíÔºâÁî≥„Åó‰∏ä„Åí„Åæ„Åô Ë¶ã„Åæ„Åô „ÅîË¶ß„Å´„Å™„Çä„Åæ„Åô ÊãùË¶ã„Åó„Åæ„Åô È£ü„Åπ„Åæ„ÅôÔºèÈ£≤„Åø„Åæ„Åô Âè¨„Åó‰∏ä„Åå„Çä„Åæ„Åô „ÅÑ„Åü„Å†„Åç„Åæ„Åô Áü•„Å£„Å¶„ÅÑ„Åæ„Åô „ÅîÂ≠òÁü•„Åß„Åô Â≠ò„Åò„Å¶„Åä„Çä„Åæ„ÅôÔºèÁü•„Å£„Å¶„Åä„Çä„Åæ„ÅôÔºèÔºàÈáëÂ≠êÈÉ®Èï∑„ÇíÔºâÂ≠ò„Åò‰∏ä„Åí„Å¶„Åä„Çä„Åæ„Åô ÊÄù„ÅÑ„Åæ„Åô „ÅäÊÄù„ÅÑ„Å´„Å™„Çä„Åæ„Åô Â≠ò„Åò„Åæ„Åô „Åó„Åæ„Åô „Å™„Åï„ÅÑ„Åæ„Åô „ÅÑ„Åü„Åó„Åæ„Åô „Åè„Çå„Åæ„Åô „Åè„Å†„Åï„ÅÑ„Åæ„Åô „ÅÇ„Åí„Åæ„Åô „Åï„Åó„ÅÇ„Åí„Åæ„Åô „ÇÇ„Çâ„ÅÑ„Åæ„Åô „ÅÑ„Åü„Å†„Åç„Åæ„Åô ‰ºö„ÅÑ„Åæ„Åô „Åä‰ºö„ÅÑ„Å´„Å™„Çä„Åæ„Åô „Åä‰ºö„ÅÑ„Åó„Åæ„ÅôÔºè„ÅäÁõÆ„Å´„Åã„Åã„Çä„Åæ„Åô ËÅû„Åç„Åæ„Åô „ÅäËÅû„Åç„Å´„Å™„Çä„Åæ„Åô „ÅäËÅû„Åç„Åó„Åæ„ÅôÔºè‰º∫„ÅÑ„Åæ„Åô „ÅÇ„Çä„Åæ„Åô „ÅÇ„Çä„Åæ„Åô „Åî„Åñ„ÅÑ„Åæ„Åô ÂØù„Åæ„Åô „Åä‰ºë„Åø„Å´„Å™„Çä„Åæ„Åô ÁùÄ„Åæ„Åô „ÅäÂè¨„Åó„Å´„Å™„Çä„Åæ„Åô ‰Ωè„Çì„Åß„ÅÑ„Åæ„Åô „Åä‰Ωè„Åæ„ÅÑ„Åß„Åô ÊåÅ„Å°„Åæ„ÅôÔºèÊåÅ„Å£„Å¶„ÅÑ„Åç„Åæ„ÅôÔºèÊåÅ„Å£„Å¶„Åç„Åæ„Åô „ÅäÊåÅ„Å°„Å´„Å™„Çä„Åæ„Åô „ÅäÊåÅ„Å°„Åó„Åæ„Åô Ê≠ª„Å´„Åæ„Åó„Åü „Åä‰∫°„Åè„Å™„Çä„Å´„Å™„Çä„Åæ„Åó„Åü „Äú„Åß„Åô „Åß„ÅÑ„Çâ„Åó„ÇÉ„ÅÑ„Åæ„Åô „Åß„Åî„Åñ„ÅÑ„Åæ„Åô „Äú„Å¶„ÅÑ„Åæ„Åô „Å¶„ÅÑ„Çâ„Åó„ÇÉ„ÅÑ„Åæ„Åô „Åß„Åä„Çä„Åæ„Åô Â∞äÊï¨ËØ≠ÂíåË∞¶ËÆ©ËØ≠ÁöÑÊÄªÁªì Âè•Âûã Â∞äÊï¨ „ÅäÔºè„Åî„Äú„Å´„Å™„Çä„Åæ„Åô „ÅäÔºè„Åî„Äú„Åè„Å†„Åï„ÅÑ Ë∞¶ËÆ© „ÅäÔºè„Åî„Äú„Åó„Åæ„Åô ÁÆÄÂçïÁî®Ê≥ï Âè™ÊúâÂ∞äÊï¨ËØ≠ÂèØ‰ª•Áî®Ë¢´Âä®Êù•Ë°®Á§∫Â∞äÊï¨ ÁâπÂà´ÂûãËßÅË°® Ê≥®ÊÑèÂ∞äÊï¨ËØ≠Ôºö ÂêÉÂíåÁ©øÈïøÂæóÂ∑Æ‰∏çÂ§öÔºå‰ΩÜÊòØÂêÉÂñùÈáåÈù¢‰∏çÈúÄË¶ÅÂâçÈù¢ÁöÑ„Åä ËØ¥ÈáåÈù¢Â∏¶‰øÉÈü≥ ËôΩÁÑ∂ÊÉ≥Âê¨Ëµ∑Êù•ÂæàÂ•áÊÄ™Ôºå‰ΩÜÊòØÁúüÁöÑÊòØËøôÊ†∑ÁöÑ ‰ΩèËøô‰∏™ËØçÊúâ‰∫õÂ•áÊÄ™ Ê≠ª‰∏ÄÂÆöÊòØËøáÂéªÂºèÁöÑ Ê≥®ÊÑèË∞¶ËÆ©ËØ≠ Êù•ÂíåÂéªÈÉΩÂèØ‰ª•ÊòØ ÂèÇ„ÄÇ ‰ΩÜÊòØÂéªËøòÊúâ‰º∫„ÅÜ„ÄÇÂêåÊó∂‰º∫„ÅÜËøòÊúâÂê¨ÁöÑÊÑèÊÄù Â≠ò„Åò Âú®Áü•ÈÅìÂíåÊÉ≥ÈáåÈù¢ÈÉΩÂèØ‰ª•Áî®ÔºåÊ≥®ÊÑèÂå∫Âà´„ÄÇÁü•ÈÅìÊòØteÂûãÁöÑÔºåÊâÄ‰ª•ÊòØ„Åä„Çä„Åæ„Åô ÊâìÊãõÂëºÁªèÂ∏∏‰ΩøÁî®ÁöÑ„ÅÇ„ÅÑ„Åï„Å§ Êúù „Åä„ÅØ„Çà„ÅÜ„Åå„Åñ„ÅÑ„Åæ„Åô „Åä„ÅØ„Çà„ÅÜ ‰ºöÁ§æ„Åã„ÇâÂ∏∞„ÇäÊôÇ „Åù„Çå„Åß„ÅØ„ÄÅ„ÅäÂ§±Á§º„Å´„Åó„Åæ„ÅôÔºèÂ§±Á§º„ÅÑ„Åü„Åó„Åæ„Åô „Åò„ÇÉ„ÄÅ„ÅäÂÖà„Å´ „ÅäÁ§º „ÅÇ„Çä„Åå„Å©„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô -&gt; „ÅÑ„ÅÑ„ÅàÔºè„Åì„Å°„Çâ„Åì„ÅùÔºè„Å©„ÅÜ„ÅÑ„Åü„Åó„Åæ„Åó„Å¶ „ÅÇ„Çä„Åå„Å©„ÅÜ -&gt; „ÅÜ„ÅÜ„ÇìÔºèÂ§ß‰∏àÂ§´„Å†„Çà Â§©Ê∞ó „ÅÑ„ÅÑÂ§©Ê∞ó„Åß„Åô„Å≠ÔºèÊöë„ÅÑ„Åß„Åô„Å≠ÔºèÈõ®„Åå„Çà„ÅèÈôç„Çä„Åæ„Åô„Å≠ -&gt; „Åù„ÅÜ„Åß„Åô„Å≠ „ÅÑ„ÅÑÂ§©Ê∞ó„Å†„ÇàÔºèÊöë„ÅÑ„Å≠Ôºè„Çà„ÅèÈôç„Çã„Å≠ -&gt; „Åù„ÅÜ„Å†„Å≠ Âà•„Çå„ÇãÊôÇ Â§±Á§º„Åó„Åæ„ÅôÔºèÂ§±Á§º„ÅÑ„Åü„Åó„Åæ„Åô -&gt; „ÅäÊ∞ó„Çí„Å§„Åë„Å¶Ôºè„Åù„Çå„Åß„ÅØ„Åæ„Åü „Åò„ÇÉ„ÅÇ„Å≠ -&gt; Ê∞ó„Çí„Å§„Åë„Å¶„Å≠Ôºè„Åò„ÇÉ„ÄÅ„Åæ„Åü Ë∞¶ËÆ©ËØ≠Âè•Âûã „Åä„Äú„Åó„Åæ„ÅôÔºè„Åî„Äú„Åó„Åæ„Åô ‰æãÂ≠ê ÁúãËßÅÊãøÁùÄ‰∏úË•øÁöÑÁ§æÈïø „ÅäÊåÅ„Å°„Åó„Åæ„Åô ËØ¥ÊòéÁöÑÊó∂ÂÄô „ÅîË™¨Êòé„Åó„Åæ„Åô ÊàëÊù•Â∏Æ‰Ω† „ÅäÊâã‰ºù„ÅÑ„Åó„Åæ„Åô ‰∏ÄËà¨‰ΩøÁî®Ë∞¶ËÆ©ËØ≠ÁöÑÊó∂ÂÄôÈÉΩ‰ºöÁúÅÁï•‚ÄúÊàë‚ÄùÁöÑ‰∏ªËØ≠ ÂØπ‰∫é‰∏äÁ∫ßÁöÑ‰∫∫‰∏çËÉΩÁî® „Å¶„ÅÇ„Åí„Çã ÔºàË¶ÅÁî®„Åï„Åó‰∏ä„Åí„ÇãÔºâ Ë∞¶ËÆ©ËØ≠ÁâπÂà´Âûã Êõ¥Â§öËßÅ‰∏äÈù¢ÁöÑË°® ‰æãÂ≠ê „É°„Éº„É´„ÇíÊãùË¶ã„Åó„Åæ„Åó„Åü ÈßÖÂâç„ÅßÂÅ∂ÁÑ∂ÂÖàÁîü„Å´„ÅäÁõÆ„Å´„Åã„Åã„Çä„Åæ„Åó„Åü ‰æãÊù•ÈÄ±„ÅÆÊù±‰∫¨„Å∏„ÅÆ„ÅîÂá∫Âºµ„ÅÆ„Åì„Å®„Åß„Åô„Åå„ÄÅÁ©∫Ê∏Ø„Åæ„Åß„ÅäËøé„Åà„Å´„Åæ„ÅÑ„Çä„Åæ„ÅôÔºè„ÅÜ„Åã„Åå„ÅÑ„Åæ„Åô „ÅÆ„Åß„ÄÅ„ÅîÂà∞ÁùÄ„Å´„Å™„ÇãÔºàÂà∞ÁùÄ„Åï„Çå„ÇãÔºâÊôÇÈñì„Çí~Â≠ò„Åò„Åï„Åõ„Å¶„Åè„Å†„Åï„ÅÑ~Ôºà„ÅäÁü•„Çâ„Åõ„Åè„Å†„Åï„ÅÑÔºåËøôÈáåÁöÑ‰∏ªËØ≠ÊòØÂØπÊñπ‰∏çÊòØËá™Â∑±Ôºâ„ÄÇÁ©∫Ê∏Ø„ÅßË≥áÊñô„Çí„ÅäÊ∏°„Åó„Åó„Åæ„Åô„ÅÆ„Åß„ÄÅËªä„ÅÆ‰∏≠„Åß„ÅîË¶ß„Åè„Å†„Åï„ÅÑ„ÄÇ„ÅîÊòºÈ£ü„ÅÆÂæå„ÄÅ‰ºöË≠∞„ÅÆÂ†¥ÊâÄ„Åæ„Åß„ÅäÈÄÅ„Çä„Åó„Åæ„Åô„ÄÇ„Å©„ÅÜ„Åû„Çà„Çç„Åó„Åè„ÅäÈ°ò„ÅÑ„ÅÑ„Åü„Åó„Åæ„Åô ÈÇÄËØ∑ÊâìÊãõÂëº Â£∞„ÇíÊéõ„Åë„Çã -&gt; Êâæ‰∫∫Â∏ÆÂøôÁöÑÊó∂ÂÄôÁöÑÊê≠ËØù ÈÉ®Èï∑„ÄÅ„Åô„Åø„Åæ„Åõ„Çì „ÅÑ„Åæ„ÄÅ„Çà„Çç„Åó„ÅÑ„Åß„Åô„ÅãÔºè„Å°„Çá„Å£„Å®„Çà„Çç„Åó„Åß„Åó„Çá„ÅÜ„Åã „ÅÑ„Åæ„ÄÅ„ÅäÊôÇÈñì„ÅÑ„Åü„Å†„Åë„Åæ„Åô„Åã ÊâìÂê¨Âà´‰∫∫ÁöÑÂÆâÊéí ‰∫àÂÆö„ÇíËÅû„Åè Êó•ÊõúÊó•„ÄÅ‰Ωï„Åã„Åî‰∫àÂÆö„Åå„ÅÇ„Çä„Åæ„Åô„Åã Êù•ÈÄ±„ÅÆÁÅ´ÊõúÊó•„ÄÅÂ∞èÊûó„Åï„Çì„ÅÆ„ÅîÈÉΩÂêà„ÅØ„ÅÑ„Åã„Åå„Åß„Åó„Çá„ÅÜ„Åã ÈÇÄËØ∑ ÈÉ®Èï∑„Å´„ÇÇ„Åú„Å≤Êù•„Å¶È†Ç„Åç„Åü„ÅÑ„Åß„Åô„Åã ËØ≠Ê∞îÊØîËæÉÂº∫ÁöÑÈÇÄËØ∑ ÈÉ®Èï∑„Å´„ÇÇ„ÅîÂá∫Â∏≠„ÅÑ„Åü„Å†„Åë„Å™„ÅÑ„Åã„Å®ÊÄù„ÅÑ„Åæ„Åó„Å¶ ÂêéÈù¢ÁöÑÊÄù„ÅÑ„Åæ„Åó„Å¶Â∏¶ÊúâË°®Á§∫ÂéüÂõ†ÁöÑÊÑèÊÄù „Çà„Çç„Åó„Åã„Å£„Åü„Çâ„ÄÅÈÉ®Èï∑„ÇÇ„ÅÑ„Çâ„Åó„ÇÉ„ÅÑ„Åæ„Åõ„Çì„Åã „Çà„Çç„Åó„Åë„Çå„Å∞„ÄÅÈÉ®Èï∑„ÇÇ„ÅÑ„Åã„Åå„Åß„Åó„Çá„ÅÜ„Åã „ÇÇ„Åó„ÅîÈÉΩÂêà„Åå„Çà„Çç„Åó„Åë„Çå„Å∞„ÄÅÈÉ®Èï∑„ÇÇ„ÅÑ„Åã„Åå„Åã„Å®ÊÄù„ÅÑ„Åæ„Åó„Å¶ „ÅäÔºè„Åî„Äú„Å™„ÅèÔºà‰∏çÊòØ‰ªÄ‰πàËØçÈÉΩËÉΩÁî®ÁöÑÔºåÂêéÈù¢‰∏çË¶ÅÂä†teÔºâ „ÅîÂøÉÈÖç„Å™„Åè „ÅîÈÅ†ÊÖÆ„Å™„Åè „ÅäÊ∞óÈÅ£„ÅÑ„Å™„Åè „Åä„Åã„Åæ„ÅÑ„Å™„Åè „Äú„Å¶„Åä„Çä„Åæ„Åô „Å¶„ÅÑ„Åæ„ÅôÁöÑË∞¶ËÆ©ËØ≠ ‰æãÂ≠ê „ÅäËøî‰∫ã„Çí„ÅäÊåÅ„Å°„Åó„Å¶„Åä„Çä„Åæ„Åô ÂΩìÊó•„Åä‰ºö„ÅÑ„Åß„Åç„Çã„ÅÆ„ÇíÊ•Ω„Åó„Åø„Å´„Åó„Å¶„Åä„Çä„Åæ„Åô ‰æãÂ≠êÔºöÈÇÄËØ∑ËÄÅÂ∏à „Çà„Çç„Åó„Åë„Çå„Å∞„ÄÅÂÖàÁîü„ÇÇ„ÅÑ„Çâ„Åó„ÇÉ„ÅÑ„Åæ„Åõ„Çì„ÅãÔºèÂÖàÁîü„ÇÇÊù•„Å¶„Åç„Åü„Å†„Åç„Åü„ÅÑ„Å®ÊÄù„Å£„Å¶„ÅÑ„Åæ„Åô ÂÖàÁîü„ÅÆ„ÅîÈÉΩÂêà„ÅØ„ÅÑ„Åã„Åå„Åß„Åó„Çá„ÅÜ„Åã „ÅäËøî‰∫ã„Çí„ÅäÊåÅ„Å°„Åó„Å¶„Åä„Çä„Åæ„Åô ËØ∑Ê±ÇÊâìÊãõÂëº Âëº„Å≥„Åã„Åë„Çã „ÅÇ„ÅÆ„ÄÅ„Å°„Çá„Å£„Å®„Çà„Çç„Åó„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã ‰ªä„ÄÅ„ÅäÂøô„Åó„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã „ÅäÊôÇÈñì„ÅÑ„Åü„Å†„Åç„Å¶„ÇÇ„Çà„Çç„Åó„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã ÔºàÂÆü„ÅØÔºâ„Äú„ÅÆ„Åß„Åô„Åå ÊåÅ„Å°Â∏∞„Å£„Å¶Êàë„ÅåÁ§æ„ÅÆ„ÇÇ„ÅÆ„Å®Ê§úË®é„Åó„Åü„ÅÑ„ÅÆ„Åß„Åô„Åå„ÄÇ„ÄÇ„ÄÇ ÂÆü„ÅØ‰Ωø„ÅÑÊñπ„Åå„Çà„Åè„Çè„Åã„Çâ„Å™„ÅÑ„ÅÆ„Åß„Åô„Åå„ÄÇ„ÄÇ„ÄÇ „ÅÑ„Åü„Å†„Åë„Åæ„Åõ„Çì„ÅãÔºè„ÅîÔºà„ÅäÔºâ„Äú„ÅÑ„Åü„Å†„Åë„Åæ„Åõ„Çì„Åã ÂêéÈù¢ÈÇ£ÁßçËØ¥Ê≥ïÊõ¥Â•Ω‰∏ÄÁÇπÔºå‰∏≠Èó¥ÂèØ‰ª•Áõ¥Êé•Â°´Âä®ËØçÁöÑmasuÂûã „Åì„ÅÆ‰∫àÂëäÁ∑®„ÅÆDVD„Çí‰∏ÄÊûö„ÅäÈÄÅ„Å£„Å¶„ÅÑ„Åü„Å†„Åë„Åæ„Åõ„Çì„Åã Ê≥®ÊÑèËøôÈáåÊ≤°ÊúâteÔºÅÔºÅÔºÅ ÁªßÁª≠ËØ∑Ê±Ç Êó•Êú¨Ë™ûË®≥„Çí„Å§„Åë„Å¶„ÅÑ„Åü„Å†„Åë„Å™„ÅÑ„Åã„Å®ÊÄù„ÅÑ„Åæ„Åó„Å¶ Êó•Êú¨Ë™ûË®≥„Çí„Å§„Åë„Å¶„ÅÑ„Åü„Å†„Åë„Çã„Å®„ÅÇ„Çä„Åå„Åü„ÅÑ„Çì„Åß„Åô„Åå„ÄÇ* ÊÄù„ÅÑ„Åæ„Åó„Å¶Â∞±Ë°®Á§∫‰∫ÜÊ≤°ËØ¥ÂÆåÔºå‰ΩÜÊòØÂêéÈù¢Ë∑üÁùÄÔºö‰Ω†ËÉΩÊé•Êî∂ÊàëÁöÑËØ∑Ê±ÇÂêóÁöÑÊÑèÊÄù ÊâìÊãõÂëºÁöÑÊñπÂºè ÊúãÂèã „Åß„Åô„Åæ„Åô Êï¨ËØ≠ „Å≠„Åà„ÄÅ„ÅÇ„ÅÆ„Å≠ ÂèØ ‰∏çÂèØ ‰∏çÂèØ „ÅÇ„ÅÆ- ÂèØ ÂèØ ÂèØ ÊÇ™„ÅÑ„Çì„Å†„Åë„Å©ÔºèÊÇ™„ÅÑ„Åë„Å© ÂèØ ‰∏çÂèØ ‰∏çÂèØ „Çà„Åã„Å£„Åü„Çâ ÂèØ ÂèØ ÂèØ „Åô„Åø„Åæ„Åõ„Çì„Åå ‰∏çÂèØ ÂèØ ÂèØ „Çà„Çç„Åó„Åã„Å£„Åü„Çâ ‰∏çÂèØ ‰∏çÂèØ ÂèØ Áî≥„ÅóË®≥„ÅÇ„Çä„Åæ„Åõ„Çì„ÅåÔºèÊÅê„ÇåÂÖ•„Çä„Åæ„Åô„ÅåÔºèÊÅêÁ∏Æ„Åß„Åô„Åå ‰∏çÂèØ ‰∏çÂèØ ÂèØ ÊñáÊú´ ÊúãÂèã „Åß„Åô„Åæ„Åô Êï¨ËØ≠ ~„Å¶Ôºà„ÇàÔºè„Å≠Ôºâ ÂèØ ‰∏çÂèØ ‰∏çÂèØ ~„Å¶„Åè„Çå„Å™„ÅÑ ÂèØ ‰∏çÂèØ ‰∏çÂèØ ~„Å¶„Åè„Çå„Åæ„Åõ„Çì„Åã ‰∏çÂèØ ÂèØ ‰∏çÂèØ ~„Å¶„ÇÇ„Çâ„Åà„Åæ„Åõ„Çì„Åã ‰∏çÂèØ ÂèØ ‰∏çÂèØ ~„ÅÑ„Åü„Å†„Åë„Åæ„Åõ„Çì„Åã ‰∏çÂèØ ÂèØ ÂèØ ~„ÅÑ„Åü„Å†„Åë„Åæ„Åõ„Çì„Åß„Åó„Çá„ÅÜ„Åã ‰∏çÂèØ ÂèØ ÂèØ ~„ÅÑ„Åü„Å†„Åç„Åü„ÅÑ„Çì„Åß„Åô„Åå ‰∏çÂèØ ÂèØ ÂèØ ~„ÅÑ„Åü„Å†„Åë„Å™„ÅÑ„Åã„Å®ÊÄù„ÅÑ„Åæ„Åó„Å¶ ‰∏çÂèØ ‰∏çÂèØ ÂèØ ~„ÅÑ„Åü„Å†„Åë„Çã„Å®„ÅÇ„Çä„Åå„Åü„ÅÑ„Çì„Åß„Åô„Åå ‰∏çÂèØ ‰∏çÂèØ ÂèØ ÁªÉ‰π†Âè•Âûã „Åô„Åø„Åæ„Åõ„Çì„Åå„ÄÅ„Äú„Å¶„ÅÑ„Åü„Å†„Åë„Åæ„Åõ„Çì„Åã Áî≥„ÅóË®≥„Å™„ÅÑ„Çì„Åß„Åô„Åå„ÄÅ„Äú„Å¶„ÅÑ„Åü„Å†„Åë„Çã„Å®„ÅÇ„Çä„Åå„Åü„ÅÑ„Çì„Åß„Åô„Åå Áî®Âú®ÈùûÂ∏∏Èöæ‰ª•ÂºÄÂè£ËØ∑Ê±ÇÁöÑÈÉëÈáçÊÅ≥ËØ∑ÁöÑÊÉÖÂÜµ‰∏ã „ÅÇ„ÅÆ„Éº„ÄÅ„Äú„Å¶„ÇÇ„Çà„Çç„Åó„Åß„Åó„Çá„ÅÜ„Åã ÂÜôÊé®Ëçê‰ø° ÊïôÂ∏´„ÅÆÊé®Ëñ¶Áä∂„ÅåÂøÖË¶Å„Å™„ÅÆ„Åß„Åô„Åå„ÄÅ„ÅäÊõ∏„Åç„ÅÑ„Åü„Å†„Åë„Å™„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã„ÄÇ ÂÖàÁîü„ÅÆÁ†îÁ©∂ÂÆ§„Å´„Åî„ÅÇ„ÅÑ„Åï„Å§„Å´‰º∫„ÅÑ„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åó„Å¶ ÂÖàÁîü„ÅÆ„ÅîÈÉΩÂêà„Åå„Çà„Çç„Åó„ÅÑÊôÇÈñì„Çí„ÅäÁü•„Çâ„Åõ„ÅÑ„Åü„Å†„Åë„Çã„Å®„ÅÇ„Çä„Åå„Åü„ÅèÂ≠ò„Åò„Åæ„Åô Ëøî‰∫ã„Çí„ÅäÂæÖ„Å°„Åó„Å¶„Åä„Çä„Åæ„Åô ÊãíÁªù Êñ≠„Çã„Äú„ÅØ„Å°„Çá„Å£„Å®„ÄÇ„ÄÇ„ÄÇ ËÆ©ÂØπÊñπÁúãÂà∞Ëá™Â∑±‰∏∫ÈöæÁöÑÊ†∑Â≠êÔºåÁü•ÈÅìËá™Â∑±ÊúâÂõ∞Èöæ Êñ≠„Çã ‰æã1ÔºöÊãíÁªùÁöÑÊó∂ÂÄôËØ¥Âà∞Âè•Â∞æÂèØ‰ª•‰∏çËØ¥Ê∏ÖÊ•ö „ÅÇ„ÄÅ„Ç≥„Éî„ÉºÊâã‰ºù„Å£„Å¶„Åè„Çå„Å™„ÅÑ„Åã ‰ªä„ÄÅ„É≠„Éì„Éº„Åß„ÅäÂÆ¢Êßò„ÅåÂæÖ„Å£„Å¶„ÅÑ„Çâ„Å£„Åó„ÇÉ„Çã„ÅÆ„Åß„ÄÇ„ÄÇ„ÄÇ ‰æã2ÔºöÂè•Â∞æÁî®„Åæ„Åó„Å¶Ôºà„Åæ„ÅôÔºâ„ÄÅ„Åß„Åó„Å¶Ôºà„Åß„ÅôÔºâÊù•Ë°®Á§∫ÂéüÂõ† ÊÆãÂøµ„Å™„Åå„Çâ‰ªäÂõû„ÅØ‰º∫„Åà„Å™„ÅÑ„Çì„Åß„Åô„ÄÇ‰ªäÂ§ú„ÅØÂèã‰∫∫„Å®‰ºö„ÅÜÁ¥ÑÊùü„Åå„ÅÇ„Çä„Åæ„Åó„Å¶„ÄÇ„ÄÇ„ÄÇ „Åô„Åø„Åæ„Åõ„Çì„ÄÇ„ÅäÈÖí„ÅØ„Å°„Çá„Å£„Å®Ëã¶Êâã„Åß„Åó„Å¶„ÄÇ„ÄÇ„ÄÇ „ÅÇ„Çä„Åæ„Åô -&gt; „Åî„Åñ„ÅÑ„Åæ„Åó„Å¶Ôºè„Å† -&gt; „Åß„Åó„Å¶ Ë¨ù„Çã ÊãíÁªù‰∫Ü‰ª•ÂêéÁöÑÈÅìÊ≠â Ë¢´ÊãúÊâò‰∫Ü‰∫ãÊÉÖÁöÑÊó∂ÂÄô „ÅäÂΩπ„Å´Á´ã„Å¶„Å™„Åè„Å¶„ÄÅÁî≥„ÅóË®≥„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ Ë¢´ÈÇÄËØ∑‰∫ÜÁöÑÊó∂ÂÄô„ÄÇËØ∑ÂÖàËØ¥Ë∞¢Ë∞¢ „Åõ„Å£„Åã„Åè„ÅäË™ò„ÅÑ„Åè„Å†„Åï„ÅÑ„Åæ„Åó„Åü„ÅÆ„Å´„ÄÅÔºà„Åô„Åø„Åæ„Åõ„ÇìÔºâ ÊãíÁªù‰∫Ü‰ΩÜÊòØËøòË¶Å‰øùÊåÅËâØÂ•ΩÁöÑÂÖ≥Á≥ª ‰ªäÂõû„ÅØ‰º∫„Åà„Å™„ÅÑ„Çì„Åß„Åô„Åå„ÄÅ„Åæ„Åü ‰ªäÂ∫¶ÔºèÊ¨°ÂõûÔºèÊ¨°„ÅÆÊ©ü‰ºö „Å´ „ÅäË™ò„ÅÑ„Åè„Å†„Åï„ÅÑÔºè„Åî‰∏ÄÁ∑í„Å´„Åï„Åõ„Å¶„Åè„Å†„Åï„ÅÑ ÁªÉ‰π† „Äú„ÅØ„Å°„Çá„Å£„Å®Ëã¶Êâã„Åß„Åó„Å¶ „ÅäË™ò„ÅÑ„Åè„Å†„Åï„ÅÑ„Åæ„Åó„Å¶„ÅÇ„Çä„Åå„Å©„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô ÊÆãÂøµ„Å™„Åå„Çâ„ÄÅ„Åù„ÅÆÊó•„ÅØÂ±±Áî∞„Åï„Çì„Å®‰ºöË≠∞„ÅÆ‰∫àÂÆö„Åß„Åî„Åñ„ÅÑ„Åæ„Åô„ÄÇ Áî≥„ÅóË®≥„ÅÇ„Çä„Åæ„Åõ„Çì„Åå„ÄÅÂèÇÂä†„Åß„Åç„Åæ„Åõ„Çì „Åõ„Å£„Åã„Åè„ÅÆ„ÅäË™ò„ÅÑ„Å™„ÅÆ„Å´„Åô„Åø„Åæ„Åõ„Çì„ÄÇ ‰ªäÂõû„ÅØ‰º∫„Åà„Å™„ÅÑ„Åß„Åô„Åå„ÄÅ„Åæ„Åü‰ªäÂ∫¶„Å´„ÅäË™ò„ÅÑ„Åè„Å†„Åï„ÅÑ Áî≥„ÅóÂá∫„Çã Ëá™Â∑±‰∏ªÂä®ÊèêÂá∫Áî≥ËØ∑„ÅäÔºè„Åî „Äú Ôºà„ÅÑ„ÅüÔºâ„Åó„Åæ„Åó„Çá„ÅÜ„Åã ‰ΩøÁî®Ëá™Ë∞¶ËØ≠Êù•Ë°®Á§∫ÈÉëÈáçÁöÑ‰∏ªÂä®ÊèêÂá∫ÔºåÂèØ‰ª•ËÆ©ÊàëÊù•Âπ≤Ëøô‰ª∂‰∫ãÁöÑÊÑèÊÄùÔºÅÔºÅÊ≤°Êúâte ‰æãÂ≠ê „ÅäËç∑Áâ©„Çí„ÅäÊåÅ„Å°„Åó„Åæ„Åó„Çá„ÅÜ„Åã Ë≥áÊñô„Çí„ÅäÈÄÅ„ÇäËá¥„Åó„Åæ„Åó„Çá„ÅÜ„Åã Âä†Ëó§„Åï„Çì„Å´„ÅØÁßÅ„Åã„Çâ„ÅîÈÄ£Áµ°Ëá¥„Åó„Åæ„Åó„Çá„ÅÜ„Åã „Äú„Åï„Åõ„Å¶„ÅÑ„Åü„Å†„Åç„Åæ„Åô ÂéüÊú¨ÊòØÂæÅÊ±ÇÂØπÊñπËÆ∏ÂèØ‰πãÂêéÂÅöÊüê‰∫ãÔºåÂêéÊù•ÂèëÂ±ïÊàêÊï¨ËØ≠Áî®Ê≥ïÔºà„Åï„Åõ„Å¶„ÅÑ„Åü„Å†„Åç„ÅÑ„Å¶„ÇÇ„Çà„Çç„Åó„ÅÑ„Åß„Åó„Çá„ÅÜ„ÅãÔºâ Êú™ÁªèËÆ∏ÂèØÂ∞±Áî®ÁöÑËØùÊúâÂº∫Âä†ÁöÑÊÑèÊÄù ‰æãÂ≠ê ‰ºöË≠∞„ÅÆÊó•„ÅØÊòºÈ£ü„ÇíÁî®ÊÑè„Åï„Åõ„Å¶„ÅÑ„Åü„Å†„Åç„Åæ„Åô ‰ªäÊó•„ÅÆÂçàÂæå„ÄÅ‰ºöË≠∞ÂÆ§„Çí‰Ωø„Çè„Åõ„Å¶„ÅÑ„Åü„Å†„Åç„Åü„ÅÑ„Çì„Åß„Åô„Åå ‰ªäÊó•„ÅØÁî≥„ÅóË®≥„Å™„ÅÑ„Çì„Åß„Åô„Åå„ÄÅÊó©„ÇÅ„Å´Â∏∞„Çâ„Åõ„Å¶„ÅÑ„Åü„Å†„Åë„Åæ„Åõ„Çì„Åã „Åì„ÅÆ„Éë„ÇΩ„Ç≥„É≥„Çí‰Ωø„Çè„Åõ„Å¶„ÅÑ„Åü„Å†„ÅÑ„Å¶„ÇÇ„Çà„Çç„Åó„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã „Äú„Åï„Åõ„Å¶„Åè„Å†„Åï„ÅÑ Ë°®ËææÂØπÊñπÂêåÊÑè‰πãÂêéÈùûÂ∏∏Âº∫ÁÉàÁöÑÊÉ≥ÂÅöËøô‰ª∂‰∫ã ‰æãÂ≠ê ‰ªä Â∫¶„ÅÆ‰ªï‰∫ã„ÅØÁßÅ„Å´ÊãÖÂΩì„Åï„Åõ„Å¶„Åè„Å†„Åï„ÅÑ ‰ªäÂ§ú„ÅØÁßÅ„Å´„Åî„Å°„Åù„ÅÜ„Çí„Åï„Åõ„Å¶„Åè„Å†„Åï„ÅÑ „ÅäË©´„Å≥„Åô„Çã ÈÅìÊ≠âÈÅìÊ≠âÂ∏∏Áî®Âè• Áî≥„ÅóË®≥„ÅÇ„Çä„Åæ„Åõ„ÇìÔºà„Åß„Åó„ÅüÔºâÔºè Áî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„ÇìÔºà„Åß„Åó„ÅüÔºâ Â§ßÂ§âÂ§±Á§º„ÅÑ„Åü„Åó„Åæ„Åó„Åü Ôºè „ÅîËø∑ÊÉë„Çí„Åä„Åã„Åë„Åó„Åæ„Åó„Åü Ôºè „Å©„ÅÜ„Åã„ÅäË®±„Åó„Åè„Å†„Åï„ÅÑ Êä•ÂëäËá™Â∑±ÁöÑÂ§±ËØØ ÂÆü„ÅØ„ÄÅ„ÅäÁ¥ÑÊùü„ÅÆÊôÇÈñì„Å´‰º∫„Åà„Å™„Åè„Å™„Å£„Å¶„Åó„Åæ„Å£„Åü„Çì„Åß„Åô 11Êó•„Çí21Êó•„Å†„Å®ËÅû„ÅçÈñìÈÅï„Åà„Å¶„Åó„Åæ„ÅÑ„Åæ„Åó„Åü ‰º†ËææÂèçÁúÅÁöÑÂøÉÊÉÖ ‰ª•ÂæåÔºè‰ªäÂæå„ÅØÊ∞ó„Çí„Å§„Åë„Åæ„Åô ‰∫åÂ∫¶„Å®„Åì„ÅÆ„Çà„ÅÜ„Å™„Éü„Çπ„Çí„Åó„Å™„ÅÑ„Çà„ÅÜ„Å´„ÄÅÊ≥®ÊÑèÔºèÁ¢∫Ë™çÔºèÂæπÂ∫ï „ÅÑ„Åü„Åó„Åæ„Åô Âà´‰∫∫ÂØπËá™Â∑±ÈÅìÊ≠âÁöÑÊó∂ÂÄô ËΩªÊùæ „ÅÇ„ÄÅ„ÅÑ„Åà„ÅÑ„Åà„ÄÅ„ÅÇ„Åæ„Çä„ÅäÊ∞ó„Å´„Å™„Åï„Çâ„Å™„ÅÑ„Åß„Åè„Å†„Åï„ÅÑ ‰∏•ËÇÉ „Åì„ÅÜ„ÅÑ„ÅÜ„ÅÆ„ÅØÂõ∞„Çä„Åæ„Åô „Åì„ÅÜ„ÅÑ„ÅÜ„Åì„Å®„Çí„Åï„Çå„Çã„Å®Âõ∞„Çã„Çì„Åß„Åô„Çà „Åì„Çå„Åã„ÇâÊ∞ó„Çí„Å§„Åë„Å¶„Åè„Å†„Åï„ÅÑ Âè•Â≠ê „ÅäÔºè„Åî„Äú„Åó„Å¶„Åó„Åæ„ÅÑ„Åæ„Åó„Å¶„ÄÅÁî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„Åß„Åó„Åü „ÅäÔºè„Åî„Äú„Åè„Å†„Åï„ÅÑ„Åæ„Åó„Åü„ÅÆ„Å´„ÄÅ‰º∫„Åà„Åæ„Åõ„Çì„Åß„ÄÅÂ§±Á§º„ÅÑ„Åü„Åó„Åæ„Åó„ÅüÔºàË°®Á§∫ÁöÑÊÑèÊÄùÊòØ‰Ω†ÈÉΩÈÇÄËØ∑ÊàëÂÅö‰∫ÜÔºå‰Ω†ÈÉΩÂáÜÂ§áÂ•Ω‰∫ÜÔºå‰πãÁ±ªÁöÑÔºå‰ΩÜÊòØÊàëÂÅö‰∏ç‰∫ÜÔºâ ÊàñËÄÖ‰∏çÂä†oÔºåÂêéÈù¢Âä†te‰πüÂèØ‰ª• ÂçëÂæÆ „ÅäÂøô„Åó„ÅÑ‰∏≠„ÄÅ„ÅäÊôÇÈñì„Çí‰Ωú„Å£„Å¶„Åè„Å†„Åï„ÅÑ„Åæ„Åó„Åü„ÅÆ„Å´„ÄÅÊôÇÈñì„ÇíÈñìÈÅï„Åà„Å¶„Åó„Åæ„ÅÑ„Åæ„Åó„Å¶Áî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ‰ªäÂæå„ÅØÂçÅÂàÜÊ≥®ÊÑè„ÅÑ„Åü„Åó„Åæ„Åô„ÅÆ„Åß„ÄÅ„ÅäË®±„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ ÊèêÊÑèËßÅÈóÆÂà´‰∫∫ÁöÑÊÑèËßÅ „Åì„Çå„Å´„Å§„ÅÑ„Å¶„ÅØ„Å©„ÅÜÊÄù„Çè„Çå„Åæ„Åô„ÅãÔºè„Åì„ÅÆÁÇπ„Å´„Å§„ÅÑ„Å¶„ÅØ„ÅÑ„Åã„Åå„Åß„Åô„Åã „Åø„Å™„Åï„Çì„ÅÆ„ÅîÊÑèË¶ã„ÅØÔºè‰Ωï„Åã„ÅîÊÑèË¶ã„ÅØ„ÅÇ„Çä„Åæ„Åô„Åã Áî®‰∏ÄÂè•ËØùË°®Á§∫ËµûÊàêÂíåÂèçÂØπ ËµûÊàêÔºö„ÅÑ„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô ÂèçÂØæÔºö„ÅÜ„Éº„ÇìÔºè„Åù„Çå„ÅØ„Å°„Çá„Å£„Å®„ÄÇ„ÄÇ„ÄÇÔºè„Å©„ÅÜ„Åß„Åó„Çá„ÅÜ„Åã„ÄÇ„ÄÇ„ÄÇ ÂºÄÂßãÈôàËø∞Ëá™Â∑±ÁöÑÊÑèËßÅ „Å°„Çá„Å£„Å®„ÄÅ„Çà„Çç„Åó„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã ËØ¥Ëá™Â∑±ÁöÑÊÑèËßÅ ÂíåÂπ≥ÁöÑÊèêÊ°àÔºà‰∏ÄËà¨Áî®ËøôÁßçÔºâ VÔºèA„ÅÑ „ÅÆ„Åß„ÅØ„Å™„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã NÔºèA„Å™ „Å™„ÅÆ„Åß„ÅØ„Å™„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã ‰æã ‰∫àÁÆó„Åå„ÇÇ„Å£„Å®„Åã„Åã„Å£„Å¶„Åó„Åæ„ÅÜ„ÅÆ„Åß„ÅØ„Å™„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã ÊôÇÈñì„ÅåË∂≥„Çä„Å™„Åè„Å¶„ÄÅÁÑ°ÁêÜ„Å™„ÅÆ„Åß„ÅØ„Å™„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã ÊèêËÆÆ ÂÖ∑‰ΩìÁöÑÊñπÊ°à V „Åü„Çâ„Å©„ÅÜ„Åã„Å®ÊÄù„ÅÑ„Åæ„ÅôÔºà„ÅåÔºâ N „Åå„ÅÑ„ÅÑ„Åã„Å®ÊÄù„ÅÑ„Åæ„ÅôÔºà„ÅåÔºâ ‰æã ÊôÇÈñì„Åå„Åã„Åã„Çã„ÅÆ„Åß„ÄÅ1„É∂ÊúàÂâç„Åã„ÇâÊ∫ñÂÇô„Åó„Åü„Çâ„Å©„ÅÜ„Åã„Å®ÊÄù„ÅÑ„Åæ„Åô„Åå ÁµêÂ©ö„ÅÆ„ÅäÁ•ù„ÅÑ„Å´„ÅØ„ÄÅ‰∫å‰∫∫„ÅåÈï∑„Åè‰Ωø„Åà„Çã„Ç≥„Éº„Éí„Éº„Ç´„ÉÉ„Éó„Å™„Å©„Åå„ÅÑ„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô ÂΩíÁ∫≥ÊÑèËßÅ „Åù„Çå„Çà„Çä„ÇÇ V„Åü Êñπ„Åå„ÅÑ„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô „Åù„Çå„Çà„Çä„ÇÇ„ÇÇ„Å£„Å®Á∞°Âçò„Å´Ê∫ñÂÇô„Åß„Åç„ÇãÁô∫Ë°®„Å´Â§â„Åà„ÅüÊñπ„Åå„ÅÑ„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô Êé•Êî∂ÊÑèËßÅ „Äú„ÅØ„ÅÑ„ÅÑ„Åì„Å®„Å†„Å®ÊÄù„ÅÑ„Åæ„Åô„ÅåÔºè„Åù„Çå„ÇÇ„Åù„ÅÜ„Åß„Åô„Åå ËØ¥ÊòéÁêÜÁî±ÂøòÂπ¥‰ºö„ÅØ‰∏≠ËèØÊñôÁêÜ„Åå„ÅÑ„ÅÑ„ÅÆ„Åß„ÅØ„Å™„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã„ÄÇ„Å®„ÅÑ„ÅÜ„ÅÆ„ÅØ„ÄÅ‰∫∫Êï∞„ÅåÊÄ•„Å´Â¢ó„Åà„Å¶„ÇÇÂ§ß‰∏àÂ§´„Åß„Åô„Åó„ÄÅËã•„ÅÑ‰∫∫„ÅØ„Åü„Åè„Åï„ÇìÈ£ü„Åπ„Åü„ÅÑ„Å®„ÅÑ„ÅÜ‰∫∫„ÇÇÂ§ö„ÅÑ„Åß„Åô„Åó„ÄÅÊñôÁêÜ„ÅÆÊï∞„ÇÇÂ§ö„Åè„Åß„ÄÅ‰∫∫Ê∞ó„Åå„ÅÇ„Çä„Åæ„Åô„ÅÆ„Åß„ÄÇ„ÄÇ„ÄÇ„Åì„Å°„Çâ„ÅÆÊñπ„Åå„ÅÑ„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ Êï¥‰ΩìÂè•Âûã „Çà„Çç„Åó„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã„ÄÇ„ÄúÔºà„Å™Ôºâ„ÅÆ„ÅØ„ÅÑ„ÅÑ„Åì„Å®„Å†„Å®ÊÄù„ÅÑ„Åæ„Åô„Åå„ÄÅ„ÄúÔºà„Å™Ôºâ„ÅÆ„Åß„ÅØ„Å™„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã„ÄÇ„Åù„Çå„Çà„Çä„ÇÇ„ÄÅ„Äú„ÅüÊñπ„Åå„ÅÑ„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„Åå„ÄÅ„ÅÑ„Åã„Åå„Åß„Åó„Çá„ÅÜ„Åã„ÄÇ ÂÜôÈÇÆ‰ª∂ „ÅäÁñ≤„ÇåÊßò„Åß„Åô„ÄÇ„Ç¢„É¨„ÇØ„Çπ„Åß„Åô„ÄÇ „É°„Éº„É´„ÇíÊãùË¶ã„Åó„Åæ„Åó„Åü„ÄÇ „Åæ„ÅöÂ∏≠„ÅÆ„Åì„Å®„Åß„Åô„Åå„ÄÅ„Éï„É©„É≥„ÇπÊñôÁêÜ„ÅØ„ÅÑ„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„Åå„ÄÅ‰∏Ä‰∫∫‰∏Ä‰∫∫„ÅÆÂ∏≠„ÅåÈõ¢„Çå„Å¶„ÅÑ„Å¶„Åø„Çì„Å™„ÅßË©±„Åô„Åì„Å®„Åß„Åç„Å™„ÅÑ„ÅÆ„Åß„ÅØ„Å™„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã„ÄÇ ‰∫∫Êï∞„Åå„Åæ„Å†Ê±∫„Åæ„Å£„Å¶„ÅÑ„Å™„ÅÑ„Å®„ÅÑ„ÅÜ„Åì„Å®„Åß„Åô„Åå„ÄÅ„Åù„Çå„Å™„Çâ‰∫∫Êï∞„ÅåÂ§â„Çè„Å£„Å¶„ÇÇÂ§ß‰∏àÂ§´„Å™‰∏≠ËèØÊñôÁêÜ„Åå„ÅÑ„ÅÑ„Å£„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ‰ªäÂ∫¶„ÅÆ„ÅäÂÆ¢Êßò„ÅØ„Ç¢„Ç∏„Ç¢„Åã„Çâ„ÅÆ„ÅäÂÆ¢Êßò„ÅåÂ§ö„ÅÑ„Å®‰º∫„Å£„Å¶„Åä„Çä„Åæ„Åô„ÅÆ„Åß„ÄÅ„Ç¢„Ç∏„Ç¢ÊñôÁêÜ„ÅÆÊñπ„ÅåÊÖ£„Çå„Å¶„ÅÑ„Å¶„ÅÑ„ÅÑ„ÅÆ„Åß„ÅØ„Å™„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã„ÄÇ ~‰∏≠ËèØÊñôÁêÜ„Åå„ÅÑ„ÅÑ„ÅÆ„Åß„ÅØ„Å™„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã„ÄÇ„Å®„ÅÑ„ÅÜ„ÅÆ„ÅØ„ÄÅ‰∫∫Êï∞„ÅåÊÄ•„Å´Â¢ó„Åà„Å¶„ÇÇÂ§ß‰∏àÂ§´„Åó„ÄÅ„ÅäÂÆ¢Êßò„ÅØ„Ç¢„Ç∏„Ç¢ÊñôÁêÜ„ÅÆÊñπ„ÅåÊÖ£„Çå„Å¶„ÅÑ„Çã„Åã„ÇÇ„Åó„Çå„Åæ„Åõ„Çì„ÄÇ~ „Åù„Çå„Çà„Çä„ÇÇ„ÄÅ‰∏≠ËèØÊñôÁêÜ„ÅÆÊñπ„Åå„ÅÑ„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„Åå„ÄÅ„ÅÑ„Åã„Åå„Åß„Åó„Çá„ÅÜ„Åã„ÄÇ Êé•Êî∂È¢ÑÁ∫¶„Äú„Åß„Åî„Åñ„ÅÑ„Åæ„Åô Êé•ÁîµËØù Áî®‰∫éËØ¥Ëá™Â∑±ÊàñËÄÖËá™Â∑±Âõ¢‰ΩìÁöÑ‰∫ãÊÉÖ „Åß„Åî„Åñ„ÅÑ„Åæ„ÅôÂíå„Åß„ÅÑ„Çâ„Åó„ÇÉ„ÅÑ„Åæ„ÅôÊòØ‰∏Ä‰∏™ÊÑèÊÄùÔºå‰∏Ä‰∏™Áî®Âú®Ëá™Â∑±‰∏Ä‰∏™Áî®Âú®ÂØπÊñπ Êâø„Çä„Åæ„ÅôÔºà„ÅÜ„Åë„Åü„Åæ„Çè„ÇãÔºâ Êé•ÂèóÈ¢ÑÁ∫¶ ÂØπÁõÆ‰∏äÁöÑ‰∫∫Êé•Êî∂È¢ÑÁ∫¶Êó∂ÂÄôÁöÑÊï¨ËØ≠ „Åî‰∫àÁ¥Ñ„ÄÅÊâø„Å£„Å¶„Åä„Çä„Åæ„Åô „Åî‰∫àÁ¥Ñ„ÅØ„ÄÅÁßÅ„ÄÅÈà¥Êú®„ÅåÊâø„Çä„Åæ„Åó„Åü „Äú„Åß„ÅÑ„Çâ„Åó„ÇÉ„ÅÑ„Åæ„Åô Á°ÆÂÆöÈ¢ÑÁ∫¶ÁöÑ‰∫∫Êï∞ÊàñËÄÖÂêçÂ≠ó Â§±Á§º„Åß„Åô„Åå„ÄÅÁî∞‰∏≠„Åï„Çì„Åß„ÅÑ„Çâ„Åó„ÇÉ„ÅÑ„Åæ„Åô„Åã 3ÂêçÊßò„Åß„ÅÑ„Çâ„Åó„ÇÉ„ÅÑ„Åæ„Åô„Åã „ÅäÂÖÉÊ∞ó„Åß„ÅÑ„Çâ„Åó„ÇÉ„ÅÑ„Åæ„Åô„Åã ‰∏çËÉΩÁî®Âú®ÂíåÂØπÊñπÊó†ÂÖ≥ÁöÑ‰∫ãÊÉÖ‰∏ä „ÅäÔºè„Åî „Äú „Å´„Å™„Çå„Åæ„Åô„Åã Âú®Êó•ËØ≠ÈáåÁõ¥Êé•ÈóÆÁõÆ‰∏äÁöÑ‰∫∫„Åß„Åç„Åæ„ÅôÊØîËæÉÂ§±Á§ºÔºåÊâÄ‰ª•Áî®ËøôÁßçÊñπÊ≥ïÁöÑÊØîËæÉÂ§ö„ÄÇÂè™ÊúâÂΩìÊúâÈùûÂ∏∏Á®ÄÂ•áÁöÑÊäÄËÉΩÁöÑÊó∂ÂÄôÊâç‰ºöÁî®„Åß„Åç„Åæ„Åô Á§æÈï∑„ÅØ„Çπ„Éö„Ç§„É≥Ë™û„Åå„ÅäË©±„Å´„Å™„Çå„Åæ„Åô„Åã „ÅäÔºè„Åî„Äú„ÅÑ„Åü„Å†„Åë„Åæ„Åô Ôºù „Äú„Å¶„ÇÇ„Çâ„Åà„Åæ„ÅôÔºàË°®Á§∫ÁöÑÊòØÂèØ‰ª•ÂÅöÁöÑÊÑèÊÄùÔºåÊ≤°ÊúâÊéàÂèóÁöÑÂê´‰πâÔºâ „Åì„ÅÆÂª∫Áâ©„ÅÆ‰∏≠„Åß„ÄÅwifi„Åå„Åä‰Ωø„ÅÑ„ÅÑ„Åü„Å†„Åë„Åæ„Åô ÁâπÊÄ•Âà∏„Çí„ÅäÊ±Ç„ÇÅ„Å´„Å™„Çå„Å∞„ÄÅÁâπÊÄ•„Å´„Åî‰πóËªä„ÅÑ„Åü„Å†„Åë„Åæ„Åô „Äú„ÅØ„Å™„Åï„ÅÑ„Åæ„Åô„Åã Ôºù „Äú„Å´„Åó„Åæ„Åô„Åã Ôºù „Å´Ê±∫„ÇÅ„Åæ„Åô ÊñôÁêÜ„ÅØ„Å©„ÅÆ„Ç≥„Éº„Çπ„Å´„Å™„Åï„ÅÑ„Åæ„Åô„Åã „Åï„Åõ„Å¶„ÅÑ„Åü„Å†„Åç„Åæ„Åô ÂÜç‰∏ÄÊ¨°Á°ÆËÆ§ Áî®Â§ö‰∫Ü‰ºöÊúâÂº∫Ëø´ÁöÑÊÑèÊÄù „ÅîÊ≥®Êñá„Çí Áπ∞„ÇäËøî„Åï„Åõ„Å¶ÔºèÁ¢∫Ë™ç„Åï„Åõ„Å¶ÔºèÂæ©Âî±„Åï„Åõ„Å¶ „ÅÑ„Åü„Å†„Åç„Åæ„Åô Ë™†„Å´ÂãùÊâã„Å™„Åå„ÇâÊú¨Êó•„ÅØÂçàÂæå‰∏ÉÊôÇ„ÅßÈñâÂ∫ó„Åï„Åõ„Å¶„ÅÑ„Åü„Å†„Åç„Åæ„Åô „Çµ„Éº„Éì„ÇπÊï¨Ë™û„ÅäÔºè„Åî„Äú„Å´„Å™„Çä„Åæ„Åó„Åü„Çâ Â¶ÇÊûú‰Ω†ÂÜ≥ÂÆöÂ•Ω‰∫ÜÁöÑËØù„ÅäÊ±∫„Åæ„Çä„Å´„Å™„Çä„Åæ„Åó„Åü„Çâ„ÄÅ„ÅäÂëº„Å≥„Åè„Å†„Åï„ÅÑ „ÅäÔºè„Åî„Äú„Åè„Å†„Åï„ÅÑ„Åæ„Åõ ‰∏ÅÂÆÅÁöÑËØ¥ËØ∑Ê±ÇÁöÑÊó∂ÂÄô „Åä‰∏Ä‰∫∫‰∏ÄÊûö„Åö„Å§„ÅäÂèñ„Çä„Åè„Å†„Åï„ÅÑ„Åæ„Åõ ‰Ωï„Åã„ÅÇ„Çä„Åæ„Åó„Åü„Çâ„ÄÅ„ÅîÁõ∏Ë´á„Åè„Å†„Åï„ÅÑ„Åæ„Åõ „ÅîË≥™Âïè„Åå„Åä„ÅÇ„Çä„Åß„Åó„Åü„Çâ„ÄÅ„ÅäÁ≠î„Åà„ÅÑ„Åü„Åó„Åæ„Åô „ÅäÂõ∞„Çä„Åß„Åó„Åü„Çâ„ÄÅ„ÅäÊâã‰ºù„ÅÑ„ÅÑ„Åü„Åó„Åæ„Åô Áü≠ËØ≠ „ÅäÊ±∫„Åæ„Çä„Åß„Åó„Åü„ÇâÔºà„ÅäÊ±∫„Åæ„Çä„Å´„Å™„Å£„Å¶„ÅÑ„Åæ„Åó„Åü„ÇâÔºâ„ÄÅ‰º∫„ÅÑ„Åæ„Åô „Åî‰∫àÁ¥Ñ„Çí„ÅîÂ∏åÊúõ„Å™„ÇâÔºà„ÅîÂ∏åÊúõ„Å´„Å™„Çã„Å™„ÇâÔºâ„ÄÅ„Åì„Å°„Çâ„ÅßÊâø„Çä„Åæ„Åô ÂÖà„Å´„Åä‰∏¶„Å≥„ÅÆÊñπÔºà„Åä‰∏¶„Å≥„Å´„Å™„Å£„Å¶„ÅÑ„ÇãÊñπÔºâ„Åã„ÇâÈ†Ü„Å´„ÅäÂÖ•„Çä„Åè„Å†„Åï„ÅÑ Êï¥ÁêÜÂà∏„Çí„ÅäÊåÅ„Å°„Åß„Åô„ÅãÔºà„ÅäÊåÅ„Å°„Å´„Å™„Å£„Å¶„ÅÑ„Çâ„Å£„Åó„ÇÉ„ÅÑ„Åæ„Åô„ÅãÔºâ Â∏∏Áî®ÊúçÂä°Áî®ËØ≠ „ÅäÂæÖ„Åü„Åõ„Åó„Åæ„Åó„Åü „Åã„Åó„Åì„Åæ„Çä„Åæ„Åó„Åü „ÅäÈ£≤„ÅøÁâ©„ÅØ„ÅÑ„Åã„Åå„ÅÑ„Åü„Åó„Åæ„Åó„Çá„ÅÜ„Åã „Åë„Å£„Åì„ÅÜ„Åß„ÅôÊé•Êî∂ÂïÜÈáèËØ¢ÈóÆÂà´‰∫∫ÁöÑÊÉ≥Ê≥ïÁöÑÊó∂ÂÄô ÂØπÁõÆ‰∏äËØ¢ÈóÆÊÉ≥Âπ≤‰ªÄ‰πàÁöÑÊó∂ÂÄôÔºå‰∏çËÉΩÁî®„Äú„Åó„Åü„ÅÑÊù•ÈóÆ ÂÖàÁîü„ÅØ‰Ωï„ÇíÈ£ü„Åπ„Åü„ÅÑ„Åß„Åô„ÅãÔºàX) ÂÖàÁîü„ÅØ‰Ωï„ÇíÂè¨„Åó‰∏ä„Åå„Çä„Åæ„Åô„Åã ÂÖàÁîü„ÅØ„Å©„ÅÆ„Çà„ÅÜ„Å™„ÇÇ„ÅÆ„Åå„ÅäÂ•Ω„Åç„Åß„Åô„Åã ÊèêÊ°à„Åô„Çã ÊèêÂª∫ËÆÆÁöÑÊó∂ÂÄôÁî®„Å®„Åã‰∏çÊòØÂæà‰∏ÅÂÆÅÔºåÂ§âÊàê „Å™„Å© „Éì„Éº„É´„ÇíÂè¨„Åó‰∏ä„Åå„Çã„Å™„Çâ„ÄÅÈäÄÂ∫ß„Éõ„Éº„É´„Å™„Å©„ÅØ„ÅÑ„Åã„Åå„Åß„Åó„Çá„ÅÜ„Åã Êó•Êú¨ÊñáÂåñ‰ΩìÈ®ì„Å™„Çâ„ÄÅÈéåÂÄâ„ÅÆ„ÅäÂØ∫„ÅßÂ∫ßÁ¶Ö„Çí„Å™„Åï„Å£„Åü„Çâ„ÅÑ„Åã„Åå„Åß„Åó„Çá„ÅÜ„Åã „ÅîÂ≠òÁü•„Åß„Åô„Åã „Éº Â≠ò„Åò„Å¶„Åä„Çä„Åæ„ÅôÔºèÂ≠ò„Åò‰∏ä„Åí„Å¶„Åä„Çä„Åæ„Åô ÂØπ‰∫ãÁâ©ÁöÑËØùÁî®ÂâçËÄÖÔºåÂØπ‰∫∫ÁöÑËØùÁî®ÂêéËÄÖ „Ç¢„Çπ„ÇØÂïÜ‰∫ã„ÅÆÈ´òÊ©ãÈÉ®Èï∑„Çí„ÅîÂ≠òÁü•„Åß„Åô„Åã „Éº „ÅØ„ÅÑ„ÄÅÂ≠ò„Åò‰∏ä„Åí„Å¶„Åä„Çä„Åæ„ÅôÔºàÂõûÁ≠îÂà´‰∫∫ÈóÆËØùÁöÑÊó∂ÂÄôÔºâ „Åî„ÄúÔºàÊº¢Â≠óÔºâ„Åß„Åô ÂêåÊ†∑Ë°®ËææÂ∞äÊï¨ËØ≠ÁöÑÊÑèÊÄù ‰Ωï„Åã„ÅîÂøÉÈÖç„Åß„Åô„Åã ÊòéÊó•„ÅÆ‰ºöË≠∞„ÄÅ„ÅîÂá∫Â∏≠„Åß„Åô„Åã ÊºîËÆ≤ ÂèëË°®ÂºÄÂßãÁöÜ„Åæ„Åï„ÄÅ„Åä„ÅØ„Çà„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô„ÄÇÊú¨Êó•„ÅØ„ÄÅ„Äú„Å´„Å§„ÅÑ„Å¶„ÅäË©±„Åó„Åó„Åæ„Åô„ÄÇ ÂØπÊºîËÆ≤Êó∂ÁöÑËßÇ‰ºóËØ¥ËØùÂ∫îËØ•Áî®Êï¨ËØ≠Âú®ËøõÂÖ•ËØùÈ¢ò‰πãÂêéÔºåÊØîËµ∑Êï¨ËØ≠Êõ¥Â∫îËØ•Áî®desu masu „Åß„Åô„Åã„Çâ Ôºù „Å†„Åã„Çâ „ÅîÂ≠òÁü•„ÅÆ„Çà„ÅÜ„Å´Ôºè„ÅîÂ≠òÁü•„ÅÆÈÄö„Çä „Äú„Çâ„Çå„Å¶„Åä„Çä„Åæ„ÅôÔºàËÄÉ„Åà„ÇãÔºèË®Ä„ÅÜÔºèË©ï‰æ°„Åô„ÇãÔºâ ÁªìÊùü ‰ª•‰∏ä„ÄÅ„Äú„ÅÑ„Å§„ÅÑ„Å¶Á¥π‰ªã„ÅÑ„Åü„Åó„Åæ„Åó„Åü „ÅîÈùôËÅ¥„ÅÇ„Çä„Åå„Å©„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô Èù¢ËØï„Å¶„Åæ„ÅÑ„Çä„Åæ„Åó„ÅüÔºù„Å¶„Åè„Çã È´òÊ†°Áîü„ÅÆÊôÇÊó•Êú¨Ë™û„ÅÆÂãâÂº∑„Çí„Åó„Å¶„Åæ„ÅÑ„Çä„Åæ„Åó„Åü ÁßÅ„ÅØ„Åì„Çå„Åæ„Åß„ÄÅÈÄöË®≥„ÅÆ‰ªï‰∫ã„Å´Áî∞È∂¥„Çè„Å£„Å¶„Åæ„ÅÑ„Çä„Åæ„Åó„Åü „Äú„Å¶„Åä„Çä„Åæ„ÅôNÁßÅ„ÅåÁ†îÁ©∂„Åó„Å¶„Åä„Çä„Åæ„Åô„ÉÜ„Éº„Éû„ÅØ„ÄÅÊó•Êú¨Ë™û„ÅÆÊï¨Ë™û„Å´„Å§„ÅÑ„Å¶„Åß„Åô „ÄúÊ¨°Á¨¨„Åß„Åô Ôºù „Äú„Çì„Åß„Åô Âæ°Á§æ„ÅÆ„Éì„Ç∏„Éç„Çπ„ÅØ„ÄÅÁßÅ„ÅÆÁ†îÁ©∂„ÉÜ„Éº„Éû„Å®Èáç„Å™„Å£„Å¶„ÅÑ„Çã„Å®ÊÄù„ÅÑ„ÄÅÂ§ßÂ§âËààÂë≥Ê∑±„ÅèÊÑü„Åò„ÅüÊ¨°Á¨¨„Åß„Åô Êç¢ÁßçËØ¥Ê≥ï| „Äú„Å´„Å§„ÅÑ„Å¶Èù¢ÁôΩ„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åó„Åü | „Äú„Å´„Å§„ÅÑ„Å¶ËààÂë≥Ê∑±„ÅèÊÑü„Åò„Åæ„Åó„Åü || „Åô„Åî„ÅèÔºè„Å®„Å¶„ÇÇ | Â§ßÂ§âÔºèÈùûÂ∏∏„Å´ || „Å©„Çì„Å™ | „Å©„ÅÆ„Çà„ÅÜ„Å™ || „Äú„Åß„Åç„Åü„Çâ„ÅÑ„ÅÑ„Å™„Å®ËÄÉ„Åà„Å¶„ÅÑ„Åæ„Åô | „Äú„Åß„Åç„Åü„Çâ„Å®ËÄÉ„Åà„Å¶„Åä„Çä„Åæ„Åô || „Äú„Åè„Çå„Åü„Çâ„ÅÑ„ÅÑ„Å™„Å®ÊÄù„ÅÑ„Åæ„Åô | „Äú„Åè„Çå„Åü„Çâ„Å®ËÄÉ„Åà„Å¶„Åä„Çä„Åæ„Åô || „Äú„Åó„Åü„ÅÑ„Åß„Åô | „Äú„Åß„Åç„Åü„Çâ„Å®ÊÄù„ÅÑ„Åæ„Åô | Ëá™Â∑±Á¥π‰ªãÊú¨Êó•„ÅØÈù¢Êé•„ÅÆÊ©ü‰ºö„Çí„Åè„Å†„Åï„ÅÑ„Åæ„Åó„Å¶„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô„ÄÇÊó©ÈÄü„Åß„Åô„Åå„ÄÅËá™Â∑±Á¥π‰ªã„Çí„Åï„Åõ„Å¶„ÅÑ„Åü„Å†„Åç„Åæ„Åô„ÄÇÁßÅ„ÅØXX„Å®Áî≥„Åó„Åæ„Åô„ÄÇ2018Âπ¥Êù•Êó•„ÅÑ„Åü„Åó„Åæ„Åó„Å¶„ÄÅÁèæÂú®„ÄÅXXX„ÇíÁ†îÁ©∂„Åó„Å¶„Åä„Çä„Åæ„Åô„ÄÇ„Å©„ÅÜ„Åû„Çà„Çç„Åó„Åè„ÅäÈ°ò„ÅÑ„ÅÑ„Åü„Åó„Åæ„Åô„ÄÇ Ë¢´ÈóÆÂà∞ÈóÆÈ¢òË¶ÅÂÖàÂõûÁ≠î „ÅØ„ÅÑÔºå‰∏çË¶ÅÂä†ÈÇ£‰πàÂ§öÁäπË±´ËØç‰∏çË¶ÅÂ§™Â§öÁöÑÁî®„Åß„Åç„Åæ„Åô Â∞ë„Åó„Åß„ÇÇ„ÅäÂΩπ„Å´Á´ã„Å¶„Åü„Çâ„Å®ÊÄù„ÅÑ„Åæ„Åô ‰æãÁßÅ„ÅØ„Ç≤„Éº„É†„ÅÆ„Éó„É≠„Ç∞„É©„É†„ÅÆÈñãÁô∫„ÇíÁ∂ö„Åë„Å¶„Åæ„ÅÑ„Çä„Åæ„Åó„Åü„ÄÇÁßÅ„Åå‰Ωø„Å£„Å¶„Åä„Çä„Åæ„Åô„ÇΩ„Éï„Éà„ÅÆÈñãÁô∫„ÇíÂ§ö„ÅèÊâã„Åå„Åë„Å¶„ÅÑ„Çâ„Å£„Åó„ÇÉ„ÇãÂæ°Á§æ„ÅÆ‰∫ãÊ•≠ÂÜÖÂÆπ„Çí‰º∫„Å£„Å¶„ÄÅÈùûÂ∏∏„Å´ËààÂë≥Ê∑±„ÅèÊÑü„Åò„Åæ„Åó„Åü„ÄÇ„Åï„Çâ„Å´„Çà„ÇäËâØ„ÅÑ„Ç≤„Éº„É†„ÇΩ„Éï„Éà„ÇíÈñãÁô∫„Åß„Åç„Åü„Çâ„Å®ËÄÉ„Åà„Å¶„Åä„Çä„Åæ„Åô„ÄÇ Êé•ÁîµËØù„ÅØ„ÅÑ„ÄÅXXX„Åß„Åî„Åñ„ÅÑ„Åæ„Åô„ÅÑ„Å§„ÇÇ„Åä‰∏ñË©±„Å´„Å™„Å£„Å¶„Åä„Çä„Åæ„Åô „Åì„Å°„Çâ„Åì„Åù„ÄÅ„Åä‰∏ñË©±„Å´„Å™„Å£„Å¶„Åä„Çä„Åæ„Åô Ôºà‰ºöÁ§æÂêçÔºâ„ÅÆXX„Å®Áî≥„Åó„Åæ„Åô„Åå„ÄÅXXÊßòÔºèÂΩπËÅ∑„ÄÅ„ÅÑ„Çâ„Å£„Åó„ÇÉ„ÅÑ„Åæ„Åô„ÅãÂêçÂâç „ÅØ„Åü„Å†„ÅÑ„Åæ„ÄÅXX‰∏≠„Åß„Åî„Åñ„ÅÑ„Åæ„ÅôÂ∏∏Áî®ËØ≠ ‰∏çÂú®ÁöÑÊó∂ÂÄô XX„ÅØ„Åü„Å†„ÅÑ„ÅæÂ∏≠„ÇíÂ§ñ„Åó„Å¶„Åä„Çä„Åæ„Åó„Å¶„ÄÇ„ÄÇ„ÄÇ ËÆ©‰ªñ‰∏Ä‰ºöÂõûÁîµ Êäò„ÇäËøî„ÅóXX„Å´ÈõªË©±„Åï„Åõ„Åæ„Åó„Çá„ÅÜ Êé•Êî∂ÁïôË®Ä „Çà„Çç„Åó„Åë„Çå„Å∞„ÄÅÁßÅ„Åå„ÅîÁî®‰ª∂„ÇíÊâø„Çä„Åæ„Åô„Åå„ÄÇ„ÄÇ„ÄÇ ÊâøÁü•„ÅÑ„Åü„Åó„Åæ„Åó„Åü„ÄÇXXX„Å´Áî≥„Åó‰ºù„Åà„Åæ„Åô„ÄÇÁßÅ„ÄÅXX„ÅåÊâø„Çä„Åæ„Åó„Åü Á®çÂêéÂÜçÊã® ÊÅê„ÇåÂÖ•„Çä„Åæ„Åô„Åå„ÄÅXXÂàÜÈÅé„Åé„Å´„ÇÇ„ÅÜ‰∏ÄÂ∫¶„Åä„Åã„Åë„ÅÑ„Åü„Å†„Åë„Åæ„Åô„Åß„Åó„Çá„ÅÜ„Åã „Åù„Çå„Åß„ÅØ„ÄÅXXÂàÜÂæå„Å´„Åì„Å°„Çâ„Åã„Çâ„Åä„Åã„Åë„Åó„Åæ„Åô ÂÜç‰∏ÄÊ¨°ËØ∑ÊïôÂßìÂêç Â§±Á§º„Åß„Åô„Åå„ÄÅ„ÇÇ„ÅÜ‰∏ÄÂ∫¶„ÅäÂêçÂâç„Çí‰º∫„Å£„Å¶„ÇÇ„Çà„Çç„Åó„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã ÊåÇÁîµËØù „Åß„ÅØ„ÄÅÂ§±Á§º„ÅÑ„Åü„Åó„Åæ„Åô Êç¢‰∫∫Êé• „ÅäÈõªË©±„Åã„Çè„Çä„Åæ„Åó„Åü„ÄÇXX„Åß„Åô ÈááËÆø„Äú‰∏≠Ôºè„Å®„Åì„Çç„ÄÅ„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô „ÅäÂøô„Åó„ÅÑ‰∏≠Ôºè„ÅäÂØí„ÅÑ‰∏≠ÔºèÈõ®„ÅÆ‰∏≠„ÄÅ„Çè„Åñ„Çè„Åñ„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô „ÅäÊÄ•„Åé„ÅÆ„Å®„Åì„ÇçÔºè„ÅäÁñ≤„Çå„ÅÆ„Å®„Åì„ÇçÔºè„Åä‰ºë„Åø„ÅÆ„Å®„Åì„Çç„ÄÅÁî≥„ÅóË®≥„ÅÇ„Çä„Åæ„Åõ„Çì ÈáçÂ§çÂØπÊñπËØ¥ÁöÑËØùÊâ©Â±ïÂØπÊñπËØ¥ÁöÑËØùÊÉ≥Á°ÆËÆ§Êó∂ ‰ªä„ÄÅ‰Ωï„Å®„Åä„Å£„Åó„ÇÉ„ÅÑ„Åæ„Åó„Åü„Åß„Åó„Çá„ÅÜ„Åã„ÄÇÔºè„Å®„ÄÅ„Åä„Å£„Åó„ÇÉ„ÅÑ„Åæ„Åô„Å® „Åù„ÅÆ„Äú„Å®Ë®Ä„ÅÜ„ÅÆ„ÅØ„ÄÅ„Å©„ÅÆ„Çà„ÅÜ„Å™ÊÑèÂë≥„Åß„Åô„Åã Êä•ÂëäÊúâÈ°∫Â∫èÁöÑÊä•Âëä „Åæ„Åö„ÄÅXXX„Å´„Å§„ÅÑ„Å¶Â†±Âëä„Åó„Åæ„Åô ‰ª•‰∏ä„ÄÅÊ¶ÇË¶Å„ÅÑ„Å§„ÅÑ„Å¶„ÅîÂ†±Âëä„Åó„Åæ„Åó„Åü Ê¨°„Å´„ÄÅ „Åù„ÅÆÊ¨°„Å´Ôºè„Åù„Çå„Åã„Çâ ÊúÄÂæå„Å´ „Å®„ÅÆ„Åì„Å®„Åß„Åô Ôºù „Åù„ÅÜ„Åß„Åô ËΩ¨Ëø∞Âê¨Âà∞Âà´‰∫∫ÁöÑËØùËØ∑Áúã „Åì„Å®„Çâ„ÅÆÂÜôÁúü„Çí„ÅîË¶ß„Åè„Å†„Åï„ÅÑ „ÅîË¶ß„ÅÑ„Åü„Å†„Åè„Å®„ÅäÂàÜ„Åã„Çä„ÅÆ„Çà„ÅÜ„Å´„ÄÅ„ÄÇ„ÄÇ„ÄÇ ÂèëË°®ÊÑüÊÉ≥ „ÄÇ„ÄÇ„ÄÇ„Å®ÊÄù„ÅÑ„Åæ„Åô „ÄÇ„ÄÇ„ÄÇ„ÅÆ„Åß„ÅØ„Å™„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã „Åü Êñπ„Åå„ÅÑ„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô ÁªìÊùüÊä•Âëä ‰ª•‰∏ä„ÅßÂ†±Âëä„ÇíÁµÇ„Çè„Çä„Åæ„Åô ‰ª•‰∏ä„ÄÅXXX„Å´„Å§„ÅÑ„Å¶„ÅîÂ†±Âëä„Åó„Åæ„Åó„Åü ‰Ωï„ÅãË≥™Âïè„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÅãÔºè„ÅîË≥™Âïè„Åå„Åä„ÅÇ„Çä„Åß„Åó„Åü„Çâ„Å©„ÅÜ„Åû Âè∏‰ºöÁöÑÊï¨ËØ≠ËôΩÁÑ∂ÊòØÊúãÂèãÔºå‰ΩÜÊòØÂú®ÂæàÂ§ö‰∫∫Èù¢ÂâçËØ¥ÁöÑÊó∂ÂÄô‰πüË¶Å‰∏ÅÂÆÅ‰∏ÄÁÇπ„ÅäV„Åß„Åô Ôºù „ÅäV„Å´„Å™„Å£„Å¶„ÅÑ„Çâ„Å£„Åó„ÇÉ„ÅÑ„Åæ„Åô ÁöÜ„Åï„Çì„ÅäÊèÉ„ÅÑ„Åß„Åô„ÅÆ„Åß„ÄÅ ÁöÜ„Åï„Çì„ÅäË¶ã„Åà„Åß„Åô„ÅÆ„Åß„ÄÅ „Åù„Çç„Åù„ÇçÂßã„ÇÅ„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„ÅôÂ∏∏Áî®ËØ≠ Â§ß„Åç„Å™ÊãçÊâã„Åß„ÅäËøé„Åà„Åè„Å†„Åï„ÅÑ „Äú„Åï„Çì„ÅÆÂâçÈÄî„ÇíÁ•ù„Åó„Å¶Ôºè‰ªäÂæå„ÅÆ„ÅîÊ¥ªË∫ç„Å®„ÅîÂÅ•Â∫∑„ÇíÁ•à„Å£„Å¶„ÄÅ‰πæÊùØ„Çí„Åó„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô ‰πæÊùØ„ÅÆÈü≥È†≠„ÅØ„ÄúÂÖàÁîü„Å´„ÅäÈ°ò„ÅÑ„Åó„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô „ÅäÊâãÂÖÉ„ÅÆ„Ç∞„É©„Çπ„Çí„ÅäÊåÅ„Å°„Åè„Å†„Åï„ÅÑ „Åî„ÇÜ„Å£„Åè„Çä„ÅäÊ•Ω„Åó„Åø„Åè„Å†„Åï„ÅÑ „Åì„Åì„Åß‰∏ÄË®Ä„ÅîÊå®Êã∂Áî≥„Åó‰∏ä„Åí„Åæ„Åô „Åß„ÅØ„ÄÅ„Äú„Åï„Åæ„Å´„ÅäÁ•ù„ÅÑ„ÅÆ„Åì„Å®„Å∞„Çí„ÅÑ„Åü„Å†„Åç„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô „Åù„Çç„Åù„Çç„ÅäËÅû„Åç„Å´„Åó„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô ÈÇÆ‰ª∂ | Êå®Êã∂ | „ÅÑ„Å§„ÇÇ„Åä‰∏ñË©±„Å´„Å™„Å£„Å¶„Åä„Çä„Åæ„Åô | | „ÅäÁ§º | „É°„Éº„É´„ÄÅ„ÅÇ„Çä„Åå„Å©„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô | | Âßã„ÇÅ„Çã | „Åß„ÅØ„ÄÅXXX„ÅÆ‰ª∂„Åß„Åô„Åå | | Áü•„Çâ„Åõ„Çã | Ê¨°Âõû„ÅØÂÖàÁîü„Çí„ÅäËøé„Åà„Åó„Å¶‰∏ãË®ò„ÅÆÈÄö„Çä„ÅäÈ£ü‰∫ã„Çí„Åô„Çã„Åì„Å®„Å´„ÅÑ„Åü„Åó„Åæ„Åó„Åü | | „ÅäÈ°ò„ÅÑ | „ÅîÊ§úË®é„ÅÑ„Åü„Å†„Åç„Åæ„Åô„Çà„ÅÜ„ÅäÈ°ò„ÅÑ„ÅÑ„Åü„Åó„Åæ„ÅôÔºè„ÅäÁõÆÈÄö„Åó„Åè„Å†„Åï„ÅÑ„Åæ„Åô„Çà„ÅÜ„ÅäÈ°ò„ÅÑÁî≥„Åó‰∏ä„Åí„Åæ„Åô | | Ëá™ÂàÜ„ÅÆÂ∏åÊúõ | „ÅäÁõÆ„Å´„Åã„Åã„Çä„Åü„ÅÑ„Å®Â≠ò„Åò„Åæ„ÅôÔºè„ÇÜ„Å£„Åè„Çä„ÅäË©±„Çí‰º∫„ÅÑ„Åü„ÅÑ„Å®Â≠ò„Åò„Åæ„ÅôÔºè‰∏ÄÂ∫¶„Åä„ÅÑ„Åß„ÅÑ„Åü„Å†„Åë„Åü„Çâ„Å®Â≠ò„Åò„Åæ„Åô | | ÁµÇ„Çè„Çä | „ÅäÂæÖ„Å°„Åó„Å¶„Åä„Çä„Åæ„ÅôÔºè„Çà„Çç„Åó„Åè„ÅäÈ°ò„ÅÑ„ÅÑ„Åü„Åó„Åæ„ÅôÔºèÂèñ„ÇäÊÄ•„Åé„ÅäËøî‰∫ãÁî≥„Åó‰∏ä„Åí„Åæ„Åô | | „ÇÇ„Å®„ÇÅ„Çã | ‰ª•‰∏ä„ÄÅ„ÅîÊ°àÂÜÖÔºè„ÅîÊãõÂæÖ Áî≥„Åó‰∏ä„Åí„Åæ„Åô | | ‰ªò„ÅëÂä†„Åà„Çã | „Å™„Åä„ÄÅ | ‰∏Ä‰∫õ‰∏Ä‰∫õÁâπÂÆöËØ¥Ê≥ïÂÆ∂‰∫∫Áß∞Âëº Êàë ‰ªñ ÊôÆÈÄö ‰ªñ Êï¨ËØ≠ Áà∂ „Å°„Å° „ÅäÁà∂„Åï„Çì „ÅäÁà∂Êßò ÊØç „ÅØ„ÅØ „ÅäÊØç„Åï„Çì „ÅäÊØçÊßò ÂÖÑ „ÅÇ„Å´ „ÅäÂÖÑ„Åï„Çì „ÅäÂÖÑÊßò Âßâ „ÅÇ„Å≠ „ÅäÂßâ„Åï„Çì „ÅäÂßâÊßò Âºü „Åä„Å®„ÅÜ„Å® Âºü„Åï„Çì ÂºüÊßò Â¶π „ÅÑ„ÇÇ„ÅÜ„Å® Â¶π„Åï„Çì Â¶πÊßò Â§´Ôºà„Åä„Å£„Å®ÔºâÔºèÊó¶ÈÇ£Ôºè‰∏ª‰∫∫ „Åî‰∏ª‰∫∫ „Åî‰∏ª‰∫∫Êßò Â¶ªÔºà„Å§„ÅæÔºâÔºèÂÆ∂ÂÜÖÔºà„Åã„Å™„ÅÑÔºâ Â••„Åï„Çì Â••Êßò Â≠ê„Å©„ÇÇ „ÅäÂ≠ê„Åï„Çì „ÅäÂ≠êÊßò ÊÅØÂ≠ê ÊÅØÂ≠ê„Åï„Çì „ÅîÂ≠êÊÅØÔºà„Åó„Åù„ÅèÔºâ Â®ò Â®ò„Åï„Çì „ÅäÂ¨¢Êßò ‰∫∫Áß∞ „Åß„Åô„Åæ„Åô Êï¨Ë™û ÂèãÈÅî „Çè„Åü„Åó „Çè„Åü„Åè„Åó „Çè„Åü„ÅóÔºèÂÉïÔºè‰ø∫ „Çè„Åü„Åó„Åü„Å° „Çè„Åü„Åè„Åó„Åü„Å° „Çè„Åü„Åó„Åü„Å°ÔºèÂÉï„Åü„Å°Ôºè‰ø∫„Åü„Å° ÁöÜ„Åï„Çì ÁöÜÊßò „Åø„Çì„Å™ „ÅäÂÆ¢„Åï„Çì „ÅäÂÆ¢Êßò ÂÆ¢ Âèã‰∫∫ „ÅîÂèã‰∫∫ ÂèãÈÅî „ÅÇ„ÅÆ‰∫∫ „ÅÇ„ÅÆÊñπ „ÅÇ„ÅÑ„Å§ÔºèÂΩºÔºèÂΩºÂ•≥ „ÅäÂ∫ó„ÅÆ‰∫∫ „ÅäÂ∫ó„ÅÆÊñπ Â∫óÂì° ‰øÇ„ÅÆ‰∫∫ ‰øÇ„ÅÆÊñπ ‰øÇ ÈßÖÂì°„Åï„Çì ÈßÖÂì°„Åï„Çì ÈßÖÂì° „Ç¢„É°„É™„Ç´„ÅÆ‰∫∫ „Ç¢„É°„É™„Ç´„ÅÆÊñπ „Ç¢„É°„É™„Ç´‰∫∫ ÂÖ¨Âè∏Ôºå‰∫∫ÂëòÔºåÂ≠¶Ê†°Á≠â Ëá™Â∑±ÁöÑ ‰ªñ‰∫∫ÁöÑ ÂºäÁ§æÔºà„Å∏„ÅÑ„Åó„ÇÉÔºâ„ÅÆXXXÔºè„ÅÜ„Å°„ÅÆXXX XXXÔºãËÅå‰Ωç ÂºäÁ§æÔºèÊàë„ÅåÁ§æÔºèÂΩìÁ§æ Âæ°Á§æÔºà„Åä„Çì„Åó„ÇÉÔºâÔºèË≤¥Á§æÔºà„Åç„Åó„ÇÉÔºâ Êú¨Ê†°ÔºèÂΩìÊ†° Âæ°Ê†°ÔºèË≤¥Ê†° Êú¨Â≠¶ÔºàÁâπÊåáÂ§ßÂ≠¶Ôºâ Âæ°Â≠¶ÔºèË≤¥Â≠¶ Â∏∏Áî® „ÅäÔºè„Åî ËØç Âä®ËØç „Åä „ÅäÈõªË©±„Åó„Åæ„Åô „ÅäÁ¥ÑÊùü„Åó„Åæ„Åô „ÅäÊåÅ„Å°„Åó„Åæ„Åô „Åî Â†±Âëä Á¥π‰ªã ÈÅ†ÊÖÆ ÂΩ¢ÂÆπËØç „Åä „ÅäÂ•Ω„ÅçÔºè„ÅäÂ´å„ÅÑ „ÅäÂÖÉÊ∞óÔºè„ÅäÁñ≤„ÇåÔºè„ÅäÊÄ•„Åé „Åî „ÅîÂÅ•Â∫∑Ôºè„ÅîÁÑ°ÁêÜ „ÅîÊ∫ÄË∂≥Ôºè„Åî‰∏çÂø´ ÂêçËØç „Åä „ÅäÈõªË©±Ôºè„ÅäÂÜôÁúü „ÅäËøî‰∫ãÔºè„ÅäÈ£ü‰∫ã „ÅäÊâãÁ¥ôÔºè„ÅäËç∑Áâ©Ôºè„ÅäÊåÅ„Å°Áâ© „ÅäÂêçÂâçÔºè„ÅäÊ∞óÊåÅ„Å° „ÅäÈáëÔºè„ÅäÁ§ºÔºè„ÅäÂúüÁî£ „ÅäÂºÅÂΩìÔºè„ÅäÈ¢®ÂëÇ „ÅäÈ£≤„ÅøÁâ©Ôºè„ÅäÂìÅÁâ© „ÅäÊâãÊ¥ó„ÅÑ „ÅäË¶ãËàû„ÅÑÔºè„ÅäÁ•à„ÇäÔºè„ÅäÁ•ù„ÅÑ „Åî „ÅîÂÆ∂ÊóèÔºè„ÅîÂ§´Â©¶Ôºè„ÅîÈï∑Áî∑ „Åî‰ΩèÊâÄÔºè„ÅîÂç∞ÈëëÔºè„Åî‰∫àÁÆóÔºè„ÅîÊÑèÂøóÔºè„ÅîÊú¨ „ÅîÁΩ≤ÂêçÔºè„ÅîÊ≥®ÊñáÔºè„ÅîË®àÁîª „Åî‰∫àÁ¥ÑÔºè„ÅîÊãõÂæÖ „ÅîÂá∫Â∏≠Ôºè„ÅîÂèÇÂä†Ôºè„ÅîÁôªÈå≤Ôºè„ÅîÂÖ•Èáë „ÅîÂÖ•Â≠¶Ôºè„ÅîÂá∫Áô∫ „ÅîÁµêÂ©öÔºè„ÅîÈñ¢‰øÇ Êó•Â≠êÁöÑËØ¥Ê≥ï ÊôÆÈÄö Êï¨ËØ≠ ‰ªäÊó• Êú¨Êó• Êò®Êó• Êò®Êó• „Åï„Åè„Åò„Å§ „ÅÇ„Åó„Åü „ÅÇ„ÅôÔºè„Åø„Çá„ÅÜ„Å´„Å° „Åä„Å®„Å®„ÅÑ „ÅÑ„Å£„Åï„Åè„Åò„Å§ „ÅÇ„Åï„Å£„Å¶ „Åø„Çá„ÅÜ„Åî„Å´„Å° ‰ªäÂπ¥ Êú¨Âπ¥ ÂéªÂπ¥ Êò®Âπ¥Ôºà„Åï„Åè„Å≠„ÇìÔºâ „Åä„Å®„Å®„Åó ‰∏ÄÊò®Âπ¥ „ÅÑ„Å£„Åï„Åè„Å≠„Çì 1„É∂Êúà „Å≤„Å®Êúà ÂâØËØçÁöÑËΩ¨Êç¢ ÊôÆÈÄö Êï¨ËØ≠ „ÅÑ„Åæ „Åü„Å†„ÅÑ„Åæ „Åï„Å£„Åç ÂÖà„Åª„Å© Âæå„Åß Âæå„Åª„Å©Ôºà„ÅÆ„Å°„Åª„Å©Ôºâ „Åì„ÅÆÈñì ÂÖàÊó• „Åù„ÅÆÊó• ÂΩìÊó• „ÇÇ„ÅÜ„Åô„Åê Èñì„ÇÇ„Å™„Åè Ëµ∂Á¥ßÂºÄÂßã „Åï„Å£„Åù„Åè ÊÄ•„ÅÑ„Å¶Ôºè„Åô„Åê„Å´ Êó©ÊÄ•„Å´Ôºà„Åï„Å£„Åç„ÇÖ„ÅÜÔºâÔºèËá≥ÊÄ•Ôºà„Åó„Åç„ÇÖ„ÅÜÔºâ „Åô„Åê„Å´ „Åü„Å†„Å°„Å´ Ââç„Å´ „ÅÇ„Çâ„Åã„Åò„ÇÅ „Äú„Åü„Çâ„Åô„Åê„Å´ „ÄúÊ¨°Á¨¨„ÄÅ ÊÆãÂøµ „ÅÇ„ÅÑ„Å´„Åè „Åú„Å≤ ‰∏ÅÂØß„Å´ ‰∏ÅÈáç„Å´ „Å†„ÅÑ„Åü„ÅÑ Ê¶Ç„Å≠Ôºà„Åä„Åä„ÇÄ„Å≠Ôºâ Â∞ë„Åó Â∞ë„ÄÖÔºà„Åó„Çá„ÅÜ„Åó„Çá„ÅÜÔºâ Âä®ËØçÁöÑËΩ¨Êç¢ ÊôÆÈÄö Êï¨ËØ≠ Áî®Ê≥ï Âèó„ÅëÂèñ„ÇãÔºè„ÇÇ„Çâ„ÅÜ ÂèóÈ†ò„Åô„Çã ÈÖçÈÄÅÁâ© Âèó„ÅëÂèñ„ÇãÔºè„ÇÇ„Çâ„ÅÜ ÊãùÂèó„Åô„Çã ÈÖçÈÄÅ ÈÇÆ‰ª∂ ‰ø° ÊüªÂèé„Åô„Çã Á°ÆËÆ§ÂÜÖÂÆπ‰πãÂêéÊü•Êî∂ÔºåËá™Â∑±‰∏çÁî® Á¥ç„ÇÅ„Çã Ëµ†ÂìÅÔºåË¥µÈáçÁâ©ÂìÅÁ≠â Èáë„ÇíÊâï„ÅÜ Á¥ç„ÇÅ„Çã Á®éÈáë ÈÄÅ„Çã ÈÄÅ‰ªò„Åô„Çã ÈÇÆÂØÑÂìÅÔºåÈÇÆ‰ª∂ Áô∫ÈÄÅ„Åô„Çã ÈÖçËææÁâ© ÂÖ•Èáë„Åô„Çã Èì∂Ë°åÊ±áÊ¨æ Êç∫Âç∞„Åô„Çã ÁõñÁ´† ‰Ωø„ÅÜ ‰ΩøÁî®„Åô„Çã Áâ©ÂìÅ Âà©Áî®„Åô„Çã Áâ©ÂìÅÔºåÊúçÂä° „Åª„Åó„ÅÑÔºè„Åó„Åü„ÅÑ Â∏åÊúõ„Åô„Çã Â£≤„Çã Ë≤©Â£≤„Åô„Çã Â£≤„ÇäÂá∫„Åô Áô∫Â£≤„Åô„Çã Ë≤∑„ÅÜ Ë≥ºÂÖ•„Åô„Çã Ê±Ç„ÇÅ„ÇãÔºà„ÇÇ„Å®„ÇÅ„ÇãÔºâ Ë™≠„ÇÄ ÊãùË™≠„Åô„Çã ÈÇÆ‰ª∂Ôºå‰ø° ËÅû„Åè ÊãùËÅ¥„Åô„Çã ÊÑèËßÅÔºåÊºîËÆ≤ Êõ∏„Åè Ë®òÂÖ•„Åô„Çã Áî≥ËØ∑Áî®Á∫∏ Êõ∏„Åè Ë®ò„ÅôÔºà„Åó„Çã„ÅôÔºâ Áü•„Çâ„Åõ„Çã ÈÄöÁü•„Åô„Çã È†º„ÇÄ ‰æùÈ†º„Åô„Çã Âèó„Åë„Çã Êâø„Çã ËÄÉ„Åà„Çã Ê§úË®é„Åô„Çã „Çè„Åã„Çã ÊâøÁü•„Åô„ÇãÔºèÁêÜËß£„Åô„ÇãÔºè‰∫ÜÊâø„Åô„Çã „ÅÇ„Åç„Çâ„ÇÅ„Çã Êñ≠Âøµ„Åô„Çã Âøò„Çå„Çã Â§±Âøµ„Åô„Çã Â∏∞ÂõΩ„Åô„Çã Âá∫Á§æ„Åô„ÇãÔºèÂá∫Âã§„Åô„Çã Êù•Ëá™Â∑±ÁöÑÂÖ¨Âè∏ ÈÄÄÁ§æ„Åô„ÇãÔºèÈÄÄÂã§„Åô„Çã ‰∏ãÁè≠ÂõûÂÆ∂ Â§±Á§º„Åô„Çã Â∏∞ÂÆÖ„Åô„Çã ÈÄÄÁ§æÔºèÈÄÄËÅ∑„Åô„Çã ËæûËÅå ÈñãÂ∫ó„Åô„Çã ÈñâÂ∫ó„Åô„Çã Êù•Â∫ó„Åô„Çã Êù•Â†¥„Åô„Çã Â∫ß„Çã „Åã„Åë„Çã]]></content>
      <categories>
        <category>Êó•ËØ≠</category>
        <category>Êï¨ËØ≠</category>
      </categories>
      <tags>
        <tag>Êï¨ËØ≠</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êï∞ÊçÆÁªìÊûÑ‰πãTree]]></title>
    <url>%2F2019%2F09%2F14%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84Tree%2F</url>
    <content type="text"><![CDATA[Âü∫Êú¨‰ΩúÁî® Ê†ëÊòØÂõæÁöÑ‰∏ÄÁßçÔºå‰ΩÜÊòØ‰∏çÊòØÈ¶ñÂ∞æËøûÂú®‰∏ÄËµ∑ÁöÑ Ê†ëÁöÑÂÖ∂‰∏≠‰∏ÄÁ±ªÊòØ‰ªé self-balanced tree BSTÊºîÂèòÂá∫Êù•ÁöÑÔºåÂåÖÊã¨Á∫¢ÈªëÊ†ëÔºåAVLÔºåSplayÔºåTreapÁ≠âÁ≠âÔºàÁªèÂ∏∏Âú®Èù¢ËØïÂá∫Áé∞‰ΩÜÊòØÂÆûÈôÖ‰∏çÂ∏∏Áî®Ôºâ Âè¶‰∏ÄÁßçÂ§ßÁ±ªÊòØ TrieÔºàÂ≠óÂÖ∏Ê†ëÔºâÔºåËÉΩ‰øùËØÅÂ≠óÂÖ∏ÊéíÂ∫è„ÄÇÂâçÁºÄÊêúÁ¥¢ÔºåÊ≠£ÂàôÂåπÈÖçÔºåÊï∞ÊçÆÂéãÁº©ÔºåÊûÑÂª∫Á¥¢ÂºïÁ≠âÁ≠âÁî®Â§Ñ ‰∫åÂèâÊ†ëÔºåÊúÄÂü∫Á°ÄÁöÑÁªìÊûÑÂÆö‰πâ ÊØè‰∏™Êï∞ÁöÑËäÇÁÇπÊúÄÂ§öÂè™Êúâ‰∏§‰∏™Â≠êËäÇÁÇπ Â≠êËäÇÁÇπÂàÜÂ∑¶Âè≥ÔºåÂøÖÈ°ª‰∏çËÉΩÈ¢†ÂÄí Â∫îÁî®ÁéØÂ¢É hashË°®Ôºåsets Êï∞ÊçÆÂ∫ìÔºå‰ºòÂÖàÈòüÂàó LDAPÊü•Êâæ‰ø°ÊÅØÔºåÂú®XML/HTML‰∏≠ËøõË°åÊêúÁ¥¢ ‰∏çÂêåÂàÜÊîØÔºö full binary treeÔºöÈô§‰∫ÜÂè∂ËäÇÁÇπÔºà‰πüÂ∞±ÊòØ‰∏Ä‰∏™Â≠êËäÇÁÇπÈÉΩÊ≤°ÊúâÁöÑÁÇπÔºâÔºåÂÖ∂‰ªñÁöÑÈÉΩÊúâ‰∏§‰∏™Â≠êËäÇÁÇπ complete binary treeÔºöÈô§‰∫ÜÊúÄÂêé‰∏ÄÂ±ÇÂ§ñÔºåÂÖ∂‰ªñÂ±ÇÁöÑËäÇÁÇπÈÉΩÊúâ‰∏§‰∏™Â≠êËäÇÁÇπÔºåÊúÄÂêé‰∏ÄÂ±ÇÁöÑÂ≠êËäÇÁÇπÂøÖÈ°ªÊòØÂ∑¶ÂØπÈΩê perfect binary treeÔºöÂΩ¢ÊàêÂÆåÁæéÁöÑ‰∏âËßíÂΩ¢ BST ‰∫åÂèâÊêúÁ¥¢Ê†ëÂÆö‰πâ ‰∏§‰∏™Â≠êËäÇÁÇπÈáåÈù¢ÔºåÂ∑¶ËæπÁöÑÂøÖÈ°ªÂ∞è‰∫éÁà∂ËäÇÁÇπÔºåÂè≥ËæπÁöÑÂøÖÈ°ªÂ§ß‰∫éÁà∂ËäÇÁÇπ Êìç‰Ωú ÊèíÂÖ•Ôºö Â¶ÇÊûúÊ≤°Êúâ‰ªª‰ΩïÁÇπÔºå‰Ωú‰∏∫root Â¶ÇÊûúÂ§ßÊîæÂà∞Âè≥ËæπÁöÑÂ≠êÊ†ëÔºåÂ∞èÊîæÂà∞Â∑¶ËæπÁöÑÂ≠êÊ†ë ÈáçÂ§ç2Áõ¥Âà∞ÊâæÂà∞Á©∫‰Ωç Âà†Èô§Ôºö Âà†Èô§Âè∂ËäÇÁÇπÔºöÊñ≠ÊéâËøô‰∏™ÁÇπÂíåÁà∂ËäÇÁÇπÁöÑËÅîÁ≥ª Âà†Èô§Âè™Êúâ‰∏Ä‰∏™Â≠êËäÇÁÇπÁöÑÁÇπÔºöÊääÁà∂ËäÇÁÇπÂØπÂæÖÂà†Èô§ÁÇπÁöÑreferenceÊîπ‰∏∫Áà∂ËäÇÁÇπÂØπÂæÖÂà†Èô§ÁÇπÂ≠êËäÇÁÇπÁöÑreference ‰∏§‰∏™Â≠êËäÇÁÇπÁöÑÁÇπÔºöÂ∑¶ËäÇÁÇπ‰∏çÂä®ÔºåÂè≥ËæπÁöÑÊç¢Âà∞Áà∂ËäÇÁÇπÁöÑ‰ΩçÁΩÆ‰∏ä/Âè≥ËäÇÁÇπ‰∏çÂêåÔºåÂ∑¶ËäÇÁÇπÊç¢Âà∞Áà∂ËäÇÁÇπ Âà†Èô§rootÔºöÈúÄË¶ÅÊõ¥ÊîπÂØπrootÁöÑreference ÈÅçÂéÜ È°∫Â∫èÔºöÂ∑¶-&gt; ‰∏≠ -&gt; Âè≥ ÂèçÂ∫èÔºöÂ∑¶ -&gt; Âè≥ -&gt; ‰∏≠ DFSÔºö‰∏≠ -&gt; Â∑¶ -&gt; Âè≥ Âπ≥Ë°°‰∫åÂèâÊ†ë AVLÊ†ë Â∑¶Âè≥‰∏§‰∏™Â≠êÊ†ëÁöÑÈ´òÂ∫¶Â∑Æ‰∏çË∂ÖËøá1 ‰∏îÂ≠êÊ†ëÊú¨Ë∫´‰πüÊòØÂπ≥Ë°°Ê†ë Âú®ÊûÑÂª∫Âπ≥Ë°°Ê†ëÁöÑÊó∂ÂÄôÁ°Æ‰øù‰ªñ‰ª¨Âπ≥Ë°°Ôºå‰ªéËÄåÂØºËá¥ÊúÄÂ∑ÆÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶‰πüÊòØ logN ËôΩÁÑ∂Âú®ÊèíÂÖ•ÊàñËÄÖÂà†Èô§ÁöÑÊó∂ÂÄôÔºåÂèØËÉΩ‰ºöÂú®ÊóãËΩ¨‰∏äËä±Ë¥πÊó∂Èó¥Ôºå‰ΩÜÊòØÊï¥‰ΩìÊÄßËÉΩÊõ¥Âä†Á®≥ÂÆö ÊóãËΩ¨ ÂØπ‰∫éÈúÄË¶ÅÊóãËΩ¨ÁöÑÊÉÖÂÜµÊù•ËØ¥Ôºå‰∏ÄÂÖ±ÊúâÂõõÁßçÂü∫Êú¨Áä∂ÂÜµ ÂØπ‰∫éÂ∑¶Â∑¶ÊàñËÄÖÂè≥Âè≥Ôºö‰ΩÜÊóãËΩ¨ ÂØπ‰∫éÂ∑¶Âè≥ÊàñËÄÖÂè≥Â∑¶ÔºöÂèåÊóãËΩ¨ Á∫¢ÈªëÊ†ë ËäÇÁÇπÊòØÁ∫¢Ëâ≤ÊàñÈªëËâ≤ Âè∂ËäÇÁÇπÈÉΩÊòØÈªëËâ≤ÁöÑ rootÊòØÈªëËâ≤ÁöÑ ÊØè‰∏™Á∫¢ËäÇÁÇπÂøÖÈ°ªÊúâ‰∏§‰∏™ÈªëÂ≠êËäÇÁÇπÔºå‰πüÂ∞±ÊòØËØ¥‰∏çËÉΩË∑ØÂæÑ‰∏äÊúâ‰∏§‰∏™ËøûÁª≠ÁöÑÁ∫¢Ëâ≤ ‰ªé‰ªª‰∏ÄËäÇÁÇπÂà∞ÂÖ∂ÊØè‰∏™Âè∂Â≠êÁöÑÊâÄÊúâÁÆÄÂçïË∑ØÂæÑÈÉΩÂåÖÂê´Áõ∏ÂêåÊï∞ÁõÆÁöÑÈªëËâ≤ËäÇÁÇπ BÊ†ëÂÆö‰πâ Áî®Êù•Â§ÑÁêÜÊéíÂ∫èÂêéÁöÑÊï∞ÊçÆÔºåÊü•ÊâæÔºåÊèíÂÖ•ÔºåÂà†Èô§ÔºåÂæ™Â∫èÂ≠òÂèñÈÉΩÂú®ÂØπÊï∞Êó∂Èó¥ÂÆåÊàê ÂØπ‰∫éÊôÆÈÄöÁöÑ‰∫åÂèâÊ†ëÔºåÂèØ‰ª•ÊúâÂ§ö‰∫é‰∏§‰∏™ÁöÑËäÇÁÇπ ‰ºòÂåñÂ§ßÂùóÊï∞ÊçÆÁöÑËØªÂÜôÊìç‰ΩúÔºåÂä†Âø´Â≠òÂèñÈÄüÂ∫¶ Âú®ÊûÑÂª∫ÁöÑÊó∂ÂÄôÔºåÊØè‰∏Ä‰∏™ÁÇπÁöÑÂ≠òÂÇ®Êï∞ÈáèÊòØÊúâÈôêÁöÑÔºåË∂ÖËøá‰∏äÈôêÁöÑÊó∂ÂÄôÔºåÊú¨ËäÇÁÇπÂàÜÂà´Êàê‰∏âÈÉ®ÂàÜÔºå‰∏Ä‰∏™ÂæÄ‰∏äÁßªÂä®ÔºåÂè¶Â§ñ‰∏§‰∏™ÂàÜÂºÄB+Ê†ë Âè™ÊúâËææÂà∞Âè∂ËäÇÁÇπÊâçÁÆóÂëΩ‰∏≠ÔºåBÊ†ëÂèØ‰ª•Âú®ÈùûÂè∂ÂëΩ‰∏≠ Êõ¥ÈÄÇÂêàÊñá‰ª∂Á¥¢ÂºïÁ≥ªÁªü B * Ê†ë ËäÇÁÇπÂà©Áî®Áéá‰ªé 1/2ÂèòÊàê‰∫Ü 2/3 TrieÊ†ë Â≠óÂÖ∏Ê†ë hashÊ†ëÁöÑÂèòÁßçÔºå‰øùÂ≠òÂ§ßÈáèÂ≠óÁ¨¶‰∏≤ Âà©Áî®ÂÖ¨ÂÖ±ÂâçÁºÄÂáèÂ∞ëÊü•ÊâæÊó∂Èó¥ ÁâπÁÇπ Ê†πËäÇÁÇπ‰∏çÂåÖÊã¨Â≠óÁ¨¶ÔºåÈô§‰∫ÜÊ†πËäÇÁÇπÈÉΩÂè™ÂåÖÂê´‰∏Ä‰∏™Â≠óÁ¨¶ ‰ªéÊ†πËäÇÁÇπÂà∞Êüê‰∏ÄËäÇÁÇπÔºå‰∏ÄË∑ØËøûËøáÂéªÂ∞±ÊòØÁõ∏ÂÖ≥ÁöÑÂ≠óÁ¨¶‰∏≤ ÊØè‰∏™ËäÇÁÇπÁöÑÂ≠êËäÇÁÇπÁöÑÂ≠óÁ¨¶ÈÉΩ‰∏çÁõ∏Âêå ÂèÇËÄÉÊù•Ê∫ê [Data Structure] Êï∞ÊçÆÁªìÊûÑ‰∏≠ÂêÑÁßçÊ†ë ÂàùÂ≠¶ËÄÖÂ∫îËØ•‰∫ÜËß£ÁöÑÊï∞ÊçÆÁªìÊûÑÔºö Tree]]></content>
      <categories>
        <category>Êï∞ÊçÆÁªìÊûÑ</category>
        <category>Ê†ë</category>
      </categories>
      <tags>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UnityÁöÑshader]]></title>
    <url>%2F2019%2F09%2F14%2FUnity%E7%9A%84shader%2F</url>
    <content type="text"><![CDATA[ÂèÇËÄÉÊù•Ê∫êËøôÈáå ÂÆö‰πâ shaderÔºåÁùÄËâ≤Âô®ÔºåÊòØ‰∏ÄÊÆµË¥üË¥£Â∞ÜËæìÂÖ•ÁöÑmeshÁî®ÊåáÂÆöÁöÑÊñπÂºèÂíåËæìÂÖ•ÁöÑË¥¥ÂõæÔºåÈ¢úËâ≤Á≠â‰ΩúÁî®ÔºåÁÑ∂ÂêéËæìÂá∫ ËæìÂÖ•Ë¥¥ÂõæÊàñËÄÖÈ¢úËâ≤Ôºå‰ª•ÂèäÂØπÂ∫îÁöÑshaderÔºåÂ∞±ÂèØ‰ª•ÂæóÂà∞‰∏Ä‰∏™materialÔºåÁÑ∂ÂêéÂ∞ÜÂèØ‰ª•ÊääÊùêÊñôÁªôÂà∞rendererÊù•ËøõË°åËæìÂá∫ shaderÂ¶ÇÊûúÊòØËá™Â∑±Êù•ÂÜôÁöÑËØùÔºåÈúÄË¶ÅÊñ∞ÂàõÂª∫‰∏Ä‰∏™shaderÊñá‰ª∂ ÊØîÂ¶ÇÂú®ËøôÈáåËÄÅÂ∏àÂÜôÁöÑomniProcamÁöÑÊäïÂΩ±ÁöÑshaderÔºåÈáåÈù¢ÁöÑÂèÇÊï∞Â∞±ÂåÖÊã¨‰∫ÜfisheyeÁõ∏Êú∫ÁöÑÂèÇÊï∞Á≠âÁ≠â„ÄÇËøôÈÉ®ÂàÜÁöÑÂèÇÊï∞‰πüÂ∞±ÊòØshaderÁöÑËæìÂÖ•ÔºåÂÆö‰πâ‰∫ÜËøô‰∏™shaderÈúÄË¶ÅÁöÑÂ±ûÊÄß ÈúÄË¶ÅÂú®ÈáåÈù¢ËÆæÂÆö‰∏çÂêåÁöÑsubshaderÔºåËøôÈÉ®ÂàÜÊòØ‰ª£Á†ÅÁöÑ‰∏ªÈ¢òÔºåÂú®ÊØè‰∏Ä‰∏™ÈáåÈù¢ÂåÖÂê´‰∏çÂêåÁöÑpass„ÄÇÁÑ∂ÂêéËøêË°åÁöÑÊó∂ÂÄô‰ºö‰ªéÊúÄ‰ºòÂÖàÁöÑÁùÄËâ≤Âô®ÂºÄÂßãÊâæ„ÄÇÂú®shaderÁöÑÊúÄÂêéÈúÄË¶Å‰∏Ä‰∏™fallbackÔºå‰πüÂ∞±ÊòØËØ¥ÊâÄÊúâÁöÑsubshaderÈÉΩ‰∏çËÉΩËøêË°åÁöÑÊó∂ÂÄôÔºåÈúÄË¶Å‰∏Ä‰∏™ËøîÂõûÊÉÖÂÜµ ‰ª£Á†ÅËÆ≤Ëß£1234567891011121314151617181920212223242526Shader &quot;Custom/Diffuse Texture&quot; &#123; Properties &#123; _MainTex (&quot;Base (RGB)&quot;, 2D) = &quot;white&quot; &#123;&#125; &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 200 CGPROGRAM #pragma surface surf Lambert sampler2D _MainTex; struct Input &#123; float2 uv_MainTex; &#125;; void surf (Input IN, inout SurfaceOutput o) &#123; half4 c = tex2D (_MainTex, IN.uv_MainTex); o.Albedo = c.rgb; o.Alpha = c.a; &#125; ENDCG &#125; FallBack &quot;Diffuse&quot;&#125; Â±ûÊÄß PropertiesÈáåÈù¢ÂÆö‰πâ‰∫ÜËøô‰∏™shaderÁöÑÂ±ûÊÄßÔºåËøôÈáåÈù¢ÁöÑÊâÄÊúâÂ±ûÊÄßÂ∞Ü‰Ωú‰∏∫inputÊèê‰æõÁªôÂ≠êÁùÄËâ≤Âô® _Name(&quot;Display Name&quot;, type) = defaultValue[{options}] Ê†ºÂºè _Â±ûÊÄßÂêç ‚Äúdisplay name‚Äù ÊòæÁ§∫ÁªôÁî®Êà∑ÁöÑÂèØËØªÁöÑÂêçÂ≠ó typeÂ±ûÊÄßÁöÑÁ±ªÂûã È¢úËâ≤ÔºåRGBA 2DÔºå2ÁöÑÊåáÊï∞Â§ßÂ∞èÁöÑË¥¥Âõæ rectÔºåÈùû2ÁöÑÊåáÊï∞Â§ßÂ∞èÁöÑË¥¥Âõæ cubeÔºåÁ´ãÊñπ‰ΩìÁ∫πÁêÜ rangeÔºå‰∏Ä‰∏™ËåÉÂõ¥ÈáåÈù¢ÁöÑÊï∞ floatÔºå‰ªªÊÑè‰∏Ä‰∏™ÊµÆÁÇπÊï∞ Â±ûÊÄßÁöÑÈªòËÆ§ÂÄºÔºåÊØîÂ¶ÇÈ¢úËâ≤ÂèØ‰ª•ËÆæÂÆöÊàê‚Äúwhite‚Äù opinionÈ°πÔºåËá≥Â∞ëÈúÄË¶ÅÂú®Ë¥¥ÂõæÂêéÈù¢Âä†‰∏äÁ©∫ÁôΩÁöÑËä±Êã¨Âè∑ÔºåÂè™Âíå2d rectÊàñËÄÖcubeÊúâÂÖ≥Á≥ª subshader tagÔºöÊØîÂ¶ÇÊ∏≤ÊüìÁ±ªÂûãÔºåÂ¶ÇÊûúÊòØÈùûÈÄèÊòéÁöÑÁâ©‰ΩìË¶ÅÂÜôÂú®opaqueÈáåÈù¢ÔºåÈÄèÊòéÁöÑÂÜôÂú®transparentÈáåÈù¢ LODÔºölevel of detail CGPROGRAMÔºåÂºÄÂßãÁöÑÊ†áËÆ∞Ôºå‰ªéËøôÈáåÂºÄÂßãÊòØ‰∏ÄÊÆµCGÁ®ãÂ∫è„ÄÇÂíåÊúÄÂêéÁöÑENDCGÊòØÂØπÂ∫îÁöÑ #pragma surface surf Lambert‰∏Ä‰∏™ÁºñËØëÊåá‰ª§ÔºåÂ£∞Êòé‰∫ÜË¶ÅÂÜô‰∏Ä‰∏™Ë°®Èù¢ÁöÑshaderÔºåÊåáÂÆö‰∫ÜÂÖâÁÖßÊ®°Âûã sampler2DÂØπË¥¥ÂõæËøõË°åÊìç‰ΩúÔºå2dÁöÑË¥¥ÂõæÊ®°Âûã„ÄÇËôΩÁÑ∂Âú®‰πãÂâçÁöÑÂ±ûÊÄßÈáåÈù¢Â£∞ÊòéËøá‰∏ÄÊ¨°Ôºå‰ΩÜÊòØÂõ†‰∏∫ËøôÈáåÈù¢ÊòØcg‰ª£Á†ÅÔºåËøòÊòØÈúÄË¶ÅÈáçÊñ∞Â£∞Êòé‰∏ÄÊ¨° ÈúÄË¶ÅÂú®structÈáåÈù¢ÂÆö‰πâÂá∫Êù•ÈúÄË¶ÅËæìÂÖ•ÂíåËæìÂá∫ÁöÑÊï∞ÊçÆÁ±ªÂûã uvÔºöuv mappingÊåáÁöÑÂ∞±ÊòØÊää‰∏Ä‰∏™2dË¥¥Âõæ‰∏äÈù¢ÁöÑÁÇπÊåâÁÖß‰∏ÄÂÆöËßÑÂàôÊò†Â∞ÑÂà∞3dÊ®°Âûã‰∏ä„ÄÇÂ¶ÇÊûúÂú®Ë¥¥ÂõæÂèòÈáèÂâçËæπÂä†‰∏äuv.uv_MainTexÊåáÁöÑÂ∞±ÊòØÊèêÂèñËøô‰∏™ÂèòÈáèÁöÑuvÂÄºÔºå‰πüÂ∞±ÊòØËØ¥‰∫åÁª¥ÂùêÊ†á surfÂáΩÊï∞ÔºåsurfÊòØ‰πãÂâçÂÆö‰πâÁöÑÂÖâÁÖßÊ®°ÂûãÔºåÊúâ‰∏§‰∏™ÂèÇÊï∞ InÈáåÈù¢ÁöÑÂÜÖÂÆπÊòØuvÂÄºÔºå‰πüÂ∞±ÊòØËØ¥ÊØèÊ¨°ÈÉΩ‰ºöË∞ÉÁî®Ë¥¥Âõæ‰∏äÈù¢ÁöÑÂùêÊ†áÁÇπÊâçËÆ°ÁÆóËæìÂá∫ inoutÊòØËæìÂá∫ÂÄº]]></content>
      <categories>
        <category>Unity</category>
        <category>ÂÖ•Èó®</category>
      </categories>
      <tags>
        <tag>shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂçÅÂ§ßÁªèÂÖ∏ÊéíÂ∫è]]></title>
    <url>%2F2019%2F09%2F03%2F%E5%8D%81%E5%A4%A7%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[ÂèÇËÄÉÂá∫Ëá™Ôºö‰∫îÂàÜÈíüÂ≠¶ÁÆóÊ≥ï Êó∂Èó¥Â§çÊùÇÂ∫¶ ÊúÄÂ•ΩÊÉÖÂÜµ ÊúÄÂùèÊÉÖÂÜµ Á©∫Èó¥Â§çÊùÇÂ∫¶: ÈúÄ‰∏çÈúÄË¶ÅÂºÄËæüÊñ∞ÁöÑÁ©∫Èó¥ ÊéíÂ∫èÊñπÂºèÔºöin-placeËøòÊòØ‰∏çÊòØin - place ÊéíÂ∫èÁ®≥ÂÆöÊÄß: ‰πüÂ∞±ÊòØ‰πãÂâçÈ°∫Â∫èÁöÑ‰∏úË•øÂú®ÊéíÂ∫è‰πãÂêéÊòØÂê¶ËøòÈ°∫Â∫è ÂÜíÊ≥°ÊéíÂ∫è ÂâçÈù¢‰∏Ä‰∏™Êï∞ÂíåÂêéÈù¢‰∏Ä‰∏™ÊØîÔºåÂ¶ÇÊûúÂâçÈù¢ÁöÑÊï∞ÊØîÂêéÈù¢ÁöÑÂ§ß(ÊàñËÄÖÂ∞è)ÔºåÂ∞±‰∫§Êç¢‰ªñ‰ª¨‰∏§‰∏™ ËøôÊ†∑‰∫§Êç¢‰∏ÄÊ¨°‰πãÂêéÁöÑÊúÄÂêé‰∏Ä‰∏™Êï∞Â∞±ÊòØÊâÄÊúâÊï∞Â≠óÈáåÈù¢ÁöÑÊúÄÂ§ßÊï∞ ‰πüÂ∞±Áõ∏ÂΩì‰∫éÊúÄÂ§ßÁöÑÊï∞ÂÉèÂÜíÊ≥°‰∏ÄÊ†∑ÂÜíÂá∫Êù•‰∫ÜÔºåÁ¨¨‰∏ÄËΩÆËøáÂêéÔºåÁ¨¨‰∫åËΩÆÂèØ‰ª•Áõ¥Êé•ÂÜíÂÄíÊï∞Á¨¨‰∫å‰∏™Êï∞Ôºå‰πüÂ∞±ÊòØËØ¥ÊØè‰∏ÄËΩÆÁöÑÂÜÖÂæ™ÁéØÊ¨°Êï∞ÂèØ‰ª•ÈÄêÊ∏êÂáèÂ∞ë ÈúÄË¶ÅÈáçÂ§çnÊ¨°Ôºà‰ΩÜÊòØÊØèÊ¨°ÂØπË∂äÊù•Ë∂äÂ∞ëÁöÑÊï∞Â≠óËøõË°å‰∏äËø∞Êìç‰ΩúÔºâÔºå‰ª•Á°Æ‰øùÊâÄÊúâÁöÑ‰∫§Êç¢ÈÉΩÂ∑≤ÁªèÂÆåÊØï‰∫Ü„ÄÇ Â¢ûÂä†‰∫Ü‰∏Ä‰∏™flagÁöÑÂà§Êñ≠ÔºåÂ¶ÇÊûúÂú®‰∏ÄËΩÆÈáåÈù¢Ê≤°Êúâ‰ªª‰Ωï‰∫§Êç¢‰∫ßÁîüÔºåÈÇ£Â∞±ËØ¥ÊòéÊâÄÊúâÁöÑÂÖÉÁ¥†ÈÉΩÂ∑≤ÁªèÊéíÂ∫èÂÆåÊØï‰∫ÜÔºàÂõ†‰∏∫Â¶ÇÊûúËøòÊúâÊï∞Â≠óÂæÄ‰∏äÂÜíÂøÖÁÑ∂‰ºöÂú®ÂâçÈù¢Êúâ‰∫§Êç¢ ËøôÊ†∑Â¶ÇÊûúÊòØÊ≠£Â∫èÊéíÂàóÁöÑËØùÔºåÂèØ‰ª•Áõ¥Êé•Ë∑≥Âá∫Âæ™ÁéØÔºå‰∏çÁî®ËøõË°åÊØîËæÉÔºåÊó∂Èó¥Â§çÊùÇÂ∫¶ÊòØn123456789101112131415def bubbleSort(num): n = len(num) for j in range(1, n): flag = True # Â¶ÇÊûúÂú®ËøôËΩÆÊ≤°Êúâ‰ªª‰Ωï‰∫§Êç¢ÔºåÂ∞±ÂèØ‰ª•ËØ¥ÊòéÊéíÂ∫èÂ∑≤ÁªèÂÆåÊàê‰∫Ü for i in range(n - j): if num[i] &gt; num[i + 1]: temp = num[i] num[i] = num[i + 1] num[i + 1] = temp flag = False if flag is True: break return num Êó∂Èó¥Â§çÊùÇÂ∫¶Ôºö ÂΩìÊ≠£Â∫èÊéíÂàóÁöÑÊó∂ÂÄôÔºåÂõ†‰∏∫ÂèØ‰ª•Áõ¥Êé•Ë∑≥Âá∫Âæ™ÁéØÔºåÊâÄ‰ª•Âè™ÈúÄË¶ÅÈÅçÂéÜ‰∏ÄÊ¨°ÊâÄÊúâÁöÑÊï∞‰øùËØÅ‰ªñ‰ª¨ÊéíÂàóÊ≠£Â∏∏ÔºåÊâÄ‰ª•Êó∂Èó¥Â§çÊùÇÂ∫¶ÊòØn ÂΩìÂÄíÂ∫èÊéíÂàóÁöÑÊó∂ÂÄôÔºåÈúÄË¶ÅÊääÊâÄÊúâÈÉΩÁßªÂä®‰∏ÄÈÅçÔºåÊâÄ‰ª•Êó∂Èó¥Â§çÊùÇÂ∫¶ÊòØ n ^ 2 Âπ≥ÂùáÁöÑÂ§çÊùÇÂ∫¶ÊòØnÊñπ Á©∫Èó¥Â§çÊùÇÂ∫¶Ôºö Âõ†‰∏∫‰∫§Êç¢Âè™ÈúÄË¶Å‰∏Ä‰∏™È¢ùÂ§ñÁöÑtempÊù•ÂÇ®Â≠ò‰∏¥Êó∂ÂèòÈáèÔºåÁ©∫Èó¥Â§çÊùÇÂ∫¶ÊòØ1 in-placeÔºöÊòØÁöÑ Á®≥ÂÆöÊÄßÔºöÁ®≥ÂÆöÔºåÂõ†‰∏∫‰∏ÄÊ¨°Êç¢ËøáÊù•ÁöÑ‰∏úË•øÂ∞±‰∏çÂä®‰∫ÜÔºåÂú®Âà§Êñ≠Â§ßÂ∞èÁöÑÊó∂ÂÄô‰πüÊòØÂà§Êñ≠ÁöÑÂ§ß‰∫éËÄå‰∏çÊòØÂ§ß‰∫éÁ≠â‰∫éÔºå‰πüÂ∞±ÊòØËØ¥ÂâçÈù¢Êç¢Âà∞ÂêéÈù¢ÁöÑÂ§ßÊï∞Ê∞∏Ëøú‰ºöÂú®ÂêéÈù¢ÁöÑÊï∞ÁöÑÂâçÈù¢ ÊØîÂ¶Ç[0, 8, 1, 8, 2]„ÄÇÈ¶ñÂÖà‰ºöÊääÁ¨¨‰∏Ä‰∏™8Êç¢Âà∞Á¨¨‰∫å‰∏™8ÁöÑÂâçÈù¢ÔºåÂõ†‰∏∫Âà§Êñ≠Êù°‰ª∂Ê≤°ÊúâÁ≠â‰∫éÔºåÊâÄ‰ª•Ë∂ä‰∏çËøáÂéª„ÄÇ ÈÄâÊã©ÊéíÂ∫è ‰ªéÊâÄÊúâÂÖÉÁ¥†‰∏≠ÊâæÂà∞ÊúÄÂ∞èÔºàÊàñËÄÖÊúÄÂ§ßÔºâÂÖÉÁ¥†ÔºåÁÑ∂ÂêéÊîæÂà∞Êï∞ÁªÑÁöÑÁ¨¨‰∏Ä‰∏™Ôºà‰πüÂ∞±ÊòØÂíåÊï∞ÁªÑÁöÑÁ¨¨‰∏Ä‰∏™‰∫§Êç¢‰ΩçÁΩÆÔºâÔºåÁÑ∂ÂêéËøô‰∏™Â∞±ÁÆóÊòØÂõ∫ÂÆö‰Ωè‰∫Ü ÁÑ∂Âêé‰ªéÁ¨¨‰∫å‰∏™Âà∞ÊúÄÂêé‰∏Ä‰∏™‰∏≠ÈÄâÊã©Áé∞Âú®ÊúÄÂ∞èÁöÑÔºåÂíåÊï∞ÁªÑÁöÑÁ¨¨‰∫å‰∏™‰∫§Êç¢‰ΩçÁΩÆÔºåÂâç‰∏§‰∏™Â∞±Âõ∫ÂÆö‰Ωè‰∫Ü ‰ª•Ê≠§Á±ªÊé® 12345678910111213141516def SelectSort(nums): n = len(nums) for i in range(n): Min = float("inf") index = None for j in range(i, n): if nums[j] &lt; Min: Min = nums[j] index = j if index != i: # ËøôÊ†∑ÂèØ‰ª•ÂáèÂ∞ë‰∏Ä‰∫õÊ†πÊú¨‰∏çÁî®‰∫§Êç¢ÁöÑÊÉÖÂÜµÔºå‰∏ã‰∏Ä‰∏™‰ΩçÁΩÆ‰∏äÊú¨Êù•Â∞±ÊòØÊúÄÂ∞èÁöÑ temp = nums[i] nums[i] = nums[index] nums[index] = temp return nums Êó∂Èó¥Â§çÊùÇÂ∫¶Ôºö ÊúÄÂ•ΩÊÉÖÂÜµÂíåÊúÄÂùèÊÉÖÂÜµÈÉΩ‰∏çËÉΩÈÅøÂÖçËµ∞‰∏§‰∏™Âæ™ÁéØÔºåÈÉΩÊòØn ^ 2 Á©∫Èó¥Â§çÊùÇÂ∫¶: 1, Êù•ÂÇ®Â≠òtempÁöÑÂÄºÂíåÊöÇÊó∂ÁöÑÊúÄÂ§ßÂÄºÁöÑÂèòÈáè in-placeÔºöÊòØÁöÑÔºåÊç¢‰ΩçÁΩÆÂ∞±ÂèØ‰ª•Ôºå‰∏çÈúÄË¶ÅÂçïÊãøÂá∫Êù• Á®≥ÂÆöÔºö ‰∏çÁ®≥ÂÆöÔºåÂõ†‰∏∫Âú®‰∫§Êç¢‰ΩçÁΩÆÁöÑÊó∂ÂÄôÔºåÂπ∂‰∏çÁü•ÈÅìÁé∞Âú®ÁöÑ‰∏úË•øË¢´‰∫§Êç¢Âà∞Âì™ÈáåÂéª‰∫Ü ÊØîÂ¶ÇÔºö[3, 3, 0, 9]ÔºåÂΩì0Âíå3‰∫§Êç¢‰ΩçÁΩÆÁöÑÊó∂ÂÄôÔºåÊääÁ¨¨‰∏Ä‰∏™3‰∫§Êç¢Âà∞Á¨¨‰∫å‰∏™3ÂêéÈù¢Âéª‰∫Ü ÊèíÂÖ•ÊéíÂ∫è Âú®Á¨¨1ËΩÆÔºåËÆ§‰∏∫Á¨¨1‰∏™Â∑≤ÁªèÊéíÂ•ΩÂ∫è‰∫ÜÔºåÁÑ∂Âêé‰ªéÁ¨¨‰∫å‰∏™ÂºÄÂßãÊãøÂá∫Êù•ÔºåÊääÂÆÉÊîæÂú®ÊéíÂ•ΩÂ∫èÁöÑÈáåÈù¢ÁöÑÂêàÈÄÇÁöÑ‰ΩçÁΩÆ‰∏ä ‰ªéÁ¨¨‰∫åËΩÆÂºÄÂßã‰æùÊ¨°Á±ªÊé®ÔºåÊâÄ‰ª•ËøòÊòØ‰∏§‰∏™Âæ™ÁéØ Âú®Á¨¨iËΩÆÈáåÈù¢ÔºåÂâçi‰∏™ÂÖÉÁ¥†Â∑≤ÁªèÊòØÊéíÂ•ΩÂ∫èÁöÑ‰∫Ü Âú®ÊèíÂÖ•ÁöÑËøáÁ®ãÂΩì‰∏≠ÔºåÈúÄË¶ÅËÄÉËôëÂ¶ÇÊûúÊääÊâÄÊúâÁöÑÈúÄË¶ÅÁßªÂä®ÁöÑÊï∞Â≠óÁöÑÂùêÊ†áÈÉΩÁßªÂä®‰∏Ä‰Ωç„ÄÇËøôÊó∂ÂÄôÊØîËæÉÊúâÊïàÁöÑËÄÉËôëÊñπÊ≥ïÊòØ‰ªéÊúÄÂè≥ËæπÂºÄÂßãÂæÄÂ∑¶ËæπÁßªÂä®ÔºåÂè™Ë¶ÅÂè≥ËæπÁöÑÊï∞ÊØîÁé∞Âú®ÁöÑtempË¶ÅÂ§ßÔºåËøô‰∏Ä‰ΩçÔºàÂÆûÈôÖ‰∏äËøô‰∏Ä‰ΩçÊåáÁöÑÊòØj - 1ÔºåÂõ†‰∏∫jÊòØÁßªÂä®‰πãÂêéÁöÑÂùêÊ†áÔºâÂ∞±ÈúÄË¶ÅÁßªÂä®„ÄÇÁßªÂä®‰πãÂêéÂÜçÂáè1 Âú®ÊâÄÊúâÁöÑÈÉΩÁßªÂä®ÁªìÊùü‰πãÂêéÔºåÂ¶ÇÊûújËøô‰∏™‰ΩçÁΩÆÂíåiÁöÑ‰ΩçÁΩÆ‰∏ç‰∏ÄÊ†∑ÔºåÂ∞±ËØ¥ÊòéÂèëÁîü‰∫ÜÊèíÂÖ•ÔºåÈÇ£‰πàÂ∞±ÊòØnums[j] = Ë¢´ÊèíÂÖ•ÁöÑÊï∞Â≠ótemp 12345678910111213def InsertSort(nums): n = len(nums) for i in range(1, n): temp = nums[i] j = i while j &gt; 0 and temp &lt; nums[j - 1]: nums[j] = nums[j - 1] j -= 1 if j != i: nums[j] = temp return nums Êó∂Èó¥Â§çÊùÇÂ∫¶ ÊúÄÂ•ΩÁöÑÊó∂ÂÄôÔºå‰∏çÈúÄË¶ÅÊèíÂÖ•ÔºåÊúÄÂ§ßÂÄºÁõ¥Êé•ÊîæÂú®‰∫ÜÂâçÈù¢ÊéíÂ•ΩÂ∫èÁöÑÊúÄÂè≥ËæπÔºå‰πüÂ∞±ÊòØÊ≤°ÊúâÂÜÖÂæ™ÁéØÔºån ÊúÄÂ∑ÆÁöÑÊó∂ÂÄôÔºåÂèçÂ∫èÔºåÈúÄË¶ÅÂÖ®ÈÉΩÂæ™ÁéØ‰∏ÄÈÅç n2 Á©∫Èó¥Â§çÊùÇÂ∫¶ 1 in-place Á®≥ÂÆöÊÄßÔºöÁ®≥ÂÆöÔºåÂõ†‰∏∫Â¶ÇÊûúÊòØ[2, 0, 0, 1]ÔºåÁ¨¨‰∏Ä‰∏™0ÂÖàÊèíÂÖ•ÂèòÊàê‰∫Ü[0_1, 2, 0_2, 1]ÔºåÁÑ∂ÂêéÊèíÂÖ•Á¨¨‰∫å‰∏™0ÁöÑÊó∂ÂÄôÂõ†‰∏∫ÊØîËæÉÁöÑÊó∂ÂÄôÊ≤°ÊúâÊØîÁ≠â‰∫éÔºåÊâÄ‰ª•‰ºöÂèòÊàê[0_1, 0_2, 2, 1] Â∏åÂ∞îÊéíÂ∫è ÈÄâÊã©‰∏Ä‰∏™Â∫èÂàóÊù•ÂØπËøô‰∏™Êï∞ÁªÑËøõË°åÊéíÂ∫èÔºåÊØîÂ¶ÇÂ¶ÇÊûúÊòØ10‰∏™Êï∞ÔºåÂèØ‰ª•ÊòØ5 2 1ËøôÊ†∑ÁöÑÔºåÊúÄÂêé‰∏Ä‰∏™‰∏ÄÂÆöÊòØ1ÔºàËÆæÂÆöÁöÑÂÖ¨ÂºèÊòØ3xn + 1‰∏çÁü•ÈÅì‰∏∫‰ªÄ‰πàÔºâ ÁÑ∂ÂêéÊ†πÊçÆËøô‰∏™Â∫èÂàóÊääÊï∞ÁªÑÂàÜÊàêËøô‰∏™Â∫èÂàó‰∏™Êï∞ÁöÑÁªÑÔºåÂØπÊØèÁªÑÁöÑÊï∞Â≠óËøõË°åÊèíÂÖ•ÊéíÂ∫è„ÄÇÊØîÂ¶ÇÁî®5ÂàÜÊàê‰∏§‰ªΩÔºåÈÇ£Â∞±Ë¶ÅËøõË°å5Ê¨°Ôºå‰∏§‰∏™‰πãÈó¥ÁöÑÊéíÂ∫è ‰∏ÄÂÖ±ËøõË°åÁöÑÊéíÂ∫èÊ¨°Êï∞ÊòØÂíåÂ∫èÂàóÁöÑ‰∏™Êï∞ÊúâÂÖ≥ÁöÑ 123456789101112131415161718def ShellSort(nums): n = len(nums) gap = 1 while gap &lt; n / 3: gap = gap * 3 + 1 # ‰∏Ä‰∏™Á•ûÂ•áÁöÑÈÄâÊã©ÊñπÊ≥ïÔºå‰πü‰∏çÁü•ÈÅì‰∏∫‰ªÄ‰πà‰ΩÜÊòØÁ°ÆÂÆûÂæàÂ•ΩÁî® while gap &gt; 0: for i in range(gap, n): # ËøôÈáåÊâßË°åÁöÑÊòØÊèíÂÖ•ÊéíÂ∫èÔºåÂíå‰∏äÈù¢ÁöÑÊèíÂÖ•ÊéíÂ∫è‰∏ÄÊ†∑ÔºåÂè™‰∏çËøáÊØèÊ¨°Ë∑≥gap‰∏™‰∫Ü temp = nums[i] j = i while j &gt; 0 and temp &lt; nums[j - gap]: nums[j] = nums[j - gap] j -= gap if j != i: nums[j] = temp # Áõ¥Êé•intÂ∞±ÂèØ‰ª•Âêë‰∏ãÂèñÊï¥ÔºåÂõ†‰∏∫Âä†1Âπ∂‰∏çÂΩ±ÂìçÂèñÊï¥ÊïàÊûú gap = int(gap / 3) return nums ÂÖ≥‰∫éÂ¢ûÈáèÔºå‰∏çÂêåÁöÑÂ¢ûÈáèÂØπÊó∂Èó¥Â§çÊùÇÂ∫¶Êúâ‰∏çÂêåÁöÑÂΩ±Âìç ÁõÆÂâçÂ∫îÁî®ÊúÄÂ§öÁöÑÊòØ KnuthÂ¢ûÈáè:1,4,13,40,‚Ä¶,(3^k - 1)/2Ôºå‰πüÂ∞±ÊòØ‰ª£Á†ÅÈáåÈù¢ÁöÑËøô‰∏™Â¢ûÈáè ËøôÊó∂ÂÄôÁöÑÂ§çÊùÇÂ∫¶ÊòØ N^Ôºà3/2Ôºâ Êó∂Èó¥Â§çÊùÇÂ∫¶Ôºö Ê†πÊçÆ‰∏çÂêåÁöÑÊ≠•Èïø‰∏çÂêåËÄåÊúâÊâÄÂ∑ÆÂà´ÔºåËøòÊúâÁöÑÊ≠•ÈïøËøòÊ≤°ËÆ°ÁÆóÂá∫Êù•Â§çÊùÇÂ∫¶ Â¶ÇÊûúÊòØÂéüÁâàÁöÑÔºå‰πüÂ∞±ÊòØÂéüÈïøÂ∫¶‰∏ÄÁõ¥Èô§2ÁöÑËØù ÊúÄÂ•ΩÊïàÊûúÔºönÔºå‰πüÂ∞±ÊòØ‰∏çÈúÄË¶ÅÂÜÖÂæ™ÁéØ ÊúÄÁÉÇÊïàÊûúÔºön^2 Á©∫Èó¥Â§çÊùÇÂ∫¶ 1 in-place ‰∏çÁ®≥ÂÆöÔºåÂõ†‰∏∫ÂæàÊúâÂèØËÉΩÂõ†‰∏∫ÂàÜÁªÑÁöÑ‰∏çÂêåÊää‰∏§‰∏™Êï∞ÁöÑÈ°∫Â∫èÈ¢†ÂÄíÔºåÊØîÂ¶Ç‰∏§ÁªÑÁöÑÂêéÈù¢ÈÉΩÊòØ3Ôºå‰ΩÜÊòØÁ¨¨‰∏ÄÁªÑÁöÑÂâç‰∏Ä‰∏™ÊòØ2ÔºåÁ¨¨‰∫åÁªÑÁöÑÂâç‰∏Ä‰∏™ÊòØ4ÔºåËøôÊ†∑Â∞±ÊääÁ¨¨‰∫å‰∏™3Êç¢Âà∞ÂâçÈù¢Âéª‰∫Ü ÂΩíÂπ∂ÊéíÂ∫è ÂΩíÂπ∂ÊéíÂ∫èÊòØÂàÜÊ≤ªÊ≥ïÁöÑ‰∏Ä‰∏™ÂÖ∏ÂûãÁöÑÂ∫îÁî®ÔºåÂèØ‰ª•ÊääÊúâÂ∫èÁöÑÂ≠êÂàóÂêàÂπ∂ÔºåÁÑ∂ÂêéÂæóÂà∞Êñ∞ÁöÑÊúâÂ∫èÁöÑÂ≠êÂàó ÊØîËæÉÊñπÊ≥ï È¶ñÂÖàÊØîËæÉ‰∏§‰∏™Â≠êÂàóÁöÑÂàùÂßãÂÄºa[i]Âíåb[j]ÔºåÊääÊØîËæÉÂ∞èÁöÑÈÇ£‰∏™ÔºàÊØîÂ¶ÇiÔºâÊîæËøõÊñ∞ÁöÑlist[k]ÈáåÈù¢ÔºåÂπ∂‰∏îËÆ©iÂíåkÂàÜÂà´Âä†‰∏ÄÔºåÁÑ∂ÂêéÁªßÁª≠ÊØîËæÉiÂíåjÔºåÁÑ∂ÂêéÁªìÊûúÊîæËøõkÈáå„ÄÇ Â¶ÇÊûúÊúâ‰∏Ä‰∏™Â≠êÂàóÂ∑≤ÁªèÂèñÂÆå‰∫ÜÔºåÈÇ£‰πàÂèØ‰ª•Áõ¥Êé•ÊääÂè¶‰∏Ä‰∏™ÈáåÈù¢ÁöÑÂâ©‰ΩôÂÖÉÁ¥†Â§çÂà∂Âà∞Êñ∞ÁöÑlistÁöÑÊúÄÂêé Âõ†‰∏∫Áé∞Âú®‰ΩøÁî®ÁöÑÂ≠êÂàóÂ∑≤ÁªèÊòØÊéíÂ•ΩÂ∫èÁöÑ‰∫ÜÔºåÊâÄ‰ª•ÂèØ‰ª•‰ΩøÁî®ËøôÁßçÊØîËæÉÊñπÊ≥ï„ÄÇÂàùÂßãÁä∂ÊÄÅËÆ§‰∏∫ÊØè‰∏Ä‰∏™Êï∞Â≠óÈÉΩÊòØ‰∏Ä‰∏™ÂçïÁã¨ÁöÑÂ≠êÂàóÔºåÊâÄ‰ª•ÂæÄ‰∏äÂêàÂπ∂ÁöÑÊó∂ÂÄôÈÉΩÊòØÊúâÂ∫èÁöÑ‰∫Ü ÂÆûÁé∞Ôºö Áî≥ËØ∑‰∏Ä‰∏™Êñ∞ÁöÑÁ©∫Èó¥ÔºåÂ§ßÂ∞èÊòØ‰∏§‰∏™Â≠êÂàóÁöÑÂ§ßÂ∞è‰πãÂíå ‰∏§‰∏™ÊåáÈíàÂàÜÂà´‰ªéÂàùÂßã‰ΩçÁΩÆÂºÄÂßã Ê†πÊçÆ‰∏äÈù¢ÁöÑÊñπÊ≥ïÁßªÂä®ÊåáÈíà Âú®ÂÆûÁé∞ÁöÑËøáÁ®ã‰∏≠ÈúÄË¶ÅÁî®Âà∞ÊãÜÂàÜÂíåÂêàÂπ∂‰∏§‰∏™Ê≠•È™§ 12345678910111213141516171819202122def MergeSort(nums): n = len(nums) if n &lt; 2: return nums middle = int(n / 2) L, R = nums[:middle], nums[middle:] return merge(MergeSort(L), MergeSort(R))def merge(L, R): M = [] i, j = 0, 0 while L and R: if L[0] &lt;= R[0]: M.append(L.pop(0)) else: M.append(R.pop(0)) while L: M.append(L.pop(0)) while R: M.append(R.pop(0)) return M Âú®pythonÂÆûÁé∞‰∏≠ÔºåÂÖ∂ÂÆûÂπ∂‰∏çÈúÄË¶ÅÁî®ÂùêÊ†áË°®Á§∫ÔºåÂèØ‰ª•Áõ¥Êé•Áî®popÊääÊØèÊ¨°ÈúÄË¶ÅÂèñÁöÑ‰∏úË•øÂèñÂá∫Êù• Êó∂Èó¥Â§çÊùÇÂ∫¶ Êó†ËÆ∫ÊúÄÂ•ΩÊàñËÄÖÊúÄÂùèÁöÑÊÉÖÂÜµÈÉΩÈúÄË¶ÅÊääÊâÄÊúâ‰∏úË•øÈÉΩÊØîËæÉ‰∏ÄÂõûÔºå‰∏ÄÂÖ±ÊòØlognÂ±ÇÔºåÊØèÂ±ÇÁöÑÂÆûÈôÖÂÜÖÂÆπÈÉΩÊòØn‰∏™ÔºåÊâÄ‰ª•ÊúÄÁªàÁöÑÂ§çÊùÇÂ∫¶ÊòØnlog(n)„ÄÇËøôÊ†∑ÁúãÂá∫Êù•ÂΩíÂπ∂ÊéíÂ∫èÂØπ‰∫éÊúÄÂ•ΩÂíåÊúÄÂùèÁöÑÊÉÖÂÜµÊØîËæÉÁ®≥ÂÆö Á©∫Èó¥Â§çÊùÇÂ∫¶Ôºö ‰∏¥Êó∂Êï∞ÁªÑÁöÑÊó∂Èó¥n + recursiveÁöÑÊó∂ÂÄôÁöÑÁ©∫Èó¥logn = O(n) out of place Á®≥ÂÆöÊÄßÔºöÁ®≥ÂÆöÔºåÂõ†‰∏∫Âú®Â∑¶ËæπÁöÑ‰∏ÄÂÆöÊòØÂú®Â∑¶Ëæπ Âø´ÈÄüÊéíÂ∫è ÈÄâÂèñÊï∞ÁªÑÁöÑÁ¨¨‰∏Ä‰∏™‰Ωú‰∏∫Ê†áÂáÜÔºåÁÑ∂ÂêéÊääÊØîËøô‰∏™Ê†áÂáÜÂ∞èÁöÑÈÉΩÊîæÂú®Â∑¶ËæπÔºåÊØîÊ†áÂáÜÂ§ßÁöÑÈÉΩÊîæÂú®Âè≥Ëæπ ÁÑ∂ÂêéÂÜçÂàÜÂà´ÂØπÂ∑¶Âè≥ËøõË°åÂø´ÈÄüÊéíÂ∫è Ê≥®ÊÑèÔºåÂú®‰∏çÊòØpythonÁöÑÊÉÖÂÜµ‰∏ãÔºåÈúÄË¶ÅÈÄöËøáËßíÊ†á‰∫íÊç¢ÁöÑÊñπÊ≥ïÂæóÂà∞ÁªìÊûú ÂÆûÁé∞ ÈÄâÊã©‰∏Ä‰∏™Âü∫ÂáÜpiv Êï∞ÂàóÊúÄÂ∑¶ËæπÁöÑÊ†áËÆ∞‰∏∫Â∑¶Ê†áËÆ∞ÔºåÊúÄÂè≥ËæπÁöÑÊ†áËÆ∞ÊòØÂè≥Ê†áËÆ∞ Â∞ÜÂ∑¶Ê†áËÆ∞ÂêëÂè≥Ê†áËÆ∞ÁßªÂä® Â¶ÇÊûúÂ∑¶Ê†áËÆ∞ÁöÑÂÄºË∂ÖËøá‰∫ÜpivÁöÑÂÄºÔºåÂÅúÊ≠¢ ÁßªÂä®Âè≥Ê†áËÆ∞ ÂΩìÂè≥Ê†áËÆ∞Â∞è‰∫épivÁöÑÊó∂ÂÄôÔºåÂÅúÊ≠¢ÁßªÂä® ÂΩìÂ∑¶Âè≥Ê†áËÆ∞ÈÉΩÂÅúÊ≠¢ÁöÑÊó∂ÂÄôÔºå‰∫§Êç¢‰∏§‰∏™Êï∞Â≠ó ÁÑ∂ÂêéÁªßÁª≠ÁßªÂä®ÔºåÁõ¥Âà∞‰∏§‰∏™Ê†áËÆ∞Á¢∞Âà∞‰∏ÄËµ∑ÔºåËøôÊó∂ÂÄôÊääËøô‰∏™ÂÄºÂíåpiv‰∫§Êç¢ 12345678910111213141516def QuickSort(nums, s, e): if s &lt; e: i, j = s, e piv = nums[i] index = i while i &lt; j: while (i &lt; j) and nums[j] &gt;= piv: j -= 1 while (i &lt; j) and nums[i] &lt;= piv: i += 1 nums[i], nums[j] = nums[j], nums[i] nums[i], nums[index] = piv, nums[i] QuickSort(nums, s, i - 1) QuickSort(nums, j + 1, e) return nums 123456789101112131415161718def QuickSort_1(nums): n = len(nums) if n &lt; 2: return nums temp = nums[0] less, more, equal = [], [], [temp] for i in nums[1:]: if i &lt; temp: less.append(i) elif i &gt; temp: more.append(i) elif i == temp: equal.append(i) # less = [x for x in nums[1:] if x &lt; temp] # more = [x for x in nums[1:] if x &gt; temp] # equal = [x for x in nums if x == temp] return QuickSort(less) + equal + QuickSort(more) 1234567891011121314def QuickSort_3(nums): if len(nums) &lt; 2: return nums i, j = 0, len(nums) - 1 piv = nums[i] index = i while i &lt; j: while (i &lt; j) and nums[j] &gt;= piv: j -= 1 while (i &lt; j) and nums[i] &lt;= piv: i += 1 nums[i], nums[j] = nums[j], nums[i] nums[i], nums[index] = piv, nums[i] return QuickSort_3(nums[:i]) + [piv] + QuickSort_3(nums[i + 1:]) Á¨¨‰∏ÄÁßçÊñπÊ≥ïinputÁöÑÊó∂ÂÄôÈúÄË¶ÅÁ°ÆÂÆöÊúÄÂºÄÂßãÂíåÁªìÊùüÊó∂ÂÄôÁöÑindex„ÄÇÁúãËµ∑Êù•Âè™ÊúâÁ¨¨‰∏ÄÁßçÊñπÊ≥ïÊòØin-placeÁöÑÂÆûÁé∞Ôºü Êó∂Èó¥Â§çÊùÇÂ∫¶Ôºö ÊúÄÂ∑ÆÁöÑÊó∂ÂÄôÂíåÂÜíÊ≥°ÊéíÂ∫èÊòØ‰∏ÄÊ†∑ÁöÑÔºà‰πüÂ∞±ÊòØÊéíÂ•ΩÁöÑÔºâÔºåËøôÊó∂ÂÄôÁöÑÂ§çÊùÇÂ∫¶ÊòØn^2 ÊúÄÂ•ΩÁöÑÊó∂ÂÄôÊòØÂÆåÂÖ®Âπ≥ÂàÜÔºåËøôÊó∂ÂÄôÊòØ nlogn Á©∫Èó¥Â§çÊùÇÂ∫¶ÔºöÂ¶ÇÊûúÁî®Á¨¨‰∏ÄÁßçÊñπÊ≥ïÔºåÂè™ËÄóË¥πrecursiveÊó∂ÂÄôÁöÑÁ©∫Èó¥Ôºå‰πüÂ∞±ÊòØlogn in-place ‰∏çÁ®≥ÂÆöÔºåÂõ†‰∏∫‰∏çÁü•ÈÅìÂú®Êç¢ÁöÑÊó∂ÂÄôÂ∞±Êää‰ªÄ‰πàÂ•áÂ•áÊÄ™ÊÄ™ÁöÑ‰∏úË•øÊç¢Âà∞ÂâçÈù¢Âéª‰∫Ü Â†ÜÊéíÂ∫è ‰∏ÄÁßçÁ±ª‰ºº‰∫åÂèâÊ†ëÁöÑËÆæËÆ°ÔºåÂ≠êËäÇÁÇπÁöÑÊï∞ÂÄºÊÄªÊòØÂ§ß‰∫éÊàñËÄÖÂ∞è‰∫éÁà∂ËäÇÁÇπÁöÑÊï∞ÂÄº„ÄÇÈ¶ñÂÖàË¶ÅËÆ©Êï∞ÊçÆÂΩ¢ÊàêËøôÊ†∑ÁöÑÁªìÊûÑ ÊØèÊ¨°Êìç‰ΩúÁöÑÊó∂ÂÄôÔºåÈÉΩÊäärootÁöÑÂÄºÂíåÊúÄÂêé‰∏Ä‰∏™ËäÇÁÇπ‰∫§Êç¢Ôºå‰∫§Êç¢ÂêéÁöÑÊúÄÂêé‰∏Ä‰∏™ËäÇÁÇπÁßªÂä®Âá∫Â†ÜÔºåÁÑ∂ÂêéÂÜçÈáçÊñ∞ÁßªÂä®Â†ÜËÆ©‰ªñ‰øùÊåÅ‰∏äÈù¢ËØ¥ÁöÑÊÄßË¥® ‰∏ÄËà¨ÈÄöËøá‰∏ÄÁª¥Êï∞ÁªÑÊù•ËÆøÈóÆ Áà∂ËäÇÁÇπiÁöÑÂ∑¶ËäÇÁÇπÔºö2i+1 Áà∂ËäÇÁÇπiÁöÑÊúâËäÇÁÇπÔºö2i+2 Â≠êËäÇÁÇπÁöÑÁà∂ËäÇÁÇπÔºö floorÔºàÔºài-1Ôºâ/2Ôºâ 12345678910111213141516171819202122232425def HeapSort(nums): # startÊòØ‰ªéÊúÄÂêé‰∏Ä‰∏™Áà∂ËäÇÁÇπÂºÄÂßãÁöÑ,ÊûÑÂª∫Âá∫heap for start in range((len(nums)-2)//2,-1,-1): MinHeap(nums,start,len(nums)-1) for i in range(len(nums)-1,-1,-1): nums[i],nums[0] = nums[0],nums[i] # Âõ†‰∏∫ËøôÈáåÊç¢Âà∞ÊúÄÂêéÂéªÁöÑÊï∞Â≠óÂ∞±Â∑≤ÁªèÁ°ÆÂÆöÊòØÊúÄÂ§ßÂÄº‰∫ÜÔºåÊâÄ‰ª•ÂÜçËÄÉËôëÁöÑÊó∂ÂÄô‰∏çÁî®ËÄÉËôë‰ªñ‰∫Ü MinHeap(nums,0,i-1) return numsdef MinHeap(nums, start, end): dad = start child = dad * 2 + 1 # Â¶ÇÊûúÂ≠êËäÇÁÇπËøòÂú®Ëøô‰∏™Â†ÜÈáåÈù¢ÁöÑËØù while child &lt;= end: if child + 1 &lt;= end and nums[child] &gt; nums[child + 1]: # ÊØîËæÉ‰∏§‰∏™Â≠êËäÇÁÇπÔºåÈÄâÂá∫Êù•Êõ¥Â∞èÁöÑÈÇ£‰∏™ child += 1 if nums[dad] &lt; nums[child]: break else: nums[dad], nums[child] = nums[child], nums[dad] dad = child child = dad * 2 + 1 Ê≥®ÊÑèÔºöÂ¶ÇÊûúÊòØmaxheapÔºàÂç≥root‰∏äÁöÑÊï∞Â≠óÊòØÊúÄÂ§ßÁöÑÊï∞Â≠óÁöÑËØùÔºâÔºåÂÆûÈôÖÊéíÂá∫Êù•ÁöÑÊòØÁî±Â∞èÂà∞Â§ßÔºåÂõ†‰∏∫maxÁöÑÊï∞Â≠óÂú®ÊØè‰∏ÄÊ¨°ÈÉΩË¢´Êç¢Âà∞‰∫ÜÊúÄÂêéÈù¢ Êó∂Èó¥Â§çÊùÇÂ∫¶Ôºönlogn Á©∫Èó¥Â§çÊùÇÂ∫¶Ôºö1 ‰∏äÈù¢ÁöÑ‰ª£Á†ÅÂèØ‰ª•ÂéüÂú∞ÂÆåÊàêÁöÑ in place Á®≥ÂÆöÊÄßÔºö‰∏çÁ®≥ÂÆöÔºåËøôÁßçÁûéÊç¢ÁöÑÂæàÈöæÊêûÊ∏ÖÊ•öÂà∞Â∫ïÊç¢Âà∞Âì™ÈáåÂéª‰∫Ü ËÆ°Êï∞ÊéíÂ∫è Êâ´Êèè‰∏ÄÈÅçÊï¥‰∏™Êï∞ÁªÑÔºåÊâæÂà∞ÊúÄÂ§ßÂÄºmaxÂíåÊúÄÂ∞èÂÄºminÔºåËä±Ë¥πÊó∂Èó¥n ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑÊï∞ÁªÑÔºåÂ§ßÂ∞èÊòØmax-min + 1 ÁÑ∂ÂêéÁî®Êñ∞Êï∞ÁªÑÈáåÈù¢ÁöÑindexÊù•ÁªüËÆ°ÊØè‰∏™Êï∞Â≠óÂá∫Áé∞ÁöÑÊ¨°Êï∞ÔºåÊúÄÂêéÊï¥ÁêÜÂá∫Êù• 123456789def CountingSort(nums): Max,Min = max(nums),min(nums) counting = [0 for i in range(Max-Min+1)] result = [] for n in nums: counting[n-Min] += 1 for n,i in enumerate(counting): result += i * [n + Min] return result 12345678910111213141516def CountingSort_2(nums): #Âπ∂‰∏çÂàõÂª∫Êñ∞ÁöÑÊï∞ÁªÑ Max= max(nums) bucketLen = Max + 1 bucket = [0]*bucketLen sortedIndex = 0 n = len(nums) for i in range(n): # Â¶ÇÊûúÁé∞Âú®ÁöÑËøô‰∏™‰ΩçÁΩÆÊòØÁ©∫ÁöÑ if not bucket[nums[i]]: bucket[nums[i]] = 0 bucket[nums[i]] += 1 for j in range(bucketLen): while bucket[j] &gt; 0: nums[sortedIndex] = j sortedIndex += 1 bucket[j] -= 1 ‰∏çÊòØÊØîËæÉÊéíÂ∫èÔºåÊó∂Èó¥‰∏äÊù•ËØ¥ÊØî‰ªª‰ΩïÊØîËæÉÊéíÂ∫èÈÉΩÂø´ Ê≤°Ê≥ïÁî®Âú®ÊéíÂ∫èÁöÑ‰∏úË•ø‰∏çÊòØÊï∞Â≠óÁöÑÊÉÖÂÜµ‰∏ãÔºåÊï∞Â≠óÂ∑ÆÂºÇÈùûÂ∏∏Â§ßÁöÑÊÉÖÂÜµ‰ºöÂæàÂç†ÂÜÖÂ≠ò„ÄÇÊéíÂ∫èÁöÑÂøÖÈ°ªÊòØÊï¥Êï∞ Êó∂Èó¥Â§çÊùÇÂ∫¶ n+kÔºåÂè™ÈúÄË¶ÅÂú®Êï¥‰∏™Êï∞ÁªÑÈáåÊâæÂá∫ÊúÄÂ§ßÂÄºÂíåÊúÄÂ∞èÂÄºÔºåÁÑ∂ÂêéÂú®kÊó∂Èó¥ÈáåÈù¢Êï∞Êï∞ÊØè‰∏™Êï∞Â≠óÂá∫Áé∞‰∫ÜÂ§öÂ∞ëÊ¨°„ÄÇÂÖ∂‰∏≠kÊòØËøô‰∫õÊï¥Êï∞ÁöÑËåÉÂõ¥ Á©∫Èó¥Â§çÊùÇÂ∫¶ kÁî®Êù•ÂÇ®Â≠òËÆ°Êï∞ÁöÑÊï∞ÁªÑ Á®≥ÂÆöÔºö‰∏∫‰∫Ü‰øùËØÅÊï∞ÁªÑÁöÑÁ®≥ÂÆöÊÄßÔºåÈúÄË¶ÅÂèçÂêëÂ°´ÂÖÖÊï∞ÁªÑÔºàÁé∞Âú®ÁöÑÊñπÊ≥ï‰∏çËÉΩ‰øùËØÅÁ®≥ÂÆöÊÄßÔºâ Ê°∂ÊéíÂ∫è ÊÄùÊÉ≥Âü∫‰∫é‰∏äÈù¢ÁöÑËÆ°Êï∞ÊéíÂ∫èÔºå‰ΩÜÊòØÊ≤°ÊúâÂàÜÈÇ£‰πàÂ§öÁßç ‰∏ªË¶ÅÊÉ≥Ê≥ïÂ∞±ÊòØÂÖàÊääÁé∞Âú®ÁöÑÂÜÖÂÆπÂàÜÂà∞k‰∏™‰∏çÂêåÁöÑÊ°∂ÈáåÈù¢ÔºåÂÜçÂú®ÊØè‰∏™Ê°∂ÈáåÈù¢ÂàÜÂà´ÊéíÂ∫è Ê≠•È™§ ÊääÊï∞ÊçÆÂàÜÂà∞k‰∏™Ê°∂Èáå ÊØè‰∏™Ê°∂ÁöÑËåÉÂõ¥ÊòØ floorÔºàÔºàmax-min+1Ôºâ/ kÔºâ ÊîæÂÖ•Ê°∂ÁöÑÁºñÂè∑‰∏∫ floor((Êï∞Â≠ó-ÊúÄÂ∞èÂÄº)/ÊØè‰∏™Ê°∂ÁöÑËåÉÂõ¥) ÂØπÊØè‰∏™‰∏ç‰∏∫Á©∫ÁöÑÊ°∂ÊéíÂ∫è ËøûÊé•ÊØè‰∏™‰∏ç‰∏∫Á©∫ÁöÑÊ°∂ Êó∂Èó¥Â§çÊùÇÂ∫¶Ôºö ÊúÄÂ•Ωn+k -&gt; Âπ≥ÂùáÂàÜ ÊúÄÂ∑ÆÊòØn^2 ÈÉΩÂàÜÂà∞‰∏Ä‰∏™Ê°∂Èáå‰∫Ü Á©∫Èó¥Â§çÊùÇÂ∫¶ n+k Á®≥ÂÆöÔºåÊ≥®ÊÑèÂÖàÊîæËøõÊ°∂ÈáåÁöÑË¶ÅÂÖàÊãøÂá∫Êù•ÔºåÊâçËÉΩ‰øùËØÅÁ®≥ÂÆö Âü∫Êï∞ÊéíÂ∫è radix sort ÈùûÊØîËæÉÁöÑÊï¥Êï∞ÊéíÂ∫èÁöÑÁÆóÊ≥ï„ÄÇ‰πüÂèØ‰ª•Áî®Âú®Â≠óÊØç‰∏äÔºå‰πüÂ∞±ÊòØLSDÂíåMSD ÊääÊï¥Êï∞Êåâ‰ΩçÂàáÂâ≤Êàê‰∏çÂêåÁöÑÊï∞Â≠óÔºåÁÑ∂ÂêéÊØè‰∏™‰ΩçÁöÑÊï∞Â≠óÂàÜÂà´ÊØîËæÉ„ÄÇÈúÄË¶ÅÊääÊØîËæÉÁöÑ‰ΩçÊîæËøõ0-9ÁöÑ‰πù‰∏™Ê°∂Èáå Ê≠•È™§ ÊâÄÊúâÊï∞Áªü‰∏ÄÂà∞‰∏Ä‰∏™ÈïøÂ∫¶ÔºåÁü≠ÁöÑËØùÂâçÈù¢Ë°•0 ‰ªéÊúÄ‰Ωé‰ΩçÂºÄÂßãÔºå‰æùÊçÆÊúÄ‰Ωé‰ΩçËøõË°åÊéíÂ∫è ‰∏ÄÁõ¥ÊéíÂà∞ÊúÄÈ´ò‰ΩçÔºåÊéíÂ∫è‰πãÂêéÂ∞±ÊòØÊúâÂ∫èÁöÑ‰∫Ü]]></content>
      <categories>
        <category>ÁÆóÊ≥ï</category>
        <category>ÊéíÂ∫è</category>
      </categories>
      <tags>
        <tag>ÁªèÂÖ∏ÊéíÂ∫è</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[unityÊòæÁ§∫Áõ∏Êú∫ÁîªÈù¢Âπ∂Âú®opencvÂ§ÑÁêÜ]]></title>
    <url>%2F2019%2F08%2F22%2Funity%E6%98%BE%E7%A4%BA%E7%9B%B8%E6%9C%BA%E7%94%BB%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[ÊâìÂºÄÁõ∏Êú∫ÊòæÁ§∫ÊñπÊ≥ïÈ¶ñÂÖàÈúÄË¶ÅÊòéÁ°ÆÔºåÁõÆÂâçÁúãÂà∞ÁöÑÊòæÁ§∫ÂõæÁâáÊúâ‰∏§ÁßçÊñπÊ≥ïÔºå‰∏ÄÁßçÊòØÊ∏≤ÊüìÂà∞ÂÆûÈôÖÁöÑgameobject‰∏äÈù¢ÂéªÔºåÂè¶‰∏ÄÁßçÊòØdrawÂà∞GUI‰∏äÈù¢Âéª„ÄÇÂÖ≥‰∫égameobjectÂú®‰∏ä‰∏Ä‰∏™ÊòæÁ§∫ÂõæÁâáÈáåÈù¢Êúâ‰∫ÜÂ§ßËá¥ÁöÑ‰∫ÜËß£„ÄÇËøôÈáå‰∏ªË¶ÅËØ¥ÁöÑÂÜÖÂÆπÂåÖÊã¨ Áõ∏Êú∫ÊòæÁ§∫ÁöÑÂøÖÂ§áÊ≠•È™§ ÂÖ≥‰∫éGUI ÂÖ≥‰∫érenderer Áõ∏Êú∫ÂÜÖÂÆπÊòæÁ§∫ Âú®unity‰∏≠ÔºåÊúâ‰∏Ä‰∏™‰∏ìÈó®ÁöÑÁ±ªÂè´ÂÅöWebCamTextureÔºåÊàë‰ª¨ÈúÄË¶Å‰∏∫ËØªÂèñËøõÊù•ÁöÑÁõ∏Êú∫textureÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑÂØπË±°„ÄÇ‰∏ÄËà¨Êù•ËØ¥ÔºåÈúÄË¶Å‰∏â‰∏™ÈÉ®ÂàÜÔºåÁõ∏Êú∫Á∫πÁêÜÔºåÁõ∏Êú∫ÂêçÂ≠óÔºàstringÔºâ‰ª•ÂèäÁõ∏Êú∫ÊòØÂê¶ÊâìÂºÄÔºàboolÔºâ startÈÉ®ÂàÜ Âú®ËøôÈÉ®ÂàÜÔºåÊàë‰ª¨È¶ñÂÖàÈúÄË¶ÅÊääÂàõÂª∫ÁöÑcameraTextureÂÆû‰æãÂåñ ÂÖ∂Ê¨°ÔºåÊàë‰ª¨ÈúÄË¶ÅË∞ÉÁî®StartCoroutineÂáΩÊï∞ÔºåÂú®ÂÖ∂‰∏≠Ë∞ÉÁî®ÊµãËØïÂáΩÊï∞Êù•Á°ÆÂÆöÁõ∏Êú∫ÊòØÂê¶ÊâìÂºÄ StartCoroutine Âú®‰∏ÄËà¨ÁöÑÊâßË°åÈáåÈù¢ÔºåunityÊòØÈÄêÂ∏ßËøêË°åÁöÑÔºåÊâÄ‰ª•ÂΩìÊìç‰ΩúËä±Ë¥πÊó∂Èó¥ÁöÑÊó∂ÂÄôÔºåÂ∏ßÁéá‰∏ãÈôçÔºåÂ∞±‰ºöÂèëÁîüÂç°È°ø ËøôÈÉ®ÂàÜÂºÄÂßã‰∫Ü‰∏Ä‰∏™ÂçèÁ®ãÔºàCoroutineÔºâÔºå‰ΩøÁî®yieldÔºåÂèØ‰ª•Âú®‰ªª‰ΩïÈÉ®ÂàÜÊöÇÂÅúËøô‰∏™CoroutineÁöÑÊâßË°å„ÄÇÂ¶ÇÊûúË¢´ÊàêÂäüÊöÇÂÅúÔºåÂÆÉ‰ºöÂú®‰∏ã‰∏ÄÂ∏ßÊÅ¢Â§çÊ≠£Â∏∏„ÄÇÊâÄ‰ª•Ëøô‰∏™ÊñπÊ≥ïÂú®Â§öÂ∏ßËøêË°å‰πã‰∏≠ÈùûÂ∏∏Â•ΩÁî®„ÄÇ unity‰ºöÂÅáË£ÖÂºÄËæü‰∏Ä‰∏™Êñ∞Á∫øÁ®ãÊù•ÊâßË°åÔºå‰ΩÜÊòØ‰∏ç‰ºöÂΩ±Âìç‰∏ªÁ∫øÁ®ãÁöÑÊåÅÁª≠ÊïàÊûú ÂèÇËÄÉ ‰ªéËøôÈáåÁöÑÂäüËÉΩÊù•ËØ¥Ôºåyield‰ºöÊ£ÄÊü•Áî®Êà∑ÊúâÊ≤°ÊúâÊéàÊùÉÔºåÂ¶ÇÊûúÊ≤°ÊúâÊéàÊùÉÁöÑËØùÔºåËøêË°åË¢´ÁªàÊ≠¢ÔºåË∑≥Âà∞‰∏ã‰∏ÄÂ∏ß„ÄÇÂ¶ÇÊûúÊéàÊùÉÊàêÂäü‰∫ÜÁöÑËØùÔºåËøêË°åÊàêÂäüÔºåÁõ∏Êú∫ÊâìÂºÄ„ÄÇ IEnumerator Âú®StartCoroutineË∞ÉÁî®ÁöÑÊòØ‰∏Ä‰∏™IEnumeratorÂáΩÊï∞Ôºå‰ªñÈÄöËøáyield‰∏Ä‰∏™boolÊù•ÂÜ≥ÂÆöÊòØ‰∏çÊòØÁªßÁª≠ËøêË°åËøô‰∏™ÂáΩÊï∞ ÊéàÊùÉ Âú®testÈáåÈù¢ÈúÄË¶ÅËÄÉËôëÊúâÊ≤°ÊúâÁî®Êà∑ÁöÑÊéàÊùÉ ÊúâÊéàÊùÉÁöÑÊÉÖÂÜµ‰∏ãÔºåÈúÄË¶ÅÊääÁõÆÂâçÁöÑWebCamTextureÔºàÊ≥®ÊÑèËøôÈáå‰∏çÊòØÂª∫Á´ãÁöÑÂÆû‰æãÔºâÁöÑdeviceÁöÑÊï∞ÊçÆ‰º†ÈÄíÁªôWebCamDeviceÔºåÂåÖÊã¨Á±ªÂûãÔºåÂêçÂ≠óÁ≠âÁ≠â„ÄÇ ÁÑ∂ÂêéÈúÄË¶ÅÊääÂåÖÊã¨Ëøô‰∏™Áõ∏Êú∫ÂêçÂ≠óÔºåsizeÂíåfpsÁöÑ‰ø°ÊÅØ‰º†Áªô‰πãÂâçcameraTextureÁöÑÂÆû‰æã ‰ª•‰∏äÈÉΩËÆæÂÆöÂ•Ω‰πãÂêéÔºåWebCamTexture.Play‰ºöÊøÄÊ¥ªËøô‰∏™Áõ∏Êú∫ÔºåËÆ©‰ªñÂºÄÂßãÂ∑•‰Ωú ÁÑ∂ÂêéÂÜçËÆ≤Áõ∏Êú∫ÁöÑtextureÊ∏≤ÊüìÂà∞objectÁöÑË°®Èù¢‰∏ä12345678910yield return Application.RequestUserAuthorization(UserAuthorization.WebCam); if(Application.HasUserAuthorization(UserAuthorization.WebCam)) &#123; WebCamDevice[] devices = WebCamTexture.devices; cameraName = devices[0].name; cameraTexture = new WebCamTexture(cameraName, 1024, 768, 15); cameraTexture.Play(); isOpen = true; renderer.material.mainTexture = cameraTexture; &#125; GUI GUI‰∏ªË¶ÅÊòØÊèê‰æõ‰∫ÜÂõæÂΩ¢ÂåñÁöÑÁ™óÂè£ÔºåÂÆûÈôÖ‰∏äÊòæÁ§∫ÁöÑÂÖÉÁ¥†ÊòØÁõ¥Êé•ÊòæÁ§∫Âú®gameÁîªÈù¢‰∏äÁöÑÔºå‰πüÂ∞±ÊòØËØ¥ËøôÈÉ®ÂàÜÊòØÂíåÂÆûÈôÖÁõ∏Êú∫ÊãçÊëÑÂà∞ÁöÑÁîªÈù¢Áã¨Á´ãÁöÑ„ÄÇÊó†ËÆ∫Áõ∏Êú∫Â¶Ç‰ΩïÁßªÂä®ÔºåÁâ©‰ΩìÂ¶Ç‰ΩïÊîπÂèòÔºåÊúÄÁªàGUIÁöÑÁîªÈù¢ÈÉΩ‰ºöÊòæÁ§∫Âà∞ÂêåÊ†∑ÁöÑÂú∞Êñπ MonoBehaviour.OnGUI() Ê≥®ÊÑèOnGUIÂáΩÊï∞Âπ∂‰∏çÈúÄË¶ÅÊàë‰ª¨Ëá™Â∑±ÂéªË∞ÉÁî®Ôºå‰∏çÈúÄË¶ÅÂÜçupdateÈáåÈù¢Ë∞ÉÁî®ÔºÅ OnGUIÊòØAPIÈáåÈù¢Ëá™Â∏¶ÁöÑÂáΩÊï∞ÔºåÊàë‰ª¨ÈúÄË¶ÅÂú®Ëøô‰∏™ÂáΩÊï∞‰∏≠Ê∏≤ÊüìÂíåÂ§ÑÁêÜGUIÁöÑevent Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÔºåOnGUIÂèØËÉΩÊØè‰∏Ä‰∏™frameË¢´callÂæàÂ§öÊ¨°ÔºåÊØèÊ¨°eventÔºà‰æãÂ¶ÇÈº†Ê†áÊìç‰ΩúÔºåÈîÆÁõòÁ≠âÁ≠âÔºâÂèëÁîüÁöÑÊó∂ÂÄôÈÉΩ‰ºöcallËøô‰∏™ÂáΩÊï∞ ‰æãÂ¶Ç‰∏ãÈù¢ÂÆòÊñπÁöÑ‰æãÂ≠êÔºåÊØèÊ¨°Èº†Ê†áÁÇπÂáªÁöÑÊó∂ÂÄôÔºåÂ∞±‰ºöprintÂá∫Áõ∏Â∫îÁöÑËØùÊù•12345678910111213using UnityEngine;using System.Collections;public class ExampleClass : MonoBehaviour&#123; void OnGUI() &#123; if (GUI.Button(new Rect(10, 10, 150, 100), "I am a button")) &#123; print("You clicked the button!"); &#125; &#125;&#125; GUI.DrawTexture Âú®GUIÁöÑÂÆûÁé∞‰∏≠ÔºåÊàë‰ª¨ÈúÄË¶ÅÂ∞ÜÁõ∏Êú∫ËØªÂèñÂà∞ÁöÑÈÉ®ÂàÜdrawÁöÑGUIÁöÑ‰∏äÈù¢ÔºåÊâÄ‰ª•Ë∞ÉÁî®‰∫ÜËøô‰∏™ÂáΩÊï∞ ÈúÄË¶ÅÁ°ÆÂÆöÁöÑÂèÇÊï∞ÂåÖÊã¨Ôºö‰ΩçÁΩÆÔºåÈúÄË¶ÅÊ∏≤ÊüìÁöÑtextureÔºåÁº©ÊîæÊØî‰æãÁ≠âÁ≠â ÂÆûÁé∞ ‰ª£Á†ÅÈÉ®ÂàÜÂèÇËÄÉ1234567891011121314151617181920212223242526272829303132333435363738394041424344454647using System.Collections;using System.Collections.Generic;using UnityEngine;public class showCamera : MonoBehaviour&#123; protected WebCamTexture cameraTexture; protected string cameraName = ""; protected bool isOpen = false; //protected MeshRenderer renderer; // Start is called before the first frame update void Start() &#123; //renderer = this.GetComponent&lt;MeshRenderer&gt;(); cameraTexture = new WebCamTexture(); StartCoroutine(Test()); &#125; // Update is called once per frame void Update() &#123; &#125; IEnumerator Test() &#123; yield return Application.RequestUserAuthorization(UserAuthorization.WebCam); if(Application.HasUserAuthorization(UserAuthorization.WebCam)) &#123; WebCamDevice[] devices = WebCamTexture.devices; cameraName = devices[0].name; cameraTexture = new WebCamTexture(cameraName, 1024, 768, 15); cameraTexture.Play(); isOpen = true; //renderer.material.mainTexture = cameraTexture; &#125; &#125; void OnGUI() &#123; if(isOpen) &#123; GUI.DrawTexture(new Rect(0, 0, 400, 300), cameraTexture, ScaleMode.ScaleToFit); &#125; &#125;&#125; Ê∏≤ÊüìÂà∞object‰∏äÈù¢ Âíå‰πãÂâçÁöÑÊìç‰ΩúÁ±ª‰ººÔºåÈúÄË¶Å ÊûÑÂª∫MeshRendererÁöÑobject Âú®startÈáåÈù¢ËØªÂèñÂá∫Áâ©‰ΩìÁöÑMeshRendererÔºàgetcomponentÔºâ ÊúÄÂêéÊâìÂºÄÁõ∏Êú∫ÂêéÔºåÊääÁõ∏Êú∫ÁöÑÂÜÖÂÆπÊ∏≤ÊüìÂà∞MeshRenderer‰∏äÈù¢ 12345678910111213141516171819202122232425262728293031323334353637383940414243using System.Collections;using System.Collections.Generic;using UnityEngine;public class showCamera : MonoBehaviour&#123; protected WebCamTexture cameraTexture; protected string cameraName = ""; protected bool isOpen = false; protected MeshRenderer renderer; // Start is called before the first frame update void Start() &#123; renderer = this.GetComponent&lt;MeshRenderer&gt;(); //cameraTexture = new WebCamTexture(); StartCoroutine(Test()); &#125; IEnumerator Test() &#123; yield return Application.RequestUserAuthorization(UserAuthorization.WebCam); if(Application.HasUserAuthorization(UserAuthorization.WebCam)) &#123; WebCamDevice[] devices = WebCamTexture.devices; cameraName = devices[0].name; cameraTexture = new WebCamTexture(cameraName, 1024, 768, 15); cameraTexture.Play(); isOpen = true; renderer.material.mainTexture = cameraTexture; &#125; &#125; //void OnGUI() //&#123; // if(isOpen) // &#123; // GUI.DrawTexture(new Rect(0, 0, 400, 300), cameraTexture, ScaleMode.ScaleToFit); // &#125; //&#125;&#125; Â∞ÜÂõæÁâáÊîæÂÖ•opencvÊù•Ê∫ê ÂæóÂà∞‰∫ÜwebÁöÑtexture‰πãÂêéÔºåÂèØ‰ª•Áõ¥Êé•Áî®openCVÁöÑÈÉ®ÂàÜÊääËøô‰∏™Áé©ÊÑèËΩ¨Êç¢ÊàêmatÔºåÁÑ∂ÂêéÂ§ÑÁêÜ ËøôÈáåÁöÑÈóÆÈ¢òÊòØÂàöÂºÄÂßãmatÁöÑÂ§ßÂ∞èËé´ÂêçÂÖ∂Â¶ôÁöÑÊòØ16ÔºåÊâÄ‰ª•ÈúÄË¶ÅÂä†‰∏ä‰∏Ä‰∏™Âà§Êñ≠Êù°‰ª∂ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667using System.Collections;using System.Collections.Generic;using UnityEngine;using OpenCVForUnity.CoreModule;using OpenCVForUnity.UnityUtils;using OpenCVForUnity.ImgprocModule;public class showCamera : MonoBehaviour&#123; protected WebCamTexture cameraTexture; //protected string cameraName = ""; //protected bool isOpen = false; private Color32[] colors; private Mat rgbaMat; private Texture2D tex; // Start is called before the first frame update void Start() &#123; //renderer = this.GetComponent&lt;MeshRenderer&gt;(); //cameraTexture = new WebCamTexture(); //StartCoroutine(Test()); cameraTexture = new WebCamTexture(WebCamTexture.devices[0].name, 640, 480); cameraTexture.Play(); StartCoroutine(init()); &#125; private IEnumerator init() &#123; Debug.Log(cameraTexture.width); if (cameraTexture.width &lt;= 16) &#123; while(!cameraTexture.didUpdateThisFrame) &#123; yield return new WaitForEndOfFrame(); &#125; cameraTexture.Pause(); colors = cameraTexture.GetPixels32(); cameraTexture.Stop(); yield return new WaitForEndOfFrame(); cameraTexture.Play(); tex = new Texture2D(cameraTexture.width, cameraTexture.height, TextureFormat.RGBA32, false); rgbaMat = new Mat(cameraTexture.height, cameraTexture.width, CvType.CV_8UC4); GetComponent&lt;Renderer&gt;().material.mainTexture = tex; &#125; &#125; private void Update() &#123; Debug.Log(cameraTexture.width); if (cameraTexture.didUpdateThisFrame &amp;&amp; rgbaMat != null) &#123; Utils.webCamTextureToMat(cameraTexture, rgbaMat); //Imgproc.cvtColor(rgbaMat, rgbaMat, Imgproc.COLOR_RGB2HSV); Utils.matToTexture2D(rgbaMat, tex); tex.Apply(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Unity</category>
        <category>OpenCV</category>
      </categories>
      <tags>
        <tag>Unity</tag>
        <tag>WebCamera</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÁºñÁ®ãÁè†ÁéëProgrammingPearls]]></title>
    <url>%2F2019%2F08%2F20%2F%E7%BC%96%E7%A8%8B%E7%8F%A0%E7%8E%91ProgrammingPearls%2F</url>
    <content type="text"><![CDATA[Á¨¨‰∏ÄÁ´†ÈóÆÈ¢ò ÂºÄÂßãÁöÑÈóÆÈ¢òÊòØÂ¶Ç‰ΩïÂØπÊñá‰ª∂ËøõË°åÊéíÂ∫è -&gt; merge sort Êï¥ÂêàÈóÆÈ¢ò‰πãÂêéÔºåÈóÆÈ¢òÂèòÊàê‰∫ÜÈúÄË¶ÅÂØπ7‰ΩçÊï∞Â≠óËøõË°åÊéíÂ∫èÔºåËøôÊ†∑ÁöÑËØùÈúÄË¶ÅÁöÑÊó∂Èó¥Â∞±ËøúÂ∞è‰∫émerge sort‰∫Ü Âè¶‰∏ÄÁßçÊñπÊ≥ï Â¶ÇÊûúÂú®ÊØè‰∏™byteÈáåÈù¢Â≠ò‰∏Ä‰∏™Êï∞Â≠óÔºåÈÇ£‰πà1MBÂèØ‰ª•Â≠ò143000Â∑¶Âè≥ÁöÑÂè∑Á†ÅÔºàe6/7) ‰ΩÜÊòØÂ¶ÇÊûúÊääÊØè‰∏™Êï∞Â≠óË°®Á§∫Êàê‰∏Ä‰∏™32‰ΩçÁöÑintÔºà‰πüÂ∞±ÊòØËØ¥ÊØè7‰ΩçÊï∞Â≠òÊàê‰∏Ä‰∏™32‰ΩçÁöÑÊï¥Êï∞ÔºåÈÇ£‰πàËøô7‰ΩçÊï∞Â∞±Âç†4‰∏™byteÔºâÔºåÈÇ£‰πàÂèØ‰ª•Â≠ò250000Â∑¶Âè≥ÁöÑÂè∑Á†Å ‰ªéËøô‰∏™ËßíÂ∫¶ËÄÉËôëÔºåÂø´ÊéíÁöÑÈÄüÂ∫¶ÊØîmergeÂø´ ÂÆûÁé∞ ‰ªé‰∏äÈù¢ÁöÑÈóÆÈ¢òÂàÜÊûêÊù•ÁúãÔºåÁî®bitmapÊàñËÄÖbit vectorÊù•Ë°®Á§∫Êï∞ÊçÆÂæàÂ∏∏ËßÅ„ÄÇ ÊØîÂ¶ÇÔºåÂèØ‰ª•Áî®‰∏Ä‰∏™20bitÁöÑstringÊù•Ë°®Á§∫{1,2,3,5,8,13} 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 Âú®Ëøô‰∏™ÈáåÈù¢ÔºåÂá∫Áé∞Âú®ÈõÜÂêàÈáåÁöÑÊï∞Â≠óÂ∞±Ë°®Á§∫‰∏∫1ÔºåÊ≤°ÊúâÂá∫Áé∞ÁöÑÂ∞±Ë°®Á§∫‰∏∫0 Âú®ÂÆûÈôÖËß£ÂÜ≥ÈóÆÈ¢òËøáÁ®ã‰∏≠Ôºå7‰ΩçÊï∞Â≠óÂèØ‰ª•Ë°®Á§∫Êàê‰∏Ä‰∏™Â∞è‰∫éÂçÉ‰∏áÁöÑÊï∞„ÄÇÂ¶ÇÊûúÁî®‰∏Ä‰∏™ÂçÉ‰∏áÁöÑ‰∫åËøõÂà∂‰∏≤Êù•Ë°®Á§∫ÔºåÈÇ£‰πàÂ¶ÇÊûúÊï¥‰∏™Êñá‰ª∂ÈáåÈù¢ÊúâÁé∞Âú®ÁöÑÂè∑Á†ÅÁöÑÊó∂ÂÄôÔºåËøô‰∏™‰ΩçÊâçË¢´Ë°®Á§∫‰∏∫1ÔºåÂê¶ÂàôÂ∞±Ë¢´Ë°®Á§∫‰∏∫0 ÂàÜ‰∏∫‰∏â‰∏™Èò∂ÊÆµ ÂÖ≥Èó≠ÊâÄÊúâÁöÑ‰ΩçÔºåÂç≥ÂçÉ‰∏á‰∏™‰ΩçÂÖ®ÈÉΩÊòØ0 ‰ªéËæìÂÖ•Êñá‰ª∂ÈáåÈù¢ÂØºÂÖ•ÊâÄÊúâÁöÑÊï∞Â≠óÔºåÊØîÂ¶Ç2897ÁöÑËØùÔºåÂ∞±ÊòØb[2897]=1 ÂÖ®ÈÉ®ËæìÂÖ•ÂÆåÊØï‰πãÂêéÔºåÂÜçÊ†πÊçÆÁé∞ÊúâÂ≠òÂú®ÁöÑÊï∞Â≠óÂ∞±ÂèØ‰ª•Áõ¥Êé•ÊéíÂ∫èÔºåËæìÂá∫‰∫Ü Â§ÑÁêÜÂéüÂàôÊÄªÂéüÂàôÔºöÂú®ÂºÄÂßãÂ§ÑÁêÜÈóÆÈ¢ò‰πãÂâçÂàÜÊûêÈóÆÈ¢òÔºåÊâçËÉΩËÆ©ÈóÆÈ¢òÊõ¥Â•ΩËß£ÂÜ≥ Á°ÆÂÆöÊ≠£Á°ÆÁöÑÈóÆÈ¢ò -&gt; ÊúÄÈáçË¶ÅÁöÑ‰∏ÄÁÇπ ÈÄâÊã©‰∫ÜbitmapÁöÑÊï∞ÊçÆÁªìÊûÑÔºöÈÄâÊã©Ëøô‰∏™Êï∞ÊçÆÁªìÊûÑÊòØÊ†πÊçÆÁîµËØùÂè∑Á†Å‰∏ç‰ºöÈáçÂ§çËøô‰∏™ÁâπÊÆäÊù°‰ª∂ÂæóÂà∞ÁöÑ multi-pass Êó∂Èó¥ÂíåÁ©∫Èó¥ÁöÑtrade off ÁÆÄÂçïËÆæËÆ° Á¨¨‰∫åÁ´† ÁÆóÊ≥ïÈóÆÈ¢ò1Ôºö Â¶ÇÊûúÊúâÊúÄÂ§ö40‰∫ø‰∏™ÊéíÂ•ΩÂ∫èÁöÑ32‰ΩçÊµÆÁÇπÊï∞ÔºåÂÖ∂‰∏≠ÊúâÈÅóÊºèÁöÑÊï∞ÊçÆÔºåÂ¶Ç‰ΩïÊâæÂà∞ÈÅóÊºèÁöÑÊï∞ÊçÆ„ÄÇËÄÉËôëÂÜÖÂ≠òË∂≥Â§üÁöÑÊó∂ÂÄôÂíåÂÜÖÂ≠ò‰∏çÂ§üÁöÑÊó∂ÂÄôÁöÑÊÉÖÂÜµ Â¶ÇÊûúÂÜÖÂ≠òË∂≥Â§üÔºåÂèØ‰ª•ÂÉèÁ¨¨‰∏ÄÁ´†ËØ¥ÁöÑ‰∏ÄÊ†∑ÔºåÁî®‰ΩçÂõæÊù•Ë°®Á§∫Ëøô‰∫õÊï∞ÊçÆÔºåÁÑ∂ÂêéÁúãÂì™‰∫õÊ≤°Êúâ Â¶ÇÊûúÂÜÖÂ≠ò‰∏çÂ§üÔºü ‰∫åÂàÜÊü•Êâæ ÂøÖÈ°ªÂÆö‰πâËåÉÂõ¥ÔºåËåÉÂõ¥ÈáåÈù¢ÊØè‰∏™Êï∞Â≠óÁöÑË°®Á§∫ÊñπÊ≥ïÂíåÊé¢ÊµãÊñπÊ≥ï ÊØîÂ¶ÇÂ¶ÇÊûúÊääËøô‰∫õÊï∞ÊçÆÂàÜÊàê‰∏§ÈÉ®ÂàÜÔºåÊØîÂ¶Ç1-10ÈáåÈù¢Âèñ‰∏≠‰ΩçÊï∞ÔºåÂõ†‰∏∫Áº∫Êï∞ÊçÆÁöÑÂéüÂõ†ÔºåÊÄªÊòØ‰ºöÊúâ‰∏ÄËæπÁöÑ‰∏™Êï∞Â∞ëÔºåÈÇ£‰πàÁº∫ÁöÑÊï∞ÊçÆÂ∞±ËÇØÂÆöÂú®Â∞ëÁöÑËøôËæπ ÈóÆÈ¢ò2Ôºö Â∞ÜÂÖ∑Êúân‰∏™ÂÖÉÁ¥†ÁöÑÂêëÈáèxÂ∑¶Êóãi‰∏™‰ΩçÁΩÆÔºåÊó∂Èó¥‰∏ä‰∏énÊàêÊ≠£ÊØîÔºåÊúâÂçÅÂá†Â≠óËäÇÁöÑÈ¢ùÂ§ñÁ©∫Èó¥ Áõ¥Êé•ÊñπÊ≥ï ÂÇ®Â≠òÂà∞È¢ùÂ§ñÊï∞ÁªÑ -&gt; Â§™Êµ™Ë¥πÁ©∫Èó¥‰∫Ü ÂÆö‰πâ‰∏Ä‰∏™ÂáΩÊï∞Â∞ÜÊï∞ÁªÑÊØèÊ¨°ÁßªÂä®‰∏Ä‰∏™‰ΩçÁΩÆ -&gt; Â§™Êµ™Ë¥πÊó∂Èó¥‰∫ÜÔºàËôΩÁÑ∂Êó∂Èó¥‰∏äÂíånÊàêÊ≠£ÊØîÔºâ Âè¶‰∏Ä‰∏™ÊÄùËÄÉ Êää‰∏Ä‰∏™Êï∞ÁªÑÂàÜÊàê‰∏çÂêåÁöÑÁªÑÔºåÊØèÊ¨°ÊääÂØπÂ∫îÁªÑÁöÑÂÜÖÂÆπËΩ¨ÁßªÔºåÁõ¥Âà∞ÊâÄÊúâÂÜÖÂÆπÈÉΩËΩ¨ÁßªÊàêÂäü„ÄÇÊØîÂ¶ÇÊääx[0]Êå™Âá∫ÂéªÔºåx[3]ËØ∫Âà∞x[0],x[6]Êå™Âà∞3ÔºåÁÑ∂Âêé0Êå™Âà∞6„ÄÇÁÑ∂ÂêéÂÜçÊå™x[1]Âíå‰ªñÁöÑÂØπÂ∫îÁöÑÂÜÖÂÆπ‰ª¨ Âè¶‰∏ÄÁßçÊÄùËÄÉÊñπÊ≥ïÔºöÊóãËΩ¨xÂÆûÈôÖÂ∞±ÊòØÊääabËΩ¨Êç¢Êàêba Â¶ÇÊûúaÊòØÂâçi‰∏™ÂÖÉÁ¥†ÔºåaÊØîbÁü≠ÔºåÊääbÂàÜÂâ≤Êàêb1Âíåb2ÔºåËÆ©b2ÂíåaÁöÑÈïøÂ∫¶‰∏ÄÊ†∑ ÈÇ£‰πàÂèØ‰ª•ÂÖà‰∫§Êç¢aÂíåb2 -&gt; b2 a b1 ÁÑ∂ÂêéÂÜçÈõÜ‰∏≠Á≤æÂäõ‰∫§Êç¢b1Âíåb2ÈáåÁöÑÂÖÉÁ¥†Ôºå‰πüÂ∞±ÊòØËØ¥ËøôÂèØ‰ª•ÊòØ‰∏Ä‰∏™recursiveÁöÑË°®Á§∫ÊñπÊ≥ï ËΩ¨ÁΩÆÔºöËøô‰∏™ÁúãËµ∑Êù•Âú®ÂÜôLeetcodeÁöÑÊó∂ÂÄôÈùûÂ∏∏Â•ΩÁî®ÂïäÔºÅÔºÅÔºÅ‰ΩÜÊòØÊ≥®ÊÑèÂú®pythonÈáåÈù¢reverseË¶ÅËá™Â∑±ÂÜô Â¶ÇÊûúÊääÈóÆÈ¢òÁúãÊàêËΩ¨ÁΩÆÔºåÂÆûÈôÖ‰∏äÊï∞ÁªÑabÂèØ‰ª• ÂÖàËΩ¨ÁΩÆaÔºöaTb ÂÜçËΩ¨ÁΩÆbÔºöaTbT ÂÜçËΩ¨ÁΩÆÊï¥‰∏™Êï∞ÁªÑÔºöÔºàaTbTÔºâT = ba ‰πüÂ∞±ÊòØËØ¥ÔºåÂ¶ÇÊûúabcdefgÊÉ≥ËÆ©‰ªñÊóãËΩ¨‰∏â‰ΩçÔºåÂÆûÈôÖ‰∏äÂèØ‰ª•ÂÅöÂà∞ÁöÑÊòØ reverseÔºà0Ôºå2ÔºâÔºöcbadefg reverseÔºà3Ôºå6ÔºâÔºöcbagfed reverseÔºà0Ôºå6ÔºâÔºödefgabc ÈóÆÈ¢ò3 ÊâæÂà∞‰∏Ä‰∏™ÂçïËØçÁöÑÂèò‰ΩçËØçÔºöÊØîÂ¶ÇpotsÂíåstop Ëß£ÂÜ≥ÊñπÊ≥ï Ê≥®ÊÑèÔºåÊâæÂà∞ÊâÄÊúâÁöÑÂèØËÉΩÊÄßÊòØÂæàÊÑöË†¢ÁöÑÔºåÊØîÂ¶Ç‰∏Ä‰∏™22‰∏™Â≠óÊØçÁöÑËØçÔºåÊâÄÊúâÁöÑÂèò‰Ωç22ÔºÅÂ§ßÊ¶ÇÊòØ10e21ÔºåÊó∂Èó¥ÁàÜÁÇ∏‰∫Ü Ê†∏ÂøÉÊÄùÊÉ≥ -&gt; ÊéíÂ∫èÔºåÊéíÂ∫è‰πãÂêéÁöÑÂèò‰ΩçËØçÂ∞±ÈÉΩ‰∏ÄÊ†∑‰∫Ü leetcode 242,49 Ëøô‰∏™È¢òÁöÑÊ†∏ÂøÉÊÄùË∑ØÂ∞±ÊòØÔºåÊØè‰∏™ÂçïËØçÊåâÂ≠óÊØçÈ°∫Â∫èÊéíÂ∫è‰πãÂêéÁöÑÁ≠îÊ°àÂ∞±ÊòØËøô‰∏™ÂçïËØçÁöÑkeyÔºåÂ¶ÇÊûú‰∏§‰∏™ÂçïËØçÁöÑkey‰∏ÄÊ†∑ÁöÑËØùËøô‰∏§‰∏™ÂçïËØçÂ∞±ÊòØÂèò‰ΩçËØçÔºåÂ¶ÇÊûú‰∏ç‰∏ÄÊ†∑ÁöÑËØùÂ∞±ÊòØÊñ∞ÁöÑËØç Âú®pythonÈáåÈù¢Áõ¥Êé•Áî®Â≠óÂÖ∏ÂèØ‰ª•ÂæàÂ•ΩÁöÑÂÇ®Â≠òÂèò‰ΩçËØç Á¨¨‰∏âÁ´† Êï∞ÊçÆÁªìÊûÑÊï∞ÊçÆÁªìÊûÑÁöÑÊÑè‰πâÂ∞±ÊòØËÆ©‰ª£Á†ÅÂèØ‰ª•Êõ¥Âä†ÁÆÄÁü≠Êï¥Ê¥Å -&gt; ÊØîÂ¶ÇÁî®Êï∞ÁªÑ‰ª£ÊõøÂæ™ÁéØ ÂéüÂàôÔºöËÉΩÁî®Â∞èÁ®ãÂ∫èËß£ÂÜ≥ÁöÑÂ∞±‰∏çË¶ÅÁî®Â§ßÁ®ãÂ∫è ÊääÈáçÂ§çÊÄß‰ª£Á†ÅÊîπÂÜô Â∞ÅË£ÖÂ§çÊùÇÁöÑÁªìÊûÑ Â∞ΩÂèØËÉΩ‰ΩøÁî®È´òÁ∫ßÂ∑•ÂÖ∑ ËÆ©Êï∞ÊçÆÂéªÊûÑÈÄ†Á®ãÂ∫è Á¨¨ÂõõÁ´† Ê≠£Á°ÆÁºñÂÜôÁ®ãÂ∫èÂÜô‰∏Ä‰∏™ÂÆåÂÖ®Ê≠£Á°ÆÁöÑbinary searchÂêßÔºÅ Ê≥®ÊÑèÁÇπ Ê±Ç‰∏≠‰ΩçÊï∞ÁöÑÊó∂ÂÄôÊòØÂâçÂêéÁõ∏Âä†ÔºåÈô§‰ª•‰∫å Ê≥®ÊÑèË∑≥Âá∫Âæ™ÁéØÁöÑÊù°‰ª∂ÊòØ start&gt; end ‰∏∫‰∫ÜÊª°Ë∂≥‰∏äÈù¢ÁöÑÂæ™ÁéØÊù°‰ª∂ÔºåÈúÄË¶ÅÊØèÊ¨°Âà§Êñ≠ÂÆåmid‰πãÂêéÔºåÊäästartÊàñËÄÖendÁßªÂä®‰∏Ä‰ΩçÔºå‰∏çÁÑ∂‰ºöÈô∑ÂÖ•Ê≠ªÂæ™ÁéØ ÂêéÈù¢ÁöÑ9Ôºå11Ôºå14‰ºöÁî®Âà∞Á®ãÂ∫èÁöÑÈ™åËØÅÊäÄÊúØ12345678910111213141516class Solution: def search(self, nums: List[int], target: int) -&gt; int: start = 0 end = len(nums) - 1 mid = (start + end) // 2 while start &lt;= end: if target == nums[mid]: return mid elif target &gt; nums[mid]: start = mid + 1 mid = (end + start) // 2 elif target &lt; nums[mid]: end = mid - 1 mid = (start + end) // 2 return -1 Á¨¨‰∫îÁ´† Ê¨°Ë¶ÅÈóÆÈ¢ò ËôΩÁÑ∂ÊØèÊ¨°ÂÜôÂÆå‰∫ÜÁ®ãÂ∫èÔºåÂ§ßÂÆ∂Âü∫Êú¨ÈÉΩ‰ºöÈÄâÊã©ÊääÂÆÉÁõ¥Êé•ÊèíÂÖ•Á≥ªÁªüÔºåÁÑ∂ÂêéÂº∫ÁÉàÁöÑÂ∏åÊúõ‰ªñËÉΩËøêË°å ÔºàÂì≠‰∫ÜÔºåÂÜôÁöÑ‰πüÂ§™ÁúüÂÆû‰∫ÜÔºâ ÊµãËØïÁî®‰æã ËÆæÁΩÆÊûÅÂ∞èÁöÑÊµãËØïÁî®‰æãÔºàÊØîÂ¶Ç0‰∏™Ôºå1‰∏™Ôºå2‰∏™ÂÖÉÁ¥†Á≠âÁ≠âÔºâ ËÆæÁΩÆÂèØ‰ª•Ëá™Âä®ÁîüÊàêÁöÑÊµãËØïÁî®‰æã ËÆ°Êó∂ÔºåÊµãËØï‰∏çÂêåÊñπÊ≥ïÁöÑÊó∂Èó¥ Ë∞ÉËØï -&gt; ÂºïÂèëbugÊòØ‰ºöÊúâÂÆûÈôÖÁöÑÈÄªËæëÂéüÂõ†ÁöÑÔºåË∞ÉËØïÁöÑÊó∂ÂÄôÈúÄË¶ÅÂÖ≥Ê≥®Ëøô‰∫õÈóÆÈ¢ò Á¨¨ÂÖ≠Á´† ÊÄßËÉΩÈÄèËßÜÂú®ÂêéÈù¢ÁöÑ‰∏âÁ´†‰ºöËØ¥Âà∞ÊèêÈ´òËøêË°åÊïàÁéáÁöÑ‰∏â‰∏™ÊñπÊ≥ïÔºåÂú®Á¨¨ÂÖ≠Á´†‰∏ªË¶ÅËÆ≤ÁöÑÊòØÂêÑ‰∏™Â±ÇÊ¨°Â¶Ç‰ΩïÁªÑÂêà‰∏∫‰∏Ä‰∏™Êï¥‰Ωì Ê°à‰æã ‰∏Ä‰∏™Ê®°ÊãüÂ§©‰ΩìÈó¥ÂèóÂäõÂÖ≥Á≥ªÔºåÊù•Ê®°ÊãüËøêÂä®ÁöÑÁ®ãÂ∫èÔºåÈÄöËøáÂØπÁ®ãÂ∫èÁöÑÊîπËøõÔºåÂú®n=1000ÁöÑÁ®ãÂ∫¶‰∏ãÔºåÊääÈÄüÂ∫¶‰ªé‰∏ÄÂπ¥ÊèêÂçáÂà∞‰∫Ü‰∏çÂà∞‰∏ÄÂ§©ÔºåÈÄüÂ∫¶ÊèêÂçáÁ≥ªÊï∞Á∫¶‰∏∫400 ÊîπËøõÊñπÊ≥ï ÁÆóÊ≥ïÂíåÊï∞ÊçÆÁªìÊûÑÔºåÊääÊó∂Èó¥Â§çÊùÇÂ∫¶n2 -&gt; nlognÔºà‰∫åÂèâÊ†ëÔºâ ÁÆóÊ≥ï‰ºòÂåñÔºå‰ºòÂåñ‰∫Ü‰∏§‰∏™Á≤íÂ≠êÈù†ÁöÑÂæàËøëÁöÑÊÉÖÂÜµ Êï∞ÊçÆÁªìÊûÑÈáçÁªÑÔºåÂáèÂ∞ë‰∫ÜÂ±ÄÈÉ®ËÆ°ÁÆóÁöÑÊ¨°Êï∞ ‰ª£Á†Å‰ºòÂåñÔºö64‰ΩçÊµÆÁÇπÊï∞Êîπ‰∏∫32‰ΩçÔºåËÆ°ÁÆóÊó∂Èó¥ÂáèÂçä„ÄÇÁî®Ê±áÁºñÈáçÂÜô‰∫ÜÊüê‰∏™ÂáΩÊï∞ÔºåÁªôÁºìÊÖ¢ÁöÑÂáΩÊï∞Âä†ÈÄü Á°¨‰ª∂ÔºåÊèêÂçá‰∫ÜÁ°¨‰ª∂ ÁÆóÊ≥ïÂä†ÈÄü‰∏ç‰∏ÄÂÆöÊòØÁã¨Á´ã‰∫éÁ°¨‰ª∂ÁöÑÔºåÊØîÂ¶ÇÂú®Ë∂ÖÁ∫ßËÆ°ÁÆóÊú∫‰∏äÔºåÊ†ëÂΩ¢ÁªìÊûÑÂØπÊó∂Èó¥ÁöÑÂΩ±ÂìçÂ∞±ÂæàÂ∞è ËÆæËÆ°Â±ÇÊ¨° ÈóÆÈ¢òÁöÑÂÆö‰πâ Á≥ªÁªüÁªìÊûÑ -&gt; Á¨¨‰∏ÉÁ´†ÔºåÂ∞ÅÂ∫ï‰º∞ËÆ° ÁÆóÊ≥ïÂíåÊï∞ÊçÆÁªìÊûÑ -&gt; 2,8Á´† ‰ª£Á†Å‰ºòÂåñ -&gt; 9 Á≥ªÁªüËΩØ‰ª∂ Á°¨‰ª∂ÔºöÊØîÂ¶ÇÂÆûÁé∞Êüê‰∏™ÂäüËÉΩÁöÑ‰∏ìÈó®Á°¨‰ª∂ ÂéüÂàô Â¶ÇÊûúÈúÄË¶ÅÂ∞ëÈáèÂä†ÈÄüÔºåÁ†îÁ©∂ÊúÄÂ•ΩÁöÑÂ±ÇÊ¨°„ÄÇËôΩÁÑ∂‰øÆÊîπÁÆóÊ≥ïÊòØÈùûÂ∏∏Â∏∏ËßÅÁöÑÁ≠îÊ°àÔºå‰ΩÜÊòØÂú®Á†îÁ©∂‰πãÂâçÊúÄÂ•ΩËÄÉËôë‰∏Ä‰∏ãÊâÄÊúâÂèØËÉΩÁöÑÂ±ÇÊ¨°„ÄÇÊØîÂ¶ÇÁ°¨‰ª∂ÔºüËøôÁßçÁöÑÔºåÊúÄÂ•ΩËÉΩÊâæÂà∞‰∏Ä‰∏™ÂæóÂà∞ÊúÄÂ§ßÂä†ÈÄüÔºåÂèàÊâÄÈúÄÁ≤æÂäõÊúÄÂ∞ëÁöÑÂ±ÇÊ¨° Â¶ÇÊûúÈúÄË¶ÅÂ§ßÈáèÂä†ÈÄüÔºåÈúÄË¶ÅÁ†îÁ©∂Â§ö‰∏™Â±ÇÊ¨°„ÄÇÂ∞±ÂÉè‰∏äÈù¢ÁöÑÊ°à‰æã‰∏ÄÊ†∑ Â∞ÅÂ∫ïËÆ°ÁÆóÂú®Â§ÑÁêÜÈóÆÈ¢ò‰πãÂâçÔºåÈúÄË¶ÅÂØπËøô‰∏™ÈóÆÈ¢òÁöÑËßÑÊ®°Êúâ‰∏Ä‰∏™Â§ßÊ¶ÇÁöÑ‰º∞ËÆ°ÔºåÊâçËÉΩÊõ¥Â•ΩÁöÑÂ§ÑÁêÜÈóÆÈ¢ò Â∏ÆÂä©Â∞ÅÂ∫ïËÆ°ÁÆó ‰∏§‰∏™‰∏çÂêåÊñπÈù¢ÁöÑÁ≠îÊ°àÂØπÊØî ÈáèÁ∫≤Ê£ÄÊµã ÁªèÈ™åÊ≥ïÂàô ÂÆûË∑µ ÊÄßËÉΩ‰º∞ËÆ° + ÂÆâÂÖ®Á≥ªÊï∞]]></content>
      <categories>
        <category>ÁÆóÊ≥ï</category>
        <category>ÁºñÁ®ãÁè†Áéë</category>
      </categories>
      <tags>
        <tag>Programming Pearls</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity‰∏éopenCVÊòæÁ§∫ÂõæÁâá]]></title>
    <url>%2F2019%2F08%2F20%2Funity%E4%B8%8EopenCV%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[ÂÖ≥‰∫éopencvÂ∫ì unityÂ∏¶‰∫ÜopencvÂ∫ìÔºå‰ΩÜÊòØËøô‰∏™Â∫ìÊòØbased on javaÁöÑÂü∫Á°Ä‰∏äÁöÑÔºå‰πüÂ∞±ÊòØËØ¥ÊàëÁªßÁî®ËøáopencvÁöÑc++Âíåpython‰πãÂêéËøôÂõûË¶ÅÁî®java‰∫Ü OpenCV for UnityÊñáÊ°£ Ê≥®ÊÑèÔºöÈúÄË¶ÅÂú®ËΩΩÂÖ•opecvÁöÑasset‰πãÂêéÔºåÊääStreamingAssetsÊñá‰ª∂Â§πÁßªÂä®Âà∞AssetÈáåÈù¢ÔºåÈúÄË¶ÅÊìç‰Ωútool--set plugin settings opencvËá™Â∏¶‰∫ÜÂæàÂ§öexampleÔºåÊääËøô‰∫õÂä†ÂÖ•Âà∞building settingÈáåÈù¢Â∞±ÂèØ‰ª•Áî®‰∫Ü ÊòæÁ§∫ÂõæÁâáÈ¶ñÂÖàÊòéÁ°Æ‰∏ÄÁÇπÔºåunityÈáåÈù¢ÊòæÁ§∫ÂõæÁâáÊ≤°ÊúâimshowËøôÁßç‰∏úË•øÔºåÈúÄË¶ÅÊääÂõæÁâáÁöÑmatËΩ¨ÂåñÊàêtextureÊ†ºÂºèÔºåÁÑ∂ÂêéÊääËøô‰∏™textureÂä†Âà∞object‰∏äÈù¢ Âú®ËøôÈáåÊàëÂª∫Á´ã‰∫Ü‰∏Ä‰∏™planeÁöÑobjectÔºåÂπ∂‰∏îË∞ÉÊï¥‰∫ÜÁõ∏Êú∫ÁöÑËßíÂ∫¶ÔºåÁî®Êù•ÊòæÁ§∫ÂõæÁâá ËøôÈÉ®ÂàÜÂú®startÈáåÈù¢ËøõË°åÔºå‰πüÂ∞±ÊòØÁé∞Âú®ÁöÑÂõæÁâáÊòØÈùôÊÄÅÊòæÁ§∫ var varÊòØÁî®Êù•Êé®Êñ≠Ëøô‰∏™ÂèòÈáèÁ±ªÂûãÔºåÂõ†‰∏∫var‰πãÂêéÁõ¥Êé•ÂàõÂª∫‰∫ÜÂèòÈáèÔºåÊâÄ‰ª•ÂèØ‰ª•Êé®Êñ≠Âá∫Êù•„ÄÇ‰ΩÜÊòØjavaËøòÊòØÈùôÊÄÅËØ≠Ë®Ä ËøôÁßçÊ†∑Â≠êÊòØ‰∏çË°åÁöÑvar foo; foo = &quot;foo&quot;; Âú®forÂæ™ÁéØÈáåÂèØ‰ª• imread Âü∫Á°ÄÂäüËÉΩÂíå‰ª•Ââç‰∏ÄÊ†∑ÔºåËØªÂèñ‰∏ÄÂº†ÂõæÁâáÔºåÂ≠ò‰∏∫matÊ†ºÂºè Ë∑ØÂæÑ‰∏≠‰ΩøÁî®‰∫ÜApplication.streamingAssetsPathÔºå‰πüÂ∞±ÊòØ‰∏äÊñá‰∏≠ËØ¥Âà∞ÈúÄË¶ÅÁßªÂä®Âà∞assetÊñá‰ª∂Â§πÈáåÁöÑopencvËá™Â∏¶ÁöÑÊñá‰ª∂Â§π„ÄÇ ImgcodecsÂíåImgprocÁ≠âÈÉΩÊòØ‰ª•ÂâçÊ≤°ÊúâÊé•Ëß¶ËøáÁöÑÂ∫ìÔºåÂ¶ÇÊûúÈúÄË¶ÅÂõæÁâáÊ≠£Â∏∏ÊòæÁ§∫ÔºåÈúÄË¶ÅÊääÊ†ºÂºè‰ªéBGRÊîπÊàêRGB Texture2D Ëøô‰∏™ÊòØÂ§ÑÁêÜÁâ©‰ΩìË°®Èù¢Á∫πÁêÜÁöÑ‰∏Ä‰∏™classÔºåÊûÑÂª∫Êñ∞ÁöÑÁöÑÊó∂ÂÄôÈúÄË¶ÅÁ°ÆÂÆöËøô‰∏™textureÁöÑÂ§ßÂ∞è Âú®ËøôÈáåÈúÄË¶ÅÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑtexture2DÔºåÊâçËÉΩÂú®‰πãÂêéÊäämatËΩ¨Âà∞textureÈáåÈù¢ Utils.matToTexture2D(dst, tex) Áî®‰∫ématÂíåÁ∫πÁêÜÁöÑËΩ¨Êç¢ÔºåÂêåÊ†∑‰πüÊúâtextureËΩ¨Âà∞matÁöÑÊñπÊ≥ï GetComponent() ÂæóÂà∞Ëøô‰∏™gameObjectÁöÑ‰∏Ä‰∏™ÈÉ®ÂàÜÔºåÂ∞ñÊã¨Âè∑ÈáåÈù¢ÁöÑÂêçÂ≠óÂèñÂÜ≥‰∫éÁé∞Âú®Ëøô‰∏™objectÈáåÈù¢Êúâ‰ªÄ‰πà ËøôÈáåÁî®ÁöÑÊòØplaneÔºåÈáåÈù¢Ëá™Â∏¶rendererÁöÑÂ±ûÊÄßÔºåÂπ∂‰∏îrendererÈáåÈù¢Â∏¶ÊúâmaterialÔºåÁî®Êù•‰øÆÊîπÊûÑÊàêËøô‰∏™objectÁöÑÊùêÊñô ÊÄªÁªì Áî®unityÊòæÁ§∫ÂõæÁâáÁöÑ‰∏≠ÂøÉÊÄùÊÉ≥Â∞±ÊòØËøô‰∏™ÂõæÁâáÂèòÊàê‰∫Üobject‰∏äÈù¢ÁöÑtextureÔºåËøô‰∏™ÂõæÁâá‰∏çËÉΩËÑ±Á¶ªobjectËÄåÁã¨Á´ãÂ≠òÂú®ÔºåÊâÄ‰ª•ÈúÄË¶ÅÈ¶ñÂÖà‰∏∫Ëøô‰∏™ÂõæÁâáÊûÑÂª∫object ÊúÄÁªàÁªìÊûúÂ¶Ç‰∏ã 123456789101112131415161718192021222324252627using System.Collections;using System.Collections.Generic;using UnityEngine;using OpenCVForUnity;using UnityEngine.UI;using OpenCVForUnity.ImgcodecsModule;using OpenCVForUnity.ImgprocModule;using OpenCVForUnity.CoreModule;public class remove : MonoBehaviour&#123; void Start() &#123; var dst = Imgcodecs.imread(Application.streamingAssetsPath + "/image.JPG"); Imgproc.cvtColor(dst, dst, Imgproc.COLOR_BGR2RGB); //Debug.Log(dst.channels()); Texture2D tex = new Texture2D(dst.width(), dst.height(), TextureFormat.RGBA32, false); OpenCVForUnity.UnityUtils.Utils.matToTexture2D(dst, tex); gameObject.GetComponent&lt;Renderer&gt;().material.mainTexture = tex; &#125;&#125;]]></content>
      <categories>
        <category>Unity</category>
        <category>OpenCV</category>
      </categories>
      <tags>
        <tag>ÂõæÂÉèÂ§ÑÁêÜ</tag>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OmniProcamUnityÊñá‰ª∂ÊÄªÁªì]]></title>
    <url>%2F2019%2F08%2F19%2FOmniProcamUnity%E6%96%87%E4%BB%B6%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Êñá‰ª∂ÊûÑÊàê Lib libOmniProCam libOmniProCamCalibration OmniProcam Projection Camera ProjectionTarget RenderTexture Shader DebugUI LibOmniProCamManager ÂÖ∂‰∏≠ÔºåÂú®libÈáåÈù¢ÊúâcalibrationÁî®ÁöÑÊé•Âè£ÔºåÂú®ÈáåÈù¢ËÆæÂÆöÂ•Ω‰∫ÜÊäïÂΩ±‰ª™ÈúÄË¶ÅÁöÑÂèÇÊï∞Êï∞ÈáèÂíåÁõ∏Êú∫ÈúÄË¶ÅÁöÑÂèÇÊï∞Êï∞Èáè„ÄÇÂú®libÈáåÈù¢Áõ¥Êé•Êîæ‰∫ÜËÄÅÂ∏àÂÜôÂ•ΩÁöÑdllÔºåÊâÄ‰ª•ÂÖ∂ÂÆûcsÊñá‰ª∂ÊòØÂú®ËÆøÈóÆËøô‰∫õdllÁöÑÂÜÖÂÆπ Camera ÁõÆÁöÑÔºöÂàùÂßãÂåñÁõ∏Êú∫ ÂèòÈáè ÂàõÂª∫‰∏Ä‰∏™classÔºöcameraInitializerÔºåÁªßÊâø‰∫ÜMonobehaviour MonoBehaviourÊòØÊØè‰∏Ä‰∏™unityÁöÑscriptÁöÑÂü∫Á°ÄÁ±ª publicÁöÑgameobjectÔºåÁî®Êù•ÂÜ≥ÂÆösetupÂì™‰∏™Áõ∏Êú∫ÔºåËøô‰∏™Áõ∏Êú∫Áõ¥Êé•‰ªéunityÁöÑUIÈáåÈù¢ÊãΩËøõÂéª protectedÁöÑcameraÁ±ªÔºåtargetcamera projectedÂèØ‰ª•Âú®Ëøô‰∏™class‰ª•ÂèäÊâÄÊúâÁªßÊâøËøô‰∏™classÁöÑÈáåÈù¢Ë¢´ËÆøÈóÆÔºå‰ΩÜÊòØprivateÂè™ËÉΩÂú®Ëøô‰∏™class‰∏≠Ë¢´ËÆøÈóÆ CameraÊòØunityÈáåÈù¢‰∏Ä‰∏™Ë°®Á§∫Áõ∏Êú∫ÁöÑÁ±ª ÂàõÂª∫‰∫Ü‰∏§‰∏™floatÁöÑÊï∞ÁªÑÔºåÂ§ßÂ∞èÂíå‰πãÂâçËÆæÁΩÆÂ•ΩÁöÑÁõ∏Êú∫ÂèÇÊï∞ÔºåÂíåÊäïÂΩ±‰ª™ÂèÇÊï∞‰∏ÄÊ†∑ ÂàùÂßãÂåñ‰∏â‰∏™4x4ÁöÑÁü©ÈòµÔºåÂàÜÂà´ÊòØÁõ∏Êú∫ÁöÑintrinsicÔºåextrinsic‰ª•ÂèäÁõ∏Êú∫ÁöÑÊäïÂΩ±Áü©Èòµ Matrix4x4ÂèØ‰ª•Ë°®Á§∫transformationÁöÑÁü©ÈòµÔºåÂåÖÊã¨Âπ≥ÁßªÊóãËΩ¨Á≠âÁ≠â ÂáΩÊï∞ void Awake() ÂäüËÉΩ Âú®ÂºÄÂßã‰πãÂâçÂàùÂßãÂåñvariableÊàñËÄÖgame stateÔºåÂú®Êï¥‰∏™striptÈáåÈù¢Âè™Ë¢´call‰∏ÄÊ¨° Âú®ÊâÄÊúâÁöÑobjectÂàùÂßãÂåñÁªìÊùü‰πãÂêé ÈÄöÂ∏∏Âú®start‰πãÂâçË¢´call ÊïàÊûú ÂàùÂßãÂåñ‰∫Ücalibration ËÆæÂÆöÂ•Ω‰∫ÜÁõÆÊ†áÁöÑÁõ∏Êú∫ÔºåÂπ∂‰∏îÊääËøô‰∏™Áõ∏Êú∫setup protected void setupCamera(Camera targetCamera, int cameraIndex) Áõ¥Êé•call‰∫ÜdllÈáåÈù¢ÂÜôÂ•ΩÁöÑÂäüËÉΩÔºà‰ΩÜÊòØËøôÈáåÂæóÂà∞ÁöÑÊòØprojectorÁöÑÔºå‰∏∫‰ªÄ‰πàÔºüÔºâÔºåÂæóÂà∞‰∫ÜÂêÑÁßçÂèÇÊï∞ ÂÖ≥‰∫éGChandle ÁÑ∂ÂêéÊäädistortionÂíåÈÉΩËÆ∞ÂΩï‰∏ãÊù•‰∫ÜÔºåÁõ¥Êé•ÊäätranslationÂíårotationÔºàÁõ∏Êú∫ÁöÑÂ§ñÁü©ÈòµÔºâËµãÂÄºÁªô‰∫ÜÁõÆÊ†áÁõ∏Êú∫„ÄÅËøôÊ†∑ÁõÆÊ†áÁõ∏Êú∫Â∞±ËÉΩÁõ¥Êé•ÁßªÂä®Âà∞Â∫îËØ•Âà∞ÁöÑ‰ΩçÁΩÆ‰∏ä‰∫Ü Âè¶Â§ñ‰∏§‰∏™ÂáΩÊï∞ÂèØ‰ª•ËøîÂõûËøôÈáåÁõÆÂâçÊ≤°ÊúâÁî®Âà∞ÁöÑdistortion kÔºà4‰∏™ÔºâÂíåcÔºà2‰∏™Ôºâ device]]></content>
      <categories>
        <category>Á†îÁ©∂ÂÆ§</category>
        <category>OmniProcamV2</category>
      </categories>
      <tags>
        <tag>OmniProcam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Levenshtein DistanceÁöÑÂÖ∑‰ΩìÂàÜÊûê]]></title>
    <url>%2F2019%2F08%2F08%2FLevenshtein%2F</url>
    <content type="text"><![CDATA[ÁºñËæëË∑ùÁ¶ª ÁºñËæëË∑ùÁ¶ªÊòØË°°ÈáèÂ≠óÁ¨¶‰∏≤Áõ∏‰ººÂ∫¶ÁöÑË∑ùÁ¶ª ‰∏ªË¶ÅÂ∫îÁî®ÊØîÂ¶ÇË°°ÈáèDNAÁöÑÁõ∏‰ººÊÄßÔºåË°°Èáè‰ªÄ‰πàÂú∞ÊñπÊñ≠Â≠óÔºåÊñá‰ª∂ÁöÑÂ∑ÆÂºÇÁ≠âÁ≠â Âü∫Êú¨Êìç‰Ωú ÂØπ‰∫éÂ≠óÁ¨¶‰∏≤ÈáåÈù¢ÁöÑ‰∏§‰∏™Â≠óÊØçÔºåÊúâ‰∏âÁßçÊìç‰ΩúÊñπÊ≥ïËÉΩËÆ©‰ªñ‰ª¨ÊîπÂèò ÊèíÂÖ•‰∏Ä‰∏™Êñ∞ÁöÑÂ≠óÊØç Âà†Èô§‰∏Ä‰∏™Â∑≤ÁªèÂ≠òÂú®ÁöÑÂ≠óÊØç ÊääÁé∞ÊúâÁöÑÂ≠óÊØçÊõøÊç¢ÊàêÂÖ∂‰ªñÂ≠óÊØç ÂØπ‰∫é‰∏§‰∏™stringÔºåÊúâÂõõÁßçÂü∫Êú¨ÁöÑÊìç‰Ωú Á¨¨‰∏ÄÁßçÔºå‰∏çÂèò ÔºàÊØîÂ¶ÇruopengÂíåfagÔºâ ÂéüÊú¨ÁöÑÊìç‰Ωú ruopeng[0,6] -&gt; fag[0,2] ÂèòÊç¢‰πãÂêé ruopen[0,5] -&gt; fa[0,1] Âõ†‰∏∫ÊúÄÂêé‰∏Ä‰ΩçÁõ∏ÂêåÔºåËøô‰∏™ÈóÆÈ¢òÂèØ‰ª•ÊãÜÂàÜÊàêÊúÄÂêé‰∏Ä‰∏™Â≠óÊØçÔºåÂíå‰∏çÂåÖÊã¨ÊúÄÂêé‰∏Ä‰∏™Â≠óÊØçÁöÑsubstringÔºåËøô‰∏™ÈóÆÈ¢òÂ∞±ÂèØ‰ª•ÊãÜÂàÜ‰∫Ü Á¨¨‰∫åÁßçÔºåÊõø‰ª£ replace ÔºàÊØîÂ¶Ç peng Âíå zhouÔºâ ÂéüÊú¨Êìç‰Ωú peng[0,3] -&gt; zhou[0,3] ÂèòÊç¢‰πãÂêé pen[0,2] -&gt; zho[0,2] + replace(g -&gt; u) ÂÖ∂‰∏≠ÔºåÊõøÊç¢ÁöÑÊìç‰ΩúÊòØ‰∏ÄÊ≠•ÔºåÊõøÊç¢‰πãÂêéÊúÄÂêé‰∏Ä‰ΩçÁöÑÂ≠óÊØçÁõ∏ÂêåÔºåËøô‰∏™ÈóÆÈ¢òÂ∞±ÂèØ‰ª•ÊãÜÂàÜÊàêÊõ¥Â∞èÁöÑÈóÆÈ¢ò‰∫Ü Á¨¨‰∏âÁßçÔºåÊèíÂÖ• insert ÂéüÊú¨Êìç‰Ωú peng[0,3] -&gt; zhou[0,3] ÂèòÊç¢‰πãÂêé peng[0,3] -&gt; zho[0,2] + insert(u) È¶ñÂÖàÔºåÁõ¥Êé•ÊääËøô‰∏™ÈóÆÈ¢òÈáåÈù¢ÁöÑzhouÊãÜÂàÜÊàê‰∫ÜÊõ¥Â∞èÁöÑÈóÆÈ¢òzhoÔºåÁÑ∂ÂêéÂÜçËøõË°å‰∏Ä‰∏™ÊèíÂÖ•Êìç‰ΩúÔºà‰∏ÄÊ≠•ÔºâÔºå‰ΩøzhoÈáçÊñ∞ÂèòÊàê‰∫Üu Á¨¨ÂõõÁßçÔºåÂà†Èô§ deletion ÂéüÊú¨Êìç‰Ωú peng[0,3] -&gt; zhou[0,3] ÂèòÊç¢‰πãÂêé pen[0,2] -&gt; zhou[0,3] + delete(g) ÂêåÊó∂‰πüÂèØ‰ª•Â∞ùËØïÂ∞ùËØïÂà†Èô§ÊéâÂâç‰∏Ä‰∏™stringÈáåÈù¢ÁöÑÊúÄÂêé‰∏Ä‰∏™Â≠óÊØçgÔºå‰∏çÂÜçÁÆ°ÈáåÈù¢ÁöÑgÔºåÊääËøô‰∏™Â≠óÁ¨¶‰∏≤Â∞ùËØïÂèòÊàêpenÊù•ËøõË°åÊØîËæÉ Ê†∏ÂøÉÊÄùÊÉ≥ È¶ñÂÖàÔºåÊàë‰ª¨ÈíàÂØπËøô‰∏§‰∏™stringÂà∂‰Ωú‰∏Ä‰∏™table ÂØπ‰∫éËøô‰∏™Ë°®Êù•ËØ¥ÔºåÊØè‰∏Ä‰∏™‰ΩçÁΩÆÈÉΩÁõ∏ÂΩì‰∫éËøô‰∏™‰ΩçÁΩÆÂØπÂ∫îÁöÑ‰∏§‰∏™substringÁöÑÁõ∏‰ººÁ®ãÂ∫¶ÔºåÊØîÂ¶ÇEÂíåFÂØπÂ∫îÁöÑÂ∞±ÊòØ ‚ÄùRUOPE‚Äú Âíå ‚ÄùF‚Äú‰∏§‰∏™substringÂØπÂ∫îÁöÑÁõ∏‰ººÂ∫¶ Âú®ÊØè‰∏™ÂçïËØçÂºÄÂßã‰πãÂâçÔºåËøòÊúâ‰∏Ä‰∏™Á©∫ÁôΩÁ¨¶Âè∑ÔºåÂØπÂ∫îÁöÑsubstringÂ∞±ÊòØÁ©∫ÁôΩ„ÄÇÊØîÂ¶ÇÁ©∫ÁôΩÁ¨¶Âè∑Ëøô‰∏ÄÂàóÂØπÂ∫îÁöÑÂ∞±ÊòØ‚Äù‚ÄúÂàÜÂà´Âíå‚ÄùF‚ÄúÔºå‚ÄùFA‚ÄúÔºå‚ÄùFAN‚ÄúÁ≠âÂÖÉÁ¥†ÁöÑÊØîËæÉ ÂØπ‰∫éÊØè‰∏™Ë°®Ê†ºÈáåÈù¢ÁöÑ‰ΩçÁΩÆÔºå‰ªé(1,1)ÂºÄÂßãÔºåËøô‰∏™‰ΩçÁΩÆÂíåÂë®Âõ¥‰ΩçÁΩÆÁöÑÂÖ≥Á≥ªÂ¶Ç‰∏ã ‰∏äÈù¢‰∏ÄÊ†ºÊòØÊèíÂÖ•ÔºåÊåáÁöÑÊòØÂú®FANGZHOUËøô‰∏™stringÁöÑsubstringÈáåÈù¢ÊèíÂÖ• Â∑¶Ëæπ‰∏ÄÊ†ºÊòØÂà†Èô§ÔºåÊåáÁöÑÊòØÊääRUOPENGËøô‰∏™ÂçïËØçÂà†Èô§‰∏Ä‰∏™Â≠óÊØç Â∑¶‰∏äËßí‰∏ÄÊ†ºÊòØÊõø‰ª£ÔºåÊåáÁöÑÊòØÊääËøô‰∏§‰∏™ÂçïËØçÁöÑÂ≠óÊØçÂàÜÂà´ÈÄÄ‰∏Ä‰Ωç„ÄÇÂ¶ÇÊûúÂΩìÂâç‰ΩçÁöÑÂ≠óÊØçÁõ∏ÂêåÔºåÂΩìÂâç‰ΩçÁöÑÂÄºÁ≠â‰∫éÈÄÄ‰∏Ä‰Ωç‰πãÂêéÁöÑÂÄºÔºåÂ¶ÇÊûúÂΩìÂâç‰∏çÂêåÔºåÊòØÈÄÄ‰∏Ä‰ΩçÁöÑÂÄº+Êõø‰ª£Ëä±Ë¥πÁöÑÊìç‰ΩúÔºà‰πüÂ∞±ÊòØ1Ôºâ Ë°®Ê†ºÂàùÂßãÂåñ È¶ñÂÖàÈúÄË¶ÅÁ°ÆÂÆöËøô‰∏™Ë°®Ê†ºÁöÑËæπÁºòÊÉÖÂÜµÔºå‰πüÂ∞±ÊòØÊ®™ÂùêÊ†áÂíåÁ∫µÂùêÊ†áÂàÜÂà´ÊòØ0ÁöÑÈÉ®ÂàÜÔºåËøô‰∏™ÈÉ®ÂàÜ‰∏çËÉΩÁî®‰∏äÈù¢ÊÄªÁªìÂá∫Êù•ÁöÑÂÖ¨ÂºèË°®Á§∫ Âõ†‰∏∫ËøôÈÉ®ÂàÜÂÖ∂ÂÆûÂ∞±ÊòØÊää‰∏çÂêåÁöÑsubstringÂíåÁ©∫ÁôΩÁ¨¶Âè∑ÊØîËæÉÔºåÈÇ£‰πàÈúÄË¶ÅÁöÑÊúÄÂ∞èÊìç‰ΩúÂ∞±Á≠â‰∫éÂΩìÂâçÂ≠óÊØçÁöÑ‰ΩçÊï∞ Â°´Ë°® ‰ªéÂΩìÂâçÁöÑÂàùÂßãÁä∂ÂÜµÂá∫ÂèëÔºåÈÄêÊ∏êÊääËøô‰∏™Ë°®Â°´ÂÆåÔºåÊØè‰∏Ä‰∏™Êñ∞ÁöÑÊ†ºÂ≠êÁöÑÂÄºÈÉΩÂèñÂÜ≥‰∫é‰∏ä‰∏Ä‰∏™Ê†ºÂ≠êÁöÑÂÄº insert = M[i-1][j]+1 delete = M[i][j-1] + 1 replace = M[i-1][j-1] + 1 dont change = M[i-1][j-1] Ôºà‰∏§‰∏™Â≠óÊØçÂåπÈÖçÔºâ Â¶ÇÊûú‰∏§‰∏™Â≠óÊØç‰∏çÂåπÈÖçÁöÑÊó∂ÂÄôÔºånow = min(insert,delete,replace) ÊúÄÁªàÁªìÊûúÂ¶Ç‰∏ãÔºåÁ∫¢Ëâ≤ÈÉ®ÂàÜ‰∏∫Â≠óÊØçÁõ∏ÂêåÈÉ®ÂàÜ python‰ª£Á†ÅÂÆûÁé∞12345678910111213141516171819202122def EditDistance(a, b): m = len(a) n = len(b) # ÊûÑÂª∫Ë°®Ê†ºÔºåÊ≥®ÊÑèÈúÄË¶ÅÊØîÈïøÂ∫¶Â§ß‰∏ÄÊ†ºÔºåÂÇ®Â≠òÁ©∫Â≠óÁ¨¶‰∏≤ M = [[0 for i in range(m + 1)] for j in range(n + 1)] # ÂàùÂßãÂåñË°®Ê†ºÔºåsubstringÂàÜÂà´ÂíåÁ©∫Â≠óÁ¨¶‰∏≤ÊØîËæÉ for i in range(1, n + 1): M[i][0] = i for i in range(1, m + 1): M[0][i] = i # DP for i in range(1, n + 1): for j in range(1, m + 1): # Âà§Êñ≠ÊòØÂê¶Áõ∏ÂêåÔºåÊ≥®ÊÑèËøôÈáåË¶ÅÂáè‰∏Ä if b[i - 1] == a[j - 1]: M[i][j] = M[i - 1][j - 1] else: insert = M[i - 1][j] + 1 delete = M[i][j - 1] + 1 replace = M[i - 1][j - 1] + 1 M[i][j] = min(insert, delete, replace) return M[n][m] Ê≥®ÊÑèÂàÜÊ∏ÖÁü©ÈòµÁöÑË°åÂíåÂàóÔºåÂú®Ëøô‰∏™ÂÆûÁé∞ÈáåaÊòØË°åÔºåbÊòØÂàó ËÄÉËôëÂà∞ÊúÄÂâçÈù¢ÁöÑÁ©∫Â≠óÁ¨¶‰∏≤ Ê≥®ÊÑè‰ªéstringÈáåÈù¢ËØªÂèñÁöÑÊó∂ÂÄôË¶ÅËÆ∞ÂæóÂáè1 Ê≥®ÊÑèÊûÑÂª∫Áü©ÈòµÁöÑÊó∂ÂÄôË°åÊï∞ÂíåÂàóÊï∞Ë¶ÅÂä†‰∏Ä Âè≥‰∏ãËßíÁöÑÁªìÊûúÂ∞±ÊòØ‰∏§‰∏™ÂÆåÊï¥Â≠óÁ¨¶‰∏≤ÂØπÊØîÁöÑÁªìÊûú Êó∂Èó¥Â§çÊùÇÂ∫¶ Ëøô‰∏™ÊñπÊ≥ïÈúÄË¶ÅÈÅçÂéÜÂ∑¶Âè≥ÁöÑsubstringÁöÑÁªÑÂêàÔºåÂπ∂‰∏îÊääÊâÄÊúâÁöÑÁªìÊûúÈÉΩÂ≠òÂú®‰∏Ä‰∏™Áü©ÈòµÈáå Â¶ÇÊûú‰∏§‰∏™stringÁöÑÈïøÂ∫¶ÂàÜÂà´ÊòØmÂíånÔºåÈÇ£‰πàÊó∂Èó¥Â§çÊùÇÂ∫¶O(mn),Á©∫Èó¥Â§çÊùÇÂ∫¶O(mn) ÊúÄÂêéÔºåRUOPENGÂú®8Êúà8Âè∑ËøôÂ§©Á•ùË∑ùÁ¶ª‰∏∫8ÁöÑFANGZHOUÔºåÂÖ´(7+1)Â§ïÂø´‰πê]]></content>
      <categories>
        <category>ÁÆóÊ≥ï</category>
        <category>Âä®ÊÄÅËßÑÂàí</category>
      </categories>
      <tags>
        <tag>Âä®ÊÄÅËßÑÂàí</tag>
        <tag>ÁºñËæëË∑ùÁ¶ª</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÁÆóÊ≥ïÂõæËß£Á¨îËÆ∞]]></title>
    <url>%2F2019%2F08%2F06%2F%E7%AE%97%E6%B3%95%E5%9B%BE%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Á¨¨‰∏ÄÁ´† ÁÆóÊ≥ïÁÆÄ‰ªã‰∫åÂàÜÊü•Êâæ ÂøÖÈ°ªÊòØÊúâÂ∫èÁöÑÊï∞ÁªÑ ÂØπ‰∫én‰∏™ÂÖÉÁ¥†ÁöÑÂàóË°®Ôºå‰ΩøÁî®‰∫åÂàÜÊü•ÊâæÊúÄÂ§öÈúÄË¶Å log2 nÊ≠•ÔºåÁî®ÊôÆÈÄöÁöÑÊü•ÊâæÊúÄÂ§öÈúÄË¶ÅnÊ≠•1234567891011121314def binary_search(l, item): low = 0 high = len(l) - 1 while low &lt;= high: mid = int((low + high) / 2) # ËøôÈáåÈúÄË¶ÅËΩ¨ÊàêintÔºå‰∏çÁÑ∂Ê≤°ÂäûÊ≥ïÂÅöindex if l[mid] == item: return mid elif l[mid] &lt; item: low = mid + 1 else: high = mid - 1 return None ËøêË°åÊó∂Èó¥ Â§ßOË°®Á§∫Ê≥ïË°®Á§∫‰∫ÜÊìç‰ΩúÊï∞ÔºåË°®Á§∫ÁöÑÊòØËøô‰∏™ÁÆóÊ≥ïÁöÑÂ¢ûÈáè Â§ßOË°®Á§∫‰∫ÜÂú®ÊúÄÁ≥üÊÉÖÂÜµ‰∏ãÁöÑËøêË°åÊó∂Èó¥ -&gt; ‰ΩÜÊòØ‰πüÊòØÈúÄË¶ÅËÆ®ËÆ∫Âπ≥ÂùáÊó∂Èó¥ÁöÑ Â∏∏ËßÅÁöÑÂ§ßOÊó∂Èó¥ logN ÂØπÊï∞Êó∂Èó¥ Logarithmic N Á∫øÊÄßÊó∂Èó¥ Linear N * logN ÂåÖÊã¨Âø´ÈÄüÊéíÂ∫èÁ≠âÔºåÈÄüÂ∫¶ËæÉÂø´ N ^ 2 ÈÄâÊã©ÊéíÂ∫èÁ≠âÔºåÈÄüÂ∫¶ËæÉÊÖ¢ NÔºÅ Factorial time ÈùûÂ∏∏ÊÖ¢ ÊóÖË°åÂïÜÈóÆÈ¢ò travelling salesman problem, TSP ‰∏Ä‰∏™Êêû‰∏çÂ•ΩÂèØ‰ª•Áî®nÔºÅÊù•Ëß£ÂÜ≥ÁöÑÈóÆÈ¢ò ‰Ω†Ë¶ÅÂéª‰∫î‰∏™‰∏çÂêåÁöÑÂú∞ÊñπÔºåÈúÄË¶ÅËßÑÂàíÊÄé‰πàÊ†∑Ë∑ØÁ∫øÊúÄÁü≠ÔºåÊúÄÂºÄÂßãÁöÑÊÄùË∑ØÂ∞±ÊòØÊääÊØèÁßçÂèØËÉΩÊÄßÈÉΩÂàóÂá∫Êù•ÔºåÁÑ∂ÂêéÂØπÊØèÁßçË∑ØÁ∫øËøõË°åËÆ°ÁÆó„ÄÇËøôÊ†∑ÁöÑËØù‰∫î‰∏™Âú∞ÊñπÂ∞±ÊòØ120ÁßçÔºåÂú∞ÊñπË∂äÂ§öË∂äÂëàÈò∂‰πòÂ¢ûÈïø Á¨¨‰∫åÁ´† ÈÄâÊã©ÊéíÂ∫èÊï∞ÁªÑÂíåÈìæË°® Êï∞ÁªÑÈúÄË¶ÅÁöÑÁ©∫Èó¥ÊòØÂõ∫ÂÆöÁöÑÔºà‰πüÂ∞±ÊòØËØ¥ÂøÖÈ°ªËøûÂú®‰∏ÄËµ∑ÔºâÔºåÊâÄ‰ª•Â¶ÇÊûúÂêéÈù¢Âä†ËøõÂéª‰∫ÜÂÖ∂‰ªñ‰∏úË•øÁöÑËØùÂ∞±‰∏çË°å‰∫ÜÔºåÈúÄË¶ÅËΩ¨Áßª‰ΩçÁΩÆÔºåÊàñËÄÖÈ¢ÑÁïôÁ©∫Èó¥ ÈìæË°®ÁöÑÊØè‰∏Ä‰∏™‰ΩçÁΩÆÈÉΩ‰ºöÊúâÂà∞‰∏ã‰∏Ä‰∏™‰ΩçÁΩÆÁöÑÊåáÈíàÔºåÊâÄ‰ª•‰∏çÈúÄË¶ÅÁßªÂä®ÂÖÉÁ¥†„ÄÇ ‰ΩÜÊòØÈìæË°®ÁöÑÈóÆÈ¢òÂú®‰∫éÔºåÂ¶ÇÊûúÊÉ≥Áõ¥Êé•ÊâæÂêéÈù¢ÁöÑ‰∏úË•øÁöÑÊó∂ÂÄôÈúÄË¶Å‰∏Ä‰∏™Êé•ÁùÄ‰∏Ä‰∏™ËØªÂèñ ÈúÄË¶ÅËØªÂèñÊï¥‰∏™Êï∞ÊçÆÁöÑÊó∂ÂÄôÈìæË°®ÊïàÁéáÂæàÈ´òÔºåÈúÄË¶ÅË∑≥Ë∑ÉÁöÑÊó∂ÂÄôÈìæË°®ÊïàÁéáÂæà‰Ωé„ÄÇËÄåÊï∞ÁªÑÂú®ËØªÂèñÈöèÊú∫ÂÖÉÁ¥†ÁöÑÊó∂ÂÄôÊïàÁéáÂæàÈ´ò Êï∞ÁªÑÊèíÂÖ• / Âà†Èô§Á∫øÊÄßÔºåËØªÂèñÂ∏∏Êï∞„ÄÇ ÈìæË°®ËØªÂèñÁ∫øÊÄßÔºåÊèíÂÖ• / Âà†Èô§Â∏∏Êï∞„ÄÇ Âú®ÂÆûÈôÖ‰∏≠ÔºåÂõ†‰∏∫Êï∞ÁªÑÊîØÊåÅÈöèÊú∫ËÆøÈóÆÔºà‰ΩÜÊòØÈìæË°®Âè™ÊîØÊåÅÈ°∫Â∫èËÆøÈóÆÔºâÔºåÊâÄ‰ª•Êï∞ÁªÑÁöÑÈÄÇÁî®ËåÉÂõ¥Â§ß‰∏Ä‰∫õ ÈÄâÊã©ÊéíÂ∫è ÂÆûÁé∞ÊñπÊ≥ïÔºöÊØèÊ¨°ÈÉΩ‰ªéÊâÄÊúâÁöÑÈáåÈù¢ÈÄâÂá∫ÊúÄÂ§ß / ÊúÄÂ∞èÔºåÁÑ∂ÂêéÊîæÂú®ÊúÄÂºÄÂ§¥ Êó∂Èó¥Â§çÊùÇÂ∫¶ n ^ 21234567891011121314def select_sort(l): newArr = [] for j in range(len(l)): smallest = float('inf') index = None for i, item in enumerate(l): if item &lt; smallest: smallest = item index = i newArr.append(l.pop(index)) # Ê≥®ÊÑèËøôÈáåÈúÄË¶ÅÊäälÁöÑÂ§ßÂ∞èÊîπÂèò‰∫Ü # ‰ΩÜÊòØÊòØÂú®Â∏¶lÁöÑloopÂ§ñÈù¢ÂèòÂæóÊâÄ‰ª•Ê≤°ÊúâÂÖ≥Á≥ª return newArr Á¨¨‰∏âÁ´† ÈÄíÂΩí recursion‰Ωï‰∏∫ÈÄíÂΩí ÂáΩÊï∞Ëá™Â∑±Ë∞ÉÁî®Ëá™Â∑± ÈÄíÂΩíÂíåÂæ™ÁéØÁöÑ‰ΩúÁî®ÊïàÊûúÊòØÁõ∏ÂêåÁöÑÔºåÊ≤°ÊúâÊÄßËÉΩ‰∏äÁöÑ‰ºòÂäøÔºå‰ΩÜÊòØÂèØ‰ª•ËÆ©ÊñπÊ°àÊõ¥Âä†Ê∏ÖÊô∞ base caseÔºöÂëäËØâÂáΩÊï∞‰ªÄ‰πàÊó∂ÂÄô‰∏çÂÜçË∞ÉÁî®Ëá™Â∑±ÔºåÂÅúÊ≠¢Âæ™ÁéØ recursive caseÔºöÂáΩÊï∞Ë∞ÉÁî®Ëá™Â∑± Ê†à stack ÂÖàËøõÂêéÂá∫ÁöÑÊï∞ÊçÆÁªìÊûÑÔºåpushÔºàÂéãÂÖ•ÔºâÂíåpopÔºàËØªÂèñÂíåÂà†Èô§Ôºâ Âú®Ë∞ÉÁî®Âè¶‰∏Ä‰∏™ÂáΩÊï∞ÁöÑÊó∂ÂÄôÔºåÂΩìÂâçÂáΩÊï∞ÊöÇÂÅúÂπ∂‰∏îÂ§Ñ‰∫éÊú™ÂÆåÊàêÁä∂ÊÄÅÔºåÂáΩÊï∞ÁöÑÊâÄÊúâÂèòÈáèÈÉΩÂÇ®Â≠òÂú®ÂÜÖÂ≠òÈáå ‰ΩøÁî®ÈÄíÂΩíÁöÑ‰∏Ä‰∏™ÈóÆÈ¢òÔºöÂ¶ÇÊûúË∞ÉÁî®Ê†àÁöÑÊó∂ÂÄôÂæàÈïøÔºå‰ºöÂç†ÊçÆÂ§ßÈáèÂÜÖÂ≠ò ËøôÁßçÊó∂ÂÄôÈúÄË¶ÅÈáçÊñ∞ÁºñÂÜô‰ª£Á†Å‰ΩøÁî®Âæ™ÁéØ ÊàñËÄÖ‰ΩøÁî®Â∞æÈÄíÂΩíÔºàÂπ∂‰∏çÊòØÊâÄÊúâËØ≠Ë®ÄÈÉΩÊîØÊåÅÔºâ Á¨¨ÂõõÁ´† Âø´ÈÄüÊéíÂ∫èÔºàÂàÜËÄåÊ≤ª‰πã divide and conquerÔºâÂàÜÊ≤ª Ê†∏ÂøÉÔºöÊää‰∏Ä‰∏™ÈóÆÈ¢òÂàÜÊàêÂ≠êÈóÆÈ¢òÔºåÂÜçÊääÂ≠êÈóÆÈ¢òÂàÜÊàêÊõ¥Â∞èÁöÑÂ≠êÈóÆÈ¢òÔºåÊúÄÂêéÁöÑÂ≠êÈóÆÈ¢òÂèØ‰ª•Áõ¥Êé•Ê±ÇËß£ÔºåËøôÊ†∑ÁöÑËØùÂéüÈóÆÈ¢òÁöÑËß£Â∞±ÊòØÂ≠êÈóÆÈ¢òÁöÑËß£ÁöÑÂêàÂπ∂ ÊØîÂ¶ÇÊäänËßÑÊ®°ÁöÑÈóÆÈ¢òÂàÜÊàêk‰ªΩÔºåÁÑ∂ÂêéÂú®k‰∏™ÈóÆÈ¢òÈáåÈù¢ÂàÜÂà´ÂÜçÂàÜÂºÄ ÁâπÂæÅ ÈóÆÈ¢òÁº©Â∞èËßÑÊ®°ÂèØ‰ª•ËΩªÊùæËß£ÂÜ≥ ÂèØ‰ª•ÂàÜËß£ÊàêËã•Âπ≤‰∏™Â∞èÈóÆÈ¢ò ÂàÜËß£Âá∫ÁöÑÂ≠êÈóÆÈ¢òÂèØ‰ª•ÂÜçÂêàÂπ∂ÔºàÂ¶ÇÊûú‰∏çÊª°Ë∂≥ËøôÊù°ÔºåÂ∫îËØ•ËÄÉËôëË¥™ÂøÉÊàñËÄÖDPÔºâ ÂàÜËß£Âá∫ÁöÑÂêÑ‰∏™Â≠êÈóÆÈ¢òÊòØÁã¨Á´ãÁöÑÔºà‰∏çÊª°Ë∂≥Â∫îËØ•ËÄÉËôëDPÔºâ ‰∏çÁî®Âæ™ÁéØËÄåÁî®ÈÄíÂΩíÔºöÂáΩÊï∞ÂºèÁºñÁ®ãÈáåÈù¢Ê≤°ÊúâÂæ™ÁéØÔºàHaskellÔºâ 1234567891011121314def RecursiveSum(l): if l == []: return 0 else: return l[0] + RecursiveSum(l[1:]) # ËøôÈáå‰∏çËÉΩÊîπÂèòlÊú¨Ë∫´ÁöÑÂ§ßÂ∞èdef MaxNum(l): if len(l) == 2: return l[0] if l[0] &gt; l[1] else l[1] submax = MaxNum(l[1:]) return l[0] if l[0] &gt; submax else submax Ê≥®ÊÑèÔºö ÈúÄË¶ÅÊâæÂ•ΩÂü∫Êú¨Êù°‰ª∂ÔºåÂ¶ÇÊûúÊâæÊúÄÂ§ßÂÄºÁöÑbaseÂ∞±ÊòØËøòÂâ©‰∏ã‰∏§‰∏™ÂÄº Ê≥®ÊÑèreturnÁöÑÂÜÖÂÆπ Âø´ÈÄüÊéíÂ∫è ÊØîÈÄâÊã©ÊéíÂ∫èÈÄüÂ∫¶Âø´ÂæàÂ§ö baseÊù°‰ª∂Ôºå‰∏Ä‰∏™ÂÖÉÁ¥†ÊàñËÄÖÁ©∫ÁöÑÊï∞ÁªÑÂ∞±‰∏çÈúÄË¶ÅÊéíÂ∫è‰∫Ü ÈúÄË¶ÅËÆæÂÆö‰∏Ä‰∏™Âü∫Êú¨ÂÄºÔºàÊØîÂ¶ÇÂèñÁ¨¨‰∏Ä‰∏™ÂÄºÔºåÊ†πÊçÆËøô‰∏™ÂÄºÊääÂéüÊï∞ÁªÑÂàÜÊàê‰∏§ÈÉ®ÂàÜÔºâÔºåËøôÊ†∑Ëøô‰∏â‰∏™Â§ßÂùóÂ∞±ÂàÜÁ±ªÂÆåÊàê‰∫Ü„ÄÇÁÑ∂ÂêéÂØπ‰∫éÊØè‰∏™Â∞èÂùóÔºåÂÜçÁªßÁª≠ÂàÜÁªÑ ÊØîÂü∫ÂáÜÂ∞èÁöÑÂ≠êÊï∞ÁªÑ Âü∫ÂáÜ ÊØîÂü∫ÂáÜÂ§ßÁöÑÂ≠êÊï∞ÁªÑ1234567891011121314def QuickSort(l): if len(l) &lt; 2: return l else: piv = l[0] # ËøôÈáåÊòØÂø´ËØªÂæóÂà∞ÊØî‰ªñÂ§ßÂíåÊØî‰ªñÂ∞èÁöÑÂÜôÊ≥ïÔºå‰∏ªË¶Å‰ªél[1:]ÂºÄÂßã less_part = [i for i in l[1:] if i &lt; piv] more_part = [i for i in l[1:] if i &gt; piv] return QuickSort(less_part) + [piv] + QuickSort(more_part) # Ê≥®ÊÑèËøôÈáåpivÊòØ‰∏™intÔºåÊâÄ‰ª•ËøûÊé•ÁöÑÊó∂ÂÄôÈúÄË¶ÅÊîπÊàêlist Êó∂Èó¥Â§çÊùÇÂ∫¶ Âø´ÈÄüÊéíÂ∫èÁöÑÈÄüÂ∫¶ÂèñÂÜ≥‰∫éÈÄâÊã©ÁöÑpivÁöÑÂÄºÁöÑÂ§ßÂ∞èÔºå‰πüÂ∞±ÊòØËØ¥Â¶ÇÊûúÂÆåÂÖ®ÊéíÂ•ΩÁöÑÊÉÖÂÜµ‰∏ãÔºåÂ§çÊùÇÂ∫¶ÊòØn2 ÂêàÂπ∂ÊéíÂ∫èÁöÑÈÄüÂ∫¶ÊòØ nlognÔºåÂø´ÈÄüÊéíÂ∫èÁöÑÂπ≥ÂùáÈÄüÂ∫¶ÊòØ nlognÔºåÊúÄ‰Ω≥ÊÉÖÂÜµÊòØ logn Âø´ÈÄüÊéíÂ∫èÈúÄË¶ÅlognÂ±ÇÔºåÊØèÂ±ÇÈúÄË¶ÅÊään‰∏™ÂÖÉÁ¥†ÂÖ®ÈÉΩÈÅçÂéÜ‰∏ÄÊ¨°ÔºåÊâÄ‰ª•ÊúÄÁªàÁöÑÁªìÊûúÊòØnlogn Âú®ËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÁöÑÊó∂ÂÄôÔºåÂ§çÊùÇÂ∫¶ÊòØÊìç‰ΩúÁöÑÊ¨°Êï∞ÔºåËÄåËøô‰∏™Ê¨°Êï∞ÈúÄË¶Å‰πò‰∏Ä‰∏™ÊØèÊ¨°Êìç‰ΩúÁöÑÂ∏∏ÈáèÔºåÂú®Âø´ÈÄüÊéíÂ∫èÁöÑÊó∂ÂÄôÂ∏∏ÈáèÊõ¥Â∞èÔºåËÄå‰∏îÂø´ÈÄüÊéíÂ∫èÊ≤°ÈÇ£‰πàÂÆπÊòìÈÅáÂà∞ÊúÄÁ≥üÊÉÖÂÜµ Á¨¨‰∫îÁ´† Êï£ÂàóË°®ÔºàhashË°®ÔºâhashÂáΩÊï∞ ÊúÄÁªàÁöÑÁõÆÁöÑÊòØÊü•ÊâæÁöÑÊó∂ÂÄôÊó∂Èó¥Â§çÊùÇÂ∫¶ÊòØ 1 ÂáΩÊï∞ÊûÑÈÄ†ÔºöÊääËæìÂÖ•Êò†Â∞ÑÂà∞‰∏Ä‰∏™Êï∞Â≠ó Êó†ËÆ∫‰Ω†‰ªÄ‰πàÊó∂ÂÄôËæìÂÖ•ÔºåËæìÂá∫ÁöÑÊï∞Â≠óÊòØ‰∏ÄËá¥ÁöÑ Â∞Ü‰∏çÂêåÁöÑËæìÂÖ•Êò†Â∞ÑÂà∞‰∏çÂêåÁöÑÊï∞Â≠ó Áü•ÈÅìÊï¥‰∏™Â≠òÂÇ®ÁöÑËåÉÂõ¥ÊúâÂ§öÂ§ßÔºå‰∏ç‰ºöËøîÂõûË∂ÖËøáËøô‰∏™Â§ßÂ∞èÁöÑÊï∞Â≠ó Â∫îÁî®ÔºöÁºìÂ≠ò ÁΩëÁ´ôÁöÑÁºìÂ≠òÊï∞ÊçÆÂ∞±Â≠òÂú®hashË°®ÈáåÈù¢ÔºåËøôÊ†∑ËÆøÈóÆÈÄüÂ∫¶Êõ¥Âø´ÔºåÁΩëÁ´ôÊú¨Ë∫´ÈúÄË¶ÅÂÅöÁöÑÂ∑•‰ΩúÊõ¥Â∞ë ËÆøÈóÆ‰∏Ä‰∏™ÁΩëÈ°µ -&gt; ÊòØÂê¶Âú®ÁºìÂ≠òÈáå -&gt; ÊúâÁöÑËØùË∞ÉÁî®ÁºìÂ≠ò -&gt; Ê≤°ÊúâÁöÑËØùÂ≠òËøõÁºìÂ≠ò ÂÜ≤Á™Å ËôΩÁÑ∂ÂÅáËÆæÁöÑÊó∂ÂÄôËÆ§‰∏∫ÊØè‰∏™‰∏úË•øÈÉΩË¢´Êò†Â∞ÑÂà∞‰∏çÂêåÂú∞ÊñπÔºåÂÖ∂ÂÆû‰ºö‰∫ßÁîüÂÜ≤Á™Å ËøôÁßçÊÉÖÂÜµ‰∏ãË¶ÅÂú®hashÂêéÈù¢Âä†‰∏älist hashÂáΩÊï∞ÈúÄË¶ÅÊääÂÜÖÂÆπÊØîËæÉÂπ≥ÂùáÂàÜÂàÜÈÖç Â¶ÇÊûúÂÇ®Â≠òÁöÑÈìæË°®ÂæàÈïøÔºåÈÇ£‰πàÊÄßËÉΩÂ∞±‰ºöÊÄ•Ââß‰∏ãÈôç ÊÄßËÉΩ ÊúÄ‰Ω≥ÊÄßËÉΩÔºå1 ÊúÄÁ≥üÊÄßËÉΩÔºåÊèíÂÖ•ÔºåÂà†Èô§ÔºåÊü•ËØ¢ÂÖ®ÈÉΩÊòØn Ë£ÖÂ°´Âõ†Â≠êÔºö Ë£ÖÂ°´ÁöÑÂÖÉÁ¥†Êï∞ / ÂÖÉÁ¥†ÊÄªÊï∞ ‰∏ÄÊó¶Ë∂ÖËøá0.7Â∞±ÈúÄË¶ÅË∞ÉÊï¥hashÁöÑÈïøÂ∫¶‰∫Ü Á¨¨ÂÖ≠Á´† BFSÔºöÊúÄÁü≠Ë∑ØÂæÑÈóÆÈ¢òBFS Áî®‰∫éÂõæÁöÑÊü•ÊâæÁÆóÊ≥ïÔºåÂèØ‰ª•Ëß£ÂÜ≥‰∏§ÁßçÈóÆÈ¢ò ‰ªéAÂá∫ÂèëÊúâÂâçÂæÄBÁöÑË∑ØÂæÑÂêó ‰ªéAÂá∫ÂèëÂà∞BÁöÑË∑ØÂæÑÊúÄÁü≠ÊòØ‰ªÄ‰πà ÂÆûÁé∞Âõæ -&gt; hashË°®ÔºåÈúÄË¶ÅÂ∞ÜnodeÊò†Â∞ÑÂà∞ÊâÄÊúâÁöÑÈÇªÂ±Ö Âú®pythonÈáåÈù¢‰ΩøÁî®dequeÂàõÂª∫ÂèåÁ´ØÈòüÂàó ÁÆóÊ≥ïÂÆûÁé∞ÔºàÂπøÂ∫¶ÊêúÁ¥¢ÔºâÔºö ÂàõÂª∫‰∏Ä‰∏™ÈòüÂàóÔºåÂÇ®Â≠òÁî®‰∫éÊü•ÊâæÁöÑ‰∫∫ È¶ñÂÖàÊääÂàùÂßãÂåñÁöÑ‰∫∫ËΩΩÂÖ•ÈòüÂàó ‰ªéÈòüÂàóÈáåÂºπÂá∫‰∏Ä‰∏™‰∫∫ÔºåÊü•Êâæ‰ªñÊòØ‰∏çÊòØÔºàÊü•Ëøá‰πãÂêéÊ†áËÆ∞ÊàêÂ∑≤Ê£ÄÊü•ÔºåÂàóË°®ËÆ∞ÂΩïÔºâÔºå‰∏çÊòØÁöÑËØùÊääËøô‰∏™‰∫∫ÁöÑÁõ∏ÈÇªÂä†ÂÖ•ÈòüÂàóÔºà‰∏ÄÁõ¥ÈáçÂ§çÔºâ Ê†áËÆ∞ÊàêÂ∑≤Ê£ÄÊü•ÈùûÂ∏∏ÈáçË¶ÅÔºåÂõ†‰∏∫‰∏çÊ†áËÆ∞ÁöÑËØùÂèØËÉΩ‰ºöÈô∑ÂÖ•Êó†ÈôêÂæ™ÁéØ Â¶ÇÊûúÊúÄÂêéÈòüÂàóÁ©∫‰∫ÜËøòÊ≤°ÊâæÂà∞ÔºåÈÇ£Â∞±ÊòØÊ≤°Êúâ 123456789101112131415def BFS(name, graph): search_queue = deque() search_queue += graph[name] searched = [name] # Áî®Êù•ÂÇ®Â≠òÂ∑≤ÁªèÊé¢Á¥¢ËøáÁöÑ‰∫∫Êï∞ while search_queue: person = search_queue.popleft() if person not in searched: if person[-1] == "m": # Âè™ÊòØ‰∏Ä‰∏™Âà§Êñ≠ÊòØ‰∏çÊòØËøô‰∏™‰∫∫ÁöÑÂäûÊ≥ï return person else: search_queue += graph[person] searched.append(person) return None Êõ¥Êñ∞ÁâàÊú¨Ôºå‰∏ç‰ΩÜÂèØ‰ª•ÊêúÁ¥¢ËøòÂèØ‰ª•ËÆ°ÁÆóÈïøÂ∫¶12345678910111213141516def BFS(name, graph): search_queue = deque() search_queue.append(name) searched = [name] # Áî®Êù•ÂÇ®Â≠òÂ∑≤ÁªèÊé¢Á¥¢ËøáÁöÑ‰∫∫Êï∞ distance = &#123;name: 0&#125; while search_queue: current = search_queue.popleft() for person in graph[current]: if person not in searched: searched.append(person) distance[person] = distance[current] + 1 if person[-1] == "m": return person, distance[person] else: search_queue.append(person) return None, None Ê≥®ÊÑèÁÇπÔºö Â¢ûÂä†‰∫ÜdistanceËøô‰∏™dictÊù•ÂÇ®Â≠òÂºÄÂßãÁÇπÂà∞Ëøô‰∏™ÁÇπÁöÑË∑ùÁ¶ª Âú®ÂàùÂßãÂåñÁöÑÊó∂ÂÄôÂè™Âú®Â∑≤ÊêúÁ¥¢ÈòüÂàóÈáåÊ∑ªÂä†‰∫ÜÁ¨¨‰∏Ä‰∏™ÁÇπÁöÑ‰ø°ÊÅØÔºåÂú®ÂêéÈù¢ÁöÑÂæ™ÁéØÈáåÊâçÊ∑ªÂä†ÂêéÈù¢ÁöÑÁÇπ ÂØπ‰∫éÊØè‰∏™‰ªéqueueÈáåÈù¢ÊãøÂá∫Êù•ÁöÑÁÇπÔºåÂ¶ÇÊûú‰∏çÂú®Â∑≤ÁªèÊü•ÊâæÁöÑÁÇπÈáåÂ∞±‰∏ÄÂÆöÈúÄË¶ÅÂä†ËøõÂéªÔºåÂπ∂‰∏îËÆ°ÁÆóË∑ùÁ¶ªÔºåË∑ùÁ¶ªÂç≥ÊòØÂíå‰∏ä‰∏ÄÁÇπÁöÑË∑ùÁ¶ª+1 ËÆ°ÁÆóËøáË∑ùÁ¶ª‰πãÂêéÂÜçÂà§Êñ≠ÊòØ‰∏çÊòØË¶ÅÊâæÁöÑÁÇπ ËøêË°åÊó∂Èó¥ ÈúÄË¶ÅÊ≤øÁùÄÊØèÊù°ËæπÂâçËøõÔºåÊâÄ‰ª•Âú®Ëæπ‰∏äÁöÑËøêË°åÊó∂Èó¥ÊòØ O(E) ÊääÊØè‰∏™‰∫∫Âä†Âà∞queueÈáåÈù¢‰πüÈúÄË¶ÅÊó∂Èó¥ÔºåÊØè‰∏™‰∫∫ÁöÑÊó∂Èó¥ÊòØÂ∏∏Êï∞ÔºåÊâÄ‰ª•‰∫∫Êï∞ÁöÑÊó∂Èó¥ÊòØ O(V) ÊÄªÁöÑËøêË°åÊó∂Èó¥ E + V ÊãìÊâëÊéíÂ∫è Â¶ÇÊûú‰ªªÂä°A‰æùËµñ‰∫é‰ªªÂä°BÔºåÈÇ£‰πà‰ªªÂä°AÂ∞±ÂøÖÈ°ªÊéíÂú®BÁöÑÂêéÈù¢ÔºåËøôÁßçÂ∞±ÊòØÊãìÊâëÊéíÂ∫è Á¨¨‰∏ÉÁ´† ÁãÑÂÖãÊñØÁâπÊãâÁÆóÊ≥ï ‰πãÂâçÁöÑÂõæÊâæÁöÑÊòØÊúÄÁü≠Ë∑ØÂæÑÔºåÁé∞Âú®ÈúÄË¶ÅÁªôÂõæÂä†ÊùÉÔºåÊâæÂä†ÊùÉ‰πãÂêéÁöÑÊúÄÁü≠Ë∑ØÂæÑ Âä†ÊùÉ‰πãÂêéÁöÑÊúÄÁü≠‰∏ç‰∏ÄÂÆöÊòØËæπÊï∞ÊúÄÁü≠ Ë¥üÁöÑÊùÉÈáç‰∏çÈ°∂Áî®ÔºåÂõ†‰∏∫Ë¥üÊùÉÈáç‰∏çËÉΩÁ°ÆÂÆöÊ≤°ÊúâÊØîÁõÆÂâçÊ∂àËÄóÊõ¥Â∞èÁöÑ ‰π¶ÈáåÂÜôÁöÑÈîôÁöÑÂú∞ÊñπÔºöÂèØ‰ª•ÊúâÁéØÔºåÊ≤°ÁéØÈÉΩÊòØÊ†ë‰∫ÜÔºÅÊúâÂêëÊó†ÁéØÂõæÂèØ‰ª•Áõ¥Êé•ÊãìÊâëÊéíÂ∫è Ê†∏ÂøÉÊÄùÊÉ≥ÔºöÊâæÂà∞Âà∞Ëøô‰∏™ÁÇπÊ∂àËÄóÊúÄÂ∞ëÁöÑË∑ØÂæÑÔºåÂπ∂‰∏îÁ°Æ‰øùÊ≤°ÊúâË∑ØÂæÑÊØîËøô‰∏™Â∞è‰∫Ü ÁÆóÊ≥ïÊµÅÁ®ã ÊâæÂá∫Ê∂àËÄóÊúÄ‰ΩéÁöÑÁÇπ Êõ¥Êñ∞Ëøô‰∏™ÁÇπÁõ∏ÈÇªÁÇπÁöÑÂºÄÈîÄ ÈáçÂ§çËøô‰∏™ËøáÁ®ãÔºåÁõ¥Âà∞ÂØπÊâÄÊúâÁÇπÈÉΩÂÅö‰∫ÜÔºàÂç≥AÁÇπÊúÄÂ∞è‰πãÂêéÊõ¥Êñ∞BÁÇπÔºåÁÑ∂ÂêéÊõ¥Êñ∞CÁÇπÔºå‰ª•Ê≠§Á±ªÊé®Ôºâ ËÆ°ÁÆóÊúÄÁªàÊµÅÁ®ã ÂÖ∑‰ΩìÂÆûÁé∞ ÂàõÂª∫‰∏Ä‰∏™Ë°®Ê†º ÂåÖÂê´‰∫ÜÊØè‰∏ÄÈ°πÂíåÊØè‰∏ÄÈ°πÁöÑÂÖ∑‰ΩìÂºÄÈîÄÔºåÁõÆÂâç‰∏çÁü•ÈÅìÁöÑÂºÄÈîÄÊ†áËÆ∞Êàêinf ÈúÄË¶ÅÂåÖÂê´ÊØè‰∏™ÁÇπÁöÑÁà∂ËäÇÁÇπÔºåÊâçËÉΩ‰øùËØÅÊúÄÂêéÂèØ‰ª•ËÆ°ÁÆóÊµÅÁ®ã ‰∏çÂÅúÁöÑÊõ¥Êñ∞Ëøô‰∏™Ë°®Ôºå‰ªéÂºÄÈîÄÊúÄ‰ΩéÁöÑ‰∏ÄÁõ¥Êõ¥Êñ∞Âà∞ÂºÄÈîÄÊúÄÈ´òÁöÑÔºåÂ¶ÇÊûúÊõ¥Êñ∞‰∫ÜÂºÄÈîÄÁöÑËØùÂêåÊ†∑ÈúÄË¶ÅÊõ¥Êñ∞Áà∂ËäÇÁÇπ Âú®Á°ÆÂÆöË∑ØÂæÑÁöÑÊó∂ÂÄôÔºå‰ªéÁªìÂ∞æÁöÑÂú∞ÊñπÂºÄÂßãÊâæÔºåÁÑ∂Âêé‰∏ÄË∑ØÊâæÂà∞ÂºÄÂ§¥ ‰∏Ä‰∏™ÈóÆÈ¢òÔºöÂÖ≥‰∫éÂõæÂú®pythonÈáåÈù¢ÁöÑË°®Á§∫ ÂÆûÈôÖÂ∞±ÊòØ‰∏Ä‰∏™dictÂè†dictÔºåÂ¶ÇÊûúÁõ¥Êé•ËÆøÈóÆG[a][b]Â∞±ÂèØ‰ª•Áõ¥Êé•ÂæóÂà∞Ëøô‰∏§‰∏™ÁÇπÁöÑË∑ùÁ¶ª Â¶ÇÊûúÊ≤°ÊúâÂä†ÊùÉÁöÑËØùÔºåÂèØ‰ª•Áõ¥Êé•dictÂè†listÔºåÂõ†‰∏∫‰∏çÈúÄË¶ÅËÆ∞ÂΩïË∑ùÁ¶ª‰∫Ü Ê≥®ÊÑèÁÇπ ÊúÄÂ•ΩÊòØÊúÄÂºÄÂßãÊåáÂÆö‰∫ÜÁ¨¨‰∏Ä‰∏™Ê∂àËÄóÊúÄ‰ΩéÁÇπÔºåÁÑ∂ÂêéÂÜçÂæ™ÁéØÈáåÈù¢ÊúÄÂêéÊâæÊ∂àËÄóÊúÄ‰ΩéÁÇπ ÂàùÂßãÂåñÁöÑÊó∂ÂÄôÊ≥®ÊÑèÔºöcostÈáåÈù¢ÂàùÂßã‰∏∫0ÔºåfatherÈáåÈù¢ÂéªÊéâËøô‰∏™ÁÇπÔºåNodeÔºàcostÊúÄ‰ΩéÁÇπÔºâÂàùÂßãÂåñÊàêËøô‰∏™ÁÇπÔºåÂæ™ÁéØÁöÑÊù°‰ª∂ÊòØNode‰∏çÊòØÁ©∫123456789101112131415161718192021222324252627282930313233343536373839404142def dijkstra(graph, src, target): # ÈúÄË¶ÅÂàõÂª∫‰∏Ä‰∏™costË°®Âíå‰∏Ä‰∏™Áà∂ËäÇÁÇπË°® cost = &#123;&#125; father = &#123;&#125; visited = [] for i in graph.keys(): # ËÆøÈóÆËøô‰∏™ÂõæÈáåÈù¢ÊâÄÊúâÁöÑkeyÔºåÂ∞±ÊòØÊâÄÊúâÁöÑÂ∫ó cost[i] = float('inf') father[i] = None cost[src] = 0 # Ëµ∑ÂßãÁÇπÁöÑcostÊòØ0 father.pop(src) # Ëµ∑ÂßãÁÇπ‰∏çÈúÄË¶ÅÁà∂ËäÇÁÇπ Node = src # ÊúÄÂ∞èÂºÄÈîÄÁÇπËøòÂ≠òÂú®ÁöÑÊó∂ÂÄôÊõ¥Êñ∞ÊâÄÊúâÁöÑÁÇπ while Node is not None: for near in graph[Node]: new_distance = cost[Node] + graph[Node][near] if new_distance &lt; cost[near]: cost[near] = new_distance father[near] = Node visited.append(Node) # ÊâæÂà∞ÊúÄÂ∞èÂºÄÈîÄÁöÑÁÇπ(ÊîæÂú®Âæ™ÁéØÈáåÈù¢Â•Ω‰∏ÄÁÇπ) Node = None smallest = float('inf') for i in cost: if i not in visited: if cost[i] &lt; smallest: smallest = cost[i] Node = i # Ë∑≥Âá∫Âæ™ÁéØÔºåÂæóÂà∞ÁªìÊûú N = &#123; "start": &#123;"a": 2, "b": 6&#125;, "a": &#123;"fin": 1&#125;, "b": &#123;"a": 3, "fin": 5&#125;, "fin": &#123;&#125;&#125;# print(N["start"]["a"])dijkstra(N, "start", "fin") Á¨¨ÂÖ´Á´† Ë¥™ÂøÉÁÆóÊ≥ï Â§ÑÁêÜnpcÈóÆÈ¢òÔºåÂç≥Ê≤°ÊúâÂø´ÈÄüÁÆóÊ≥ïÁöÑËß£Ê≥ïÁöÑÈóÆÈ¢ò ÂØπNPCÈóÆÈ¢òÊâæÂà∞Ëøë‰ººËß£ ‰æãÂ≠êÈóÆÈ¢ò ËØæË°®ÈóÆÈ¢òÔºö Â∏åÊúõÂ∞ΩÂèØËÉΩÂ§öÁöÑËØæÂú®Ëøô‰∏™Â±ãÂ≠êÈáåÈù¢‰∏äÔºå‰ΩÜÊòØ‰∏äËØæÊó∂Èó¥ÂÜ≤Á™ÅÔºåÂ¶Ç‰ΩïÊéíËØæ ÂÖàÊâæÂà∞Ëøô‰∏™ÊïôÂÆ§ÈáåÊúÄÊó©ÂºÄÂßãÁöÑËØæÔºåÁÑ∂ÂêéÊâæÂà∞ËøôËäÇËØæÁªìÊùü‰πãÂêéÊúÄÊó©ÂºÄÂßãÁöÑËØæ Ë£Ö‰∏úË•ø ËÉåÁùÄÂåÖÂéªË£Ö‰∏úË•øÔºåÂÆπÈáèÊúâÈôêÔºåÂ¶Ç‰ΩïË£ÖÂà∞ÊúÄÂ§ß‰ª∑ÂÄºÁöÑ ‰ªéÊúÄÂ§ßÁöÑÂºÄÂßãË£ÖÔºå‰ΩÜÊòØÂæóÂà∞ÁöÑ‰∏çÊòØÊúÄ‰ºòËß£ÔºåÊúÄ‰ºòËß£Â∫îËØ•Âä®ÊÄÅËßÑÂàí Ê†∏ÂøÉÊÄùÊÉ≥ÔºöÊØè‰∏ÄÊ≠•ÈÉΩÁî®Â±ÄÈÉ®ÊúÄ‰ºòËß£ÔºåÂæóÂà∞ÁöÑÁªìÊûúÂ∞±ÊòØÂÖ®Â±ÄÊúÄ‰ºòËß£„ÄÇÂç≥‰ΩøÂæó‰∏çÂà∞ÊúÄ‰ºòËß£Ôºå‰πüÂèØ‰ª•ÂæóÂà∞Ëøë‰ººÊúÄ‰ºòËß£ Âè™ËÉΩÁî®Ë¥™ÂøÉÁöÑÈóÆÈ¢ò ÈõÜÂêàË¶ÜÁõñÈóÆÈ¢òÔºåÊØîÂ¶ÇÊÉ≥Âú®ÂÖ®ÈÉ®Âå∫ÂüüÂπøÊí≠Ôºå‰ΩÜÊòØÊØèÂÆ∂ÁîµÂè∞Âè™Ë¶ÜÁõñÁâπÂÆöÂå∫ÂüüÔºåÂ¶ÇÊûúÊâçËÉΩËä±Ë¥πÊúÄÂ∞èÁöÑËÆ°Âàí ÂàóÂá∫ÊâÄÊúâÁöÑÂèØËÉΩÊÄßÁöÑËØùÔºåÂ§çÊùÇÂ∫¶ÊòØ 2^n Ëøë‰ººÁÆóÊ≥ïÔºö‰ªéË¶ÜÁõñÊúÄÂ§öÂú∞ÊñπÁöÑÁîµÂè∞ÂºÄÂßãÊâæÔºå‰∏ÄÁõ¥Âà∞Ë¶ÜÁõñÊâÄÊúâÂú∞Êñπ Ë¥™ÂøÉÁÆóÊ≥ïÁöÑÂ§çÊùÇÂ∫¶ÊòØ n^2ÔºånÊòØÂπøÊí≠Âè∞ÁöÑÊï∞Èáè Âõ†‰∏∫ÊØèÊ¨°ÈÉΩÈúÄË¶ÅÈÅçÂéÜ‰∏ÄÊ¨°ÊâæÂá∫ÊúÄÈúÄË¶ÅÁöÑÈÇ£‰∏™Ôºàn)ÔºåËøôÊ†∑ÁöÑÊìç‰ΩúÈúÄË¶ÅËøõË°åÊúÄÂ§önÊ¨°Ôºà‰∏á‰∏ÄÊØèÊ¨°ÈÉΩË¶ÜÁõñ‰∏ç‰∏äÔºâ NPCÈóÆÈ¢òÔºö‰ªéÊóÖË°åÂïÜÈóÆÈ¢òËØ¶Ëß£ ÊóÖË°åÂïÜÈóÆÈ¢òÂíåÊ±ÇË∑ØÂæÑÈóÆÈ¢òÁöÑÂå∫Âà´Âú®‰∫éÔºåÊóÖË°åÂïÜÈóÆÈ¢òÈúÄË¶ÅËÆøÈóÆ‰∏ÄÈÅçÊâÄÊúâÁöÑÂú∞ÊñπÔºåÊâæÂà∞ÊúÄÁü≠Ë∑ØÁ∫ø ÊóÖË°åÂïÜÈóÆÈ¢òÈúÄË¶ÅÊü•ÁúãÊâÄÊúâÁöÑÂèØËÉΩÁöÑË∑ØÁ∫ø ‰ªéÁÆÄÂçïÈóÆÈ¢òÂá∫Âèë ‰∏§‰∏™Âú∞ÊñπÁöÑÊó∂ÂÄôÔºåÂèØËÉΩÁöÑË∑ØÁ∫øÊúâ‰∏§Êù°Ôºà‰∏ÄÊù•‰∏ÄÂõûÔºâ ‰∏â‰∏™Âú∞ÊñπÁöÑÊó∂ÂÄô 6Êù° ÈúÄË¶ÅËÆ°ÁÆóÂá∫ÊâÄÊúâÁöÑËß£ÊâçÊúâÂèØËÉΩ‰ªé‰∏≠ÈÄâÂá∫ÊúÄÁü≠ÁöÑË∑ØÁ∫ø -&gt; NPCÈóÆÈ¢ò Ëøë‰ººÊñπÊ≥ïÔºöÊØèÊ¨°ÈÉΩÂéªÁ¶ªÂæóÊúÄËøëÁöÑÂú∞Êñπ ËØÜÂà´ÈóÆÈ¢ò ÂÖÉÁ¥†ËæÉÂ∞ëÁöÑÊó∂ÂÄôÈÄüÂ∫¶Âø´ÔºåÈöèÁùÄÂÖÉÁ¥†Â¢ûÂä†ÈùûÂ∏∏ÊÖ¢ Ê∂âÂèäÊâÄÊúâÁªÑÂêà ‰∏çËÉΩÂàÜÊàêÂ∞èÈóÆÈ¢òÔºåÂøÖÈ°ªËÄÉËôëÊâÄÊúâÊÉÖÂÜµ Ê∂âÂèäÂ∫èÂàóÔºàÊØîÂ¶ÇÊóÖË°åÂïÜ‰∏≠ÁöÑÂüéÂ∏ÇÂ∫èÂàóÔºâÔºåÈõÜÂêàÔºàÈõÜÂêàË¶ÜÁõñÈóÆÈ¢òÔºâ‰∏îÈöæ‰ª•Ëß£ÂÜ≥„ÄÇÊàñËÄÖÂèØ‰ª•ËΩ¨Êç¢ÊàêËøôÁßçÈóÆÈ¢òÁöÑ Á¨¨‰πùÁ´† Âä®ÊÄÅËßÑÂàíÊ†∏ÂøÉÊÄùÊÉ≥ Êää‰∏Ä‰∏™Â§ßÁöÑÈóÆÈ¢òÊãÜÂàÜÊàêÂæàÂ§öÂ∞èÈóÆÈ¢òÁöÑËß£ÁöÑÂêàÂπ∂ ÊúÄÁªàÁöÑÁªìÊûúÂÖ∂ÂÆûÁ±ª‰ºº‰∏Ä‰∏™Ë°®ÔºåÊØèÊ¨°ÂÜçÂæóÂà∞Êñ∞ÁöÑÁªìÊûúÁöÑÊó∂ÂÄôÔºåÂÖ∂ÂÆûÊòØÂú®ÊØîËæÉ ÂêåÁ≠âÂ§ßÂ∞è‰∏ã‰∏ä‰∏Ä‰∏™ÁöÑÂÄºÔºàÂç≥‰∏ä‰∏ÄË°åÁöÑÂÄºÔºåËøô‰∏™ÂÄºÂ∑≤ÁªèÊòØ‰πãÂâçÂÇ®Â≠ò‰∏ãÊù•ÁöÑÊúÄÂ§ßÁöÑÂÄº‰∫ÜÔºâ ÂΩìÂâçÊîæÊñ∞ÁöÑ‰∏úË•øÁöÑ‰ª∑ÂÄº+ÊîæÂÆåËøô‰∏™‰∏úË•ø‰πãÂêéÂâ©‰∏ãÁ©∫Èó¥ÂèØ‰ª•ÊîæÁöÑ‰∏úË•øÁöÑÊúÄÂ§ß‰ª∑ÂÄºÔºàËøô‰∏™ÊúÄÂ§ß‰ª∑ÂÄºÂêåÊ†∑‰πüË¢´ËÆ∞ÂΩï‰∫ÜÔºâ DPÂ§ÑÁêÜÈóÆÈ¢òÁöÑÊó∂ÂÄôÂè™ËÉΩÊï¥‰ª∂ÁöÑÂ§ÑÁêÜÔºå‰πüÂ∞±ÊòØËØ¥ÂàÜÂ∏ÉÂ∫îËØ•ÊòØÁ¶ªÊï£ÁöÑËÄå‰∏çÊòØËøûÁª≠ÁöÑ ËÄå‰∏îDPÂ§ÑÁêÜÈóÆÈ¢òÁöÑÊó∂ÂÄôÂêÑ‰∏™Â≠êÈóÆÈ¢ò‰πãÈó¥‰∏çËÉΩ‰∫íÁõ∏‰æùËµñÔºåÂ¶ÇÊûú‰∫íÁõ∏‰æùËµñ‰∫ÜÂ∞±ÂæàÂ§çÊùÇ‰∫Ü ÊúÄÈïøÂÖ¨ÂÖ±Â≠ê‰∏≤ ÊØîÂ¶ÇÊêúÁ¥¢ÂºïÊìéËØØËæìÂÖ•ÔºåÊÄé‰πàÂà§Êñ≠Áõ∏ËøëËØç ÊØèÁßçÂä®ÊÄÅËßÑÂàíÈÉΩÊ∂âÂèäÁΩëÁªúÔºåÊØè‰∏™ÁΩëÊ†ºÈáåÈù¢ÁöÑÂÄºÂ∞±ÊòØÊàëÈúÄË¶Å‰ºòÂåñÁöÑÂÄº ÊØè‰∏™ÂçïÂÖÉÊ†ºÈáåÊòØ‰ªÄ‰πà ÊØè‰∏™ÂçïÂÖÉÊ†ºÊòØËøô‰∏™Ê†ºÂ≠ê‰πãÂâçÁõ∏ÂêåÁöÑÂ≠óÊØçÊï∞Èáè Â¶Ç‰ΩïÊääËøô‰∏™ÈóÆÈ¢òÂàÜÊàêÂ≠êÈóÆÈ¢ò Â¶ÇÊûúÁõ∏ÂêåÔºåÂ∞±ÊòØÂâç‰∏Ä‰∏™ÁöÑÂ≠óÊØçÊï∞+1ÔºåÂ¶ÇÊûú‰∏çÂêåÂ∞±ÊòØ0 ÁΩëÁªúÁöÑÂùêÊ†áËΩ¥ÊòØ‰ªÄ‰πà Âú®Ëøô‰∏™ÈóÆÈ¢ò‰∏≠ÔºåÊòØ‰∏§‰∏™ÂçïËØçÁöÑÂêÑ‰∏™Â≠óÊØç Ê≥®ÊÑèÂú®Ëøô‰∏™ÈóÆÈ¢òÈáåÈù¢ÔºåÊúÄÁªàÁ≠îÊ°à‰∏çÊòØÂú®ÊúÄÂêéÂá∫Áé∞ÁöÑ ÊúÄÈïøÂÖ¨ÂÖ±Â≠óÂ∫èÂàóÔºÅÔºÅÂíåÂ≠ê‰∏≤‰∏ç‰∏ÄÊ†∑ÔºåÂØπÊØîÁöÑÊòØÂ∫èÂàóËÄå‰∏çÊòØÂ≠óÊØçÁöÑ‰∏™Êï∞ ÂΩìÂ≠óÊØç‰∏çÂêåÁöÑÊó∂ÂÄôÔºåÈÄâÊã©‰∏äËæπÊàñËÄÖÂ∑¶ËæπÊúÄÂ§ßÁöÑÈÇ£‰∏™ Â∫îÁî® levenshtein distanceÔºàÂ≠óÁ¨¶‰∏≤ÁöÑÁõ∏‰ººÁ®ãÂ∫¶Ôºå‰πüÂ∞±ÊòØ‰∏äÈù¢ÁöÑÂÖ¨ÂÖ±Â≠êÂ∫èÂàóÔºâ ÊåáÂá∫Êñá‰ª∂ÁöÑÂ∑ÆÂºÇÔºåDNAÁöÑÁõ∏‰ººÊÄßÔºåÁ°ÆÂÆö‰ªÄ‰πàÂú∞ÊñπÊñ≠Â≠ó Ê†∏ÂøÉÊÄùÊÉ≥ÔºöÈúÄË¶ÅÊää‰∏§‰∏™strÈáåÈù¢ÊâÄÊúâÁöÑsubstrÁöÑcombinationÈÉΩËÆ°ÁÆó‰∏Ä‰∏ã ÂÆûÁé∞ ÂàùÂßãÂåñÊù°‰ª∂ÔºöÊèíÂÖ• ÂÆûÈôÖ‰∏äÊù•ËØ¥‰∏Ä‰∏™Ê†ºÂ≠êÊúâ‰∏âÁßçÊìç‰ΩúÔºåÂà†Èô§ÔºåÊèíÂÖ•ÂíåÁΩÆÊç¢ÔºåËøô‰∏™Ê†ºÂ≠êÈúÄË¶ÅÊîπÂèòÁöÑÊìç‰ΩúÊòØËøô‰∏â‰∏™Êìç‰ΩúÁöÑÊúÄÂ∞èÂÄº Âà†Èô§ = d[i - 1][j] + 1 ÊèíÂÖ• = d[i][j - 1] + 1 ÔºàÁõ∏ÂΩì‰∫éËøô‰∏™ÂçïËØçÁöÑÂâç‰∏Ä‰∏™Â≠óÊØçÔºåÂä†‰∏ä‰∏Ä‰∏™ÊèíÂÖ•ÔºåËøô‰∏§‰∏™Ê≤°ÊúâÊú¨Ë¥®Âå∫Âà´Ôºâ ÊõøÊç¢ = d[i - 1][j - 1] + costÔºåÂÖ∂‰∏≠Ëøô‰∏™costÔºåÂ¶ÇÊûú‰∏§‰∏™Áõ∏ÂêåÂ∞±ÊòØ0Ôºå‰∏§‰∏™‰∏çÂêåÂ∞±ÊòØ1 ÂÖ∑‰ΩìËØ¥ÊòéËßÅlevenshtein distanceËØ¥Êòé Á¨¨ÂçÅÁ´† KÊúÄËøëÈÇªÂàõÂª∫Êé®ËçêÁ≥ªÁªü ÂêëËøô‰∏™‰∫∫Êé®ËçêÁîµÂΩ±ÔºåÊâæÂà∞Á¶ªËøô‰∏™‰∫∫ÊúÄËøëÁöÑ‰∫î‰∏™Áî®Êà∑ Â¶Ç‰ΩïÂà§Êñ≠ÊúÄËøëÔºöÁâπÂæÅÊäΩÂèñ Á¨¨ÂçÅ‰∏ÄÁ´† Êé•‰∏ãÊù•Â¶Ç‰ΩïÊ†ëÔºàÊï∞ÊçÆÂ∫ì + È´òÁ∫ßÊï∞ÊçÆÁªìÊûÑÔºâ ‰∫åÂèâÊü•ÊâæÊ†ëÔºöÂØπ‰∫éÊØè‰∏Ä‰∏™ËäÇÁÇπÔºåÂ∑¶ËäÇÁÇπÈÉΩÊØî‰ªñÂ∞èÔºåÂè≥ËäÇÁÇπÈÉΩÊØî‰ªñÂ§ß Êó∂Èó¥Â§çÊùÇÂ∫¶ logn Âπ≥Ë°°ÈóÆÈ¢ò Âª∂‰º∏Ôºö BÊ†ëÔºåÁ∫¢ÈªëÊ†ëÔºåÂ†ÜÔºåÂª∂Â±ïÊ†ë ÂèçÂêëÁ¥¢Âºï ÊêúÁ¥¢ÂºïÊìéÁöÑÂ∑•‰ΩúÂéüÁêÜ ÊääÁΩëÈ°µÂàõÂª∫hashË°®ÔºåkeyÊòØÂçïËØçÔºåvalueÊòØÂåÖÂê´ÂçïËØçÁöÑÈ°µÈù¢ ÂÇÖÈáåÂè∂ÂèòÊç¢ ‰ø°Âè∑Â§ÑÁêÜ Âπ∂Ë°åÁÆóÊ≥ïÔºàÊèêÈ´òÈÄüÂ∫¶Ôºâ ÂØπÈÄüÂ∫¶ÁöÑÊèêÂçáÊòØÈùûÁ∫øÊÄßÁöÑ Âπ∂Ë°åÁÆ°ÁêÜÂºÄÈîÄ Ë¥üËΩΩÂùáÂåÄ MapReduce ÂàÜÂ∏ÉÂºèÁÆóÊ≥ï Êää‰∏ÄÂè∞ÁîµËÑë‰∏äÈù¢Â§ÑÁêÜÁöÑÂ∑•‰ΩúÂàÜÂ∏ÉÂà∞Â§öÂè∞ÁîµËÑëÔºåÂ§ÑÁêÜÂ§ßÈáèÊï∞ÊçÆ ÂàÜÂ∏É+ÂΩíÂπ∂ Â∏ÉÈöÜËøáÊª§Âô® Ê¶ÇÁéáÂûãÊï∞ÊçÆÁªìÊûÑÔºöÂèØËÉΩÂá∫Áé∞ÈîôÊä•Ôºå‰ΩÜÊòØ‰∏çÂèØËÉΩÂá∫Áé∞ÊºèÊä• ÂÇ®Â≠òÁ©∫Èó¥ÂæàÂ∞ë HyperLogLog Á±ª‰ºº‰∫éÂ∏ÉÈöÜËøáÊª§Âô®ÁöÑÁÆóÊ≥ïÔºå‰∏çËÉΩÁªôÂá∫ÂáÜÁ°ÆÁöÑÁ≠îÊ°à‰ΩÜÊòØÂç†ÊçÆÁöÑÁ©∫Èó¥ÂæàÂ∞è SHA Âè¶‰∏ÄÁßçhashÔºåÂÆâÂÖ®Êï£ÂàóÁÆóÊ≥ïÔºåÁªôÂÆö‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤ËøîÂõûhash ÊØîËæÉÂ§ßÂûãÊñá‰ª∂ Ê£ÄÊü•ÂØÜÁ†Å Â±ÄÈÉ®‰∏çÊïèÊÑüÔºå‰øÆÊîπÂÖ∂‰∏≠‰∏Ä‰∏™Â≠óÁ¨¶Ôºå‰ºöÊîπÂèòÂæàÂ§ö Diffie-Hellman ÂØÜÈí•‰∫§Êç¢ Â¶Ç‰ΩïÂØπÊ∂àÊÅØÂä†ÂØÜÔºåËÆ©Âè™ÊúâÊî∂‰ª∂‰∫∫ÁúãÂæóÊáÇ Á∫øÊÄßËßÑÂàí Âú®ÁªôÂÆöÁöÑÁ∫¶ÊùüÊù°‰ª∂‰∏ãÊúÄÂ§ßÈôêÂ∫¶ÁöÑÊîπÂñÑÊåáÂÆöÁöÑÊåáÊ†á]]></content>
      <categories>
        <category>ÁÆóÊ≥ï</category>
        <category>ÁÆóÊ≥ïÂõæËß£</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SVD]]></title>
    <url>%2F2019%2F07%2F16%2FSVD%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[fusion360]]></title>
    <url>%2F2019%2F06%2F26%2Ffusion360%2F</url>
    <content type="text"><![CDATA[Áªô‰∫àÁâπÂæÅ Êãâ‰º∏Êåá‰ª§ ‰øÆÈ•∞Â§ñÂΩ¢ ‰øÆÊîπËæπÁºò ÂúÜËßí ÂÄíËßí Â§ñËßÇÂ§ÑÁêÜ ÈÄâÊã©Ë¥¥Âõæ Âè≥ÈîÆÈÄâÊã©Â§ñËßÇ ÂèØ‰ª•ÈÄâÊã©Âä†Âà∞Èù¢‰∏äÈù¢ÊàñËÄÖÂä†Âà∞ÊâÄÊúâ‰∏úË•ø‰∏äÈù¢ renderÔºà3DÊ®°Âûã2DÂåñÔºâ ‰ªémodelÊîπÊàêÊ∏≤Êüì ÁÇπÈÇ£‰∏™Âè∞ÁÅØÔºå‰øÆÊîπÂõæÁâáÁöÑÂú∫ÊôØËÆæÁΩÆÔºåÊØîÂ¶ÇÈ´òÂÆΩÊØî ÊâÄÊúâ‰∏úË•øÈÉΩÂºÑÂ•Ω‰∫Ü‰πãÂêéÁõ¥Êé•Ê∏≤ÊüìÔºåÊ∏≤ÊüìÂà∞Ëá™Â∑±Êª°ÊÑèÁöÑÂú∞Êñπ ÁîªËçâÂõæ ÂèØ‰ª•ÊääÂèÇËÄÉÁöÑÂõæÊîæÂú®Âπ≥Èù¢‰∏äÊù•ÔºåËøôÊ†∑ÁîªËµ∑Êù•ÊØîËæÉËΩªÊùæÔºàÊèíÂÖ•Ôºâ ÈúÄË¶ÅÊ†°ÂáÜÂä†ËøõÂéªÂõæÁâáÁöÑÊØî‰æã ‰øÆÂª∫ÂÅèÁßª‰πãÁ±ªÁöÑÂØπÊ†áCAD ÁîªÊõ≤Á∫ø Áõ¥Êé•ÂÖ≥ÈîÆÁÇπÁîªÊõ≤Á∫øÔºåÂèØ‰ª•ÂÜçË∞ÉÊï¥ Âá†‰ΩïÂÖ≥Á≥ªÈù†ËÆ°ÁÆóÊù• ÂíñÂï°ÊùØ ÊùØË∫´ ÊóãËΩ¨‰ΩìÊàêÂûã ÊùØÁõñ Êñ∞Âª∫Êñ∞ÁöÑÈõ∂ÈÉ®‰ª∂ ‰øÆÊîπ ‚Äì ÂêàÂπ∂ÔºàÁõ∏‰∫§ËøêÁÆó ËçâÂõæ ‚Äì ÊäïÂΩ±ÔºåÂèØ‰ª•ÊääÂÖ∂‰ªñÁöÑ‰∏úË•øÊäïÂΩ±Âà∞Áé∞Âú®ÁöÑÂπ≥Èù¢]]></content>
      <categories>
        <category>CAD</category>
        <category>Fusion360</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[libProCamÁ¨îËÆ∞]]></title>
    <url>%2F2019%2F06%2F25%2FlibProCam%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Binarizer.cppËøô‰∏™ÈÉ®ÂàÜÊòØÊù•ËÆ°ÁÆóÂõæÂÉèÁöÑbinaryÁöÑÔºåÂåÖÊã¨ ËÆ°ÁÆóËøô‰∏™ÂõæÁâáÁöÑthreshold ÂÅöËÉåÊôØsubstract CppÁõ∏ÂÖ≥ ÊûÑÈÄ†ÂáΩÊï∞ ÊûÑÈÄ†‰∏Ä‰∏™Á±ªÁöÑÊó∂ÂÄô‰ΩøÁî®ÁöÑÂáΩÊï∞ÔºåËøô‰∏™ÂáΩÊï∞ÁöÑÂêçÂ≠óÂíåÁ±ªÂêçÁõ∏ÂêåÔºåÈªòËÆ§ÊòØÊ≤°ÊúâÂèÇÊï∞ÁöÑÔºåÂèØ‰ª•Ëá™Â∑±Âä†‰∏äÂèÇÊï∞ÔºåËøôÊ†∑ÂàõÂª∫ÂØπË±°ÁöÑÊó∂ÂÄôÂ∞±ÈúÄË¶ÅÁªôÂèÇÊï∞ ÂØπÊ†ápythonÈáåÈù¢ÁöÑinit ÊûêÊûÑÂáΩÊï∞ ÂêçÂ≠óÂíåÊûÑÈÄ†ÂáΩÊï∞ÂÆåÂÖ®Áõ∏ÂêåÔºå‰ΩÜÊòØÂú®ÂâçÈù¢Â¢ûÂä†‰∫Ü‰∏Ä‰∏™Ê≥¢Êµ™Á∫øÔºåÊ≤°ÊúâËøîÂõûÂÄº‰πüÊ≤°ÊúâÂèÇÊï∞ÔºåÂè™ÊòØÁî®Êù•Âú®ÂÖ≥Èó≠Á®ãÂ∫èÁöÑÊó∂ÂÄôÈáäÊîæËµÑÊ∫ê ËôöÂáΩÊï∞ ÂÄüÂä©ÊåáÈíàÊù•ËææÂà∞Â§öÊÄÅÁöÑÊïàÊûú ÂÆö‰πâ‰∏Ä‰∏™ÂáΩÊï∞ÊòØËôöÂáΩÊï∞Ôºå‰∏ç‰ª£Ë°®Ëøô‰∏™ÂáΩÊï∞‰∏çË¢´ÂÆûÁé∞ÔºåËÄåÊòØ‰ª£Ë°®Âü∫Á±ªÁöÑÊåáÈíàÂèØ‰ª•Ë∞ÉÁî®Â≠êÁ±ªÁöÑËøô‰∏™ÂáΩÊï∞ Â¶ÇÊûúÂÆö‰πâ‰∏∫Á∫ØËôöÂáΩÊï∞ÔºåÊâçËØ¥Êòé‰∏ç‰ºöÂÆûÁé∞ ÊØîÂ¶Ç‰∏ãÈù¢ÁöÑ‰æãÂ≠êÈáåÈù¢ÔºåBÊòØÂ≠êÁ±ªÔºåAÊòØÂü∫Á±ªÔºåÂàõÂª∫ÁöÑÊòØAÁöÑÊåáÈíàÔºå‰ΩÜÊòØË∞ÉÁî®ÁöÑÂç¥ÊòØBÁöÑÂáΩÊï∞ÔºåËøôËØ¥ÊòéËøô‰∏™ÂáΩÊï∞ÁöÑË∞ÉÁî®‰∏çÊòØÂú®ÁºñËØëÁöÑÊó∂ÂÄôË¢´Á°ÆÂÆöÁöÑÔºåËÄåÊòØÂú®ËøêË°åÁöÑÊó∂ÂÄôË¢´Á°ÆÂÆöÁöÑ12345678910111213141516171819202122class A&#123;public: virtual void foo() &#123; cout&lt;&lt;"A::foo() is called"&lt;&lt;endl; &#125;&#125;;class B:public A&#123;public: void foo() &#123; cout&lt;&lt;"B::foo() is called"&lt;&lt;endl; &#125;&#125;;int main(void)&#123; A *a = new B(); a-&gt;foo(); // Âú®ËøôÈáåÔºåaËôΩÁÑ∂ÊòØÊåáÂêëAÁöÑÊåáÈíàÔºå‰ΩÜÊòØË¢´Ë∞ÉÁî®ÁöÑÂáΩÊï∞(foo)Âç¥ÊòØBÁöÑ! return 0;&#125; Á∫ØËôöÂáΩÊï∞ÔºåÂú®ÂáΩÊï∞ÁöÑÂÆö‰πâÂêéÈù¢Âä†‰∏ä =0 ÁªèÂ∏∏‰ºöÂú®ÂÆö‰πâÂü∫Á±ªÁöÑÊó∂ÂÄôÁî®Á∫ØËôöÂáΩÊï∞ÔºåÂõ†‰∏∫Âü∫Á±ªÂèØËÉΩÊúâÂæàÂ§öÁöÑÊ¥æÁîüÔºå‰ΩÜÊòØÂü∫Á±ªÊú¨Ë∫´ÁîüÊàêÁöÑÂØπË±°ÂèØËÉΩÊòØ‰∏çÂêàÁêÜÁöÑ ÊØîÂ¶ÇÂä®Áâ©ÂèØ‰ª•Ê¥æÁîüÁãÆÂ≠êËÄÅËôéÔºå‰ΩÜÊòØÂä®Áâ©Êú¨Ë∫´‰∏çÊòØÂæàÂêàÁêÜ Âú®Â≠êÁ±ªÈáåÈù¢ÂøÖÈ°ªÈáçÊñ∞Â£∞ÊòéËøô‰∏™ÂáΩÊï∞Ôºå‰πüÂ∞±ÊòØËØ¥Âú®Â≠êÁ±ªÁöÑÊó∂ÂÄôÂøÖÈ°ªÊèê‰æõ‰∏Ä‰∏™Ëøô‰∏™ÂáΩÊï∞ÁöÑÂÆûÁé∞Ôºå‰ΩÜÊòØÂü∫Á±ªÁöÑ‰ΩúËÄÖ‰∏çÁü•ÈÅì‰Ω†ÊÄé‰πàÂÆûÁé∞ÂÆÉ]]></content>
      <categories>
        <category>Á†îÁ©∂ÂÆ§</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[‰∏Ä‰∫õOpenCVÈáåÈù¢‰πãÂâçÊ≤°Áî®Âà∞ÁöÑÂáΩÊï∞]]></title>
    <url>%2F2019%2F06%2F20%2F%E4%B8%80%E4%BA%9BOpenCV%E9%87%8C%E9%9D%A2%E4%B9%8B%E5%89%8D%E6%B2%A1%E7%94%A8%E5%88%B0%E7%9A%84%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Áúã‰∫ÜÂà´‰∫∫ÂÜôÁöÑ‰ª£Á†ÅÔºåÊÑüËßâÂ•ΩÂ§öopenCVÈáåÈù¢ÁöÑÂü∫Á°ÄÂäüËÉΩÊàëÈÉΩ‰∏çÁü•ÈÅìÔºåÂΩìÊó∂ËøòÊòØÂú®Ëá™Â∑±ÂÜôÁöÑÔºåÊØîÂ¶ÇÈôçÂô™ÂïäÔºåÂáèÂéªËÉåÊôØÂïäÁ≠âÁ≠âÁöÑ ÂÖ≥‰∫éËΩΩÂÖ•Ê®°ÂûãÁúã‰∫Ü‰∏Ä‰∏™Github‰∏äÈù¢ÁöÑÈ°πÁõÆÔºåÊòØËá™Â∑±ËÆ≠ÁªÉ‰∫Ü‰∏Ä‰∏™‰∫î‰∏™ÊâãÂäøÁöÑËØÜÂà´ÔºåÁÑ∂ÂêéÁî®Ëøô‰∫õÊâãÂäøÊù•ÊéßÂà∂Ëá™Â∑±Â±ãÂ≠êÈáåÈù¢ÁöÑÁÅØÂÖâÂèòÂåñÔºåÁî®kerasËÆ≠ÁªÉÁöÑÊâÄ‰ª•ÂÖàËΩΩÂÖ•‰∫ÜËøô‰∏™ÁöÑÊ®°ÂûãÔºåÁÑ∂ÂêéÊúâ‰∏§‰∏™‰∏çÂêåÁöÑÈ¢ÑÊµãÁöÑÂáΩÊï∞ Á¨¨‰∏Ä‰∏™ÂáΩÊï∞Áî®‰∫Ümodel.predict_classesÔºåËøô‰∏™ÂáΩÊï∞È¢ÑÊµãÂá∫Êù•ÁöÑÁõ¥Êé•ÊòØÁ±ªÂà´ÔºåÊâìÂç∞Âá∫Êù•ÁöÑÂ∞±ÊòØÁ±ªÂà´ÁöÑÁºñÂè∑ Á¨¨‰∫å‰∏™Áî®ÁöÑÊòØmodel.predictÔºåËøô‰∏™È¢ÑÊµãÂá∫Êù•ÁöÑÊòØ‰∏Ä‰∏™Êï∞Â≠óÔºå‰∏çËÉΩÁõ¥Êé•Áî®ÔºåËøòÈúÄË¶ÅÊääËøô‰∏™Êï∞ÂÄºargmax(predict_test,axis=1)ÊâçÂèØ‰ª•Áî®Ôºà‰πüÂ∞±ÊòØÊâæÂà∞ÊúÄÂ§ßÁöÑÔºâ createBackgroundSubtractorMOG2()retval = cv.createBackgroundSubtractorMOG2( [, history[, varThreshold[, detectShadows]]] ) ÂàõÂª∫‰∫Ü‰∏Ä‰∏™MOG2ÁöÑbackground substructor ÂèÇÊï∞ÂàÜÂà´ÊòØ historyÁöÑÈïøÂ∫¶ ËÆ°ÁÆóÁöÑÊòØÊõºÂìàÈ°øË∑ùÁ¶ªÔºåËøô‰∏™ÁöÑÈòàÂÄº ÊòØÂê¶Ê£ÄÊµãÂΩ±Â≠êÔºåÂ¶ÇÊûúÊ£ÄÊµãÁöÑËØùÈÄüÂ∫¶ÂõûÊÖ¢‰∏ÄÁÇπ ÂàõÂª∫ÂÆåÁöÑÊ®°ÂûãÊúâÂæàÂ§öÂäüËÉΩ ËøôÈáåÁî®Âà∞‰∫Ü‰∏Ä‰∏™applyÔºåÂ∞±ÊòØÂØπ‰∏ÄÂº†ÂõæËøõË°åËøô‰∏™Êìç‰ΩúÔºåÊù•ËÆ°ÁÆóÂá∫ËøôÂº†ÂõæÁâáÁöÑforeground ËøôÈáåÊúâ‰∏Ä‰∏™ÂèÇÊï∞Âè´learning rateÔºåÊåáÁöÑÊòØ‰Ω†ÁöÑËøô‰∏™Ê®°Âûã‰ºö‰∏ç‰ºöÈöèÁùÄÊó∂Èó¥ËÄåÊîπÂèòÔºå0ÁöÑËØùÂ∞±ÊòØ‰∏çÂèòÔºå1ÁöÑËØùÂ∞±ÊòØÂÆåÂÖ®Áî±‰∏ä‰∏ÄÂ∏ßÂΩ¢ÊàêÔºåÁÑ∂ÂêéË¥üÊï∞ÁöÑËØù‰ºöËá™Âä®ÈÄâÊã©‰∏Ä‰∏™ bitwise_and()dst = cv.bitwise_and( src1, src2[, dst[, mask]] ) ËøôÈáåËÆ°ÁÆó‰∫ÜÊØè‰∏Ä‰ΩçÁöÑ‰∏éÔºàandÔºâËÆ°ÁÆóÔºåÂä†‰∏ä‰∫Ü‰∏Ä‰∏™ÂèØÈÄâÁöÑÂèÇÊï∞maskÔºåËøôÊ†∑ÂèØ‰ª•Áõ¥Êé•ËÆ°ÁÆóÂá∫Êù•ÂâçÊôØÂéªÊéâËÉåÊôØ videoCapture.set()dst = cv.bitwise_and( src1, src2[, dst[, mask]] ) ËøôÈáå‰ªñÁöÑ‰ª£Á†ÅÊ≤°ÊúâÁî®Â±ûÊÄßÔºåÁõ¥Êé•ËÆæÁΩÆ‰∫Ü‰∏§‰∏™Êï∞Â≠óÔºåÊØè‰∏™Êï∞Â≠ó‰ºö‰ª£Ë°®‰∏Ä‰∏™Â±ûÊÄßÔºåÊï∞Â≠óÁöÑËåÉÂõ¥ÊòØ0-18 ‰πüÂ∞±ÊòØËØ¥Â•πËÆæÁΩÆ‰∫Ü10Ëøô‰∏™Â±ûÊÄßÔºåÁÑ∂ÂêéÊääËøô‰∏™Â±ûÊÄßÁöÑÂ§ßÂ∞èËÆæÁΩÆÊàê‰∫Ü200 cv2.bilateralFilter(frame, 5, 50, 100) ‰∏Ä‰∏™Âè´Ëøô‰∏™ÂêçÂ≠óÁöÑÊª§ÈïúÔºåÂèØ‰ª•Ê∂àÈô§ÊéâÂõæÁâáÈáåÈù¢‰Ω†‰∏çÊÉ≥Ë¶ÅÁöÑÂô™Èü≥ ÊïàÊûúÊØîËæÉÂ•ΩÔºåÂèØ‰ª•Âú®Ê∂àÈô§Âô™Èü≥ÁöÑÂêåÊó∂‰øùËØÅÂõæÂÉèÊØîËæÉÊ∏ÖÊô∞Ôºå‰ΩÜÊòØ‰∏éÊ≠§ÂêåÊó∂Ëøô‰∏™filterÁöÑÈÄüÂ∫¶‰ºöÊØîÂ§ßÂ§öÊï∞ÁöÑÊÖ¢‰∏Ä‰∫õ ÂõæÂÉèÁøªËΩ¨ flip ‰∏§‰∏™ÂèÇÊï∞ÔºåÁøªËΩ¨ÁöÑÂõæÂÉè‰ª•ÂèäÁøªËΩ¨ÂèÇÊï∞ 0ÊòØÁ´ñÁõ¥ÁøªËΩ¨Ôºå1ÊòØÊ∞¥Âπ≥ÁøªËΩ¨ÔºåÂ∞è‰∫é0ÁöÑÊó∂ÂÄôÊòØÊóãËΩ¨180Â∫¶ÔºàÂÖàÁ´ñÁõ¥ÂÜçÊ∞¥Âπ≥ÁøªËΩ¨Ôºâ inRangedst = cv.inRange( src, lowerb, upperb[, dst] ) Êü•ÁúãÊòØÂê¶ÊúâÊï∞Â≠óÂú®Ëøô‰∏™ËåÉÂõ¥ÈáåÈù¢Ôºå‰∏â‰∏™channelÈÉΩÂú®ÁöÑËØùÂ∞±ËæìÂá∫1Ôºå‰∏çÂú®ÁöÑËØùÂ∞±ËæìÂá∫0 ÂèØ‰ª•Áªô‰∏çÂêåÁöÑchannelËµã‰∏çÂêåÁöÑÂÄº calcHisthist = cv.calcHist( images, channels, mask, histSize, ranges[, hist[, accumulate]] ) ËÆ°ÁÆó‰∏ÄÁ≥ªÂàóËæìÂÖ•ÁöÑhistogram ÂéüÊù•ÊúâËøô‰∏™ÂáΩÊï∞ÔºåÊääËøô‰∏™ËæìÂÖ•normalizeÂà∞255‰∏™channel‰∏äÈù¢Â∞±ËÉΩÂæóÂà∞ÔºåËøôÊ†∑Â∞±ÂèØ‰ª•ÂæóÂà∞ËøôÂº†ÂõæÁâáÈáåÈù¢ÁöÑÂàÜÂ∏É‰∫Ü ËÄå‰∏îËÄÉËôë‰∫Ü‰∏äÈù¢ÁöÑmaskÁöÑÊÉÖÂÜµ calcBackProjectÔºàÂ≠òÁñëÔºÅÔºâdst = cv.calcBackProject( images, channels, hist, ranges, scale[, dst] ) ËÆ°ÁÆó‰∏Ä‰∏™histÁöÑback projection CamShift()]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>OpenCV</category>
      </categories>
      <tags>
        <tag>OpenCv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ËÆ∫ÊñáTouch180]]></title>
    <url>%2F2019%2F06%2F17%2F%E8%AE%BA%E6%96%87Touch180%2F</url>
    <content type="text"><![CDATA[Touch180: Finger Identification on Mobile Touchscreen using Fisheye Camera and Convolutional Neural Networkabstract È±ºÁúº+Ê∑±Â∫¶Â≠¶‰π†ÔºåËØÅÊòéÊ£ÄÊµãÊâãÊåáÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß ÁîüÊàê‰∫Ü‰∏Ä‰∏™dataset ËÆ≠ÁªÉ‰∫Ü‰∏Ä‰∏™CNNÔºåÁ°ÆÂÆöÊâãÊåátouchÁöÑ‰ΩçÁΩÆ intro ÂèØ‰ª•ÈÄöËøáÁªô‰∏çÂêåÁöÑÊâãÊåá‰∏çÂêåÁöÑËÅåË¥£Êù•Â¢ûÂº∫ÂØπËß¶Êë∏Â±èÁöÑ‰ΩøÁî® ‰ª•ÂâçÁöÑÂàÜÂà´ÊâãÊåáÁöÑËÆ∫Êñá wearable device -&gt; ÊØîËæÉË¥µ Á°ÆÂÆöËß¶Êë∏ÁöÑÂå∫Âüü -&gt; ÂøÖÈ°ªÂ§ö‰∏™ÊâãÊåáËß¶Êéß ËøòÊúâ‰∏Ä‰∏™ÊñπÊ≥ïÊòØÂú®Êâã‰∏äÊà¥‰∏ä‰∫Ü‰∏Ä‰∏™ÊúâÈ¢úËâ≤ÁöÑÊàíÊåáÔºàËØ∂Ëøô‰∏™ÊñπÊ≥ïÁî®Êù•ÂÆûÁé∞Áé∞Âú®ÁöÑdeviceÁöÑÁîªÁîªÂäüËÉΩÊÑüËßâÊÄé‰πàÊ†∑Ôºâ Áî®‰∫ÜÊ∑±Â∫¶Áõ∏Êú∫ÁöÑ -&gt; ‰∏çÈÄÇÂêàmobile device ÂÖ∂‰ªñÁî®CNNÁöÑÊ≤°Êúâ‰ΩøÁî®È±ºÁúºÁõ∏Êú∫ dataset Áõ¥Êé•Áî®‰∏çÂêåÁöÑframeÊù•ÂÅöÁöÑdataset Áî®‰∫î‰∏™‰∫åËøõÂà∂ÁöÑÊï∞Â≠óÊù•Ë°®Á§∫labeling net]]></content>
      <categories>
        <category>Papers</category>
        <category>È±ºÁúºÊâãÂäøËØÜÂà´</category>
      </categories>
      <tags>
        <tag>fisheye</tag>
        <tag>hand</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[unityÂÖ•Èó®Âà∂‰Ωúspace shooter]]></title>
    <url>%2F2019%2F06%2F13%2Funity%E5%85%A5%E9%97%A8spaceshooter%2F</url>
    <content type="text"><![CDATA[ÁõÆÊ†á Ëøô‰∏™Ê∏∏ÊàèÊòØÂíåÈõ∑ÁîµÁ±ª‰ººÁöÑÊ∏∏Êàè ÈúÄË¶ÅËÆæÂÆöÁ¢∞ÊíûÁ≠âÁ≠âÊ∏∏ÊàèÈÄªËæëÔºåÁÑ∂ÂêéËÆæËÆ°Èü≥‰πêÔºåÂõæÁ≠âÁ≠â‰∏úË•ø setupÔºåplayerÔºåcameraset up ÈúÄË¶ÅÁ°ÆÂÆöÂ•ΩÂ∫îÁî®ÁöÑÂºÄÂèëÂπ≥Âè∞file-build setting Ê≥®ÊÑèËøô‰∏™Ê∏∏ÊàèÊÉ≥ÂºÄÂèëÁΩëÈ°µÁâàÁöÑÔºå‰ΩÜÊòØÁé∞Âú®Â∑≤Áªè‰∏çÊîØÊåÅweb playerÔºåÂª∫ËÆÆ‰ΩøÁî®web GL ÂèØ‰ª•Âú®project setting-playerÈáåÈù¢ÊîπÂèò‰∏Ä‰∫õÊ∏∏ÊàèÁöÑËÆæÁΩÆÔºàËøôÈáåÊîπÂèò‰∫ÜÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶Ôºâ Âú®Âè≥‰∏äËßíÁöÑlayoutÂèØ‰ª•ÊîπÂèòÁ™óÂè£ÁöÑÂ∏ÉÂ±Ä ÊîæÁΩÆÊ∏∏ÊàèÁöÑobject Áõ¥Êé•‰ªémodelÈáåÈù¢ÊãñËøõÊù•ÊîæËøõsceneÊàñËÄÖhierarchyÈáåÈù¢ ÁÇπÂáªFÂèØ‰ª•ÈîÅÂÆöËøô‰∏™‰∏úË•øÔºàÊúÄ‰Ω≥ËßÜËßíÔºâ ÈúÄË¶ÅËÆæÁΩÆËøô‰∏™objectÂú®ÂéüÁÇπ Êúâ‰∏Ä‰∏™mesh filiterÊù•ÂÜ≥ÂÆöËøô‰∏™‰∏úË•øÁî®ÁöÑ‰ªÄ‰πàÊ®°Âûã ‰∏Ä‰∏™mesh rendererÊù•Ê∏≤ÊüìËøô‰∏™Ê®°Âûã Ëøô‰∏™ÈáåÈù¢Êúâ‰∏§‰∏™‰∏çÂêåÁöÑÊùêÊñô Âõ†‰∏∫ÈúÄË¶ÅÁâ©‰Ωì‰πãÈó¥ÁöÑÁ¢∞ÊíûÔºåÊâÄ‰ª•ÈúÄË¶ÅÂ¢ûÂä†physics--rigidbody Âä†ÂÖ•‰∫ÜËøô‰∏™‰∏úË•ø‰πãÂêéÔºåÁâ©‰ΩìÂ∞±Êúâ‰∫ÜÁâ©ÁêÜ‰∏äÁöÑÁâπÂæÅ ‰∏ãÈù¢Áî±‰∫éÈúÄË¶ÅÁ¢∞ÊíûÔºåÊâÄ‰ª•ÈúÄË¶ÅÂÆö‰πâËøô‰∏™Áâ©‰ΩìÁöÑ‰ΩìÁßØ Â¢ûÂä†‰∏Ä‰∏™physics -- capsule collision Áõ∏ÂΩì‰∫éÊääËøô‰∏™Áâ©‰ΩìÁöÑÂë®Âõ¥Âä†‰∏ä‰∫Ü‰∏Ä‰∏™cageÔºåÊù•Á°ÆÂÆö‰ªñÁöÑ‰ΩìÁßØ ÈúÄË¶ÅÂú®ËøôÈáåÈù¢ÂÆö‰πâÁ¢∞ÊíûÁöÑÊñπÂêëÔºàÂõ†‰∏∫ËøôÈáåÈù¢ÊòØÊ≤øÁùÄzËøêÂä®ÁöÑÔºåÊâÄ‰ª•Á¢∞ÊíûÂú®zËΩ¥‰∏äÈù¢Ôºâ ÂèØ‰ª•Êîπ‰∏ÄÊîπËßÜËßíÔºåÁÑ∂ÂêéÁõ¥Êé•ÊãâbarÊù•Ë∞ÉËäÇËøô‰∏™consuleÁöÑÂ§ßÂ∞è ÂÖ≥‰∫écoliider Èô§‰∫ÜËøôÈáåÈù¢Áî®Âà∞ÁöÑËÉ∂ÂõäÂûãÁöÑ‰ª•Â§ñÔºåËøòÊúâsquareÁöÑsphereÁöÑÔºåconfoundÁöÑÔºàÊ∑∑ÂêàÔºâÔºüÔºåÂú®ËÉΩËß£ÂÜ≥ÈóÆÈ¢òÁöÑÊó∂ÂÄôÂ∞ΩÈáèÁî®‰∏äÈù¢ÁöÑÂü∫Á°ÄÂõæÂΩ¢ Èô§Ê≠§‰πãÂ§ñÔºåËøòÊúâ‰∏Ä‰∏™mesh coillderÔºåÁî®Êù•‰∏ìÈó®Â•ëÂêàËøô‰∏™Áâ©‰ΩìÁöÑ‰ΩìÁßØÁöÑÔºå‰ΩÜÊòØÊòØÊúÄÂêéÁöÑÈÄâÊã©ÔºåÈÄâÊã©ÁöÑÊó∂ÂÄôÊúÄÂ•Ω‰πüÈÄâÊã©‰∏Ä‰∫õÊØîËæÉÁÆÄÂçïÁöÑÂΩ¢Áä∂(Â¶ÇÂõæÊâÄÁ§∫ÔºåÊñ∞ÁöÑÁ¢∞ÊíûËåÉÂõ¥‰ºöÂÆåÊï¥Â•ëÂêàËøô‰∏™Áâ©‰Ωì) Âú®coillderÈáåÈù¢ÂèØ‰ª•Ëá™Â∑±ËÆæÂÆöËøô‰∏™ÂØπÂ∫îÁöÑmeshÁöÑÁßçÁ±ªÔºåÂç≥‰ΩøÂíå‰ΩøÁî®ÁöÑÊ®°Âûã‰∏çÂêå‰πüÂèØ‰ª•Ôºà‰πüÂ∞±ÊòØËØ¥ÂèØ‰ª•Âª∫Á´ã‰∏Ä‰∏™Áõ∏ÂØπ‰∫éËøô‰∏™Ê®°ÂûãÁÆÄÂçïÁöÑÊ®°ÂûãÔºåÁÑ∂ÂêéÂª∫Á´ãÁ¢∞ÊíûÔºâ ‰∏∫‰∫ÜÈÄâ‰∏≠ÁöÑËøô‰∏™‰∏úË•øÂèØ‰ª•Ë¢´ËØÜÂà´‰∏∫Á¢∞ÊíûÁâ©‰ΩìÔºåÈÄâÊã©is trigger ‰∏∫‰∫ÜÂ¢ûÂä†‰∏ÄÁÇπÁ•ûÂ•áÁöÑÊñ∞ÂäüËÉΩÔºåÂú®È¢ÑËÆæÂ•ΩÁöÑprefabÔºà‰∏Ä‰∏™ÂèØ‰ª•ÈáçÂ§çÂÖãÈöÜÁöÑÂØπË±°ÔºâÈáåÈù¢ÊâæÂà∞‰∏Ä‰∏™ÂºïÊìéÁöÑÂä®ÁîªÔºåÊãñÂà∞playerÁöÑÂ≠êÁõÆÂΩï‰∏ãÈù¢ÔºåËøô‰∏™‰∏úË•øÂ∞±Ëá™Âä®Âä†ËøõÂéª‰∫Ü Áõ∏Êú∫ÂíålightÁõ∏Êú∫ Âõ†‰∏∫‰∏ÄÂºÄÂßãÁõ∏Êú∫‰ºöÂàùÂßãÂåñÂú®Áâ©‰Ωì‰πãÂêéÁöÑ‰ΩçÁΩÆÔºåÊâÄ‰ª•Áé∞Âú®Âú®gameÁïåÈù¢Âè™ËÉΩÁúãÂà∞Ëøô‰∏™Áâ©‰ΩìÁöÑÂ±ÅËÇ°ÈÉ®ÂàÜÔºåÈúÄË¶ÅËÆæÁΩÆÁõ∏Êú∫ ÁÇπÂáªmain cameraÔºåËøôÊó∂ÂÄôÂè≥‰∏ãËßí‰ºöÂá∫Áé∞Áõ∏Êú∫‰ΩçÁΩÆÁöÑÁº©Áï•Âõæ ‰ΩçÁΩÆ -&gt; Ë∞ÉËäÇÂà∞Áâ©‰Ωì‰∏äÊñπÔºåÂπ∂‰∏îÊóãËΩ¨90Â∫¶ ËÆæÁΩÆÁõ∏Êú∫ÁöÑÁßçÁ±ª Â¶ÇÊûúÈÄâÊã©perspectiveÁöÑÁõ∏Êú∫ÔºåÂèØ‰ª•ÈÄöËøáË∞ÉËäÇFOVÊù•ÂÜ≥ÂÆöÁúãÂà∞ÁöÑÊòØÂ§öÂ§ß ËøôÈáåÈÄâÊã©orthographicÔºàÊ≠£ÊäïÂΩ±Ôºå‰∏ªËßÜÂõæÈÇ£ÁßçÊÑüËßâÔºâÁöÑÁõ∏Êú∫ÔºåÁÑ∂ÂêéÁõ¥Êé•Ë∞ÉËäÇÁúãÂà∞ÁöÑsizeÂ∞±ÂèØ‰ª•‰∫Ü Âõ†‰∏∫Â∏åÊúõobject‰øùÊåÅÂú®ÂéüÁÇπ‰∏äÔºåÊâÄ‰ª•Âú®ËøôÈáåÁßªÂä®camera ÂèØ‰ª•Âú®gameÁîªÈù¢ÈáåÈù¢Áõ¥Êé•Ë∞ÉËäÇobjectÁöÑ‰ΩçÁΩÆÁ≠âÁ≠â‰∏úË•ø ‰∏ãÈù¢ÊääÂú®cameraÈáåÈù¢ÊääËÉåÊôØÊîπÊàêÈªëËâ≤Ôºàsoild colorÔºâ ‰ΩÜÊòØËøôÊó∂ÂÄôobjectÁöÑÈ¢úËâ≤Âπ∂Ê≤°ÊúâÂèòÈªëÔºåËøôÊòØÂõ†‰∏∫ÊâìÂºÄ‰∫Üambiant light Âú®window--rendering--lighting settingÈáåÈù¢ÔºåÊääsourceÊîπÊàêcolorÂ∞±ÂèØ‰ª•ÊîπÂèòÁéØÂ¢ÉÂÖâÁöÑÈ¢úËâ≤ ÁéØÂ¢ÉÂÖâÔºöambient light Ëøô‰∏™ÂÖâÊ≤°ÊúâÊñπÂêëÔºåÊâÄ‰ª•Â¶ÇÊûúÈÉΩÂä†‰∏ä‰∫ÜÁöÑËØùÂèØËÉΩ‰ºöÂæàÂ•áÊÄ™ ÂÖâ ÂàõÂª∫‰∏Ä‰∏™ÊúâÊñπÂêëÁöÑlight -&gt; main light Â∫îËØ•ÊòØÊúÄ‰∫ÆÁöÑÂÖâ Â∏åÊúõÂèØ‰ª•ÁúãÂà∞È£ûÊú∫ÁöÑÈ¢úËâ≤‰ΩÜÊòØ‰∏çÂ∏åÊúõÂ§™‰∫Æ Ë∞ÉÊï¥Ëøô‰∏™ÂÖâÁöÑËßíÂ∫¶‰ª•ÂèäÂº∫Â∫¶ Âª∫Á´ãÁ¨¨‰∫å‰∏™ÂÖâÔºåÊù•ÁÖß‰∫Æ‰∏çÊÄé‰πà‰∫ÆÁöÑÈÉ®ÂàÜ -&gt; fill light ËøòÊòØË∞ÉÊï¥ËßíÂ∫¶ÔºåÁÖß‰∫ÆÁ¨¨‰∏Ä‰∏™ÂÖâÁÖß‰∏çÂà∞ÁöÑÈÉ®ÂàÜ ‰∏∫‰∫Ü‰∏çËÆ©Ëøô‰∏™ÂÖâÈÇ£‰πàÂº∫ÔºåÊääËøô‰∏™ÂÖâÁöÑÂº∫Â∫¶ÈÄÇÂΩìË∞ÉÂ∞è ‰∏∫‰∫ÜÈÄÇÂ∫îÂ§™Á©∫ÁöÑÂÜ∑Ëâ≤Ë∞ÉÔºåÊääÂÖâÊ∫êÈ¢úËâ≤ÊîπÊàêËìùÁªøËâ≤ ÊúÄÂêéÂ¢ûÂä†Á¨¨‰∏â‰∏™ÂÖâÔºåÊääÊöóÈÉ®ÂãæËæπÔºàÁõ∏ÂΩì‰∫éÁ¥†ÊèèÈáåÈù¢ÁöÑÂú®Ëæπ‰∏äÁöÑÈ´ò‰∫ÆÈÉ®ÂàÜÔºâ -&gt; rim light ‰∏∫‰∫Ü‰∏çÁÖß‰∫Æ‰∏úË•øÁöÑ‰∏äÂ±ÇÔºåÂú®xËΩ¥ÊääËßíÂ∫¶Ë∞ÉÊàêÂ§çÊï∞ ‰∏∫‰∫ÜÂãæËæπÔºåÈ¢úËâ≤ÊòØÁôΩËâ≤ÁöÑ Èôç‰Ωé‰∫ÆÂ∫¶ ÊúÄÂêéÂª∫Á´ã‰∏Ä‰∏™Êñ∞ÁöÑÁ©∫ÁöÑobjectÔºå‰ΩçÁΩÆresetÂ•ΩÔºåÊù•Êï¥ÁêÜ‰∏äÈù¢ÁöÑ‰∏â‰∏™ÂÖâ Ê≥®ÊÑèÔºåÂõ†‰∏∫ËøôÈáåÁöÑÂÖâÊòØdirectional lightÔºåÊâÄ‰ª•ÂÖâÁÖßÁöÑÊïàÊûúÂíåÂÖâÊ∫êÁöÑ‰ΩçÁΩÆÊó†ÂÖ≥ÔºåÂè™ÂíåÂÖâÊ∫êÁöÑËßíÂ∫¶ÊúâÂÖ≥ ËÉåÊôØ Êñ∞ÂàõÂª∫‰∏Ä‰∏™quadÔºåË∞ÉÊï¥‰ΩçÁΩÆÂíåËßíÂ∫¶ËÆ©Áõ∏Êú∫ËÉΩÁúãÂà∞‰ªñ removeÊéâÁ¢∞ÊíûÁöÑÈÉ®ÂàÜÔºåÂõ†‰∏∫ËÉåÊôØ‰∏çÈúÄË¶Å Âä†‰∏ätexture -&gt; ÂèØ‰ª•Áõ¥Êé•ÊääËøôÂº†ÂõæÁâáÊãΩÂà∞ÂØπÂ∫îÁöÑ‰ΩçÁΩÆ‰∏äÈù¢ ËøôÊ†∑‰ºöÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑmaterialÂä†Âà∞Ëøô‰∏™meshÁöÑrenderer‰∏äÈù¢Âéª Áº©ÊîæËøô‰∏™ÊñπÂùóÔºåËÆ©Ëøô‰∏™ÂõæÁâáÂèØ‰ª•ÂÆåÂÖ®ÊòæÁ§∫ÔºàÈ´òÂÆΩÊØîÂøÖÈ°ª‰øùÊåÅÔºÅÔºâ ËøôÊó∂ÂÄôÁÖßÂú®player‰∏äÈù¢ÁöÑÂÖâ‰πüÂèØ‰ª•ÁÖßÂú®ËÉåÊôØ‰∏äÈù¢Ôºå‰ΩÜÊòØ‰∏çÊòØÂæàÂ∏åÊúõËøôÁßçÁªìÊûú ‰∏ÄÁßçÊñπÊ≥ïÊòØÊääbackgroundÂÆåÂÖ®Áã¨Á´ã‰∏Ä‰∏™layerÂá∫Êù• Âè¶‰∏ÄÁßçÊñπÊ≥ïÊòØÊîπÂèòËøô‰∏™textureÁöÑshader ËøôÈáåÊîπÊàêÂÆåÂÖ®ÁöÑtestureÔºåËøôÊ†∑Â∞±‰∏ç‰ºöÂèóÂà∞ÂÖâÁöÑÂΩ±Âìç‰∫Ü ÊúÄÂêéÊääËàπ‰ªéÈô∑ÂÖ•ÁöÑbackgroundÈáåÊãΩÂá∫Êù• ÁßªÂä®player È¶ñÂÖàÈúÄË¶ÅÂú®playerÂ∫ï‰∏ãÂª∫Á´ãÊñ∞ÁöÑscripts fixedupdate -&gt; Á°ÆÂÆöÁâ©‰ΩìÁé∞Âú®ÁöÑ‰ΩçÁΩÆ È¶ñÂÖàÂæóÂà∞ÂûÇÁõ¥ÂíåÂπ≥Ë°åÁöÑËæìÂÖ•ÔºàÈîÆÁõòÊàñËÄÖÈº†Ê†áËæìÂÖ•Ôºâ Áâ©‰ΩìÁöÑÁßªÂä®ÊòØ‰∏Ä‰∏™‰∏âÁª¥ÁöÑÊï∞ÁªÑÔºåÂàÜÂà´ÊòØxyzËΩ¥ÔºåËøôÈáåyËΩ¥ÁöÑÁßªÂä®ÊòØ0.0fÔºåÂÖ∂‰ªñ‰∏§‰∏™ÂàÜÂà´ÊòØÂπ≥Ë°åÂíåÂûÇÁõ¥ÁöÑÁßªÂä® Âõ†‰∏∫Â∑≤ÁªèÁî®‰∫Ürigid bodyÔºåÂèØ‰ª•‰ªéÈáåÈù¢ÁªôÁâ©‰Ωì‰∏Ä‰∏™ÈÄüÂ∫¶GetComponent&lt;Rigidbody&gt;().velocity -&gt; ËøôÊó∂ÂÄôÁßªÂä®ÁöÑÈùûÂ∏∏ÊÖ¢ÔºåÂõ†‰∏∫inputÊé•Êî∂ÁöÑÂè™ÊòØ0Âíå1ÔºåÊâÄ‰ª•ÊØèÁßíÁßªÂä®‰∏Ä‰∏™unit ËøôÊó∂ÂÄôÂä†‰∏ä‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑspeedÂèÇÊï∞ÔºåÊØèÊ¨°Âú®ËÆ°ÁÆóÈÄüÂ∫¶ÁöÑÊó∂ÂÄô‰πò‰∏äËøô‰∏™ÂèÇÊï∞Â∞±ÂèØ‰ª•‰∫Ü Ê≥®ÊÑèÔºåÂõ†‰∏∫ËøôÈáåÁöÑspeedÊòØ‰∏™publicÁöÑÂÄºÔºåÊâÄ‰ª•ÂèØ‰ª•Áõ¥Êé•Âú®unityÁöÑUIÈáåÈù¢ËøõË°åÊìç‰Ωú ËøôÊó∂ÂÄôÂá∫Áé∞‰∫Ü‰∏Ä‰∏™ÈóÆÈ¢òÔºåplayer‰ºöË∑ëÂá∫Â±èÂπï Â¢ûÂä†‰∏Ä‰∏™Âà§Êñ≠Êù°‰ª∂ÔºåÁßªÂä®Ëøô‰∏™‰∏úË•øÂ¶ÇÊûúÂà∞‰∫ÜËæπÁïåÔºåÈÇ£‰πàÊääposition‰ªéÂÖàresetÂà∞ËæπÁïå‰∏ä Âõ†‰∏∫ËøôÊ†∑Âú®Êõ¥Êñ∞‰∏ã‰∏ÄÂ∏ß‰πãÂâçÈÉΩ‰∏ç‰ºöÂá∫Áïå ‰ΩøÁî®‰∫ÜmathfÈáåÈù¢ÁöÑ‰∏Ä‰∏™ÂáΩÊï∞clampÔºåÊù•ËÆæÂÆöxÂíåzÁöÑËåÉÂõ¥ Ëøô‰∏™ÂáΩÊï∞Ë∂ÖËøá‰∫Ü‰∏ãÁïåÂ∞±‰ºö‰∏ÄÁõ¥ÊòæÁ§∫‰∏ãÁïåÔºåË∂ÖËøá‰∫Ü‰∏äÂ±äÂ∞±‰ºö‰∏ÄÁõ¥ÊòæÁ§∫‰∏äÂ±ä ‰∏∫‰∫Ü‰∏çËÆ©ËÆæÂÆöÁöÑxmaxÔºåxminÔºåzmaxÔºåzminÂú®UIÈáåÈù¢Â§™Âç†Âú∞ÔºåÊâÄ‰ª•Âª∫Á´ã‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑclassÊù•Ë£ÖËøô‰∫õ‰∏úË•øÔºàÊ≥®ÊÑèÊñ∞ÁöÑclass‰∏çÈúÄË¶ÅÁªßÊâøÔºâÔºåÁÑ∂ÂêéÂú®ÈúÄË¶ÅÁî®ÁöÑÊó∂ÂÄôÂª∫Á´ãÊñ∞ÁöÑÂØπË±°Ôºåcall ‰∏∫‰∫ÜËÉΩÂú®UIÈáåÊòæÁ§∫ÔºåÈúÄË¶ÅÂú®Êñ∞ÂàõÂª∫ÁöÑclass‰∏äÈù¢Âä†‰∏ä[System.Serializable] Ëøô‰∫õËæπÁºòËÆæÁΩÆ‰ªÄ‰πàÂÄºÂèØ‰ª•Áõ¥Êé•Êää‰∏úË•øÊãñÂà∞ËæπÁºòÁÑ∂ÂêéÁúãÁúãÊòØ‰ªÄ‰πàÂÄºÂ∞±ÂèØ‰ª•‰∫Ü tiltÊàñËÄÖbankÔºöËÆ©È£ûËàπÂà∞Â∑¶Âè≥ÁßªÂä®ÁöÑÊó∂ÂÄôÂèØ‰ª•ÊóãËΩ¨‰∏Ä‰∏ã Â¢ûÂä†‰∫ÜÊóãËΩ¨ÂäüËÉΩQuaternion.Euler shotsÂ∏åÊúõÊääËøôÈÉ®ÂàÜÁöÑÈÄªËæëÂíåËøôÈÉ®ÂàÜÁöÑÂõæÂÉèÂàÜÈöîÂºÄÔºöËøôÊ†∑Êç¢Ê®°ÂûãÁöÑÊó∂ÂÄôÂ∞±ÂæàÊñπ‰æø‰∫Ü È¶ñÂÖàÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑquanÔºåÂú®Ëøô‰∏™‰∏äÈù¢Âä†‰∏ätexture ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑmaterialÔºåÁÑ∂ÂêéÂÜçËøô‰∏™ÈáåÈù¢ÈÄâÊã©‰∏Ä‰∏™texture ÁÑ∂ÂêéÂÜçÊääÊñ∞ÁöÑmaterialÂä†Âà∞ÂØπÂ∫îÁöÑ‰∏úË•øÈáåÈù¢ Â∏åÊúõËøô‰∏™‰∏úË•øÈªëËâ≤ÁöÑÈÉ®ÂàÜÊ∂àÂ§±ÔºåshaderÈÄâÊã©mobile--particle--addtiveÔºàmobileÊØîËæÉÊúâÊïàÁéáÔºâ Â¢ûÂä†Ëøô‰∏™‰∏úË•øÁöÑÁ¢∞ÊíûÔºåÂéªÊéâVFXÁöÑÁ¢∞Êíû ÁÑ∂ÂêéÂä†‰∏äËøô‰∏™ÂÖâÁöÑËøêÂä®ÈÄªËæë transform.forward()ÂêëÂâçËøêÂä®Ôºå‰πò‰∏äÈÄüÂ∫¶ ÊääËøô‰∏™‰∏úË•øËÆæÂÆöÊàê‰∏Ä‰∏™prefabÔºàÁõ¥Êé•ÊãñÂà∞prefabÁöÑÊñá‰ª∂Â§πÈáåÈù¢Ôºâ shoot shots Â∑≤ÁªèÊääÈúÄË¶ÅÂ∞ÑÂá∫ÂéªÁöÑÂÖâÁ∫øËÆæÂÆöÊàê‰∫Ü‰∏Ä‰∏™prefabÔºåËøôÊó∂ÂÄôÂè™Ë¶ÅÂú®ÊØèÊ¨°ÁÇπÈº†Ê†áÁöÑÊó∂ÂÄôÊääËøô‰∏™‰∏úË•øÂ∞ÑÂá∫ÂéªÂ∞±ÂèØ‰ª•‰∫Ü ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑÁ©∫ÁöÑobject‰Ωú‰∏∫playerÁöÑÂ≠êÁõÆÂΩïÊù•ÂÆö‰πâÂèëÂá∫ÂéªÊøÄÂÖâÁöÑ‰ΩçÁΩÆÔºàshotSpawnÔºâ Âú®player‰∏≠Êñ∞Â¢û‰∏Ä‰∏™ÂäüËÉΩÔºåpublicÁöÑÂØπË±°ÊòØshotÂíåshotSpawnÔºåËøô‰∏§‰∏™‰∏úË•øÈÉΩÂèØ‰ª•Áõ¥Êé•‰ªéUIÈáåÈù¢ÊãñËøõÊù•ÔºåÁÑ∂ÂêéËÆæÂÆöËøô‰∏™Â≠êÂºπÂèëÂ∞ÑÁöÑÈÄªËæëÔºåÊØèÊ¨°Êåâ‰∏ãÈº†Ê†áÈÉΩÂπ∂‰∏îÂú®0.25ÁßíÂ§ñ‰ºöÂèëÂ∞ÑÂ≠êÂºπ Êåâ‰∏ãÈº†Ê†áÂêéÊääshowSpawnÁöÑtransformËµãÂÄºÁªôshotÔºåËøôÊ†∑Â∞±Áü•ÈÅìshotÁöÑ‰ΩçÁΩÆ‰∫Ü ÈóÆÈ¢òÔºöÁé∞Âú®Ê∏∏ÊàèËøõË°åËøáÁ®ã‰∏≠‰ºöÂæÄrootÈáåÈù¢Â¢ûÂä†ÂæàÂ§öprefab boundaryÔºåhazardsÔºåenemyboundaryÂú®ÁîªÈù¢ÈáåÈù¢Ê∂àÂ§±ÁöÑÂ≠êÂºπ‰πüÂà†Êéâ -&gt; Âª∫Á´ã‰∏Ä‰∏™box ÊâìÂºÄtrigger ÁªôËøô‰∏™boxÈáåÈù¢Áî®‰∏Ä‰∏™ÂáΩÊï∞ÔºåÂà§Êñ≠ÊòØÂê¶Êíû‰∏äËøô‰∏™ËæπÊ°ÜÔºåÊíû‰∏ä‰∫ÜÁöÑËØùÂ∞±Âà†Èô§Êíû‰∏äÁöÑÁâ©‰ΩìOnTriggerExit 1234567public class DestroyByBoundry : MonoBehaviour&#123; void OnTriggerExit(Collider other) &#123; Destroy(other.gameObject); &#125;&#125; hazrads‰ºöÊíû‰∏äplayerÁöÑÈô®Áü≥ È¶ñÂÖàÂª∫Á´ã‰∏Ä‰∏™Êñ∞ÁöÑÈô®Áü≥ÂØπË±°ÔºåËøô‰∏™ÂØπË±°Â∫îËØ•ÂèØ‰ª•Ë¢´ÊíûÂáªÁöÑÔºåÂä†‰∏äÁ¢∞ÊíûÂíåÂàö‰Ωì Âä†‰∏äËøô‰∏™Èô®Áü≥ÁöÑËá™Âä®ÊóãËΩ¨Ôºå‰ΩøÁî®ÈöèÊú∫ÁöÑÊï∞Â≠óÔºåÂπ∂‰∏îÊääangular dragÊîπÊàê0 Âä†‰∏äÊøÄÂÖâÂíåÈô®Áü≥Á¢∞Êíû‰πãÂêéÔºå‰∏§‰∏™‰∏úË•øÂêåÊó∂Ê∂àÂ§±ÁöÑÊïàÊûú ÂçïÁ∫ØÁöÑÂä†Á¢∞ÊíûÊïàÊûú‰ºöÂèëÁé∞Âõ†‰∏∫ËæπÁïåÂºïÂèëÁöÑÈô®Áü≥Ê∂àÂ§±bug Âõ†‰∏∫Èô®Áü≥ÂÖàÂíåËæπÁïåÁ¢∞Êíû‰∫ÜÔºåÁÑ∂Âêé‰∏§‰∏™‰∏ÄËµ∑Ê∂àÂ§±‰∫Ü ÈúÄË¶ÅÊääBoundaryÂä†‰∏ä‰∏Ä‰∏™Êñ∞ÁöÑtag1234if (other.tag == "Boundary") &#123; return; &#125; ÁàÜÁÇ∏ÔºÅÂ∞±ÊòØËâ∫ÊúØÔºÅ Âú®contact destroyÁöÑÊñá‰ª∂ÈáåÈù¢Â¢ûÂä†Êñ∞ÁöÑÁàÜÁÇ∏ÊïàÊûú Êñ∞Âª∫‰∏Ä‰∏™explosionÁöÑgameobjectÔºåÁªôËøô‰∏™ÂØπË±°ËµãÂÄº‰ΩçÁΩÆInstantiate(explosion, transform.position, transform.rotation); Áªôplayer‰∏Ä‰∏™Êñ∞ÁöÑtagÔºåÁÑ∂ÂêéÂú®Á¢∞ÊíûÈáåÈù¢Âà§Êñ≠ÊòØÈô®Áü≥ÊíûplayerËøòÊòØÈô®Áü≥ÊíûÊøÄÂÖâÔºåËµãÂÄº‰∏çÂêåÁöÑÁàÜÁÇ∏ÊïàÊûú ÊäämoverÂ¢ûÂä†Âà∞Èô®Áü≥ÈáåÈù¢ÔºåÈÄüÂ∫¶ËÆæÁΩÆ‰∏∫Ë¥üÂÄºÔºåËøôÊ†∑Èô®Áü≥Â∞±ËÉΩÂæÄËá™Â∑±Ë∫´‰∏äÊéâ‰∫Ü game controller ÂàõÂª∫Êï¥‰∏™Ê∏∏ÊàèÁöÑÈÄªËæë ËÆæÁΩÆÂ•ΩÁöÑÈô®Áü≥ÂàõÂª∫ÊàêÊñ∞ÁöÑprefab ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑÂØπË±°‰Ωú‰∏∫ÊéßÂà∂Âô®ÔºåÂä†ÂÖ•‰∏Ä‰∏™Êñ∞ÁöÑÂØπË±°hazardÔºåÂàùÂßãÂåñÂ•ΩÊéâ‰∏ãÊù•ÁöÑÊïå‰∫∫ÁöÑ‰ΩçÁΩÆÔºåËÆ©Êïå‰∫∫ÂèØ‰ª•‰ªéÈöèÊú∫ÁöÑ‰ΩçÁΩÆÂæÄ‰∏ãÊéâ ÊØèÊ¨°ÊéâËêΩ‰πãÈó¥ÈöîÁùÄÊó∂Èó¥ÔºàËøôÈÉ®ÂàÜÂíåC++Êúâ‰∫õ‰∏ç‰∏ÄÊ†∑ÔºâÔºåÊääÊâÄÊúâÁöÑÊéâËêΩÊîæÂú®‰∏Ä‰∏™whileÈáåÈù¢ ÂéªÊéâÂâ©‰ΩôÁöÑÁàÜÁÇ∏ÊïàÊûú scoreÔºåaudioÔºåbuildingÂä†Â£∞Èü≥ È¶ñÂÖàÊääÈô®Áü≥ÁàÜÁÇ∏ÁöÑËÉåÊôØÈü≥Âä†Âà∞Èô®Áü≥ÁöÑprefabÈáåÈù¢ ËÉåÊôØÈü≥‰πêÂä†Âà∞game controllerÔºåÊ≠¶Âô®ÁöÑÈü≥‰πêÂä†Âà∞player Ê≠¶Âô®ÁöÑÈü≥‰πêÈúÄË¶ÅÂú®ÊØèÊ¨°ÂèëÂ∞ÑÁöÑÊó∂ÂÄôËß¶Âèë Ë∞ÉÊï¥ÂêÑ‰∏™Èü≥ÈáèÁöÑÂ§ßÂ∞è ËÆ°ÁÆóscore Êñ∞Âª∫‰∏Ä‰∏™textÔºåËÆæÂÆöÂ•ΩËøô‰∏™textÁöÑÂ≠ó‰ΩìÊïàÊûú‰πãÁ±ªÁöÑ ÁÑ∂ÂêéÊääËøô‰∏™text referenceÂà∞gamecontrollerÈáåÈù¢ÔºåÁÑ∂ÂêéÊääÊúÄÂºÄÂßãÁöÑÂàÜÊï∞ÂàùÂßãÂåñÔºåÂπ∂‰∏îÂÜôÂá∫Êù•Êõ¥Êñ∞scoreÁöÑ‰ª£Á†Å ÊääËøô‰∏™score referenceÈô®Áü≥ÈáåÈù¢ Â¢ûÂä†ÊñáÂ≠óÊïàÊûú ÈúÄË¶ÅÂ¢ûÂä†ÈáçÊñ∞ÂºÄÂßãÊ∏∏ÊàèÂíåÊ∏∏ÊàèÁªìÊùüÁöÑtext Âú®Ê∏∏ÊàèÈÄªËæëÈáåÈù¢Âä†‰∏äÁöÑÊòØËøô‰∏™Áé©ÊÑèÊÄé‰πàÊõ¥Êñ∞ÂíåËÆ°ÁÆóÔºåÈúÄË¶Å‰∏§‰∏™flagÂà§Êñ≠ÊúâÊ≤°ÊúâÊ∏∏ÊàèÁªìÊùü ÈúÄË¶ÅÂú®Á¢∞ÊíûÈáåÈù¢ÊääplayerÂºÑÊ≠ª Â¢ûÂä†ÊúÄÂêéÁöÑÊïàÊûú Â¢ûÂä†Èô®Áü≥ Â§çÂà∂‰πãÂâçÁöÑasteroidÂπ∂‰∏îÁªô‰ªñ‰ª¨‰∏çÂêåÁöÑÊ®°ÂûãÂíåÁ¢∞Êíû Êää‰πãÂâçÁöÑÂØπË±°ÊîπÊàê‰∏Ä‰∏™Êï∞ÁªÑÂ∞±ÂèØ‰ª•handleÂæàÂ§ö‰∏™ÂØπË±°‰∫ÜÔºåÈöèÊú∫ÈÄâÊã© Â¢ûÂä†ÁßªÂä®ÁöÑÂ∞èÊòüÊòüÔºàÈ°πÁõÆÈáåÈù¢Ëá™Â∏¶ÁöÑÔºâ ËÆ©ËÉåÊôØÈáçÂ§çËµ∑Êù• ÊääËÉåÊôØËÆæÁΩÆÂú®‰∏Ä‰∏™ËåÉÂõ¥ÂÜÖÔºå‰∏ÄÊó¶Ë∂ÖËøá‰∫ÜËøô‰∏™ËåÉÂõ¥Â∞±ÈáçÊñ∞ÂºÄÂßã]]></content>
      <categories>
        <category>Unity</category>
        <category>ÂÖ•Èó®</category>
      </categories>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VS17ÁöÑÈÖçÁΩÆÈóÆÈ¢ò]]></title>
    <url>%2F2019%2F06%2F07%2FVS17%E7%9A%84%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Êó†Ê≥ïÊâìÂºÄÊ∫êÊñá‰ª∂ÈóÆÈ¢ò Áõ¥Êé•‰ªéËÄÅÂ∏àÈÇ£ÈáåÂæóÂà∞ÁöÑÈ°πÁõÆÔºåÁ¨¨‰∏ÄÊ¨°ËøêË°åÁõ¥Êé•Âá∫ÈîôÔºåÊü•‰∫Ü‰∏Ä‰∏ã‰∏ªË¶ÅÈúÄË¶ÅÊ≥®ÊÑè‰∏ãÈù¢Âá†‰∏™ Ë£ÖVSÁöÑÊó∂ÂÄôÊúâÊ≤°ÊúâË£ÖÊ†áÂáÜÂ∫ì‰πãÁ±ªÁöÑ Â∞ùËØï‰ΩøÁî®windowÁöÑÂÖ∂‰ªñÁâàÊú¨ÁöÑSDK Âè≥ÈîÆÈ°πÁõÆÔºåÂ±ûÊÄßÈáåÈù¢ ‰∏äÈù¢‰∏§‰∏™ÈóÆÈ¢òÈÉΩÂèØ‰ª•Âú®VSÁöÑinstallerÈáåÈù¢ÊâæÂà∞Áõ∏ÂÖ≥ÁöÑÂÆâË£Ö Â§ö‰∏™mainÁöÑÈóÆÈ¢ò ËøôÂõûÁöÑÊñá‰ª∂ÈáåÈù¢Êúâ‰∏§‰∏™cppÈÉΩÂ∏¶ÁùÄmainÔºåÂ¶ÇÊûúÊÉ≥Ë¶ÅËøêË°åÁöÑËØùÈúÄË¶ÅÊää‰∏Ä‰∏™cppÂè≥ÈîÆÁßªÈô§Âá∫È°πÁõÆÂÜçËøêË°åÂè¶‰∏Ä‰∏™]]></content>
      <categories>
        <category>IDE</category>
        <category>Visual Studio</category>
      </categories>
      <tags>
        <tag>VS17</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pythonÁöÑÂ§çÂà∂ÂíåÂ§öÁª¥Êï∞ÁªÑ]]></title>
    <url>%2F2019%2F06%2F05%2Fpython%E7%9A%84%E5%A4%8D%E5%88%B6%E5%92%8C%E5%A4%9A%E7%BB%B4%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[ÊúÄËøëÂÜôÈù¢ËØïÈ¢òÁöÑÊó∂ÂÄôÈÅáÂà∞‰∫ÜËá™Â∑±ÈÉΩÊÉ≥‰∏çÂà∞ÁöÑÂ•áÊÄ™Â∞èÈîôËØØ Â§öÁª¥Êï∞ÁªÑÂú®ÂàõÂª∫Â§öÁª¥Êï∞ÁªÑÁöÑÊó∂ÂÄôÔºåÊú¨Êù•Â∫îËØ•ÊòØÁî®ÂµåÂ•óÁöÑforÂæ™ÁéØÊù•ÁîüÊàê[[0 for i in range(m)] for j in range(n)](Âõ†‰∏∫‰∏ÄËà¨ÁΩëÊµã‰∏çËÉΩË∞ÉÁî®numpyÔºå‰∏çÁÑ∂Â∞±Áõ¥Êé•Áî®numpyÊêû‰∫Ü) ‰ΩÜÊòØÊúÄËøëÊÉ≥Ë¶ÅÂÅ∑ÊáíÁöÑÊó∂ÂÄôÂ∞ùËØïÁî® [[0] * n] * m Êù•ÂàõÂª∫ÔºåÁªìÊûúÁñØÁãÇÈÅ≠ÈÅábug„ÄÇ ÊúÄÁªàÂéüÂõ†ÊòØÂèëÁé∞ËøôÊ†∑ÂàõÂª∫Âá∫Êù•ÁöÑÊï∞ÁªÑÔºåÊØè‰∏ÄË°åÈÉΩÊòØÁ¨¨‰∏ÄË°åÁöÑÂºïÁî®ÔºåÊâÄ‰ª•ÊØèÊ¨°Êìç‰ΩúÂ§ßÂÆ∂ÈÉΩ‰ºö‰∏ÄËµ∑Âèò (‰ΩÜÊòØËøôÁßçÊñπÊ≥ïÂèØ‰ª•ÂàõÂª∫‰∏ÄÁª¥ÁöÑ) listÁöÑÂ§çÂà∂Êàë‰∏ÄÁõ¥‰ª•‰∏∫a=bÂ∞±ÊòØlistÁöÑÂ§çÂà∂‰∫ÜÔºå‰ΩÜÊòØÂπ∂‰∏çÊòØËøôÊ†∑ÁöÑÔºÅÔºÅËøôÊ†∑ÁöÑËØùaÊòØ‰∏Ä‰∏™ÂÖ≥‰∫ébÁöÑreferenceÔºåÂπ∂‰∏çÊòØÂ§çÂà∂bÔºåÊîπÂèòÁöÑÊó∂ÂÄôÊòØ‰ºö‰∏ÄËµ∑ÊîπÂèòÁöÑ ‰∏ãÈù¢Âá†ÁßçÊñπÊ≥ïÂèØ‰ª•Áî®Ôºö a = list(b) a = b[:] a = b * 1 a = copy.copy(b) #ÈúÄË¶Åimport copy]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
        <category>list</category>
      </categories>
      <tags>
        <tag>listÂ§çÂà∂</tag>
        <tag>Â§öÁª¥Êï∞ÁªÑ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫éÂ≠óÁ¨¶‰∏≤ÂåπÈÖçÁÆóÊ≥ïKMPÂíåBM]]></title>
    <url>%2F2019%2F06%2F05%2F%E5%85%B3%E4%BA%8E%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95KMP%E5%92%8CBM%2F</url>
    <content type="text"><![CDATA[‰ªäÂ§©Âú®leetcodeÁªà‰∫éÂà∑Âà∞‰∫ÜstringÁöÑÈ¢òÔºåÊòØÂú®‰∏ÄÂ§ß‰∏≤Â≠óÁ¨¶ÈáåÈù¢ÂåπÈÖçÁõ∏Â∫îÁöÑÂ≠óÁ¨¶„ÄÇÊâòpythonÁöÑÁ¶èÔºåÂ±ÖÁÑ∂Ë¢´ÊàëÁî®Êö¥ÂäõÁ†¥Ëß£Ëß£ÂÜ≥‰∫ÜÔºåËôΩÁÑ∂ÁªìÊûú‰∏çÊòØÂæà‰ºòÈõÖ„ÄÇ123456789class Solution: def strStr(self, haystack: str, needle: str) -&gt; int: if needle == "": return 0 for i, ch in enumerate(haystack): if ch == needle[0]: if needle == haystack[i:i+len(needle)]: return i return -1 KMP È¶ñÂÖàÔºåÊääËøô‰∏™ÈúÄË¶ÅÊ£ÄÊµãÁöÑstringÔºàaÔºâÁöÑÁ¨¨‰∏Ä‰∏™ÂíåÁõÆÊ†ástringÔºàtÔºâÁöÑÁ¨¨‰∏Ä‰∏™ËøõË°åÂØπÊØîÔºåÂ¶ÇÊûú‰∏çÂåπÈÖçÔºåÂêéÁßª‰∏Ä‰Ωç Áõ¥Âà∞ÊâæÂà∞Á¨¨‰∏Ä‰∏™Áõ∏ÂêåÁöÑÂ≠óÊØçÔºåÁÑ∂ÂêéÊääaÂíåbÂêåÊó∂ÂêéÁßª‰∏Ä‰Ωç ËøòÊòØÁõ∏ÂêåÔºåÁªßÁª≠ÂêéÁßª ‰∏çÂêåÔºàËøôÈÉ®ÂàÜÊòØËøô‰∏™‰ª£Á†ÅÁöÑÁ≤æÈ´ìÔºâ ‰∏ÄËà¨ÁöÑÊÄùË∑ØÊòØÊääbÂÖ®ÈÉΩÂêéÁßª‰∏Ä‰ΩçÔºå‰ΩÜÊòØËøôÊ†∑ÂÖ∂ÂÆûÊ∂àËÄóÊå∫Â§ßÁöÑ KMPÁöÑÊÄùË∑ØÊòØÔºåÊó¢ÁÑ∂bÁöÑÂâçn‰ΩçÈÉΩÂ∑≤ÁªèÊØîËæÉËøá‰∫ÜÔºåÈÇ£Â∞±‰∏çË¶ÅÊîæÂºÉËøô‰∏™‰ø°ÊÅØÔºå‰∏çË¶ÅÁßªÂä®Âõû‰πãÂâçÊØîËæÉËøáÁöÑn‰Ωç‰∫ÜÔºåÁªßÁª≠ÂêéÁßªÁßªÂä®Âà∞ÂÖ®Êñ∞ÁöÑ‰ΩçÁΩÆ ÈúÄË¶ÅÁßªÂä®ÁöÑ‰ΩçÊï∞ = Â∑≤ÁªèÂåπÈÖçÂà∞ÁöÑÂ≠óÊï∞ - ÂØπÂ∫îÊúÄÂêé‰∏Ä‰ΩçÂåπÈÖç‰∏äÁöÑ‰∏úË•øÁöÑÂåπÈÖçÂÄºÔºàÁî±partial match tableÂæóÂá∫Ôºâ Â¶Ç‰Ωï‰∫ßÁîüËøôÂº†Ë°®ÊØîÂ¶Ç‰∏Ä‰∏™ÂçïËØç bread ÂâçÁºÄÔºöb,br,bre,brea ÂêéÁºÄÔºöread,ead,ad,dÈÉ®ÂàÜÂåπÈÖçÂÄºÂ∞±ÊòØÂâçÁºÄÂíåÂêéÁºÄÊúÄÈïøÁöÑÂÖ±ÊúâÂÖÉÁ¥†ÈïøÂ∫¶ ÊØîÂ¶ÇABCDABDËøô‰∏™string AÂâçÂêéÁºÄÈÉΩÊòØÁ©∫ÁöÑÔºåÈïøÂ∫¶0 ABÔºåÂâçÁºÄAÔºåÂêéÁºÄBÔºåÂÖ±ÊúâÈïøÂ∫¶0 ABCÔºå[A, AB]ÔºåÂêéÁºÄ‰∏∫[BC, C]ÔºåÂÖ±ÊúâÂÖÉÁ¥†ÁöÑÈïøÂ∫¶0 ABCDÔºå[A,AB,ABC],[B,BC,BCD] -&gt; 0 ABCDA, [A,AB,ABC,ABCD],[BCDA,CDA,DA,A] -&gt; Êúâ‰∏Ä‰∏™ÂÖ±ÊúâÂÖÉÁ¥†AÔºåÈïøÂ∫¶‰∏∫1 ABCDAB,[A, AB, ABC, ABCD, ABCDA],[BCDAB, CDAB, DAB, AB, B] -&gt; ÂÖ±ÊúâÂÖÉÁ¥†ABÔºåÈïøÂ∫¶‰∏∫2 ‚ÄúABCDABD‚ÄùÁöÑÂâçÁºÄ‰∏∫[A, AB, ABC, ABCD, ABCDA, ABCDAB]ÔºåÂêéÁºÄ‰∏∫[BCDABD, CDABD, DABD, ABD, BD, D]ÔºåÂÖ±ÊúâÂÖÉÁ¥†ÁöÑÈïøÂ∫¶‰∏∫0„ÄÇÔºàÈöæÁÇπÔºöÊÄé‰πàÂæóÂà∞‰∏äÈù¢ÁöÑËøô‰∏™ÈïøÂ∫¶Ôºâ BM È¶ñÂÖàÂ∞ÜaÂíåbÁöÑÂ§¥ÂØπÂÖ∂ÂºÄÂßãÔºåÁÑ∂Âêé‰ªéÂ∞æÈÉ®ÂºÄÂßãÊØîËæÉ„ÄÇÂõ†‰∏∫Â¶ÇÊûúÂ∞æÈÉ®‰∏çÂåπÈÖçÁöÑËØùÔºåËøôÊï¥‰∏™‰∏Ä‰∏≤ÈÉΩ‰∏çÂåπÈÖç‰∫Ü„ÄÇÁü•ÈÅì‰∫ÜËøô‰∏™‰∏çÂåπÈÖçÁöÑÂ≠óÁ¨¶‰πãÂêéÔºåËøô‰∏™Â≠óÁ¨¶Â∞±Ë¢´Áß∞‰∏∫ÂùèÂ≠óÁ¨¶ Â¶ÇÊûúËøô‰∏™ÂùèÂ≠óÁ¨¶ÂåÖÊã¨Âú®ÂçïËØçÈáåÈù¢ÔºåÂàôÈúÄË¶ÅÊääËøô‰∏§‰∏™ÂØπÂÖ∂ ÂêéÁßª‰ΩçÊï∞ = ÂùèÂ≠óÁ¨¶ÁöÑ‰ΩçÁΩÆ - ÊêúÁ¥¢ËØç‰∏≠ÁöÑ‰∏ä‰∏ÄÊ¨°Âá∫Áé∞‰ΩçÁΩÆ Â¶ÇÊûú‰∏çÂåÖÂê´Âú®ÊêúÁ¥¢ËØçÈáåÈù¢ÔºåÈÇ£‰πà‰∏ä‰∏ÄÊ¨°ÁöÑ‰ΩçÁΩÆÊòØ-1 ÊúÄÂêé‰∏Ä‰ΩçÂåπÈÖç‰∏ä‰∫ÜÔºåÈÇ£‰πàÂ∞±È°∫ÁùÄbÂæÄÂâçÊçã Âú®aÈáåÈù¢ÂèØ‰ª•ÂíåbÂêéÈù¢ÂåπÈÖç‰∏äÁöÑÈÉΩÊòØgood suffixÔºàÊØîÂ¶ÇexampleÁöÑeÔºåleÔºåpleÁ≠âÁ≠âÔºâ Â•ΩÂêéÁºÄÁöÑÂêéÁßªÔºöÂêéÁßª‰ΩçÊï∞ = Â•ΩÂêéÁºÄÁöÑ‰ΩçÁΩÆÔºàÊúÄÂêé‰∏Ä‰∏™Â≠óÁ¨¶‰∏∫ÂáÜÔºâ - ÊêúÁ¥¢ËØç‰∏≠ÁöÑ‰∏ä‰∏ÄÊ¨°Âá∫Áé∞‰ΩçÁΩÆ Â¶ÇÊûúÊ≤°ÊúâÂá∫Áé∞ËøáÊòØ -1 Â¶ÇÊûúÊúâÂ§ö‰∏™Â•ΩÂêéÁºÄÔºåÈÇ£‰πàÈô§‰∫ÜÊúÄÈïøÁöÑÂ•ΩÂêéÁºÄÔºåÂÖ∂‰ªñÁöÑ‰∏ä‰∏ÄÊ¨°Âá∫Áé∞‰ΩçÁΩÆÂøÖÈ°ªÂú®Â§¥ÈÉ®ÔºàbÁöÑÂ§¥ÈÉ®Ôºâ Âú®‰∏äÈù¢‰∏§‰∏™ËßÑÂàôÈáåÈù¢ÔºåÈÄâÊã©ÁßªÂä®ÁöÑÊúÄÂ§ßÂÄº ‰∏äÈù¢‰∏§‰∏™ËßÑÂàôÂè™ÂíåÊêúÁ¥¢ËØçÊúâÂÖ≥ÔºåÂíåÂéüÊù•ÁöÑÂ≠óÁ¨¶‰∏≤Ê≤°ÂÖ≥Á≥ªÔºåÊâÄ‰ª•ÂèØ‰ª•ÊèêÂâçÁîüÊàêÂùèÂ≠óÁ¨¶ÂíåÂ•ΩÂêéÁºÄË°®ÔºåÁõ¥Êé•ÊØîËæÉÁßªÂä®‰ΩçÊï∞]]></content>
      <categories>
        <category>ÁÆóÊ≥ï</category>
        <category>Â≠óÁ¨¶‰∏≤Â§ÑÁêÜ</category>
      </categories>
      <tags>
        <tag>KMP</tag>
        <tag>BM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫épythonÁöÑthreading]]></title>
    <url>%2F2019%2F06%2F03%2F%E5%85%B3%E4%BA%8Epython%E7%9A%84threading%2F</url>
    <content type="text"><![CDATA[Â§öÁ∫øÁ®ãÂ§öÁ∫øÁ®ãÁ±ª‰ºº‰∫éÂêåÊó∂ÊâßË°åÂ§ö‰∏™‰ªªÂä° ÂèØ‰ª•ÊääÂç†Áî®Êó∂Èó¥ÈïøÁöÑÁ®ãÂ∫èÊîæÂà∞ÂêéÂè∞ÂéªÂ§ÑÁêÜ ÂèØ‰ª•‰ΩøÁî®Êà∑ÁïåÈù¢Êõ¥Âä†Âê∏Âºï‰∫∫ÔºàÊØîÂ¶ÇÁÇπÂáªÊåâÈíÆÔºå‰ºöÂá∫Áé∞ËøõÂ∫¶Êù°Ôºâ Â§ÑÁêÜÈÄüÂ∫¶Êõ¥Âø´]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Á∫øÁ®ã</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫éÂä®ÊÄÅËßÑÂàí(dynamic programmin)]]></title>
    <url>%2F2019%2F05%2F24%2F%E5%85%B3%E4%BA%8E%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92DP%2F</url>
    <content type="text"><![CDATA[ÂÖ•Èó®refÔºöhttps://www.zhihu.com/question/23995189 ‰æãÂ≠êÂú®Ë∫´‰∏äÂ∏¶ÁùÄ‰∏çÂêåÊï∞È¢ùÁöÑÈíûÁ•®ÔºåÁõÆÊ†áÊòØÂáëÂá∫Êù•Êüê‰∏™ÈáëÈ¢ùwÔºå‰ΩøÁî®Â∞ΩÈáèÂ∞ëÁöÑÈíûÁ•® Â¶ÇÊûúÁî®Ë¥™ÂøÉÁÆóÊ≥ïÔºåÂÆûÈôÖ‰∏äÂ∞±ÊòØÂ∞ΩÂø´ËÆ©wÂèòÂæóÊõ¥Â∞èÔºåÊúâÊõ¥Â§ßÈù¢ÂÄºÁöÑÂ∞±Áî®Êõ¥Â§ßÈù¢ÂÄºÁöÑÈíûÁ•® ‰ΩÜÊòØÂ¶ÇÊûúÊç¢‰∫Ü‰∏ÄÁªÑÂÖ∂‰ªñÁöÑÈíûÁ•®Èù¢ÂÄºÔºåÂèØËÉΩÂ∞±‰ºöÂá∫Áé∞ÈóÆÈ¢òÔºàÊØîÂ¶Ç 1Ôºå5Ôºå11Âáë15Ôºâ Âõ†‰∏∫Âú®Ë¥™ÂøÉÁÆóÊ≥ïÈáåÈù¢ÔºåÈúÄË¶ÅÂÖàÊää15ÈôçÊàê4ÔºåÂÜçÊää4Èôç‰∏ãÊù•Ôºå‰ΩÜÊòØÈôç4ÁöÑÊàêÊú¨ÂæàÈ´òÔºåÈúÄË¶Å4Âº†1 Âú®ËÄÉËôëÁöÑÊó∂ÂÄôÈº†ÁõÆÂØ∏ÂÖâÔºåÂè™ËÄÉËôë‰∫ÜÁúºÂâçÁöÑÊÉÖÂÜµÔºåÊ≤°ÊúâËÄÉËôëÂêéÁª≠ÁöÑÂèëÂ±ï Â¶ÇÊûúÂºÄÂßãÂàó‰∏æÔºåÂÖ∂ÂÆûËøô‰∏™ÈóÆÈ¢òÂ∞±‰ºöÂèòÊàêÊé•‰∏ãÊù•ÈúÄË¶ÅÂáëÂá∫Êù•nÔºåÈúÄË¶Åf(n)Âº†ÈíûÁ•® ËøôÊó∂ÂÄôÔºåÂáë15ÂÖ∂ÂÆûÂ∞±ÂèòÊàê‰∫Ü‰∏â‰∏™ÊÉÖÂÜµ f(4) + 1 f(10) + 1 f(14) +1 ÂèØ‰ª•ÂèëÁé∞ÂÆûÈôÖ‰∏äf(15)Âè™ÂíåËøô‰∏â‰∏™ÂÄºÊúâÂÖ≥Á≥ªÔºå‰πüÂ∞±ÊòØÂè™Âíån-1Ôºån-5Ôºån-11ÊúâÂÖ≥Á≥ª f(n) = min(f(n-1),f(n-5),f(n-11))+1 ËøôÊòØ‰∏Ä‰∏™ÂèØ‰ª•Ëø≠‰ª£ÁöÑÂºèÂ≠êÂØπ‰∏çÂØπÔºÅ Âπ∂‰∏çÂÖ≥ÂøÉÂà∞Â∫ïÊòØÊÄé‰πàÂáëÂá∫Êù•ÁöÑÔºåÂèçÊ≠£Âè™ÂÖ≥ÂøÉf(w)ÁöÑÂÄº Âú®‰ª£Á†ÅÂÆûÁé∞‰∏äÈù¢ÔºåÂè™ÈúÄ‰ªéÂ∞èÂà∞Â§ßÂØπÊØîÊâÄÊúâÁöÑcostÂ∞±ÂèØ‰ª•‰∫ÜÔºå‰πüÂ∞±ÊòØÂØπÊØîÊñ∞ÁöÑÊñπÊ°àÁöÑcostÊòØ‰∏çÊòØ‰ºöÊØî‰ª•ÂâçÁöÑÊñπÊ°àÂ∞è„ÄÇÊ≥®ÊÑèÂú®Ê±ÇÁöÑÊó∂ÂÄôÂèØËÉΩ‰ºöÈúÄË¶Åi-1/-5/-11ÁöÑÂÄºÔºåÊâÄ‰ª•Ë¶ÅÊää‰ªéÂ§¥Âà∞Â∞æÁöÑÂÄºÈÉΩËÆ∞ÂΩï‰∏ãÊù• ÊØîÂ¶ÇË¶ÅÊ±ÇÂáë15ÂùóÈí±Ôºå‰ºöÂÖàËÄÉËôë15ÊØî1Â§ßÔºåÈÇ£‰πàÊää1ÂùóÊãøÂá∫Êù•ÔºåÁúãÁúãÂèñ14ÂùóÈí±ÁöÑÊó∂ÂÄôÈúÄË¶ÅÁöÑÊ≠•È™§ÊòØÂ§öÂ∞ëÔºåÁÑ∂ÂêéÊää5ÂùóÊãøÂá∫Êù•ÔºåÁúãÁúãÊØîÊãø1ÂùóÂ∑ÆÂ§öÂ∞ëÔºåÊúÄÂêéÊãø11ÔºåÁúãÁúãÂíå‰πãÂâçÁöÑcostÂ∑ÆÂ§öÂ∞ë Âå∫Âà´ dpÂíåË¥™ÂøÉÁÆóÊ≥ïÁöÑÂå∫Âà´Â∞±Âú®‰∫éÔºådp‰ºöÂàÜÂà´ÁÆóÂá∫‰∏çÂêåÁ≠ñÁï•ÁöÑ‰ª£‰ª∑ÔºåËÄåË¥™ÂøÉÁÆóÊ≥ïÂåÖÂê´ÁùÄÂÜó‰ΩôÁöÑ‰ø°ÊÅØÔºàÂà∞Â∫ïÊÄé‰πà‰ΩøÁî®Ôºâ ÊâÄ‰ª•Â∞±ÊòØÊ±ÇÂá∫Êù•fn -&gt; ÂæóÂà∞Ê±ÇfnÈúÄË¶ÅÁöÑfc -&gt; Ê±ÇfcÔºå‰∏çÂÅúÁöÑÂæ™ÁéØ ‰πüÂ∞±ÊòØÊää‰∏Ä‰∏™ÈóÆÈ¢òÊãÜÊàê‰∫Ü‰∏çÂêåÁöÑÂ≠êÈóÆÈ¢ò Ê¶ÇÂøµ ÂêéÊó†ÊïàÊÄß ‰∏ÄÊó¶fnÁ°ÆÂÆöÔºåÊàë‰ª¨Â∞±‰∏çÈúÄË¶ÅÁü•ÈÅìÊÄé‰πàÂæóÂà∞ÁöÑfn‰∫ÜÔºåÂè™Âú®ÂêéÈù¢Áõ¥Êé•Áî®Â∞±ÂèØ‰ª•‰∫Ü ÊúÄ‰ºòÂ≠êÁªìÊûÑ Âú®ÂæóÂà∞fnÁöÑÊó∂ÂÄôÊú¨Ë∫´ÂæóÂà∞ÁöÑÂ∞±ÊòØÊúÄ‰ºòÁöÑfn‰∫ÜÔºåÊâÄ‰ª•Âú®Áî®ÁöÑÊó∂ÂÄôÊâçÂèØ‰ª•ÊîæÂøÉÁöÑÁî® ‰∏ÄÊó¶ÈóÆÈ¢òÂèØ‰ª•ÊãÜÊàêÂ≠êÈóÆÈ¢òÔºåÂπ∂‰∏îÊª°Ë∂≥‰∏äÈù¢ÁöÑ‰∏§‰∏™Ê¶ÇÂøµÔºåÂ∞±ÂèØ‰ª•Áî®dpËß£‰∫Ü ‰∏∫‰ªÄ‰πàÂø´ dpÂíåË¥™ÂøÉÈÉΩÊòØÂú®Á©∫Èó¥ÈáåÂØªÊâæÊúÄ‰ºòËß£Ôºå‰ΩÜÊòØdpÂú®ÊâæËß£ÁöÑÊó∂ÂÄôÂ∑≤ÁªèÊâæÂà∞‰∫ÜÂ≠êÈóÆÈ¢òÁöÑÊúÄ‰ºòËß£Ôºå‰πüÂ∞±ÊòØËØ¥‰ªñÂ∑≤ÁªèÊääÂ≠êÈóÆÈ¢òÈáåÈù¢‰∏çÂèØËÉΩÁöÑÁä∂ÊÄÅÊéíÈô§Êéâ‰∫Ü ÁÆóÊ≥ïËÆæËÆ° ÊääÁé∞Âú®Èù¢ÂØπÁöÑÂ±ÄÈù¢ÁúãÂÅöx ÂØπ‰∫éxÔºåÈúÄË¶ÅÊ±ÇÂæóÁ≠îÊ°àÊòØfxÔºåÁõÆÊ†áÊòØÊ±ÇÂá∫Êù•fTÔºåÊâæÂá∫xÂíåÂì™‰∫õÂ±ÄÈù¢pÊúâÂÖ≥ÔºåÂÜôÂá∫‰∏Ä‰∏™Áä∂ÊÄÅ‰∏ì‰∏öÊñπÁ®ãÔºåÊù•Ê±ÇfpÂà∞fxÁöÑÂÖ≥Á≥ª ‰πüÂ∞±ÊòØËÄÉËôëÁé∞Âú®ÊàëÊòØË∞ÅÔºåÂíåÊàë‰ªéÂì™ÈáåÊù•ÔºàÊàñËÄÖÊàëÂà∞Âì™ÈáåÂéªÔºâ]]></content>
      <categories>
        <category>ÁÆóÊ≥ï</category>
        <category>Âä®ÊÄÅËßÑÂàí</category>
      </categories>
      <tags>
        <tag>Âä®ÊÄÅËßÑÂàí</tag>
        <tag>DP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nAssignment3StyleTransfer]]></title>
    <url>%2F2019%2F05%2F22%2FCS231nAssignment3StyleTransfer%2F</url>
    <content type="text"><![CDATA[target Áé∞Âú®Êúâ‰∏§Âº†ÂõæÁâáÔºåÈúÄË¶Å‰∫ßÁîü‰∏Ä‰∫õÊñ∞ÁöÑÂõæÁâáÊòØ‰∏ÄÂº†ÂõæÁâáÁöÑÂÜÖÂÆπ‰ΩÜÊòØÊòØÂè¶‰∏ÄÂº†ÂõæÁâáÁöÑstyle È¶ñÂÖàÊàë‰ª¨Â∏åÊúõÂèØ‰ª•ÊûÑÂª∫‰∏Ä‰∏™loss functionÔºåÂèØ‰ª•ËøûÊé•styleÂíåÊØè‰∏™‰∏çÂêåÁöÑimageÔºåÁÑ∂ÂêéÂú®ÊØè‰∏™ÂõæÁâáÁöÑpixel‰∏äÈù¢Èôç‰Ωégradient Âú®Ëøô‰∏™ÈáåÈù¢Áî®squeezeNetÔºàÂú®ImageNet‰∏äÈù¢pretrainÁöÑÔºâÊù•ÊèêÂèñÂõæÁâáÁöÑfeature È¢ÑÂÖàËÆæÂÆöÂ•ΩÁöÑÂáΩÊï∞ Âõ†‰∏∫Âú®ËøôÈÉ®ÂàÜÁõ¥Êé•Â§ÑÁêÜÁöÑÊòØjpegÁöÑÂõæÁâáËÄå‰∏çÊòØcifar-10ÁöÑÂõæÁâá‰∫ÜÔºåÊâÄ‰ª•Âú®ËøôÈÉ®ÂàÜÈúÄË¶ÅÂØπÂá∫ÁâáËøõË°åÈ¢ÑÂ§ÑÁêÜ ÂêåÊó∂ÈúÄË¶ÅËÆæÂÆö‰∏Ä‰∏™dtype = torch.FloatTensor Êù•ËÆæËÆ°ÊòØÁî®CPUË∑ëËøòÊòØÁî®GPUË∑ëÔºàGPUÁöÑÈáåÈù¢‰ºöÂ∏¶cudaÔºâ CNN = torchvision.models.squeezenet1_1(pretrained=True).featuresÊèêÂèñsqueezenetÁöÑmodelÔºåÂπ∂‰∏îËÆæÂÆöCNNÁöÑtypeÁ≠â‰∫é‰∏äÈù¢ËÆæÂÆöÂ•ΩÁöÑdtype Âõ†‰∏∫‰∏çÈúÄË¶ÅÂÜçËøõË°åËÆ≠ÁªÉ‰∫ÜÔºåÈúÄË¶ÅÊääcnnÈáåÈù¢ÁöÑÊâÄÊúâËá™Âä®ËÆ°ÁÆógradÁöÑÂäüËÉΩÂÖ≥Êéâ ÊèêÂèñÁâπÂæÅ ËæìÂÖ• xÔºå‰∏Ä‰∏™tensorÔºåÂ§ßÂ∞èÊòØ(N,C,H,W),ÈáåÈù¢ÊòØ‰∏Ä‰∏™minibatchÁöÑÊï∞ÊçÆ cnnÔºåÂàöÊâçËΩΩÂÖ•Â•ΩÁöÑmodel ËæìÂá∫ featuresÔºå‰∏Ä‰∏™listÔºåfeatures[i]ÁöÑÂ§ßÂ∞èÊòØ(N,C_i,H_i,W_i) Âú®‰∏çÂêåÂ±ÇÂæóÂà∞ÁöÑfeature‰ºöÊúâ‰∏çÂêåÁöÑchannelÁöÑÊï∞Èáè‰ª•ÂèäHÂíåWÁöÑÂ§ßÂ∞è ÂÆûÁé∞Ôºö Âú®ÂÖ∑‰ΩìÁöÑ‰ª£Á†ÅÂÆûÁé∞ÈáåÈù¢ÔºåÁõ¥Êé•Áî®valueÂæóÂà∞ÊØè‰∏ÄÂ±Ç‰πãÂêéÁöÑÁªìÊûúÔºå‰∏ã‰∏ÄÂ±ÇÁöÑËæìÂÖ•Â∞±ÊòØ‰∏ä‰∏ÄÂ±ÇÂæóÂà∞ÁöÑÁªìÊûú123456789def extract_features(x, cnn): features = [] prev_feat = x for i, module in enumerate(cnn._modules.values()): next_feat = module(prev_feat) features.append(next_feat) prev_feat = next_feat return features ËÆ°ÁÆólossloss‰∏ÄÂÖ±Áî±‰∏â‰∏™ÈÉ®ÂàÜÁªÑÊàêÔºåÂàÜÂà´ÊòØÔºöÂõæÁâácontentÁöÑloss + styleÁöÑloss + total var loss Êàë‰ª¨Ëøô‰∏™‰∏úË•øÁöÑÁõÆÁöÑÊòØÁî®‰∏ÄÂº†ÂõæÁâáÁöÑÂÜÖÂÆπÂíåÂè¶‰∏Ä‰∏™ÂõæÁâáÁöÑstyle ÂΩìÂÜÖÂÆπÂÅèÁ¶ª‰∫ÜcontentÂõæÁâáÁöÑcontentÔºåstyleÂÅèÁ¶ª‰∫ÜstypeÂõæÁâáÁöÑÊó∂ÂÄôÂ∞±ÈúÄË¶ÅpenalizeÔºàÂ§ÑÁΩöÔºâ ‰∏∫‰∫ÜÂÆûÁé∞Ëøô‰∏™ÂäüËÉΩÔºåÊàë‰ª¨ÈúÄË¶ÅÁî®hybridÁöÑlossÔºåÂπ∂‰∏î‰∏çÊòØÂú®weights‰∏äÈù¢Ë∞ÉÂèÇÔºåËÄåÊòØÂú®ÊØèÂº†ÂõæÁâáÁöÑpixel‰∏äÈù¢Ë∞ÉÊï¥ content loss Ëøô‰∏™ÂáΩÊï∞Ë°°ÈáèÁîüÊàêÁöÑÂõæÁâáÁöÑfeature mapÂíåÂéüÊù•‰Ωú‰∏∫contentÁöÑÂõæÁâáÂÅèÁ¶ªÂ§öÂ∞ë Êàë‰ª¨Âè™ÂÖ≥ÂøÉËøô‰∏™networkÈáåÈù¢ÁöÑ‰∏ÄÂ±ÇÁöÑË°®Á§∫ÔºåËøô‰∏ÄÂ±Ç‰ºöÊúâËá™Â∑±ÁâπÂÆöÁöÑchannelÊï∞Èáè‰ª•ÂèäfilterÁöÑÂ§ßÂ∞è Êàë‰ª¨ÈúÄË¶ÅÊääËøô‰∏™feature map reshapeÔºåÊääÊâÄÊúâÁöÑÁ©∫Èó¥‰ΩçÁΩÆÁªÑÂêàÂà∞Âêå‰∏Ä‰∏™Áª¥Â∫¶‰∏äÈù¢ ‰ΩÜÊòØÂú®ÂÆûÈôÖÁöÑÂÆûÁé∞‰∏äÈù¢ÔºåÊàë‰ª¨‰∏çÈúÄË¶ÅÂÜçreshape‰∫ÜÔºåÂõ†‰∏∫Â§ßÂ∞èÂèØ‰ª•Áõ¥Êé•ÂØπÂ∫îÂ§ÑÁêÜ‰∫Ü 123456789101112131415161718def content_loss(content_weight, content_current, content_original): """ Compute the content loss for style transfer. Inputs: - content_weight: Scalar giving the weighting for the content loss. - content_current: features of the current image; this is a PyTorch Tensor of shape (1, C_l, H_l, W_l). - content_target: features of the content image, Tensor with shape (1, C_l, H_l, W_l). Returns: - scalar content loss """ # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** return content_weight * torch.sum((content_original - content_current)**2) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** style lossÂØπ‰∫é‰∏Ä‰∏™ÁªôÂÆöÁöÑÂ±ÇlayerÔºåÂÆö‰πâloss ËÆ°ÁÆóGram MatÔºåGÔºåË°®Á§∫‰∏çÂêåfilterÁöÑÁõ∏ÂÖ≥ÊÄß„ÄÇËøô‰∏™Áü©ÈòµÊòØ‰∏™ÂçèÊñπÂ∑ÆÁü©ÈòµÔºåÊàë‰ª¨Â∏åÊúõÂΩ¢ÊàêÁöÑÂõæÁâáÁöÑactivation ÁªüËÆ°ÂíåstyleÂõæÁâáÁöÑÂèØ‰ª•matchÔºåËÆ°ÁÆóËøô‰∏§‰∏™ÁöÑÂçèÊñπÂ∑ÆÂ∞±ÊòØ‰∏Ä‰∏™ÂäûÊ≥ïÔºàÂπ∂‰∏îÁªèËøáÈ™åËØÅÊïàÊûúÊØîËæÉÂ•ΩÔºâ ÁªôÂÆö‰∏Ä‰∏™feature mapÔºåGÁü©ÈòµÁöÑÂΩ¢Áä∂Â∫îËØ•ÊòØÔºàClÔºåClÔºâ„ÄÇClÊòØËøô‰∏ÄÂ±ÇÁöÑfilterÁöÑÊï∞Èáè„ÄÇÈáåÈù¢ÁöÑÂÖÉÁ¥†Â∫îËØ•Á≠â‰∫é‰∏§‰∏™filterÁöÑ‰πòÁßØ ÊääÁîüÊàêÂõæÁâáÁöÑGÂíåstyleÂõæÁâáÁöÑGÂÅöÂ∑ÆÔºåÂπ≥ÊñπÂíåÂ∞±ÊòØ‰∏ÄÂ±ÇÁöÑloss ÊâÄÊúâÂ±ÇÁöÑlossÂä†Âú®‰∏ÄËµ∑Â∞±ÊòØÊÄªÂÖ±ÁöÑloss G Mat implement view(),ÂΩ¢Êàê‰∏Ä‰∏™ÂÜÖÂÆπÁõ∏Âêå‰ΩÜÊòØÂ§ßÂ∞è‰∏çÂêåÁöÑtensor .matmul ‰∏§‰∏™tensorÁõ∏‰πò .permute ÁªôtensorÈáåÈù¢ÁöÑÁª¥Â∫¶Êç¢‰Ωç12345678910111213141516171819202122232425262728293031def gram_matrix(features, normalize=True): """ Compute the Gram matrix from features. Inputs: - features: PyTorch Tensor of shape (N, C, H, W) giving features for a batch of N images. - normalize: optional, whether to normalize the Gram matrix If True, divide the Gram matrix by the number of neurons (H * W * C) Returns: - gram: PyTorch Tensor of shape (N, C, C) giving the (optionally normalized) Gram matrices for the N input images. """ # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N,C,H,W = features.size() # N,C,M features = features.view(N,C,H*W) # N,C,M x N,M,C -&gt; N,C,C gram = features.matmul(features.permute(0,2,1)) if normalize==True: gram /= (H*W*C) return gram # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** loss implement ËæìÂÖ• featsÔºöÁé∞Âú®ÂõæÁâáÁöÑÊØè‰∏ÄÂ±ÇÁöÑfeatureÔºå‰ªé‰∏äÈù¢ÁöÑÊèêÂèñÁâπÂæÅÂáΩÊï∞ÂæóÂà∞ style_layersÔºöindices style_targetsÔºöÂíå‰∏äÈù¢ÁöÑÈïøÂ∫¶Áõ∏ÂêåÔºåËÆ°ÁÆóÁöÑÊòØÁ¨¨iÂ±ÇÂéüÂõæÁâáÂæóÂà∞ÁöÑG Mat style_weightsÔºöscalar Âú®ËÆ°ÁÆóÁöÑÊó∂ÂÄôÂè™ÈúÄË¶ÅËÄÉËôëÊØè‰∏ÄÂ±ÇÈáåÈù¢ËÆ°ÁÆóÂá∫Êù•ÁöÑÁé∞Âú®ÁöÑG MatÔºàÊ≥®ÊÑèÁ¥¢Âºï‰∏çÊòØiÔºâÂíåÂéüÂõæÁâáÁöÑGÔºåÂíå‰∏äÈù¢‰∏ÄÊ†∑ÁöÑËÆ°ÁÆóÂ∞±ÂèØ‰ª•‰∫Ü 123456789101112131415161718192021222324252627282930313233# Now put it together in the style_loss function...def style_loss(feats, style_layers, style_targets, style_weights): """ Computes the style loss at a set of layers. Inputs: - feats: list of the features at every layer of the current image, as produced by the extract_features function. - style_layers: List of layer indices into feats giving the layers to include in the style loss. - style_targets: List of the same length as style_layers, where style_targets[i] is a PyTorch Tensor giving the Gram matrix of the source style image computed at layer style_layers[i]. - style_weights: List of the same length as style_layers, where style_weights[i] is a scalar giving the weight for the style loss at layer style_layers[i]. Returns: - style_loss: A PyTorch Tensor holding a scalar giving the style loss. """ # Hint: you can do this with one for loop over the style layers, and should # not be very much code (~5 lines). You will need to use your gram_matrix function. # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** loss = torch.tensor(0.).type(dtype) for i in range(len(style_layers)): G_Mat = gram_matrix(feats[style_layers[i]]) loss_layer = style_weights[i] * torch.sum((style_targets[i] - G_Mat)**2) loss += loss_layer return loss # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** total-variation reg ‰∏∫‰∫ÜËÆ©ÂõæÁâáÊòæÁ§∫ÁöÑÂÜÖÂÆπÊõ¥Âä†Âπ≥ÊªëÔºåÂä†ÂÖ•‰∫ÜËøô‰∏™ÊÉ©ÁΩöÈÉ®ÂàÜ ËÆ°ÁÆóÁöÑÊñπÊ≥ïÂèØ‰ª•ÊòØËÆ°ÁÆóÊØè‰∏™ÂÉèÁ¥†ÂíåÂÆÉÁõ∏ÈÇªÂÉèÁ¥†ÁöÑÂ∑ÆÁöÑÂπ≥ÊñπÂíåÔºàÁõ∏ÈÇªÂÉèÁ¥†ÂàÜÂà´ÂåÖÊã¨ÂûÇÁõ¥ÂíåÊ∞¥Âπ≥Ôºâ ÈúÄË¶ÅËÆ©ÁªìÊûúvecÂåñÔºåÁõ¥Êé•Áî®-1ÊääÁü©ÈòµÈîô‰Ωç‰∏Ä‰∏™ 123456789101112131415161718192021def tv_loss(img, tv_weight): """ Compute total variation loss. Inputs: - img: PyTorch Variable of shape (1, 3, H, W) holding an input image. - tv_weight: Scalar giving the weight w_t to use for the TV loss. Returns: - loss: PyTorch Variable holding a scalar giving the total variation loss for img weighted by tv_weight. """ # Your implementation should be vectorized and not require any loops! # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** H_var = torch.sum((img[:,:,1:,:] - img[:,:,:-1,:])**2) W_var = torch.sum((img[:,:,:,1:] - img[:,:,:,:-1])**2) return (H_var + W_var) * tv_weight # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** Â∑≤ÁªèÂÜôÂ•Ω‰∫ÜËΩ¨ÂåñstyleÁöÑÂáΩÊï∞ È¶ñÂÖàÊèêÂèñcontentÂíåstyleÂõæÁâáÁöÑÁâπÂæÅ ÁÑ∂ÂêéÂàùÂßãÂåñÈúÄË¶ÅÁîüÊàêÁöÑÂõæÁâáÔºåËøôÂº†ÂõæÁâá‰∏äÈù¢ÈúÄË¶ÅÊâìÂºÄgrad ËÆæÁΩÆÂ•ΩhyperÔºåËÆæÂÆöÂ•Ωoptimizer ÁÑ∂ÂêéÂú®‰∏ÄÂÆöÁöÑËåÉÂõ¥ÈáåÔºåÁî®cnnÊèêÂèñÁé∞Âú®ÂõæÁâáÁöÑÁâπÂæÅ Áî®Áé∞Âú®ÁöÑÁâπÂæÅËÆ°ÁÆólossÔºåÁÑ∂ÂêéÊîπÂèòÁé∞Âú®ÁöÑÂõæÁâá]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
        <category>CS231n‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>style transfer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nassignment3Vis]]></title>
    <url>%2F2019%2F05%2F21%2FCS231nassignment3Vis%2F</url>
    <content type="text"><![CDATA[Network Visualization (PyTorch) Âú®ËøôÈÉ®ÂàÜÁî®‰∫Ü‰∏Ä‰∏™Â∑≤ÁªèÂú®ImageNet‰∏äÈù¢pretrainËøáÁöÑCNN Áî®Ëøô‰∏™CNNÊù•ÂÆö‰πâ‰∏Ä‰∏™loss functionÔºåÁÑ∂ÂêéÁî®Ëøô‰∏™lossÊù•ÊµãÈáèÁé∞Âú®ÁöÑ‰∏çÈ´òÂÖ¥Á®ãÂ∫¶ backÁöÑÊó∂ÂÄôËÆ°ÁÆóËøô‰∏™lossÂØπ‰∫éÊØè‰∏™ÂÉèÁ¥†ÁöÑgradient ‰øùÊåÅËøô‰∏™model‰∏çÂèòÔºå‰ΩÜÊòØÂú®ÂõæÁâá‰∏äÈù¢Â±ïÁ§∫Âá∫Êù•gradientsÁöÑ‰∏ãÈôçÔºåÂΩ¢ÊàêËÆ©lossÊúÄÂ∞èÁöÑÂõæÁâá Ëøô‰∏™‰Ωú‰∏ö‰∏ÄÂÖ±ÂàÜÊàê‰∏â‰∏™ÈÉ®ÂàÜÔºö saliency mapÔºö‰∏Ä‰∏™ÊØîËæÉÂø´ÁöÑÊñπÊ≥ïÊù•Â±ïÁ§∫Ëøô‰∏™ÂõæÁâáÂì™‰∏™ÈÉ®ÂàÜÂΩ±Âìç‰∫ÜnetÂàÜÁ±ªÁöÑÂÜ≥ÂÆö fooling imageÔºöÊâ∞‰π±‰∏Ä‰∏™ÂõæÁâáÔºåËÆ©‰ªñÁúãËµ∑Êù•Ë∑ü‰∫∫‰ººÁöÑÔºå‰ΩÜÊòØ‰ºöË¢´ËØØÂàÜÁ±ª class visualizationÔºöÂΩ¢ÊàêÂèØ‰ª•ÂæóÂà∞ÊúÄÂ§ßÂàÜÁ±ªÂæóÂàÜÁöÑÂõæÁâá Ê≥®ÊÑèËøôÈáåÈúÄË¶ÅÂÖàÊøÄÊ¥ªcondaÔºå‰∏çÁÑ∂Âú®jupterÈáåÈù¢torch‰ºöÊä•Èîô ‰∫ãÂÖàÂ§ÑÁêÜ ‰∫ãÂÖàÂÆö‰πâ‰∫ÜÂáΩÊï∞preprocessÁöÑÈÉ®ÂàÜÔºåÂõ†‰∏∫pretrainÁöÑÊó∂ÂÄô‰πüÊòØÊèêÂâçËøõË°åÂ•Ω‰∫ÜÈ¢ÑÂ§ÑÁêÜ ÈúÄË¶Å‰∏ãËΩΩ‰∏ãÊù•È¢ÑÂ§ÑÁêÜÁöÑÊ®°ÂûãÔºåËøôÈáåÁî®ÁöÑÊòØSqueezeNetÔºåÂõ†‰∏∫ËøôÊ†∑ÂèØ‰ª•Áõ¥Êé•Âú®CPU‰∏äÈù¢ÂΩ¢ÊàêÂõæÁâá ËØªÂèñ‰∏ÄÈÉ®ÂàÜImageNetÈáåÈù¢ÁöÑÂõæÁâáÁúã‰∏ÄÁúãÊòØ‰ªÄ‰πàÊ†∑Â≠êÁöÑ saliency maps saliencyÂëäËØâÊàë‰ª¨ÊØè‰∏™pixelÂØπÂàÜÁ±ªÂæóÂàÜÁöÑÂΩ±Âìç ‰∏∫‰∫ÜËÆ°ÁÆóËøô‰∏™‰∏úË•øÔºåÊàë‰ª¨ÈúÄË¶ÅËÆ°ÁÆóÊ≤°ÊúâÊ≠£ÂàôÂåñ‰πãÂâçÁöÑscoreÂØπ‰∫éÊ≠£Á°ÆÂàÜÁ±ªÁöÑgradientÔºàÂÖ∑‰ΩìÂà∞ÊØè‰∏™pixelÔºâ ÊØîÂ¶ÇÂõæÁâáÁöÑÂ§ßÂ∞èÊòØ3xHxWÔºåÈÇ£‰πàÂæóÂà∞ÁöÑgradientÁöÑÂΩ¢Áä∂‰πüÂ∫îËØ•ÊòØ3xHxW Ë°®Á§∫ÁöÑÂ∞±ÊòØËøô‰∏™pixelÊîπÂèòÁöÑËØùÂØπ‰∫éÊï¥‰∏™ÁªìÊûúÊîπÂèòÁöÑÂΩ±Âìç ‰∏∫‰∫ÜËÆ°ÁÆóÔºåÊàë‰ª¨ÂèñÊØè‰∏™gradientÁöÑÁªùÂØπÂÄºÔºåÁÑ∂ÂêéÂèñ‰∏â‰∏™channelÈáåÈù¢ÁöÑÊúÄÂ§ßÂÄºÔºåÊúÄÂêéÂæóÂà∞ÁöÑÂ§ßÂ∞èÊòØHxW gather method Â∞±ÂÉèÂú®assignment1ÈáåÈù¢ÈÄâÊã©‰∏Ä‰∏™Áü©ÈòµÈáåÈù¢ÁöÑÊúÄÂ§ßÂÄº‰∏ÄÊ†∑ÔºågatherËøô‰∏™ÊñπÊ≥ïÂ∞±ÊòØÂú®s.gather(1, y.view(-1, 1)).squeeze()‰∏Ä‰∏™NÔºåCÁöÑÁü©ÈòµsÈáåÈù¢ÈÄâÊã©ÂØπÂ∫îÁöÑyÈÇ£‰∏™ÁöÑÂÄºÁÑ∂ÂêéÂΩ¢Êàê‰∏Ä‰∏™Ë°åÁöÑÊï∞ÁªÑ compute_saliency_map ËæìÂÖ•Ôºö X:ËæìÂÖ•ÁöÑÂõæÁâá (N,3,H,W) y:label (N,) model:È¢ÑËÆ≠ÁªÉÂ•ΩÁöÑÊ®°Âûã ËæìÂá∫Ôºö saliencyÔºåÂ§ßÂ∞èÊòØÔºàNÔºåHÔºåWÔºâ Ê≥®ÊÑèÔºåÂõ†‰∏∫torchËøô‰∏™ÂØπË±°Ëá™Â∑±Êú¨Êù•Â∞±Â∑≤ÁªèÂ∏¶ÁùÄgrad‰∫ÜÔºåÊâÄ‰ª•Áõ¥Êé•Ê±ÇÂá∫Êù•Â∞±ÂèØ‰ª•‰∫ÜÔºå‰ΩÜÊòØÊ≥®ÊÑèÈúÄË¶ÅÂÆö‰πâ‰∏Ä‰∏ãbackward‰πãÂêéÁöÑÂ§ßÂ∞èÂ∫îËØ•ÊòØÂ§öÂ∞ë 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def compute_saliency_maps(X, y, model): """ Compute a class saliency map using the model for images X and labels y. Input: - X: Input images; Tensor of shape (N, 3, H, W) - y: Labels for X; LongTensor of shape (N,) - model: A pretrained CNN that will be used to compute the saliency map. Returns: - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input images. """ # Make sure the model is in "test" mode model.eval() # Make input tensor require gradient X.requires_grad_() saliency = None ############################################################################## # TODO: Implement this function. Perform a forward and backward pass through # # the model to compute the gradient of the correct class score with respect # # to each input image. You first want to compute the loss over the correct # # scores (we'll combine losses across a batch by summing), and then compute # # the gradients with a backward pass. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** #forward #NxC scores = model(X) #N correct_scores = scores.gather(1,y.view(-1,1)).squeeze() #backward correct_scores.backward(torch.ones(correct_scores.size())) saliency = X.grad saliency = saliency.abs() saliency,_ = torch.max(saliency, dim = 1) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return saliency fooling images ÂèØ‰ª•ÁîüÊàêfooling imageÔºåÁªô‰∏Ä‰∏™imageÂíå‰∏Ä‰∏™ÁõÆÊ†áclassÔºåÊàë‰ª¨ËÆ©gradient‰∏ÄÁõ¥ÂçáÈ´òÔºåÂéªËÆ©ÁõÆÊ†áÁöÑscoreÊúÄÂ§ßÔºå‰∏ÄÁõ¥Âà∞ÊúÄÂêéÁöÑÂàÜÁ±ªÊòØÁõÆÊ†áÁöÑÂàÜÁ±ª ËæìÂÖ• X (1,3,224,224) target_y Âú®0-1000ÁöÑËåÉÂõ¥ÈáåÈù¢ model È¢ÑËÆ≠ÁªÉÁöÑCNN ËæìÂá∫Ôºö x_fooling TODO When computing an update step, first normalize the gradient:# dX = learning_rate * g / ||g||_2 ÈúÄË¶ÅËá™Â∑±ÂÜô‰∏Ä‰∏™ËÆ≠ÁªÉÁöÑÈÉ®ÂàÜ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def make_fooling_image(X, target_y, model): """ Generate a fooling image that is close to X, but that the model classifies as target_y. Inputs: - X: Input image; Tensor of shape (1, 3, 224, 224) - target_y: An integer in the range [0, 1000) - model: A pretrained CNN Returns: - X_fooling: An image that is close to X, but that is classifed as target_y by the model. """ # Initialize our fooling image to the input image, and make it require gradient X_fooling = X.clone() X_fooling = X_fooling.requires_grad_() learning_rate = 1 ############################################################################## # TODO: Generate a fooling image X_fooling that the model will classify as # # the class target_y. You should perform gradient ascent on the score of the # # target class, stopping when the model is fooled. # # When computing an update step, first normalize the gradient: # # dX = learning_rate * g / ||g||_2 # # # # You should write a training loop. # # # # HINT: For most examples, you should be able to generate a fooling image # # in fewer than 100 iterations of gradient ascent. # # You can print your progress over iterations to check your algorithm. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** for i in range(100): scores = model(X_fooling) index = torch.argmax(scores,dim = 1) if index[0] == target_y: break target_score = scores[0,target_y] target_score.backward() grad = X_fooling.grad.data X_fooling.data += learning_rate * (grad/grad.norm()) X_fooling.grad.zero_() # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return X_fooling class visualization ‰ªé‰∏Ä‰∏™ÈöèÊú∫ÁöÑnoiseÂºÄÂßãÁÑ∂ÂêéÂæÄÁõÆÊ†áÁöÑclass‰∏äÈù¢Â¢ûÂä†gradient 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980def create_class_visualization(target_y, model, dtype, **kwargs): """ Generate an image to maximize the score of target_y under a pretrained model. Inputs: - target_y: Integer in the range [0, 1000) giving the index of the class - model: A pretrained CNN that will be used to generate the image - dtype: Torch datatype to use for computations Keyword arguments: - l2_reg: Strength of L2 regularization on the image - learning_rate: How big of a step to take - num_iterations: How many iterations to use - blur_every: How often to blur the image as an implicit regularizer - max_jitter: How much to gjitter the image as an implicit regularizer - show_every: How often to show the intermediate result """ model.type(dtype) l2_reg = kwargs.pop('l2_reg', 1e-3) learning_rate = kwargs.pop('learning_rate', 25) num_iterations = kwargs.pop('num_iterations', 100) blur_every = kwargs.pop('blur_every', 10) max_jitter = kwargs.pop('max_jitter', 16) show_every = kwargs.pop('show_every', 25) # Randomly initialize the image as a PyTorch Tensor, and make it requires gradient. img = torch.randn(1, 3, 224, 224).mul_(1.0).type(dtype).requires_grad_() for t in range(num_iterations): # Randomly jitter the image a bit; this gives slightly nicer results ox, oy = random.randint(0, max_jitter), random.randint(0, max_jitter) img.data.copy_(jitter(img.data, ox, oy)) ######################################################################## # TODO: Use the model to compute the gradient of the score for the # # class target_y with respect to the pixels of the image, and make a # # gradient step on the image using the learning rate. Don't forget the # # L2 regularization term! # # Be very careful about the signs of elements in your code. # ######################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** scores = model(img) target_score = scores[0,target_y] target_score.backward() grad = img.grad.data grad -= 2*l2_reg * img.data img.data += learning_rate * (grad/grad.norm()) img.grad.zero_() # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ######################################################################## # END OF YOUR CODE # ######################################################################## # Undo the random jitter img.data.copy_(jitter(img.data, -ox, -oy)) # As regularizer, clamp and periodically blur the image for c in range(3): lo = float(-SQUEEZENET_MEAN[c] / SQUEEZENET_STD[c]) hi = float((1.0 - SQUEEZENET_MEAN[c]) / SQUEEZENET_STD[c]) img.data[:, c].clamp_(min=lo, max=hi) if t % blur_every == 0: blur_image(img.data, sigma=0.5) # Periodically show the image if t == 0 or (t + 1) % show_every == 0 or t == num_iterations - 1: plt.imshow(deprocess(img.data.clone().cpu())) class_name = class_names[target_y] plt.title('%s\nIteration %d / %d' % (class_name, t + 1, num_iterations)) plt.gcf().set_size_inches(4, 4) plt.axis('off') plt.show() return deprocess(img.data.cpu())]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
        <category>CS231n‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>ÂèØËßÜÂåñ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nassignment3LSTM]]></title>
    <url>%2F2019%2F05%2F17%2FCS231nassignment3LSTM%2F</url>
    <content type="text"><![CDATA[targetimplement LSTM update rule and use it for image captioning LSTM Âú®vanilla RNNÈáåÈù¢ÔºåÂèØ‰ª•Ê†πÊçÆvanillaÊù•ËÆ°ÁÆóÈïøÁöÑsequenceÔºå‰ΩÜÊòØÂêåÊ†∑‰ºöÂõ†‰∏∫‰∏çÂÅúÁöÑ‰πòÁü©ÈòµÂØºËá¥gradientÁàÜÁÇ∏ÁöÑÈóÆÈ¢òÔºåLSTM‰∏ªË¶ÅÂ∞±ÊòØÁî®‰∫Ü‰∏Ä‰∏™ÂÖ∂‰ªñÁöÑupdate ruleËß£ÂÜ≥‰∫ÜËøô‰∏™ÈóÆÈ¢ò Âíåvanilla RNNÂ∑Æ‰∏çÂ§öÔºåÁé∞Âú®Ëøô‰∏™stepÁöÑxÔºåÂâç‰∏Ä‰∏™hidden state„ÄÇLSTM‰øùÊåÅÁùÄH-dÁöÑcell stateÔºåÊâÄ‰ª•‰πü‰ºö‰ªéÂâç‰∏Ä‰∏™Êé•Êî∂Âà∞Ââç‰∏Ä‰∏™ÁöÑcell state„ÄÇ LSTM‰ºöÂ≠¶‰∏Ä‰∏™input-to-hiddenÁöÑÁü©Èòµ 4HxDÔºå hidden-to-hiddenÁöÑÁü©Èòµ 4HxHÔºå bias 4H Âú®ÊØè‰∏ÄÈÉ®ÈÉΩ‰ºöÂÖàËÆ°ÁÆóË¢´ÊøÄÊ¥ª‰πãÂêéÁöÑÂáΩÊï∞Ôºà4HÔºâÔºåÁÑ∂ÂêéÊääËøô‰∏™ÁªìÊûúaÂàÜÊàêÂõõ‰∏™ÈÉ®ÂàÜÔºåÊØè‰∏™ÈÉ®ÂàÜÁöÑÂ§ßÂ∞èÊòØH Ê†πÊçÆËøôÂõõ‰∏™ÈÉ®ÂàÜËÆ°ÁÆóinput gateÔºåforget gateÔºåoutput gateÔºåblock gate Ââç‰∏â‰∏™ÈÉΩÁî®sigmoidÊøÄÊ¥ªÔºåÊúÄÂêé‰∏Ä‰∏™Áî®tanhÊøÄÊ¥ª ÁÑ∂ÂêéÁî®‰∏äÈù¢ÁöÑÂõõ‰∏™ÂèÇÊï∞ËÆ°ÁÆó‰∏ã‰∏Ä‰∏™cell stateÂíåhidden state step forward ËæìÂÖ•ÁöÑÂ§ßÂ∞èÊòØDÔºåhiddenÁöÑÂ§ßÂ∞èÊòØHÔºåminibatchÁöÑÂ§ßÂ∞èÊòØN input x (N,D) prev_h (N,H) prev_c (N,H) Wx input 2 hidden (D,4H) Wh hidden 2 hidden (H,4H) bias, (4H) output next_h (N,H) next_c (N,H) cache ÊåâÁÖß‰πãÂâçÁªôÁöÑÂÖ¨ÂºèÁõ¥Êé•ËÆ°ÁÆóÂ∞±Ë°å‰∫ÜÔºåÂÖ∂ÂÆûÂ∞±ÊòØÊääÂéüÊù•Ê±ÇÂá∫Êù•ÁöÑÂÄºÂàÜÊàê‰∫ÜÂõõ‰∏™ÈÉ®ÂàÜÔºåÂàÜÂà´Ê±ÇÂá∫Êù•‰∫ÜÂõõ‰∏™Êñ∞ÁöÑÂÄºÔºåÁî®ËøôÂõõ‰∏™Êñ∞ÁöÑÂÄºÁöÑÂÖ¨ÂºèÂèØ‰ª•ÂæóÂà∞‰∏ã‰∏Ä‰∏™Áä∂ÊÄÅÁöÑcÂíåh step backward input dnext_h (N,H) ÈÉΩÊòØ‰∏äÈù¢‰∏Ä‰∏™ÂõûÊù•ÁöÑ dnext_c (N,H) cache output dx(N,D) dprev_h (N,H) dprev_c (N,H) dWx (D,4H) dWh (H,4H) db (4H) ÊåâÁùÄÊ≠£ÊñπÂêëËÆ°ÁÆóÁöÑÈ°∫Â∫èbackÂõûÂéªÂ∞±ÂèØ‰ª•‰∫ÜÔºåÊ≥®ÊÑèËøôÈáåÊúâ‰∏™ÈóÆÈ¢òÂ∞±ÊòØÂõ†‰∏∫next_cË¢´Áî®Êù•ËÆ°ÁÆónext h‰∫ÜÔºåÊâÄ‰ª•dnext_cÈúÄË¶ÅÂÜçÊ±Ç‰∏Ä‰∏ãÂÖ≥‰∫énext hÁöÑÂØºÊï∞ÔºåÂπ∂‰∏îÊääÊ±ÇÂá∫Êù•ÁöÑÊñ∞ÁöÑÂÄºÂä†Âú®‰ª•ÂâçÁöÑ‰∏úË•ø‰∏äÈù¢ ÂêéÈù¢ÁöÑÁü©ÈòµËÆ°ÁÆóÂ∞∫ÂØ∏ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124def lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b): """ Forward pass for a single timestep of an LSTM. The input data has dimension D, the hidden state has dimension H, and we use a minibatch size of N. Note that a sigmoid() function has already been provided for you in this file. Inputs: - x: Input data, of shape (N, D) - prev_h: Previous hidden state, of shape (N, H) - prev_c: previous cell state, of shape (N, H) - Wx: Input-to-hidden weights, of shape (D, 4H) - Wh: Hidden-to-hidden weights, of shape (H, 4H) - b: Biases, of shape (4H,) Returns a tuple of: - next_h: Next hidden state, of shape (N, H) - next_c: Next cell state, of shape (N, H) - cache: Tuple of values needed for backward pass. """ next_h, next_c, cache = None, None, None ############################################################################# # TODO: Implement the forward pass for a single timestep of an LSTM. # # You may want to use the numerically stable sigmoid implementation above. # ############################################################################# # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, H = prev_h.shape # -&gt; N,4H a = x.dot(Wx) + prev_h.dot(Wh) + b a_i = a[:, :H] a_f = a[:, H:2 * H] a_o = a[:, 2 * H:3 * H] a_g = a[:, 3 * H:] i = sigmoid(a_i) f = sigmoid(a_f) o = sigmoid(a_o) g = np.tanh(a_g) next_c = f * prev_c + i * g next_h = o * np.tanh(next_c) cache = (x, prev_h, prev_c, Wx, Wh, a, i, f, o, g, next_c, next_h) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return next_h, next_c, cachedef lstm_step_backward(dnext_h, dnext_c, cache): """ Backward pass for a single timestep of an LSTM. Inputs: - dnext_h: Gradients of next hidden state, of shape (N, H) - dnext_c: Gradients of next cell state, of shape (N, H) - cache: Values from the forward pass Returns a tuple of: - dx: Gradient of input data, of shape (N, D) - dprev_h: Gradient of previous hidden state, of shape (N, H) - dprev_c: Gradient of previous cell state, of shape (N, H) - dWx: Gradient of input-to-hidden weights, of shape (D, 4H) - dWh: Gradient of hidden-to-hidden weights, of shape (H, 4H) - db: Gradient of biases, of shape (4H,) """ dx, dprev_h, dprev_c, dWx, dWh, db = None, None, None, None, None, None ############################################################################# # TODO: Implement the backward pass for a single timestep of an LSTM. # # # # HINT: For sigmoid and tanh you can compute local derivatives in terms of # # the output value from the nonlinearity. # ############################################################################# # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, H = dnext_h.shape x, prev_h, prev_c, Wx, Wh, a, i, f, o, g, next_c, next_h = cache # dnext_h/do -&gt; do do = np.tanh(next_c) * dnext_h # dnext_h/dnext_c dnext_c = o * (1 - np.tanh(next_c) ** 2) * dnext_h + dnext_c # dnext_c/df -&gt; df df = prev_c * dnext_c # dnext_c/dprev_c dprev_c = f * dnext_c # dnext_c/di di = g * dnext_c # dnext_c/dg dg = i * dnext_c da = np.zeros((N, 4 * H)) # sigmoid i da[:, :H] = i * (1 - i) * di da[:, H:2 * H] = f * (1 - f) * df da[:, 2 * H:3 * H] = o * (1 - o) * do da[:, 3 * H:] = (1 - g * g) * dg # a = x.dot(Wx) + prev_h.dot(Wh) + b # N,4H D,4H dx = da.dot(Wx.T) # N,D N,4H dWx = x.T.dot(da) # N,4H H,4H dprev_h = da.dot(Wh.T) # N,H N,4H dWh = prev_h.T.dot(da) # da N,4H db = np.sum(da, axis=0) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dx, dprev_h, dprev_c, dWx, dWh, db forward ËæìÂÖ•‰∫Ü‰∏ÄÂ§ß‰∏≤dataÔºåÂÅáËÆæËæìÂÖ•ÁöÑdataÂåÖÊã¨‰∫ÜT‰∏™vectorÔºåÊØè‰∏™ÁöÑdimÊòØDÔºåÁî®ÁöÑhiddenÁöÑÂ§ßÂ∞èÊòØHÔºåÂú®NÁöÑminibatch‰∏äÈù¢ËøõË°åÔºåËøîÂõûÂØπ‰∫éÊâÄÊúâtime stepÁöÑhidden state ÂàùÂßãÂåñÁöÑcellÊòØ0Ôºå‰∏ç‰ºöreturn cell stateÔºåÂè™ÊòØLSTMËá™Â∑±ÁöÑÂèòÈáè ËæìÂÖ• x (N,T,D) h0, (N,H) Wx (D,4H) Wh (H,4H) b (4H) out h (N,T,D) cache Ê≥®ÊÑèhÊòØÈúÄË¶ÅÂàùÂßãÂåñ‰∏∫0ÁöÑÔºåÊØèÊ¨°forÈáåÈù¢ÊãøÂá∫Êù•ÁöÑÊòØhÈáåÈù¢ÁöÑ‰∏ÄÈÉ®ÂàÜÊù•ËµãÂÄº backward Âíå‰πãÂâçÁöÑÂ∑Æ‰∏çÂ§öÔºåÊ≥®ÊÑèWÂíåbÈÉΩÊòØË¶ÅÁßØÁ¥ØÁöÑÔºå‰πãÂâçÈÉΩÊòØË¶ÅÂàùÂßãÂåñÁöÑ ËÄå‰∏îbackÁöÑÊó∂ÂÄôË¶ÅÁî®reversedÁöÑÈ°∫Â∫è 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104def lstm_forward(x, h0, Wx, Wh, b): """ Forward pass for an LSTM over an entire sequence of data. We assume an input sequence composed of T vectors, each of dimension D. The LSTM uses a hidden size of H, and we work over a minibatch containing N sequences. After running the LSTM forward, we return the hidden states for all timesteps. Note that the initial cell state is passed as input, but the initial cell state is set to zero. Also note that the cell state is not returned; it is an internal variable to the LSTM and is not accessed from outside. Inputs: - x: Input data of shape (N, T, D) - h0: Initial hidden state of shape (N, H) - Wx: Weights for input-to-hidden connections, of shape (D, 4H) - Wh: Weights for hidden-to-hidden connections, of shape (H, 4H) - b: Biases of shape (4H,) Returns a tuple of: - h: Hidden states for all timesteps of all sequences, of shape (N, T, H) - cache: Values needed for the backward pass. """ h, cache = None, None ############################################################################# # TODO: Implement the forward pass for an LSTM over an entire timeseries. # # You should use the lstm_step_forward function that you just defined. # ############################################################################# # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, T, D = x.shape N, H = h0.shape prev_h = h0 prev_c = np.zeros((N, H)) cache = &#123;&#125; h = np.zeros((N, T, H)) for step in range(T): prev_h, prev_c, cache_step = lstm_step_forward( x[:, step, :], prev_h, prev_c, Wx, Wh, b) h[:, step, :] = prev_h cache[step] = cache_step # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return h, cachedef lstm_backward(dh, cache): """ Backward pass for an LSTM over an entire sequence of data.] Inputs: - dh: Upstream gradients of hidden states, of shape (N, T, H) - cache: Values from the forward pass Returns a tuple of: - dx: Gradient of input data of shape (N, T, D) - dh0: Gradient of initial hidden state of shape (N, H) - dWx: Gradient of input-to-hidden weight matrix of shape (D, 4H) - dWh: Gradient of hidden-to-hidden weight matrix of shape (H, 4H) - db: Gradient of biases, of shape (4H,) """ dx, dh0, dWx, dWh, db = None, None, None, None, None ############################################################################# # TODO: Implement the backward pass for an LSTM over an entire timeseries. # # You should use the lstm_step_backward function that you just defined. # ############################################################################# # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x = cache[0][0] # Ê≥®ÊÑèËøôÊòØ‰∏Ä‰∏™stepÈáåÈù¢ÁöÑxÔºåÂ§ßÂ∞èÊòØNÔºåD N, D = x.shape _, T, H = dh.shape dx = np.zeros((N, T, D)) dprev_h = np.zeros((N, H)) dprev_c = np.zeros((N, H)) dh0 = np.zeros((N, H)) dWx = np.zeros((D, 4 * H)) dWh = np.zeros((H, 4 * H)) db = np.zeros(4 * H) for step in reversed(range(T)): dnext_h = dh[:, step, :] + dprev_h dnext_c = dprev_c dx[:, step, :], dprev_h, dprev_c, dWx_temp, dWh_temp, db_temp = lstm_step_backward( dnext_h, dnext_c, cache[step]) dWx += dWx_temp dWh += dWh_temp db += db_temp dh0 = dprev_h # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dx, dh0, dWx, dWh, db Ââ©‰∏ãÁöÑÂíåRNNÈÉ®ÂàÜÊ≤°Êúâ‰ªÄ‰πàÂå∫Âà´‰∫ÜÔºå‰∏ªË¶ÅÂ∞±ÊòØÊää‰ª£Á†ÅÁöÑÈÄâÈ°πÈáåÈù¢Âä†‰∏älstmÁöÑÈÉ®ÂàÜ]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
        <category>CS231n‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>word captioning</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫égithubÂà†Èô§Âíåignore]]></title>
    <url>%2F2019%2F05%2F16%2F%E5%85%B3%E4%BA%8Egithub%E5%88%A0%E9%99%A4%E5%92%8Cignore%2F</url>
    <content type="text"><![CDATA[removeaddËøáÁöÑÊñá‰ª∂Â¶ÇÊûúÊÉ≥Ë¶ÅÈÉΩÊí§ÈîÄ‰∫Ü‰øÆÊîπgit rm -r --cached .Ôºà‰∏çÂ∞èÂøÉadd‰πãÂêéÂÖ≥‰∏ä‰∫ÜÁöÑÊÉÖÂÜµÔºâÂ¶ÇÊûústatus‰πãÂêéÂ∞±ÂèëÁé∞‰∏çÂØπÔºåÂèØ‰ª•Áî®git reset HEAD &lt;file&gt;ÔºåÂêéÈù¢Âä†ÁÇπÂ∞±ÊòØÊí§ÈîÄÂÖ®ÈÉ®ÁöÑ Â¶ÇÊûúÂ∑≤Áªèpush‰∫ÜÔºåÂèØ‰ª•ËøòÂéüÁâàÊú¨12345git revert HEAD Êí§ÈîÄÂâç‰∏ÄÊ¨° commit git revert HEAD^ Êí§ÈîÄÂâçÂâç‰∏ÄÊ¨° commit git revert commit-id (Êí§ÈîÄÊåáÂÆöÁöÑÁâàÊú¨ÔºåÊí§ÈîÄ‰πü‰ºö‰Ωú‰∏∫‰∏ÄÊ¨°Êèê‰∫§ËøõË°å‰øùÂ≠òÔºâ (refÔºöhttps://blog.csdn.net/kongbaidepao/article/details/52253774) ignoreÊúâ‰∏Ä‰∫õÊØîËæÉÂ§ßÁöÑÊñá‰ª∂ÊÉ≥Ë¶ÅÂøΩÁï•ÊéâÁöÑÔºåÈúÄË¶ÅÂú®Ê†πÁõÆÂΩïÂª∫Á´ã‰∏Ä‰∏™.gitignoreÔºåÈáåÈù¢Áõ¥Êé•ÊîæÈúÄË¶ÅÁöÑË∑ØÂæÑÂ∞±ÂèØ‰ª•‰∫Ü ‰∏çË¶ÅÂæÄÈáåÈù¢‰º†ÂæàÂ§ßÁöÑÊï∞ÊçÆÈ∏≠‰ºöÁàÜÁÇ∏ÁöÑTAT]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>gitignore</tag>
        <tag>remove</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment3RNN]]></title>
    <url>%2F2019%2F05%2F10%2FCS231Nassignment3RNN%2F</url>
    <content type="text"><![CDATA[assignment3 targetIn this exercise you will implement a vanilla recurrent neural networks and use them it to train a model that can generate novel captions for images. Microsoft COCO Âú®ËøôÊ¨°ÁöÑ‰Ωú‰∏öÈáåÁî®ÁöÑÊòØMicrosoftÁöÑcoco datasetÔºåÂ∑≤ÁªèÊòØ‰∏Ä‰∏™ÂæàÂ∏∏Áî®ÁöÑÁªôÊñáÂ≠óÈÖç‰∏äËØ¥ÊòéÊñáÔºàcaptioningÔºâÁöÑdataset‰∫ÜÔºåÊúâ80000‰∏™ËÆ≠ÁªÉÂíå40000‰∏™valÔºåÊØè‰∏™ÂõæÁâáÂåÖÂê´‰∏Ä‰∏™‰∫î‰∏™Â≠óÁöÑÊ≥®Èáä Âú®Ëøô‰∏™‰Ωú‰∏öÈáåÂ∑≤Áªèpreprocess‰∫ÜdataÔºåÊØè‰∏™ÂõæÁâáÂ∑≤Áªè‰ªéVGG-16ÔºàImageNet pretrainÔºâlayer 7ÊèêÂèñ‰∫ÜfeatureÔºåÂ≠òÂú®‰∫Ütrain2014_vgg16_fc7.h5Âíåval2014_vgg16_fc7.h5 ‰∏∫‰∫ÜÂáèÂ∞ëÂ§ÑÁêÜÁöÑÊó∂Èó¥ÂíåÂÜÖÂ≠òÔºåfeatureÁöÑÁâπÂæÅ‰ªé4096ÈôçÂà∞‰∫Ü512 ÁúüÂÆûÁöÑÂõæÁâáÂ§™Â§ß‰∫ÜÔºåÊâÄ‰ª•ÊääÂõæÁâáÁöÑurlÂ≠òÂú®‰∫ÜtxtÈáåÈù¢ÔºåËøôÊ†∑Âú®visÁöÑÊó∂ÂÄôÂèØ‰ª•Áõ¥Êé•‰∏ãËΩΩËøô‰∫õÂõæÁâáÔºàÂøÖÈ°ªËÅîÁΩëÔºâ Áõ¥Êé•Â§ÑÁêÜstringÁöÑÊïàÁéáÂ§™‰Ωé‰∫ÜÔºåÊâÄ‰ª•Âú®captionÁöÑ‰∏Ä‰∏™encodedÁâàÊú¨‰∏äÈù¢ËøõË°åÂ§ÑÁêÜÔºåËøôÊ†∑ÂèØ‰ª•ÊäästringË°®Á§∫Êàê‰∏Ä‰∏≤int„ÄÇÂú®datasetÈáåÈù¢‰πüÊúâËøô‰∏§‰∏™‰πãÈó¥ËΩ¨Êç¢ÁöÑ‰ø°ÊÅØ -&gt; Âú®ËΩ¨Êç¢ÁöÑÊó∂ÂÄô‰πüÂä†‰∫ÜÊõ¥Â§öÁöÑtokens ‰∫ãÂÖàÁúã‰∫Ü‰∏Ä‰∏ãÂõæÁâáÂíåÂØπÂ∫îÁöÑËØ≠Âè• RNN Âú®ËøôÁ´†Ë¶ÅÁî®rnn language modelÊù•ËøõË°åimage captioning cs231n/rnn_layers.py step forwardvanilla RNNÁöÑsingle timestepÔºåÁî®tanhÊù•ÊøÄÊ¥ª„ÄÇËæìÂÖ•dataÁöÑÂ§ßÂ∞èÊòØDÔºåhidden layerÁöÑÂ§ßÂ∞èÊòØHÔºåminibatchÁöÑÂ§ßÂ∞èÊòØN ËæìÂÖ• x(N,D) prev_h:Ââç‰∏Ä‰∏™timestepÁöÑhidden (N,H) Wx:input- to- hidden connections (D,H) Wh:hidden-to-hidden connections (H,H) b:bias,(H,) ËøîÂõû(tuple): next_h:‰∏ã‰∏Ä‰∏™hidden stateÔºå(N,H) cache:backÈúÄË¶ÅÁöÑÊï∞ÊçÆ ÊûÑÊàê: RNNÁî®ÁöÑÂ∞±ÊòØ‰∏ä‰∏Ä‰∏™ÁöÑhÔºåËøô‰∏Ä‰∏™ÁöÑxÂêåÊó∂‰πò‰ª•‰∏çÂêåÁöÑÂèÇÊï∞ÔºåÂêàÂú®‰∏ÄËµ∑È¢ÑÊµãËøô‰∏ÄÊ¨°ÁöÑh ÂØπ‰∫éÊüê‰∏™Êó∂Èó¥ÁÇπ‰∏äÁöÑËæìÂÖ•ÔºåËøòÈúÄË¶Å‰∏ä‰∏Ä‰∏™ÁöÑstate hÔºåÂèÇÊï∞WÔºå‰πòÂú®‰∏ÄËµ∑ÂæóÂà∞Êñ∞ÁöÑstate Ëøô‰∏™ÂèÇÊï∞ÁöÑWÊó†ËÆ∫Âú®Âì™‰∏™Ê≠•È™§ÈáåÈù¢‰ΩøÁî®Ôºå‰∏ÄÁõ¥ÈÉΩÊòØ‰∏ÄÊ†∑ÁöÑ 1234567891011121314151617181920212223242526272829303132333435363738def rnn_step_forward(x, prev_h, Wx, Wh, b): """ Run the forward pass for a single timestep of a vanilla RNN that uses a tanh activation function. The input data has dimension D, the hidden state has dimension H, and we use a minibatch size of N. Inputs: - x: Input data for this timestep, of shape (N, D). - prev_h: Hidden state from previous timestep, of shape (N, H) - Wx: Weight matrix for input-to-hidden connections, of shape (D, H) - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H) - b: Biases of shape (H,) Returns a tuple of: - next_h: Next hidden state, of shape (N, H) - cache: Tuple of values needed for the backward pass. """ next_h, cache = None, None ############################################################################## # TODO: Implement a single forward step for the vanilla RNN. Store the next # # hidden state and any values you need for the backward pass in the next_h # # and cache variables respectively. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x_1 = x.dot(Wx) h_1 = prev_h.dot(Wh) x_raw = x_1 + h_1 + b next_h = np.tanh(x_raw) cache = (x, prev_h, Wx, Wh, x_raw, next_h) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return next_h, cache step backward ËæìÂÖ•Ôºö dnextÔºå‰∏ã‰∏Ä‰∏™stateÁöÑlossÁöÑgradientÔºå(N,H) cache ËæìÂá∫Ôºö dx:inputÁöÑgradientÔºå(N,D) dprev_h:Ââç‰∏Ä‰∏™hidden stateÁöÑgradientÔºå(N,H) dWx:WxÁöÑgradient,(D,H) dWh:WhÁöÑgradientÔºå(H,H) db:biasÁöÑgradientÔºå(H,) ÂÖ∂ÂÆûËøô‰∏™Ê±ÇËµ∑Êù•gradientÊõ¥ÁÆÄÂçï‰∫ÜÔºåÂõ†‰∏∫ÊØè‰∏Ä‰∏™ÁöÑÂØºÊï∞ÈÉΩÂæàÂ•ΩÊ±ÇÔºåÊêûÂØπ‰∫ÜÁü©ÈòµÁöÑÂΩ¢Áä∂Â∞±ÂèØ‰ª•‰∫Ü 123456789101112131415161718192021222324252627282930313233343536373839404142434445def rnn_step_backward(dnext_h, cache): """ Backward pass for a single timestep of a vanilla RNN. Inputs: - dnext_h: Gradient of loss with respect to next hidden state, of shape (N, H) - cache: Cache object from the forward pass Returns a tuple of: - dx: Gradients of input data, of shape (N, D) - dprev_h: Gradients of previous hidden state, of shape (N, H) - dWx: Gradients of input-to-hidden weights, of shape (D, H) - dWh: Gradients of hidden-to-hidden weights, of shape (H, H) - db: Gradients of bias vector, of shape (H,) """ dx, dprev_h, dWx, dWh, db = None, None, None, None, None ############################################################################## # TODO: Implement the backward pass for a single step of a vanilla RNN. # # # # HINT: For the tanh function, you can compute the local derivative in terms # # of the output value from tanh. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x, prev_h, Wx, Wh, x_raw, next_h = cache # d(tanh) = 1 - tanh * tanh # NxH dx_raw = (1 - next_h * next_h) * dnext_h # H, db = np.sum(dx_raw, axis=0) # N,D .T x N,H -&gt; DxH dWx = x.T.dot(dx_raw) # N H x D,H dx = dx_raw.dot(Wx.T) # N,H .T x N,H dWh = prev_h.T.dot(dx_raw) # N,H dprev_h = dx_raw.dot(Wh.T) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dx, dprev_h, dWx, dWh, db forward + backwoard ÂàöÊâçÂè™ÊòØÂÆûÁé∞‰∫ÜÊØè‰∏ÄÊ≠•ÁöÑforwardÂíåbackwardÔºåÁé∞Âú®Ë¶ÅÂÆûÁé∞Êï¥‰∏™ÁöÑËøô‰∏™ËøáÁ®ã‰∫Ü forward ÂÅáËÆæËæìÂÖ•ÁöÑÊòØ‰∏ÄÁ≥ªÂàóÁî±T‰∏™vectorÁªÑÊàêÁöÑÔºåÊØè‰∏™ÁöÑÂ§ßÂ∞èÊòØD minibatchÁöÑÂ§ßÂ∞èÊòØNÔºåhiddenÁöÑÂ§ßÂ∞èÊòØHÔºåËøîÂõûÊï¥‰∏™timesetpsÈáåÈù¢ÁöÑhidden state ËæìÂÖ• Êï¥‰∏™timestepÈáåÈù¢ÁöÑÊï∞ÊçÆx(N,T,D) h0ÔºåÂàùÂßãÂåñÁöÑhidden state(N,H) Wx (D,H) Wh (H,H) b (H,) ËæìÂá∫ hÊï¥‰∏™timestepÈáåÈù¢ÁöÑstates(N,T,H) cache ÂÆûÈôÖ‰∏äÂ∞±ÊòØÈ¶ñÂÖàËÆæÁΩÆ‰∫ÜÊúÄÂºÄÂßãÁöÑËæìÂÖ•h0ÔºåÁÑ∂ÂêéÂú®Êó∂Èó¥Âæ™ÁéØTÈáåÈù¢‰∏çÂÅúÁöÑË∞ÉÁî®‰∏äÈù¢Â∑≤ÁªèÂÜôÂ•ΩÁöÑstepÁöÑÂáΩÊï∞ÔºåÊõ¥Êñ∞prev_hÔºåÊää‰∏çÂêåÁöÑÂÄºÂ≠òÂú®cacheÈáåÈù¢ Ê≥®ÊÑèhÈúÄË¶ÅÂàùÂßãÂåñÔºÅÔºÅ backward ËæìÂÖ•‰∫ÜdhÂíåcacheÔºåÈúÄË¶ÅËæìÂá∫ÊâÄÊúâ‰∏úË•øÁöÑgradient ÊÄùË∑Ø‰∏ªË¶ÅÊòØÊØè‰∏Ä‰∏™stepÈáåÈù¢ÊòØÂä†ÁöÑÂÖ≥Á≥ªÔºåÊâÄ‰ª•ÂØπ‰∫édWxÔºådWhÂíådbÊù•ËØ¥ÔºåÈúÄË¶ÅÂú®ÊØèÊ¨°ÈÅçÂéÜÈáåÈù¢Âä†‰∏ä‰πãÂâçÁöÑÂÄºÔºåÁõ∏ÂΩì‰∫éÊØèÊ¨°ÈÉΩÈúÄË¶ÅÂä†‰∏äÊñ∞ÁöÑ‰∏úË•ø backÁöÑÊó∂ÂÄôÈúÄË¶ÅnextÁöÑÊó∂ÂÄôÊù•Ê±ÇÁé∞Âú®ÁöÑÔºåÁÑ∂ÂêéÂú®‰∏ã‰∏ÄËΩÆÊäänextÊõ¥Êñ∞ÊàêÁé∞Âú®ÁöÑ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899def rnn_forward(x, h0, Wx, Wh, b): """ Run a vanilla RNN forward on an entire sequence of data. We assume an input sequence composed of T vectors, each of dimension D. The RNN uses a hidden size of H, and we work over a minibatch containing N sequences. After running the RNN forward, we return the hidden states for all timesteps. Inputs: - x: Input data for the entire timeseries, of shape (N, T, D). - h0: Initial hidden state, of shape (N, H) - Wx: Weight matrix for input-to-hidden connections, of shape (D, H) - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H) - b: Biases of shape (H,) Returns a tuple of: - h: Hidden states for the entire timeseries, of shape (N, T, H). - cache: Values needed in the backward pass """ h, cache = None, None ############################################################################## # TODO: Implement forward pass for a vanilla RNN running on a sequence of # # input data. You should use the rnn_step_forward function that you defined # # above. You can use a for loop to help compute the forward pass. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, T, D = x.shape N, H = h0.shape h = np.zeros((N, T, H)) prev_h = h0 cache = &#123;&#125; for i in range(T): prev_h, cache_i = rnn_step_forward(x[:, i, :], prev_h, Wx, Wh, b) h[:, i, :] = prev_h cache[i] = cache_i # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return h, cachedef rnn_backward(dh, cache): """ Compute the backward pass for a vanilla RNN over an entire sequence of data. Inputs: - dh: Upstream gradients of all hidden states, of shape (N, T, H). NOTE: 'dh' contains the upstream gradients produced by the individual loss functions at each timestep, *not* the gradients being passed between timesteps (which you'll have to compute yourself by calling rnn_step_backward in a loop). Returns a tuple of: - dx: Gradient of inputs, of shape (N, T, D) - dh0: Gradient of initial hidden state, of shape (N, H) - dWx: Gradient of input-to-hidden weights, of shape (D, H) - dWh: Gradient of hidden-to-hidden weights, of shape (H, H) - db: Gradient of biases, of shape (H,) """ dx, dh0, dWx, dWh, db = None, None, None, None, None ############################################################################## # TODO: Implement the backward pass for a vanilla RNN running an entire # # sequence of data. You should use the rnn_step_backward function that you # # defined above. You can use a for loop to help compute the backward pass. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** N, T, H = dh.shape N, D = cache[0][0].shape dx = np.zeros((N, T, D)) dh0 = np.zeros((N, H)) dWx = np.zeros((D, H)) dWh = np.zeros((H, H)) db = np.zeros(H) dprev_h = np.zeros((N, H)) for i in reversed(range(T)): cache_i = cache[i] dnext_h = dh[:, i, :] + dprev_h dx[:, i, :], dprev_h, dWx_tmp, dWh_tmp, db_tmp = rnn_step_backward( dnext_h, cache_i) dWx += dWx_tmp dWh += dWh_tmp db += db_tmp dh0 = dprev_h # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dx, dh0, dWx, dWh, db word embeddingÂú®Ê∑±Â∫¶Â≠¶‰π†ÁöÑÁ≥ªÁªüÈáåÈù¢‰∏ªË¶ÅÊòØÁî®vectorÊù•Ë°®Á§∫ÂçïËØçÁöÑÔºåÂ≠óÂÖ∏ÈáåÈù¢ÁöÑÊØè‰∏Ä‰∏™ÈÉΩ‰ºöÂÖ≥Á≥ªÂà∞‰∏Ä‰∏™vectorÔºåÁÑ∂ÂêéËøô‰∫õvectors‰ºöÂíåÁ≥ªÁªüÁöÑÂÖ∂‰ªñÈÉ®ÂàÜ‰∏ÄËµ∑Â≠¶‰π†Âú®ËøôÈÉ®ÂàÜÈúÄË¶ÅÊääintË°®Á§∫ÁöÑÂçïËØçËΩ¨ÂåñÊàêvectors ÁêÜËß£ Âú®‰∏ÄÂè•ËØùÈáåÈù¢Ôºå‰∏Ä‰∏™ÂçïËØçÂ∞±ÊòØ‰∏Ä‰∏™Áª¥Â∫¶ÔºåËÄåword embeddingÁöÑÊ†∏ÂøÉÂ∞±ÊòØÈôçÁª¥ ÊääÂ≠óÁªÑÊàêÊÆµËêΩÔºåÁÑ∂ÂêéÁî®ÊÆµËêΩÊù•ÊÄªÁªìÂá∫Êù•ÊúÄÂêéÁöÑÊ†∏ÂøÉÂÜÖÂÆπ forward ‰∏Ä‰∏™minibatchÁöÑÂ§ßÂ∞èÊòØNÔºåÈïøÂ∫¶ÊòØTÔºåÊääÊØè‰∏™ÂçïËØçÁªôÂà∞‰∏Ä‰∏™Â§ßÂ∞èÊòØDÁöÑvector input x (N,T)‰∏Ä‰∏™N‰∏™Êï∞ÊçÆÔºåÊØè‰∏™Êï∞ÊçÆÈáåÈù¢T‰∏™ÂçïËØçÔºåTÁªôÂá∫Êù•ÁöÑÊòØÂçïËØçÁöÑindice W (V,D)ÁªôÊâÄÊúâwordÁöÑvectors return outÔºö(N,T,D)ÁªôÊâÄÊúâÂçïËØç‰∏Ä‰∏™DÁöÑvector cache backward backÁöÑÊó∂ÂÄô‰∏çËÉΩbackÂà∞wordÔºàÂõ†‰∏∫ÊòØintÔºâÔºåÊâÄ‰ª•Âè™ÈúÄË¶ÅÂæóÂà∞embedding matÁöÑgradient 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566def word_embedding_forward(x, W): """ Forward pass for word embeddings. We operate on minibatches of size N where each sequence has length T. We assume a vocabulary of V words, assigning each word to a vector of dimension D. Inputs: - x: Integer array of shape (N, T) giving indices of words. Each element idx of x muxt be in the range 0 &lt;= idx &lt; V. - W: Weight matrix of shape (V, D) giving word vectors for all words. Returns a tuple of: - out: Array of shape (N, T, D) giving word vectors for all input words. - cache: Values needed for the backward pass """ out, cache = None, None ############################################################################## # TODO: Implement the forward pass for word embeddings. # # # # HINT: This can be done in one line using NumPy's array indexing. # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** out = W[x, :] cache = x, W # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return out, cachedef word_embedding_backward(dout, cache): """ Backward pass for word embeddings. We cannot back-propagate into the words since they are integers, so we only return gradient for the word embedding matrix. HINT: Look up the function np.add.at Inputs: - dout: Upstream gradients of shape (N, T, D) - cache: Values from the forward pass Returns: - dW: Gradient of word embedding matrix, of shape (V, D). """ dW = None ############################################################################## # TODO: Implement the backward pass for word embeddings. # # # # Note that words can appear more than once in a sequence. # # HINT: Look up the function np.add.at # ############################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x, W = cache dW = np.zeros_like(W) np.add.at(dW, x, dout) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################## # END OF YOUR CODE # ############################################################################## return dW Temporal Affine layer Âú®ÊØè‰∏™timestepÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨ÈúÄË¶Å‰∏Ä‰∏™affineÊù•ÊääRNNÁöÑhidden vectorËΩ¨Êç¢ÊàêÊØè‰∏™ÂçïËØçÂú®vocabularyÈáåÈù¢ÁöÑscoresÔºàÂéüÊù•ÊòØÊ†πÊçÆËøô‰∏™Êù•ËØÑÂàÜÁöÑÔºåÁÑ∂ÂêéÊØèÊ¨°ÈÄâÂá∫Êù•‰∏Ä‰∏™ÂêàÈÄÇÁöÑÂçïËØçÔºâ Âõ†‰∏∫Âíå‰πãÂâçÂÅöËøáÁöÑ‰∏ÄÊ†∑ÔºåÊâÄ‰ª•Áõ¥Êé•Êèê‰æõ‰∫Ü Temporal SOftmax loss Âú®RNNÁöÑÁªìÊûÑÈáåÈù¢ÔºåÊØè‰∏™timestep‰ºöÁîüÊàê‰∏Ä‰∏™ÂØπ‰∫évocabularyÈáåÈù¢ÊâÄÊúâÂçïËØçÁöÑscore(Áü©Èòµ) Âú®ÊØèÊ≠•ÈáåÈù¢ÈÉΩÁü•ÈÅìground truthÔºåÊâÄ‰ª•Áî®softmaxÊù•ËÆ°ÁÆóÊØè‰∏ÄÊ≠•ÁöÑlossÂíågradientÔºåÁÑ∂ÂêéËÆ°ÁÆó‰∏Ä‰∏™minibatchÈáåÈù¢ÊâÄÊúâÊó∂Èó¥ÁöÑÂπ≥Âùáloss Âõ†‰∏∫ÊØè‰∏™Âè•Â≠ê‰∏ç‰∏ÄÂÆö‰∏ÄÊ†∑ÈïøÔºåÊâÄ‰ª•Âú®ÈáåÈù¢Âä†‰∏ä‰∫ÜNULLÁöÑtokenÔºåËÆ©ÊâÄÊúâ‰∏úË•ø‰∏ÄËæπÈïøÔºå‰ΩÜÊòØÂú®ËÆ°ÁÆólossÁöÑÊó∂ÂÄô‰∏çÂ∏åÊúõËÆ°ÁÆóËøô‰∏™NULL„ÄÇÊâÄ‰ª•Ëøò‰ºöÊé•Êî∂‰∏Ä‰∏™maskÊù•ÂëäËØâËøô‰∏™ÂáΩÊï∞Âì™‰∏™Âú∞ÊñπÈúÄË¶ÅÁÆóÂì™‰∏™Âú∞Êñπ‰∏çÈúÄË¶ÅÁÆó RNN for image captioning Âú®cs231n/classifiers/rnn.pyÈáåÈù¢ÔºåÁé∞Âú®Âè™ÈúÄË¶ÅËÄÉËôëvanialla RNNÁöÑÈóÆÈ¢ò implement lossÈáåÈù¢ÁöÑforwardÂíåbackward IO ËæìÂÖ• image featuresÔºåÂ§ßÂ∞èÊòØ(N,D) captionsÔºögorund truthÔºåÂ§ßÂ∞èÊòØ(N,T)ÂÖ∂‰∏≠ÊØè‰∏™ÂÖÉÁ¥†Â∫îËØ•ÈÉΩÂú® 0-V‰πãÈó¥ ËæìÂá∫ loss grads TODO affine transÔºå‰ªéÂõæÁâáÁöÑÁâπÂæÅËÆ°ÁÆóÂàùÂßãÂåñÁöÑhidden stateÔºåËæìÂá∫ÁöÑÂ§ßÂ∞èÊòØ (N,H) -&gt; W_proj,b_proj -&gt; Ëøô‰∏ÄÊ≠•ÂàùÂßãÂåñÁöÑÊòØh0Ôºå‰πüÂ∞±ÊòØÊúÄÂºÄÂßãÁöÑÁä∂ÊÄÅ word embeddingÔºåÊääËæìÂÖ•Âè•Â≠êÁöÑintÔºàË°®Á§∫Âú®vocaÈáåÈù¢ÁöÑ‰ΩçÁΩÆÔºâËΩ¨ÂåñÊàêvectorÔºåËæìÂá∫ÁªìÊûúÊòØ(N,T,W) vanilla RNNÔºàÊàñËÄÖÂêéÈù¢ÁöÑLSTMÔºâÊù•ËÆ°ÁÆó‰∏≠Èó¥ÁöÑtimestepÈáåÈù¢hidden stateÁöÑÊîπÂèòÔºåËæìÂá∫ÁªìÊûú(N,T,H) temporal affineÊù•ÊääÊØè‰∏ÄÊ≠•ÁöÑÁªìÊûúËΩ¨ÂåñÊàêÂú®vocabulary‰∏äÈù¢ÁöÑscoreÔºå(N,T,V) temporal softmaxÊääscoreËΩ¨ÂåñÊàêlossÔºåÊ≥®ÊÑèÈúÄË¶ÅÂøΩÁï•mask‰∏äÈù¢Ê≤°ÊúâÁöÑ Âú®backÁöÑÊó∂ÂÄôÈúÄË¶ÅËÆ°ÁÆólossÂÖ≥‰∫éÊâÄÊúâÂèÇÊï∞ÁöÑgradientÔºåÂ≠òÂú®‰∏äÈù¢ÁöÑdictÈáåÈù¢ ÂÆûÈôÖ‰∏äÁõ¥Êé•ÊåâÁÖß‰πãÂâçÂÜôÂ•ΩÁöÑ‰∏ÄÁõ¥Êìç‰ΩúÂ∞±ÂèØ‰ª•‰∫ÜÔºÅ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105def loss(self, features, captions): """ Compute training-time loss for the RNN. We input image features and ground-truth captions for those images, and use an RNN (or LSTM) to compute loss and gradients on all parameters. Inputs: - features: Input image features, of shape (N, D) - captions: Ground-truth captions; an integer array of shape (N, T) where each element is in the range 0 &lt;= y[i, t] &lt; V Returns a tuple of: - loss: Scalar loss - grads: Dictionary of gradients parallel to self.params """ # Cut captions into two pieces: captions_in has everything but the last word # and will be input to the RNN; captions_out has everything but the first # word and this is what we will expect the RNN to generate. These are offset # by one relative to each other because the RNN should produce word (t+1) # after receiving word t. The first element of captions_in will be the START # token, and the first element of captions_out will be the first word. captions_in = captions[:, :-1] captions_out = captions[:, 1:] # You'll need this mask = (captions_out != self._null) # Weight and bias for the affine transform from image features to initial # hidden state W_proj, b_proj = self.params['W_proj'], self.params['b_proj'] # Word embedding matrix W_embed = self.params['W_embed'] # Input-to-hidden, hidden-to-hidden, and biases for the RNN Wx, Wh, b = self.params['Wx'], self.params['Wh'], self.params['b'] # Weight and bias for the hidden-to-vocab transformation. W_vocab, b_vocab = self.params['W_vocab'], self.params['b_vocab'] loss, grads = 0.0, &#123;&#125; ############################################################################ # TODO: Implement the forward and backward passes for the CaptioningRNN. # # In the forward pass you will need to do the following: # # (1) Use an affine transformation to compute the initial hidden state # # from the image features. This should produce an array of shape (N, H)# # (2) Use a word embedding layer to transform the words in captions_in # # from indices to vectors, giving an array of shape (N, T, W). # # (3) Use either a vanilla RNN or LSTM (depending on self.cell_type) to # # process the sequence of input word vectors and produce hidden state # # vectors for all timesteps, producing an array of shape (N, T, H). # # (4) Use a (temporal) affine transformation to compute scores over the # # vocabulary at every timestep using the hidden states, giving an # # array of shape (N, T, V). # # (5) Use (temporal) softmax to compute loss using captions_out, ignoring # # the points where the output word is &lt;NULL&gt; using the mask above. # # # # In the backward pass you will need to compute the gradient of the loss # # with respect to all model parameters. Use the loss and grads variables # # defined above to store loss and gradients; grads[k] should give the # # gradients for self.params[k]. # # # # Note also that you are allowed to make use of functions from layers.py # # in your implementation, if needed. # ############################################################################ # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** # N,D x D,H -&gt; N,H hidden_init, hidden_init_cache = affine_forward( features, W_proj, b_proj) # N,T -&gt; N,T,D embeding, embeding_cache = word_embedding_forward(captions_in, W_embed) # RNN -&gt; N,T,H if self.cell_type == 'rnn': hidden_state, hidden_cache = rnn_forward( embeding, hidden_init, Wx, Wh, b) # N,T,H x H,V -&gt; N,T,V scores, score_cache = temporal_affine_forward( hidden_state, W_vocab, b_vocab) # N,T,V -&gt; loss loss, dloss = temporal_softmax_loss(scores, captions_out, mask) grads = &#123;&#125; # gradient in temporal affine daffine_x, grads['W_vocab'], grads['b_vocab'] = temporal_affine_backward( dloss, score_cache) if self.cell_type == 'rnn': drnn, dh_init, grads['Wx'], grads['Wh'], grads['b'] = rnn_backward( daffine_x, hidden_cache) grads['W_embed'] = word_embedding_backward(drnn, embeding_cache) dfeatures, grads['W_proj'], grads['b_proj'] = affine_backward( dh_init, hidden_init_cache) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################ # END OF YOUR CODE # ############################################################################ return loss, grads overfit small data Âíå‰πãÂâç‰∏ÄÊ†∑ÔºåÂÜô‰∫Ü‰∏Ä‰∏™solverÊù•ËÆ°ÁÆóÔºåÂåÖÊã¨‰∫ÜËÆ≠ÁªÉmodelÁöÑÊâÄÊúâÈúÄË¶ÅÁöÑ‰∏úË•øÔºåÂú®optim..pyÈáåÈù¢ÊúâÂæàÂ§ö‰∏çÂêåÁöÑupdateÁöÑÊñπÊ≥ï ÂèØ‰ª•Êé•ÂèótrainÊàñËÄÖvalÁöÑdataÂíålabelÔºåÂèØ‰ª•ÂæóÂà∞ËÆ≠ÁªÉÊàñËÄÖvalÁöÑacc„ÄÇÂú®ËÆ≠ÁªÉ‰πãÂêéËøô‰∏™modelÈáåÈù¢‰ºö‰øùÂ≠òÊúÄÂ•ΩÁöÑÂèÇÊï∞ÔºåËÆ©valÊúÄ‰Ωé Âú®Ëøô‰∏ÄÊ≠•ÈáåÈù¢ÔºåËΩΩÂÖ•‰∫Ü50‰∏™cocoÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºåÁÑ∂ÂêéÂØπ‰∏Ä‰∏™modelËøõË°åËÆ≠ÁªÉÔºåÊúÄÂêéÂæóÂà∞ÁöÑloss‰ºöÂ∞è‰∫é0.1 test-time sampling ÂíåÂàÜÁ±ª‰∏çÂêåÔºåRNNËÆ≠ÁªÉÂíåÊµãËØïÂæóÂà∞ÁöÑÁªìÊûú‰ºöÈùûÂ∏∏‰∏çÁõ∏Âêå ËÆ≠ÁªÉÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨Êääground-truthÊîæËøõRNN ÊµãËØïÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨‰ºösampleÂá∫Êù•ÊØè‰∏™timestepÁöÑÂçïËØçÁöÑÂàÜÂ∏ÉÔºåÁÑ∂ÂêéÊääËøô‰∫õÂàÜÂ∏ÉÂÜçÂñÇÂà∞‰∏ã‰∏Ä‰∏™stepÈáåÈù¢ implementÂú®ÊØèÊ¨°stepÈáåÈù¢ÔºåÊàë‰ª¨ÊääÁé∞Âú®ÁöÑÂçïËØçembedÔºåÂíåÂâç‰∏Ä‰∏™hidden state‰∏ÄËµ∑ËæìÂÖ•ËøõRNNÈáåÈù¢ÔºåÂæóÂà∞‰∏ã‰∏Ä‰∏™hidden stateÔºåÁÑ∂ÂêéÂæóÂà∞vocabulary‰∏äÈù¢ÁöÑscoreÔºåÈÄâÊã©ÊúÄÊúâÂèØËÉΩÁöÑÂçïËØçÁÑ∂ÂêéÊ†πÊçÆËøô‰∏™ÂçïËØçÂæóÂà∞‰∏ã‰∏Ä‰∏™ÂçïËØç ËæìÂÖ•Ôºö features (N,D) ËøòÊ≤°ÊúâËøõË°åprojectionÁöÑÊï∞ÊçÆ max_lengthÔºöÊúÄÈïøÁöÑcaptionÁöÑÈïøÂ∫¶ ËæìÂá∫ captions (N,max_length)ÔºåÈáåÈù¢ÊîæÁöÑÊòØ0-VÁöÑintÔºåÁ¨¨‰∏Ä‰∏™Â∫îËØ•ÊòØ TODO ÈúÄË¶ÅÊääfeaturesÂàùÂßãÂåñÔºåÁÑ∂ÂêéÁ¨¨‰∏Ä‰∏™ËæìÂÖ•ÁöÑÂçïËØçÂ∫îËØ•ÊòØ(ÊúÄÂºÄÂßã) Âú®‰πãÂêéÁöÑÊØè‰∏ÄÊ≠•ÈáåÈù¢ Áî®Â∑≤ÁªèÂ≠¶‰π†Â•ΩÁöÑÂèÇÊï∞Ôºåembed‰∏ä‰∏Ä‰∏™ÂçïËØç RNN stepÔºå‰ªé‰∏ä‰∏Ä‰∏™hiddenÂíåÁé∞Âú®ÁöÑembedÂæóÂà∞‰∏ã‰∏Ä‰∏™hiddenÔºàÈúÄË¶ÅcallÊØè‰∏ÄÊ≠•ÁöÑÂáΩÊï∞ËÄå‰∏çÊòØÂÆåÊï¥ÁöÑÂáΩÊï∞Ôºâ Êää‰∏ã‰∏Ä‰∏™ËΩ¨ÂåñÊàêscore Âú®scoreÈáåÈù¢ÈÄâÊã©ÊúÄÊúâÂèØËÉΩÁöÑÂçïËØçÔºåÂÜôÂá∫Êù•Ëøô‰∏™ÂçïËØçÁöÑindexÔºå ‰∏∫‰∫ÜÁÆÄÂçïÔºåÂú®Âá∫Áé∞‰πãÂâç‰∏çÁî®ÂÅúÊ≠¢ Ê≥®ÊÑèÔºö Â∫îËØ•Áî®ÁöÑÊòØaffineÊù•ËÆ°ÁÆóscoreËÄå‰∏çÊòØtemporalÔºåÂõ†‰∏∫Ë¶ÅËÆ°ÁÆóÁöÑÂè™ÊòØÁé∞Âú®Ëøô‰∏™ËåÉÂõ¥ÈáåÈù¢ÁöÑscoreÔºåËÆ°ÁÆóÂá∫Êù•ÁöÑÂ§ßÂ∞èÂ∫îËØ•ÊòØ(N,V)ÔºåÊâÄ‰ª•Â∫îËØ•Âú®ÊØèË°åÊâæÂà∞ÊúÄÂêàÈÄÇÁöÑ ÊØè‰∏ÄÊ≠•ËÆ°ÁÆóÂá∫Êù•ÁöÑÊúÄÂ§ßÂÄºÂ∫îËØ•ËÆ∞Âú®Áõ∏Â∫îstepÁöÑÂàó‰∏ä 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485def sample(self, features, max_length=30): """ Run a test-time forward pass for the model, sampling captions for input feature vectors. At each timestep, we embed the current word, pass it and the previous hidden state to the RNN to get the next hidden state, use the hidden state to get scores for all vocab words, and choose the word with the highest score as the next word. The initial hidden state is computed by applying an affine transform to the input image features, and the initial word is the &lt;START&gt; token. For LSTMs you will also have to keep track of the cell state; in that case the initial cell state should be zero. Inputs: - features: Array of input image features of shape (N, D). - max_length: Maximum length T of generated captions. Returns: - captions: Array of shape (N, max_length) giving sampled captions, where each element is an integer in the range [0, V). The first element of captions should be the first sampled word, not the &lt;START&gt; token. """ N = features.shape[0] captions = self._null * np.ones((N, max_length), dtype=np.int32) # Unpack parameters W_proj, b_proj = self.params['W_proj'], self.params['b_proj'] W_embed = self.params['W_embed'] Wx, Wh, b = self.params['Wx'], self.params['Wh'], self.params['b'] W_vocab, b_vocab = self.params['W_vocab'], self.params['b_vocab'] ########################################################################### # TODO: Implement test-time sampling for the model. You will need to # # initialize the hidden state of the RNN by applying the learned affine # # transform to the input image features. The first word that you feed to # # the RNN should be the &lt;START&gt; token; its value is stored in the # # variable self._start. At each timestep you will need to do to: # # (1) Embed the previous word using the learned word embeddings # # (2) Make an RNN step using the previous hidden state and the embedded # # current word to get the next hidden state. # # (3) Apply the learned affine transformation to the next hidden state to # # get scores for all words in the vocabulary # # (4) Select the word with the highest score as the next word, writing it # # (the word index) to the appropriate slot in the captions variable # # # # For simplicity, you do not need to stop generating after an &lt;END&gt; token # # is sampled, but you can if you want to. # # # # HINT: You will not be able to use the rnn_forward or lstm_forward # # functions; you'll need to call rnn_step_forward or lstm_step_forward in # # a loop. # # # # NOTE: we are still working over minibatches in this function. Also if # # you are using an LSTM, initialize the first cell state to zeros. # ########################################################################### # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** hidden_init, _ = affine_forward( features, W_proj, b_proj) start_word, _ = word_embedding_forward(self._start, W_embed) current_word = start_word next_state = hidden_init for step in range(max_length): prev_state = next_state if self.cell_type == 'rnn': next_state, _ = rnn_step_forward( current_word, prev_state, Wx, Wh, b) step_scores, _ = affine_forward( next_state, W_vocab, b_vocab) captions[:, step] = np.argmax(step_scores, axis=1) current_word, _ = word_embedding_forward( captions[:, step], W_embed) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ############################################################################ # END OF YOUR CODE # ############################################################################ return captions]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
        <category>CS231n‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Â≠¶‰π†OpenCVÁ¨¨19Á´†ÔºåÊäïÂΩ±Âíå3DËßÜËßâ]]></title>
    <url>%2F2019%2F05%2F08%2FOpenCV19%2F</url>
    <content type="text"><![CDATA[Chapter 19È¶ñÂÖà‰ºöËÆ®ËÆ∫‰ªé3DÂæóÂà∞2D‰ø°ÊÅØÔºåÁÑ∂ÂêéÂÜçËÆ®ËÆ∫‰ªé2DÊé®Êñ≠3D‰ø°ÊÅØÂ¶ÇÊûúÊ≤°ÊúâÂ§öÂº†ÂõæÁâáÊòØÂæàÈöæÂæóÂà∞Èù†Ë∞±ÁöÑ3D‰ø°ÊÅØÁöÑÔºö ÈÄöËøástereo vision ÈÄöËøámotion Projections ÂæóÂà∞‰∫ÜÁâ©‰ΩìÂú®‰∏âÁª¥ÈáåÈù¢ÁöÑ‰ΩçÁΩÆ‰πãÂêéÔºåÂõ†‰∏∫Êàë‰ª¨Âú®18Á´†Â∑≤Áªècalibration‰∫ÜÁõ∏Êú∫ÔºåÊâÄ‰ª•ÂèØ‰ª•ÂæóÂà∞Ëøô‰∏™ÁÇπÂú®ÂõæÁâáÈáåÈù¢ÁöÑ‰ΩçÁΩÆ Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÂáΩÊï∞projectPointsÊù•ÊäïÂΩ±‰∏ÄÁ≥ªÂàóÁöÑÁÇπÔºåÈíàÂØπÂàö‰Ωì a list of loca‚Äê tions in the object‚Äôs own body-centered coordinate system Âä†‰∏ä‰∫ÜÂπ≥ÁßªÂíåÊóãËΩ¨ÔºåÁõ∏Êú∫intrinsicÂíådistortion ÊúÄÂêéËæìÂá∫Âú®ÁîªÈù¢‰∏äÁöÑÂ∫ó Affine and Perspective TransformationsaffineÊòØÈíàÂØπ‰∏Ä‰∏™listÊàñËÄÖ‰∏ÄÊï¥Âº†ÂõæÁâáËøõË°åÁöÑÔºåÂèØ‰ª•Êää‰∏Ä‰∏™point‰ªéÂõæÁâáÁöÑ‰∏Ä‰∏™locationÁßªÂä®Âà∞Âè¶‰∏Ä‰∏™locationÔºåperspective transÊõ¥Â§öÁöÑÊòØÈíàÂØπ‰∏Ä‰∏™Áü©ÂΩ¢ÂõæÁâá -&gt; related to prspective transformation ÊÄªÁªì‰∏çÂêåÁöÑÂáΩÊï∞ Bird‚Äôs-eye-view transÔºàp699Ôºâ Âú®robticÂ∑°Ëà™ÁöÑÊó∂Èó¥ÔºåÁªèÂ∏∏ÊääÊéíÂà∞ÁöÑÁîªÈù¢ÂèòÊàê‰ªé‰∏äÂæÄ‰∏ãÁúãÁöÑbird-view ÈúÄË¶ÅÁõ∏Êú∫ÁöÑintrinsicÂíådistortion ÔºàÊääÊ£ãÁõòÊîæÂú®Âú∞‰∏äËøõË°åcalibrationÔºâ Ê≠•È™§ È¶ñÂÖàËØªÂèñÁõ∏Êú∫ÁöÑÂèÇÊï∞Âíådistortion model ÊâæÂà∞Âú∞Èù¢‰∏äÂ∑≤Áü•ÁöÑÂ∫óÔºàÊØîÂ¶ÇchessboardÔºâÔºåÊâæÂà∞Ëá≥Â∞ëÂõõ‰∏™ÁÇπ cv::getPerspectiveTransform()ËÆ°ÁÆóÂú∞Èù¢‰∏äÂ∑≤Áü•ÁÇπÁöÑhomography H cv::warpPerspective()ÂΩ¢Êàêbird-eye-view three-dim pose estimationÁâ©‰ΩìÁöÑ‰∏âÁª¥poseÂèØ‰ª•‰ªé ‰∏Ä‰∏™Áõ∏Êú∫ÔºöÂøÖÈ°ªÂÖàËÄÉËôëÊÉÖÂÜµÊÉπ Â§ö‰∏™Áõ∏Êú∫ÊçïÊçâÔºö‰ªéÂ§ö‰∏™‰∏çÂêåÂõæÁâáÊù•Êé®Êñ≠ÔºåËøôÊ†∑Âç≥‰ΩøÊòØ‰∏çÁü•ÈÅìÁöÑ‰∏úË•øÈÉΩÂèØ‰ª•Êìç‰Ωú single camera Â¶ÇÊûúÊàë‰ª¨Áü•ÈÅì‰∏Ä‰∏™objectÔºåÊàë‰ª¨ÈúÄË¶ÅÁü•ÈÅìËøô‰∏™‰∏úË•øÂú®‰ªñËá™Â∑±ÂùêÊ†áÁ≥ªÈáåÈù¢ÂÖ≥ÈîÆÁÇπÁöÑÂùêÊ†á Â¶ÇÊûúÁé∞Âú®Áªô‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑview pointÔºåÂèØ‰ª•Ê†πÊçÆÂÖ≥ÈîÆÁÇπÁöÑ‰ΩçÁΩÆÊù•Êé®Êñ≠ cv::solvePnP() Áî®Êù•ËÆ°ÁÆó‰∏Ä‰∏™know objectÁöÑ‰ΩçÁΩÆ ‰ªéÂõæÁâáÈáåÈù¢ÊèêÂèñÁâπÂæÅÁÇπÔºåÁÑ∂ÂêéËÆ°ÁÆó‰∏çÂêåÁÇπÁöÑ‰ΩçÁΩÆÔºåËøô‰∏™ÈóÆÈ¢òÁöÑËß£ÊòØÂ∫îËØ•ÊòØÂîØ‰∏ÄÁöÑ PNPÈóÆÈ¢ò‰∏çÊòØÊØèÊ¨°ÈÉΩÊúâÂîØ‰∏ÄÁöÑËß£ Â¶ÇÊûúÊ≤°ÊúâË∂≥Â§üÁöÑÂÖ≥ÈîÆÁÇπÔºå‰∏∫‰∫Ü‰øùÈô©Ëµ∑ËßÅÂ∫îËØ•ÊúâË∂≥Â§üÁöÑÂ∫ó ÊàñËÄÖÂΩìÁâ©‰ΩìÁ¶ªÂæóÁâπÂà´ËøúÔºàËøôÊó∂ÂÄôÂÖâÁ∫øÊé•Ëøë‰∫éÂπ≥Ë°å‰∫ÜÔºåÂ∞±‰∏çÂ•ΩÂà§Êñ≠‰∫ÜÔºâ ÊÄªÁöÑÊù•ËØ¥ÔºåÂçïÁõÆËßÜËßâÂíå‰∫∫Ëá™Â∑±ÁöÑÁúºÁùõÔºàÂçïÂè™ÔºâÁúã‰∏úË•øÁöÑÊÑüËßâÂ∑Æ‰∏çÂ§öÔºå‰∏çËÉΩËé∑ÂæóÁ≤æÁ°ÆÁöÑÂ§ßÂ∞èÔºåËøò‰ºö‰∫ßÁîü‰∏Ä‰∫õÈîôËßâÔºàÊØîÂ¶ÇÊääÂ§ßÊ•ºÁöÑÁ™óÊà∑ËÆæËÆ°ÁöÑÂ∞èÊù•ÊòæÂæóÊ•ºÊõ¥È´òÔºâ Stereo ImagingÂú®ÁîµËÑë‰∏≠ÔºåÈÄöËøáËÆ°ÁÆóÂú®‰∏§Âº†ÂõæÈáåÈù¢ÈÉΩÂá∫Áé∞ÁöÑÁÇπÁöÑ‰ΩçÁΩÆÊù•ËÆ°ÁÆóÔºåËøôÊ†∑Â∞±ÂèØ‰ª•ËÆ°ÁÆóËøô‰∏™ÁÇπÁöÑ‰∏âÁª¥‰ΩçÁΩÆ„ÄÇËôΩÁÑ∂ËøôÊ†∑ËÆ°ÁÆóÁöÑËÆ°ÁÆóÈáèÂæàÂ§ßÔºå‰ΩÜÊòØÂèØ‰ª•ÈÄöËøá‰∏Ä‰∫õÊñπÊ≥ïÊù•ÂéãÁº©ÊêúÂØªÁöÑËåÉÂõ¥Ôºå‰ªéËÄåÂæóÂà∞Áõ∏Â∫îÁöÑÁªìÊûú„ÄÇ‰∏ªË¶ÅÂàÜ‰∏∫4Ê≠•Ôºö Âú®Êï∞Â≠¶‰∏äremoveÊéâÁõ∏Êú∫lensÁöÑËæêÂ∞ÑÂíåÂπ≥Áßªdistortion -&gt; undistortion Ë∞ÉÊï¥Áõ∏Êú∫‰πãÈó¥ÁöÑËßíÂ∫¶ÂíåË∑ùÁ¶ª -&gt; rectification„ÄÇËøô‰∏ÄÊ≠•ËæìÂá∫‰πãÂêéÁöÑ‰∏§Âº†ÂõæÁâáÂ∫îËØ•ÊòØrow-alignedÁöÑÔºàfrontal parallelÔºâ ÊâæÂà∞Â∑¶Âè≥‰∏§Âº†ÂõæÁõ∏ÂêåÁöÑfeature -&gt; correspondence„ÄÇËøô‰∏ÄÊ≠•ÁöÑËæìÂá∫ÊòØ‰∏Ä‰∏™disparity mapÔºåËæìÂá∫ÁöÑÊòØ‰∏§‰∏™Âõæ‰∏≠Áõ∏ÂêåÁâπÂæÅÁÇπÁöÑxÂùêÊ†áÊñπÂêë‰∏äÈù¢ÁöÑdisparity ÊúÄÂêéÂèØ‰ª•ÊäädisparityËΩ¨Êç¢ÊàêtriangulationÔºåËøô‰∏ÄÊ≠•Âè´ÂÅöreprojectionÔºåËøôÊ†∑ËæìÂá∫ÁöÑÂ∞±ÊòØdepth map‰∫Ü triangulationÔºàÊâæÂà∞disparityÂíådepthÁöÑÂÖ≥Á≥ªÔºâ Êï¥‰ΩìÊ¶ÇÂøµÂ¶Ç‰∏äÂõæÊâÄÁ§∫ÔºåÂú®ËøôÂº†ÂõæÈáåÊàë‰ª¨ÂÅáËÆæÁ≥ªÁªüÂ∑≤ÁªèÂÆåÂÖ®undistortÔºåalignedÔºà‰∏§Âº†ÂõæÁâáÁöÑË°åÂíåË°åÂØπ‰∏ä‰∫ÜÔºâ‰∫ÜÔºå‰∏§‰∏™Áõ∏Êú∫ÁöÑÂπ≥Èù¢ÂÆåÂÖ®Áõ∏ÂêåÔºåÁÑ¶Ë∑ù‰πüÁõ∏ÂêåÔºåÂπ∂‰∏î‰∏§‰∏™Áõ∏Êú∫ÁöÑcxÂ∑≤ÁªèË¢´calibratedÂ•Ω‰∫ÜÔºàÁõ∏ÂêåÔºâ ËøôÊó∂ÔºåËøô‰∏™Áâ©‰ΩìÁÇπPÁöÑdepthÂíådisparityÊòØÊàêÊ≠£ÊØîÁöÑÔºåÊ±ÇÂá∫Êù•ÁöÑdisparityÊòØÔºöxl - xrÔºàxlÂíåxrÈÉΩÊòØÊ†πÊçÆÂêÑËá™ÁöÑÁõ∏Êú∫‰∏≠ÂøÉÁöÑÂùêÊ†áÔºâ: T - (xl - xr)/Z - f = T/Z Ëøô‰∏™ÂÖ≥Á≥ªËôΩÁÑ∂ÊòØÊ≠£ÊØî‰ΩÜÊòØ‰∏çÊòØÁ∫øÊÄßÁöÑ ÂΩìdisparityÊé•Ëøë0ÁöÑÊó∂ÂÄôÔºåÂ∞èÁöÑdisparityÁöÑÂ∑ÆÂºÇ‰ºöÂºïÂèëÈùûÂ∏∏Â§ßÁöÑdepthÁöÑÂ∑ÆÂºÇ ÂΩìdisparityÈùûÂ∏∏Â§ßÁöÑÊó∂ÂÄôÔºådisparityÁöÑÊîπÂèò‰∏ç‰ºöÂØπdepthÂºïËµ∑Â§™Â§öÁöÑÂΩ±Âìç ÊúÄÁªàÔºåstereoÁöÑÁ≥ªÁªüÂè™Âú®ÊØîËæÉÊé•ËøëÁõ∏Êú∫ÁöÑÈÉ®ÂàÜÊúâÊØîËæÉÈ´òÁöÑdepth resolutionÔºàÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºâ ‰∏äÈù¢ÁöÑ‰æãÂ≠êÊòØ‰∫åÁª¥ËΩ¨‰∏ÄÁª¥ÁöÑÔºåÂÆûÈôÖÂú®OpenCVÁöÑÁ≥ªÁªüÈáåÈù¢ÊòØ‰∏âÁª¥ËΩ¨‰∫åÁª¥ÁöÑ Âú®ÂÆûÈôÖÁöÑÂ∫îÁî®ÈáåÈù¢Áõ∏Êú∫‰∏çÊòØÈÇ£‰πàÁêÜÊÉ≥ÁöÑÂÖ±Á∫øÁöÑÔºåË¶ÅÂ∞ΩÈáèÁ°Æ‰øùÂÖ±Á∫øÔºåÊâç‰∏ç‰ºöÂºïËµ∑Â§™Â§öÁöÑdistortion„ÄÇÊúÄÁªàÁöÑÁõÆÁöÑÊòØÈÄöËøámathÁöÑËÆ°ÁÆóËÆ©‰ªñÂÖ±Á∫øÔºåËÄå‰∏çÊòØÂú®Áâ©ÁêÜ‰∏äÂÖ±Á∫ø Èô§Ê≠§‰πãÂ§ñÔºåËøòÈúÄË¶Å‰øùËØÅÁõ∏Êú∫ÁöÑÊãçÊëÑÊòØÂêåÊ≠•ÁöÑÔºåÈÅøÂÖçÂú®ÊãçÊëÑÁöÑÊó∂ÂÄô‰ºöÊúâ‰∏úË•øÁßªÂä® Epipolar GeometryÔºàÁÆÄÂåñÂèåÁõÆÊ®°ÂûãÔºâstereo image systemÁöÑÊ®°ÂûãÔºö ÁªÑÂêà‰∫Ü‰∏§‰∏™pinhole model Âä†ÂÖ•‰∫ÜÊñ∞ÁöÑpoints epipoles ‰∏ªË¶ÅÁÇπÔºö ÂØπ‰∫éÊØè‰∏™Áõ∏Êú∫ÈÉΩ‰ºöÊúâ‰∏Ä‰∏™ÊäïÂΩ±ÁöÑ‰∏≠ÂøÉOÔºåÂπ∂‰∏îÊúâ‰∏§‰∏™ÂíåËøô‰∏™Áõ∏ÂÖ≥ÁöÑÊäïÂΩ±Âπ≥Èù¢ Âú®Áé∞ÂÆû‰∏≠ÁöÑÁâ©‰ΩìP‰ºöÂú®‰∏§‰∏™ÊäïÂΩ±Âπ≥Èù¢‰∏äÂàÜÂà´ÊúâÊäïÂΩ±plÂíåpr elÊàñËÄÖerÔºåÂÆö‰πâÊòØÂè¶‰∏Ä‰∏™Áõ∏Êú∫ÁöÑ‰∏≠ÂøÉÂú®Ëøô‰∏™ÊäïÂΩ±Âπ≥Èù¢‰∏äÁöÑÊäïÂΩ±ÔºåelÂíåplÂèØ‰ª•ÂΩ¢Êàê‰∏ÄÊù°epipolar line ÂæóÂà∞Ë¶Å‰πâ ÊØè‰∏™‰∏âÁª¥ÁöÑÁÇπÔºåÈÉΩ‰ºöÂú®ÊØè‰∏™Áõ∏Êú∫‰∏äÈù¢ÂæóÂà∞‰∏Ä‰∏™epipolarÁöÑÔºåËøô‰∏™ÁÇπÂíåpr/plÁöÑ‰∫§ÁÇπÂ∞±ÊòØepipolar line ‰∏Ä‰∏™ÂõæÁâáÈáåÈù¢ÁöÑfeatureÔºåÂú®Âè¶‰∏Ä‰∏™ÂõæÁâáÈáåÈù¢ÂøÖÈ°ªÂú®Áõ∏ÂØπÂ∫îÁöÑepipolar line‰∏äÈù¢Ôºàepipolar constraintÔºâ ‰∏äÈù¢ÈÇ£‰∏™ÂÆö‰πâÊÑèÂë≥ÁùÄÔºöÂèØ‰ª•ÊääÂú®ÂõæÁâá‰∏äÂØªÊâæÁâπÂæÅ‰ªé‰∫åÁª¥ÔºàÂõæÁâáÔºâÈôç‰ΩéÂà∞‰∏ÄÁª¥ÔºàÁ∫øÔºâ Âπ∂‰∏îÂõæÁâáÁöÑorder‰ºö‰øùÂ≠òÔºåÊØîÂ¶Ç‰∏ÄÊù°Á∫øÂú®‰∏§Âº†ÂõæÈáåÈù¢ÈÉΩÊòØÊ∞¥Âπ≥ÁöÑ The Essential and Fundamental Matrices E MatÔºöÂåÖÊã¨‰∫Ü‰∏§‰∏™Áõ∏Êú∫ÁöÑtranslationÂíårotation F MatÔºöÂåÖÊã¨‰∫ÜEÁöÑ‰ø°ÊÅØÔºå‰ª•ÂèäÁõ∏Êú∫ÁöÑintrinsicÔºàÂú®pixelÁöÑÂ±ÇÈù¢‰∏äÂÖ≥ËÅî‰∏§‰∏™Áõ∏Êú∫Ôºâ ‰∫åËÄÖÁöÑÂå∫Âà´ EÂè™Áü•ÈÅì‰∏§‰∏™Áõ∏Êú∫ÁöÑÂÖ≥Á≥ªÔºå‰∏çÁü•ÈÅì‰ªª‰ΩïÂÖ≥‰∫éÂõæÁâáÁöÑ‰ø°ÊÅØÔºåÂè™Âú®Áâ©‰ΩìÁöÑÂ±ÇÈù¢‰∏äÂÖ≥ËÅî‰∫Ü‰∏§‰∏™Áõ∏Êú∫ FÂÖ≥ËÅî‰∫Ü‰∏§‰∏™ÁÖßÁâáÂú®ÂêÑËá™ÂõæÁâáÂùêÊ†áÁ≥ªÈáåÈù¢ÁöÑÂÖ≥Á≥ª E math + F matÔºàp713ÔºåËøòÊ≤°ÊúâÊÄé‰πàÁúãÔºâ Âú®Â∑¶ËæπÁöÑÁõ∏Êú∫ÈáåÔºåËßÇÂØüÂà∞ÁöÑÁÇπÊòØplÔºåÂú®Âè≥ËæπÁöÑÁõ∏Êú∫ËßÇÂØüÂà∞ÁöÑÁÇπÊòØpr pr = RÔºàpl - TÔºâ cv::findFundamentalMatComputing Epipolar Lines(ËÆ°ÁÆó‰∏äÈù¢Ê®°ÂûãÈáåÈù¢ÁöÑÈÇ£Êù°Á∫ø) Êúâ‰∫ÜF Mat‰πãÂêéÂ∏åÊúõÂèØ‰ª•ËÆ°ÁÆó‰∏äÈù¢ÁöÑepipolar line„ÄÇÊØè‰∏Ä‰∏™ÂõæÁâáÈáåÈù¢ÁöÑlineÈÉΩ‰ºöÂú®Âè¶‰∏ÄÂº†ÂõæÁâáÈáåÊúâ‰∏Ä‰∏™ÂØπÂ∫îÁöÑline lineÁî®‰∏Ä‰∏™‰∏â‰∏™ÁÇπÁöÑvectorÊù•Ë°®Á§∫ cv::computeCorrespondEpilines Stereo Calibration‰∏äÈù¢Â∑≤ÁªèËØ¥‰∫ÜÂæàÂ§öÁöÑÁêÜËÆ∫Áü•ËØÜ‰∫ÜÊâÄ‰ª•Êàë‰ª¨Áé∞Âú®Â∞±ÂºÄÂßãcalibrationÂêßÔºÅ Stereo calibrationÊòØÂú®Á©∫Èó¥‰∏äÈù¢ËÆ°ÁÆó‰∏§‰∏™Áõ∏Êú∫ÁöÑ‰ΩçÁΩÆ„ÄÇÁõ∏ÂèçÔºåÂêéÈù¢Ë¶ÅËØ¥ÁöÑrectificationÊâçÊòØÊù•‰øùËØÅ‰∏§Âº†ÂõæÁâáË°åÊòØÂÖ±Á∫øÁöÑ Stereo calibration‰∏ªË¶Å‰æùÈù†ÁöÑÊòØÊâæ‰∏§‰∏™Áõ∏Êú∫‰πãÈó¥ÁöÑTÂíåRÁü©ÈòµÔºåËøô‰∏§‰∏™ÈÉΩÂèØ‰ª•Áî®cv::stereoCalibrate()Êù•ËÆ°ÁÆó ÂíåÂçïÁõÆÁõ∏Êú∫ÁöÑcalibrationÊúâ‰∫õÁõ∏‰ººÔºå‰ΩÜÊòØÂçïÁõÆÁöÑÁõ∏Êú∫Ë¶ÅÂØªÊâæ‰∏ÄÁ≥ªÂàóÁõ∏Êú∫Âíåchessboard‰πãÈó¥ÁöÑRÂíåT ÂèåÁõÆÁöÑcalibrationÂú®ÂØªÊâæÂîØ‰∏Ä‰∏Ä‰∏™ËÉΩËÆ©Â∑¶Âè≥Áõ∏Êú∫ÂåπÈÖç‰∏äÁöÑRÂíåT ÂèØ‰ª•ÂæóÂà∞‰∏â‰∏™Á≠âÂºèÊ±ÇËß£ Âõ†‰∏∫ÂõæÁâáÁöÑnoiseÊàñËÄÖrounding errorÔºåÊØèÁªÑÂæóÂà∞ÁöÑÁªìÊûúÂèØËÉΩ‰ºöÊúâËΩªÂæÆÁöÑ‰∏çÂêåÔºåÊúÄÂêé‰ºöÂèñ‰∏≠‰ΩçÊï∞ calibration‰ºöÊääÂè≥ËæπÁöÑÁõ∏Êú∫ÊîæÂú®ÂíåÂ∑¶ËæπÁöÑÁõ∏Êú∫Áõ∏ÂêåÁöÑplane‰∏äÈù¢ÔºåËøôÊ†∑Ëøô‰∏§‰∏™Áõ∏Êú∫ÂæóÂà∞ÁöÑÂõæÁâáÂ∞±ÊòØparallelÁöÑÔºå‰ΩÜÊòØËøôÊó∂ÂÄôËøò‰∏çÊòØrow-alignedÁöÑÔºÅÔºÅÔºÅ ÂèØ‰ª•Áõ¥Êé•ÈÄöËøáÁî®Ëøô‰∏Ä‰∏™ÂáΩÊï∞ËÆ°ÁÆóÁõ∏Êú∫ÁöÑintrinsicÔºåextrinsicÂíåStereoÁöÑÂèÇÊï∞Ôºå‰∏çÁî®ÂÖàËøõË°åcalibration Stereo Rectification Â¶ÇÊûú‰∏§‰∏™ÂõæÁâáaligned‰∫ÜÔºåÈÇ£‰πàÊ†πÊçÆ‰∏äÈù¢ËÆ°ÁÆóÂá∫Êù•ÁöÑdisparityÂ∞±ÂèØ‰ª•ÂæàËΩªÊòìÁöÑÂæóÂà∞depth map‰∫Ü„ÄÇ‰ΩÜÊòØÂú®ÂÆûÈôÖ‰∏≠Âè™ÊúâÁõ∏Êú∫Ê≤°ÊúâËøô‰πàÂÆπÊòìÂÅöÂà∞ ÁõÆÊ†áÔºöÊàë‰ª¨ÈúÄË¶Åreproject‰∏§‰∏™image planeÔºåËÆ©‰ªñ‰ª¨Âú®ÂÆåÂÖ®Áõ∏ÂêåÁöÑplaneÈáåÈù¢ÔºåÂèØ‰ª•ÂæóÂà∞ÂÆåÁæéÁöÑaligned Êàë‰ª¨Â∏åÊúõÂú®rectification‰πãÂêéÂõæÁâáÁöÑrow aligedÔºåËøôÊ†∑stereo correspondenceÔºàÂú®‰∏§‰∏™ÂõæÁâáÈáåÊâæÁõ∏ÂêåÁöÑÁÇπÔºâÂ∞±‰ºöÂèòÂæóÊõ¥ÂèØ‰ø°ËÄå‰∏îÂÆπÊòìËÆ°ÁÆó Âú®Âè¶‰∏ÄÂº†ÁÖßÁâáÈáåÂè™Êâæmatch‰∏Ä‰∏™ÁÇπÁöÑrow ËøôÊ†∑ÁöÑÁªìÊûú‰ºöÊúâÊó†Èôê‰∏™ÂæÖÈÄâ Êàë‰ª¨ÂÜç‰∫∫‰∏∫ÁöÑÂä†‰∏äÈôêÂà∂ ÁªìÊûú‰ºöÊúâÂÖ´‰∏™termÔºåÂõõ‰∏™ÁªôÂ∑¶ËæπÁöÑÁõ∏Êú∫ÔºåÂõõ‰∏™ÁªôÂè≥ËæπÁöÑÁõ∏Êú∫Ôºà‰∏§ÁßçËÆ°ÁÆóËøô‰∫õÂèÇÊï∞ÁöÑÁÆóÊ≥ïÔºâ ÊØè‰∏™Áõ∏Êú∫ÈÉΩ‰ºöÊúâdistCoffsÂíåÊóãËΩ¨Áü©ÈòµRÔºå‰øÆÊ≠£ÂíåÊú™‰øÆÊ≠£ÁöÑÁõ∏Êú∫Áü©ÈòµÔºà4‰∏™Ôºâ Áî®‰∏äÈù¢Ëøô‰∫õ‰∏úË•øÔºåÂæóÂà∞mapÊù•Á°ÆÂÆöÂéüÂõæË¶ÅÊÄé‰πà‰øÆÊîπcv::initUndistortRectifyMap() Hartley‚Äôs algorithm + Bouguet‚Äôs algorithmÔºàp730ÔºâRectification mapStereo Correspondence Âú®‰∏§‰∏™ÂõæÁâáÈáåÈù¢match‰∏âÁª¥ÁöÑÁÇπÔºåÂè™ËÉΩÂú®‰∏§Âº†ÂõæÁâá‰∫§Âè†ÁöÑÂú∞ÊñπÊâæÂà∞ ‰∏§Áßç‰∏çÂêåÁöÑÁÆóÊ≥ï block matchingÔºöÂø´ÔºåÊïàÁéáÈ´òÔºåÂü∫‰∫é‚Äúsum of absolute difference‚Äù (SADÔºâ Âè™‰ºöÊâæÂà∞È´òÂ∫¶Á¨¶ÂêàÁöÑÁÇπÔºàhighly texturedÔºâ-&gt; Êà∑Â§ñ semi-global block matching (SGBM) ÔºöÁ≤æÁ°ÆÂ∫¶Êõ¥È´ò matching is done at subpixel level using the Birchfield-Tomasi metric enforce a global smoothness constraint on the computed depth information that it approximates by considering many one-dimensional smoothness constraints through the region of interest Block matching‰∏â‰∏™Ê≠•È™§ prefilteringÔºånormalÂõæÁâáÁöÑ‰∫ÆÂ∫¶ÔºåÂ¢ûÂº∫Á∫πÁêÜ Áî®SADÁöÑÁ™óÂè£ÔºåÊêúÁ¥¢Ê∞¥Âπ≥ÁöÑepipolar line Âú®rectificatin‰πãÂêéÔºåÊØèË°åÈÉΩÊòØ‰∏Ä‰∏™epipolar lineÔºåÊâÄ‰ª•Â∑¶ËæπÁöÑÂõæÁâáËÇØÂÆöÂú®Âè≥ËæπÁöÑÂêå‰∏ÄË°åÈáåÈù¢Êúâ‰∏Ä‰∏™ÂØπÂ∫îÁöÑÈÉ®ÂàÜ disparity‰ºöÂú®‰∏ÄÂÆöÁöÑpixelËåÉÂõ¥ÈáåËøõË°åÊêúÁ¥¢Ôºå‰∏çÂêåËåÉÂõ¥ÈáåÁöÑdisparity‰ª£Ë°®ÁöÑÊòØ‰∏çÂêåÁöÑdepth„ÄÇ‰ΩÜÊòØË∂ÖËøá‰∫ÜÊúÄÂ§ßÂÄºÁöÑËØùÂ∞±Êâæ‰∏çÂà∞depth‰∫Ü -&gt; Each disparity limit defines a plane at a fixed depth from the cameras PostfilteringÔºåÂáèÂ∞ëÊØîËæÉÂ∑ÆÁöÑÁªìÊûú Semi-global block matchingcode example Ôºàp752ÔºâStructure from Motion ‰ªéÁßªÂä®‰∏≠ÂæóÂà∞ÊûÑÈÄ†‰ø°ÊÅØ„ÄÇ‰ΩÜÊòØÂú®ÈùôÊ≠¢ÁöÑÊÉÖÂÜµ‰∏ãÔºå‰∏Ä‰∏™Áõ∏Êú∫ÁßªÂä®ÂæóÂà∞ÁöÑ‰ø°ÊÅØÂíå‰∏§‰∏™Áõ∏Êú∫ÂæóÂà∞ÁöÑ‰ø°ÊÅØÊ≤°ÊúâÊú¨Ë¥®ÁöÑÂå∫Âà´ ‰ΩÜÊòØÂ¶ÇÊûúÁâπÂà´Â§ßÁöÑÊó∂ÂÄôÔºåÂ∞±ÈúÄË¶ÅÈÄöËøáËÆ°ÁÆóframe‰πãÈó¥ÁöÑÂÖ≥Á≥ªÂæóÂà∞ÊúÄÂêéÁöÑÁªìÊûúÔºàSLAMÔºüÔºâ Âú®ÈôÑÂΩï FitLineÔºàÁõ¥Á∫øÊãüÂêàÔºâ Âú®‰∏âÁª¥ÁöÑÂàÜÊûê‰πã‰∏≠ÊØîËæÉÂ∏∏Áî®ÔºåÊâÄ‰ª•Âú®ËøôÈáå‰ªãÁªç]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>OpenCV</category>
        <category>Projection</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Projection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetcodeÁ¨îËÆ∞]]></title>
    <url>%2F2019%2F05%2F07%2FLeetcode%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ËøõÂ∫¶Ôºö arrayÈÉ®ÂàÜÂ∑Æ‰∏çÂ§ö stringÈÉ®ÂàÜÊèêÈ´òÂæÄÂêéÊ≤°ÊúâÁªßÁª≠ mathÈÉ®ÂàÜÊµÖÂ∞ùËæÑÊ≠¢ ÂºÄÂßãÊêûÊ†ëÁöÑÈÉ®ÂàÜ 1 twoSumGiven an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example: Given nums = [2, 7, 11, 15], target = 9, Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. 1234567class Solution: def twoSum(self, nums: List[int], target: int) -&gt; List[int]: for i, item in enumerate(nums): if target - item in nums and nums.index(target - item) != i: return [i, nums.index(target - item)] ÊÄªÁªìÔºö ÂàöÂºÄÂßãÁî®‰∫ÜÁõ¥Êé•forÊâÄÊúâÁöÑÂÖÉÁ¥†ÁöÑÊñπÊ≥ïÔºåÂøòËÆ∞ËÄÉËôëÂΩì‰∏§‰∏™Êï∞Â≠óÈáçÂ§çÁöÑÊó∂ÂÄôÈúÄË¶ÅÊÄé‰πàÂäûÔºåËÄÉËôë‰∫Ü‰πãÂêéÂú®ÈùûÂ∏∏Â§ßÁöÑÊï∞ÁöÑÊÉÖÂÜµ‰∏ãÁàÜÁÇ∏‰∫Ü Ê†áÂáÜÁ≠îÊ°àËØ¥Âà∞‰∫ÜhashË°®Ôºå‰ΩÜÊòØÂÖ∂ÂÆûÂú®pythonÂÆûÁé∞ÈáåÈù¢Êú¨Ë∫´Â∞±ÊòØ‰∏™hashÔºà‰∏çÁÑ∂ÊÄé‰πà‰ªéÁ¥¢ÂºïÂæóÂà∞ÁªìÊûúÔºâÔºå‰∏çÈúÄË¶ÅËÄÉËôëËøô‰∏™ÈóÆÈ¢ò ÁÑ∂ÂêéËÄÉËôë‰∫ÜÊääÊâÄÊúâ‰∏úË•øÈÉΩÊîæ‰∏Ä‰∏™dictÈáåÈù¢ÔºàÊØïÁ´ühashÔºüÔºâÔºå‰ΩÜÊòØÈÅáÂà∞ÁöÑÈóÆÈ¢òÊòØ‰ªévalueÁõ¥Êé•ÂæóÂà∞key‰ºöÁîü‰∏Ä‰∫õÈóÆÈ¢ò„ÄÇÂ¶ÇÊûúÊääÊï∞Â≠ó‰Ωú‰∏∫keyÔºåÁ¥¢Âºï‰Ωú‰∏∫value‰ºöÂèëÁé∞Êï∞Â≠óÊúâÈáçÂ§çÁöÑÔºå‰ºöË¶ÜÁõñkeyÁöÑÂÄº ËøôÊó∂ÂÄôÁ™ÅÁÑ∂ÂèëÁé∞ÔºåÂ¶ÇÊûúÁî®Êï∞Â≠ó‰Ωú‰∏∫Á¥¢ÂºïÁöÑËØùÂÖ∂ÂÆûdictÂíålistÊ≤°ÊúâÊú¨Ë¥®Âå∫Âà´ÔºåÂú®listÈáåÈù¢Êìç‰ΩúÂ∞±Ë°å‰∫ÜÔºåËÄå‰∏îlistÁöÑ.index()ÂèØ‰ª•Áõ¥Êé•ËøîÂõûËøô‰∏™ÂÄºÂæóÂùêÊ†áÔºàÊâæÂà∞ÁöÑÊòØÁ¨¨‰∏Ä‰∏™ÂÄºÔºÅÔºÅÔºâ ÊâÄ‰ª•Áõ¥Êé•Áî®enumerateÊääÊâÄÊúâÁöÑindexÂíåitemÈÉΩÂàóÂá∫Êù•Â∞±ÂèØ‰ª•Ëß£ÂÜ≥‰∫ÜÔºåÁ•ûÂ•á„ÄÇ 27 remove elementGiven an array nums and a value val, remove all instances of that value in-place and return the new length. Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory. The order of elements can be changed. It doesn‚Äôt matter what you leave beyond the new length. Example 1: Given nums = [3, 2, 2, 3], val = 3, Your function should return length = 2, with the first two elements of nums being 2. It doesn‚Äôt matter what you leave beyond the returned length.Example 2: Given nums = [0, 1, 2, 2, 3, 0, 4, 2], val = 2, Your function should return length = 5, with the first five elements of nums containing 0, 1, 3, 0, and 4. Note that the order of those five elements can be arbitrary. It doesn‚Äôt matter what values are set beyond the returned length. 12345678910111213class Solution: def removeElement(self, nums: List[int], val: int) -&gt; int: remove_nums = 0 ori_length = len(nums) for i in range(len(nums)): if nums[i] == val: remove_nums += 1 nums[i] = float('inf') nums.sort() nums = nums[:ori_length - remove_nums] return len(nums) ÊÄªÁªìÔºö ËøôÈÅìÈ¢òÁöÑÈáçÁÇπÊòØÈúÄË¶Åin - placeÁöÑÂ§ÑÁêÜÔºåÁ©∫Èó¥Â§çÊùÇÂ∫¶Ë¶ÅÊ±ÇÂæàÈ´òÔºàÁÑ∂ËÄåÊàëÁöÑÁ©∫Èó¥ÁªìÊûúÂæàÂûÉÂúæÔºâ„ÄÇ‰∏Ä‰∏™ÈáçÁÇπÂ∞±ÊòØËøîÂõûÁöÑlist‰∏çÈúÄË¶ÅÊåâÁÖßÂéüÊù•ÁöÑÈ°∫Â∫èÊéíÂàó ‰ªé‰∏çÈúÄË¶ÅÂéüÊù•ÁöÑÈ°∫Â∫èÂæóÂà∞ÁöÑÊÄùË∑ØÊòØÔºöÊàëÊääÈúÄË¶ÅÂà†Èô§ÁöÑ‰∏úË•øÁöÑ‰ΩçÁΩÆÊîπÊàê‰∫ÜinfÔºåÁÑ∂ÂêéÂØπÊâÄÊúâÈÉ®ÂàÜËøõË°åÊéíÂ∫èÔºåÂæóÂà∞ÊéíÂ∫è‰πãÂêéÁöÑÁªìÊûúÂÜçËøõË°åÂàáÁâáÔºàËøôÈáåÂàöÂºÄÂßãÁöÑÊÄùË∑ØÊòØÂà†ÊéâËøô‰∏™Âú∞ÊñπÁöÑ‰∏úË•øÁÑ∂ÂêéÂÜçinsertÔºåÂêéÊù•ÂèëÁé∞Áõ¥Êé•ÊõøÊç¢Â∞±Â•Ω‰∫ÜÔºâ ÂÖ∂ÂÆû‰πüÂèØ‰ª•Áõ¥Êé•Áî®‰∫§Êç¢‰ΩçÁΩÆÁöÑÊñπÊ≥ïÔºå‰∏çÁî®ÂàáÁâáÔºåÂõ†‰∏∫È¢òÁõÆÂè™ÈúÄË¶ÅÂâçÈù¢ÁöÑËøô‰∫õÂÖÉÁ¥†Á¨¶ÂêàË¶ÅÊ±ÇÂ∞±ÂèØ‰ª•‰∫ÜÔºåÊ≤°ÊúâËØ¥ÂêéÈù¢ÁöÑÊÄé‰πàÊ†∑„ÄÇ Áúã‰∫Ü‰∏Ä‰∫õdiscussionÈÉΩÊòØmemoryÂè™ÊØî5 % ÁöÑ‰∫∫Â∞ë„ÄÇ„ÄÇ„ÄÇ‰ΩÜÊòØÂ∑ÆË∑ùÈÉΩ‰∏çÂ§ßÂ∫îËØ•Ê≤°ÈóÆÈ¢òÔºÅ ÁúãÂà∞‰∫Ü‰∏Ä‰∏™Ë∂ÖÁ∫ßÁâõÈÄºÁÆÄË¶ÅÂÜôÊ≥ïÔºö1234while val in nums: nums.remove(val)return len(nums) 80Given a sorted array nums, remove the duplicates in-place such that duplicates appeared at most twice and return the new length. Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory. Example 1: Given nums = [1, 1, 1, 2, 2, 3], Your function should return length = 5, with the first five elements of nums being 1, 1, 2, 2 and 3 respectively. It doesn‚Äôt matter what you leave beyond the returned length. 1234567891011121314151617181920212223242526class Solution: def removeDuplicates(self, nums: List[int]) -&gt; int: i = 0 while(True): if i &gt;= len(nums) - 1: if len(nums) &gt; 2 and nums[i] == nums[i - 2]: nums = nums[:nums.index(nums[i]) + 2] break else: break if nums[i] == nums[i + 1]: i += 1 else: next_num = nums[i + 1] start_index = nums.index(nums[i]) next_index = nums.index(next_num) if next_index - start_index &gt; 2: for l in range(start_index + 2, next_index): nums[l] = float('inf') i = next_index while float('inf') in nums: nums.remove(float('inf')) return len(nums) ÊÄªÁªìÔºö ÊàëÊ∑±‰ø°ÊàëÁöÑÊñπÊ≥ïËôΩÁÑ∂Ë†¢‰ΩÜÊòØÊ≤°ÊúâÈóÆÈ¢òÔºå‰ΩÜÊòØË∑ëÂá∫Êù•Â∞±ÊòØÊúâÈóÆÈ¢òÔºåÂàÜÊòéÊàëreturn‰πãÂâçÁöÑÊï∞ÊçÆËøòÈÉΩÊòØÂØπÁöÑÔºå‰ΩÜÊòØreturn‰πãÂêéÊòæÁ§∫ÁöÑ‰∏úË•øÂ∞±ÈÉΩÊúâÈóÆÈ¢ò‰∫Ü ‰∏ªË¶ÅÊÄùË∑ØÊòØËøôÊ†∑ÁöÑ Âõ†‰∏∫in - placeÊìç‰ΩúÔºåÊâÄ‰ª•Â∞±‰∏çËÉΩÁõ¥Êé•Áî®removeÂéªÊéâÂÖÉÁ¥†ÂØºËá¥‰∏ãÊ†áÈîô‰π± Êú¨Êù•ÊòØÊÉ≥Âíå‰∏äÈù¢ÁöÑÊÄùË∑Ø‰∏ÄÊ†∑ÔºåÊç¢ÊàêinfÔºåÁÑ∂ÂêéÂÜçÊääÊúâinfÁöÑÈÉ®ÂàÜÂà†Èô§ÊéâÔºàÂèÇËÄÉ‰∫Ü # 27ÁöÑÁÆÄÊòìËß£Ê≥ïÔºâ ÊÄé‰πàÊç¢ÊàêinfÂë¢ÔºåÊàëÂà§Êñ≠ÁöÑÊñπÊ≥ïÊòØÊâæÂà∞‰∏ã‰∏Ä‰∏™ÂÄºÂæóindexÔºåÁÑ∂ÂêéËÆ°ÁÆóËøô‰∏™indexÂíå‰∏ä‰∏Ä‰∏™‰πãÈó¥Â∑ÆÂ§öÂ∞ë‰∏™Êï∞ÔºåÁÑ∂ÂêéÊääÂØåË£ïÁöÑÊï∞Â≠óÈÉΩÊõøÊç¢Êàêinf ÂøΩÁï•ÁöÑÈóÆÈ¢òÔºö Êï∞Êï∞Êï∞Èîô‰∫ÜÂæàÂ§öÈóÆÈ¢ò ÊúÄÂºÄÂßãÊ≤°ÊúâËÄÉËôëÂà∞‰ªÄ‰πàÂÅúÊ≠¢ ÁÑ∂ÂêéÊ≤°ÊúâËÄÉËôëÂà∞Â¶ÇÊûúÊúÄÂêé‰∏Ä‰∏™Êï∞Â≠óÈáçÂ§ç‰∫Ü‰∏§ÈÅç‰ª•‰∏äË¶ÅÊÄé‰πàÂäûÁöÑÈóÆÈ¢òÔºàËøô‰πüÊòØÊàëÁî®next_indexÁöÑ‰∏Ä‰∏™ÂºäÁ´ØÔºâ ÁÑ∂ÂêéÁúãÁùÄÂ§ß‰Ω¨ÁöÑ‰ª£Á†ÅÂì≠Âá∫‰∫ÜÂ£∞ÔºÅÔºÅÔºÅ12345678910class Solution: def removeDuplicates(self, nums: List[int]) -&gt; int: i = 0 for n in nums: if i &lt; 2 or n != nums[i - 2]: nums[i] = n i += 1 return i ÊÄªÁªìÔºö ÂìáËøô‰∏™ÊÄùË∑ØÁúüÁöÑÁâõÈÄºÔºÅ ‰∏≠ÂøÉÊÄùÊÉ≥Â∞±ÊòØËÆ©nÊù•Â¢ûÂä†‰ΩÜÊòØi‰∏çÂ¢ûÂä†ÔºåËøôÈáåÂ∑≤ÁªèËØ¥‰∫Ü‰∏çÂú®ÊÑèÂâçÈù¢È°π‰πãÂêélistÈáåÈù¢ÁöÑÂÜÖÂÆπÔºå‰πüÂ∞±ÊòØËØ¥ÂâçnÈ°π‰πãÂêéÁöÑ‰∏úË•øÈÉΩ‰∏çÁî®ÁÆ°‰∫Ü„ÄÇÊó¢ÁÑ∂Â¶ÇÊ≠§ÁöÑËØù‰∏éÂÖ∂Áî®infÊù•ÊõøÊç¢Ëøô‰∏™‰ΩçÁΩÆÁöÑÊï∞Â≠óÔºå‰∏çÂ¶ÇÁõ¥Êé•Áî®ÂêéÈù¢ÁöÑÈ°πÂ°´Âú®Áõ∏ÂØπÂ∫îÁöÑ‰ΩçÁΩÆ‰∏äÔºåÂè™ÊúâÂ°´ÊàêÂäü‰∫ÜÊâç‰ºöÂ¢ûÂä†i ËøôÈáåÈúÄË¶ÅÂÖàÂà§Êñ≠iÁöÑÂÄºÊòØÂê¶Â∞è‰∫é2ÔºåÁÑ∂ÂêéÂÜçËÆ°ÁÆónums[i - 2]ÔºåÂê¶Âàô‰ºöout of range iË∑ëÁöÑÈÄüÂ∫¶Ê≤°ÊúâË∂ÖËøánË∑ëÁöÑÈÄüÂ∫¶ÊâÄ‰ª•Ê≤°ÊúâÂÖ≥Á≥ª ÂêàÁêÜÂà©Áî®È¢òÈáåÈù¢ÁöÑÊù°‰ª∂ÈôêÂà∂ÁúüÁöÑÂæàÈáçË¶ÅÔºÅÔºÅ 189 Rotate arrayGiven an array, rotate the array to the right by k steps, where k is non - negative. Example 1: Input: [1, 2, 3, 4, 5, 6, 7] and k = 3Output: [5, 6, 7, 1, 2, 3, 4]Explanation:rotate 1 steps to the right: [7, 1, 2, 3, 4, 5, 6]rotate 2 steps to the right: [6, 7, 1, 2, 3, 4, 5]rotate 3 steps to the right: [5, 6, 7, 1, 2, 3, 4] Example 2: Input: [-1, -100, 3, 99] and k = 2Output: [3, 99, -1, -100]Explanation:rotate 1 steps to the right: [99, -1, -100, 3]rotate 2 steps to the right: [3, 99, -1, -100] Note: Try to come up as many solutions as you can, there are at least 3 different ways to solve this problem.Could you do it in-place with O(1) extra space? ÊÄùË∑Ø ÈúÄ‰∏çÈúÄË¶ÅÊ≥®ÊÑèk = 0ÁöÑÊó∂ÂÄô Â¶ÇÊûúkÁöÑ‰∏™Êï∞ÁâπÂà´Â§ßÈúÄ‰∏çÈúÄË¶ÅÁÆÄÂåñ‰∏Ä‰∏ã 123456789101112class Solution: def rotate(self, nums: List[int], k: int) -&gt; None: """ Do not return anything, modify nums in-place instead. """ steps = k % len(nums) unchange_nums = nums[:len(nums) - steps] change_nums = nums[len(nums) - steps:] nums[:steps] = change_nums nums[steps:] = unchange_nums ÊÄªÁªìÔºö Â±ÖÁÑ∂Á¨¨‰∏ÄÁßçÂ∞±Ëøô‰πàÂÜôÂá∫Êù•‰∫ÜÔºåÂÆûÈôÖ‰∏äÂ∞±ÊòØÊääÂêéÈù¢ÁöÑÊï∞Â≠óÁßªÂä®Âà∞ÂâçÈù¢Âéª Ê≥®ÊÑènums‰∏çËÉΩÁõ¥Êé•Áî®change_nums + unchange_numsÔºåÂ§ßÊ¶ÇÊòØ‰ªñËÆ§‰∏∫Ëøô‰∏™‰∏çÊòØin - place‰∫ÜÂêß Âè¶‰∏ÄÁßçÊñπÊ≥ïÔºöin-place123456789101112 k = k % len(nums) self.reverse_nums(nums, 0, len(nums) - 1) self.reverse_nums(nums, 0, k - 1) self.reverse_nums(nums, k, len(nums) - 1)def reverse_nums(self,nums,start,end): while start &lt; end: temp = nums[start] nums[start] = nums[end] nums[end] = temp start += 1 end -= 1 ÂÆûÈôÖ‰∏äÔºårotateÁöÑÂè¶Â§ñ‰∏ÄÁßçÊñπÊ≥ïÊòØÂÖàÊääÊï¥‰∏™listÂèçÂêëÔºåÁÑ∂ÂêéÊääÂâçÈù¢ÁöÑk‰∏™ÂèçÂêëÔºåÁÑ∂ÂêéÂÜçÊääÂêéÈù¢ÁöÑ(n-k)‰∏™ÂèçÂêëÔºàËøôÈáåÊàëÊòØÊ≤°ÊÉ≥Âà∞ÁöÑÔºâ Êää‰∏Ä‰∏™Êï∞ÁªÑÂèçÂêëÁöÑÁÆóÊ≥ïÂ∞±ÊòØ‰ªé‰∏§Â§¥Âêë‰∏≠Èó¥ÈÄºËøëÁùÄ‰∫§Êç¢ÔºàÊàëËØ•Â•ΩÂ•ΩÂéªÁúãÁúãÂü∫Á°ÄÁöÑÁÆóÊ≥ï‰∫Ü„ÄÇ„ÄÇÔºâ ÊúÄÂêéÔºåËøòÊúâ‰∏ÄÁßçÊñπÊ≥ïÊòØË∑≥ÁùÄËÆæÁΩÆÂÄºÔºå‰πüÂ∞±ÊòØËØ¥k‰∏™‰πãÂêéÁöÑÂÄºÂ∞±Â∫îËØ•ÊòØÁé∞Âú®Ëøô‰∏™‰ΩçÁΩÆÁöÑÂÄº 41 First Missing PositiveGiven an unsorted integer array, find the smallest missing positive integer. Example 1: Input: [1,2,0]Output: 3Example 2: Input: [3,4,-1,1]Output: 2Example 3: Input: [7,8,9,11,12]Output: 1Note: Your algorithm should run in O(n) time and uses constant extra space. Á¨¨‰∏Ä‰∏™ÊÄùË∑ØÔºöÊó∂Èó¥nlog(n)12345678class Solution: def firstMissingPositive(self, nums: List[int]) -&gt; int: nums.sort() target = 1 for n in nums: if n == target: target += 1 return target Ëøô‰∏™ÊÄùË∑ØÊï¥‰ΩìÂª∫Á´ãÂú®ÂÖàÊéíÂ∫èÁöÑÂü∫Á°Ä‰∏äÔºå‰ΩÜÊòØÊéíÂ∫èÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶Êú¨Ë∫´Â∞±Â∑≤ÁªèÊòØnlog(n)‰∫Ü ÊéíÂ∫è - ÊâæÂà∞ÊØî0Â§ßÁöÑÊï∞Â≠ó‰ªéËøôÈáåÂºÄÂßã - Ëøô‰∏™Êï∞Â≠ó‰∏çÁ¨¶ÂêàÁöÑËØùÊâæ‰∏ã‰∏Ä‰∏™ ‰ΩÜÊòØÊàëÂú®ÊâæÊØî0Â§ßÁöÑÊï∞Â≠óÁöÑÊó∂ÂÄôËøòÊÉ≥ÁùÄÊäälistÂàáÁâáÔºåÂàáÁâáÂ∞±ÂèàÈúÄË¶ÅËÄÉËôë0ÂïäÔºå1ÂïäÔºåÁº∫Â§öÂ∞ë‰∏™Êï∞Â≠óÁöÑÈóÆÈ¢òÔºåÁ©∫ÁöÑlist„ÄÇÂÖ∂ÂÆûÊ†πÊú¨‰∏çÁî®Ëøô‰πàÈ∫ªÁÉ¶ Êú¨Ë¥®‰∏äËøô‰∏™ÊñπÊ≥ïÂ∞±ÊòØÔºåÊâæÂà∞missÁöÑÊ≠£Êï∞ÔºåÈÇ£Â∞±‰ªéÊ≠£Êï∞ÁöÑÁ¨¨‰∏Ä‰∏™Ôºà1ÔºâÂºÄÂßãÊâæÔºåÂ¶ÇÊûúÊâæÂà∞‰∫ÜËøô‰∏™Êï∞Â∞±ÁªßÁª≠Êâæ‰∏ã‰∏Ä‰∏™Ôºàtarget++ÔºâÔºåÊÄªÊòØËÉΩÊâæÂà∞ÁöÑÂòõÔºåÊâæÂà∞ÁöÑÂ∞±ÊòØÁº∫ÁöÑÊï∞Â≠ó‰∫Ü Ëá™Â∑±ÁöÑÊñπÊ≥ï12345678910111213141516class Solution: def firstMissingPositive(self, nums: List[int]) -&gt; int: if nums is None or len(nums) == 0: return 1 for i in range(len(nums)): target_num = i + 1 if nums[i] == target_num: if i == len(nums) - 1: return target_num + 1 else: continue if target_num in nums: temp = nums.index(target_num) nums[temp],nums[i] = nums[i], nums[temp] else: return target_num Ê°∂ÊéíÂ∫èÔºöË¶ÅÊääÂØπÂ∫îÁöÑÊï∞Â≠óÊîæÂú®ÂØπÂ∫îÁöÑ‰ΩçÁΩÆ‰∏ä ËøôÈÅìÈ¢òÈáåÂ∫îËØ•ÁöÑÊ†∑Â≠êÂ∞±ÊòØnums[index] = index + 1 Â§ß‰Ω¨ÁöÑÊÄùË∑Ø -&gt; È¶ñÂÖàÂà§Êñ≠ËæπÁïåÊù°‰ª∂ÔºÅÔºÅ(Â≠¶Âà∞‰∫ÜÂ≠¶Âà∞‰∫Ü) ÁúãËøá‰∫Ü‰∏äÈù¢ÁöÑÊèêÁ§∫ÂÜôÂá∫Êù•ÁöÑÁ¨¨‰∫åÁâà Âà§Êñ≠ËæπÁïåÊù°‰ª∂ Âà§Êñ≠Ëøô‰∏™Êï∞Â≠óÊòØ‰∏çÊòØÊëÜÂú®‰∫ÜÊ≠£Á°ÆÁöÑ‰ΩçÁΩÆ Ê≠£Á°ÆÔºåÂà§Êñ≠ÊòØÂê¶ÊòØÊúÄÂêé‰∏Ä‰∏™Êï∞Â≠ó ÊòØÔºåËæìÂá∫ÁöÑÊòØÊúÄÂêé‰∏Ä‰∏™Êï∞Â≠ó+1 ‰∏çÊòØÔºåËøô‰∏™‰ΩçÁΩÆÁöÑÊ≠£Á°Æ‰∫ÜÔºåÂà§Êñ≠‰∏ã‰∏Ä‰∏™‰ΩçÁΩÆ Ê≤°ÊúâÔºåÂà§Êñ≠numsÈáåÈù¢ËøòÊúâÊ≤°ÊúâÂ∫îËØ•ÊëÜÂú®Ëøô‰∏™‰ΩçÁΩÆÁöÑÊï∞Â≠ó ÊúâÔºåÈÇ£Â∞±ÂíåËøô‰∏™‰ΩçÁΩÆ‰∫§Êç¢ Ê≤°ÊúâÔºåÈÇ£Ê≤°ÊúâÁöÑÊï∞Â≠óÂ∞±ÊòØÁº∫Â∞ëÁöÑÊï∞Â≠ó‰∫Ü Âõ†‰∏∫ÊØèÊ¨°ÈÉΩÊòØÊääÊï∞Â≠óÊç¢Âà∞‰∫ÜÊ≠£Á°ÆÁöÑ‰ΩçÁΩÆ‰∫ÜÔºåÊâÄ‰ª•‰∫§Êç¢ÊúÄÂ§öËøõË°ålen(nums)Ê¨°ÔºåÊó∂Èó¥Â§çÊùÇÂ∫¶ÊòØO(n) 123456789def firstMissingPositive(self, nums): for i in xrange(len(nums)): while 0 &lt;= nums[i]-1 &lt; len(nums) and nums[nums[i]-1] != nums[i]: tmp = nums[i]-1 nums[i], nums[tmp] = nums[tmp], nums[i] for i in xrange(len(nums)): if nums[i] != i+1: return i+1 return len(nums)+1 Â§ß‰Ω¨ÁöÑÂè¶‰∏Ä‰∏™ÊñπÊ≥ïÔºåÂÖ∂ÂÆûÊÄùË∑ØÂíå‰∏äÈù¢ÁöÑÂ∑Æ‰∏çÂ§öÔºåÂ∞±ÊòØÊääÊï∞Â≠óÊç¢Âà∞Ê≠£Á°ÆÁöÑ‰ΩçÁΩÆ‰∏äÔºå‰ΩÜÊòØÂà§Êñ≠ÁöÑÊù°‰ª∂ÂíåÊàëÁöÑÊúâ‰∏ÄÁÇπ‰∏çÂêåÔºåÂèØËÉΩÂõ†‰∏∫ÊàëÁöÑÊòØÂü∫‰∫épythonÁöÑÂäüËÉΩ ÂÖ∂‰∏≠ÔºåÊç¢Âà∞Ê≠£Á°Æ‰ΩçÁΩÆÁöÑÊï∞Â≠óÂ∞±ÊòØÂú®1Âà∞len(nums)‰πãÈó¥ÁöÑÊï∞Â≠ó„ÄÇnums[i]-1ÊòØËøô‰∏™Êï∞Â≠óÂ∫îËØ•ÁöÑÂùêÊ†á‰ΩçÁΩÆÔºåÂ¶ÇÊûúÂ∫îËØ•ÁöÑ‰ΩçÁΩÆÂíåÁé∞Âú®ÁöÑ‰ΩçÁΩÆÁöÑÊï∞Â≠ó‰∏ç‰∏ÄÊ†∑ÔºåÈÇ£Â∞±‰∫§Êç¢Ëøô‰∏§‰∏™Êï∞Â≠ó Ê≥®ÊÑèËøôÈáåÈúÄË¶ÅÁî®whileÊç¢ÔºåË¶Å‰∏ÄÁõ¥Êç¢Âà∞Ê≠£Á°ÆÁöÑ‰ΩçÁΩÆÊâçÂèØ‰ª• ËøôÊ†∑ÁöÑÁªìÊûúÂ∞±ÊòØÂ§ßÂÆ∂ÈÉΩÊåâÊ≠£Á°ÆÁöÑÂ°´Â•Ω‰∫ÜÔºåÊúÄÂêé‰∏çÂØπÁöÑÈÇ£‰∏™‰ΩçÁΩÆÁöÑindex+1Â∞±ÊòØÈúÄË¶ÅÁöÑÁªìÊûú 299You are playing the following Bulls and Cows game with your friend: You write down a number and ask your friend to guess what the number is. Each time your friend makes a guess, you provide a hint that indicates how many digits in said guess match your secret number exactly in both digit and position (called ‚Äúbulls‚Äù) and how many digits match the secret number but locate in the wrong position (called ‚Äúcows‚Äù). Your friend will use successive guesses and hints to eventually derive the secret number. Write a function to return a hint according to the secret number and friend‚Äôs guess, use A to indicate the bulls and B to indicate the cows. Please note that both secret number and friend‚Äôs guess may contain duplicate digits. Example 1: Input: secret = ‚Äú1807‚Äù, guess = ‚Äú7810‚Äù Output: ‚Äú1A3B‚Äù Explanation: 1 bull and 3 cows. The bull is 8, the cows are 0, 1 and 7.Example 2: Input: secret = ‚Äú1123‚Äù, guess = ‚Äú0111‚Äù Output: ‚Äú1A1B‚Äù Explanation: The 1st 1 in friend‚Äôs guess is a bull, the 2nd or 3rd 1 is a cow.Note: You may assume that the secret number and your friend‚Äôs guess only contain digits, and their lengths are always equal. 1234567class Solution: def getHint(self, secret: str, guess: str) -&gt; str: bull = sum(a == b for a,b in zip(secret,guess)) cow = 0 for x in set(guess): cow += min(secret.count(x),guess.count(x)) return str(bull) + "A" + str(cow-bull) + "B" ËøôÈáåËá™Â∑±ÊÉ≥‰∫Ü‰∏Ä‰∫õÊØîËæÉË†¢ÁöÑÊÉ≥Ê≥ï‰πãÂêéÁõ¥Êé•ÂèÇËÄÉÂà´‰∫∫ÁöÑ‰∫Ü ÂÖ∂‰∏ÄÊòØÊØîÂØπ‰ªñ‰ª¨‰∏§‰∏™‰ΩçÁΩÆÂíåÊï∞Â≠óÈÉΩÁõ∏ÂêåÁöÑ‰∏úË•øÔºåÊÉ≥Ë¶ÅËΩ¨Êç¢ÊàêdictÊù•ÊØîËæÉÔºå‰ΩÜÊòØÂêéÊù•ÂèëÁé∞stringÂ∞±ÂèØ‰ª•Áõ¥Êé•index‰∫Ü‰∏çÁî®Ëøô‰πàÈ∫ªÁÉ¶ ÊÉ≥ËøáËÉΩ‰∏çËÉΩÊåâ‰ΩçÂÅöÂáèÊ≥ïÔºåÊú™Êûú ÂÖ∂‰∫åÊòØÂú®ÂæóÂà∞‰∫Übull‰πãÂêéÊääbullÁöÑÈÉ®ÂàÜ‰ªéÂéüÊù•ÁöÑÈáåÈù¢ÂâîÈô§Âá∫ÂéªÁÑ∂ÂêéÂÜçÊØîËæÉÁõ∏‰ººÁöÑÊï∞Â≠ó ÈÅáÂà∞‰∫Ü‰∏ªË¶ÅÈóÆÈ¢òÊòØÈáçÂ§çÁöÑÊï∞Â≠óÊÄé‰πàÂäû‰ª•ÂèäÂ¶Ç‰ΩïÂâîÈô§Âá∫Âéªbull ‰∏ªË¶ÅÊÄùË∑ØÊòØËøôÊ†∑ÁöÑÔºö ÂÖ∂ÂÆûcowÁöÑÊï∞ÈáèÂ∞±ÊòØbull-cowÈÉΩÊòØÁöÑÊï∞ÈáèÂáèÂéªbullÁöÑÊï∞ÈáèÔºå‰πüÂ∞±Áõ∏ÂΩì‰∫éÁª¥ÊÅ©ÂõæÈáåÈù¢ÔºåÂè™ÊúâAÁöÑÈáèÊòØAÁöÑÈáè - ÂêåÊó∂ABÁöÑÈáè„ÄÇËøôÈáåÊòØbullÂ∞±Áõ∏ÂΩì‰∫éABÈÉΩÊúâÔºå‰∏§‰∏™ÈáåÈù¢ÊâÄÊúâÈáçÂ§çÁöÑÊï∞ÈáèÂ∞±Áõ∏ÂΩì‰∫éAÁöÑÈáè ËøôÊ†∑ÂèØ‰ª•ÂÅöÂáèÊ≥ïÂ∞±Ëß£ÂÜ≥‰∫Ü‰∏äÈù¢ÁöÑ‰ªébullÂæóÂà∞cowÁöÑÈóÆÈ¢òÔºÅÔºÅ ÊâÄ‰ª•ËØ¥ÁúãÈóÆÈ¢òËøòÊòØË¶ÅÁúãÊú¨Ë¥® Èù¢ÂØπÈáçÂ§çÁöÑÊï∞Â≠óÔºåÂ±ÖÁÑ∂ÂèØ‰ª•Áõ¥Êé•ÊäästringËΩ¨Êç¢Êàêset ËøôÈáåÂ§ç‰π†‰∏Ä‰∏ãsetÂ•ΩÂêóÔºÅÔºÅÔºÅËøô‰∏™ÈõÜÂêàÂ±ÖÁÑ∂ÂèØ‰ª•Ê≤°ÊúâÈáçÂ§çÁöÑÂÖÉÁ¥†ÔºåÂπ≥Â∏∏ÊàëÂøΩËßÜ‰Ω†‰∫ÜÂëÄÂ∞èÂèØÁà±ÔºåËΩ¨ÂåñÊàêsetÂ∞±‰∏ç‰ºöÈáçÂ§ç‰∫ÜÂì¶ÔºåÈúáÊÉäÔºÅÔºÅ ËøôÊ†∑ÈóÆÈ¢òÂ∞±ÂèòÊàê‰∫ÜÔºö Ê±ÇbullÔºöÁî®zipÊää‰∏§‰∏™‰∏úË•ø‰∏Ä‰∏ÄÂØπÂ∫îÁöÑÊâìÂåÖËµ∑Êù•ÔºàÂ±ÖÁÑ∂ËøòÊúâ‰Ω†Â∞èÂèØÁà±ÔºÅÔºâÁõ¥Êé•ÂØπÊØî Ê±ÇbothÔºöguessÈáåÈù¢ÁåúÁöÑÊ¨°Êï∞Â∞±ÊòØÊÄª‰ΩìÁöÑÊ¨°Êï∞ÔºåsecretÈáåÈù¢ÁöÑÊ¨°Êï∞ÊòØÁúüÂÆûÁöÑÊ¨°Êï∞ÔºåÂØπ‰∫éÊØè‰∏™Âú®guessÈáåÈù¢ÔºàsetÔºâÁöÑÂÖÉÁ¥†ÈÉΩÁúãÁúãÂàÜÂà´Âú®‰∏§‰∏™ÈáåÈù¢ÊòØÂ§öÂ∞ë‰∏™ÔºåÁÑ∂ÂêéÂ∞èÁöÑÈÇ£‰∏™Â∞±ÊòØbothÁöÑÂ§ßÂ∞è ËøôÈáå‰ªãÁªç.count()Â∞èÂèØÁà±ÔºåÂ±ÖÁÑ∂ËøòÂèØ‰ª•Êï∞Êï∞ÔºÅ ÊúÄÂêéboth-bullÂ∞±ÊòØÁªìÊûú‰∫Ü 134 gas stationÂ±ÖÁÑ∂Ëá™Â∑±ÊêûÂá∫Êù•‰∫Ü‰∏Ä‰∏™ÁúãËµ∑Êù•ÂæàË†¢ÁöÑ1234567891011121314151617181920212223242526class Solution: def canCompleteCircuit(self, gas: List[int], cost: List[int]) -&gt; int: if sum(gas) &lt; sum(cost): return -1 tank = 0 current = 0 counter = 0 while(True): tank = tank + gas[current] - cost[current] if tank &lt; 0: if current &lt; len(gas): current = current + 1 counter = 0 tank = 0 continue else: return -1 current += 1 current = current % len(gas) counter += 1 # print(current,counter) if counter == len(gas): return current % len(gas) ~Êó∂Èó¥Ë∂ÖËøá‰∫ÜÁôæÂàÜ‰πã48ÁöÑ‰∫∫ÔºåÊÑüËßâÂèØËÉΩËøòÂèØ‰ª•Âêß~Êó∂Èó¥ÈÉΩÊòØÈ™ó‰∫∫ÁöÑÂèàË∑ë‰∫Ü‰∏ÄÊ¨°Â±ÖÁÑ∂Ë∂ÖËøá‰∫ÜÁôæÂàÜ‰πã86ÁöÑÔºÅÔºÅ ÈáçÁÇπ ‰∏ÄÁõ¥ÊåâÁùÄÈ°∫Â∫èË∑ëÔºå‰∏ç‰ºöË∑≥ÁùÄËµ∞ Â¶ÇÊûúgasÁöÑÊÄªÈáè‰ªé‰∏ÄÂºÄÂßãÂ∞±Â∞è‰∫écostÁöÑÊÄªÈáèÔºåÈÇ£ÁªùÂØπ‰∏çÂèØËÉΩ ÊàëÁöÑÊÄùË∑ØÔºö ‰ªéÁ¨¨‰∏Ä‰∏™ÁÇπÂºÄÂßãËØïÁùÄË∑ëÔºå‰∏ÄÁõ¥Âà∞ËØïÁùÄ‰ªéÊúÄÂêé‰∏Ä‰∏™ÁÇπÂºÄÂßãË∑ëÔºåÊâæÂà∞‰∫ÜÂ∞±Áõ¥Êé•ËøîÂõû Â¢ûÂä†‰∏Ä‰∏™ËÆ°Êï∞ÁöÑvarÔºåËÆ∞‰∏ÄÂÖ±Ë∑ë‰∫ÜÂ§öËøúÔºåÂõ†‰∏∫ÊòØÊåâÁùÄÈ°∫Â∫èË∑ëÁöÑÊâÄ‰ª•Ëøô‰∏™varÁ≠â‰∫égasÁöÑÈïøÂ∫¶ÁöÑÊó∂ÂÄôÂ∞±ÊòØË∑ëÂÆå‰∫Ü ÈÅøÂÖçout of rangeÈóÆÈ¢òÔºåÈúÄË¶ÅÊ±Ç‰ΩôÊï∞ ÈÅáÂà∞ÈóÆÈ¢òÔºö ÂΩìtankÂ∞è‰∫é0ÔºåÊõ¥Êñ∞ÂÆåÊù°‰ª∂‰πãÂêéËÆ∞ÂæócontinueÁªßÁª≠Âæ™ÁéØÂëÄ ÂàöÂºÄÂßãÊÉ≥Áî®ÁöÑÂà§Êñ≠Êù°‰ª∂ÊòØforÊàñËÄÖwhileÈáåÈù¢Â∏¶Êù°‰ª∂ÔºåËøòÊÉ≥‰∫Ü‰∏Ä‰∏ãË¶Å‰∏çË¶ÅzipËøô‰∏§‰∏™Êï∞ÊçÆÔºå‰ΩÜÊòØÈÉΩÊòØlistÂÆûÂú®ÊòØÊ≤°ÊúâÂøÖË¶Å„ÄÇ‰ΩÜÊòØÊÑüËßâÊòØÊÉ≥ÁöÑÂÆûÂú®ÊòØÂ§™Â§ö‰∫Ü 1234567891011class Solution: def canCompleteCircuit(self, gas: List[int], cost: List[int]) -&gt; int: if sum(gas) &lt; sum(cost): return -1 rest = start = 0 for i in range(len(gas)): rest += gas[i] - cost[i] if rest &lt; 0: start = i + 1 rest = 0 return start Â±ÖÁÑ∂ÊúâËøô‰πàÁÆÄË¶ÅÁöÑÂÜôÊ≥ïÔºÅÔºÅ ÊâÄ‰ª•Âè™Ë¶Å‰∏çÊòØsum(gas) &lt; sum(cost)Â∞±‰∏ÄÂÆö‰ºöÊúâËß£ËØ∂ÔºåÁ•ûÂ•á„ÄÇ‰πüÂ∞±ÊòØËØ¥Êàë‰∏äÈù¢Êúâ‰∏Ä‰∏™ËøîÂõûÁöÑ-1ÊòØÊ≤°ÊúâÊÑè‰πâÁöÑ ËÄå‰∏îÁî®forÁöÑËØùÂ∞±‰∏çÁî®ÂÜçËÄÉËôëcounterÁöÑÈóÆÈ¢ò‰∫Ü ‰ªéÂì™ÈáåÂ§±Ë¥•Â∞±‰ªéÂì™ÈáåÁöÑ‰∏ã‰∏Ä‰∏™Áà¨Ëµ∑Êù• 118 Pascal‚Äôs TriangleExample: Input: 5Output:[ [1], [1,1], [1,2,1], [1,3,3,1], [1,4,6,4,1]] 1234567891011121314151617181920212223class Solution: def generate(self, numRows: int) -&gt; List[List[int]]: result = [] if numRows == 0: return [] for row in range(numRows): now_row = [] if row == 0: now_row = [1] elif row == 1: now_row = [1,1] else: now_row = [1] for member in range(1,row): now_row.append(result[row-1][member-1] + result[row-1][member]) now_row.append(1) result.append(now_row) return result ÊÄªÁÆóÊòØËá™Â∑±ÂÜôÂá∫Êù•‰∏Ä‰∏™‰∏úË•ø‰∫Ü Â•ΩÁÆÄÂçïÔºåÈô§‰∫ÜÂâç‰∏§Ë°åÊòØÁâπÂÆöÁöÑÔºåÂÖ∂‰ªñÁöÑÂèØ‰ª•ÂΩí‰∏∫‰∏ÄÁ±ª Ê±Ç‰∏Ä‰∏™ÁÆÄÂçïÁöÑÊï∞Â≠¶ÂÖ≥Á≥ªÂ∞±Ë°å‰∫ÜÔºåÊï∞Êï∞Âà´Êï∞Èîô‰∫ÜÔºÅÔºÅÊ≥®ÊÑèÊï∞0 ÂîØ‰∏ÄÊ≤°ÊúâÊ≥®ÊÑèÁöÑÁÇπÂ∞±ÊòØÔºö‰∫ãÂÖà‰∏çÁü•ÈÅìlistÁöÑÂ§ßÂ∞èÔºåÊâÄ‰ª•ÂàùÂßãÂåñÊàêÁ©∫ÁöÑ‰πãÂêéÈúÄË¶ÅÁî®appendÊ∑ªÂä†ÂÖÉÁ¥† 119 Êù®Ëæâ‰∏âËßíÂΩ¢2Given a non-negative index k where k ‚â§ 33, return the kth index row of the Pascal‚Äôs triangle. Note that the row index starts from 0. Input: 3Output: [1,3,3,1] 1234567class Solution: def getRow(self, rowIndex: int) -&gt; List[int]: L = [1] while True: if len(L) == rowIndex + 1: return L L = [u+v for u,v in zip([0]+L,L+[0])] Ê≤°ÊÉ≥Âà∞Êù®Ëæâ‰∏âËßíÂΩ¢ÁöÑ‰ª£Á†Å‰πüÊúâÁÆÄË¶ÅÁöÑËß£Ê≥ïÔºåËøô‰∏™ÊòØÁî®LËÆ∞ÂΩï‰∫Ü‰∏ä‰∏ÄË°åÁöÑ‰ø°ÊÅØÔºåÁÑ∂ÂêéÂÜçÊääËøôË°åÊâ©ÂÖÖ‰∏§‰∏™0ÔºåÁõ∏ÂΩì‰∫éËøô‰∏™‰∏âËßíÂΩ¢ÁöÑÊú¨Ë¥®ÊòØ‰∏§Ë°åÈîô‰ΩçÁõ∏Âä†ÔºÅÔºÅ Ê≥®ÊÑèÊúÄÂêéÁöÑLÂæóÂà∞ÁöÑÊòØ‰∏Ä‰∏™listÔºålistË¶ÅÊúâlistÁöÑÊ†∑Â≠ê Êõ¥Âä†ÁêÜËß£‰∫Ü‰∏Ä‰∏ãzipÂíåÂçïË°åforÁöÑÁî®Ê≥ï index‰ªé0ÂºÄÂßãÔºåÁªìÊûúÂºÄÂßãÊ≤°ÊúâÊ≥®ÊÑèÂà∞ while true Âä†‰∏ä‰∏Ä‰∏™ ifÁöÑÊïàÊûúÁ≠âÂêå‰∫éforÁöÑÊïàÊûúÔºÅÔºÅÔºÅË∂äÂÜôË∂äÁ≥äÊ∂Ç 169 Majority ElementGiven an array of size n, find the majority element. The majority element is the element that appears more than ‚åä n/2 ‚åã times. You may assume that the array is non-empty and the majority element always exist in the array. Example 1: Input: [3,2,3]Output: 3Example 2: Input: [2,2,1,1,1,2,2]Output: 2 1234class Solution: def majorityElement(self, nums: List[int]) -&gt; int: nums.sort() return nums[len(nums)//2] ÊÄùË∑ØÔºöËøôÂõûÊÉ≥Âà∞‰∫ÜÂæàÂ§öÂéÜÈÅçÁöÑÊñπÊ≥ïÔºå‰ΩÜÊòØÊÑüËßâÂ§™Ë†¢‰∫ÜÔºåÁªà‰∫éÂºÄÂßãÊÉ≥ÊÄé‰πàÊâçËÉΩÊõ¥Â•ΩÁöÑÂÆûÁé∞‰∫Ü Âú®ÂÜôÂÜôÁîªÁîªÁöÑÊó∂ÂÄôÁ™ÅÁÑ∂ËÄÉËôëÂà∞ÔºåÂ¶ÇÊûúÊúâË∂ÖËøá‰∏ÄÂçäÁöÑÊï∞ÈáèÈÉΩÊòØËøô‰∏™Êï∞ÁöÑËØùÔºåÊääËøô‰∏™listÊéíÂ∫è‰πãÂêéÊúÄ‰∏≠Èó¥ÁöÑÈÇ£‰∏™Êï∞ËÇØÂÆöÊòØËøô‰∏™Êï∞ ÊûÅÈôêÊÉÖÂÜµÂ∞±ÊòØ‰∏§‰∏™ÂÖÉÁ¥†Â∑Æ1ÔºåËøôÊó∂ÂÄôÊòØÂ§ö‰∏ÄÁÇπÁöÑÈÇ£‰∏™Êï∞ÁöÑËæπÁïå‰∏ä ÂÖ∂‰ªñÁöÑÊÉÖÂÜµ‰∏ãÂ∞±ÊòØÂú®Âá∫Áé∞ÊúÄÂ§öÁöÑÈÇ£‰∏™Êï∞ÁöÑ‰∏≠Èó¥ Êú¨Êù•ÊÉ≥Ë¶ÅÁî®floorÁöÑÔºå‰ΩÜÊòØÂèëÁé∞ÈúÄË¶ÅmathÂåÖÔºåÊâÄ‰ª•Áî®‰∫Ü // Êù•Ê±ÇÈô§‰πãÂêéÁöÑÊï¥Êï∞ 229 Majority Element 2Given an integer array of size n, find all elements that appear more than ‚åä n/3 ‚åã times. Note: The algorithm should run in linear time and in O(1) space. Example 1: Input: [3,2,3]Output: [3]Example 2: Input: [1,1,1,3,3,2,2,2]Output: [1,2]12345678910111213141516171819202122class Solution: def majorityElement(self, nums: List[int]) -&gt; List[int]: if not nums: return [] major1,major2,count1,count2 = 0,1,0,0 for n in nums: if major1 == n: count1 += 1 elif major2 ==n: count2 += 1 elif count1 ==0: major1 = n count1 = 1 elif count2 == 0: major2 = n count2 =1 else: count1 -= 1 count2 -= 1 return [n for n in (major1,major2) if nums.count(n) &gt; len(nums) // 3] Ê≥®ÊÑèËøôÈÅìÈ¢òËØ¥ÁöÑÊòØÂá∫Áé∞Ê¨°Êï∞Â§ß‰∫é1/3ÁöÑÊï∞Â≠óÔºåÊâÄ‰ª•ÁªìÊûúÂè™ÊúâÂè™ËÉΩÊòØÊ≤°ÊúâÔºå1‰∏™ÊàñËÄÖ‰∏§‰∏™Ôºå‰∏çÂ≠òÂú®ÁªìÊûúÊòØ‰∏â‰∏™ÁöÑÊÉÖÂÜµÔºÅ Ëøô‰∏™ÊÉ≥‰∫ÜÂçäÂ§©‰∏ç‰ºöÂÅöÔºåÊü•‰∫Ü‰∏Ä‰∏ãÁî®ÁöÑÊòØBoyer-Moore Majority Vote algorithm Ëøô‰∏™ÁÆóÊ≥ïÁöÑ‰∏ªË¶ÅÊÑèÊÄùÊòØÂ¶ÇÊûú‰∏§Êã®‰∫∫ÊâìÊû∂ÔºåÊâìÊû∂‰∏ÄÂØπ‰∏ÄÊäµÊ∂àÔºåÁÑ∂ÂêéÁúãÁúãÂâ©‰∏ãÁöÑÈÉ®ÂàÜÂì™‰∏™ÊØîËæÉÂ§ö ËÆ∞ÂΩïÂâ©‰∏ãÁöÑ‰∏úË•øÁöÑÊñπÊ≥ïÂ∞±ÊòØÂ¢ûÂä†‰∫Ü‰∏Ä‰∏™È¢ùÂ§ñÁöÑÈÉ®ÂàÜÔºåÂåÖÊã¨majorÂíåcount‰∏§ÈÉ®ÂàÜÔºåmajorËÆ∞ÂΩïÁöÑÊòØÊúâÂâ©‰ΩôÁöÑÊï∞ÊòØ‰ªÄ‰πàÔºåcountËÆ∞ÂΩïËøòÊúâÂ§öÂ∞ë‰∏™ Â¶ÇÊûúcountÊ≤°Êúâ‰∫ÜÔºåÈÇ£‰πàÂ∞±‰ªéÁé∞Âú®ÈÅáÂà∞ÁöÑÊñ∞ÁöÑÊï∞ÂºÄÂßãËÆ∞ Â¶ÇÊûúÁé∞Âú®ÁöÑÊï∞‰∏çÊòØÈúÄË¶ÅÁöÑÔºåÈÇ£‰πàcount - 1ÔºåÂ¶ÇÊûúÊòØÁé∞Âú®ÈúÄË¶ÅÁöÑÈÇ£‰πàcount + 1 ÊúÄÂºÄÂßãÊòØÁî®Âú®‰∏Ä‰∏™Êï∞ÁªÑÈáåÈù¢ÊâæË∂ÖËøá‰∏ÄÂçäÁöÑÊï∞ÁöÑÔºå‰ΩÜÊòØÊàë‰∏ä‰∏ÄÈÅìÈ¢òÁî®‰∫ÜÂÖ∂‰ªñÊñπÊ≥ïÊâÄ‰ª•Ê≤°Áî®Âà∞ Ê≥®ÊÑèÂõ†‰∏∫ÊòØÊ±Ç1/3ÁöÑÊï∞Â≠óÔºåÊâÄ‰ª•ËôΩÁÑ∂ÊúâÂâ©‰∏ãÁöÑÔºå‰ΩÜÊòØÂâ©‰∏ãÁöÑ‰∏ç‰∏ÄÂÆöÈÉΩÊòØÁ¨¶ÂêàË¶ÅÊ±ÇÁöÑÔºåÈúÄË¶ÅÂÜçÊï∞‰∏Ä‰∏ã‰∏™Êï∞ÂØπ‰∏çÂØπÔºàËøôÊâçÊúâ‰∫ÜreturnËøô‰∏ÄË°åÈáåÈù¢ÁöÑ‰∏úË•øÔºâ ‰∫∫Á±ªÁöÑÁÆóÊ≥ïÁúüÊòØÂ•áÂπªÊó†Á©∑ 274 h-indexGiven an array of citations (each citation is a non-negative integer) of a researcher, write a function to compute the researcher‚Äôs h-index. According to the definition of h-index on Wikipedia: ‚ÄúA scientist has index h if h of his/her N papers have at least h citations each, and the other N ‚àí h papers have no more than h citations each.‚Äù Example: Input: citations = [3,0,6,1,5]Output: 3Explanation: [3,0,6,1,5] means the researcher has 5 papers in total and each of them had received 3, 0, 6, 1, 5 citations respectively. Since the researcher has 3 papers with at least 3 citations each and the remaining two with no more than 3 citations each, her h-index is 3.Note: If there are several possible values for h, the maximum one is taken as the h-index. 1234567891011class Solution: def hIndex(self, citations: List[int]) -&gt; int: result = 0 for h_cand in range(len(citations) + 1): h_more = 0 for citation in citations: if citation &gt;= h_cand: h_more += 1 if h_more &gt;= h_cand: result = max(result,h_cand) return result ÊÄùË∑ØÔºåÈùûÂ∏∏Áõ¥ËßÇÁöÑÊñπÊ≥ïÔºåÁõ¥Êé•iterateÊâÄÊúâÁöÑÂÖÉÁ¥†ÔºåÂ¶ÇÊûúÊâæÂà∞‰∫ÜÊõ¥Â§ßÁöÑresultÁöÑÂÄºÂ∞±ÂèñÊúÄÂ§ßÁöÑÔºàÊ†πÊçÆÈ¢òÁõÆË¶ÅÊ±ÇÔºâ Ê≥®ÊÑèÁöÑÁÇπÂú®ÈúÄË¶Å h_more &gt;= h_candËÄå‰∏çÊòØÁ≠â‰∫éÔºåÂõ†‰∏∫ÁªôÂá∫ÁöÑÂÆö‰πâÁöÑÊÑèÊÄùÊòØindex-hÊòØÊúâh‰∏™ÁöÑÂÄºÂ§ß‰∫éÁ≠â‰∫éhÔºåh_moreÁöÑ‰∏™Êï∞‰ºöÊØîh_candÂ§öÔºà‰ΩÜÊòØÂõ†‰∏∫Âèñ‰∫Ü‰∏ãÈù¢ÁöÑmaxÔºåÊâÄ‰ª•Á≠â‰∫éÂÖ∂ÂÆû‰πüÊòØÂèØ‰ª•ÂæóÔºâ Ëøô‰∏™ÁöÑÈÄüÂ∫¶ÁúüÁöÑÂ•ΩÊÖ¢ÔºåÂ∞ùËØï‰∏Ä‰∏ãbinary search 1234567891011121314151617class Solution: def hIndex(self, citations: List[int]) -&gt; int: bucket = [0 for n in range(len(citations)+1)] for nums in citations: if nums &gt;= len(citations): bucket[len(citations)] += 1 else: bucket[nums] += 1 result = 0 for nums in range(len(bucket)): nums = len(bucket) - nums -1 result += bucket[nums] if result &gt;= nums: return nums return 0 Áî®‰∫ÜÊ°∂ÊéíÂ∫èÁöÑÁ•ûÂ•áÊñπÊ≥ï ËøòÊòØÂèñÂÜ≥‰∫éÂÆö‰πâÔºåÂ¶ÇÊûú‰∏ÄÂÖ±Êúâ5‰∏™paperÁöÑËØùÔºåÂèØ‰ª•ÈÄâÁöÑhÁöÑÂÄºÊúâ6‰∏™ÔºåÂàÜÂà´ÊòØ0 1 2 3 4 5ÔºåÊääËøôÁïô‰∏™ÂÄºÂàÜÊàêÂÖ≠‰∏™Ê°∂ÔºåÊØè‰∏™ÈáåÈù¢ÊîæÁöÑÂ∞±ÊòØÊØîËøôÊ°∂ÁöÑindeÁ≠â‰∫éÁöÑpaperÁöÑÊï∞Èáè Â¶ÇÊûúÊÄªÊï∞Áõ¥Êé•Â§ß‰∫éÊúÄÂ§ßÁöÑÊ°∂Êï∞ÔºåÂ∞±ÊîæÂú®ÊúÄÂêé‰∏Ä‰∏™ÈáåÈù¢ ËøôÊòØÂú®Á¨¨‰∏Ä‰∏™Âæ™ÁéØÂπ≤ÁöÑ‰∫ãÊÉÖ Á¨¨‰∫å‰∏™Âæ™ÁéØÈáåÔºåÊääËøô‰∫õÊ°∂ÈáåÈù¢ÁöÑÂÄºÂèñÂá∫Êù•Â∞±ÊòØÊØîËøô‰∏™Ê°∂ÁöÑindexÂ§ß‰∫éÁ≠â‰∫éÁöÑpaperÁöÑÊï∞ÈáèÔºå‰ªéÂêéÂæÄÂâçÊï∞ÔºåÂ¶ÇÊûúËøô‰∏™paperÁöÑÊï∞ÈáèÂ§ß‰∫é‰∫ÜÁé∞Âú®ÁöÑindexÔºåÈÇ£Â∞±ËØ¥ÊòéÁé∞Âú®ÁöÑindexÂ∞±ÊòØhÔºÅ ËøôÈáåÂ≠¶Âà∞‰∫Ü‰∏Ä‰∏™ÂàõÂª∫Âõ∫ÂÆöÈïøÂ∫¶ÂàóË°®ÁöÑÊñπÊ≥ïbucket = [0 for n in range(len(citations)+1)] 12345678class Solution: def hIndex(self, citations: List[int]) -&gt; int: citations.sort(reverse = True) result = 0 for i,n in enumerate(citations): if n &gt;= i+1: result = max(result,i+1) return result ÂÜçÂè¶‰∏ÄÁßçÊÄùË∑ØÔºåÁî®‰∫ÜÊéíÂ∫è Â¶ÇÊûúÊääËøô‰∏™listÊåâÈôçÂ∫èÊéíÂ∫èÁöÑËØùÔºåindexÁöÑÊï∞ÈáèÂä†‰∏ÄÂ∞±ÊòØÁõÆÂâçÊï∞ËøáÁöÑpaperÁöÑÊï∞ÈáèÔºåcitation[index]Â∞±ÊòØËøô‰∏™Êï∞Èáè‰∏äÈù¢ÂØπÂ∫îÁöÑcitationÁöÑÊï∞ÈáèÔºåËøô‰∏§‰∏™ÂÄºÂ∫îËØ•Ê≠£Â•ΩÁõ∏Á≠âÔºåÊàñËÄÖcitationÊõ¥Â§ß‰∏ÄÁÇπÔºåÈúÄË¶ÅÂú®ÊéíÂ•ΩÂ∫èÁöÑÂÜÖÂÆπÈáåÈù¢ÊâæÂà∞Ëøô‰∏ÄÈ°πÔºÅ ËøôÊ†∑ÈÄüÂ∫¶ÊØîÊ°∂ÊéíÂ∫èÁ®çÂæÆÊÖ¢‰∏ÄÁÇπ‰ΩÜÊòØËøòÊòØËõÆÂø´ÁöÑÔºåËµ∑Á†ÅÊØîÁ¨¨‰∏ÄÁßçË¶ÅÂø´ÂæàÂ§ö‰∫Ü 275 h-index 21234567891011class Solution: def hIndex(self, citations: List[int]) -&gt; int: n = len(citations) l, r = 0, n-1 while l &lt;= r: mid = (l+r)//2 if citations[mid] &gt;= n-mid: r = mid - 1 else: l = mid + 1 return n-l ÂèØ‰ª•‰æùÁÑ∂Ê≤øÁî®‰∏äÈù¢ÁöÑÊñπÊ≥ïÔºå‰ΩÜÊòØÂèØËÉΩÊòØÂõ†‰∏∫Êï∞ÊçÆÈáè‰∏äÂéªÁöÑÂéüÂõ†ÔºåÊâÄ‰ª•ÈÄüÂ∫¶ÂèòÊÖ¢‰∫Ü ËøôÈáåÂèØ‰ª•Âä†ÂÖ•‰∫åÂàÜÊ≥ïÊêúÁ¥¢Âèñ‰ª£‰∏äÈù¢ÁöÑÁõ¥Êé•iterate whileÁöÑÊù°‰ª∂ÊòØÂõ†‰∏∫ÁßªÂä®‰∏Ä‰ΩçÔºåÊâÄ‰ª•‰ºöÂá∫Áé∞l&gt;rÁöÑÊÉÖÂÜµÔºåÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÂ∞±ÂèØ‰ª•ÂÅú‰∏ãÊù•‰∫Ü ‰∫åÂàÜÊ≥ïÂ∞±ÊòØËøô‰πàÂÜôÁöÑÔºÅ 217 contains duplicate123456class Solution: def containsDuplicate(self, nums: List[int]) -&gt; bool: for n in nums: if nums.count(n) &gt;= 2: return True return False 1234567class Solution: def containsDuplicate(self, nums: List[int]) -&gt; bool: setNums = set(nums) if len(setNums) == len(nums): return False else: return True Ê∂àËÄóÊó∂Èó¥Â§™Èïø‰∫ÜÔºÅÔºÅ ËØ¥ÊòéËøô‰∏™countÁöÑÊó∂Èó¥ËøòÊòØ‰∏çÂèØ‰ª• ÊÉ≥Âà∞‰∫ÜÁî®set‰ΩÜÊòØÊ≤°Áõ∏ÂΩìÊÄé‰πàÁî®set setÂèØ‰ª•ÊääÊúâÈáçÂ§çÂÜÖÂÆπÁöÑÂèòÊàêÊ≤°ÊúâÈáçÂ§çÂÜÖÂÆπÁöÑÔºÅÔºÅ ÊâÄ‰ª•setÂíålistÁöÑÈïøÂ∫¶ÊòØ‰∏ç‰∏ÄÊ†∑ÁöÑ 219 contains duplicate2Given an array of integers and an integer k, find out whether there are two distinct indices i and j in the array such that nums[i] = nums[j] and the absolute difference between i and j is at most k. Example 1: Input: nums = [1,2,3,1], k = 3Output: trueExample 2: Input: nums = [1,0,1,1], k = 1Output: trueExample 3: Input: nums = [1,2,3,1,2,3], k = 2Output: false 1234567891011class Solution: def containsNearbyDuplicate(self, nums: List[int], k: int) -&gt; bool: if len(set(nums)) &gt;= len(nums): return False extra = &#123;&#125; for i,n in enumerate(nums): if n in extra and i-extra[n] &lt;= k: return True extra[n] = i return False Ê≥®ÊÑèËøôÈáåÈúÄË¶ÅÊâæÂà∞ÁöÑÂ∑ÆÁöÑÁªùÂØπÂÄºÊòØÊúÄÂ§ßÊòØkÔºåÊâÄ‰ª•ÊâæÂà∞‰∏Ä‰∏™ÊØîkÂ∞èÁöÑÂæàÂÆπÊòìÔºÅÔºÅÂè™Ë¶ÅÊâæÂà∞Â∞±ËÉΩËøîÂõû Âà§Êñ≠ËæπÁïåÊù°‰ª∂ ÊääÂÖÉÁ¥†‰Ωú‰∏∫keyÊîæËøõextraÈáåÈù¢ÔºåvalÊòØËøô‰∏™ÂÖÉÁ¥†ÁöÑindexÔºåÂõ†‰∏∫keyÊòØÂîØ‰∏ÄÁöÑÊâÄ‰ª•ÂèØ‰ª•‰∏ÄÁõ¥ÊâæÂà∞Á¶ªÂæóÊúÄËøëÁöÑindexÔºåËøôÊ†∑Â∞±Ë∂äÊù•Ë∂äËÉΩÁ°Æ‰øùÊª°Ë∂≥Êù°‰ª∂Ôºå‰∏ÄÊó¶Êª°Ë∂≥Êù°‰ª∂Â∞±ËøîÂõûÔºåÂ¶ÇÊûúÊâÄÊúâÁöÑÈÉΩ‰∏çÊª°Ë∂≥Â∞±false 220Given an array of integers, find out whether there are two distinct indices i and j in the array such that the absolute difference between nums[i] and nums[j] is at most t and the absolute difference between i and j is at most k. Example 1: Input: nums = [1,2,3,1], k = 3, t = 0Output: trueExample 2: Input: nums = [1,0,1,1], k = 1, t = 2Output: trueExample 3: Input: nums = [1,5,9,1,5,9], k = 2, t = 3Output: false 1234567891011121314151617class Solution: def containsNearbyAlmostDuplicate(self, nums: List[int], k: int, t: int) -&gt; bool: if t &lt; 0: return False buckets = &#123;&#125; for i in range(len(nums)): bucket = nums[i] // (t+1) if bucket in buckets: return True elif bucket - 1 in buckets and nums[i] - buckets[bucket-1] &lt;= t: return True elif bucket + 1 in buckets and buckets[bucket+1] - nums[i] &lt;=t: return True buckets[bucket] = nums[i] if i &gt;= k: del bucket[nums[i-k] // (t+1)] return False ËøêÁî®ÁöÑÊòØÊ°∂ÊéíÂ∫èÁöÑÊÄùË∑ØÔºåÊØè‰∏™nums[i]‰ºöÊîæÂú®‰∏Ä‰∏™Ê°∂ÈáåÔºåËøô‰∏™Ê°∂ÁöÑÂÆΩÂ∫¶ÊòØËøô‰∏§‰∏™Êï∞Â≠óÁöÑÂ∑Æ Â¶ÇÊûúÊÉ≥Ë¶ÅËøô‰∏§‰∏™Êï∞ÂÄºÁöÑÂ∑ÆÂÄºÂ∞è‰∫éÁ≠â‰∫étÔºåÈÇ£‰πàÈúÄË¶ÅËøô‰∏§‰∏™Êï∞Â≠óÂú®‰∏Ä‰∏™Ê°∂ÈáåÊàñËÄÖÂú®Áõ∏ÈÇªÁöÑÊ°∂ÈáåÔºàÂõ†‰∏∫ÂêéÈù¢Â¢ûÂä†‰∫ÜkÁöÑÂà§Êñ≠Êù°‰ª∂ÔºåÊâÄ‰ª•‰∏çÁî®ËÄÉËôëkÔºâ ÊÄùË∑Ø È¶ñÂÖàËÄÉËôë‰∫Ü‰∏Ä‰∏ãkÔºåÂ¶ÇÊûúiÂ§ß‰∫ékÁöÑÊó∂ÂÄôÔºåÂ∞±ÂèØ‰ª•Áõ¥Êé•ÊâîÊéâi-k‰πãÂâçÁöÑÊï∞ÊçÆ‰∫ÜÔºåÂè™ËÄÉËôë‰∏≠Èó¥ÁöÑk+1‰∏™Êï∞ÊçÆÔºåËøôÊ†∑ÁöÑËØùÁ©∫Èó¥Â§çÊùÇÂ∫¶Âæà‰Ωé„ÄÇËøôÈáåÁöÑÊâîÊéâÊåáÁöÑÊòØÊääbucketÈáåÈù¢ÁöÑÂÄºÁõ¥Êé•ÊâîÊéâÔºåËøôÊ†∑Â∞±ÈÅøÂÖç‰∫ÜÊâæÂà∞Âú®Áõ∏ÂêåÁöÑÊ°∂ÈáåÈù¢Âç¥iÂíåjÁöÑÂ∑ÆÂÄºË∂ÖËøákÁöÑÈóÆÈ¢ò È¶ñÂÖàiterateÊï¥‰∏™numsÔºåÊää‰∏çÂêåÁöÑÊï∞Â≠óÊîæÂú®‰∏çÂêåÁöÑÊ°∂ÈáåÔºåÊ≥®ÊÑèÊ°∂ÁöÑ‰∏™Êï∞ÊòØt+1 ÁÑ∂ÂêéÂ¶ÇÊûúÂú®Êîæ‰πãÂâçËøô‰∏™Ê°∂Êúâ‰∏úË•øÔºåÊàñËÄÖÁõ∏ÈÇªÁöÑÊ°∂ÁöÑÂÄºÂíåÁé∞Âú®ÁöÑÂÄºÁöÑÂ∑ÆÊòØÂ∞è‰∫éÁ≠â‰∫étÁöÑÔºåÈÇ£‰πàÂ∞±Â≠òÂú®ÔºåËøîÂõûtrue Â¶ÇÊûúÈÉΩ‰∏çÂ≠òÂú®ÁöÑËØùÔºåÊääÁé∞Âú®ÁöÑÊï∞Â≠óÊîæÂà∞ÂØπÂ∫îÁöÑÊ°∂ÈáåÈù¢ Âè¶Â§ñ‰∏Ä‰∏™ÊÄùË∑ØËÄÉËôëÁöÑÊòØ‰∫åÂèâÊ†ëÁöÑÊï∞ÊçÆÁªìÊûÑÔºåÁî®Ëøô‰∏™ÁªìÊûÑÂèØ‰ª•ÂæàÂø´ÁöÑÊêúÁ¥¢Âà∞Á¶ªËøô‰∏™Êï∞ÊúÄËøëÁöÑÊï∞ÊçÆÂπ∂‰∏îÂà§Êñ≠Ëøô‰∏™Êï∞ÊçÆÂíåËøô‰∏™Êï∞ÁöÑÂ∑ÆÊòØ‰∏çÊòØÂ∞è‰∫étÔºÅ 55 Jump game123456789101112131415class Solution: def canJump(self, nums: List[int]) -&gt; bool: if nums is []: return False if len(nums) == 1: return True current = len(nums) - 1 while current &gt;= 0: flag = False for i in range(0,current): if current - i &lt;= nums[i] and current &gt;= i: flag = True current = i if current == 0: return True if flag == False: return False ËôΩÁÑ∂Ë∂ÖÊó∂‰∫Ü‰ΩÜÊòØÂÜôÁöÑËøò‰∏çÈîôÁöÑiterate =„ÄÇ=ÁÆó‰∫ÜËøôÂ∞±ÊòØ‰∏ÄÂù®Â±éÔºÅÔºÅÔºÅ 123456789class Solution: def canJump(self, nums: List[int]) -&gt; bool: current = len(nums) - 1 for i in range(len(nums))[::-1]: if current - i &lt;= nums[i]: current = i if current == 0: return True return False ÊàëÁöÑÊñπÊ≥ïÂÖ∂ÂÆûÊÄùË∑ØÊòØÊ≤°ÊúâÈóÆÈ¢òÁöÑÔºå‰∏ªË¶ÅÂú®‰∫éÂ§™Âï∞Âó¶‰∫ÜËÄå‰∏îÂæ™ÁéØÂ§™Â§ö‰∫ÜÔºåÂÖ∂ÂÆûÁõ¥Êé•‰ªéÂêéÂæÄÂâçÊâæÂ∞±Ë°å‰∫ÜÔºÅÔºÅÔºÅ‰ªéÂêéÂæÄÂâçÊâæ‰∏çÁî®ËÄÉËôëÊÄé‰πàËÆ©‰ªñÂæ™ÁéØËµ∑Êù•ÂëÄÔºåÁõ¥Êé•‰∏Ä‰∏™‰∏Ä‰∏™ÂæÄÂâçÊé®Â∞±ÂèØ‰ª•‰∫Ü ÂâçÈù¢ÈÇ£‰∏™ÁöÑÈóÆÈ¢òÂú®‰∫éÂ§öÂè†‰∫Ü‰∏Ä‰∏™whileÔºå‰∫éÊòØÊó∂Èó¥Áû¨Èó¥ÁàÜÁÇ∏ÔºåÂÜôÂâçÈù¢ÁöÑÈÇ£‰∏™ÁöÑÊó∂ÂÄô‰πüÂú®ÊÉ≥ÁùÄÂ¶Ç‰ΩïÊâæÂõûÂæ™ÁéØÈáåÈù¢ÂéªÔºåÁªìÊûúËøòÊòØÁî®‰∫Ü‰∏™Ë†¢ÂäûÊ≥ï 1234567class Solution: def canJump(self, nums: List[int]) -&gt; bool: j = 0 for i,n in enumerate(nums): if j &lt; i: return False j = max(i+n,j) return True i+nÂ∞±ÊòØ‰ªéËøôÊ≠•ÂºÄÂßãÂèØ‰ª•ÁßªÂä®ÁöÑÊúÄÂ§ßË∑ùÁ¶ªÔºåjÊòØ‰∏ä‰∏ÄÊ≠•ÂèØ‰ª•ÁßªÂä®ÁöÑÊúÄÂ§ßË∑ùÁ¶ªÔºåËøô‰∏§‰∏™Âì™‰∏™Â§ßÂ∞±Ëµ∞Âì™‰∏™ Â¶ÇÊûúËøô‰∏™Ë∑ùÁ¶ªËøòËµ∂‰∏ç‰∏äiÔºåÈÇ£Â∞±ËØ¥ÊòéËµ∞‰∏çÂà∞ÊúÄÂêé‰∫ÜÔºåÂëäËæû 45 Jump game 2123456789101112class Solution: def jump(self, nums: List[int]) -&gt; int: if len(nums) &lt;= 1: return 0 start, end = 0, 0 step,maxend = 0,0 while True: step += 1 for i in range(start, end+1): if i+nums[i] &gt;= len(nums) -1: return step maxend = max(maxend, i + nums[i]) start = end + 1 end = maxend ÂÆûÈôÖ‰∏äÊù•ËØ¥Áî®ÁöÑÊòØBFSÁöÑÊÄùÊÉ≥Ôºå‰ΩÜÊòØ‰∏çÊòØÊØèÊ¨°ÈÉΩÊää‰∏úË•ø‰ªéqueueÈáåÈù¢ÊãøÂá∫Êù•ÔºåËÄåÊòØÁ°ÆÂÆö‰∫ÜÊØèÊ¨°ÂØªÊâæÁöÑÂºÄÂßãÁöÑÈòÄÂÜÖ startÂíåendÂàÜÂà´‰ª£Ë°®Áé∞Âú®ÂèØ‰ª•ÂºÄÂßãÂØªÊâæÁöÑÂºÄÂßãÂíåÁªìÊùüÔºåÂ¶ÇÊûúÂú®Ëøô‰∏™ËåÉÂõ¥ÈáåÈù¢ÊâæÂà∞‰∫ÜÁ¨¶ÂêàË¶ÅÊ±ÇÁöÑÁªìÊûúÔºåÈÇ£‰πàÁõ¥Êé•ËøîÂõûËøô‰∏™Ê≠•Êï∞ÔºåÂ¶ÇÊûúÊ≤°ÊâæÂà∞ÁöÑËØùÂ∞±‰ªé‰∏ã‰∏Ä‰∏™ËåÉÂõ¥ÂºÄÂßãÊâæÔºå‰∏ã‰∏Ä‰∏™ËåÉÂõ¥ÊòØ‰∏ä‰∏Ä‰∏™ËåÉÂõ¥ÁöÑend+1 Âà∞ÁõÆÂâçËÉΩÂà∞ÁöÑÊúÄÂ§ßÁöÑËåÉÂõ¥ Ê≥®ÊÑèÁ¨¶ÂêàÁöÑË¶ÅÊ±ÇÊòØÂ§ß‰∫éÁ≠â‰∫én-1ËÄå‰∏çÊòØÊ≠£Â•ΩËµ∞Âà∞Ëøô‰∏™ÁÇπ Ê±ÇmaxendÂíå‰πãÂâçÁöÑ‰∏ÄÊ†∑ 121 Best Time to Buy and Sell StockSay you have an array for which the ith element is the price of a given stock on day i. If you were only permitted to complete at most one transaction (i.e., buy one and sell one share of the stock), design an algorithm to find the maximum profit. Note that you cannot sell a stock before you buy one. Example 1: Input: [7,1,5,3,6,4]Output: 5Explanation: Buy on day 2 (price = 1) and sell on day 5 (price = 6), profit = 6-1 = 5. Not 7-1 = 6, as selling price needs to be larger than buying price.Example 2: Input: [7,6,4,3,1]Output: 0Explanation: In this case, no transaction is done, i.e. max profit = 0. 12345678910class Solution: def maxProfit(self, prices: List[int]) -&gt; int: minBuy = float('inf') maxProfit = 0 for i in prices: if i &lt; minBuy: minBuy = i elif i - minBuy &gt; maxProfit: maxProfit = i - minBuy return maxProfit Áî®bruteÁöÑÁÆóÊ≥ï‰ºötime limitÔºåËøôÈáåÁî®ÁöÑÊñπÊ≥ïÊòØÁî®‰∏§‰∏™ÂèòÈáèÂàÜÂà´ËÆ∞ÂΩïÊúÄ‰ΩéÁöÑ‰ª∑Èí±ÂíåÊúÄÈ´òÁöÑÂà©Ê∂¶ÔºåËøôÊ†∑ÁöÑËØùÂè™ÈúÄË¶ÅÂØπÊï∞ÁªÑÈÅçÂéÜ‰∏ÄÊ¨°Â∞±ËÉΩÂæóÂà∞ÊúÄÁªàÁöÑÁªìÊûú Âõ†‰∏∫Âà§Êñ≠Ëøô‰∏™‰ª∑Èí±‰Ωé‰∫ÜÁöÑËØùÔºåÊ±ÇËøô‰∏™‰∏úË•øÁöÑÊúÄÂ§ßÂà©Ê∂¶‰πüÂ∞±Âè™ËÉΩÁî®Ëøô‰∏™ÊúÄ‰Ωé‰ª∑Èí±‰πãÂêéÁöÑ‰∏úË•øÊ±Ç‰∫ÜÔºåÊâÄ‰ª•‰∏ç‰ºöÂÜ≤Á™Å 122 Áé∞Âú®ÂèØ‰ª•ËøõË°åÂ§öÊ¨°‰∫§Êòì‰∫ÜÔºå‰ΩÜÊòØÊØèÊ¨°‰πãÈó¥‰∏çËÉΩÈáçÂè† ÂÖ∂ÂÆûÂè™Ë¶ÅÂêé‰∏ÄÊ¨°ÊØîÂâç‰∏ÄÊ¨°Ë¥µÔºåËøô‰∏™profitÂ∞±ÂèØ‰ª•‰∏ÄÁõ¥Á¥ØËÆ°ÔºåÂàÜ‰∏∫‰∏ÄÁõ¥‰∏äÊ∂®ÊàñËÄÖ‰∏≠Èó¥Êéâ‰∏ãÊù•‰∏Ä‰∏ãÂÜçÈáçÊñ∞‰π∞ÁöÑÊÑüËßâ 1234567class Solution: def maxProfit(self, prices: List[int]) -&gt; int: maxProfit = 0 for i in range(1,len(prices)): if prices[i] &gt; prices[i-1]: maxProfit += prices[i] - prices[i-1] return maxProfit 123 Áé∞Âú®ÊúÄÂ§öËøõË°å‰∏§Ê¨°‰∫§Êòì,ÊâæÂà∞ÊúÄÂ§ßÁöÑÂà©Ê∂¶ 1234567891011121314class Solution: def maxProfit(self, prices: List[int]) -&gt; int: cost_1 = float('inf') profit_1 = 0 cost_2 = float('inf') profit_2 = 0 for price in prices: cost_1 = min(cost_1,price) profit_1 = max(profit_1, price - cost_1) cost_2 = min(cost_2,price - profit_1) profit_2 = max(profit_2, price - cost_2) return profit_2 ÂÖ∂‰∏≠Ôºå‰∏ãÊ†áÂ∏¶1ÁöÑÊòØÁ¨¨‰∏ÄÊ¨°‰∫§Êòì‰πãÂêéÁöÑÁªìÊûúÔºå‰∏ãÊ†áÂ∏¶2ÁöÑÊòØÁ¨¨‰∫åÊ¨°‰∫§Êòì‰πãÂêéÁöÑÁªìÊûú ‰ªéÊÄª‰Ωì‰∏äÊù•ÁúãÔºåÁ¨¨‰∫åÊ¨°‰π∞ÂÖ•‰πãÂêéËä±ÊéâÁöÑÈí±ÂÆûÈôÖ‰∏äÊòØÁ¨¨‰∫åÊ¨°‰π∞ÂÖ•ÁöÑÂÆûÈôÖËä±Ë¥π - Á¨¨‰∏ÄÊ¨°‰∫§Êòì‰πãÂêéÊå£ÁöÑÈí±ÔºàÂèØ‰ª•ÊòØË¥üÊï∞Ôºâ„ÄÇËÄåÁ¨¨‰∫åÊ¨°ÂçñÂá∫‰πãÂêéÁöÑÊÄªÁöÑÊî∂Áõä‰∏∫ Á¨¨‰∫åÊ¨°ÂçñÂá∫ÁöÑÈí± - Á¨¨‰∫åÊ¨°‰π∞ÂÖ•‰πãÂêéÁöÑÂÆûÈôÖËä±Ë¥π ÊâÄ‰ª•ÔºåÂ¶ÇÊûúÈúÄË¶ÅÂà©Ê∂¶ÊúÄÂ§ßÔºåÈúÄË¶ÅÁ¨¨‰∫åÊ¨°‰π∞ÂÖ•ÁöÑÂÆûÈôÖËä±Ë¥πÊúÄÂ∞èÔºåÈúÄË¶ÅÁ¨¨‰∏ÄÊ¨°ÁöÑÂà©Ê∂¶ÊúÄÂ§ßÔºåÈúÄË¶ÅÁ¨¨‰∏ÄÊ¨°‰π∞ÂÖ•ÁöÑËä±Ë¥πÊúÄÂ∞èÔºåÊúÄÁªàÂΩ¢Êàê‰∫ÜËøô‰∏™‰ª£Á†Å 188 Áé∞Âú®ÈúÄË¶ÅËøõË°åÊúÄÂ§ökÊ¨°‰∫§ÊòìÔºåÊääprofitÂºÑÂà∞ÊúÄÂ§ß ËøôÈÉ®ÂàÜÂ•ΩÂÉèÂ§ßÂÆ∂ÈÉΩÁî®Âà∞‰∫ÜDP 1234567891011121314class Solution: def maxProfit(self, k: int, prices: List[int]) -&gt; int: n = len(prices) if n &lt; 2: return 0 if k &gt;= n/2: return sum(i-j for i, j in zip(prices[1:],prices[: -1]) if i &gt; j) profits = [0] * n for _ in range(k): preprofit = 0 for i in range(1,n): profit = prices[i] - prices[i-1] preprofit = max(preprofit + profit, profits[i]) profits[i] = max(preprofit, profits[i-1]) return profits[-1] È¶ñÂÖàËÄÉËôëËæπÁïåÊù°‰ª∂ÔºåÂ¶ÇÊûúkÁöÑÊï∞ÈáèÂ∑≤ÁªèÊØîn/2Â§ß‰∫ÜÔºåÈÇ£‰πàÂèØ‰ª•Áõ¥Êé•ËÆ§‰∏∫ÂèØ‰ª•ËøõË°åÊó†ÈôêÊ¨°‰∫§Êòì‰∫ÜÔºåÂ∞±Âíå‰∏äÈù¢ÁöÑÁ¨¨‰∫åÈ¢ò‰∏ÄÊ†∑ ‰∏ªË¶ÅÊÄùË∑ØÂ∞±ÊòØÁé∞Âú®ÂÆö‰πâ‰∫Ü‰∏§‰∏™ÂèòÈáèÔºå‰∏Ä‰∏™ÂèòÈáèË°®Á§∫Âú®ÂâçiÂ§©ÂÆåÊàêÁöÑ‰∫§ÊòìÔºåÂ∑≤ÁªèÂæóÂà∞ÁöÑÊúÄÂ§ßÂà©Ê∂¶„ÄÇÂè¶‰∏Ä‰∏™ÂèòÈáèÂÆö‰πâ‰∫ÜÂú®Á¨¨iÂ§©ÂçñÂá∫ÁöÑËØùÔºåËøôÊó∂ÂÄôÂæóÂà∞ÁöÑÊúÄÂ§ßÂà©Ê∂¶„ÄÇËøô‰∏§‰∏™ÂèòÈáèÁöÑÈÉΩÊòØÂú®Âú®Á¨¨jÊ¨°‰∫§ÊòìÈáå„ÄÇ Áî®‰∏Ä‰∏™ÈïønÁöÑlist profitsÊù•ËÆ∞ÂΩïËøô‰∏™Â§©Êï∞‰πãÂêéËé∑ÂæóÁöÑÂà©Áõä„ÄÇÂú®kÊ¨°‰∫§Êòì‰∏≠‰∏ÄÁõ¥Êõ¥Êñ∞Ëøô‰∏™profitsÈáåÈù¢ÁöÑÊúÄÂ§ßÂÄº„ÄÇÊâÄ‰ª•ÂÆûÈôÖ‰∏äÂÖ≥‰∫ékÁöÑÂèòÈáè‰∏çÈúÄË¶ÅËÄÉËôë È¶ñÂÖàÂàÜÊûêÂú®Á¨¨iÂ§©ÂæóÂà∞ÁöÑÂà©Ê∂¶ÔºåÂ∞±ÊòØËøô‰∏ÄÂ§©ÁöÑ‰ª∑Ê†ºÂáèÂéªÂâç‰∏ÄÂ§©ÁöÑ‰ª∑Ê†º„ÄÇÊõ¥Êñ∞‰πãÂâçiÂ§©ÈáåÈù¢ÁöÑÊÄªÂà©Ê∂¶ÔºåÂ∞±ÊòØÊääÊúÄÂºÄÂßãÁöÑpreprfitÂÜçÂä†‰∏äËøô‰∏ÄÂ§©Ëé∑ÂæóÁöÑÂà©Ê∂¶ÔºåÂíåÊú¨Êù•ÁöÑpreprofitÊù•ÊØîÂ§ßÂ∞èÔºåÊõ¥Êñ∞preprofit Êõ¥Êñ∞ÂÆûÈôÖ‰∏äÁ¨¨iÂ§©ÁöÑÂà©Ê∂¶ÔºåÂØπÊØîÂÆûÈôÖ‰∏äÂâç‰∏ÄÂ§©ÁöÑÂà©Ê∂¶ÂíåÂâçiÂ§©ÁöÑÂà©Ê∂¶Âì™‰∏™Â§ß 309 ‰∏≠Èó¥Â∏¶ÂÜ∑Âç¥ÁöÑ‰π∞ËÇ°Á•® ÊØèÊ¨°ÂçñÂá∫Âéª‰πãÂêéÂøÖÈ°ªË¶Åcooldown‰∏ÄËΩÆ Áî®‰∫ÜdpÂíåstate machineÊù•Ë°®Á§∫Ôºå‰∏ÄÂÖ±‰ºöÊúâ‰∏âÁßçÁä∂ÊÄÅ s0(reset) -sell-&gt; s1 -cool-&gt; s2(reset) -buy-&gt; s0 Áî®‰∏Ä‰∏™Êï∞ÁªÑÊù•ËÆ∞ÂΩïÂú®ÊØèÂ§©Âú®Ëøô‰∏™Áä∂ÊÄÅÈáåÈù¢ÁöÑÊúÄÂ§ßÂà©Ê∂¶ÔºåÁÑ∂ÂêéÂÜç‰ªéÊúÄÂêé‰∏ÄÂ§©ÁöÑÊúÄÂ§ßÂà©Ê∂¶ÈáåÈù¢ÊåëÂá∫Êù•‰∏Ä‰∏™ Ê≥®ÊÑèËÄÉËôëËæπÁïåÊù°‰ª∂ Â≠¶‰ºö‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÂàùÂßãÂåñlistÁöÑÊñπÊ≥ï ÊÑüËßâËá™Â∑±Áªà‰∫éÁêÜËß£‰∫ÜdpÂë¢ÔºàÂπ∂Ê≤°ÊúâÔºâ12345678910111213141516class Solution: def maxProfit(self, prices: List[int]) -&gt; int: n = len(prices) if n &lt; 2: return 0 s0,s1,s2 = [0]*n,[0]*n,[0]*n s0[0] = -prices[0] s1[0] = float('-inf') s2[0] = 0 for i in range(1,n): price = prices[i] s0[i] = max(s0[i-1],s2[i-1] - price) s1[i] = s0[i-1] + price s2[i] = max(s1[i-1],s2[i-1]) return max(s0[n-1],s1[n-1],s2[n-1]) 11 Ë£ÖÊ∞¥Given n non-negative integers a1, a2, ‚Ä¶, an , where each represents a point at coordinate (i, ai). n vertical lines are drawn such that the two endpoints of line i is at (i, ai) and (i, 0). Find two lines, which together with x-axis forms a container, such that the container contains the most water. Note: You may not slant the container and n is at least 2. 12345678910111213class Solution: def maxArea(self, height: List[int]) -&gt; int: n = len(height) start, end = 0, n-1 maxArea = 0 while start &lt; end: if height[start] &gt;= height[end]: maxArea = max(maxArea,height[end] * (end-start)) end -= 1 else: maxArea = max(maxArea,height[start] * (end-start)) start += 1 return maxArea ËøôÈÅìÈ¢òÁöÑÈáçÁÇπÂú®Ëøô‰∏™Ë£ÖÊ∞¥ÁöÑÂ§ßÂ∞èÊòØÁî±ÊØîËæÉÁü≠ÁöÑÈÇ£Êù°ËæπÂÜ≥ÂÆöÁöÑ„ÄÇËÄå‰∏îËÇØÂÆöÊòØÂ∫ïËæπË∂äÈïøË∂äÁâõÈÄºÔºåÊâÄ‰ª•‰ªéÂ∫ïËæπÊúÄÈïøÁöÑ‰∏§ËæπÂºÄÂßãÊâæÔºåÁÑ∂ÂêéÂú®‰∏§‰∏™È´òÂ∫¶ÈáåÈù¢ÂèñÊØîËæÉÂ§ßÁöÑÁªßÁª≠Êâæ‰∏ã‰∏Ä‰∏™ ÈúÄË¶ÅÁî®‰∏Ä‰∏™ÂèòÈáèÊù•ÂÇ®Â≠ò max areaÁöÑÂ§ßÂ∞èÔºàËøô‰∏™ÊàëÊÉ≥Âà∞‰∫ÜÔºâ ÁÑ∂ÂêéÊØîËæÉÂø´ÁöÑÊñπÊ≥ïÊòØ‰ªé‰∏§ÈÅçÂºÄÂßãÈÄºËøëÔºåËøôÊ†∑ÁöÑËØùÂè™ÈÅçÂéÜ‰∫ÜËøô‰∏™list‰∏ÄÊ¨°ÔºåÊó∂Èó¥Â§çÊùÇÂ∫¶ÊòØnÔºåÂ•ΩÂÉèÊúâ‰∏™ÊéíÂ∫èÁÆóÊ≥ïÂíåËøô‰∏™ÁöÑÊÉ≥Ê≥ï‰πüÂ∑Æ‰∏çÂ§ö Ê≥®ÊÑèwhileÁöÑÂà§Êñ≠Êù°‰ª∂ÂÖ∂ÂÆûÂ∞±ÊòØËøô‰∏™ 42 Ë£ÖÊ∞¥Given n non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it is able to trap after raining. 12345678910111213141516class Solution: def trap(self, height: List[int]) -&gt; int: n = len(height) if n &lt; 2: return 0 left_max,right_max = [0]*n,[0]*n left_max[0],right_max[-1] = height[0],height[-1] maxTrap = 0 for i in range(1,n): left_max[i] = max(left_max[i-1],height[i]) for i in reversed(range(0,n-1)): right_max[i] = max(right_max[i+1],height[i]) for i in range(n): maxTrap += min(left_max[i],right_max[i]) - height[i] return maxTrap Áî®dpËß£ÂÜ≥ÁöÑËøô‰∏™ÈóÆÈ¢ò Ê†∏ÂøÉÊÄùÊÉ≥Âú®Á´ñÁùÄÔºàÊåâÂàóÔºâÊï∞ÊØè‰∏™Ê†ºÂ≠êÔºåËøô‰∏™Ê†ºÂ≠êÂèØ‰∏çÂèØ‰ª•Ë£ÖÊ∞¥ÂíåÂ∑¶Âè≥‰∏§ËæπÁöÑÊúÄÈ´òÁÇπÊúâÂÖ≥ÔºåËøô‰∏™Ê†ºÂ≠êËÉΩË£ÖÂ§öÂ∞ëÊ∞¥Âíå1.ÊúÄÁü≠ÁöÑÈ´òÁÇπÂíå2.Ëøô‰∏™Ê†ºÂ≠êÊú¨Ë∫´ÁöÑÈ´òÂ∫¶ÊúâÂÖ≥ ÊâÄ‰ª•ÂèØ‰ª•Áî®‰∏â‰∏™Âæ™ÁéØÊêûÂÆöËøô‰∏™ÈóÆÈ¢òÔºåÁî®Á©∫Èó¥Êç¢Êó∂Èó¥ÔºåÂú®listÈáåÈù¢ËÆ∞ÂΩï‰∏ãÊù•ÊØè‰∏™ÂàóÂØπÂ∫îÁöÑÂ∑¶ËæπÁöÑÊúÄÈ´òÁÇπÂíåÂè≥ËæπÁöÑÊúÄÈ´òÁÇπÔºåÁÑ∂ÂêéÂÜçÊï∞ÊØè‰∏™ÂàóÁöÑÂÆπÈáèÔºåÂ§ßÂ∞èÊòØÔºàÂ∑¶Âè≥ÊúÄÈ´ò‰∏≠Èó¥Áü≠ÁöÑÈÇ£‰∏™Ôºâ - ÔºàËøô‰∏™ÂàóÂØπÂ∫îÁöÑÈ´òÂ∫¶Ôºâ 334 ÂçáÂ∫èÁöÑ‰∏â‰∏™Êï∞Â≠óGiven an unsorted array return whether an increasing subsequence of length 3 exists or not in the array. Formally the function should: Return true if there exists i, j, ksuch that arr[i] &lt; arr[j] &lt; arr[k] given 0 ‚â§ i &lt; j &lt; k ‚â§ n-1 else return false.Note: Your algorithm should run in O(n) time complexity and O(1) space complexity. 123456789101112131415class Solution: def increasingTriplet(self, nums: List[int]) -&gt; bool: if len(nums) &lt; 3: return False first = float('inf') second = float('inf') third = None for i,num in enumerate(nums): if num &lt;= first: first = num elif num &gt; first and num &lt;= second: second = num else: third = num return (third != None) ÊàëÊúÄÂàùÁöÑÊÄùË∑ØÊ≤°ÊúâÈîôÔºåÈúÄË¶ÅÊúâÂèòÈáèÊù•‰øùÂ≠òËøô‰∏â‰∏™ÂçáÂ∫èÁöÑ‰∏úË•ø ÂÖ∂ÂÆûÊ†∏ÂøÉÁöÑÊÄùË∑ØÂú®‰∫éÔºåÂ¶ÇÊûúÁé∞Âú®Ëøô‰∏™Êï∞ÊØîÁ¨¨‰∏Ä‰∏™ÂçáÂ∫èÁöÑÊï∞Â≠óÂ∞èÔºåÈÇ£‰πàËøô‰∏™Êï∞Â≠óÂÆåÂÖ®Â∞±ÂèØ‰ª•Êàê‰∏∫Êñ∞ÁöÑÁ¨¨‰∏Ä‰∏™Êï∞Â≠óÔºåÊØîÂ¶Ç 3 2 4 5ÔºåÈÇ£‰πà345Âíå245Ê≤°Êúâ‰ªÄ‰πàÊú¨Ë¥®ÁöÑÂå∫Âà´ÔºåËÄå‰∏ÄÊó¶thirdÊúâ‰∫ÜÂèñÂÄºÔºåÈÇ£‰πàÂ∞±ËØ¥ÊòéËÇØÂÆöÂ∑≤ÁªèÊúâ‰∫Ü‰∏Ä‰∏™ÁªìÊûú 128Given an unsorted array of integers, find the length of the longest consecutive elements sequence. Your algorithm should run in O(n) complexity. Example: Input: [100, 4, 200, 1, 3, 2]Output: 4Explanation: The longest consecutive elements sequence is [1, 2, 3, 4]. Therefore its length is 4. 123456789101112131415161718192021222324252627282930313233343536class Solution: def longestConsecutive(self, nums: List[int]) -&gt; int:# if nums == []: return 0# max_num = max(nums)# min_num = min(nums)# if max_num &gt; len(nums) or -max# if min_num &lt; 0:# max_num -= min_num# ass_list = [None] * (max_num + 1)# for i,num in enumerate(nums):# # Á°Æ‰øùÈÉΩÊòØÊ≠£Êï∞# if min_num &lt; 0:# num = num-min_num# ass_list[num] = 1 # max_length = 0# prev_length = 0# for i in range(len(ass_list)):# if ass_list[i] != None:# max_length += 1# else:# prev_length = max(max_length,prev_length)# max_length = 0# return max(max_length,prev_length) if nums == []: return 0 current_length,prev_length = 1,1 num_set = set(nums) for num in num_set: if num - 1 not in num_set: current_num = num while current_num+1 in num_set: current_num += 1 current_length += 1 prev_length = max(prev_length,current_length) current_length = 1 return max(current_length, prev_length) Ëøô‰∏™ÈóÆÈ¢ò‰∏ÄÂºÄÂßãÁöÑÊÄùË∑ØÊòØÈîôÁöÑÔºåÂ∑≤ÁªècommentÊéâ‰∫ÜÔºå‰ΩÜÊòØÊÑüËßâËøô‰∏™ÊÉ≥Ê≥ïÂÖ∂ÂÆûÂ∞±ÊòØÊõ¥ÂÖ∑‰ΩìÂåñÁöÑhashË°®ËÄåÂ∑≤ÔºåÁ¨¨‰∏Ä‰∏™ÊÄùË∑ØÊòØÊääÊâÄÊúâÁöÑÊï∞Â≠óÂπ≥ÂùáÁöÑÊîæÂú®‰∏Ä‰∏™listÈáåÈù¢ÔºåÁÑ∂ÂêéÊØè‰∏™Êï∞Â≠óÁöÑÊú¨Ë∫´Â∞±ÂØπÂ∫îÁöÑÊòØ‰ªñÁöÑindexÔºåËøôÊ†∑ÁöÑËØùÂ∞±ÂèØ‰ª•Áõ¥Êé•Áü•ÈÅìÊúâÂì™‰∫õÊï∞Â≠óÊòØËøûÁª≠ÁöÑ‰∫Ü„ÄÇ‰ΩÜÊòØËøôÁßçÊñπÊ≥ïÂú®Êï∞Â≠óÁâπÂà´Â§ßÁöÑÊó∂ÂÄôÁ©∫Èó¥‰∏äÂ∞±ÁàÜÁÇ∏‰∫ÜÔºåÁ©∫Èó¥Â§çÊùÇÂ∫¶‰πüÊòØÂíåÊï∞Â≠óÂ§ßÂ∞èÊúâÂÖ≥ ËøôÊó∂ÂÄôÂèàË¶ÅÊãøÂá∫Êù•Âø´‰πêÁöÑhashË°®‰∫ÜÔºåËÆ∞‰ΩèpythonËá™Â∑±Ëá™Â∏¶hashË°® ÊØèÈÅáÂà∞‰∏Ä‰∏™Êï∞Â≠óÔºåÈúÄË¶ÅÂà§Êñ≠Ëøô‰∏™Êï∞Â≠óÁöÑ‰∏ã‰∏Ä‰∏™Êï∞Â≠óÂú®‰∏çÂú®Ëøô‰∏™numsÈáåÈù¢ÔºåÂ¶ÇÊûúÂú®ÁöÑËØùÊõ¥Êñ∞Êï∞Â≠óÂíåÈïøÂ∫¶ÔºåÂ¶ÇÊûú‰∏çÂÜçÁöÑËØùÂà∑Êñ∞ËÆ°Êï∞Âô®Âπ∂‰∏îÂºÄÂßã‰∏ã‰∏Ä‰∏™Êï∞Â≠ó ‰ΩÜÊòØÁõ¥Êé•ËøôÊ†∑ÁÆóËøòÊòØ‰ºöÊó∂Èó¥ÁàÜÁÇ∏ÔºàÊØîÂ¶Ç‰∏ÄÂ†ÜËøûÁª≠ÁöÑÂè™Êúâ‰∏Ä‰∏™ÊòØË∑≥ÂºÄÁöÑÔºâÔºåÊâÄ‰ª•ÂèàÂä†ËøõÂéª‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÂà§Êñ≠Êù°‰ª∂ÔºåËøô‰∏™Êù°‰ª∂ÁöÑÁ≤æÈ´ìÂú®‰∫éÔºåÂ¶ÇÊûúËøô‰∏™Êï∞‰πãÂâçÁöÑÊï∞Â≠óÂú®numsÈáåÈù¢ÔºåÈÇ£‰πàËøô‰∏™Êï∞Âú®ÁÆó‰ªñÂâçÈù¢ÈÇ£‰∏™Êï∞ÁöÑÊó∂ÂÄôÂ∞±Â∫îËØ•Ë¢´ÁÆó‰∏ä‰∫ÜÔºåÊâÄ‰ª•ËøôÈÉ®ÂàÜÂ∞±ÂèØ‰ª•Ë∑≥ËøáËøô‰∏™Êï∞‰∫ÜÔºåÂè™ÊúâÂΩìÂâç‰∏Ä‰∏™Êï∞Â≠ó‰∏çÂú®ÁöÑÊó∂ÂÄôÊâçÈúÄË¶ÅÊï∞ÈïøÂ∫¶ 164Given an unsorted array, find the maximum difference between the successive elements in its sorted form. Return 0 if the array contains less than 2 elements. Example 1: Input: [3,6,9,1]Output: 3Explanation: The sorted form of the array is [1,3,6,9], either (3,6) or (6,9) has the maximum difference 3.Example 2: Input: [10]Output: 0Explanation: The array contains less than 2 elements, therefore return 0.Note: You may assume all elements in the array are non-negative integers and fit in the 32-bit signed integer range.Try to solve it in linear time/space. 123456789101112class Solution: def maximumGap(self, nums: List[int]) -&gt; int: nums.sort() max_gap = 0 if len(nums) &lt; 2: return 0 for i in range(1,len(nums)): gap = nums[i] - nums[i-1] max_gap = max(max_gap, gap) return max_gap Áõ¥Êé•Áî®pythonËá™Â∏¶ÁöÑÊéíÂ∫èÈÄüÂ∫¶‰∏ç‰∏ÄÂÆöÂæàÊÖ¢ÔºåËôΩÁÑ∂Âè™Ë∂ÖËøá‰∫ÜÁôæÂàÜ‰∫Ü20ÁöÑ‰∫∫‰ΩÜÊòØÊúÄÂêéËøòÊòØË∑ëÂá∫Êù•‰∫Ü Ëøô‰∏™ÊñπÊ≥ïÈùûÂ∏∏Áõ¥Êé•‰∫Ü 12345678910111213141516171819202122232425262728class Solution: def maximumGap(self, nums: List[int]) -&gt; int: n = len(nums) if n &lt; 2: return 0 max_num, min_num = max(nums), min(nums) if max_num == min_num: return 0 wide = max((max_num - min_num) // (n-1),1) num_b = (max_num - min_num) // wide + 1 maxGap = 0 # prev_bucket = float('-inf') max_b = [0]* num_b min_b = [float('inf')]* num_b for i, num in enumerate(nums): idx = (num-min_num) // wide max_b[idx] = max(max_b[idx],num) min_b[idx] = min(min_b[idx],num) prev_max = max_b[0] for i in range(1,num_b): if max_b[i] == 0: continue maxGap = max(maxGap,min_b[i] - prev_max) prev_max = max_b[i] return maxGap Ëøô‰∏™Ê°∂ÊéíÂ∫èÁªà‰∫éÂÜôÂá∫Êù•‰∫ÜÔºåÂü∫Êú¨ÊÄùË∑ØÊòØ‰∏äÈù¢ÁöÑÊà™ÂõæÔºåÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊúâÂá†ÁÇπ Á¨¨‰∏ÄÔºåpython‰∏çÂØºÂÖ•mathÁöÑËØùÊ≤°ÂäûÊ≥ïÊ±ÇceilingÔºå‰ΩÜÊòØÂèØ‰ª•Áî® -Ôºà-a // bÔºâÊù•Ê±Ç Á¨¨‰∫åÔºåÂú®Ê±ÇbucketÁöÑ‰∏™Êï∞ÁöÑÊó∂ÂÄôÔºåÈúÄË¶ÅÂ§öÂä†‰∏ä‰∏Ä‰∏™bucketÔºåÂõ†‰∏∫‰∏Ä‰∏™bucketÈáåÈù¢ÊúÄÂêéÁöÑÊï∞Â≠óÊòØÊîæÂú®‰∏ã‰∏Ä‰∏™bucketÈáåÈù¢ÊúÄÂâçÈù¢ÁöÑ Á¨¨‰∏âÔºåÂèØËÉΩ‰ºöÊúâÁ©∫ÁöÑbucketÔºåÊâÄ‰ª•‰∏çËÉΩÁõ¥Êé•Áî®Ëøô‰∏™ÁöÑminÂáèÂéª‰∏ä‰∏Ä‰∏™ÁöÑmaxÔºåÂøÖÈ°ªË¶ÅÁïô‰∏Ä‰∏™ÂèòÈáè‰øùÂ≠ò‰∏ä‰∏Ä‰∏™ÁöÑmax Á¨¨ÂõõÔºåÂΩìÊâÄÊúâÊï∞Â≠óÈÉΩÁõ∏ÂêåÁöÑÊó∂ÂÄô‰ºöÂèòÂæóÂæàÈ∫ªÁÉ¶ÔºåÊúÄÂêéÂä†‰∏äÂéª‰∏Ä‰∏™Êù°‰ª∂ËøáÊª§ÊéâËøô‰∏™ÈÉ®ÂàÜ 28 implement strStrÔºàÔºâImplement strStr(). Return the index of the first occurrence of needle in haystack, or -1 if needle is not part of haystack. Example 1: Input: haystack = ‚Äúhello‚Äù, needle = ‚Äúll‚ÄùOutput: 2Example 2: Input: haystack = ‚Äúaaaaa‚Äù, needle = ‚Äúbba‚ÄùOutput: -1 123456789class Solution: def strStr(self, haystack: str, needle: str) -&gt; int: if needle == "": return 0 for i, ch in enumerate(haystack): if ch == needle[0]: if needle == haystack[i:i+len(needle)]: return i return -1 ÂàöÂºÄÂßãÁâπÂà´Âø´‰πêÁöÑÊö¥ÂäõÁ†¥Ëß£‰∫ÜÔºåÁúüÊòØ‰∏á‰∏áÊ≤°ÊÉ≥Âà∞ ÊÑüËßâpythonÂ§ÑÁêÜËµ∑Êù•Â≠óÁ¨¶‰∏≤ÊòØÁúüÁöÑÂºÄÂøÉ ‰ΩÜÊòØËøô‰∏™ÁöÑÊó∂Èó¥‰∏çÊòØÂæàÂø´‰πê ÂÖ≥‰∫éÂ≠óÁ¨¶‰∏≤ÂåπÈÖçÊúâÂè¶Â§ñ‰∏§‰∏™ÁÆóÊ≥ïKMPÂíåBMÔºàBMÊõ¥Âø´‰∏ÄÁÇπÔºâ 14Write a function to find the longest common prefix string amongst an array of strings. If there is no common prefix, return an empty string ‚Äú‚Äù. Example 1: Input: [‚Äúflower‚Äù,‚Äùflow‚Äù,‚Äùflight‚Äù]Output: ‚Äúfl‚ÄùExample 2: Input: [‚Äúdog‚Äù,‚Äùracecar‚Äù,‚Äùcar‚Äù]Output: ‚Äú‚ÄùExplanation: There is no common prefix among the input strings.123456789101112131415161718192021class Solution: def longestCommonPrefix(self, strs: List[str]) -&gt; str: if len(strs) == 0: return "" if len(strs) == 1: return strs[0] LCP = self.compare(strs[0],strs[1]) for i in range(2,len(strs)): LCP = self.compare(LCP,strs[i]) return LCP def compare(self,a,b): i = j = 0 counter = 0 while i &lt; len(a) and j &lt; len(b): if a[i] == b[i]: counter += 1 else: break i += 1 j += 1 if counter == 0: return "" else: return a[:counter] ÊÄùË∑ØÔºöÂπ≥Ë°åÊØîËæÉÔºåÂÖàÊâæÂá∫Êù•Ââç‰∏§‰∏™ÈáåÈù¢ÁöÑprefixÔºåÁÑ∂ÂêéÂÜçÁî®Ëøô‰∏™prefixÂíåÁ¨¨‰∏â‰∏™‰∏úË•øÊØîËæÉ Ê≥®ÊÑèËæìÂÖ•ÁöÑÈïøÂ∫¶ÊòØ1ÁöÑÊó∂ÂÄôÔºåÈúÄË¶ÅËæìÂá∫Êï¥‰∏™Â≠óÁ¨¶‰∏≤ Ê≥®ÊÑèÂ¶ÇÊûúÊØîËæÉÂ§±Ë¥•‰∫ÜÁöÑËØùÔºåË¶ÅÁõ¥Êé•ÂÅúÊ≠¢ÊØîËæÉÔºÅ 58Given a string s consists of upper/lower-case alphabets and empty space characters ‚Äò ‚Äò, return the length of last word in the string. If the last word does not exist, return 0. Note: A word is defined as a character sequence consists of non-space characters only. Example: Input: ‚ÄúHello World‚ÄùOutput: 512345678910111213141516class Solution: def lengthOfLastWord(self, s: str) -&gt; int: if len(s) == 0: return 0 while s[-1] == " ": s = s[:-1] if len(s) == 0: return 0 new_str = s.split(" ") # return new_str print(new_str) return len(new_str[-1]) # cnt = 0 # for v in reversed(s): # if v.isspace(): # if cnt: break # else: cnt += 1 # return cnt ÂéüÊù•ËøêË°åÊó∂Èó¥‰πüÂæàÁéÑÂ≠¶ ‰ΩÜÊòØËøòÊòØÂà´‰∫∫ÁöÑ‰ª£Á†ÅÁúãËµ∑Êù•ÂéâÂÆ≥‰∏ÄÁÇπÔºÅ 387Given a string, find the first non-repeating character in it and return it‚Äôs index. If it doesn‚Äôt exist, return -1. Examples: s = ‚Äúleetcode‚Äùreturn 0. s = ‚Äúloveleetcode‚Äù,return 2.1234567891011class Solution: def firstUniqChar(self, s: str) -&gt; int: count = collections.Counter(s) index = 0 for ch in s: if count[ch] == 1: return index else: index += 1 return -1 Â±ÖÁÑ∂ÊúâËøô‰πà‰∏™‰∏úË•øÂè´ÂÅöcounterÔºåÊÑüÂà∞ÈúáÊÉäÔºÅÔºÅÔºÅ 383Given an arbitrary ransom note string and another string containing letters from all the magazines, write a function that will return true if the ransom note can be constructed from the magazines ; otherwise, it will return false. Each letter in the magazine string can only be used once in your ransom note. Note:You may assume that both strings contain only lowercase letters. canConstruct(‚Äúa‚Äù, ‚Äúb‚Äù) -&gt; falsecanConstruct(‚Äúaa‚Äù, ‚Äúab‚Äù) -&gt; falsecanConstruct(‚Äúaa‚Äù, ‚Äúaab‚Äù) -&gt; true Ëøô‰∏™È¢òÁõÆ‰πüÂ§™ÂÜôÊÑè‰∫ÜÂêßÔºåÊÑèÊÄùÂ∞±ÊòØÊàëÈúÄË¶ÅÂÜô‰∏Ä‰∏™ÂãíÁ¥¢‰ø°ÔºåÁÑ∂ÂêéË¶Å‰ªéÊùÇÂøó‰∏äÈù¢ÊâæÂçïËØçÔºåÁúãÁúãËÉΩ‰∏çËÉΩÁî®ÊùÇÂøó‰∏äÈù¢ÁöÑ‰∏úË•øÊãºÂáëÂá∫Êù•Ëøô‰∏™ÂçïËØç 1234567891011class Solution: def canConstruct(self, ransomNote: str, magazine: str) -&gt; bool: alphabet = [0]*26 for ch in magazine: index = ord(ch) - ord('a') alphabet[index] += 1 for ch in ransomNote: index = ord(ch) - ord('a') alphabet[index] -= 1 if alphabet[index] &lt; 0: return False return True ÁúãÂà∞‰∫Ü‰∏Ä‰∏™Ê∏ÖÂ•áÁöÑÊÄùË∑ØÁÑ∂ÂêéËá™Â∑±ÂÆûÁé∞‰∫Ü‰∏Ä‰∏ã ÁªüËÆ°magazineÈáåÈù¢ÊØè‰∏™Â≠óÊØçÁöÑÊï∞ÈáèÔºåÂíåÈúÄË¶ÅÁöÑÂ≠óÊØçÊï∞ÈáèÂØπÊØîÔºåÂ¶ÇÊûú‰∏çÂ§üÁöÑËØùÂ∞±‰∏çË°å ÊàëÂú®ÂÜôÁöÑÊó∂ÂÄôÂ§öiteration‰∫Ü‰∏ÄÊ¨°26‰∏™Â≠óÊØçÔºå‰ΩÜÊòØÂÖ∂ÂÆûÂú®ransomNoteÈáåÈù¢Áõ¥Êé•ÂØπÊØîÂíå0ÁöÑÂ§ßÂ∞èÂ∞±ÂèØ‰ª•‰∫Ü ÊÑüËßâÂ≠óÊØçÂíåÊï∞Â≠óÊúÄÂ§ßÁöÑÂå∫Âà´Â∞±Âú®‰∫éÂ≠óÊØçÊúâÈôêËÄåÊï∞Â≠óÊó†Èôê 344reverse‰∏Ä‰∏™listÔºåË¶ÅÊ±Çin-placeËÄå‰∏îÂç†Áî®o1ÁöÑÁ©∫Èó¥12345678910class Solution: def reverseString(self, s: List[str]) -&gt; None: """ Do not return anything, modify s in-place instead. """ length = len(s) for i in range(length // 2): temp = s[i] s[i] = s[length - 1 - i] s[length - 1 - i] = temp ÂÖ∂ÂÆûÂèØ‰ª•‰∏çÁî®tempÁöÑÔºåÁõ¥Êé•Áî® s[i]Ôºås[length - 1 - i] = s[length - 1 - i], s[i]Â∞±ÂèØ‰ª•‰∫Ü 151reverse‰∏Ä‰∏™stringÔºåËÆ©ËøôÂè•ËØùÂÄíËøáÊù•Ôºå‰∏ªË¶Å‰ºöÊúâÂ§ö‰∏™Á©∫Ê†º123class Solution: def reverseWords(self, s: str) -&gt; str: return " ".join(s.split()[::-1]) pythonÁúüÁöÑÊòØÂæà‰ΩúÂºä‰∫Ü split‰∏çÂä†ÂèÇÊï∞Â∞±ÂèØ‰ª•Áõ¥Êé•ÂàÜÂºÄÊâÄÊúâÂ§ßÂ∞èÁöÑÁ©∫Ê†º 70 Áà¨Ê•ºÊ¢Ø DPYou are climbing a stair case. It takes n steps to reach to the top. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top? Note: Given n will be a positive integer. 123456789101112class Solution: def climbStairs(self, n: int) -&gt; int: if n == 1: return 1 elif n ==0: return 0 elif n == 2: return 2 f = (n+1)*[0]#Ëµ∞nËäÇÁöÑÊó∂ÂÄôÂèØ‰ª•ÊúâÁöÑÊñπÊ≥ïÊï∞Èáè f[1] = 1 f[2] = 2 for i in range(3,n+1): f[i] = f[i-1] + f[i-2] return f[n] ÂÖ∂ÂÆûÂ∞±Áõ∏ÂΩì‰∫éÊñêÊ≥¢ÈÇ£Â•ëÊï∞ÂàóÔºåÁ¨¨iÁßçÁöÑÂèØËÉΩÁöÑÊñπÊ≥ïÊòØ‰ªéi-2Ëµ∞‰∏Ä‰∏™2Ôºå‰ª•Âèä‰ªéi-1Ëµ∞‰∏Ä‰∏™1ÁöÑÂíå 345Êää‰∏Ä‰∏™stringÈáåÈù¢ÁöÑÂéüÂõ†ÂèçÂ∫è 1234567891011121314class Solution: def reverseVowels(self, s: str) -&gt; str: vowels = "AEIOUaeiou" index = [] for i, j in enumerate(s): if j in vowels: index.append(i) s = list(s) i,j = 0,len(index)-1 while i&lt;j: s[index[i]],s[index[j]] = s[index[j]],s[index[i]] i += 1 j -= 1 return "".join(s) È¶ñÂÖàÂà§Êñ≠Âì™‰∏™ÊòØÂéüÂõ† ÁÑ∂ÂêéÊääÂÖÉÈü≥ÁöÑÈÉ®ÂàÜÂÄíËøáÊù• .joinÊäälistËΩ¨Âõûstring 205 Isomorphic StringsEasy 767 217 Favorite ShareGiven two strings s and t, determine if they are isomorphic. Two strings are isomorphic if the characters in s can be replaced to get t. All occurrences of a character must be replaced with another character while preserving the order of characters. No two characters may map to the same character but a character may map to itself. Example 1: Input: s = ‚Äúegg‚Äù, t = ‚Äúadd‚ÄùOutput: true1234567891011class Solution: def isIsomorphic(self, s: str, t: str) -&gt; bool: n = len(s) sub_1,sub_2 = [0]*256,[0]*256 for i in range(n): a,b = s[i],t[i] if sub_1[ord(a)] != sub_2[ord(b)]: return False sub_1[ord(a)] = i + 1 sub_2[ord(b)] = i + 1 return True Ê≥®ÊÑèËøôÈáåÈù¢ÁöÑmapping‰∏ç‰∏ÄÂÆöÊòØÂ≠óÊØçÔºå‰πüÂèØ‰ª•ÊòØÊï∞Â≠ó asciiÁ†Å‰∏ÄÂÖ±ÊòØ256‰∏™ÔºåÊâÄ‰ª•ÊòØ‰∏ç‰ºöË∂ÖÂá∫Ëøô‰∏™ËåÉÂõ¥ÁöÑ ‰∏ªË¶ÅÊÄùË∑ØÂ∞±ÊòØËøôÊ†∑ÁöÑÔºå‰∏§‰∏™Êï∞ÁªÑÂàÜÂà´ËÆ∞ÂΩïÁöÑÊòØÂØπÂ∫î‰ΩçÁΩÆÁöÑasciiÁ†ÅÁöÑmappingÁöÑ‰ΩçÊï∞ÔºåÂ¶ÇÊûúËøô‰∏§‰∏™‰ΩçÊï∞‰∏ç‰∏ÄÊ†∑ÁöÑËØùÔºåÂ∞±ËØ¥ÊòéËøô‰∏§‰∏™ÁöÑmappingÊñπÂºèÊúâÈóÆÈ¢òÔºåÊâÄ‰ª•return FalseÔºå‰∏çÁÑ∂ÁöÑËØùreturn True 290 word patternGiven a pattern and a string str, find if str follows the same pattern. Here follow means a full match, such that there is a bijection between a letter in pattern and a non-empty word in str. Example 1: Input: pattern = ‚Äúabba‚Äù, str = ‚Äúdog cat cat dog‚ÄùOutput: true12345class Solution: def wordPattern(self, pattern: str, str: str) -&gt; bool: pattern = list(pattern) string = str.split(" ") return len(set(zip(pattern,string))) == len(set(string)) == len(set(pattern)) and len(pattern) == len(string) ÂèàÂà∞‰∫ÜÊ¥ªÁî®zipÁöÑÊó∂ÂÄôÔºåËøîÂõûÁöÑÊòØ‰∏Ä‰∏™‰∏™ÂØπÂ∫îÁöÑ‰∏úË•øÔºå‰πüÂ∞±ÊòØËØ¥ËøîÂõûÁöÑÊòØ a-dog,b-cat,b-cat,a-dog ËøôÊó∂ÂÄôÊää‰ªñ‰ª¨ËΩ¨ÂåñÊàêsetÔºåÂæóÂà∞ÁöÑÂ∞±ÊòØ‰∏çÂ∏¶ÈáçÂ§çÁöÑ‰∏úË•øÁöÑÈïøÂ∫¶ Â¶ÇÊûúÂåπÈÖç‰∏äÁöÑÈïøÂ∫¶ÂíåÂéüÂÖàÁöÑÈïøÂ∫¶ÂÖ®ÈÉΩÁõ∏ÂêåÔºàÂéªÊéâÈáçÂ§çÁöÑÂÖÉÁ¥†ÔºâÔºåÈÇ£‰πàÂ∞±ËØÅÊòéÂåπÈÖç‰∏ä‰∫Ü 49 Âèò‰ΩçËØç12345678910111213141516171819class Solution: def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]: # for i,item in enumerate(strs): # item = list(item) # item.sort() # item = "".join(item) # temp[i],temp_sort = item,item # temp_sort.sort() # print(temp,strs) d = &#123;&#125; for word in strs: key = "".join(sorted(word)) if key in d: d.get(key).append(word) else: d[key] = [word] # d[key] = d.get(key,[]) + [word] return d.values() Ê†∏ÂøÉÊÄùÊÉ≥ -&gt; ÊéíÂ∫èÔºåÊéíÂ∫è‰πãÂêéÁöÑÂèò‰ΩçËØçÂ∞±ÈÉΩ‰∏ÄÊ†∑‰∫Ü leetcode 242,49 Ëøô‰∏™È¢òÁöÑÊ†∏ÂøÉÊÄùË∑ØÂ∞±ÊòØÔºåÊØè‰∏™ÂçïËØçÊåâÂ≠óÊØçÈ°∫Â∫èÊéíÂ∫è‰πãÂêéÁöÑÁ≠îÊ°àÂ∞±ÊòØËøô‰∏™ÂçïËØçÁöÑkeyÔºåÂ¶ÇÊûú‰∏§‰∏™ÂçïËØçÁöÑkey‰∏ÄÊ†∑ÁöÑËØùËøô‰∏§‰∏™ÂçïËØçÂ∞±ÊòØÂèò‰ΩçËØçÔºåÂ¶ÇÊûú‰∏ç‰∏ÄÊ†∑ÁöÑËØùÂ∞±ÊòØÊñ∞ÁöÑËØç Âú®pythonÈáåÈù¢Áõ¥Êé•Áî®Â≠óÂÖ∏ÂèØ‰ª•ÂæàÂ•ΩÁöÑÂÇ®Â≠òÂèò‰ΩçËØç 56 merge intervalsGiven a collection of intervals, merge all overlapping intervals. Example 1: Input: [[1,3],[2,6],[8,10],[15,18]]Output: [[1,6],[8,10],[15,18]]Explanation: Since intervals [1,3] and [2,6] overlaps, merge them into [1,6]. 12345678910class Solution: def merge(self, intervals: List[List[int]]) -&gt; List[List[int]]: intervals.sort(key = lambda x : x[0]) output = [] for i in intervals: if output and i[0] &lt;= output[-1][1]: output[-1][1] = max(output[-1][1], i[1]) else: output.append(i) return output Ê≥®ÊÑèÁÇπÔºö ÁªôÁöÑÊï∞ÊçÆËæìÂÖ•Âπ∂‰∏ç‰∏ÄÂÆöÊòØÊéíÂ•ΩÂ∫èÁöÑÔºåÊâÄ‰ª•ÈúÄË¶ÅÂÖàÊéíÂ•ΩÂ∫è„ÄÇËøôÈáåÁî®Âà∞‰∫ÜÊéíÂ∫èÁöÑkeyÁöÑÂäüËÉΩ„ÄÇlambdaÊòØÂÆö‰πâ‰ªªÊÑèÂáΩÊï∞ g(x)= x[0] ÈúÄË¶ÅËæìÂá∫ÁöÑÊ†ºÂºèÊòØlistÂ•ólistÔºåÊâÄ‰ª•ÈúÄË¶Åappend ÊÄùË∑ØÈîô‰∫ÜÁöÑ‰∏Ä‰∏™ÊñπÂêëÊòØÔºåÂÖ∂ÂÆûÊØè‰∏™i‰∏çÂ∫îËØ•ÂíåÈöîÂ£ÅÁöÑiÊØîÂ§ßÂ∞èÔºåËÄåÊòØÂ∫îËØ•ÂíåoutputÈáåÈù¢ÁöÑÊúÄÁªàÁªìÊûúÊØîÂ§ßÂ∞èÔºåÂõ†‰∏∫ÈúÄË¶ÅËÄÉËôëÂà∞Â•ΩÂá†‰∏™ÂÜÖÂÆπÈÉΩÂèØ‰ª•ÂêàÂπ∂ÁöÑÊÉÖÂÜµ 57ÊèíÂÖ•12345678910111213141516171819202122232425262728class Solution: def insert(self, intervals: List[List[int]], newInterval: List[int]) -&gt; List[List[int]]: out = [] adding = False if len(intervals) == 0: return [newInterval] if newInterval[1] &lt; intervals[0][0]: out.append(newInterval) adding = True for i in intervals: if adding is False: if newInterval[0] &gt; i[1]: out.append(i) elif newInterval[1] &lt; i[0]: out.append(newInterval) adding = True else: after_insert = [min(i[0],newInterval[0]),max(i[1],newInterval[1])] out.append(after_insert) adding = True # print("adding") if adding is True: if i[0] &gt; out[-1][1]: out.append(i) else: out[-1][1] = max(out[-1][1],i[1]) if adding is False: out.append(newInterval) return out Ëá™Â∑±Ëã¶ÊÄùÂÜ•ÊÉ≥‰∫Ü‰∏Ä‰∏™Â§öÂ∞èÊó∂ÁöÑÁ≠îÊ°à ÊúâÁÇπÁπÅÁêêÔºådebugÁöÑÊó∂ÂÄô‰∏ªË¶ÅÊòØÊÉÖÂÜµËÄÉËôëÁöÑ‰∏çÂ§üÊòéÁ°ÆÔºåÂåÖÊã¨Ê≤°ÊúâËÄÉËôëÁ©∫ÁöÑÊÉÖÂÜµÔºåÂú®ÊúÄÂêéÊèíÂÖ•ÁöÑÊÉÖÂÜµÔºåÂú®ÊúÄÂâçÊèíÂÖ•ÁöÑÊÉÖÂÜµ ‰ΩÜÊòØÊúÄÂêéÊÄªÁªìÁöÑÊÉ≥ÔºåÂ∫îËØ•ÂØπÊèíÂÖ•ÁöÑÂâçÂêé‰∏ÄËßÜÂêå‰ªÅÔºåÂõ†‰∏∫Áä∂ÂÜµÂÖ∂ÂÆûÊòØÂ∑Æ‰∏çÂ§öÁöÑÔºåËÄåÊàëÊääÂâçÈù¢ÂàÜÊàê‰∫ÜÂ•ΩÂ§öÁßçÁä∂ÂÜµÔºåÂêéÈù¢ÂÄíÊòØÂÜôÊàê‰∫Ü‰∏ÄÁßçÊÉÖÂÜµ 12345678910111213left = []right = []s,e = newInterval[0],newInterval[1]for i in intervals: if i[1] &lt; s: left.append(i) elif i[0] &gt; e: right.append(i) else: s = min(i[0],s) e = max(i[1],e)return left + [[s,e]] + right ËøôÊòØdiscussionÈáåÈù¢ÁöÑ‰∏ÄÁßçÁÆÄË¶ÅÁöÑËß£Ê≥ïÔºåÊÄùË∑ØÁöÑ‰∏çÂêåÂ∞±ÊòØ‰ªñÊòØÊØèÊ¨°ÈÉΩmergeÂà∞newÈáåÈù¢‰∫ÜÔºà‰πüÂ∞±ÊòØsÂíåeÔºâÔºåËÄåÊàëÊòØmergeÂà∞outÈáåÈù¢‰∫Ü ÂÖ∂ÂÆûÊàëÁöÑ‰ª£Á†ÅÊú¨Ë∫´ÁöÑ‰πüÊúâmergeÂà∞newÁöÑÊÑèÊÄùÔºå‰ΩÜÊòØË¢´ÊàëÂàÜÂá∫‰∫ÜÂ§™Â§öÁßçÂ§™Â§çÊùÇÁöÑÊÉÖÂÜµ 101ÂØπÁß∞Ê†ë1234567891011121314151617181920212223# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def isSymmetric(self, root: TreeNode) -&gt; bool: now = [] if root: now.append(root) while now: vals = [] for i in now: if i: vals.append(i.val) else: vals.append(None) if list(reversed(vals)) != vals: return False else: now = [j for i in now if i for j in (i.left, i.right)] return True ÈÅçÂéÜÁöÑÊñπÊ≥ïÔºåÊúÄÂêé‰∏Ä‰∏™nowÁöÑË°®ËææÂºèÂÄºÂæóÂ≠¶‰π† Ê≥®ÊÑèrootÊòØnodeÔºåËÄåËøô‰∏™nodeÂÆûÈôÖÁöÑÂÄºÂú®valsÈáåÈù¢ÔºåÂõ†‰∏∫Â•Ω‰πÖÊ≤°Â§ÑÁêÜnode‰∫ÜÊâÄ‰ª•ÂøòËÆ∞‰∫ÜËøô‰∏ÄÁÇπ 12345678910def isSymmetric(self, root: TreeNode) -&gt; bool: def Symm(L,R): if L and R: return L.val == R.val and Symm(L.left,R.right) and Symm(L.right,R.left) else: return L == R # return L is None and R is None #ÂêåÁ≠âÊÑè‰πâ return Symm(root, root) # Ê≤°ÊúâÂÖ≥‰∫éÁ©∫ÁöÑÊ†ëÁöÑÂà§Êñ≠Êù°‰ª∂ÔºåÊâÄ‰ª•ÈúÄË¶Å‰ªérootÂºÄÂßã Ëøô‰∏™ÊñπÊ≥ïËøá‰∫é‰ºòÈõÖÔºåÊàëË¶ÅÂì≠Âá∫Êù•‰∫Ü 87 Scramble StringGiven a string s1, we may represent it as a binary tree by partitioning it to two non-empty substrings recursively. Below is one possible representation of s1 = ‚Äúgreat‚Äù: great / \ gr eat / \ / \g r e at / \ a tTo scramble the string, we may choose any non-leaf node and swap its two children. For example, if we choose the node ‚Äúgr‚Äù and swap its two children, it produces a scrambled string ‚Äúrgeat‚Äù. rgeat / \ rg eat / \ / \r g e at / \ a t ÊÄùË∑ØÔºö È¶ñÂÖàÔºåÂ¶ÇÊûúÊàëËøô‰∏™ÂçïËØçÁöÑsubstringÊª°Ë∂≥Ëøô‰∏™Ë¶ÅÊ±ÇÁöÑËØùÔºå‰∏äÈù¢‰∏ÄÂ±ÇÁöÑÂçïËØçÂ∞±Êª°Ë∂≥Ëøô‰∏™Ë¶ÅÊ±ÇÔºå‰πüÂ∞±ÊòØËØ¥ÂèØ‰ª•recursiveÁöÑÂÆåÊàêËøô‰∏™Â∑•‰ΩúÔºåÂØπ‰∫é‰∏çÂêåÁöÑsubstring callËøô‰∏™ÂáΩÊï∞Êù•Ê£ÄÈ™åÊòØÂê¶Êª°Ë∂≥Ë¶ÅÊ±Ç ËæπÁïåÊù°‰ª∂Ôºö Â¶ÇÊûústringÁöÑÈïøÂ∫¶Â∞è‰∫éÁ≠â‰∫é2ÔºåÈÇ£‰πàÊÄé‰πàÊç¢ÂÖ∂ÂÆûÈÉΩÊòØÊª°Ë∂≥ÁöÑ Â¶ÇÊûú‰∏§‰∏™stringÁõ¥Êé•Áõ∏Á≠âÔºåÈÇ£‰πà‰πüÊòØÊª°Ë∂≥ÁöÑ ÂÖàÂÜ≥Êù°‰ª∂Ôºö Â¶ÇÊûúËøô‰∏§‰∏™stringÁöÑÈïøÂ∫¶ÈÉΩ‰∏ç‰∏ÄÊ†∑ÔºåÈÇ£‰πàËÇØÂÆö‰πü‰∏ç‰∏ÄÊ†∑ Â¶ÇÊûúËøô‰∏§‰∏™stringÈáåÈù¢Â≠óÊØçÁöÑsort‰πãÂêéÈÉΩ‰∏ç‰∏ÄÊ†∑ÔºåÈÇ£‰πàËÇØÂÆö‰∏ç‰∏ÄÊ†∑ Âà§Êñ≠Êù°‰ª∂Ôºö ÂØπ‰∫é‰∏Ä‰∏™stringÔºåÂ¶ÇÊûú‰ªék‰ΩçÁΩÆÊù•ÂàÜÁöÑËØùÔºåÊúâ‰∏§Áßç‰∏çÂêåÁöÑÁªìÊûú„ÄÇorÂÖ≥Á≥ª ÁªìÊûú1Ôºös1ÁöÑÂâçk‰∏™Âíås2ÁöÑÂâçk‰∏™‰∏ÄÊ†∑ and s1ÁöÑÂêén-k‰∏™Âíås2ÁöÑÂêén-k‰∏™‰∏ÄÊ†∑ ÁªìÊûú2Ôºös1ÁöÑÂâçk‰∏™Âíås2ÁöÑÂêék‰∏™‰∏ÄÊ†∑ and s1ÁöÑÂâçn-k‰∏™Âíås2ÁöÑÂâçn-k‰∏™‰∏ÄÊ†∑ 1234567891011class Solution: def isScramble(self, s1: str, s2: str) -&gt; bool: n1,n2 = len(s1),len(s2) if n1 != n2 or sorted(s1) != sorted(s2): return False if n1 &lt;= 2 or s1 == s2: return True f = self.isScramble for i in range(1,n1): if (f(s1[0:i], s2[0:i]) and f(s1[i:],s2[i:])) or \ f(s1[0:i], s2[n2-i:]) and f(s1[i:],s2[0:n2-i]): return True return False 38 count and sayThe count-and-say sequence is the sequence of integers with the first five terms as following: 1 11 21 1211 1112211 is read off as ‚Äúone 1‚Äù or 11.11 is read off as ‚Äútwo 1s‚Äù or 21.21 is read off as ‚Äúone 2, then one 1‚Äù or 1211. Given an integer n where 1 ‚â§ n ‚â§ 30, generate the nth term of the count-and-say sequence. Note: Each term of the sequence of integers will be represented as a string. Ëá™Â∑±ÁöÑÊô∫ÈöúËß£Ê≥ï12345678910111213141516171819202122232425262728class Solution: def countAndSay(self, n: int) -&gt; str: if n == 1: return "1" result = [1] for i in range(2,n+1): result = self.Say(result) return result def Say(self,num): n = len(num) counter = 1 counters = "" nums = str(num[0]) for i in range(1,n): if num[i] == num[i-1]: counter += 1 else: counters += str(counter) counter = 1 nums += str(num[i]) counters += str(counter) result = "" for i in range(len(counters)): result += counters[i] result += nums[i] return result Ê≥®ÊÑèÔºåÂ¶ÇÊûúË¶ÅÊäälistÊé•ÊàêstringÔºåÈúÄË¶ÅÂÖàÊääÈáåÈù¢ÁöÑÊâÄÊúâÈ°πÈÉΩËΩ¨Êàêstring ÊÑüËßâËá™Â∑±ËøòÊòØÂæà‰∏çÊìÖÈïørecursive #316 remove deplicate lettersGiven a string which contains only lowercase letters, remove duplicate letters so that every letter appears once and only once. You must make sure your result is the smallest in lexicographical order among all possible results. Example 1: Input: ‚Äúbcabc‚ÄùOutput: ‚Äúabc‚ÄùExample 2: Input: ‚Äúcbacdcbc‚ÄùOutput: ‚Äúacdb‚Äù 12345678910111213141516171819class Solution: def removeDuplicateLetters(self, s: str) -&gt; str: # s = sorted(s) # i = 0 # for n in s: # # print(n,i,s[i-1]) # if i &lt; 1 or n != s[i-1]: # s[i] = n # i += 1 # return "".join(s[:i]) s = list(s) result = [] last_occurrence = &#123;c: i for i, c in enumerate(s)&#125; for i,n in enumerate(s): if n not in result: while result and n &lt; result[-1] and result[-1] in s[i:]: result.pop() result.append(n) return "".join(result) ËøôÈÅìÈ¢òÈáåÈù¢ÁöÑÈáçÁÇπÂú®lexicographical order ‰πüÂ∞±ÊòØËØ¥ÔºåÂú®Êìç‰ΩúÁöÑÊó∂ÂÄôÔºåÂ¶ÇÊûúËøô‰∏™Â≠óÊØçÂú®ÂêéÈù¢ÁöÑ‰ΩçÁΩÆ‰∏äÂá∫Áé∞‰∫ÜÔºå‰ΩÜÊòØÊîæÂú®ÂâçÈù¢ÁöÑ‰ΩçÁΩÆ‰∏ä‰ºöÂØºËá¥ÂâçÈù¢ÂèòÂ§ßÔºåÈÇ£‰πàÂ∞±ÂèñÂêéÈù¢ÁöÑÈÇ£‰∏™ÁªìÊûú Êú¨Êù•ÊàëÊÉ≥ÁöÑÊòØÂèØ‰ª•ÂÖàÊääÊ≤°Âá∫Áé∞ËøáÁöÑÊîæËøõÂéªÔºåÁÑ∂ÂêéÂÜçÂà∑Êñ∞„ÄÇ‰ΩÜÊòØÁõ¥Êé•ÊîæÊúÄÂ•ΩÁöÑÂ∫îËØ•Êõ¥Â•Ω‰∏Ä‰∫õ Âá†ÁßçÊÉÖÂÜµÔºö Â¶ÇÊûúÂ∑≤ÁªèÂá∫Áé∞‰∫ÜÔºöÈÇ£‰πàÁõ¥Êé•Ë∑≥Ëøá Â¶ÇÊûúÊ≤°Âá∫Áé∞Ôºö Â¶ÇÊûúÊØî‰πãÂâçÁöÑÂ∞èÔºåÂπ∂‰∏îÂâçÈù¢ÁöÑÈÇ£‰∏™Âú®ÂêéÈù¢ËøòÊúâÔºåÂ∞±ÂæóÂæÄÂâçÈ°∂„ÄÇËøòË¶ÅËÄÉËôëÈ°∂Ê≤°‰∫ÜÁöÑÊÉÖÂÜµÔºå‰πüÂ∞±ÊòØresult‰∏ç‰∏∫Á©∫ ËøôÈáåÊ≥®ÊÑèËøô‰∏â‰∏™Êù°‰ª∂ÊòØÂπ∂ÂàóÁöÑÔºåÈúÄË¶ÅÂêåÊó∂and„ÄÇÊàëÂàöÂºÄÂßãÊääÂú®ÂêéÈù¢Âá∫Áé∞ÊîæÂà∞Âæ™ÁéØÈáåÈù¢Âéª‰∫ÜÔºåÊâÄ‰ª•Ê≠ªÂæ™ÁéØ‰∫Ü Âú®‰∏äÈù¢È°∂ÂÆå‰πãÂêéÔºåÂÜçÊääÊúÄÊñ∞ÁöÑÂä†Âà∞ÊúÄÂêé 168 excel column titleGiven a positive integer, return its corresponding column title as appear in an Excel sheet. For example: 1 -&gt; A 2 -&gt; B 3 -&gt; C ... 26 -&gt; Z 27 -&gt; AA 28 -&gt; AB ... 123456789101112131415161718class Solution: def convertToTitle(self, n: int) -&gt; str: result = [] while n &gt; 0: letter = n % 26 n = n // 26 if letter == 0: letter = 26 n = n-1 result.append(letter) result = result[::-1] for i,item in enumerate(result): item += 64 item = str(chr(item)) result[i] = item # print(result) return "".join(result) Ëá™Â∑±ÁöÑÂÇªÈÄºÊñπÊ≥ïÔºö ÊúÄÂÖàÂæóÂà∞ÁöÑ‰ΩôÊï∞Â∫îËØ•ÊòØÊúÄÂêéÁöÑÂ≠óÊØçÁöÑÂÄºÔºåÊâÄ‰ª•ËøôÈáåÂá∫Êù•ÁöÑresultÈúÄË¶ÅÁøªËΩ¨‰∏Ä‰∏ã ÁøªËΩ¨listÊúÄÂø´ÁöÑÊñπÊ≥ïÊòØ [::-1] str(chr(n))ÊääÊï∞Â≠óËΩ¨ÊàêcharÔºåordÊäächarËΩ¨ÊàêÊï∞Â≠óÔºåÂ§ßÂÜôAÊòØ65ÔºåÂ∞èÂÜôaÊòØ97 1return "" if num == 0 else self.convertToTitle((num - 1) / 26) + chr((num - 1) % 26 + ord('A')) Â§ß‰Ω¨ÁöÑ‰∏ÄË°å ÂøòËÆ∞‰∫ÜËøôÁßçstrÁöÑËøûÊé•ÊñπÊ≥ï Áõ¥Êé•Âáè-1ËÆ°ÁÆóÊõ¥Êñπ‰æø 171 Excel Sheet Column Number1234567class Solution: def titleToNumber(self, s: str) -&gt; int: # s = s[::-1] # result = 0 # for i,item in enumerate(s): # result += 26^(i) + (ord(item) - ord("A")) return 0 if s == "" else self.titleToNumber(s[:-1]) * 26 + ord(s[-1]) - ord("A") + 1 ‰∏äÈù¢ÈÇ£ÈÅìÈ¢òÁöÑÂèãÊÉÖÈ¢òÔºåÊ®°ÊãüÂ§ß‰Ω¨ÂÜôÂá∫‰∫ÜËß£Ê≥ï Ê≥®ÊÑèlistÁöÑ‰∏äÈôêÔºåÂà∞-1ÁöÑËØùÊòØÂà∞-2‰∏çÂåÖÊã¨-1 13 roman to integerRoman numerals are represented by seven different symbols: I, V, X, L, C, D and M. Symbol ValueI 1V 5X 10L 50C 100D 500M 1000For example, two is written as II in Roman numeral, just two one‚Äôs added together. Twelve is written as, XII, which is simply X + II. The number twenty seven is written as XXVII, which is XX + V + II. Roman numerals are usually written largest to smallest from left to right. However, the numeral for four is not IIII. Instead, the number four is written as IV. Because the one is before the five we subtract it making four. The same principle applies to the number nine, which is written as IX. There are six instances where subtraction is used: I can be placed before V (5) and X (10) to make 4 and 9.X can be placed before L (50) and C (100) to make 40 and 90.C can be placed before D (500) and M (1000) to make 400 and 900.Given a roman numeral, convert it to an integer. Input is guaranteed to be within the range from 1 to 3999.1234567891011121314151617181920class Solution: def romanToInt(self, s: str) -&gt; int: trans = &#123; "I":1, "V":5, "X":10, "L":50, "C":100, "D":500, "M":1000 &#125; s = s.replace("IV","IIII").replace("IX","VIIII") s = s.replace("XL","XXXX").replace("XC","LXXXX") s = s.replace("CD","CCCC").replace("CM","DCCCC") result = 0 for c in s: result += trans[c] return result ÊØîËæÉÂÖ∏ÂûãÁöÑÁî®dictËß£ÂÜ≥ÁöÑ‰æãÂ≠êÔºåÂñÑÁî®stringÈáåÈù¢ÁöÑreplaceÊñπÊ≥ï 12 int to roman‰∏äÈù¢ÁöÑÂèãÊÉÖÈ¢ò ËôΩÁÑ∂ÂèØ‰ª•Á©∑‰∏æÂÆûÁé∞Ôºå‰ΩÜÊòØÊàëÈ™ÑÂÇ≤ÁöÑËá™Â∑±ÂÜôÂá∫Êù•‰∫ÜrecursiveÁöÑÊñπÊ≥ï ÈúÄË¶ÅÊ≥®ÊÑèÂ≠óÊØçÁöÑÊõøÊç¢È°∫Â∫èÔºå‰∏çÁÑ∂‰ºöÊç¢Èîô1234567891011121314151617181920212223242526272829303132class Solution: def intToRoman(self, num: int) -&gt; str: space = ["M", "D", "C", "L", "X", "V", "I"] trans = &#123; "I": 1, "V": 5, "X": 10, "L": 50, "C": 100, "D": 500, "M": 1000 &#125; s = self.find_raw(num, 0, space, trans) s = s.replace("DCCCC", "CM").replace("CCCC", "CD") s = s.replace("LXXXX", "XC").replace("XXXX", "XL") s = s.replace("VIIII", "IX").replace("IIII", "IV") return s def find_raw(self, num, name, space, trans): if num &lt; 5: return num * "I" else: temp = (num // trans[space[name]]) * space[name] after = self.find_raw( num % trans[space[name]], name + 1, space, trans) return temp + afters = Solution()print(s.intToRoman(9)) 273 int to english1234567891011121314151617181920212223242526272829class Solution: def numberToWords(self, num: int) -&gt; str: t0to19 = ["Zero", "One", "Two", "Three", "Four", "Five", "Six", "Seven", "Eight", "Nine", "Ten", "Eleven", "Twelve", "Thirteen", "Fourteen", "Fifteen", "Sixteen", "Seventeen", "Eighteen", "Nineteen"] tens = ["Twenty", "Thirty", "Forty", "Fifty", "Sixty", "Seventy", "Eighty", "Ninety"] def word(num, i = 0): if num == 0: return [""] if num &lt; 20: return [t0to19[num]] if num &lt; 100: return [tens[num // 10 - 2]] + word(num % 10) if num &lt; 1000: return [t0to19[num // 100]] + ["Hundred"] + word(num % 100) else: trans = &#123;"Billion": int(1e9), "Million": int( 1e6), "Thousand": int(1e3)&#125; part = ["Billion", "Million", "Thousand"][i] if num // trans[part] == 0: return word(num % trans[part], i + 1) else: return word(num // trans[part]) + [part] + word(num % trans[part], i + 1) s = word(num, 0) while "" in s: s.remove("") return " ".join(s) or "Zero" Ê≥®ÊÑèÁßªÈô§Á©∫È°πÁöÑÊó∂ÂÄôÔºåÈúÄË¶ÅÁî®whileËÄå‰∏çÊòØif Âõ†‰∏∫ÊúÄÂêéÈúÄË¶ÅÁ©∫Ê†ºËøûÊé•ÔºåÊâÄ‰ª•ÊúÄÂ•ΩÂÖàÊâîÂà∞listÈáåÈù¢ÂÜçÂá∫Êù• ËøôÈ¢ò‰πüÂ§™ÂÇªÊØî‰∫Ü=„ÄÇ=Êó†ËÆ∫ÊÄé‰πàÊ†∑ÈÉΩË¶ÅËá™Â∑±ÊâãÊâìËøô‰πàÂ§ö‰∏úË•ø # 68 text justificationÈúÄË¶ÅÊääËøô‰∏ÄË°åÂ≠óÂ∑¶Âè≥ÂØπÈΩê1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution: def fullJustify(self, words: List[str], maxWidth: int) -&gt; List[str]: # ÊØè‰∏ÄË°åÂ°´Êª°ÔºåÂ¶ÇÊûúÂ°´‰∏çÊª°ÁöÑÊó∂ÂÄôÔºåËØçÁöÑ‰∏≠Èó¥ÁöÑÁ©∫Ê†ºÂ∞ΩÈáèÂπ≥Âùá # ÊúÄÂêé‰∏ÄË°åÂè≥ËæπÂä†Á©∫Ê†º # ÊØèËØª‰∏Ä‰∏™ÂçïËØçÂêéÈù¢ÈúÄË¶ÅÂä†‰∏ÄË°å space = 0 line = [0] # ÊØè‰∏ÄË°åÂºÄÂ§¥ÁöÑÂçïËØçÁöÑÂùêÊ†á for i, word in enumerate(words): if space + len(word) &lt; maxWidth: space += len(word) + 1 elif space + len(word) == maxWidth and i != len(words) - 1: space = 0 line.append(i + 1) elif space + len(word) &gt; maxWidth: space = len(word) + 1 #Ê≥®ÊÑèËøôÈáåÁöÑÈïøÂ∫¶ÂèòÂåñ‰∫Ü line.append(i) output = [] for i in range(len(line)): if i &lt; len(line) - 1: s = "" this_line = words[line[i]:line[i+1]] length = -1 # ÊúÄÂêé‰∏Ä‰∏™ÂçïËØç‰∏çÂ∏¶Á©∫Ê†º for w in this_line: length += len(w) + 1 if len(this_line) == 1: s = this_line[0] + (maxWidth - len(this_line[0])) * " " else: space_len = (maxWidth - length) // (len(this_line) - 1) extra_space = (maxWidth - length) % (len(this_line) - 1) for i,w in enumerate(this_line): if i &lt; len(this_line) - 1: s = s + w + " " + space_len*" " if i &lt;= extra_space - 1: s = s + " " else: s = s + w output.append(s) else: this_line = words[line[i]:] s = " ".join(this_line) s = s + " "*(maxWidth-len(s)) output.append(s) return output ÊÄùË∑Ø ÂÖàÂàÜÂºÄÂçïËØç ÂÜçÂæÄÈáåÊèíÁ©∫Ê†º 6ÊääÊï¥Êï∞ËΩ¨ËøáÊù•12345678910111213141516171819202122class Solution: def reverse(self, x: int) -&gt; int: Positive = True x2 = [] if str(x)[0] == "-": Positive = False x = int(x - x * 2) while x &gt;= 10: num = x % 10 x = x // 10 x2.append(str(num)) x2.append(str(x)) output = "".join(x2) output = int(output) if Positive: output = int(output) else: output = int(output) - 2 * int(output) if output &gt; 2**31 - 1 or output &lt; -2**31: return 0 else: return output Ê≥®ÊÑèÂïä2ÁöÑ31Ê¨°Êñπ‰∏çÊòØ2e31ÂïäÂïäÊàëÂú®Âπ≤‰ªÄ‰πà 165. Compare Version Numbers ÊØîËæÉ‰∏§‰∏™ÁâàÊú¨Âè∑ÔºåÈúÄË¶ÅÂøΩÁï•ÈáåÈù¢ÁöÑ0 123456789101112131415161718192021222324252627282930313233343536class Solution: def compareVersion(self, version1: str, version2: str) -&gt; int: v1 = version1.split(".") v2 = version2.split(".") v1 = [int(x) for x in v1] v2 = [int(x) for x in v2] # ÂèØ‰ª•ÁÆÄÂåñ‰∏∫‰∏§Ë°å # versions1 = [int(v) for v in version1.split(".")] # versions2 = [int(v) for v in version2.split(".")] if len(v1) &gt; len(v2): length = len(v2) else: length = len(v1) for i in range(length): c1,c2 = v1[i],v2[i] if c1 &gt; c2: return 1 elif c1 &lt; c2: return -1 end = i rest1,rest2 = v1[i+1:],v2[i+1:] if sum(rest1) == sum(rest2): return 0 elif sum(rest1) &gt; sum(rest2): return 1 elif sum(rest1) &lt; sum(rest2): return -1 # Âè¶‰∏ÄÁßçÊñπÊ≥ïÔºåÊõ¥ÁÆÄÊ¥Å # for i in range(max(len(versions1),len(versions2))): # v1 = versions1[i] if i &lt; len(versions1) else 0 # v2 = versions2[i] if i &lt; len(versions2) else 0 # if v1 &gt; v2: # return 1 # elif v1 &lt; v2: # return -1; # return 0; ÈúÄË¶ÅËÄÉËôëÁöÑ‰∏ªË¶ÅÂ∞±ÊòØÈïøÂ∫¶‰∏ç‰∏ÄÊ†∑ÁöÑÊÉÖÂÜµÂíåÂ°û0ÁöÑÊÉÖÂÜµÔºåÊàëÁöÑÊÉ≥Ê≥ïÊòØÂèñÊØîËæÉÂ∞èÁöÑÊÄªÈïøÂ∫¶ÔºåÁÑ∂ÂêéÂÜçÊØîËæÉÂâ©‰ΩôÁöÑ Â§ß‰Ω¨ÁöÑÊÉÖÂÜµÊòØÊØîËæÉÁöÑÊâÄÊúâÁöÑÈïøÂ∫¶ÔºåÂ¶ÇÊûúË∂ÖËøá‰∫ÜÁé∞Âú®ÁöÑÈïøÂ∫¶Â∞±Áõ¥Êé•ËÆæÁΩÆ‰∏∫0ÔºåËøôÊ†∑‰∏ç‰ºöÂΩ±ÂìçÊØîËæÉ„ÄÇÊúÄÂêéÈÉΩÊØîÂÆåÈÉΩÊ≤°Â∑ÆÂ∞±ÊòØ0 66Given a non-empty array of digits representing a non-negative integer, plus one to the integer. The digits are stored such that the most significant digit is at the head of the list, and each element in the array contain a single digit. You may assume the integer does not contain any leading zero, except the number 0 itself. Example 1: Input: [1,2,3]Output: [1,2,4]Explanation: The array represents the integer 123. 12345678910111213class Solution: def plusOne(self, digits: List[int]) -&gt; List[int]: n = len(digits) for i in range(n-1,-1,-1): digits[i] += 1 if digits[i] &lt; 10: return digits digits[i] = 0 if digits[0] == 0: digits.append(0) for j in range(n,0,-1): digits[j] = digits[j-1] digits[0] = 1 return digits Ê≤°Âï•Â•ΩÂ§öËØ¥ÁöÑÔºåÊâÄÊúâÊÉÖÂÜµÈÉΩËÄÉËôë‰∫ÜÂ∞±Ë°å‰∫Ü ‰ΩÜÊòØÂÖ∂ÂÆûÔºåÂ¶ÇÊûú‰ºö‰∫ßÁîüËøõ‰ΩçÔºåÂè™ÊúâÂèØËÉΩÊòØÂõ†‰∏∫ÊúÄÂêé‰∏Ä‰ΩçÊòØ9ÔºåÊâÄ‰ª•ÊàëËøô‰∏™Âà§Êñ≠Êù°‰ª∂Á®çÂæÆÊúâ‰∏ÄÁÇπÊ≤°ÊÉ≥Ê∏ÖÊ•öÁöÑÊÑüËßâ ‰∏ãÈù¢Ëøô‰∏™ÂÜôÂá∫Êù•Êõ¥Âä†‰ºòÈõÖ12345678910111213141516class Solution: def plusOne(self, digits): """ :type digits: List[int] :rtype: List[int] """ if len(digits) == 1 and digits[0] == 9: return [1, 0] if digits[-1] != 9: digits[-1] += 1 return digits else: digits[-1] = 0 digits[:-1] = self.plusOne(digits[:-1]) return digits 258 ‰∏Ä‰∏™Êï∞Â≠óÁöÑÈÄê‰ΩçÁõ∏Âä†ÔºåÁõ¥Âà∞Â∞è‰∫é91234567891011class Solution: def addDigits(self, num: int) -&gt; int: if num &lt; 10: return num Sum = 0 for i in str(num): Sum += int(i) return self.addDigits(Sum) # if num == 0 : return 0 # else:return (num - 1) % 9 + 1 ‰∏äÈù¢ÈÇ£ÁßçÊñπÊ≥ïÊòØÊàëÂÜôÁöÑÔºåÂ§çÊùÇÂ∫¶ÊòØn ‰∏ãÈù¢ÁöÑÊñπÊ≥ïÊòØÊï∞Â≠¶ËßÑÂæãÔºåÂ§çÊùÇÂ∫¶ÊòØ1 144 Binary Tree Preorder TraversalGiven a binary tree, return the preorder traversal of its nodes‚Äô values. Example: Input: [1,null,2,3] 1 \ 2 / 3 Output: [1,2,3] Ê≥®ÊÑèÂÆ°È¢òÔºöËøôÈÅìÈ¢òÂπ∂‰∏çÊòØÊåâÂ∑¶Â∞èÂè≥Â§ßÁöÑÈ°∫Â∫èÊéíÂàóÁöÑÔºåËÄå‰∏îpreorder traversalÊåáÁöÑÂ∞±ÊòØÂÖàËÆøÈóÆrootÔºåÂÜç‰ªéÂ∑¶Âà∞Âè≥ËÆøÈóÆrootÁöÑÂ≠êËäÇÁÇπ ÈúÄË¶ÅÊ≥®ÊÑèËæìÂÖ•‰∏∫Á©∫ÁöÑÊÉÖÂÜµ recursiveÂíåiterateÈÉΩÂèØ‰ª•ÂÆåÊàê Âú®recursiveÈáåÈù¢ÔºåÂõ†‰∏∫ÈúÄË¶ÅÊääÂÜÖÂÆπÂÇ®Â≠òÂú®listÈáåÈù¢ÔºåÊâÄ‰ª•ÈúÄË¶ÅÊñ∞Âª∫‰∏Ä‰∏™ÂáΩÊï∞12345678910111213class Solution: def preorderTraversal(self, root: TreeNode) -&gt; List[int]: result = [] if root: self.preorder(root,result) return result def preorder(self,root,result): if root: result.append(root.val) if root.left: self.preorder(root.left,result) if root.right: self.preorder(root.right,result) 1234567891011class Solution: def preorderTraversal(self, root: TreeNode) -&gt; List[int]: stack = [root] result = [] while stack: current = stack.pop() if current: result.append(current.val) stack.append(current.right) stack.append(current.left) return result Ê≥®ÊÑèÂõ†‰∏∫ÊòØÊääÂÜÖÂÆπÊîæÂú®stackÈáåÈù¢ÔºåÊâÄ‰ª•Ë¶ÅÂÖàÊîærightÊâçËÉΩËÆ©‰ªñÂêéÂá∫Êù• ÈúÄË¶ÅÂà§Êñ≠currentÊòØ‰∏çÊòØ‰∏∫Á©∫ popÈªòËÆ§ÁöÑÂ∞±ÊòØÊúÄÂêé‰∏Ä‰Ωç 145 Binary Tree Postorder Traversal Âíå‰∏ä‰∏ÄÈÅìÈ¢òÂèçÂ∫è Ê≥®ÊÑèËôΩÁÑ∂ÊòØpostÔºå‰ΩÜÊòØËøòÊòØÈúÄË¶ÅÂÖàËÆøÈóÆÂ∑¶childÔºåÂÜçËÆøÈóÆÂè≥child 1234567891011121314class Solution: def postorderTraversal(self, root: TreeNode) -&gt; List[int]: res = [] if root: self.post(root,res) return res def post(self,root,res): if root.left: self.post(root.left,res) if root.right: self.post(root.right,res) if root: res.append(root.val) 1234567891011class Solution: def postorderTraversal(self, root: TreeNode) -&gt; List[int]: stack = [root] res = [] while stack: current = stack.pop() if current: res.append(current.val) stack.append(current.left) stack.append(current.right) return res[::-1] iterativeÁöÑÊñπÊ≥ïÂèØ‰ª•ÈááÁî®ÂÖàÂ§ÑÁêÜÂè≥ËæπÁöÑÁÇπÔºåÂÜçÂ§ÑÁêÜÂ∑¶ËæπÁöÑÁÇπ„ÄÇÂõ†‰∏∫Âè≥ËæπÁöÑÂêéÊîæËøõstackÊâÄ‰ª•ÂÖàÂá∫Êù•ÂÖàËøõresÈáåÈù¢ ÊúÄÂêéÂÜçÊääÁªìÊûúÂÄíÂ∫èÔºàÁâõÈÄºÔºâ 102Given a binary tree, return the level order traversal of its nodes‚Äô values. (ie, from left to right, level by level). For example:Given binary tree [3,9,20,null,null,15,7], 3 / \ 9 20 / \ 15 7return its level order traversal as:[ [3], [9,20], [15,7]] 12345678910111213141516171819202122232425262728293031323334# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def levelOrder(self, root: TreeNode) -&gt; List[List[int]]:# self.levels = []# self.find(root,0)# return self.levels # def find(self,node, level):# if node:# if len(self.levels) &lt;= level:# self.levels += [[node.val]]# else:# self.levels[level] += [node.val]# self.find(node.left, level + 1)# self.find(node.right,level + 1) if not root: return [] stack, queue, nCount, res = [root],[],1,[[root.val]] while stack: temp = stack.pop(0) if temp.left: stack.append(temp.left) if temp.right: stack.append(temp.right) nCount -= 1 if nCount == 0: queue = [x.val for x in stack] if queue: res += [queue] nCount = len(stack) #ÂæóÂà∞ÁöÑÊòØ‰∏ã‰∏ÄÂ±ÇÁöÑ‰∏™Êï∞ return res ‰∏§ÁßçÊñπÊ≥ïÔºåÈáçÁÇπÊòØÊâæÂà∞Â¶Ç‰ΩïÈáçÊñ∞ËÆ°Êï∞levelÁöÑÂ±ÇÁ∫ßÔºåÁ¨¨‰∏ÄÁßçÊñπÊ≥ï‰∏çÊòØÈ°∫ÁùÄ‰∏ÄÊ≠•‰∏ÄÊ≠•ÂÜôËøõÁªìÊûúÈáåÁöÑÔºåÊòØË∑≥ÁùÄÂÜôËøõÂéªÁöÑ„ÄÇÁ¨¨‰∫å‰∏™ÊñπÊ≥ïÊòØÁõ¥Êé•ÂÜôËøõÂéªÁöÑ 103 ÊääÊ†ëÊåâÂ±ÇzigzagÊéíÂàóGiven a binary tree, return the zigzag level order traversal of its nodes‚Äô values. (ie, from left to right, then right to left for the next level and alternate between). For example:Given binary tree [3,9,20,null,null,15,7], 3 / \ 9 20 / \ 15 7return its zigzag level order traversal as:[ [3], [20,9], [15,7]]12345678910111213141516171819class Solution: def zigzagLevelOrder(self, root: TreeNode) -&gt; List[List[int]]: if not root: return [] levels = [] self.Find(root,0,levels) return levels def Find(self, node, level, levels): if node: if len(levels) &lt;= level: levels.append([node.val]) elif level%2: levels[level].insert(0,node.val) elif not level%2: levels[level].append(node.val) self.Find(node.left,level+1,levels) self.Find(node.right,level+1,levels) Áõ¥Êé•Âà§Êñ≠Â±ÇÊï∞Â∞±ÂèØ‰ª•ÂÆûÁé∞ÔºåÂ¶ÇÊûúÁî®‰∏Ä‰∏™flagË°®Á§∫Ê≤°Ê≥ïÂú®‰∏ÄÊï¥Â±ÇÁöÑÂ±ÇÈù¢‰∏äÂÆûÁé∞ listÊòØÂèØ‰ª•‰∏§Á´ØÊèíÂÖ•ÁöÑ 100 Âà§Êñ≠‰∏§‰∏™treeÊòØ‰∏çÊòØ‰∏ÄÊ†∑ÁöÑ12345678910111213141516171819class Solution: def isSameTree(self, p: TreeNode, q: TreeNode) -&gt; bool: # if (not p and q) or (not q and p): # return False # if p and q: # if p.val != q.val: return False # else: # return self.isSameTree(p.left,q.left) and self.isSameTree(p.right,q.right) # return p == q # if p and q: # return p.val == q.val and self.isSameTree(p.left,q.left) and self.isSameTree(p.right,q.right) # return p == q if p and q: if p.val != q.val: return False return self.isSameTree(p.left,q.left) and self.isSameTree(p.right,q.right) return p == q ÊÑüËßâËá™Â∑±ÂÜôrecursiveÊÄªÊòØÊúâÁÇπÈóÆÈ¢òÔºåÈúÄË¶ÅÂà§Êñ≠Â•ΩÁªàÊûÅÊù°‰ª∂ 226 Êää‰∏Ä‰∏™‰∫åÂèâÊ†ëÂØπÁß∞ÂèòÊç¢123456789101112131415# ‰∏çÈúÄË¶ÅÂèòÊç¢Ê†ëÁöÑvalÔºåÂèØ‰ª•Áõ¥Êé•ÂèòÊç¢nodeclass Solution: def invertTree(self, root: TreeNode) -&gt; TreeNode: # def invert(L,R): # if L and R: # L.val, R.val = R.val, L.val # invert(L.left,R.right) # invert(L.right,R.left) if root: invert = self.invertTree root.right, root.left = invert(root.left), invert(root.right) return root ÈúÄË¶ÅÊç¢nodeËÄå‰∏çÊòØÊç¢val 257Given a binary tree, return all root-to-leaf paths. Note: A leaf is a node with no children. Example: Input: 1 / \2 3 \ 5 Output: [‚Äú1-&gt;2-&gt;5‚Äù, ‚Äú1-&gt;3‚Äù] Explanation: All root-to-leaf paths are: 1-&gt;2-&gt;5, 1-&gt;312345678910111213141516class Solution: def binaryTreePaths(self, root: TreeNode) -&gt; List[str]: if not root: return [] stack = [(root,"")] result = [] while stack: current,ls = stack.pop() if not current.left and not current.right: result.append(ls+str(current.val)) if current.right: stack.append((current.right,ls+str(current.val)+"-&gt;")) if current.left: stack.append((current.left,ls+str(current.val)+"-&gt;")) return result dfsÁöÑÊñπÊ≥ïÔºåÁªàÊ≠¢Êù°‰ª∂ÊòØÁé∞Âú®ÁöÑÁÇπÊ≤°Êúâ‰ªª‰Ωïchild‰∫Ü„ÄÇËá™Â∑±ÊêûÈîôÁöÑÂú∞Êñπ‰∏ªË¶ÅÊòØÈúÄË¶ÅstringË∑üÁùÄstack‰∏ÄËµ∑Ëµ∞ÔºåËÄå‰∏çÊòØ‰∏§‰∏™ÂàÜÂà´Âà§Êñ≠„ÄÇ ÂêåÊ†∑ÁöÑÂà∞Â∫ïÂèØ‰ª•ÂÜôÂá∫Êù•Á¨¨112È¢òÔºåÊú¨Ë¥®‰∏äÊòØ‰∏ÄÊ†∑ÁöÑÔºåÂ∞±ÊòØÊääÊ±ÇË∑ØÂæÑÊç¢Êàê‰∫ÜËøô‰∏™Ë∑ØÂæÑÁöÑÂíå ÂêåÁêÜÂÜôÂá∫Êù•113ÔºåÂú®tupleÈáåÈù¢ÂÜçÂä†‰∏äË∑ØÂæÑÁöÑËÆ°ÁÆóÂ∞±ÂèØ‰ª•‰∫Ü 129‰πüÂêåÁêÜÔºÅ‰ΩÜÊòØ129ÂèØ‰ª•Áõ¥Êé•Âú®ÊØèÊ¨°recursionÈáåÈù¢Êää‰∏ä‰∏Ä‰ΩçÊï∞‰πò10ÔºåÁÑ∂ÂêéÂä†‰∏äËøô‰∏Ä‰ΩçÊï∞ÔºåËøôÊ†∑‰ºöÊØîÂæóÂà∞ÊâÄÊúâË∑ØÂæÑÂÜçËÆ°ÁÆóÁöÑÈÄüÂ∫¶Âø´ÂæàÂ§ö 111 ÊâæÂá∫Ëøô‰∏™treeÁöÑÊúÄÂ∞èdepth ÂèØ‰ª•Áî®BFS‰πüÂèØ‰ª•Áî®DFSÔºå‰ΩÜÊòØÊ≥®ÊÑèÁöÑÊòØ‰∏§‰∏™returnÁöÑ‰∏úË•øÁöÑÊù°‰ª∂ÊòØ‰∏ç‰∏ÄÊ†∑ÁöÑ„ÄÇDFSÁöÑÊó∂ÂÄôÂøÖÈ°ªÊääÂ∑¶Âè≥Ê†ëÊØîÂ§ßÂ∞è123456789101112131415161718class Solution: def minDepth(self, root: TreeNode) -&gt; int: if not root: return 0 # stack = [(root,1)] # while stack: # current,depth = stack.pop(0) # if not current.left and not current.right: # return depth # if current.left: # stack.append((current.left,depth+1)) # if current.right: # stack.append((current.right,depth+1)) # dfs if root.left is None or root.right is None: return max(self.minDepth(root.left),self.minDepth(root.right))+1 else: return min(self.minDepth(root.left),self.minDepth(root.right))+1 104 ÂØªÊâæÊúÄÊ∑±ÁöÑÂ±Ç ‰∏çÁî®Âà§Êñ≠Êù°‰ª∂ÔºåÁõ¥Êé•dfsÊØèÊ¨°Âä†‰∏ÄÂ∞±ÂèØ‰ª•ÂÆûÁé∞‰∫Ü12345class Solution: def maxDepth(self, root: TreeNode) -&gt; int: if not root: return 0 # if not root.left and not root.right: return max(self.maxDepth(root.left),self.maxDepth(root.right)) + 1 110 Âà§Êñ≠ÊòØ‰∏çÊòØÂπ≥Ë°°Ê†ë recursionÁöÑÊñπÊ≥ïÔºåÊ≥®ÊÑèÁöÑÊòØÊØèÊ¨°ËøîÂõûÁöÑÊó∂ÂÄôËøûÂ∏¶ÁùÄÂ≠êÊ†ëÊòØÂê¶Âπ≥Ë°°‰∏ÄËµ∑ËøîÂõûÁöÑÔºåÊï¥‰ΩìÊÄùË∑ØÂíå‰πãÂâçÁöÑÂ∏¶ÁùÄÊ∑±Â∫¶‰∏ÄËµ∑ËøîÂõûÁöÑÊÑüËßâÂ∑Æ‰∏çÂ§ö ÊàñËÄÖ‰πüÂèØ‰ª•Áõ¥Êé•ËÆæÁΩÆ‰∏Ä‰∏™ÂáΩÊï∞ÔºåËÆ°ÁÆóÂá∫ÂêÑ‰∏™ÈÉ®ÂàÜÁöÑheightÔºåÁÑ∂ÂêéÂÜçÊîæÂà∞isBalanceÈáåÈù¢‰ªé‰∏äÂà∞‰∏ãËÆ°ÁÆó123456789class Solution: def isBalanced(self, root: TreeNode) -&gt; bool: return self.dfs(root)[1] def dfs(self,root): if not root: return (0, True) #depth, if_balance l_depth, l_balance = self.dfs(root.left) r_depth, r_balance = self.dfs(root.right) return max(l_depth,r_depth)+1, l_balance and r_balance and abs(l_depth-r_depth) &lt;= 1 337/213ÈÉΩÊòØË¥ºÂÅ∑‰∏úË•øÔºå‰∏çËÉΩËøûÁùÄÂÅ∑‰∏§ÂÆ∂„ÄÇÁÆÄÂçïÁöÑÂä®ÊÄÅËßÑÂàíÈóÆÈ¢ò„ÄÇËøô‰∏™ÈóÆÈ¢òÁöÑ‰∏ªË¶ÅÊÄùË∑ØÂ¶Ç‰∏ãÔºö ÂØπ‰∫éÊØè‰∏ÄÂÆ∂ÔºåÂÖ∂ÂÆûÈÉΩÊúâ‰∏§ÁßçÊÉÖÂÜµÔºöÂÅ∑ËøôÂÆ∂Âíå‰∏çÂÅ∑ËøôÂÆ∂ÊÉÖÂÜµ‰∏ãÂæóÂà∞ÁöÑÈí± ÂÅ∑ËøôÂÆ∂ÁöÑÊó∂ÂÄôÔºåÂÅ∑Âà∞ÁöÑÈí±Á≠â‰∫éÔºöËøôÂÆ∂ÁöÑÈí±+Ââç‰∏ÄÂÆ∂ÔºàchildnodeÔºâ‰∏çÂÅ∑Êó∂ÂÄôÂæóÂà∞ÁöÑÈí± ‰∏çÂÅ∑ËøôÂÆ∂ÁöÑÊó∂ÂÄôÔºåÂÅ∑Âà∞ÂæóÈí±Á≠â‰∫éÔºömaxÔºàÂÅ∑Ââç‰∏ÄÂÆ∂Ôºå‰∏çÂÅ∑Ââç‰∏ÄÂÆ∂Ôºâ Ê≥®ÊÑèËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÂâç‰∏ÄÂÆ∂ÂèØ‰ª•ÂÅ∑ÂèØ‰ª•‰∏çÂÅ∑ÔºåÂèñÂÜ≥‰∫éÊúâÂ§öÂ∞ëÈí±‰∏â‰∏™È¢òÂ¶Ç‰∏ãÔºö ÊúÄÁÆÄÂçïÁöÑÊÉÖÂÜµÊòØÊï∞ÁªÑ ‰∏≠Á≠âÊÉÖÂÜµÊòØ‰∏Ä‰∏™ÁéØÔºåÂç≥Êï∞ÁªÑÁöÑÊî∂Â∞æ‰∏çËÉΩËøûÁùÄÂÅ∑„ÄÇÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÂÖ∂ÂÆûÂ∞±ÊòØËÆ°ÁÆó‰∏§Ê¨°Ôºå‰∏ÄÊ¨°‰∏çÂÅ∑Á¨¨‰∏ÄÂÆ∂Ôºå‰∏ÄÊ¨°‰∏çÂÅ∑ÊúÄÂêé‰∏ÄÂÆ∂ÔºåÁúãÂì™ÁßçÊÉÖÂÜµÂ§ö ÊúÄÂêéÁöÑÊÉÖÂÜµÊòØ‰∫åÂèâÊ†ëÁöÑÊÉÖÂÜµÔºåËøôÁßçÊÉÖÂÜµ‰∏ãÂèØ‰ª•ÁªôÊØè‰∏™ÁÇπÈÉΩËßÑÂÆö‰∏Ä‰∏™tupleÂàÜÂà´Ë°®Á§∫ÂÅ∑‰∫ÜÂíåÊ≤°ÂÅ∑ÁöÑÁªìÊûú 1234567891011class Solution: #Á¨¨‰∫åÁßçÊÉÖÂÜµ‰∏ã def rob(self, nums: List[int]) -&gt; int: if len(nums) == 0: return 0 if len(nums) == 1: return nums[0] return max(self.simple_rob(nums[1:]),self.simple_rob(nums[:-1])) def simple_rob(self,nums): rob,not_rob = 0,0 for n in nums: rob,not_rob = not_rob+n, max(not_rob,rob) return max(rob,not_rob) 12345678910class Solution: #Á¨¨‰∏âÁßçÊÉÖÂÜµ‰∏ã def rob(self, root: TreeNode) -&gt; int: return max(self.dfs(root)) def dfs(self,root): if not root: return (0,0) # [0]steal this node, [1] don't steal this node left = self.dfs(root.left) right = self.dfs(root.right) return (root.val + left[1] + right[1],max(left[0],left[1]) + max(right[0],right[1])) 235 Lowest Common Ancestor of a Binary Search Tree ÊâæÂà∞ÁªôÁöÑ‰∏§‰∏™ÁÇπÁöÑÊúÄ‰ΩéÁöÑÂÖ¨ÂÖ±ÁöÑÁ•ñÂÖàÔºàparentÔºâ ÂÖ∂ÂÆûÈúÄË¶ÅÊ≥®ÊÑèËøô‰∏™ÊÄùË∑ØÔºåÊÄùË∑ØÂ∞±ÊòØÂΩìËøô‰∏§‰∏™ÁÇπÈÉΩÊØîÁé∞Âú®ÁöÑrootÂ∞èÁöÑÊó∂ÂÄôÔºåÈÇ£Ëøô‰∏™ÂÖ¨ÂÖ±ÁÇπÂú®rootÁöÑÂ∑¶ËæπÔºåÂ¶ÇÊûúÈÉΩÂ∞èÁöÑÊó∂ÂÄôÂ∞±Âú®Âè≥Ëæπ„ÄÇ Âõ†‰∏∫ËøôÈáåË¶ÅÊâæÁöÑÊòØÊúÄlowÁöÑÂÖ¨ÂÖ±ÁÇπÔºå‰πüÂ∞±ÊòØÁ¶ªrootÊúÄËøúÁöÑÁÇπ 123456789class Solution: def lowestCommonAncestor(self, root: 'TreeNode', p: 'TreeNode', q: 'TreeNode') -&gt; 'TreeNode': if not root or not p or not q: return None if max(p.val,q.val) &lt; root.val: return self.lowestCommonAncestor(root.left,p,q) if min(p.val,q.val) &gt; root.val: return self.lowestCommonAncestor(root.right,p,q) return root 236 ‰æùÁÑ∂ÊòØÊâæÂÖ¨ÂÖ±Á•ñÂÖàÔºå‰ΩÜÊòØ‰∏çÊòØÂú®BSTÈáåÈù¢ÊâæËÄåÊòØÊôÆÈÄöÁöÑ‰∫åÂèâÊ†ëÈáåÈù¢Êâæ‰∫ÜÔºåÊâÄ‰ª•‰πüÂ∞±ÊòØ‰∏çËÉΩÁî®BSTÁöÑÊÄßË¥®‰∫Ü123456789class Solution: def lowestCommonAncestor(self, root: 'TreeNode', p: 'TreeNode', q: 'TreeNode') -&gt; 'TreeNode': if root is None or root==p or root ==q: return root left = self.lowestCommonAncestor(root.left,p,q) right = self.lowestCommonAncestor(root.right,p,q) if left and right: return root return left or right 108 Convert Sorted Array to Binary Search Tree Ê≥®ÊÑèÔºåÂ∑≤ÁªèÁªô‰∫ÜÊéíÂ•ΩÂ∫èÁöÑarray‰∫ÜÔºåËÄå‰∏îÈúÄË¶ÅÁöÑÁªìÊûúÊòØheight-balanceÁöÑÔºåËøôÈáåÂèØ‰ª•Áõ¥Êé•ÂèñËøô‰∏™arrayÊúÄ‰∏≠Èó¥ÁöÑ‰Ωú‰∏∫rootÔºåÁÑ∂ÂêéÂ∑¶Âè≥ÂàÜÂà´recursion Â¶ÇÊûúÁî®Âπ≥Â∏∏ÁöÑÊèíÂÖ•ÊñπÊ≥ïÔºåÊèíÂÖ•ËøõÊù•ÁöÑÊ†ë‰∏ç‰∏ÄÂÆöÊòØÂπ≥Ë°°ÁöÑ12345678910class Solution: def sortedArrayToBST(self, nums: List[int]) -&gt; TreeNode: if not nums: return None mid = len(nums) // 2 root = TreeNode(nums[mid]) root.left = self.sortedArrayToBST(nums[:mid]) root.right = self.sortedArrayToBST(nums[mid+1:]) return root 77 ÂõûÊ∫ØÊ≥ïÔºåÂàó‰∏æÊâÄÊúâÁªÑÂêà ÂõûÊ∫ØÊ≥ïÈúÄË¶ÅÊ≥®ÊÑè‰∏â‰∏™Èò∂ÊÆµ ÂèØ‰ª•ÈÄâÊã©ÁöÑÊù°‰ª∂ÊòØ‰ªÄ‰πàÔºàÈúÄË¶ÅÂú®Ëøô‰∫õÊù°‰ª∂ÈáåËø≠‰ª£) ÂØπÊù°‰ª∂ÁöÑÈôêÂà∂ÊòØ‰ªÄ‰πà„ÄÇÊØîÂ¶ÇÂú®Ëøô‰∏™‰æãÂ≠êÈáåÈù¢ÔºåÂ¶ÇÊûú‰∏Ä‰∏™Êï∞Â≠óÁî®Ëøá‰∫ÜÂ∞±‰∏çËÉΩÂÜçÁî®‰∫Ü„ÄÇ‰∏çËÉΩÂÆûÁé∞ÊàñËÄÖÂ∑≤ÁªèÂÆûÁé∞ÁöÑÊù°‰ª∂ÈúÄË¶ÅÂºπÂá∫ ÁõÆÊ†áÔºöÈúÄË¶ÅÂæóÂà∞‰∏Ä‰∏™base case„ÄÇÊØîÂ¶ÇËøô‰∏™È¢òÈáåÈù¢ÔºåÂ≠óÁ¨¶‰∏≤ÁöÑÈïøÂ∫¶Âà∞‰∫ÜkÔºåÂ∞±ÈúÄË¶ÅËæìÂÖ•‰∫Ü Áî®‰∫éÈóÆÈ¢òÁßçÁ±ªÔºöËÆ°ÁÆóÊàñËÄÖÂàó‰∏æÂÖ®ÈÉ®ÁöÑÂèØËÉΩ ËøôÈÅìÈ¢òÁöÑpythonÁöÑÈóÆÈ¢òÔºåÂú®listÈáåÈù¢append‰πãÂêépopÊòéÊòæ‰ºöÂá∫Áé∞‰∏Ä‰∫õÈóÆÈ¢ò1234567891011121314151617181920class Solution: def combine(self, n: int, k: int) -&gt; List[List[int]]: all_res = [] self.search(1,n,k,[],all_res) return all_res def search(self,index,n,k,res,all_res): #start, n, choose num, all result if len(res) == k: all_res.append(res) # print(all_res) return for i in range(index,n+1): # res.append(i) # print("before",res) # print(i+1,res,all_res) self.search(i+1,n,k,res+[i],all_res) # del(res[-1]) # print("after",res) return 39 ÊâÄÊúâËÉΩÂà∞targetÊï∞Â≠óÁöÑÁªÑÂêà ÂõûÊ∫ØInput: candidates = [2,3,6,7], target = 7,A solution set is:[ [7], [2,2,3]]123456789101112131415161718class Solution: def combinationSum(self, candidates: List[int], target: int) -&gt; List[List[int]]: def solver(nums,target,index,path,res): if target &lt; 0: return if target == 0: # path.sort() # if path not in res: res.append(path) return for i in range(index,len(nums)): solver(nums,target-nums[i],i,path+[nums[i]],res) res = [] solver(candidates,target,0,[],res) return res Ê≥®ÊÑèËøôÈáåÈúÄË¶ÅÊØèÊ¨°‰ªéiÂºÄÂßãËøõË°å‰∏ã‰∏ÄËΩÆÔºå‰πüÂ∞±ÊòØÂ¶ÇÊûúÁ¨¨‰∏Ä‰∏™2ÂèØ‰ª•Âä†ËøõÂéªÔºåÁ¨¨‰∫åÊ¨°ËøòÊòØ‰ªé2ÂºÄÂßãÂæÄÈáåËØïÁùÄÂä†„ÄÇË¶ÅÊòØ2Âä†‰∏çËøõÂéª‰∫ÜÔºåÂ∞±Âè™‰ºöÂæÄ2ÂêéÈù¢ÁöÑindexËµ∞Ôºà‰πüÂ∞±ÊòØÈªòËÆ§Áªô‰Ω†ÁöÑlistÂ∑≤ÁªèÊòØÊéíÂ•ΩÂ∫èÁöÑ‰∫ÜÔºâ Êï¥‰ΩìÊÄùË∑ØÂíåÂâçÈù¢Âá†ÈÅìÈ¢òÂ∑Æ‰∏çÂ§ö„ÄÇÈáçÁÇπÂ∞±ÊòØÁ°ÆËÆ§ÂÅúÊ≠¢ÁöÑÊù°‰ª∂ÔºåÁÑ∂ÂêéÊØèÊ¨°ÂÖàÂà§Êñ≠ÂÅúÊ≠¢Êù°‰ª∂ÔºåÂ¶ÇÊûú‰∏çÁ¨¶ÂêàÂÜçËøõË°årecursion„ÄÇÊ≥®ÊÑèrecursionÁöÑÊØèËΩÆÁöÑÊù°‰ª∂Âà§ÂÆö 40 Êï∞Â≠ó‰∏çÊòØÊåâÈ°∫Â∫èÊéíÂ•ΩÁöÑ‰∫ÜÔºåÊï∞Â≠ó‰ºöÈáçÂ§çÂá∫Áé∞‰∫Ü ÊàëÈÄâÊã©ÁöÑÊñπÊ≥ïÊòØÂú®ÊØèÊ¨°Âä†ÂÖ•Êñ∞ÁöÑpath‰πãÂâçÔºåÊéíÂ∫èÔºåÁÑ∂ÂêéÊØîÂØπËøô‰∏™ÊòØÂê¶Âú®Â∑≤ÁªèÁÆóÂá∫Êù•ÁöÑÁªìÊûúÈáåÈù¢ÔºàËôΩÁÑ∂Â•ΩÂÉè‰∏çÂø´Ôºâ 123456789101112131415class Solution: def combinationSum2(self, candidates: List[int], target: int) -&gt; List[List[int]]: def solver(nums,target,index,path,res): if target &lt; 0: return if target == 0: path.sort() if path not in res: res.append(path) for i in range(index,len(nums)): solver(nums,target-nums[i],i+1,path+[nums[i]],res) res = [] solver(candidates,target,0,[],res) return res Âà´‰∫∫ÁöÑÊñπÊ≥ï‰∏ªË¶ÅÂ¢ûÂä†‰∫Ü‰∏§‰∏™Êñ∞ÁöÑÂà§Êñ≠ÔºåÁ¨¨‰∏Ä‰∏™ÊòØÂ¶ÇÊûúÂú®forÈáåÈù¢ÔºåÁé∞Âú®ÁöÑÊï∞Â≠óÂ∑≤ÁªèÊØîÈúÄË¶ÅÁöÑtargetÂ§ß‰∫ÜÔºåÈÇ£‰πàÂ∞±‰∏çÈúÄË¶ÅÁªßÁª≠ÊêúÁ¥¢ÂêéÈù¢ÊâÄÊúâÁöÑÈÉ®ÂàÜ‰∫ÜÔºàÔºüÔºâ„ÄÇÂõ†‰∏∫Áé∞Âú®ÊâÄÊúâÁöÑÊï∞Â≠óÈÉΩÊòØpositiveÁöÑ ÊúÄÈáçË¶ÅÁöÑÊòØÔºåÂ¶ÇÊûúËøô‰∏™Êï∞Â≠ó‰∏çÊòØÁ¨¨‰∏Ä‰∏™ÊîæËøõÂéªÁöÑÊï∞Â≠óÔºåÂπ∂‰∏îËøô‰∏™Êï∞Â≠óÂíå‰πãÂâçÁöÑÊï∞Â≠óÁõ∏ÂêåÔºåÈÇ£‰πàËøô‰∏™Êï∞Â≠óÂ∫îËØ•Áõ¥Êé•Ë¢´ignore 12345678910111213141516171819class Solution: def combinationSum2(self, candidates: List[int], target: int) -&gt; List[List[int]]: def solver(nums,target,index,path,res): if target &lt; 0: return if target == 0: print(path) res.append(path) for i in range(index,len(nums)): if i &gt; index and nums[i]==nums[i-1]: continue if nums[i] &gt; target: break solver(nums,target-nums[i],i+1,path+[nums[i]],res) res = [] candidates.sort() solver(candidates,target,0,[],res) return res ‰ª• 1Ôºå1Ôºå2Ôºå5Ôºå6Ôºå7Ôºå10Âáë8‰∏∫‰æãÂ≠ê ÂΩìÂèñÁ¨¨‰∏Ä‰∏™1ÁöÑÊó∂ÂÄôÔºåËÉΩÁªÑÂá∫Êù•116Ôºå125Ôºå17Ôºå‰∏â‰∏™ÁªìÊûú„ÄÇËøôÊó∂ÂÄôËøô‰∏â‰∏™ÁªìÊûúÈÉΩÂú®Á¨¨‰∏ÄÂ±ÇÁöÑi=0ÁöÑÊó∂ÂÄôÁöÑÂá∫Êù•ÁöÑÁªìÊûú„ÄÇÂΩìËøô‰∏ÄÂ±ÇÊâÄÊúâÁöÑÁªìÊûúÂèñËøá‰πãÂêéÔºåÂ∞±‰ºö‰ªéÁ¨¨‰∏Ä‰∏™1ÈÄÄÂá∫Êù•ÔºåËøõÂà∞Á¨¨‰∫å‰∏™1. ‰ΩÜÊòØÂ¶ÇÊûúÁõ¥Êé•ÁÆóÁ¨¨2‰∏™1Ôºå‰πüËÉΩÁªÑÁ≤ó125Âíå17Ôºå‰ªéÁªìÊûú‰∏äËØ¥Ëøô‰∏§‰∏™1ÊòØÈáçÂ§çÁöÑÔºåÊâÄ‰ª•‰ª£Á†ÅÂú®ËøôÈÉ®ÂàÜÁõ¥Êé•continue‰∫ÜÔºåÊ≤°ÊúâËÆ°ÁÆóÁ¨¨‰∫å‰∏™1ÔºåËÄåÊòØÁõ¥Êé•Ë∑≥Âà∞‰∫ÜÁ¨¨‰∏â‰∏™Êï∞Â≠ó2 ËøôÊ†∑ËÆ°ÁÆóÈáçÂ§çÁöÑÊñπÊ≥ïÊØîÊàëÂÜçsort‰∏ÄÊ¨°ÁÑ∂Âêésearch‰∏ÄÊ¨°Ê∂àËÄóÁöÑÊó∂Èó¥Â∞ëÂæàÂ§ö 216 ÂõûÊ∫Ø ‰ªé1-9ÈáåÈÄâk‰∏™Êï∞Â≠óÁªÑÂêàÔºåÂæóÂà∞ÁõÆÊ†áÊï∞Â≠ó ÂæàÁÆÄÂçïÔºåÊ≤°Âï•ÂèØÊêûÁöÑ1234567891011121314151617181920class Solution: def combinationSum3(self, k: int, n: int) -&gt; List[List[int]]: def Solver(nums,k,n,index,path,res): if len(path) == k: if n &lt;0: return if n == 0: res.append(path) return for i in range(index,9): if i &gt; n: break Solver(nums,k,n-nums[i],i+1,path+[nums[i]],res) nums = [i for i in range(1,10)] res = [] Solver(nums,k,n,0,[],res) return res 377 ËôΩÁÑ∂ÊîæÂú®‰∏äÈù¢ÁöÑÁ≥ªÂàóÈáå‰∫Ü‰ΩÜÊòØÊòØDPGiven an integer array with all positive numbers and no duplicates, find the number of possible combinations that add up to a positive integer target. Example: nums = [1, 2, 3]target = 4 The possible combination ways are:(1, 1, 1, 1)(1, 1, 2)(1, 2, 1)(1, 3)(2, 1, 1)(2, 2)(3, 1) Note that different sequences are counted as different combinations. Therefore the output is 7. 123456789class Solution: def combinationSum4(self, nums: List[int], target: int) -&gt; int: nums.sort() com = [1] + [0]*target for i in range(target+1): for num in nums: if num &gt; i: break com[i] += com[i-num] return com[target] 46 ÊâæÂá∫ÊâÄÊúâÁöÑÊéíÂàóÁªÑÂêàGiven a collection of distinct integers, return all possible permutations. Example: Input: [1,2,3]Output:[ [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1]] ËøôÈáåÊØè‰∏™Êï∞Â≠ó‰∏çÊ≠¢Áî®‰∏ÄÊ¨°ÔºåÊâÄ‰ª•ÈúÄË¶Å‰∏Ä‰∏™ÊñπÊ≥ïÊù•ËÆ∞ÂΩïÂ∑≤ÁªèvisitÁöÑÊï∞Â≠óÔºåÊàñËÄÖÊäänumsÁöÑÂ§ßÂ∞èÊîπÂèòÔºàÊØîÂ¶ÇÊØè‰∏ÄÊ¨°Êñ∞ËæìÂÖ•ÁöÑnumsÈÉΩË∑≥ËøáÁé∞Âú®‰ΩøÁî®ÁöÑÊï∞Â≠óÔºâ Ê≥®ÊÑèËøôÈáåÈù¢Ê≤°ÊúâÈáçÂ§çÁöÑÊï∞Â≠ó ÊàëËøô‰∏™ÊñπÊ≥ï‰πüÂèØ‰ª• 12345678910111213141516class Solution: def permute(self, nums: List[int]) -&gt; List[List[int]]: def Solver(nums,index,path,res): if len(path) == len(nums): res.append(path) return for i in nums: if i not in path: Solver(nums,i+1,path+[i],res) res = [] Solver(nums,0,[],res) return res 47Âú®‰∏äÈù¢ÁöÑÂü∫Á°Ä‰∏äÊúâ‰∫ÜÈáçÂ§çÁöÑÊï∞Â≠ó È¶ñÂÖà‰øùËØÅ‰∫ÜÊï∞ÁªÑÂøÖÈ°ªË¶ÅÊòØsortÁöÑÔºåËøôÊ†∑ÊâçËÉΩÁ°ÆÂÆöÁõ∏ÂêåÁöÑÊï∞Â≠óÊå®Âú®‰∏ÄËµ∑ Ê†∏ÂøÉÊÄùÊÉ≥Â∞±ÊòØÔºåÊØèÊ¨°ÂèñÂá∫‰∏Ä‰∏™Êï∞Â≠óÁöÑÊó∂ÂÄôÔºåÊääÂéüÊù•numsÁöÑËøô‰∏™Êï∞Áõ¥Êé•ÂéªÊéâÔºå‰∏ãÊ¨°ÂÜç‰ªé0ÂºÄÂßãÊâæÔºåËøôÊ†∑Â∞±ËÉΩÂæóÂà∞ÊâÄÊúâÁöÑÊï∞ÊçÆ‰∫Ü Âú®recursionÂà§Êñ≠Êù°‰ª∂‰∏äÔºåÂõ†‰∏∫Â∑≤ÁªèÁ°ÆÂÆö‰∫ÜÊï∞ÁªÑÊúâÂ∫èÔºåÊâÄÊúâÊØèÊ¨°ËÆ∞ÂΩï‰∏Ä‰∏™tempÔºåÊù•Ë°®Á§∫‰∏ä‰∏Ä‰∏™Êï∞Â≠óÔºåÂè™ÊúâÂΩìËøô‰∏™Êï∞Â≠ó Á¨¨‰∏ÄÊ¨°Ë¢´ÊãøÂá∫Êù•Ôºàindex==0ÔºâorËøô‰∏™Êï∞Â≠óÂíå‰∏ä‰∏Ä‰∏™Êï∞Â≠ó‰∏çÁõ∏Á≠âor‰∏ä‰∏Ä‰∏™ËøòÊ≤°ÊúâÊï∞Â≠óÁöÑÊó∂ÂÄôÔºåÊâçËÉΩËøõÂÖ•recursion12345678910111213141516class Solution: def permuteUnique(self, nums: List[int]) -&gt; List[List[int]]: def Solver(nums,temp,path,res): if len(nums) == 0: res.append(path) return for i in range(0,len(nums)): if temp is None or nums[i] != temp or i == 0: temp = nums[i] Solver(nums[:i]+nums[i+1:],temp,path+[nums[i]],res) nums.sort() res = [] Solver(nums,None,[],res) return res 60The set [1,2,3,‚Ä¶,n] contains a total of n! unique permutations. By listing and labeling all of the permutations in order, we get the following sequence for n = 3: ‚Äú123‚Äù‚Äú132‚Äù‚Äú213‚Äù‚Äú231‚Äù‚Äú312‚Äù‚Äú321‚ÄùGiven n and k, return the kth permutation sequence. Êó∂Èó¥Â§™Èïø‰∫ÜÔºå‰∏çËÉΩÁî®backtrackingÊù•ÂÅö ÊÄùË∑ØÔºåÂâçÔºàn-1ÔºâÔºÅ‰∏™Êï∞Â≠óÁöÑÂºÄÂ§¥ÊòØ1ÔºåÁÑ∂Âêén-1ÔºÅ‰∏™ÊòØ2ÔºåÁÑ∂ÂêéÊòØ3Ôºå‰ª•Ê≠§Á±ªÊé®‰∏ÄÁõ¥Âà∞ÊúÄÂêé„ÄÇÂõ†‰∏∫‰∏ÄÂÖ±n‰∏™Êï∞Â≠óÔºån-1ÔºÅxn‰πüÂ∞±ÊòØnÔºÅ‰∫Ü Âú®Á°ÆÂÆöÁ¨¨‰∏Ä‰∏™Êï∞Â≠ó‰πãÂêéÔºåÁ¨¨‰∫å‰∏™Êï∞Â≠óÁöÑÂâçn-2ÔºÅ‰∏™ÊòØ2ÔºåÁÑ∂ÂêéÊòØ3ÔºåÁÑ∂Âêé‰ª•Ê≠§Á±ªÊé®]]></content>
      <categories>
        <category>ÁÆóÊ≥ï</category>
        <category>Leetcode</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment2‰πãPytorch]]></title>
    <url>%2F2019%2F05%2F07%2FCS231nassignment2Pytorch%2F</url>
    <content type="text"><![CDATA[ËøôÈÉ®ÂàÜÈúÄË¶ÅÂú®torchÂíåTensorFlow‰∏§‰∏™frameworkÈáåÈù¢ÈÄâ‰∏Ä‰∏™„ÄÇ PyTorchWhat Âä†ÂÖ•‰∫ÜTensorÁöÑobjectÔºàÁ±ª‰ºº‰∫énarrayÔºâÔºå‰∏çÈúÄË¶ÅÊâãÂä®ÁöÑbackprop‰∫Ü Why Âú®GPU‰∏äÈù¢Ë∑ëÔºå‰∏çÈúÄË¶ÅCUDAÂ∞±ÂèØ‰ª•Âú®Ëá™Â∑±ÁöÑGPU‰∏äÈù¢Ë∑ëNN functionsÂæàÂ§ö Á´ôÂú®Â∑®‰∫∫ÁöÑËÇ©ËÜÄ‰∏äÔºÅ Âú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠Â∫îËØ•ÂÜôÁöÑÊ∑±Â∫¶Â≠¶‰π†‰ª£Á†Å Â≠¶‰π†ËµÑÊñô Justin Johnson has made an excellenttutorial for PyTorch. DetailedAPI doc If you have other questions that are not addressed by the API docs, the PyTorch forum is a much better place to ask than StackOverflow. Êï¥‰ΩìÁªìÊûÑ Á¨¨‰∏ÄÈÉ®ÂàÜÔºåÂáÜÂ§áÔºå‰ΩøÁî®dataset Á¨¨‰∫åÈÉ®ÂàÜÔºåabstraction level1ÔºåÁõ¥Êé•Âú®ÊúÄÂ∫ïÂ±ÇÁöÑTensors‰∏äÈù¢Êìç‰Ωú Á¨¨‰∏âÈÉ®ÂàÜÔºåabstraction level2Ôºånn.ModuleÂÆö‰πâ‰∏Ä‰∏™‰ªªÊÑèÁöÑNNÁªìÊûÑ Á¨¨ÂõõÈÉ®ÂàÜÔºåabstraction level3Ôºånn.SequentialÔºåÂÆö‰πâ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁ∫øÊÄßfeed - backÁΩëÁªú Á¨¨‰∫îÈÉ®ÂàÜÔºåËá™Â∑±Ë∞ÉÂèÇÔºåÂ∞ΩÈáèËÆ©CIFAR - 10ÁöÑÁ≤æÂ∫¶Â∞ΩÂèØËÉΩÈ´ò Part 1.PreparationpytorchÈáåÈù¢Êúâ‰∏ãËΩΩdatasetÔºåÈ¢ÑÂ§ÑÁêÜÂπ∂‰∏îËø≠‰ª£ÊàêminibatchÁöÑÂäüËÉΩ import torchvision.transforms as T Ëøô‰∏™ÂåÖÂåÖÊã¨‰∫ÜÈ¢ÑÂ§ÑÁêÜ‰ª•ÂèäÂ¢ûÂº∫dataÁöÑÂäüËÉΩÔºåÂú®ËøôÈáåÈÄâÊã©‰∫ÜÂáèÂéªÂπ≥ÂùáÁöÑRGBÂπ∂‰∏îÈô§‰ª•Ê†áÂáÜÂ∑Æ ÁÑ∂ÂêéÂØπ‰∏çÂêåÁöÑÈÉ®ÂàÜÂàÜÂà´ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™dataset objectÔºàËÆ≠ÁªÉÔºåÊµãËØïÔºåvalÔºâÔºåËøô‰∏™dataset‰ºöËΩΩÂÖ•‰∏ÄÊ¨°training exampleÔºåÂπ∂‰∏îÂú®DataLoaderÈÉ®ÂàÜÊûÑÂª∫minibatch 1234567891011121314151617181920212223242526272829NUM_TRAIN = 49000# The torchvision.transforms package provides tools for preprocessing data# and for performing data augmentation; here we set up a transform to# preprocess the data by subtracting the mean RGB value and dividing by the# standard deviation of each RGB value; we've hardcoded the mean and std.transform = T.Compose([ T.ToTensor(), T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])# We set up a Dataset object for each split (train / val / test); Datasets load# training examples one at a time, so we wrap each Dataset in a DataLoader which# iterates through the Dataset and forms minibatches. We divide the CIFAR-10# training set into train and val sets by passing a Sampler object to the# DataLoader telling how it should sample from the underlying Dataset.cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True, transform=transform)loader_train = DataLoader(cifar10_train, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True, transform=transform)loader_val = DataLoader(cifar10_val, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, transform=transform)loader_test = DataLoader(cifar10_test, batch_size=64) ÈúÄË¶Å‰∏Ä‰∏™ÊòØÂê¶‰ΩøÁî®GPUÁöÑflagÔºåÂπ∂‰∏îsetÂà∞true„ÄÇÂú®Ëøô‰∏™‰Ωú‰∏öÈáåÈù¢‰∏çÊòØÂøÖÈ°ªÁî®GPUË∑ëÔºå‰ΩÜÊòØÂ¶ÇÊûúÁîµËÑë‰∏çËÉΩenableCUDAÁöÑËØùÔºåÂ∞±‰ºöËá™Âä®ËøîÂõûCPUÊ®°Âºè„ÄÇ Èô§Ê≠§‰πãÂ§ñÔºåÂª∫Á´ã‰∫Ü‰∏§‰∏™global varÔºådtype‰ª£Ë°®float32Ôºådevice‰ª£Ë°®Áî®Âì™‰∏™ Âõ†‰∏∫macÊú¨Ë∫´‰∏çÊîØÊåÅCUDAÔºåËÄå‰∏îÂ•ΩÂÉèÊñ∞ÁâàÊú¨ÁöÑÁ≥ªÁªüËøò‰∏çËÉΩÂÆâË£ÖNÂç°ÁöÑÈÉ®ÂàÜÔºåÊâÄ‰ª•Áé∞Âú®Áî®ÁöÑCPU 12345678910111213USE_GPU = Truedtype = torch.float32 # we will be using float throughout this tutorialif USE_GPU and torch.cuda.is_available(): device = torch.device('cuda')else: device = torch.device('cpu')# Constant to control how frequently we print train lossprint_every = 100print('using device:', device) Part2 Barebones PyTorch ËôΩÁÑ∂ÊúâÂæàÂ§öÈ´òÂ±ÇÁöÑAPIÂ∑≤ÁªèÊúâ‰∫ÜÂæàÂ§öÂäüËÉΩÔºå‰ΩÜÊòØËøôÈÉ®ÂàÜ‰ªéÊØîËæÉÂ∫ïÂ±ÇÁöÑÈÉ®ÂàÜÊù•ËøõË°å Âª∫Á´ã‰∏Ä‰∏™ÁÆÄÂçïÁöÑfc - relu netÔºå‰∏§‰∏™‰∏≠Èó¥Â±ÇÔºåÊ≤°Êúâbias Áî®TensorÁöÑmethodÊù•ËÆ°ÁÆóforwardÔºåÂπ∂‰∏îÁî®Ëá™Â∏¶ÁöÑautogradÊù•ËÆ°ÁÆóback Â¶ÇÊûúËÆæÂÆö‰∫Ürequires_grad = TrueÔºåÈÇ£‰πàÂú®ËÆ°ÁÆóÁöÑÊó∂ÂÄô‰∏ç‰ªÖ‰ºöËÆ°ÁÆóÂÄºÔºåËøò‰ºöÁîüÊàêËÆ°ÁÆóbackÁöÑgraph if x is a Tensor with x.requires_grad == True then after backpropagation x.grad will be another Tensor holding the gradient of x with respect to the scalar loss at the end PyTorch Tensors: Flatten Function TensorsÊòØ‰∏Ä‰∏™ÂíånarrayÂæàÂÉèÁöÑ‰∏úË•øÔºåÂÆö‰πâ‰∫ÜÂæàÂ§öÊØîËæÉÂ•ΩÁî®ÁöÑÂäüËÉΩÔºåÊØîÂ¶ÇflattenÊù•reshape image data Âú®TensorÈáåÈù¢‰∏Ä‰∏™ÂõæÁâáÁöÑÂΩ¢Áä∂ÊòØNxCxHxW datapointÁöÑÊï∞Èáè channels feature mapÁöÑHÂíåW ‰ΩÜÊòØÂú®affineÈáåÈù¢Êàë‰ª¨Â∏åÊúõ‰∏Ä‰∏™datapointÂèØ‰ª•Ë°®Áé∞Êàê‰∏Ä‰∏™ÂçïÁã¨ÁöÑvectorÔºåËÄå‰∏çÊòØchannelÂíåÂÆΩÂíåÈ´ò ÊâÄ‰ª•Âú®ËøôÈáåÁî®flattenÊù•È¶ñÂÖàËØªÂèñNCHWÁöÑÊï∞ÊçÆÔºåÁÑ∂ÂêéËøîÂõûËøô‰∏™dataÁöÑviewÔºàÁõ∏ÂΩì‰∫éarrayÈáåÈù¢ÁöÑreshapeÔºåÊääÂÆÉÊîπÊàê‰∫ÜNxÔºüÔºüÔºåÂÖ∂‰∏≠ÔºüÔºüÂèØ‰ª•ÊòØ‰ªª‰ΩïÂÄºÔºâ 123456def flatten(x): N = x.shape[0] # read in N, C, H, W # "flatten" the C * H * W values into a single vector per image return x.view(N, -1) Barebones PyTorch: Two-Layer NetworkÂΩìÂÆö‰πâ‰∏Ä‰∏™ two_layer_fcÁöÑÊó∂ÂÄôÔºå‰ºöÊúâ‰∏§Â±ÇÁöÑ‰∏≠Èó¥Â∏¶reluÁöÑforwardÔºåÂú®ÂÜôÂ•Ω‰∫Üforward‰πãÂêéÈúÄË¶ÅÁ°Æ‰øùËæìÂá∫ÁöÑÂΩ¢Áä∂ÊòØÂØπÁöÑÂπ∂‰∏îÊ≤°Êúâ‰ªÄ‰πàÈóÆÈ¢ò(ÊúÄËøëÂ•ΩÂÉèÂØπËøô‰∏™Â§ßÂ∞èÂ∑≤ÁªèÊ≤°Êúâ‰ªÄ‰πàÁñëÈóÆ‰∫Ü) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import torch.nn.functional as F # useful stateless functionsdef two_layer_fc(x, params): """ A fully-connected neural networks; the architecture is: NN is fully connected -&gt; ReLU -&gt; fully connected layer. Note that this function only defines the forward pass; PyTorch will take care of the backward pass for us. The input to the network will be a minibatch of data, of shape (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units, and the output layer will produce scores for C classes. Inputs: - x: A PyTorch Tensor of shape (N, d1, ..., dM) giving a minibatch of input data. - params: A list [w1, w2] of PyTorch Tensors giving weights for the network; w1 has shape (D, H) and w2 has shape (H, C). Returns: - scores: A PyTorch Tensor of shape (N, C) giving classification scores for the input data x. """ # first we flatten the image x = flatten(x) # shape: [batch_size, C x H x W] w1, w2 = params # Forward pass: compute predicted y using operations on Tensors. Since w1 and # w2 have requires_grad=True, operations involving these Tensors will cause # PyTorch to build a computational graph, allowing automatic computation of # gradients. Since we are no longer implementing the backward pass by hand we # don't need to keep references to intermediate values. # you can also use `.clamp(min=0)`, equivalent to F.relu() x = F.relu(x.mm(w1)) x = x.mm(w2) return xdef two_layer_fc_test(): hidden_layer_size = 42 # minibatch size 64, feature dimension 50 x = torch.zeros((64, 50), dtype=dtype) w1 = torch.zeros((50, hidden_layer_size), dtype=dtype) w2 = torch.zeros((hidden_layer_size, 10), dtype=dtype) scores = two_layer_fc(x, [w1, w2]) print(scores.size()) # you should see [64, 10]two_layer_fc_test() Barebones PyTorch: Three-Layer ConvNet ‰∏ä‰∏ãËøô‰∏§‰∏™ÈÉΩÊòØÔºåÂú®ÊµãËØïÁöÑÊó∂ÂÄôÂèØ‰ª•Áõ¥Êé•pass 0Êù•ÊµãËØïtensorÁöÑÂ§ßÂ∞èÊòØ‰∏çÊòØÂØπÁöÑ ÁΩëÁªúÁöÑÁªìÊûÑ conv with biasÔºåchannel_1 filtersÔºåKW1xKH1Ôºå2 zero - padding RELU conv with biasÔºåchannel_2 filtersÔºåKW2xKH2Ôºå1 zero - padding RELU fc with biasÔºåËæìÂá∫C class Ê≥®ÊÑèÔºÅÂú®ËøôÈáåfc‰πãÂêéÊ≤°ÊúâsoftmaxÁöÑÊøÄÊ¥ªÂ±ÇÔºåÂõ†‰∏∫Âú®ÂêéÈù¢ËÆ°ÁÆólossÁöÑÊó∂ÂÄô‰ºöÊèê‰æõsoftmaxÔºåËÆ°ÁÆóËµ∑Êù•Êõ¥Âä†ÊúâÊïàÁéá Ê≥®ÊÑè2ÔºÅÂú®conv2d‰πãÂâç‰∏çÈúÄË¶ÅflattenÔºåÂú®fc‰πãÂâçÊâçÈúÄË¶Åflatten 123456789101112131415161718192021222324252627282930313233343536373839404142434445def three_layer_convnet(x, params): """ Performs the forward pass of a three-layer convolutional network with the architecture defined above. Inputs: - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images - params: A list of PyTorch Tensors giving the weights and biases for the network; should contain the following: - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights for the first convolutional layer - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first convolutional layer - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving weights for the second convolutional layer - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second convolutional layer - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you figure out what the shape should be? (N,channel_2*H*W) - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you figure out what the shape should be? (C,) Returns: - scores: PyTorch Tensor of shape (N, C) giving classification scores for x """ conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params scores = None ################################################################################ # TODO: Implement the forward pass for the three-layer ConvNet. # ################################################################################ # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x = nn.functional.conv2d(x, conv_w1, bias=conv_b1, padding=2) x = nn.functional.conv2d(F.relu(x), conv_w2, bias=conv_b2, padding=1) x = flatten(x) x = x.mm(fc_w) + fc_b scores = x # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ################################################################################ # END OF YOUR CODE # ################################################################################ return scores Barebones PyTorch: Initialization random_weight(shape) initializes a weight tensor with the Kaiming normalization method. -&gt; ‰ΩøÁî®‰∫ÜKAIMING normal zero_weight(shape) initializes a weight tensor with all zeros. Useful for instantiating bias parameters. 123456789101112131415161718192021222324252627def random_weight(shape): """ Create random Tensors for weights; setting requires_grad=True means that we want to compute gradients for these Tensors during the backward pass. We use Kaiming normalization: sqrt(2 / fan_in) """ if len(shape) == 2: # FC weight fan_in = shape[0] else: # conv weight [out_channel, in_channel, kH, kW] fan_in = np.prod(shape[1:]) # randn is standard normal distribution generator. w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in) w.requires_grad = True return wdef zero_weight(shape): return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)# create a weight of shape [3 x 5]# you should see the type `torch.cuda.FloatTensor` if you use GPU.# Otherwise it should be `torch.FloatTensor`random_weight((3, 5)) Barebones PyTorch: Check Accuracy Âú®ËøôÈÉ®ÂàÜ‰∏çÈúÄË¶ÅËÆ°ÁÆógradÔºåÊâÄ‰ª•Ë¶ÅÂÖ≥‰∏ätorch.no_grad()ÈÅøÂÖçÊµ™Ë¥π ËæìÂÖ• ‰∏Ä‰∏™DataLoaderÊù•ÁªôÊàë‰ª¨ÊÉ≥Ë¶ÅcheckÁöÑdataÂàÜÂùó ‰∏Ä‰∏™Ë°®Á§∫Ê®°ÂûãÂà∞Â∫ïÊòØ‰ªÄ‰πàÊ†∑Â≠êÁöÑmodel_fnÔºåÊù•ËÆ°ÁÆóÈ¢ÑÊµãÁöÑscores Ëøô‰∏™modelÈúÄË¶ÅÁöÑÂèÇÊï∞ Ê≤°ÊúâËøîÂõûÂÄº‰ΩÜÊòØ‰ºöprintÂá∫Êù•acc 12345678910111213141516171819202122232425262728def check_accuracy_part2(loader, model_fn, params): """ Check the accuracy of a classification model. Inputs: - loader: A DataLoader for the data split we want to check - model_fn: A function that performs the forward pass of the model, with the signature scores = model_fn(x, params) - params: List of PyTorch Tensors giving parameters of the model Returns: Nothing, but prints the accuracy of the model """ split = 'val' if loader.dataset.train else 'test' print('Checking accuracy on the %s set' % split) num_correct, num_samples = 0, 0 with torch.no_grad(): for x, y in loader: x = x.to(device=device, dtype=dtype) # move to device, e.g. GPU y = y.to(device=device, dtype=torch.int64) scores = model_fn(x, params) _, preds = scores.max(1) num_correct += (preds == y).sum() num_samples += preds.size(0) acc = float(num_correct) / num_samples print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc)) BareBones PyTorch: Training Loop Áî®stochastic gradient descent without momentumÊù•trainÔºåÂπ∂‰∏îÁî®torch.functional.cross_entropyÊù•ËÆ°ÁÆóloss ËæìÂÖ• model_fc params learning_rate Ê≤°ÊúâËæìÂá∫ ËøõË°åÁöÑÊìç‰Ωú ÊäädataÁßªÂä®Âà∞GPUÊàñËÄÖCPU ËÆ°ÁÆóscoreÂíåloss loss.backward() update paramsÔºåËøôÈÉ®ÂàÜ‰∏çÈúÄË¶ÅËÆ°ÁÆógrad BareBones PyTorch: Training a ConvNet ÈúÄË¶ÅÁΩëÁªú Convolutional layer(with bias) with 32 5x5 filters, with zero - padding of 2 ReLU Convolutional layer(with bias) with 16 3x3 filters, with zero - padding of 1 ReLU Fully - connected layer(with bias) to compute scores for 10 classes ÈúÄË¶ÅËá™Â∑±ÂàùÂßãÂåñÂèÇÊï∞Ôºå‰∏çÈúÄË¶Åtune hypers Ê≥®ÊÑè1ÔºöfcÁöÑwÁöÑÂ§ßÂ∞èÊòØD,CÔºåË∑üÊï∞ÊçÆÊó†ÂÖ≥ÈúÄË¶Å‰ªé‰∏ä‰∏ÄÂ±ÇÁöÑËæìÂá∫Ê±Ç conv‰πãÂêéÁöÑÂõæÁâáÂ§ßÂ∞è‰ªé32-&gt; 30 12345678910111213141516171819202122232425262728293031learning_rate = 3e-3channel_1 = 32channel_2 = 16conv_w1 = Noneconv_b1 = Noneconv_w2 = Noneconv_b2 = Nonefc_w = Nonefc_b = None################################################################################# TODO: Initialize the parameters of a three-layer ConvNet. ################################################################################## *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****conv_w1 = random_weight((channel_1, 3, 5, 5))conv_b1 = zero_weight(channel_1)conv_w2 = random_weight((channel_2, channel_1, 5, 5))conv_b2 = zero_weight(channel_2)fc_w = random_weight((channel_2 * 30 * 30, 10))fc_b = zero_weight(10)# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****################################################################################# END OF YOUR CODE #################################################################################params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]train_part2(three_layer_convnet, params, learning_rate) Part3 PyTorch Module API ‰∏äÈù¢ÁöÑÊâÄÊúâËøáÁ®ãÊòØÊâãÁÆóÊù•trackÊï¥‰∏™ËøáÁ®ãÁöÑÔºå‰ΩÜÊòØÂú®Êõ¥Â§ßÁöÑnetÈáåÈù¢Â∞±Ê≤°Êúâ‰ªÄ‰πàÁî®‰∫Ü nn.ModuleÊù•ÂÆö‰πâÁΩëÁªúÔºåÂπ∂‰∏îÂèØ‰ª•ÈÄâoptmiÁöÑÊñπÊ≥ï Subclass nn.Module. Give your network class an intuitive name like TwoLayerFC. __init__()ÈáåÈù¢ÂÆö‰πâËá™Â∑±ÈúÄË¶ÅÁöÑÊâÄÊúâÂ±Ç. nn.Linear and nn.Conv2d ÈÉΩÂú®Ê®°ÂùóÈáåËá™Â∏¶‰∫Ü. nn.Module will track these internal parameters for you. Refer to the doc to learn more about the dozens of builtin layers. Warning: don‚Äôt forget to call the super().__init__() first!ÔºàË∞ÉÁî®Áà∂Á±ªÔºâ In the forward() method, define the connectivity of your network. Áõ¥Êé•Áî®initÈáåÈù¢ÂàùÂßãÂåñÂ•ΩÁöÑÊñπÊ≥ïÊù•forwardÔºå‰∏çË¶ÅÂÜçforwardÈáåÈù¢Â¢ûÂä†Êñ∞ÁöÑÊñπÊ≥ï Áî®‰∏äÈù¢ÁöÑÊñπÊ≥ïÊù•ÂÜô‰∏Ä‰∏™‰∏âÂ±ÇÁöÑlayer Ê≥®ÊÑèÈúÄË¶ÅÂàùÂßãÂåñwÂíåbÁöÑÂèÇÊï∞ÔºåÁî®kaimingÁöÑÊñπÊ≥ï 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class ThreeLayerConvNet(nn.Module): def __init__(self, in_channel, channel_1, channel_2, num_classes): super().__init__() ######################################################################## # TODO: Set up the layers you need for a three-layer ConvNet with the # # architecture defined above. # ######################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** self.conv_1 = nn.Conv2d(in_channel,channel_1,5,stride=1, padding=2,bias=True) nn.init.kaiming_normal_(self.conv_1.weight) nn.init.constant_(self.conv_1.bias, 0) self.conv_2 = nn.Conv2d(channel_1,channel_2,3,stride=1, padding=1,bias=True) nn.init.kaiming_normal_(self.conv_2.weight) nn.init.constant_(self.conv_2.bias, 0) self.fc_3 = nn.Linear(channel_2 * 32 * 32 , num_classes) nn.init.kaiming_normal_(self.fc_3.weight) nn.init.constant_(self.fc_3.bias, 0) # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ######################################################################## # END OF YOUR CODE # ######################################################################## def forward(self, x): scores = None ######################################################################## # TODO: Implement the forward function for a 3-layer ConvNet. you # # should use the layers you defined in __init__ and specify the # # connectivity of those layers in forward() # ######################################################################## # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** x = self.conv_1(x) x = self.conv_2(F.relu(x)) x = flatten(F.relu(x)) x = self.fc_3(x) scores = x # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)***** ######################################################################## # END OF YOUR CODE # ######################################################################## return scoresdef test_ThreeLayerConvNet(): x = torch.zeros((64, 3, 32, 32), dtype=dtype) # minibatch size 64, image size [3, 32, 32] model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=8, num_classes=10) scores = model(x) print(scores.size()) # you should see [64, 10]test_ThreeLayerConvNet() Module API: Check Accuracy ‰∏çÁî®ÊâãÂä®passÂèÇÊï∞‰∫ÜÔºåÁõ¥Êé•Â∞±ÂèØ‰ª•ÂæóÂà∞Êï¥‰∏™netÁöÑacc Module API: Training Loop Áî®optimizerËøô‰∏™objectÊù•update weights ËæìÂÖ• model optimizer epochÔºåÂèØÈÄâ Ê≤°ÊúâreturnÔºå‰ΩÜÊòØ‰ºöÊâìÂç∞Âá∫Êù•trainingÊó∂ÂÄôÁöÑacc ÂÖ∂ÂÆûÂ∞±ÊòØËÆæÁΩÆÂ•ΩmodelÂíåoptimizerÂ∞±ÂèØ‰ª•‰∫Ü Part4 PyTorch Sequential API nn.SequentialÊ≤°Êúâ‰∏äÈù¢ÁöÑÁÅµÊ¥ªÔºå‰ΩÜÊòØÂèØ‰ª•ÈõÜÊàê‰∏äÈù¢ÁöÑ‰∏Ä‰∏≤ÂäüËÉΩ ÈúÄË¶ÅÊèêÂâçÂÆö‰πâ‰∏Ä‰∏™Âú®forwardÈáåÈù¢ËÉΩÁî®ÁöÑflatten 123456789101112131415161718192021# We need to wrap `flatten` function in a module in order to stack it# in nn.Sequentialclass Flatten(nn.Module): def forward(self, x): return flatten(x)hidden_layer_size = 4000learning_rate = 1e-2model = nn.Sequential( Flatten(), nn.Linear(3 * 32 * 32, hidden_layer_size), nn.ReLU(), nn.Linear(hidden_layer_size, 10),)# you can use Nesterov momentum in optim.SGDoptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)train_part34(model, optimizer) ÂÆûÁé∞‰∏âÂ±ÇÔºåÊ≥®ÊÑèÈúÄË¶ÅÂàùÂßãÂåñÂèÇÊï∞ ËøôÈáåÈÅáÂà∞‰∫Ü‰∏Ä‰∏™ÈóÆÈ¢òÊòØÂΩìÁî®random_weightÂÆûÁé∞ÁöÑÊó∂ÂÄôÔºåacc‰ºöÁâπÂà´‰Ωé ‰ªéËøôÈáåÂèëÁé∞ÂèØ‰ª•ÈáçÊñ∞ÂÆö‰πâÂè¶‰∏Ä‰∏™ËÆ°ÁÆóÊñπÊ≥ï‰∏çÂêåÁöÑweights ‰ªéËøôÈáåÂæóÁü•Â¶Ç‰ΩïÁªômoduleÂ¢ûÂä†Êñ∞ÁöÑfunction 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657def xavier_normal(shape): """ Create random Tensors for weights; setting requires_grad=True means that we want to compute gradients for these Tensors during the backward pass. We use Xavier normalization: sqrt(2 / (fan_in + fan_out)) """ if len(shape) == 2: # FC weight fan_in = shape[1] fan_out = shape[0] else: fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW] fan_out = shape[0] * shape[2] * shape[3] # randn is standard normal distribution generator. w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / (fan_in + fan_out)) w.requires_grad = True return wchannel_1 = 32channel_2 = 16learning_rate = 1e-2model = Noneoptimizer = None################################################################################# TODO: Rewrite the 2-layer ConvNet with bias from Part III with the ## Sequential API. ################################################################################## *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****model = nn.Sequential( nn.Conv2d(3, channel_1,5,stride = 1,padding = 2), nn.ReLU(), nn.Conv2d(channel_1, channel_2,3,stride = 1,padding = 1), nn.ReLU(), Flatten(), nn.Linear(32*32*channel_2, 10),)def init_weights(m): print(m) if type(m) == nn.Linear: m.weight.data = xavier_normal(m.weight.size()) m.bias.data = zero_weight(m.bias.size())model.apply(init_weights)optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****################################################################################# END OF YOUR CODE ################################################################################train_part34(model, optimizer) Part5 Êù•ËÆ≠ÁªÉCIFAR-10ÂêßÔºÅËá™Â∑±ÊâænetÁöÑÁªìÊûÑÔºåhyperÔºålossÔºåoptimizersÊù•ÊääCIFAR-10ÁöÑval_accÂú®10‰∏™epoch‰πãÂÜÖÂçáÂà∞70%‰ª•‰∏äÔºÅ Layers in torch.nn package: http://pytorch.org/docs/stable/nn.html Activations: http://pytorch.org/docs/stable/nn.html#non-linear-activations Loss functions: http://pytorch.org/docs/stable/nn.html#loss-functions Optimizers: http://pytorch.org/docs/stable/optim.html ‰∏Ä‰∫õÂèØËÉΩÁöÑÊñπÊ≥ïÔºö Filter size: Above we used 5x5; would smaller filters be more efficient? Number of filters: Above we used 32 filters. Do more or fewer do better? Pooling vs Strided Convolution: Do you use max pooling or just stride convolutions? Batch normalization: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster? Network architecture: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include: [conv-relu-pool]xN -&gt; [affine]xM -&gt; [softmax or SVM] [conv-relu-conv-relu-pool]xN -&gt; [affine]xM -&gt; [softmax or SVM] [batchnorm-relu-conv]xN -&gt; [affine]xM -&gt; [softmax or SVM] Global Average Pooling: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in Google‚Äôs Inception Network (See Table 1 for their architecture). Regularization: Add l2 weight regularization, or perhaps use Dropout. ‰∏Ä‰∫õtipsÔºö Â∫îËØ•‰ºöÂú®Âá†Áôæ‰∏™iterÈáåÈù¢Â∞±ÁúãÂà∞ËøõÊ≠•ÔºåÂ¶ÇÊûúparams work well tune hyperÁöÑÊó∂ÂÄô‰ªé‰∏ÄÂ§ßÁâárangeÂíåÂ∞èÁöÑtrainÂºÄÂßãÔºåÊâæÂà∞Â•Ω‰∏Ä‰∫õÁöÑ‰πãÂêéÂÜçÂõ¥ÁªïËøô‰∏™ËåÉÂõ¥ÊâæÔºàÂ§öËÆ≠‰∏ÄÁÇπÔºâ Âú®ÊâæhyperÁöÑÊó∂ÂÄôÂ∫îËØ•Áî®val set 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647model = Noneoptimizer = None# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****channel_1 = 16channel_2 = 32channel_3 = 64channel_4 = 64fc_1 = 1024num_classes = 10model = nn.Sequential( nn.Conv2d(3, channel_1,3,stride = 1,padding = 1), nn.BatchNorm2d(channel_1), nn.ReLU(), nn.MaxPool2d(kernel_size = 2), nn.Conv2d(channel_1, channel_2,3,stride = 1,padding = 1), nn.BatchNorm2d(channel_2), nn.ReLU(), nn.MaxPool2d(kernel_size = 2), nn.Conv2d(channel_2, channel_3,3,stride = 1,padding = 1), nn.BatchNorm2d(channel_3), nn.ReLU(), nn.Conv2d(channel_3, channel_4,3,stride = 1,padding = 1), nn.BatchNorm2d(channel_4), nn.ReLU(), nn.MaxPool2d(kernel_size = 2), Flatten(), nn.Linear(4*4*channel_4, num_classes)# nn.Linear(fc_1,num_classes) )learning_rate = 1e-3optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****################################################################################# END OF YOUR CODE ################################################################################# You should get at least 70% accuracytrain_part34(model, optimizer, epochs=10) Á¨¨ÂõõÂ±ÇconvËØïËøáksize=1ÔºåÊïàÊûú‰∏çÊòØÂæàÂ•Ω BNÂ•ΩÂÉèÊïàÊûúÂæàÂ•Ω maxpoolÂ§ö‰∏Ä‰∫õÔºåËÆ°ÁÆóË¥üÊãÖÂ∞ëËÄå‰∏îÊïàÊûúÂ•ΩÂÉèÊØîËæÉÂ•Ω ÊúÄÁªàval_accÂú®77-79Â∑¶Âè≥Ôºåtest_acc = 76.22]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
        <category>CS231n‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫épythonÁîüÊàêÂä®ÊÄÅÂèòÈáèÂêç]]></title>
    <url>%2F2019%2F05%2F07%2F%E5%85%B3%E4%BA%8Epython%E7%94%9F%E6%88%90%E5%8A%A8%E6%80%81%E5%8F%98%E9%87%8F%E5%90%8D%2F</url>
    <content type="text"><![CDATA[Âä®ÊÄÅÁîüÊàêÂèòÈáèÂêçÂ¶ÇÊûúÊÉ≥Ë¶ÅÁîüÊàê‰∏ÄÁ≥ªÂàóÁöÑa0Ôºåa1Ôºå‚Ä¶.a20ËøôÁßçÂèòÈáèÂêçÔºåÁõ¥Êé•ÊâãÂÜôÂ§™È∫ªÁÉ¶‰∫Ü localslocal()Ôºå‰ª•Â≠óÂÖ∏ÁöÑÁ±ªÂûãËøîÂõûÂΩìÂâç‰ΩçÁΩÆÁöÑÂÖ®ÈÉ®Â±ÄÈÉ®ÂèòÈáè 1234arrange_list = locals()for i in range(10): arrange_list['list_' + str(i)] = [] Ë∞ÉÁî®Âä®ÊÄÅÂèòÈáèÔºåÂèØ‰ª•Áî®Â≠óÂÖ∏ÁöÑgetÊñπÊ≥ïÂæóÂà∞ÂèòÈáèÁöÑÂÄº 1234arrange_list = locals()for i in range(10): print(arrange_list.get('var'+str(i)), end = " ") Âà©Áî®execËøõË°åËµãÂÄº12for i in range(5): exec('var&#123;&#125; = &#123;&#125;'.format(i, i)) Ë∞ÉÁî®Âä®ÊÄÅÂèòÈáè12for i in range(5): exec('print(var&#123;&#125;, end = " ")'.format(i))]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Âä®ÊÄÅÁîüÊàêÂèòÈáèÂêç</tag>
        <tag>ÂèòÈáèÂêç</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫éÂ§öÁª¥Êï∞ÁªÑÁöÑËΩ¨ÁΩÆÂíåÂ¢ûÂä†Êñ∞ÁöÑÁª¥Â∫¶]]></title>
    <url>%2F2019%2F04%2F25%2F%E5%85%B3%E4%BA%8E%E5%A4%9A%E7%BB%B4%E6%95%B0%E7%BB%84%E7%9A%84%E8%BD%AC%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Âú®‰∫åÁª¥ËΩ¨ÁΩÆÁöÑÊó∂ÂÄôÔºåa[i][j] = a[j][i]Âú®Â§öÁª¥Êï∞ÁªÑËΩ¨ÁΩÆÁöÑÊó∂ÂÄôÔºåÈúÄË¶Å‰∫§Êç¢‰ªñ‰ª¨ÁöÑ‰∏ãÊ†áÊØîÂ¶ÇÂéüÊù•ÁöÑÊï∞ÁªÑÊòØ(X,Y,Z)ÔºåËΩ¨ÁΩÆ‰πãÂêéÊòØ(Z,X,Y)ËøôÊó∂ÂÄôÂ∫îËØ•Áî®ÁöÑÊòØnp.transpose(A,(2,0,1)) np.newaxis -&gt; Â¢ûÂä†Êñ∞ÁöÑÁª¥Â∫¶ÂéüÊù•ÊòØÔºà6ÔºåÔºâÁöÑÊï∞ÁªÑÔºåÂú®Ë°å‰∏äÂ¢ûÂä†Áª¥Â∫¶ÂèòÊàêÔºà1,6ÔºâÁöÑ‰∫åÁª¥Êï∞ÁªÑÔºåÂú®Âàó‰∏äÂ¢ûÂä†Áª¥Â∫¶Âèò‰∏∫(6,1)ÁöÑ‰∫åÁª¥Êï∞ÁªÑ]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>narray</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Â≠¶‰π†OpenCVÂçÅÂÖ´Á´†_Camera models & calibration]]></title>
    <url>%2F2019%2F04%2F22%2FOpenCVCameracalibration%2F</url>
    <content type="text"><![CDATA[camera models &amp; calibrationÁâ©‰Ωì‰ºöÂê∏Êî∂‰∏ÄÈÉ®ÂàÜÁöÑÂÖâÔºåÁÑ∂ÂêéÂèçÂ∞Ñ‰∏ÄÈÉ®ÂàÜÁöÑÂÖâÔºåÂèçÂ∞ÑÁöÑÂÖâÂ∞±ÊòØ‰ªñËá™Â∑±ÁöÑÈ¢úËâ≤ÔºåËøô‰∏™ÂÖâË¢´Êàë‰ª¨ÁöÑÁúºÁùõÔºàÊàñËÄÖÁõ∏Êú∫ÔºâÊé•Êî∂ÔºåÁÑ∂ÂêéÊäïÂΩ±Âà∞Êàë‰ª¨ÁöÑËßÜÁΩëËÜúÔºàÊàñËÄÖÁõ∏Êú∫ÁöÑÂõæÁâáÔºâ‰∏äÔºåËøô‰πãÈó¥ÁöÑÂá†‰ΩïÂÖ≥Á≥ªÂú®CV‰∏äÈù¢ÈùûÂ∏∏ÈáçË¶Å ÂÖ∂‰∏≠‰∏Ä‰∏™ÈùûÂ∏∏ÁÆÄÂçïÁöÑÊ®°ÂûãÂ∞±ÊòØpinhole camera model„ÄÇÂÖâÁ©øËøá‰∏ÄÈù¢Â¢ô‰∏äÁöÑ‰∏Ä‰∏™Â∞èÁöÑapertureÔºåËøô‰∏™ÊòØËøôÁ´†ÁöÑÊ®°ÂûãÁöÑÂºÄÂßãÔºå‰ΩÜÊòØÁúüÂÆûpinholeÊ®°Âûã‰∏çÊòØÂæàÂ•ΩÂõ†‰∏∫‰ªñ‰∏çËÉΩÂø´ÈÄüÊõùÂÖâÔºàËÅöÈõÜÁöÑÂÖâ‰∏çÂ§üÔºâ-&gt; ÁúºÁùõ‰ºöÊõ¥ÂéâÂÆ≥‰∏ÄÁÇπÔºå‰ΩÜÊòØlenËøò‰ºödistortÂõæÁâá„ÄÇ ËøôÁ´†ÁöÑÁõÆÁöÑÔºö Â¶Ç‰Ωïcamera calibration Á∫†Ê≠£ÊôÆÈÄöÁöÑpinholeÊ®°ÂûãÁöÑlenÁöÑÂÅèÂ∑Æ calibration‰πüÂêåÊ†∑ÊòØËé∑Âèñ‰∏âÁª¥‰∏ñÁïåÁöÑ‰∏ªË¶ÅÊñπÂºèÔºåÂõ†‰∏∫‰∏Ä‰∏™Âú∫ÊôØ‰∏ç‰ªÖ‰ªÖÊòØ‰∏âÁª¥Ôºå‰ªñ‰ª¨ËøòÊúâÁâ©ÁêÜÁöÑÁ©∫Èó¥Âíå‰ΩìÁßØÔºåÊâÄ‰ª•Ëé∑ÂèñpixelÂíå‰∏âÁª¥ËØóÂè•ÂùêÊ†áÁöÑÂÖ≥Á≥ª‰πüÂæàÈáçË¶Å 18Á´†Á∫†Ê≠£ÁöÑÊòØlenÁöÑdistortionÔºå19Á´†ÊûÑÂª∫Êï¥‰∏™3DÁöÑÁªìÊûÑ homography transform -&gt; ‰∏Ä‰∏™ÈùûÂ∏∏ÈáçË¶ÅÁöÑË¶ÅÁ¥† camera model ÊäïÂΩ±Âà∞image plane‰∏äÈù¢ÔºåÁªìÊûúÂú®Ëøô‰∏™plane‰∏äÈù¢ÊÄªÊòØÂØπÁÑ¶ÁöÑfocusÔºåÂõæÁâáÁöÑÂ§ßÂ∞èÂíåËøô‰∏™ÁÑ¶Ë∑ùÁöÑÈïøÂ∫¶ÊúâÂÖ≥ ÂØπ‰∫éÁêÜÊÉ≥ÁöÑpinholeÊù•ËØ¥Ôºåimage planeÂà∞pinholeÁöÑË∑ùÁ¶ªÂ∞±ÊòØÂáÜÁ°ÆÁöÑÁÑ¶Ë∑ù ‰ªéËøô‰∏™Âü∫Á°ÄÁöÑÊ®°Âûã‰∏ä -&gt; ÂæóÂà∞‰∏Ä‰∏™ËÆ°ÁÆóËµ∑Êù•Êõ¥Âä†ÁÆÄÂçïÁöÑÊ®°Âûã ‰∫§Êç¢pinholeÂíåprojection planeÁöÑ‰ΩçÁΩÆ Áé∞Âú®pinholeÁöÑ‰ΩçÁΩÆÂèòÊàê‰∫Üprojective planeÁöÑ‰∏≠ÂøÉ ÊØè‰∏Ä‰∏™Á¶ªÂºÄÁâ©‰ΩìË°®Èù¢ÔºàQÔºâÁöÑÂÖâÁ∫øÈÉΩÊúùÁùÄprojection centerËµ∞ Âú®Ê®™ËΩ¥ÂíåÊäïÂΩ±Èù¢‰∏äÁöÑ‰∫§ÁÇπË¢´ÂÆö‰πâ‰∏∫principal point Ëøô‰∏™Êñ∞ÁöÑÂπ≥Èù¢Âíå‰ª•ÂâçÁöÑprojectiveÂπ≥Èù¢‰∏ÄÊ†∑Ôºå‰∏äÈù¢ÊäïÂΩ±‰∏äÁöÑÁâ©‰Ωì‰πüÈÉΩÊòØÂíåÂéüÊù•‰∏ÄÊ†∑ÁöÑÂ∞∫ÂØ∏ Êç¢‰∫ÜÊ®°Âûã‰πãÂêéÊ≤°Êúâ‰∫ÜË¥üÂè∑Ôºöx/f = X/Z Âú®ÁêÜÊÉ≥ÁöÑÊ®°ÂûãÈáåÂèØËÉΩËßâÂæóËøô‰∏™principal pointÂ∞±ÊòØimageÁöÑ‰∏≠ÂøÉÔºå‰ΩÜÊòØÂÆûÈôÖ‰∏ä‰∏≠ÂøÉ‰∏ç‰ºöÂú®Ê®™ËΩ¥ÂíåÊäïÂΩ±Èù¢ÁöÑ‰∫§ÁÇπ‰∏ä ÂºïÂÖ•‰∫Ü‰∏§‰∏™Êñ∞ÁöÑÂèÇÊï∞ cx Âíå cy Ëøô‰∏§‰∏™ÂèÇÊï∞ÂÆûÈôÖ‰∏äÂ∞±ÊòØ‰∏≠ÂøÉÁÇπÁöÑÂÅèÂ∑ÆÔºàÂπ≥Èù¢‰∏äÁöÑÂÅèÂ∑ÆÔºâÔºåÊâÄ‰ª•ÂæóÂà∞ÊäïÂΩ±Âú®image plane‰∏äÈù¢ÁöÑÂÆûÈôÖÂùêÊ†áÂ¶Ç‰∏ã Âú®‰∏äÈù¢ÁöÑÂÖ¨ÂºèÈáåÈù¢Áî®‰∫Ü‰∏§‰∏™‰∏çÂêåÁöÑfÔºåfxÂíåfyÔºåËøôÊòØÂõ†‰∏∫ Âú®ÂÆûÈôÖÁöÑÂõæÁâáÈáåÊù•ËØ¥ÔºåÂÖ∂ÂÆûÊØè‰∏™ÂÉèÁ¥†Ê†º‰∏çÊòØÊ≠£ÊñπÂΩ¢ËÄåÊòØÈïøÊñπÂΩ¢ÁöÑ fx = ÂÆûÈôÖÁöÑfocal length * sxÔºàÊØè‰∏™mmÈáåÈù¢ÁöÑÂÉèÁ¥†Êï∞ÈáèÔºâ -&gt; ÊúÄÁªàÂæóÂà∞ÁöÑfxÊòØÂÉèÁ¥†Ê†º Ê≥®ÊÑèÔºö sxÂíåsyÂú®calibrationÁöÑÊó∂ÂÄôÂπ∂‰∏çËÉΩÁõ¥Êé•ÊµãÈáè physical focal length‰πü‰∏çËÉΩË¢´ÂÆûÈôÖÊµãÈáè Êàë‰ª¨Âè™ËÉΩÂæóÂà∞Ëøô‰∏§‰∏™‰∏úË•øÁöÑ‰πòÁßØÔºåf basic of projective geometry projective transform -&gt; Êääphysical worldÈáåÈù¢ÁöÑ‰∏ÄÁªÑÁÇπQiÔºàXi,Yi,ZiÔºâmapÂà∞‰∏ÄÂº†ÂõæÁâá‰∏äÈù¢(xi,yi)ÁöÑËøáÁ®ã Áî®Ëøô‰∏™‰∏úË•øÁöÑÊó∂ÂÄôÔºå‰∏Ä‰∏™ÊØîËæÉÊñπ‰æøÁöÑÊñπÊ≥ïÊòØÁî®homogeneous coordinates associ‚Äê ated with a point in a projective space of dimension n are typically expressed as an (n + 1)-dimensional vector (e.g., x, y, z becomes x, y, z, w), with the additional restric‚Äê tion that any two points whose values are proportional are, in fact, equivalent points ÊäïÂΩ±Âπ≥Èù¢‰∏äÈù¢ÁöÑÁª¥Â∫¶ÊòØ‰∏§Áª¥ÔºåÊàë‰ª¨ÂèØ‰ª•ÊääÂÆÉË°®Á§∫Êàê‰∏âÁª¥ÁöÑ‰∏úË•ø -&gt; ÊääÁé∞Âú®Â≠òÂú®Áª¥Â∫¶ÁöÑÊï∞Â≠óÈô§‰ª•Â¢ûÂä†ÁöÑÁª¥Â∫¶ÁöÑÂÄºÂ∞±ÂèØ‰ª•ÂæóÂà∞‰ª•ÂâçÁöÑÂÄº Áî®ËøôÁßçÂäûÊ≥ïÔºåÂèØ‰ª•Êää‰πãÂâçÁöÑfxÔºåfy,cx,cyÈáçÊñ∞ÁªÑÁªáÊàê‰∏Ä‰∏™Áü©ÈòµÔºöcamera intrinsics matrix ‰∏ãÈù¢Ëøô‰∏™ÂΩ¢ÂºèÈáçÊñ∞‰πòÂõûÊù•Â∞±ÊòØ‰πãÂâçÁöÑÂÖ≥Á≥ª Âú®opencvÈáåÈù¢‰πüÊúâÂæóÂà∞homogeneous coordinatesÂíåÁî±ÁªìÊûúÂèçÊé®ÂõûÊù•ÁöÑÂáΩÊï∞ Ê≥®ÊÑèÔºåÂú®pinholeÈáåÈù¢ÁöÑÊàêÂÉèÈÄüÂ∫¶ÊòØÈùûÂ∏∏ÊÖ¢ÁöÑÔºåÂ¶ÇÊûúÈúÄË¶ÅÊõ¥Âø´ÈÄüÂú∞ÂΩ¢ÊàêÂõæÁâáÔºåÊàë‰ª¨ÈúÄË¶ÅÈÄöËøálensÊù•ËÅöÁÑ¶ÈùûÂ∏∏ÂπøËåÉÂõ¥ÈáåÈù¢ÁöÑÂÖâ -&gt; ‰ΩÜÊòØÁªìÊûúÂ∞±ÊòØlens‰ºö‰∫ßÁîüdistortion Rodrigues Transform Âú®‰∏âÁª¥ÁöÑËåÉÂõ¥ÈáåÔºåÁªèÂ∏∏‰ºö‰ΩøÁî®‰∏Ä‰∏™3x3ÁöÑÁü©ÈòµÊù•Ë°®Á§∫‰∏Ä‰∏™Áâ©‰ΩìÁöÑÊóãËΩ¨ Âè™Ë¶ÅÊääÈúÄË¶ÅÊóãËΩ¨ÁöÑvector‰πò‰∏äËøô‰∏™matÂ∞±ÂèØ‰ª•ÂæóÂà∞Áõ∏Â∫îÁöÑÁªìÊûú ‰ΩÜÊòØ‰∏çÊòØÂæàÂ•ΩÁõ¥ËßÇÁöÑÂæóÂà∞Ëøô‰∏™ÊóãËΩ¨Áü©Èòµ ‰ªãÁªç‰∏ÄÁßçÂú®opencvÈáåÈù¢ÁöÑË°®Á§∫ÊñπÊ≥ï -&gt; Êõ¥ÂÆπÊòìÁõ¥ËßÇÁöÑÁêÜËß£ÊÑèÊÄù Êú¨Ë¥®‰∏äÊù•ËØ¥Â∞±ÊòØÁî®‰∏Ä‰∏™vectorË°®Á§∫ÊØè‰∏™ËßíÂ∫¶‰∏äÈúÄË¶ÅÊóãËΩ¨Â§öÂ∞ë Rodrigues TransformÊåáÁöÑÂ∞±ÊòØÁü©ÈòµË°®Á§∫Ê≥ïÂíåÂêëÈáèË°®Á§∫Ê≥ï‰πãÈó¥ÁöÑÂÖ≥Á≥ª Êï∞Â≠¶ÂéüÁêÜÔºö‰ΩôÂº¶ÂÆöÁêÜÔºüÔºàÁü•ÈÅì‰∏§‰∏™ÂêëÈáèÂèØ‰ª•Ê±ÇÂá∫Êù•‰ªñ‰ª¨‰πãÈó¥ÁöÑËßíÂ∫¶Ôºâ Ëøô‰∏§‰∏™ÂÖ≥Á≥ª‰πãÈó¥ÂèØ‰ª•ÂæàËΩªÊòìÁöÑ‰∫íÁõ∏ËΩ¨ÂåñÔºåopencvÈáåÈù¢‰πüÊúâÁõ∏Â∫îÁöÑÂ∫ì lens distortion Âú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠Âõ†‰∏∫Âà∂ÈÄ†ÁêÉÂΩ¢ÁöÑÈïúÂ§¥Êõ¥ÂÆπÊòì‰∏Ä‰∫õÔºåÂπ∂‰∏îÂæàÈöæÊµãÈáèÊòØ‰∏çÊòØÂπ≥ÁöÑÔºåÊâÄ‰ª•lensÈÉΩ‰ºö‰∫ßÁîüdistortion Âú®ËøôÈÉ®ÂàÜ‰ªãÁªç‰∫Ü‰∏§Áßç‰∏ªË¶ÅÂæódistortionÔºåhow to model radial distortion -&gt; ÈïúÁâáÁöÑÂΩ¢Áä∂‰∫ßÁîüÁöÑ tangential distortion -&gt; ÁªÑË£ÖÊï¥‰∏™Áõ∏Êú∫ÁöÑÊó∂ÂÄô‰∫ßÁîüÁöÑ radial Áõ∏Êú∫ÁöÑdistortion‰∏ÄËà¨ÈÉΩ‰ºö‰∫ßÁîüÂú®Êé•ËøëimagerËæπÁºòÁöÑÈÉ®ÂàÜÔºàfisheye effectÔºâ ËøúÁ¶ªlens‰∏≠ÂøÉÁöÑÈÉ®ÂàÜÊØîËµ∑‰∏≠ÂøÉÈÉ®ÂàÜ‰ºöÊäòÂè†Êõ¥Â§öÔºåÊâÄ‰ª•Â¶ÇÊûúÊäïÂΩ±‰∏Ä‰∏™Ê≠£ÊñπÂΩ¢ÔºåËæπÁöÑÈÉ®ÂàÜÈÉΩ‰ºöÈºìËµ∑Êù• Â¶ÇÊûúÁõ∏Êú∫ÊØîËæÉ‰æøÂÆúÁöÑËØùÔºàweb cameraÔºâÔºåÂë®Âõ¥ÁöÑÊäòÂè†‰ºöÊõ¥Â§öÔºåËÄåÂ•ΩÁöÑÁõ∏Êú∫‰ºöÊõ¥Ê≥®ÈáçÂáèÂ∞ëradial distortionÁöÑÊïàÊûú ÂØπ‰∫éËæêÂ∞ÑÁöÑÁï∏ÂèòÊù•ËØ¥Ôºådistortion‰ºöÈöèÁùÄÊé•ËøëËæπËæπËÄåÂ¢ûÂä† Âú®ÂÆûÈôÖ‰∏≠Ëøô‰∏™Áï∏ÂèòÂæàÂ∞èÔºåÊâÄ‰ª•ÂèØ‰ª•Áî®Ê≥∞ÂãíÁ∫ßÊï∞ÁöÑr=0ÈôÑËøëÂ±ïÂºÄÊù•Ëß£ÂÜ≥ ÂØπ‰∫éÊØîËæÉ‰æøÂÆúÁöÑweb cameraÔºåÂèØ‰ª•ÈÄâÁî®k1ÊàñËÄÖk2 ÂØπ‰∫éÈ±ºÁúºËøôÁßçÁï∏ÂèòÂæàÂ§ßÁöÑÔºåÂèØ‰ª•Áî®k3 Âú®distort‰πãÂêéÁöÑ‰ΩçÁΩÆÂèØ‰ª•Áî®‰ª•‰∏ãÁöÑÂÖ¨ÂºèË°®Á§∫ (x,y)ÊòØÂéüÊù•ÁöÑ‰ΩçÁΩÆÔºåcorrectedÊòØÊïôÊîøÊ≤ªÂíåÁöÑ‰ΩçÁΩÆ rÊòØÁ¶ªÂºÄ‰∏≠ÂøÉÁöÑÂçäÂæÑ tangential Âú®Âà∂ÈÄ†Áõ∏Êú∫ÁöÑÊó∂ÂÄôÔºålensÂíåimage planeÊ≤°ÊúâÂÆåÂÖ®Âπ≥Ë°åÂØºËá¥ÁöÑÔºåÊâÄ‰ª•ÊäïÂΩ±‰∏äÂéª‰ºöÊòØ‰∏Ä‰∏™Âá†‰ΩïÂèòÊç¢ Ëøô‰∏™distortionÂü∫Êú¨ÊòØÁî±‰∏§‰∏™ÂèÇÊï∞ÁªÑÊàêÔºöp1Âíåp2 ÊÄªÁªì‰∏ãÊù•ÔºåÂú®Áõ∏Êú∫ÁöÑdistortionÈáå‰∏ÄÂÖ±Êúâ‰∫î‰∏™ÂèÇÊï∞Ôºåk1k2k3p1p2ÔºåËøô‰∫î‰∏™ÂáΩÊï∞ÊûÑÊàê‰∫Ü‰∏Ä‰∏™distortion vector(5x1) ËôΩÁÑ∂Âú®ÂõæÂÉèÈáåÈù¢ËøòÊúâ‰∏Ä‰∫õÂÖ∂‰ªñÁöÑÁï∏ÂèòÔºå‰ΩÜÊòØÂõ†‰∏∫ÂΩ±ÂìçÊ≤°ÊúâËøô‰∏§‰∏™Â§ßÊâÄ‰ª•opencvÊ≤°ÊúâËÄÉËôëËøôÈÉ®ÂàÜ calibration ‰∏ä‰∏ÄÈÉ®ÂàÜÂæóÂà∞‰∫ÜÂ¶Ç‰ΩïË°®Á§∫Áõ∏Êú∫ÁöÑÂèÇÊï∞‰ª•ÂèädistortionÁöÑÂèÇÊï∞ ËøôÈÉ®ÂàÜËÄÉËôëÂ¶Ç‰ΩïËÆ°ÁÆóËøô‰∫õÂèÇÊï∞ ÂÖ∂‰∏≠‰∏Ä‰∏™ÂáΩÊï∞clibrationCamera() Áî®Áõ∏Êú∫ÂéªÁÖß‰∏Ä‰∏™Â∑≤ÁªèÁü•ÈÅìÁªìÊûÑÁöÑ‰∏úË•øÔºåÈáåÈù¢ÊúâÂæàÂ§öÂ∑≤ÁªèÂÆö‰πâÂ•Ω‰∫ÜÁöÑÁÇπ ÈÄöËøáËøô‰∏™ÂèØ‰ª•ÂæóÂà∞Áõ∏Êú∫ÁöÑÁõ∏ÂØπ‰ΩçÁΩÆÂíåËßíÂ∫¶ÔºåÂêåÊó∂‰πüÂèØ‰ª•ÂæóÂà∞intrinsic parameters Âπ≥ÁßªÁü©ÈòµÂíåÊóãËΩ¨Áü©Èòµ ÂØπ‰∫éÊØèÂº†ÁÖßÁöÑÂõæÁâáÁöÑÁâ©‰ΩìÔºåËøô‰∏™Áâ©‰ΩìÁöÑposeÂèØ‰ª•Áî®‰∏Ä‰∏™ÊóãËΩ¨Áü©Èòµ+‰∏Ä‰∏™Âπ≥ÁßªÁü©ÈòµÊèèËø∞Ôºå‰πüÂ∞±ÊòØÁî®Ëøô‰∏™Áü©ÈòµÊääÁé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑÁÇπËΩ¨ÂåñÂà∞ÊäïÂΩ±Âπ≥Èù¢‰∏ä ÊóãËΩ¨Áü©Èòµ ÊóãËΩ¨ËøêÂä®Êó†ËÆ∫Âú®Â§öÂ∞ëÁª¥ÈÉΩÂèØ‰ª•Ë¢´ÊèèËø∞‰∏∫Ôºö‰∏Ä‰∏™ÂùêÊ†áÁöÑvector‰πòÂØπÂ∫îÂ§ßÂ∞èÁöÑÊñπÈòµ -&gt; Áî®‰∏Ä‰∏™Êñ∞ÁöÑÂùêÊ†áÁ≥ªÊù•ÊèèËø∞Ëøô‰∏™ÁÇπÁöÑ‰ΩçÁΩÆ -&gt; ÂÖ∂ÂÆû‰πüÂ∞±ÊòØÊîπÊàê‰∫ÜÊûÅÂùêÊ†áÁ≥ªÔºü ‰∏âÁª¥ËåÉÂõ¥ÈáåÈù¢ÁöÑÊóãËΩ¨ÂèØ‰ª•Áî®‰∏§‰∏™ËßíÂ∫¶Ë°®Á§∫ ÁªïÁùÄxÔºåyÔºåz‰∏â‰∏™ÊñπÂêëÊóãËΩ¨ÁöÑËßíÂ∫¶‰ª•ÂèäÂØπÂ∫îÁöÑÁü©ÈòµÊòØËøô‰∏™Ê†∑Â≠êÁöÑ Ëøô‰∏â‰∏™ÊñπÂêëÁöÑR‰πòÂú®‰∏ÄËµ∑Â∞±ÊòØÊúÄÂêéÁöÑÊóãËΩ¨Áü©ÈòµRÔºå‰ΩÜÊòØËøô‰∏™ÁöÑÊñπÂêëÊòØÂèçÁùÄÁöÑÔºåÊâÄ‰ª•ËøòÈúÄË¶Å‰∏Ä‰∏™transposeËΩ¨ÂõûÊù• Âπ≥ÁßªÁü©Èòµ Âπ≥ÁßªÁü©ÈòµÁî®Êù•ÊèèËø∞ÊÄé‰πà‰ªé‰∏Ä‰∏™ÂùêÊ†áÁ≥ªÁªüshiftÂà∞Âè¶‰∏Ä‰∏™ÂùêÊ†áÁ≥ªÁªü -&gt; ‰πüÂ∞±ÊòØ‰∏Ä‰∏™‰ªéÁ¨¨‰∏Ä‰∏™ÂùêÊ†áÁ≥ªÂéüÁÇπÂà∞Á¨¨‰∫å‰∏™ÂùêÊ†áÁ≥ªÂéüÁÇπÁöÑoffset Âú®calibrationÁöÑÊó∂ÂÄôÔºåÂ∞±ÊòØ‰ªéÁâ©‰ΩìÂùêÊ†áÁ≥ªÁöÑÂéüÁÇπÂà∞‰∫ÜÁõ∏Êú∫ÂùêÊ†áÁ≥ªÁöÑÂéüÁÇπ Âπ≥ÁßªÁü©ÈòµÔºö T‚Üí = origin_object ‚àí origin_camera. ÁªºÂêà ÁªìÂêà‰∏äÈù¢‰∏§‰∏™Áü©ÈòµÊù•ËØ¥Ôºå‰ªéobject‰∏äÈù¢ÁöÑ‰∏Ä‰∏™ÁÇπÊäïÂΩ±Âà∞camera plane‰∏äÈù¢ÁöÑ‰∏Ä‰∏™ÁÇπÁöÑÂÖ≥Á≥ª‰∏∫ Pc‚Üí =R‚ãÖ(Po‚Üí ‚àíT‚Üí) Ê≥®ÊÑèÂàÜÊ∏ÖÊ•öËøôÈáåÈù¢ÁöÑÁü©ÈòµÂíåÂêëÈáè Êää‰∏äÈù¢ÁöÑËøô‰∏™ÂÖ¨ÂºèÔºåÂÜçÂä†‰∏äcameraËá™Â∑±ÁöÑintrinsic-correction„ÄÇÊï¥‰ΩìÂ∞±ÊòØopencvÈáåÈù¢ÈúÄË¶ÅÊ±ÇÁöÑÊâÄÊúâÈÉ®ÂàÜ ÊâÄÊ±ÇÂèÇÊï∞ ‰∏âÁª¥ÁöÑÊóãËΩ¨Áî®‰∏â‰∏™ËßíÂ∫¶Ë°®Á§∫Ôºå‰∏âÁª¥ÁöÑÂπ≥ÁßªÁî®‰∏â‰∏™parameterË°®Á§∫(x,y,z) -&gt; Áé∞Âú®ÂæóÂà∞‰∫Ü6‰∏™ÂèÇÊï∞ Áõ∏Êú∫ÁöÑintrinsic mat(fx,fy,cx,cy) -&gt; ‰∏ÄÂÖ±Âõõ‰∏™ÂèÇÊï∞ Áé∞Âú®‰∏ÄÂÖ±ÈúÄË¶ÅÊ±Ç10‰∏™ÂèÇÊï∞Ôºà‰ΩÜÊòØÁõ∏Êú∫ÁöÑintrinsicÊòØ‰∏çÂèòÁöÑÔºâ Ê±ÇÂèÇÊï∞ -&gt; Âú®Ê±ÇËß£ÁöÑÊó∂ÂÄôÔºåÂ¶ÇÊûú‰ΩøÁî®‰∏Ä‰∏™Âπ≥Èù¢Áâ©‰ΩìÔºåÈÇ£‰πàÊØèÂº†ÂõæÁâáÈÉΩÂèØ‰ª•ÂæóÂà∞8‰∏™ÂèÇÊï∞Ôºà‰ΩçÁΩÆÁöÑ6‰∏™‰ºöÈöèÁùÄÂõæÁâáÂèòÂåñ + Âè™ËÉΩÁî®‰∏§‰∏™ÂèÇÊï∞Êù•Ê±ÇintrinsicÔºâ Ëá≥Â∞ëÈúÄË¶Å2Âº†ÂõæÁâáÊù•ÂæóÂà∞ÊâÄÊúâÁöÑÂèÇÊï∞ calibration boards ‰ªéÂéüÂàô‰∏äÊù•ËØ¥Ôºå‰ªª‰ΩïÊúâÁâπÂæÅÁöÑ‰∏úË•øÈÉΩÂèØ‰ª•Ë¢´Áî®Êù•calibrationÔºåÂåÖÊã¨Ê£ãÁõòÔºåÂúÜÊ†ºÔºårandpatternÔºåarUcoÁ≠âÁ≠â,Êúâ‰∫õÊñπÊ≥ïÊòØÂü∫‰∫é‰∏âÁª¥ÁöÑÁâ©‰ΩìÁöÑÂü∫Á°Ä‰∏äÁöÑÔºå‰ΩÜÊòØ‰∫åÁª¥Âπ≥Èù¢ÁöÑÁâ©‰ΩìÊõ¥Â•ΩÊìç‰Ωú Âú®ËøôÈáå‰∏ªË¶ÅÈÄâÊã©ÁöÑÊòØÁî®Ê£ãÁõòËøõË°åcalibration ÂÖ≥‰∫échessboardÁöÑÂáΩÊï∞cv::findChessboardCorners() ÂèØ‰ª•Áî®Ëøô‰∏™ÂáΩÊï∞ÊâæÂà∞Ê£ãÁõòÁöÑcornersÔºå param ÈúÄË¶ÅËæìÂÖ•8bitÂõæÁâá ÈúÄË¶ÅËæìÂÖ•Ëøô‰∏™Ê£ãÁõòÊØèË°åÊØèÂàóÂ∫îËØ•ÊúâÁöÑÊ†ºÂ≠êÊï∞ÔºàËÆ°ÁÆóÁöÑÊòØÂÜÖÈÉ®ÁÇπÔºâ ËæìÂá∫ÁöÑÊòØËøô‰πàcornerÁöÑÂùêÊ†á ÂèØÈÄâflagÂÜ≥ÂÆöÈúÄ‰∏çÈúÄË¶ÅÂ§ö‰ΩôÁöÑfilter cv::cornerSubPix() ‰∏äÈù¢‰∏ÄÊ≠•ÊâæÂà∞ÁöÑÂè™ÊòØcornerÁöÑÂ§ßÊ¶Ç‰ΩçÁΩÆ Âú®find cornerÈáåÈù¢Ëá™Âä®call‰∫ÜËøô‰∏™ÂáΩÊï∞Ôºå‰∏∫‰∫ÜËÉΩÂæóÂà∞Êõ¥Á≤æÁ°ÆÁöÑÁªìÊûú Â¶ÇÊûúÈúÄË¶ÅÂæóÂà∞Êõ¥Á≤æÁ°ÆÁöÑÁªìÊûúÔºåÂèØ‰ª•ÈáçÂ§çÁöÑcallËøô‰∏™ÂáΩÊï∞Ôºå‰ΩÜÊòØ‰ºöÊúâtighter termination criteria cv::drawChessboardCorners() ‰∏∫debugÁî®ÔºåÊõ¥ÊòéÁ°ÆÁöÑÁîªÂá∫Êù•ÊâæÂà∞ÁöÑcorner Â¶ÇÊûúÊ≤°ÊúâÊâæÂà∞ÊâÄÊúâÁöÑÔºå‰ºöÊääÂÖ∂‰ªñÂèØËÉΩÁöÑÁî®Á∫¢Ëâ≤circleÁîªÂá∫Êù•ÔºåÂ¶ÇÊûúÊâæÂà∞‰∫ÜÔºåÊØè‰∏ÄË°åÁöÑÈ¢úËâ≤‰ºö‰∏ç‰∏ÄÊ†∑ ‰∏ã‰∏ÄÊ≠•ËΩ¨Âà∞perspective transformÔºåËøô‰∏™transform‰ºöÂΩ¢Êàê‰∏Ä‰∏™3x3ÁöÑhomography mat ÂÖ≥‰∫écircle gridÁöÑÂáΩÊï∞cv::findCirclesGrid() Âíå‰∏äÈù¢ÁöÑÊ£ãÁõòÊ≤°Êúâ‰ªÄ‰πàÊú¨Ë¥®ÁöÑÂå∫Âà´Ôºå‰∏ªË¶ÅÂ∞±ÊòØÁîªÂá∫Êù•‰∏Ä‰∏™ÊòØÈªëÁôΩÊ†ºÔºåÂè¶‰∏Ä‰∏™ÊòØÁôΩËâ≤ÁöÑËÉåÊôØ‰∏äÈù¢ÊúâÈªëËâ≤ÁöÑÂúÜÁÇπÔºåËæìÂá∫Â∞èÂúÜÁÇπÁöÑ‰ΩçÁΩÆ Ëøô‰∏™ÊñπÊ≥ïÈúÄË¶ÅÂúÜÁÇπÊòØÂØπÁß∞ÁöÑÔºå‰∏ä‰∏ã‰∏ÄÁªÑÁÆóÂÅö‰∏ÄË°åÔºåÁ´ñÁùÄ‰∏ÄÂàóÁÆó‰∏ÄÂàóÔºåÊÄé‰πàÊï∞ÈùûÂ∏∏ÈáçË¶Å Homography planar homographyÊòØ‰∏Ä‰∏™Âπ≥Èù¢Âà∞Âè¶‰∏Ä‰∏™Âπ≥Èù¢ÁöÑprojection mappingÔºåÊâÄ‰ª•‰ªé‰∏Ä‰∏™2DÂπ≥Èù¢Âà∞Áõ∏Êú∫Âπ≥Èù¢ÁöÑËøáÁ®ãÂ∞±ÊòØ‰∏Ä‰∏™planar homography Áî®Áü©ÈòµÁöÑ‰πòÊ≥ïÂ∞±ÂèØ‰ª•Ë°®Á§∫Ëøô‰∏™ËøáÁ®ã ÂÖ∂‰∏≠QÊòØÁé∞ÂÆû‰∏≠ÁöÑÁÇπÔºåqÊòØÊàêÂÉèÂô®‰∏äÈù¢ÁöÑÁÇπÔºåÊï¥‰ΩìÂÖ≥Á≥ª‰∏∫Ôºöq‚Üí = s ‚ãÖ H ‚ãÖ Q‚Üí sÔºå‰∏Ä‰∏™ÈöèÊÑèÁöÑscaleÂèÇÊï∞ÔºåhomographyÂ∞±ÊòØÁî±ÁùÄ‰∏Ä‰∏™ÂèÇÊï∞ÂÜ≥ÂÆöÁöÑ conventionally factored H, HÁî±‰∏§‰∏™ÈÉ®ÂàÜÁªÑÊàê physical‰∏äÈù¢ÁöÑtransformationÔºåÂÆûÈôÖÂ∞±ÊòØÊàë‰ª¨ÁúãÂà∞ÁöÑËøô‰∏™Áâ©‰ΩìÁöÑ‰ΩçÁΩÆW = [R,t‚Üí] projectionÔºåÂèñÂÜ≥‰∫éÁõ∏Êú∫ÁöÑintrinsic q‚Üí = s ‚ãÖ M ‚ãÖ W ‚ãÖ Q‚ÜíÔºåÂÖ∂‰∏≠MÊòØÁõ∏Êú∫ÁöÑintrinsic mat Êàë‰ª¨Â∏åÊúõQ‰∏çÊòØÁªôÊâÄÊúâÁ©∫Èó¥ÂÆö‰πâÁöÑÁÇπÔºåËÄåÊòØ‰∏Ä‰∏™ÂÆö‰πâÂú®Êàë‰ª¨ÁúãÁöÑÂπ≥Èù¢‰∏äÈù¢ÁöÑÂùêÊ†áÔºåËøôÊ†∑ËÆ°ÁÆóËµ∑Êù•‰ºöÊñπ‰æøÔºà‰∏âÁª¥ËΩ¨‰∫åÁª¥Ôºâ ÊâÄ‰ª•ÊääQÈáåÈù¢ÁöÑZÁöÑÂùêÊ†áÊîπÊàê‰∫Ü0ÔºåËøôÊ†∑ÊóãËΩ¨Áü©ÈòµÂ∞±‰ºöË¢´ÁÆÄÂåñ‰∏∫‰∏Ä‰∏™3x1ÁöÑÂàó Âπ∂‰∏îÁ¨¨‰∏â‰∏™Âàó‰πò‰∫ÜZÁöÑ0‰πãÂêéÂ∞±Ë¢´Ê∂àÊéâ‰∫Ü ÊúÄÂêéÂ∞±ÂèØ‰ª•ÊääHË°®Á§∫Âá∫Êù•‰∫Ü -&gt; 3x3 = intrinsic(3x3) x (rota + trans)(1x3) Âú®ËÆ°ÁÆóhomography matÁöÑÊó∂ÂÄôÔºåÁî®‰∫ÜÂ§öÂº†ÂêåÊ†∑ÂÜÖÂÆπÁöÑ‰∏úË•øÊù•ËÆ°ÁÆótranslationÂíåintrinsic ‰∏â‰∏™ÊóãËΩ¨Ôºå‰∏â‰∏™Âπ≥Áßª -&gt; ÊØèÂº†ÂõæÁâáÊúâ6‰∏™Êú™Áü•ÁöÑÂèÇÊï∞ ÊØèÂº†ÂõæÁâáÂèØ‰ª•ÂæóÂà∞8‰∏™Á≠âÂºè Êää‰∏Ä‰∏™Ê≠£ÊñπÂΩ¢mappingÊàê‰∏Ä‰∏™ÂõõËæπÂΩ¢ÂèØ‰ª•ÂæóÂà∞4‰∏™‰∏çÂêåÁöÑ(x,y) points ÊâÄ‰ª•ÊØèÂ§ö‰∏ÄÂº†ÂõæÁâáÂ∞±ÂèØ‰ª•Â§öÂá∫Êù•ËÆ°ÁÆó‰∏§‰∏™Êñ∞ÁöÑÂèÇÊï∞ÁöÑÊú∫‰ºö ËøôÊ†∑ÁúãÔºåpdst‚Üí = H * psrc‚ÜíÔºåÂèçÁùÄ‰πüÂèØ‰ª•Êé®ÂõûÊù•ÔºåËøôÊ†∑Êàë‰ª¨Â∞±ÁÆó‰∏çÁü•ÈÅìM‰πüÂèØ‰ª•ËÆ°ÁÆóHÔºåÊàñËÄÖËØ¥Êàë‰ª¨ÊòØÁî®HÊù•ËÆ°ÁÆóM Âú®opencvÈáåÈù¢Ôºåcv::findHomography()ÂèØ‰ª•Áî®take‰∏ÄÂ†ÜÊúâÂÖ≥Á≥ªÁöÑÁÇπÁÑ∂ÂêéËøîÂõû‰ªñ‰ª¨‰πãÈó¥ÁöÑhomo matÔºåÁÇπË∂äÂ§öËÆ°ÁÆóÁöÑË∂äÂáÜÁ°Æ ËôΩÁÑ∂ÊúâÂÖ∂‰ªñÁöÑÊñπÊ≥ïÂèØ‰ª•ËÆ°ÁÆóÁªìÊûúÔºå‰ΩÜÊòØÂØπÊµãÈáèËØØÂ∑Æ‰∏çÊòØÂæàÂèãÂ•Ω three robust fitting methods method to cv::RANSAC ÈöèÊú∫ÁöÑÈÄâÊã©Êèê‰æõÁöÑÁÇπÁöÑsubsetÔºåÁÑ∂ÂêéÂè™Áî®Ëøô‰∫õsubsetÊù•ËÆ°ÁÆóhomo mat ÁÑ∂ÂêéÊääÂâ©‰∏ãÁöÑÊï∞ÊçÆÊãøÊù•ËÆ°ÁÆó‰∏Ä‰∏ãÈù†Ë∞±Âíå‰∏çÈù†Ë∞±ÁöÑ ÊúÄÂêé‰øùÂ≠òÊúÄÊúâÊΩúÂäõÁöÑinliers Âú®Áé∞ÂÆû‰∏≠ÊØîËæÉÂ•ΩÁî®ÔºåÂèØ‰ª•ËøáÊª§Êéâ‰∏ÄÈÉ®ÂàÜÂô™Èü≥ LMeDS algorithm ÂáèÂ∞ëmedian error ‰∏çÈúÄË¶ÅÊõ¥Â§öÁöÑinfoÂíådataÊù•ËøêË°å ‰ΩÜÊòØit will perform well only if the inliers constitute at least a majority of the data points RHO algorithm Âä†ÊùÉÁöÑÁ¨¨‰∏ÄÁßçÊñπÊ≥ïÔºåËøêË°åÈÄüÂ∫¶Êõ¥Âø´ camera calibrationÊ£ãÁõòcorner‰∏™Êï∞ Âà∞Â∫ïÊúâÂ§öÂ∞ëÂèÇÊï∞ camera intrinsic Âõõ‰∏™ distortion‰∫î‰∏™ÔºàÊàñËÄÖÊõ¥Â§öÔºâ‰∏â‰∏™ËæêÂ∞ÑÔºàÂèØ‰ª•Â¢ûÂä†Âà∞6‰∏™Ôºâ + ‰∏§‰∏™Âπ≥Áßª Ëøô‰∫î‰∏™ÂèÇÊï∞ÊòØ‰ªé2D -&gt; 2DÁöÑ ‰∏â‰∏™corner pointsÂèØ‰ª•ÂæóÂà∞6‰∏™‰ø°ÊÅØÔºåË∂≥Â§üÂ§ÑÁêÜËøô‰∫î‰∏™ÂèÇÊï∞ ÊâÄ‰ª•‰∏ÄÂº†ÂõæÂ∞±Â§ü‰∫ÜÔºàÂè™ÊòØÂéüÂàô‰∏äËøô‰πàËØ¥Ôºâ extrinsic parametersÔºåËøô‰∏™‰∏úË•øÁöÑÂÆûÈôÖ‰ΩçÁΩÆ ‰ΩÜÊòØÂõ†‰∏∫intrinsicÂíåextrinsic‰πãÈó¥ÊúâÂØπÂ∫îÁöÑÂÖ≥Á≥ªÔºå‰∏ÄÂº†ÂõæÁâáÂπ∂‰∏çÂ§ü -&gt; Âõ†‰∏∫Âú®‰∏ÄÂº†ÂõæÁâáÈáåËøòÈúÄË¶ÅËÆ°ÁÆóextrinsicÁöÑÈÉ®ÂàÜ ÂÅáËÆæÊúâN‰∏™cornerÔºå‰∏ÄÂÖ±ÊúâK‰∏™imagesÔºà‰∏çÂêåÁöÑpositionÔºâ ‰∏ÄÂÖ±‰ºöÊúâ 2 N K‰∏™Ôºå2ÊòØx,yÁöÑÂùêÊ†á‰ºöÊúâ‰∏§‰∏™ÔºåÁÑ∂ÂêéN‰∏™cornerÔºåK‰∏™ÂõæÁâá ÊöÇÊó∂ÂøΩÁï•distortionÁöÑÂèÇÊï∞ÔºåËøôÊ†∑ÈúÄË¶Å4‰∏™inÂíå6K‰∏™exÔºàÂõ†‰∏∫ÊØèÂº†ÂõæÁâáÁöÑexÈÉΩÊòØ‰∏ç‰∏ÄÊ†∑ÁöÑÔºâ 2NK &gt;= 6K + 4 Â¶ÇÊûúN = 5ÔºåÂè™ÈúÄË¶Å‰∏ÄÂº†ÂõæÁâáÂ∞±ÂèØ‰ª•Ëß£ÂÜ≥„ÄÇ‰ΩÜÊòØ‰∏∫‰∫ÜÂæóÂà∞homo matÔºåËá≥Â∞ëÈúÄË¶Å‰∏§‰∏™K(‰πãÂâçËØ¥Âà∞ËøáÁöÑ) Êó†ËÆ∫Ê£ÄÊµãÂà∞Â§öÂ∞ëcornerÔºåÂæóÂà∞ÁöÑÊúâÁî®‰ø°ÊÅØÂ∞±ÊòØÂõõ‰∏™Ëßí -&gt; Áî±Ê≠§Êé®ÊµãËá≥Â∞ë‰∏§‰∏™K Âú®ÂÆûÈôÖÁöÑÂ∫îÁî®ÈáåÈù¢Ôºå‰∏ÄËà¨ÈúÄË¶Å7x8ÔºåËá≥Â∞ëÂçÅÂº†ÂõæÔºåËøôÊ†∑ÂèóÂà∞noiseÁöÑÂΩ±ÂìçÊõ¥Â∞è ÂÖ∑‰ΩìÁöÑÊï∞Â≠¶ËÆ°ÁÆó ‰∏∫‰∫ÜÁÆÄÂçïÔºåÈ¶ñÂÖàÂÅáËÆæÂú®calibrationÁöÑÊó∂ÂÄôÊ†πÊú¨Ê≤°Êúâdistortion ÂØπ‰∫éÊØè‰∏™viewÔºå‰ºöÂæóÂà∞‰∏Ä‰∏™Homo matÔºåÊääËøô‰∏™matÊãÜÊàê‰∏Ä‰∏™ÂàóÂêëÈáè(3x1) Âú®ÂâçÈù¢‰πüÁü•ÈÅìHÂèØ‰ª•ÊãÜÊàêMÂíå‰∏Ä‰∏™[r1,r2,t]ÁöÑÂêëÈáèÁõ∏‰πòÔºåÂÜç‰πò‰∏ä‰∏Ä‰∏™scale s H=[h1,h2,h3] =s‚ãÖM‚ãÖ[r1,r2,t],ÂÖ∂‰∏≠landaÊòØ1/s: ÊóãËΩ¨ÂêëÈáèÁöÑÂü∫Â∫ï(orthogonal)ÊòØ‰∫íÁõ∏ÂûÇÁõ¥ÁöÑÔºåÂõ†‰∏∫Â∑≤ÁªèÊääscaleËøô‰∏™ÂèÇÊï∞ÊèêÂá∫Âéª‰∫ÜÔºåÊâÄ‰ª•ÂèØ‰ª•Áõ¥Êé•ËÆ§‰∏∫r1Âíår2ÊòØÂü∫‰∫ÜÔºåËøôÊ†∑ÁöÑËØù‰ªñ‰ª¨ÁöÑÁÇπ‰πòÊòØ0 Êäär1Âíår2Áî®MÂíåhÊù•Ë°®Á§∫ÔºåËøôÊ†∑ÁöÑËØùr1r2Á≠â‰∫é0Â∞±ÂèØ‰ª•ËΩ¨ÂåñÊàê‰∏Ä‰∏™hMÁöÑÂÖ¨Âºè r1Âíår2ÁöÑÊ®°‰πüÁõ∏Á≠âÔºåÊâÄ‰ª•ÂèØ‰ª•ÁªßÁª≠ÂæóÂà∞‰∏Ä‰∏™Á≠âÂºè ËÆæÁΩÆ‰∏Ä‰∏™Áü©ÈòµBÁ≠â‰∫éM.-T * M-1ÔºåËøôÊ†∑ÂèØ‰ª•ËÆ°ÁÆóÂá∫Êù•BÁöÑÂÄº(BÁÆóÂá∫Êù•ÊòØÂØπÁß∞ÁöÑ) ÊääBÂ∏¶ÂõûÂéüÊù•ÁöÑÁ≠âÂºèÔºåÂåñÁÆÄÔºåÁÑ∂ÂêéÊääK‰∏™Á≠âÂºèÂè†Âä†Âú®‰∏ÄËµ∑ ËøôÊ†∑Â∞±ÂèØ‰ª•Êé®Âá∫Êù•Âá†‰∏™ÂèÇÊï∞ÁöÑË°®ËææÂºè calibrationÁöÑÂáΩÊï∞cv::calibrateCamera().Êù•Ëß£ÂÜ≥calibrationÁöÑÈóÆÈ¢ò ÂæóÂà∞ÁöÑÁªìÊûúÂåÖÊã¨in mat, dis_co, ÊóãËΩ¨ÂêëÈáèÂíåÂπ≥ÁßªÂêëÈáè ËæìÂá∫ÁöÑin matÁöÑÂ§ßÂ∞èÊòØ3x3 ËæìÂá∫ÁöÑdis_coÁöÑÂ§ßÂ∞èÂèñÂÜ≥‰∫éÁî®Â§öÂ∞ëÁ∫ßÁöÑdistortionÔºå‰∏ÄËà¨Êù•ËØ¥ÊòØ4Ôºå5‰∏™ÁöÑÂ∑≤ÁªèÂØπfisheyeË∂≥Â§ü‰∫ÜÔºå8‰∏™ÁöÑËØùcalibrationÁöÑÁ≤æÂ∫¶Â∞±ÁâπÂà´È´ò‰∫Ü Â¶ÇÊûúÈúÄË¶ÅÈ´òÁ≤æÂ∫¶ÁöÑcalibrationÁöÑËØùÔºåÈúÄË¶ÅÁöÑÂõæÁâáÊï∞Èáè‰πü‰ºöÁñØÁãÇÂ¢ûÂä† ËæìÂÖ•ÁöÑÈÉ®ÂàÜÂåÖÊã¨ Áâ©‰ΩìÁöÑÂùêÊ†áÔºåÊåáÁöÑÊòØÂú®chessboard‰∏äÈù¢ÁöÑÂùêÊ†áÁÇπÔºåÊòØ‰∫åÁª¥ÁöÑÁÇπÔºåÂÖ∂ÂÆû‰πüÂ∞±ÊòØÁ¨¨Âá†‰∏™Ê†ºÂ≠êÔºü Ê≥®ÊÑèËøôÈáåÔºåÁªüËÆ°ÁöÑÂçï‰ΩçÊòØÊ†ºÂ≠êÔºåÊâÄ‰ª•Â¶ÇÊûúÊÉ≥Ë¶ÅÂæóÂà∞physical‰∏äÁöÑË∑ùÁ¶ªÔºåÈúÄË¶ÅÂú®calibration board‰∏äÈáèÂá∫Êù•‰∏Ä‰∏™Ê†ºÂ≠êÁöÑÈïøÂ∫¶ÔºåÁÑ∂Âêé‰πòËøô‰∏™Ê†ºÂ≠êÁöÑÊï∞Èáè image‰∏äÈù¢ÁöÑÂùêÊ†áÔºåcorners ‰∏ÄÂè£Ê∞îËÆ°ÁÆóÊâÄÊúâÁöÑÂèÇÊï∞‰∏çÊòØÂæàÂ•ΩÂÆûÁé∞Ôºå‰∏ÄËà¨‰ΩøÁî®ÁöÑÊñπÊ≥ïÊòØÂÖàÂõ∫ÂÆö‰∏ÄÈÉ®ÂàÜËÆ°ÁÆóÂè¶‰∏ÄÈÉ®ÂàÜÔºåÁÑ∂ÂêéÂÜçÂõ∫ÂÆöÂè¶‰∏ÄÈÉ®ÂàÜËÆ°ÁÆóËøô‰∏ÄÈÉ®ÂàÜ„ÄÇÂΩìÊâÄÊúâÁöÑ‰∏úË•øÈÉΩ‰º∞ËÆ°ÁöÑÂ∑Æ‰∏çÂ§ö‰∫ÜÔºåÂÜç‰∏ÄËµ∑ËÆ°ÁÆó ÊúÄÂêéËøòÊúâ‰∏Ä‰∏™ÂèÇÊï∞ÊòØtermination criteriaÔºåÁªàÊ≠¢ÁöÑÂü∫ÂáÜ -&gt; epsilon ‰ºöÊ†πÊçÆ‰∏Ä‰∏™errorÊù•ËÆ°ÁÆóÊòØÂê¶ÁªàÊ≠¢ Âè™ËÆ°ÁÆóextrinsiccv::slovePnP() ÊúâÁöÑÊó∂ÂÄôÊàë‰ª¨Â∑≤ÁªèÂæóÂà∞‰∫ÜÁõ∏Êú∫ÁöÑintrinsicÔºåÂè™Â∏åÊúõÂæóÂà∞objectÁöÑ‰ΩçÁΩÆ Â§ßÈÉ®ÂàÜÂÜÖÂÆπÂíå‰∏äÈù¢ÈÉΩÊòØ‰∏ÄÊ†∑ÁöÑÔºåÈô§‰∫Ü Áâ©‰ΩìÁöÑ‰ΩçÁΩÆÂè™ÈúÄË¶Å‰∏Ä‰∏™view distCoÂíåintrinsicÈÉΩÊòØËá™Â∑±ËÆæÁΩÆÂ•ΩÁöÑÔºå‰∏çÈúÄË¶ÅËÆ°ÁÆó cv::solvePnPRansac() ‰∏äÈù¢ÁöÑÂáΩÊï∞ÂØπ‰∫éoutliersÁöÑrobustÊïàÊûú‰∏çÊòØÂæàÂ•ΩÔºåÂØπ‰∫échessboardÊù•ËØ¥ÔºåËøô‰∏™robust‰∏çÊòØÂæàÈáçË¶ÅÔºåÂõ†‰∏∫Ê£ãÁõòËá™Â∑±Êú¨Ë∫´Â∑≤ÁªèÂæàÂèØÈù†‰∫Ü„ÄÇ‰ΩÜÊòØÂØπ‰∫éÁé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑÁâ©‰ΩìÊù•ËØ¥‰∏çÊòØËøô‰πàÂèØÈù† Âä†ÂÖ•‰∫ÜRANSACÈÉ®ÂàÜÔºü Undistortion Âú®calibrationÈáåÈù¢Êúâ‰∏§‰∏™ÈúÄË¶ÅËß£ÂÜ≥ÁöÑ‰∫ãÊÉÖÔºå‰∏Ä‰∏™ÊòØdistortionÔºå‰∏Ä‰∏™ÊòØ‰∏âÁª¥Ë°®ËææÁöÑÊ≠£Á°ÆÊÄß opencvËá™Â∑±Êúâ‰∏Ä‰∏™ÂèØ‰ª•Áî®ÁöÑÊñπÊ≥ï cv::undistor() -&gt; ÂèØ‰ª•‰∏ÄÁû¨Èó¥ÂÆåÊàê cv::initUndistortRectifyMap() + cv::remap() -&gt; Âú®video‰∏äÈù¢‰ΩøÁî®ÁöÑÊó∂ÂÄôÊïàÁéáÊõ¥È´ò‰∏Ä‰∫õ undistortion map Âú®Êää‰∏ÄÂº†ÂõæÁâáundistortÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨ÈúÄË¶ÅÊääÊØè‰∏™ÂÉèÁ¥†ÈÉΩÂØπÂ∫îÂà∞outputÈáåÈù¢ÂØπÂ∫îÁöÑÂú∞ÊñπÂéªÔºåÊúâÂá†Áßç‰∏çÂêåÁöÑË°®ËææÊñπÊ≥ï 2-channel float Êúâ‰∏Ä‰∏™ÂØπ‰∫éNxMÁöÑremappingÔºåË°®Á§∫ÊàêNxMÁöÑarrayÔºåÊúâ‰∏§‰∏™channelÔºàÂàÜÂà´ÂØπÂ∫îXÂíåYÊñπÂêëÁöÑremapÔºâÔºåÈáåÈù¢ÊòØÊµÆÁÇπÊï∞ ÂØπ‰∫éÊØè‰∏Ä‰∏™ËæìÂÖ•ÁöÑÂÉèÁ¥†‰ΩçÁΩÆ(i,j)ÔºåÊúâ‰∏Ä‰∏™ÂØπ‰∫éËøô‰∏§‰∏™‰ΩçÁΩÆÁöÑÂêëÈáèÔºåÊù•Ë°®ËææËøô‰∏§‰∏™ÈáèÂ∫îËØ•Âì™ÈáåÂéª Â¶ÇÊûúËÆ°ÁÆóÂá∫Êù•ÁöÑÁªìÊûú‰∏çÊòØ‰∏Ä‰∏™Êï¥Êï∞ÔºåÈÇ£‰πàÁî®interpolationÊù•ËÆ°ÁÆóÊúÄÂêéÂ∫îËØ•Âç†ÁöÑÊ†ºÂ≠êÁöÑÊï∞Èáè Á¨¨‰∫åÁßçË°®ËææÂºèÊòØ 2-array floatÔºåÊØè‰∏Ä‰∏™arrayÊòØ‰∏Ä‰∏™channelÁöÑÁßªÂä® Á¨¨‰∏âÁßçÊòØfixed pointÔºåËÆ°ÁÆóÁöÑÈÄüÂ∫¶Êõ¥Âø´‰∏ÄÁÇπÔºå‰ΩÜÊòØÈúÄË¶ÅÊèê‰æõÁöÑ‰ø°ÊÅØÁöÑÁ≤æÁ°ÆÂ∫¶Êõ¥È´ò cv::convertMaps() Âõ†‰∏∫Êúâ‰∏äÈù¢ÁöÑ‰∏âÁßç‰∏çÂêåÁöÑË°®ËææÂΩ¢ÂºèÔºåÊâÄ‰ª•Ëøô‰∏™ÂáΩÊï∞Áî®Êù•Âú®ÂêÑ‰∏™ÂΩ¢Âºè‰πãÈó¥ËΩ¨Âèò cv::initUndistortRectifyMap() ‰ªéÂàöÊâçÁöÑÈÉ®ÂàÜÁü•ÈÅì‰∫ÜÂà∞Â∫ï‰ªÄ‰πàÊòØundistortion mapÔºåÁé∞Âú®ÂºÄÂßãËÆ®ËÆ∫Â¶Ç‰ΩïËÆ°ÁÆóËøô‰∏™map Áé∞Âú®ÂÖà‰ªéÂçïÁõÆÁõ∏Êú∫ÂºÄÂßãmonocularÔºåÂ¶ÇÊûúÂèåÁõÆÁöÑËØùÂèØ‰ª•Áõ¥Êé•ËÆ°ÁÆódepthÔºà‰∏ã‰∏ÄÁ´†Ôºâ Ê≠•È™§ÔºåÂàÜÂºÄÊòØÂõ†‰∏∫ËÆ°ÁÆómapÂè™ÈúÄË¶Å‰∏ÄÊ¨° ÂÖàËÆ°ÁÆóundistortion map cv::initUndistortRectifyMap() ËæìÂÖ•ÁöÑÂèÇÊï∞ÊòØintrinsic matÂíådistortion coefficientÔºà‰ªécamera calibrationÂæóÂà∞ÁöÑÔºâ ÂèØ‰ª•ÂæóÂà∞‰∏Ä‰∏™Êñ∞ÁöÑcamera matÔºåËøôÊ†∑ÁöÑËØùÂç≥‰Ωø‰∏çundistortion‰πüÂèØ‰ª•ÂæóÂà∞Ê≠£Á°ÆÁöÑÂõæÁâáÔºàÂú®Â§ö‰∏™Áõ∏Êú∫ÁöÑcalibrationÁöÑÊó∂ÂÄôÊØîËæÉÈáçË¶ÅÔºâ ÊúÄÂêé‰ºöËæìÂá∫‰∏§Âº†map ÁÑ∂ÂêéÂú®ÂõæÁâá‰∏äundistort cv::remap() ÂΩìËÆ°ÁÆó‰∫Ü‰∏äÈù¢ÁöÑmap‰πãÂêéÔºåÂ∞±ÂèØ‰ª•Áî®remapËøô‰∏™ÂáΩÊï∞ËøõË°åÊ†°Ê≠£‰∫Ü ËæìÂÖ•ÁöÑmapÁöÑÁßçÁ±ª‰πüÊòØ‰∏äÈù¢ÊèêÂà∞ÁöÑ‰∏âÁßçÈÉΩÂèØ‰ª• cv::undistort() Â¶ÇÊûúÂè™Êúâ‰∏ÄÂº†ÂõæÁâáÔºåÊàñËÄÖÂØπ‰∫éÊØèÂº†ÂõæÁâáÈÉΩÈúÄË¶ÅÈáçÊñ∞ËÆ°ÁÆómapÁöÑÊó∂ÂÄôÔºåÂ∞±ÈúÄË¶ÅÁî®Ëøô‰∏™ÂáΩÊï∞‰∫ÜÔºàÊâÄ‰ª•Âú®È°πÁõÆÈáåÈù¢Áî®Ëøô‰∏™ÁöÑÈÄüÂ∫¶‰ºöÂèòÊÖ¢Ôºâ sparse undistortion cv::distortionPoints() Â¶ÇÊûúÊàëÊ≤°ÊúâÊï¥Âº†ÂõæÁâáÔºåÂè™Êúâ‰∏Ä‰∫õÂõæÁâá‰∏äÁöÑÁÇπÔºåÁÑ∂ÂêéÊàëÂè™ÂÖ≥ÂøÉËøô‰∫õÂõæÁâá‰∏äÁöÑÁÇπÔºåÂèØ‰ª•Áî®Ëøô‰∏™ÂáΩÊï∞ËÆ°ÁÆóËøôÂº†ÂõæÁâá‰∏äÈù¢ÂÖ≥Ê≥®ÁÇπÁöÑ‰ΩçÁΩÆ]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>OpenCV</category>
        <category>Calibration</category>
      </categories>
      <tags>
        <tag>camera</tag>
        <tag>calibration</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nassignment2CNN]]></title>
    <url>%2F2019%2F04%2F18%2FCS231nassignment2CNN%2F</url>
    <content type="text"><![CDATA[target ‰πãÂâçÂ∑≤ÁªèÂÆûË∑µ‰∫ÜfcÁöÑÁõ∏ÂÖ≥‰∏úË•øÔºå‰ΩÜÊòØÂú®ÂÆûÈôÖÁöÑ‰ΩøÁî®ÈáåÂ§ßÂÆ∂‰ΩøÁî®ÁöÑÈÉΩÊòØCNN ÊâÄ‰ª•ËøôÈÉ®ÂàÜÂ∞±ÂºÄÂßãÂÆûË∑µCNN‰∫Ü convolution: Native forward pass CNNÁöÑÊ†∏ÂøÉÈÉ®ÂàÜÂ∞±ÊòØÂç∑ÁßØ in cs231n/layers.pyÔºåconv_forward_naive È¶ñÂÖàËøôÊó∂ÂÄô‰∏çÁî®ËÄÉËôëÊïàÁéáÈóÆÈ¢òÔºåÊúÄËΩªÊùæÁöÑÂÜôÂ∞±ÂèØ‰ª•‰∫Ü ËæìÂÖ•ÁöÑÊï∞ÊçÆÊòØN‰∏™dataÔºåÊØè‰∏™ÊúâC‰∏™channelÔºåHÁöÑÈ´òÂ∫¶ÂíåWÁöÑÂÆΩÂ∫¶ ÊØè‰∏™ËæìÂÖ•ÂíåF‰∏™‰∏çÂêåÁöÑfilterÂÅöÂç∑ÁßØÔºåÊØè‰∏™Âç∑ÁßØÊ†∏ÂØπÊâÄÊúâÁöÑchannel‰ΩúÁî®ÔºåÂç∑ÁßØÊ†∏ÁöÑÂ§ßÂ∞èÊòØHHxWW input x, (N,C,H,W) w, fliter weights of shape (F,C,HH,WW) b, bias, (F,) conv_param: dict ‚Äústride‚Äù Ê≠•Èïø ‚Äúpad‚Äù zero-paddingÁöÑÂ§ßÂ∞è Ê≥®ÊÑèÂú®paddingÁöÑÊó∂ÂÄô‰∏çË¶ÅË∞ÉÊï¥xÔºåËÄåÊòØÂæóÂà∞‰∏Ä‰∏™padding‰πãÂêéÁöÑÊñ∞ÁöÑ‰∏úË•ø output out, (N,F,H‚Äô,W‚Äô) H‚Äô = 1 + (H + 2 * pad - HH) / stride W‚Äô = 1 + (W + 2 * pad - WW) / stride cache: (x,w,b,conv_param) implement È¶ñÂÖàÈúÄË¶ÅÂØπËæìÂÖ•ÁöÑÂõæÁâáËøõË°åpadding np.pad ËæìÂÖ•ÁöÑarray padÁöÑÂÆΩÂ∫¶ÔºåÂ¶ÇÊûúÈªòËÆ§ÁöÑËØùÂ∞±ÊòØÂâçÂêéÈÉΩÂä†ÔºåÁÑ∂ÂêéÊòØËøô‰∏™Êï∞Â≠óÁöÑÂÆΩÂ∫¶ -&gt; Ê≥®ÊÑèËøôÈáåÁöÑÊó∂ÂÄôÂõ†‰∏∫‰∏ÄÂÖ±ÊúâÂõõ‰∏™Áª¥Â∫¶ÔºåÂâç‰∏§‰∏™Áª¥Â∫¶ÊòØ‰∏çÁî®padÁöÑ mode = ‚Äòconstant‚Äô constant_valuesÔºåË°®Á§∫ÁöÑÊòØpadËøõÂéªÁöÑÂÄºÔºåÂèØ‰ª•ÂâçÂêépadÁöÑ‰∏ç‰∏ÄÊ†∑ÔºåÂõ†‰∏∫ËøôÈáåÊòØ0-paddingÊâÄ‰ª•ËøôÈáåÊòØ0 Ë¶ÅÂØπÊâÄÊúâÂõæÁâáËøõË°åÂ§ÑÁêÜÔºåÈúÄË¶ÅÂú®N‰∏™ÂõæÁâáÈáåÈÄâÊã©‰∏Ä‰∏™ Âú®filterÁöÑÊâÄÊúâÈáåÈù¢ÈÄâÊã©‰∏Ä‰∏™ ËÄÉËôëÂú®HÊñπÂêëÂíåWÊñπÂêëÁöÑÁßªÂä®Ê≠•Êï∞ÔºåÁÑ∂ÂêéÈÄöËøáËøô‰∏™Ê≠•Êï∞ÂíåÊ≠•ÈïøÁöÑ‰πòÁßØÂú®ÂéüÂõæÈáåÈù¢ÂèñÈúÄË¶ÅÂÅöÂç∑ÁßØÁöÑÈÉ®ÂàÜ Ê≥®ÊÑèËøôÈáåÂèØ‰ª•‰∏çÁî®ËÄÉËôëchannelÔºåÂõ†‰∏∫ÂõæÁâáÂíåfilterÁöÑchannelÊòØÂêåÊ†∑ÁöÑÂ±ÇÊï∞ÔºåÊâÄ‰ª•Áõ¥Êé•ÂèØ‰ª•boardcast ÁÑ∂ÂêéËøô‰∏™ÈÉ®ÂàÜÂíåÂç∑ÁßØÊ†∏Áõ∏‰πòÔºàÁõ¥Êé•‰πòÔºâÔºåÊ±ÇÂíåÔºåÂä†‰∏äbiasÔºåÂ∞±ÊòØËøô‰∏™ÂÉèÁ¥†ÁÇπ‰∏äÂ∫îËØ•ÁöÑÊï∞ÂÄº 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162def conv_forward_naive(x, w, b, conv_param): """ A naive implementation of the forward pass for a convolutional layer. The input consists of N data points, each with C channels, height H and width W. We convolve each input with F different filters, where each filter spans all C channels and has height HH and width WW. Input: - x: Input data of shape (N, C, H, W) - w: Filter weights of shape (F, C, HH, WW) - b: Biases, of shape (F,) - conv_param: A dictionary with the following keys: - 'stride': The number of pixels between adjacent receptive fields in the horizontal and vertical directions. - 'pad': The number of pixels that will be used to zero-pad the input. During padding, 'pad' zeros should be placed symmetrically (i.e equally on both sides) along the height and width axes of the input. Be careful not to modfiy the original input x directly. Returns a tuple of: - out: Output data, of shape (N, F, H', W') where H' and W' are given by H' = 1 + (H + 2 * pad - HH) / stride W' = 1 + (W + 2 * pad - WW) / stride - cache: (x, w, b, conv_param) """ out = None ########################################################################### # TODO: Implement the convolutional forward pass. # # Hint: you can use the function np.pad for padding. # ########################################################################### stride = conv_param['stride'] pad = conv_param['pad'] N, C, H, W = x.shape F, _, HH, WW = w.shape H_out = 1 + (H + 2 * pad - HH) // stride W_out = 1 + (W + 2 * pad - WW) // stride out = np.zeros((N, F, H_out, W_out)) x_pad = np.pad(x, ((0,), (0,), (pad,), (pad,)), 'constant', constant_values=0) # ÂØπÂéüÂõæÁâáÁöÑÊØèÂ±ÇËøõË°åÂç∑ÁßØ for pics in range(N): image = x_pad[pics] for filters in range(F): for H_move in range(H_out): for W_move in range(W_out): image_conv = image[:, stride * H_move: stride * H_move + HH, stride * W_move: stride * W_move + WW] filter_conv = w[filters, :] out_pixel = np.sum(image_conv * filter_conv) + b[filters] out[pics, filters, H_move, W_move] = out_pixel ########################################################################### # END OF YOUR CODE # ########################################################################### cache = (x, w, b, conv_param) return out, cache ÂèØËßÜÂåñ‰∏≠Èó¥ÁöÑÂõæÂÉèËøáÁ®ã ËøôÈáåËæìÂÖ•‰∫Ü‰∏§‰∏™‰∏çÂêåÁöÑËæìÂÖ•ÂõæÁâá ÂàÜÂà´ÂèØËßÜÂåñ‰∫ÜËøô‰∏™ÂõæÁâáÁöÑ‰∏çÂêåweights Convolution: Naive backward passÊÑâÂø´ÁöÑÁÆÄÂçïËÆ°ÁÆóbackÁöÑËøáÁ®ãÔºåÂÖà‰∏çÁî®ËÄÉËôëcost input dout cacheÔºàx,w,b,conv_param) -&gt; ÂèÇÊï∞ÊòØpadding Âíå stride output dx dw db ÂÆûÁé∞ÔºöconvÊòØÊÄé‰πàÊ±ÇÂØºÁöÑÔºüÂÖ∂ÂÆûÊéíÈô§‰ΩçÁΩÆÁöÑÊîπÂèò‰πãÂ§ñÔºåforwardÂè™ËøõË°å‰∫Ü‰∏â‰∏™Êìç‰Ωú Êääx padding‰∏∫x_pad wx_pad_conv + b -&gt; Ê±ÇÂá∫‰∏Ä‰∏™Â§ßÂ∞èÂíåfilterÁõ∏ÂêåÁöÑÁü©Èòµ ÊääÊ±ÇÂá∫Êù•ÁöÑ‰∏Ä‰∏™(HH,WW)ÁöÑÁü©ÈòµÁöÑÊâÄÊúâÂÄºÊ±Çsum backwardÁöÑÊÄùË∑Ø È¶ñÂÖàÔºåÊØè‰∏ÄÂº†ÂõæÁâáÁöÑÊØè‰∏Ä‰∏™channelÁöÑÔºådoutÁöÑÂ§ßÂ∞èÂíåËæìÂá∫ÂõæÁâáÁöÑÂ§ßÂ∞è‰∏ÄÊ†∑ Â∫îËØ•ÊòØH_out = 1 + (H + 2 * pad - HH) // strideËøôÊ†∑Ê±ÇÂá∫Êù•ÁöÑÁªìÊûú Êï¥‰∏™doutÁöÑsizeÊòØ(N,F,Hout,Wout)ÔºåÂÖ∂‰∏≠NÊòØ‰πãÂâçÂõæÁâáÁöÑÊï∞ÈáèÔºåFÊòØÊñ∞ÂΩ¢ÊàêÁöÑÂõæÁâáÁöÑchannel ÊâÄ‰ª•Âú®forÂæ™ÁéØ‰∏≠Ôºådout‰∏≠ÈÄâ‰∏≠[n,f,hout,wout]ÔºåÂ∞±ÂèØ‰ª•ÂæóÂà∞Ëøô‰∏™ÁâπÁÇπÂÆöÁöÑÂÄºÔºåÁß∞‰∏∫df dfÁöÑÂæóÂà∞ÊñπÊ≥ïÊòØwx+bÂæóÂà∞‰∏Ä‰∏™Áü©ÈòµÔºåÁÑ∂ÂêéÂÜçÂØπËøô‰∏™Áü©ÈòµÊ±ÇÂíå Âõ†‰∏∫Ê±ÇÂíåÂÆûÈôÖÂ∞±ÊòØÁ¥ØÂä†ÔºåÊ±ÇÂØºÊï∞ÁöÑÊó∂ÂÄôÂè™Ë¶ÅÊääÊØè‰∏Ä‰∏™Ê†ºÂ≠êÁöÑdxÔºådwÔºådbÂØºÊï∞Ê±ÇÂá∫Êù•ÔºåÁÑ∂ÂêéÂä†Âú®‰∏ÄËµ∑Â∞±Ë°å‰∫Ü Âõ†‰∏∫ÂÖ¨ÂºèÂ∞±ÊòØwx + bÔºåÊâÄ‰ª•dxÊòØwÔºådwÊòØxÔºådbÊòØÂ∏∏Êï∞ -&gt; ÁÑ∂ÂêéÂÜçÊääÊØè‰∏™Ê†ºÂ≠êÊ±ÇÂá∫Êù•ÁöÑÂä†Âú®‰∏ÄËµ∑ÔºåÊ≥®ÊÑèÂêÑ‰∏™Áü©ÈòµÁöÑÂ§ßÂ∞èÔºådxÂ∫îËØ•ÊòØÂú®xÁü©ÈòµÈáåÂèñÂÅöÂç∑ÁßØÁöÑÈÉ®ÂàÜÔºåËøôÈÉ®ÂàÜÁöÑÂØºÊï∞Á≠â‰∫éw‰πòdfÁöÑÂíå ÊúÄÂêéÔºåÂõ†‰∏∫xË¢´padding‰∫ÜÔºådxÂ∫îËØ•Âéªdx_pad‰∏≠Ê≤°ÊúâË¢´paddingÁöÑÈÉ®ÂàÜÔºå‰πüÂ∞±ÊòØ‰ªé[pad:pad + H] ‰ª£Á†ÅÂ¶Ç‰∏ã123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051def conv_backward_naive(dout, cache): """ A naive implementation of the backward pass for a convolutional layer. Inputs: - dout: Upstream derivatives. - cache: A tuple of (x, w, b, conv_param) as in conv_forward_naive Returns a tuple of: - dx: Gradient with respect to x - dw: Gradient with respect to w - db: Gradient with respect to b """ dx, dw, db = None, None, None ########################################################################### # TODO: Implement the convolutional backward pass. # ########################################################################### x, w, b, conv_param = cache N, C, H, W = x.shape F, _, HH, WW = w.shape _, _, H_dout, W_dout = dout.shape stride = conv_param['stride'] pad = conv_param['pad'] x_pad = np.pad(x, ((0,), (0,), (pad,), (pad,)), 'constant', constant_values=0) db = np.zeros_like(b) dw = np.zeros_like(w) dx_pad = np.zeros_like(x_pad) # print(dx_pad.shape) for pics in range(N): for filters in range(F): for H_move in range(H_dout): for W_move in range(W_dout): # f=sum(wx_pad + b) (df is a number now) df = dout[pics, filters, H_move, W_move] # d for sum, size (HH,WW) # dsum = df * np.ones((HH, WW)) db[filters] += df dx_pad[pics, :, H_move * stride: H_move * stride + HH, W_move * stride: W_move * stride + WW] += df * w[filters] dw[filters] += x_pad[pics, :, stride * H_move: stride * H_move + HH, stride * W_move: stride * W_move + WW] * df dx = dx_pad[:, :, pad:pad + H, pad:pad + W] ########################################################################### # END OF YOUR CODE # ########################################################################### return dx, dw, db Max-PoolingÔºöNative forwardinput x, (N,C,H,W) pool_param -&gt; dict ‚Äòpool_height‚Äô ‚Äòpool_width‚Äô ‚Äòstride‚Äô ‰∏çÈúÄË¶ÅËøõË°åpadding output out, (N,C,H‚Äô,W‚Äô) H‚Äô = 1 + (H - pool_height) / stride W‚Äô = 1 + (W - pool_width) / stride cache(x,pool_param) ÂÆûÁé∞ Áõ¥Êé•ÊâæÂà∞Áõ∏Â∫îÁöÑÂùóÁÑ∂ÂêéÊ±Çmax Ê≥®ÊÑèÊ±ÇmaxÁöÑÊó∂ÂÄôË¶ÅÊ≥®ÊÑèaxis,Êàë‰ª¨ÈúÄË¶ÅÊ±ÇÂæóÊòØÂú®‰∏ÄÂº†ÂõæÁâáÊØè‰∏™channel‰∏äÈù¢ÁöÑÊúÄÂ§ßÂÄºÔºåÂú®Ëøô‰∏™ÂºèÂ≠êÈáåÈù¢Âõ†‰∏∫Â∑≤ÁªèÁ°ÆÂÆö‰∫ÜpicsÁöÑÂÄºÔºåÂÆûÈôÖ‰∏äÁöÑoutÂÖ∂ÂÆûÊòØ‰∏Ä‰∏™‰∏âÁª¥ÁöÑÊï∞ÁªÑÔºåÊâÄ‰ª•Â∫îËØ•Ê±Çaxis = (1,2)‰∏äÈù¢ÁöÑÊúÄÂ§ßÂÄºÔºåËÄå‰∏çÊòØÊ±Ç(2,3‰∏äÈù¢ÁöÑ) ‰ª£Á†Å12345678910111213141516171819202122232425262728293031323334353637383940def max_pool_forward_naive(x, pool_param): """ A naive implementation of the forward pass for a max-pooling layer. Inputs: - x: Input data, of shape (N, C, H, W) - pool_param: dictionary with the following keys: - 'pool_height': The height of each pooling region - 'pool_width': The width of each pooling region - 'stride': The distance between adjacent pooling regions No padding is necessary here. Output size is given by Returns a tuple of: - out: Output data, of shape (N, C, H', W') where H' and W' are given by H' = 1 + (H - pool_height) / stride W' = 1 + (W - pool_width) / stride - cache: (x, pool_param) """ out = None ########################################################################### # TODO: Implement the max-pooling forward pass # ########################################################################### N, C, H, W = x.shape pool_height, pool_width, stride = pool_param['pool_height'], pool_param['pool_width'], pool_param['stride'] H_out = 1 + (H - pool_height) // stride W_out = 1 + (W - pool_width) // stride out = np.zeros((N,C,H_out,W_out)) for pics in range(N): for h_out in range(H_out): for w_out in range(W_out): out[pics,:,h_out,w_out] = np.max(x[pics,:,stride * h_out: stride* h_out + pool_height,stride* w_out: stride*w_out + pool_width],axis = (1,2)) ########################################################################### # END OF YOUR CODE # ########################################################################### cache = (x, pool_param) return out, cache Max-pooling: Native backwardinput dout, size = (N,C,W_out,W_out) cache output dx, size = (N,C,W,H) ÂÆûÁé∞ maxÁöÑÂÄºÂú®ÂÆûÈôÖ‰∏äÊòØ‰∏Ä‰∏™routerÔºålocal gradientÂØπ‰∫éÊúÄÂ§ßÁöÑÂÄºÁöÑÂú∞ÊñπÊòØ1ÔºåÂÖ∂‰ªñÂÄºÁöÑÂú∞ÊñπÂΩ±ÂìçÊòØ0 ÈúÄË¶ÅÊâæÂà∞xÈáåÈù¢ÂÄºÁ≠â‰∫éÊúÄÂ§ßÂÄºÁöÑÂùêÊ†áÔºåÁÑ∂ÂêéÊääËøô‰∏™ÂùêÊ†áÁöÑdxÊîπÊàêÂØπÂ∫îdoutÁöÑÂÄºÔºàÂõ†‰∏∫ÈìæÂºèÊ≥ïÂàôÂ∫îËØ•dout * 1ÔºâÔºåÂÖ∂‰ªñÂú∞ÊñπÁöÑdxÈÉΩÊòØ0 ÂÖ≥‰∫éÊâæÂà∞Ëøô‰∏™ÁÇπÁöÑÂùêÊ†á ÊàëÁî®‰∫ÜÊòæÂæóÂæàÂÇªÁöÑÊñπÊ≥ïÔºåÂú®xÁöÑËåÉÂõ¥ÈáåÈù¢ÊâæÂà∞Ëøô‰∏™ËåÉÂõ¥ÈáåÊúÄÂ§ßÁöÑÂùêÊ†áÔºåÁî®‰∫ÜÂæàÂ§öÂúàÂæ™ÁéØ ÂÆûÈôÖ‰∏äÂèØ‰ª•‰ªémaxÁöÑÂÄºÊâæÂà∞ÂéüÊù•ÁöÑÂùêÊ†á numpy.unravel_index(indices, dims) ÁªìÂêànp.argmaxÔºåËøîÂõûÊúÄÂ§ßÂÄºÁöÑÂùêÊ†á -&gt; ind = np.unravel_index(np.argmax(a, axis=None), a.shape) ËøôÊ†∑ÁöÑËØùÊâæÂà∞ÁöÑÊòØÂú®ÊØè‰∏™maxÁöÑÊ°ÜÊ°ÜÈáåÊúÄÂ§ßÂÄºÁöÑÂùêÊ†áÔºåÂú®Ëøô‰∏™Ê°ÜÊ°ÜÁöÑËåÉÂõ¥ÈáåÊâæÂà∞Ëøô‰∏™ÂùêÊ†áÂ∞±ÊòØÈúÄË¶ÅÊîπÂèòÁöÑÂú∞Êñπ 1234567891011121314151617181920212223242526272829303132333435363738def max_pool_backward_naive(dout, cache): """ A naive implementation of the backward pass for a max-pooling layer. Inputs: - dout: Upstream derivatives - cache: A tuple of (x, pool_param) as in the forward pass. Returns: - dx: Gradient with respect to x """ dx = None ########################################################################### # TODO: Implement the max-pooling backward pass # ########################################################################### x, pool_param = cache N, C, H, W = x.shape pool_height, pool_width, stride = pool_param['pool_height'], pool_param['pool_width'], pool_param['stride'] _,_,H_out,W_out = dout.shape dx = np.zeros_like(x) for pics in range(N): for channels in range(C): for h_out in range(H_out): for w_out in range(W_out): # for H in range(stride * h_out, stride* h_out + pool_height): # for W in range(stride * w_out, stride * w_out + pool_width): # if x[pics,channels,H,W] == np.max(x[pics,channels,stride * h_out: stride* h_out + pool_height,stride* w_out: stride*w_out + pool_width]): # dx[pics,channels,H,W] = dout[pics,channels,h_out,w_out] ind = np.unravel_index(np.argmax(x[pics,channels,stride * h_out: stride* h_out + pool_height,stride* w_out: stride*w_out + pool_width]), (pool_height,pool_width)) dx[pics,channels,stride * h_out: stride* h_out + pool_height,stride* w_out: stride*w_out + pool_width][ind] = dout[pics,channels,h_out,w_out] # print(ind) ########################################################################### # END OF YOUR CODE # ########################################################################### return dx Fast layers Âú®cs231n/fast_layers.pyÈáåÈù¢Áõ¥Êé•Êèê‰æõ‰∫ÜÊØîËæÉÂø´ÁâàÊú¨ÁöÑËÆ°ÁÆóÊñπÊ≥ï The fast convolution implementation depends on a Cython extension; to compile it you need to run the following from the cs231n directory: 1python setup.py build_ext --inplace ËÆ∞ÂæóÈáçÂêØ‰∏Ä‰∏ãjupter 12345678910111213141516171819202122232425Testing conv_forward_fast:Naive: 5.283360sFast: 0.014807sSpeedup: 356.809600xDifference: 4.926407851494105e-11Testing conv_backward_fast:Naive: 9.893734sFast: 0.015421sSpeedup: 641.578958xdx difference: 1.949764775345631e-11dw difference: 5.155328198575201e-13db difference: 3.481354613192702e-14Testing pool_forward_fast:Naive: 0.212025sfast: 0.002980sspeedup: 71.143680xdifference: 0.0Testing pool_backward_fast:Naive: 0.391351sfast: 0.012568sspeedup: 31.138711xdx difference: 0.0 ÂèØ‰ª•ÂèëÁé∞fastÁâàÊú¨convÁöÑÈÄüÂ∫¶‰ºöÂø´300ÂÄçÔºåËÄåpooling‰πü‰ºöÂø´Âá†ÂçÅÂÄç conv sandwich layer -&gt; Â∑≤ÁªèÂÜôÂ•Ω‰∫ÜÔºåconv + relu + poolThree-layer ConvNetcs231n/classifiers/cnn.py,implement‰∏Ä‰∏™‰∏âÂ±ÇÁöÑCNNÁªìÊûÑ conv - relu - 2x2 maxpool - affine1 - relu - affine2 - softmax ËæìÂÖ•ÂõæÁâáÁöÑminibatch‰∏∫(N,C,H,W) init input_dim: (C,H,W)ÊòØÊØèÂº†ÂõæÁâáÈïø‰ªÄ‰πàÊ†∑Â≠ê num_filters: convÂ±ÇÈáåÈù¢filterÁöÑ‰∏™Êï∞ filters_sizeÔºåÁõ¥Êé•ÊääÈ´òÂíåÂÆΩÁªü‰∏ÄÊàê‰∏Ä‰∏™Êï∞Â≠ó‰∫ÜÔºåÂèçÊ≠£ÈÉΩÊòØÊñπÂΩ¢ÁöÑ hidden_dimÔºöÁî®fcÂ±ÇÁöÑÊï∞Èáè num_classes: ÊúÄÂêéËæìÂá∫ÁöÑclassÁöÑÊï∞Èáè weight_scaleÔºöÂàùÂßãÂåñÁöÑÊó∂ÂÄôÁöÑscale regÔºöL2 dtypeÔºöËÆ°ÁÆóÊâÄÁî®ÁöÑdatatypeÔºàÂ¶Ç np.float32) loss + gradient ÈúÄË¶ÅÂàùÂßãÂåñ‰∏âÂ±ÇÁöÑÂèÇÊï∞ÔºåW123Âíåb123 ÂàùÂßãÂåñweightsÔºàÊ≠£ÊÄÅÂàÜÂ∏ÉÔºâÂíåbiasÔºàÂÖ®ÊòØ0Ôºâ -&gt; Ê≥®ÊÑèfcÂíåconvÂ±ÇÁöÑ‰∏ç‰∏ÄÊ†∑ Âõ†‰∏∫Âú®loss‰∏≠ÊúâÂ∏ÆÂä©inputÁöÑÂ§ßÂ∞è‰øùÊåÅÁöÑÊìç‰ΩúÔºåÊâÄ‰ª•Á¨¨‰∫åÂ±ÇÁöÑÂõæÁâáÂèØ‰ª•‰∏çËÄÉËôëpaddingÂíåstrideÁöÑÂèòÂåñ W1ÁöÑÂ§ßÂ∞èÊòØfilterÁöÑÂ§ßÂ∞è(F,C,HH,WW)ÔºåÈúÄË¶ÅfilterÁöÑÊï∞ÈáèÔºåchannelÁöÑÊï∞ÈáèÔºå‰ª•ÂèäÊØè‰∏™filterÁöÑÂ§ßÂ∞èÔºåb1ÊòØ(filter,) conv_relu‰πãÂêéËøõË°å‰∫Ü‰∏ÄÊ¨°max poolÔºåÊâÄ‰ª•ÂõæÁâáÁöÑÂ§ßÂ∞èÁº©Â∞è‰∫Ü‰∏ÄÂçä ÂêéÈù¢‰∏§‰∏™affineÁöÑÂ§ßÂ∞èÂ∞±Ë∑üËæìÂÖ•Ôºåhidden_numÂíåÊúÄÂêéÁöÑnum_classesÊúâÂÖ≥Á≥ª‰∫ÜÔºåbÁöÑÂ§ßÂ∞èË∑üËæìÂá∫Ëµ∞ Ê≥®ÊÑèÁ¨¨‰∫å‰∏™affine‰πãÂêé‰∏çÈúÄË¶Årelu lossÁî®‰πãÂâçÂÜôÂ•ΩÁöÑsoftmax Ê≥®ÊÑèÈúÄË¶Åregularization Áõ¥Êé•Áî®‰πãÂâçÂÜôÂ•ΩÁöÑÊäägradient backÂõûÂéªÂ∞±ÂèØ‰ª•‰∫Ü Sanity check loss¬∂Âú®Âª∫Á´ã‰∏Ä‰∏™Êñ∞ÁöÑnetÁöÑÊó∂ÂÄôÔºåÁ¨¨‰∏Ä‰ª∂‰∫ãÂ∞±Â∫îËØ•ÊòØËøô‰∏™ Áî®softmaxÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨Â∏åÊúõrandom weightÔºåÊ≤°ÊúâregÁöÑÁªìÊûúÊòØlog(C) Â¶ÇÊûúÂä†‰∏ä‰∫ÜregÔºåËøô‰∏™Êï∞Èáè‰ºöËΩªÂæÆÂ¢ûÂä†‰∏ÄÁÇπ overfit small data Áõ¥Êé•Áî®ÈùûÂ∏∏Â∞ëÁöÑÊï∞ÊçÆÊù•ËÆ≠ÁªÉ‰∏Ä‰∏™Êñ∞ÁöÑÁΩëÁªúÔºåÂ∫îËØ•ËÉΩÂú®Ëøô‰∏™‰∏äÈù¢overfit Â∫îËØ•‰ºö‰∫ßÁîü‰∏Ä‰∏™ÈùûÂ∏∏È´òÁöÑËÆ≠ÁªÉÁ≤æÂ∫¶ÂíåÈùûÂ∏∏‰ΩéÁöÑvalÁ≤æÂ∫¶ Ê≥®ÊÑèÂú®lossÈáåÈù¢ÁöÑÊó∂ÂÄôÈúÄË¶ÅËÆ∞ÂΩï‰∏ãÊù•scoresÔºåÊàëÂ∞±ÊòØÂõ†‰∏∫ÂèòÈáèÂêçÂÜôÈîô‰∫ÜÊâÄ‰ª•‰∏ÄÁõ¥bug ÊúÄÂêéËÆ≠ÁªÉÂá∫Êù•ÁöÑtrain_accÊé•Ëøë100%ÔºåËÄåval_accÂè™ÊúâÁôæÂàÜ‰πã20 1234567891011121314151617181920np.random.seed(231)num_train = 100small_data = &#123; 'X_train': data['X_train'][:num_train], 'y_train': data['y_train'][:num_train], 'X_val': data['X_val'], 'y_val': data['y_val'],&#125;model = ThreeLayerConvNet(weight_scale=1e-2)solver = Solver(model, small_data, num_epochs=15, batch_size=50, update_rule='adam', optim_config=&#123; 'learning_rate': 1e-3, &#125;, verbose=True, print_every=1)solver.train() ËÆ≠ÁªÉËøô‰∏™‰∏âÂ±ÇÁöÑÁΩëÁªú Áõ¥Êé•Áî®ÊâÄÊúâÊï∞ÊçÆËÆ≠ÁªÉËøô‰∏™ÁΩëÁªúÔºåÂ∫îËØ•ÂæóÂà∞ÁöÑtrain_accÂ∫îËØ•Âú®40% ÊúÄÂêéËÆ≠ÁªÉ‰∫Ü1‰∏™epochÔºå980Ê¨°iter1(Epoch 1 / 1) train acc: 0.496000; val_acc: 0.489000 ÂèØËßÜÂåñÁ¨¨‰∏ÄÂ±ÇÁöÑfilter Spatial Batch Normalization Âú®‰πãÂâçÊàë‰ª¨Â∑≤ÁªèÁúãÂà∞BNÂØπ‰∫éËÆ≠ÁªÉNNÂæàÊúâÁî®‰∫ÜÔºåÊ†πÊçÆ15Âπ¥ÁöÑ‰∏Ä‰∏™ËÆ∫ÊñáÔºåCNNÈáåÈù¢‰πüÂèØ‰ª•Áî®BN -&gt; SBN ÊôÆÈÄöÁöÑBN‰ºöÊé•Êî∂(N,D)Â§ßÂ∞èÁöÑinputÔºåÂπ∂‰∏îoutputÊòØÂêåÊ†∑ÁöÑÂ§ßÂ∞èÔºånormalÁöÑÊó∂ÂÄôÁî®dataÁöÑÊÄªÊï∞N CNNÈáåÈù¢Ôºåinput‰∏∫(N,C,H,W)ÔºåoutputÂ§ßÂ∞èÁõ∏ÂêåÔºà‰πüÂ∞±ÊòØÂíåXÂêåÊ†∑Â∞∫ÂØ∏Ôºâ Â¶ÇÊûúÁî®Âç∑ÁßØÂæóÂà∞ÁöÑÁâπÂæÅmapÔºåwe expect the statistics of each feature channel to be relatively consistent both between different imagesand different locations within the same image -&gt; ÊâÄ‰ª•Âú®SBNÈáåÈù¢ÔºåËÆ°ÁÆóÂØπÊØè‰∏™CÈáåÈù¢ÁöÑÁâπÂæÅËÆ°ÁÆómeanÂíåvar Spatial batch normalization: forwardcs231n/layers.pyinput: x,(N,C,H,W) gamma,scale parameter (C,) beta,shift param (C,) bn_param: dict mode: train/test eps momentum running_mean running_varoutput out,(N,C,H,W) cache, backÁöÑÊó∂ÂÄôÈúÄË¶ÅÁöÑ‰∏úË•ø Ê≥®ÊÑèÔºåÂèØ‰ª•Ë∞ÉÁî®‰πãÂâçÂÜôÁöÑÂÖ≥‰∫é batchnorm_forward ÁöÑÂÜÖÂÆπÔºå‰ª£Á†ÅÂ∫îËØ•Â∞ë‰∫é‰∫îË°å ËøôÈáåÈúÄË¶ÅÁî®Âà∞Â§öÁª¥Êï∞ÁªÑÁöÑËΩ¨ÁΩÆÔºåÈúÄË¶ÅÊääÁü©ÈòµÂèòÊàêÔºàN H WÔºâ * CÁöÑÊ†ºÂºèÔºåÁÑ∂ÂêéÂú®Ê±ÇÂÆåbn‰πãÂêéÂÜçËΩ¨ÂõûÂéª ‰πãÂâçfcÈáåÈù¢‰ΩøÁî®ÁöÑÊó∂ÂÄôÁöÑÂ§ßÂ∞èÊòØ(N,D)ÔºåËøôÊ†∑ÁöÑËØùÊòØÂú®ÊâÄÊúâÁöÑN‰∏äÈù¢ÂèñÂπ≥Âùá ËøôÈáåÁöÑC‰ª£Êõø‰∫Ü‰ª•ÂâçÁöÑDÔºåNHW‰ª£Êõø‰∫Ü‰ª•ÂâçÁöÑN(ÊääÊØèÂº†ÁâπÂæÅÂõæÁúãÂÅö‰∏Ä‰∏™ÁâπÂæÅÂ§ÑÁêÜÔºà‰∏Ä‰∏™Á•ûÁªèÂÖÉÔºâÔºåËøôÈáåÁöÑÁâπÂæÅÂõæÊåáÁöÑÊòØ‰∏ÄÂ±ÇÁöÑ‰∏úË•ø) ËøôÈáåÁî®Âà∞ÁöÑÊòØ‰∏ÄÂº†ÁâπÂæÅÂõæÈáåÈù¢ÁöÑÊâÄÊúâÁ•ûÁªèÂÖÉÁöÑÂèÇÊï∞ÂÖ±‰∫´ Spatial batch normalization: backward ËæìÂÖ•dout(N,C,H,W)ÂíåcacheÔºåËæìÂá∫dxÔºådgammaÂíådbeta ÂêåÊ†∑‰πüÊòØÁõ¥Êé•Ë∞ÉÁî®‰πãÂâçÁöÑÔºåÂèòÂΩ¢ÊñπÊ≥ïÂíå‰πãÂâç‰∏ÄÊ†∑ Group Normalization ÂêåÊ†∑ÂéüÁêÜÔºåÊääÁª¥Â∫¶ÂèòÂåñ‰πãÂêé‰ΩøÁî® np.newaxis()]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
        <category>CS231n‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231nassignment2‰πãDropout]]></title>
    <url>%2F2019%2F04%2F18%2FCS231nassignment2Dropout%2F</url>
    <content type="text"><![CDATA[Target regularization NN randomly setting some features to 0 during forward pass Geoffrey E. Hinton et al, ‚ÄúImproving neural networks by preventing co-adaptation of feature detectors‚Äù, arXiv 2012 Dropout forward + backwardin cs231n/layers.py IO input x,input data, of any shape dropout_params pÔºåÊØè‰∏™neuronÊòØ‰∏çÊòØ‰øùÁïôÁöÑÂèØËÉΩÊÄßÊòØp modeÔºö‚Äôtrain‚ÄôÁöÑÊó∂ÂÄô‰ºöËøõË°ådropoutÔºå‚Äòtest‚ÄôÁöÑÊó∂ÂÄô‰ºöÁõ¥Êé•return input seedÔºöÁî®Êù•generate random number for dropout output out, ÂíåxÂêåÊ†∑Â§ßÂ∞è cache, tuple(dropout_params, mask). In training, mask is used to multiply the input Âú®ÂÆûÁé∞‰∏≠‰∏çÊé®ËçêÁî®vanillaÁöÑÊñπÊ≥ï 123456NOTE: Please implement **inverted** dropout, not the vanilla version of dropout.See http://cs231n.github.io/neural-networks-2/#reg for more details.NOTE 2: Keep in mind that p is the probability of **keep** a neuronoutput; this might be contrary to some sources, where it is referred toas the probability of dropping a neuron output. ÂÆûÁé∞ Âú®ËÆ≠ÁªÉÁöÑÊó∂ÂÄôÂú®hiddÂ±ÇÈÉΩdrop‰∫Ü‰∏ÄÈÉ®ÂàÜÔºåÂ¶ÇÊûúÊÑøÊÑèÁöÑËØù‰πüÂèØ‰ª•Âú®inputÂ±ÇÂ∞±drop Âú®predictÁöÑÊó∂ÂÄô‰∏çÂÜçdrop‰∫ÜÔºÅ‰ΩÜÊòØÈúÄË¶ÅÊ†πÊçÆdropÁöÑÊØî‰æãÂØπoutputÁöÑÊï∞ÈáèËøõË°åscale -&gt; ÊâÄ‰ª•ËøôÊ†∑Â∞±‰ºöÂèòÂæóÂæàÈ∫ªÁÉ¶ÔºàvanillaÁöÑÊñπÊ≥ïÔºâ ÊØîÂ¶ÇÊØî‰æãÊòØpÔºådrop‰πãÂêéÂâ©‰∏ã‰∫Üpx ÈÇ£Âú®testÁöÑÊó∂ÂÄôxÁöÑÂ§ßÂ∞è‰πüÂ∫îËØ•ÂèòÊàêpx(x -&gt; px) inverted dropoutÔºåÂú®ËÆ≠ÁªÉÁöÑÊó∂ÂÄôÂ∞±ÂØπÂ§ßÂ∞èËøõË°åÊîæÁº©ÔºåÂú®testÁöÑÊó∂ÂÄô‰∏çÊé•Ëß¶forward pass 12H1 = np.maximum(0, np.dot(W1, X) + b1)U1 = (np.random.rand(*H1.shape) &lt; p) / p # /p!!! backÁöÑÂÆûÁé∞Êõ¥ÂÆπÊòì‰∫ÜÔºåÂ¶ÇÊûúËøô‰∏™ÁÇπË¢´drop‰∫ÜÁöÑËØùÂØπÂÜçÂæÄÂâçÁöÑdxÂ∞±Ê≤°ÊúâÂΩ±ÂìçÔºåÂ¶ÇÊûúËøô‰∏™ÁÇπÊ≤°ÊúâË¢´dropÁöÑËØùÂØπ‰πãÂâçÁöÑÂΩ±ÂìçÂ∞±ÊòØÂ∏∏Êï∞ code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081def dropout_forward(x, dropout_param): """ Performs the forward pass for (inverted) dropout. Inputs: - x: Input data, of any shape - dropout_param: A dictionary with the following keys: - p: Dropout parameter. We keep each neuron output with probability p. - mode: 'test' or 'train'. If the mode is train, then perform dropout; if the mode is test, then just return the input. - seed: Seed for the random number generator. Passing seed makes this function deterministic, which is needed for gradient checking but not in real networks. Outputs: - out: Array of the same shape as x. - cache: tuple (dropout_param, mask). In training mode, mask is the dropout mask that was used to multiply the input; in test mode, mask is None. NOTE: Please implement **inverted** dropout, not the vanilla version of dropout. See http://cs231n.github.io/neural-networks-2/#reg for more details. NOTE 2: Keep in mind that p is the probability of **keep** a neuron output; this might be contrary to some sources, where it is referred to as the probability of dropping a neuron output. """ p, mode = dropout_param['p'], dropout_param['mode'] if 'seed' in dropout_param: np.random.seed(dropout_param['seed']) mask = None out = None if mode == 'train': ####################################################################### # TODO: Implement training phase forward pass for inverted dropout. # # Store the dropout mask in the mask variable. # ####################################################################### mask = (np.random.randn(*x.shape) &lt; p) / p out = x * mask ####################################################################### # END OF YOUR CODE # ####################################################################### elif mode == 'test': ####################################################################### # TODO: Implement the test phase forward pass for inverted dropout. # ####################################################################### out = x ####################################################################### # END OF YOUR CODE # ####################################################################### cache = (dropout_param, mask) out = out.astype(x.dtype, copy=False) return out, cachedef dropout_backward(dout, cache): """ Perform the backward pass for (inverted) dropout. Inputs: - dout: Upstream derivatives, of any shape - cache: (dropout_param, mask) from dropout_forward. """ dropout_param, mask = cache mode = dropout_param['mode'] dx = None if mode == 'train': ####################################################################### # TODO: Implement training phase backward pass for inverted dropout # ####################################################################### dx = dout * mask ####################################################################### # END OF YOUR CODE # ####################################################################### elif mode == 'test': dx = dout return dx FC with DP Â∫îËØ•Âú®ÊØèÂ±ÇÁöÑrelu‰πãÂêéÔºåÂ¢ûÂä†dropoutÁöÑÈÉ®ÂàÜ Âú®‰πãÂâçÂÆö‰πâÁöÑfunctionÈáåÈù¢Âä†‰∏äÊñ∞ÁöÑdropoutÈÉ®ÂàÜÔºåÂõ†‰∏∫ÂÄîÂº∫ÁöÑÊÉ≥Âä†Âú®ÂÆö‰πâÂ•ΩÁöÑÂáΩÊï∞ÈáåÈù¢ÔºåÊâÄ‰ª•‰∫ßÁîü‰∫Ü‰∏Ä‰∫õÂ•áÊÄ™ÁöÑÂª∂‰º∏ÈóÆÈ¢ò Â¶ÇÊûúÊÉ≥Ë¶ÅÂèØÈÄâÂèÇÊï∞ÔºåÂú®def functionÈáåÈù¢Áõ¥Êé•ÂÆö‰πâÂ•ΩÂ∞±Ë°å‰∫Ü Â¶ÇÊûúËøîÂõûÂÄº‰∏çÈúÄË¶ÅÔºåÁõ¥Êé•Âú®ËøîÂõûÁöÑÊó∂ÂÄô_Â∞±Â•Ω‰∫Ü Ê≥®ÊÑèÂú®fc_netÈáåÈù¢Â¶ÇÊûúdropout = 1 ÁöÑËØùÔºåÂÆûÈôÖ‰∏äÁöÑflagÊòØÊ≤°ÊúâÊÑè‰πâÁöÑ 1234567891011121314151617181920212223242526272829303132333435363738def affine_Normal_relu_dropout_forward(self, x, w, b, mode, gamma=None, beta=None, bn_params=None): Normal_cache = None dp_cache = None a, fc_cache = affine_forward(x, w, b) if mode == "batchnorm": mid, Normal_cache = batchnorm_forward(a, gamma, beta, bn_params) elif mode == "layernorm": mid, Normal_cache = layernorm_forward(a, gamma, beta, bn_params) else: mid = a dp, relu_cache = relu_forward(mid) if self.use_dropout: out, dp_cache = dropout_forward(dp, self.dropout_param) else: out = dp cache = (fc_cache, Normal_cache, relu_cache, dp_cache) return out, cachedef affine_Normal_relu_dropout_backward(self, dout, cache, mode): fc_cache, Normal_cache, relu_cache, dp_cache = cache dgamma = 0.0 dbeta = 0.0 if self.use_dropout: ddp = dropout_backward(dout, dp_cache) else: ddp = dout da = relu_backward(ddp, relu_cache) if mode == "batchnorm": dmid, dgamma, dbeta = batchnorm_backward_alt(da, Normal_cache) elif mode == "layernorm": dmid, dgamma, dbeta = layernorm_backward(da, Normal_cache) else: dmid = da dx, dw, db = affine_backward(dmid, fc_cache) return dx, dw, db, dgamma, dbeta regularization experiment ËÆ≠ÁªÉ‰∏Ä‰∏™2Â±ÇÁöÑÁΩëÁªúÔºå500‰∏™trainingÔºå‰∏Ä‰∏™Ê≤°ÊúâdropoutÔºåÂè¶‰∏Ä‰∏™0.25ÁöÑdp Âπ∂‰∏îÂèØËßÜÂåñ‰∫ÜÊúÄÁªàÁöÑÁªìÊûú ‰ªéÁªìÊûú‰∏äÊù•ÁúãÊÑüËßâÔºåÂ¶ÇÊûúepochÊØîËæÉÂ∞ëÁöÑËØùÔºådropoutÁöÑÊïàÊûú‰ºöÊõ¥Â•Ω Âä†‰∏ädropoutÔºånormalizationÔºåÁöÑfcÁΩëÁªúÂÖ®ÈÉ®‰ª£Á†Å123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260class FullyConnectedNet(object): """ A fully-connected neural network with an arbitrary number of hidden layers, ReLU nonlinearities, and a softmax loss function. This will also implement dropout and batch/layer normalization as options. For a network with L layers, the architecture will be &#123;affine - [batch/layer norm] - relu - [dropout]&#125; x (L - 1) - affine - softmax where batch/layer normalization and dropout are optional, and the &#123;...&#125; block is repeated L - 1 times. Similar to the TwoLayerNet above, learnable parameters are stored in the self.params dictionary and will be learned using the Solver class. """ def __init__(self, hidden_dims, input_dim=3 * 32 * 32, num_classes=10, dropout=1, normalization=None, reg=0.0, weight_scale=1e-2, dtype=np.float32, seed=None): """ Initialize a new FullyConnectedNet. Inputs: - hidden_dims: A list of integers giving the size of each hidden layer. - input_dim: An integer giving the size of the input. - num_classes: An integer giving the number of classes to classify. - dropout: Scalar between 0 and 1 giving dropout strength. If dropout=1 then the network should not use dropout at all. - normalization: What type of normalization the network should use. Valid values are "batchnorm", "layernorm", or None for no normalization (the default). - reg: Scalar giving L2 regularization strength. - weight_scale: Scalar giving the standard deviation for random initialization of the weights. - dtype: A numpy datatype object; all computations will be performed using this datatype. float32 is faster but less accurate, so you should use float64 for numeric gradient checking. - seed: If not None, then pass this random seed to the dropout layers. This will make the dropout layers deteriminstic so we can gradient check the model. """ self.normalization = normalization self.use_dropout = dropout != 1 self.reg = reg self.num_layers = 1 + len(hidden_dims) self.dtype = dtype self.params = &#123;&#125; ############################################################################ # TODO: Initialize the parameters of the network, storing all values in # # the self.params dictionary. Store weights and biases for the first layer # # in W1 and b1; for the second layer use W2 and b2, etc. Weights should be # # initialized from a normal distribution centered at 0 with standard # # deviation equal to weight_scale. Biases should be initialized to zero. # # # # When using batch normalization, store scale and shift parameters for the # # first layer in gamma1 and beta1; for the second layer use gamma2 and # # beta2, etc. Scale parameters should be initialized to ones and shift # # parameters should be initialized to zeros. # ############################################################################ pr_num = input_dim # can't use enumerate beacuse I need the number more than the size of hidden_dims for layer in range(self.num_layers): layer += 1 weights = 'W' + str(layer) bias = 'b' + str(layer) # ËøôÊó∂ÂÄôÊòØÊúÄÂêé‰∏ÄÂ±Ç(the last layer) if layer == self.num_layers: self.params[weights] = np.random.randn( hidden_dims[len(hidden_dims) - 1], num_classes) * weight_scale self.params[bias] = np.zeros(num_classes) # other layers else: hidd_num = hidden_dims[layer - 1] self.params[weights] = np.random.randn( pr_num, hidd_num) * weight_scale self.params[bias] = np.zeros(hidd_num) pr_num = hidd_num if self.normalization in ["batchnorm", "layernorm"]: self.params['gamma' + str(layer)] = np.ones(hidd_num) self.params['beta' + str(layer)] = np.zeros(hidd_num) # print(len(self.params)) # print(self.params) ############################################################################ # END OF YOUR CODE # ############################################################################ # When using dropout we need to pass a dropout_param dictionary to each # dropout layer so that the layer knows the dropout probability and the mode # (train / test). You can pass the same dropout_param to each dropout layer. self.dropout_param = &#123;&#125; if self.use_dropout: self.dropout_param = &#123;'mode': 'train', 'p': dropout&#125; if seed is not None: self.dropout_param['seed'] = seed # With batch normalization we need to keep track of running means and # variances, so we need to pass a special bn_param object to each batch # normalization layer. You should pass self.bn_params[0] to the forward pass # of the first batch normalization layer, self.bn_params[1] to the forward # pass of the second batch normalization layer, etc. self.bn_params = [] if self.normalization == 'batchnorm': self.bn_params = [&#123;'mode': 'train'&#125; for i in range(self.num_layers - 1)] if self.normalization in ["batchnorm", "layernorm"]: self.bn_params = [&#123;&#125; for i in range(self.num_layers - 1)] # Cast all parameters to the correct datatype for k, v in self.params.items(): self.params[k] = v.astype(dtype) def loss(self, X, y=None): """ Compute loss and gradient for the fully-connected net. Input / output: Same as TwoLayerNet above. """ X = X.astype(self.dtype) mode = 'test' if y is None else 'train' # Set train/test mode for batchnorm params and dropout param since they # behave differently during training and testing. if self.use_dropout: self.dropout_param['mode'] = mode if self.normalization == 'batchnorm': for bn_param in self.bn_params: bn_param['mode'] = mode scores = None ############################################################################ # TODO: Implement the forward pass for the fully-connected net, computing # # the class scores for X and storing them in the scores variable. # # # # When using dropout, you'll need to pass self.dropout_param to each # # dropout forward pass. # # # # When using batch normalization, you'll need to pass self.bn_params[0] to # # the forward pass for the first batch normalization layer, pass # # self.bn_params[1] to the forward pass for the second batch normalization # # layer, etc. # ############################################################################ cache = &#123;&#125; temp_out = X for i in range(self.num_layers): w = self.params['W' + str(i + 1)] b = self.params['b' + str(i + 1)] if i == self.num_layers - 1: scores, cache['cache' + str(i + 1)] = affine_forward(temp_out, w, b) else: if self.normalization in ["batchnorm", "layernorm"]: gamma = self.params['gamma' + str(i + 1)] beta = self.params['beta' + str(i + 1)] temp_out, cache['cache' + str(i + 1)] = self.affine_Normal_relu_dropout_forward( temp_out, w, b, self.normalization, gamma, beta, self.bn_params[i]) else: # temp_out, cache['cache' + # str(i + 1)] = affine_relu_forward(temp_out, w, b) temp_out, cache['cache' + str(i + 1)] = self.affine_Normal_relu_dropout_forward( temp_out, w, b, mode=self.normalization) ############################################################################ # END OF YOUR CODE # ############################################################################ # If test mode return early if mode == 'test': return scores loss, grads = 0.0, &#123;&#125; ############################################################################ # TODO: Implement the backward pass for the fully-connected net. Store the # # loss in the loss variable and gradients in the grads dictionary. Compute # # data loss using softmax, and make sure that grads[k] holds the gradients # # for self.params[k]. Don't forget to add L2 regularization! # # # # When using batch/layer normalization, you don't need to regularize the scale# # and shift parameters. # # # # NOTE: To ensure that your implementation matches ours and you pass the # # automated tests, make sure that your L2 regularization includes a factor # # of 0.5 to simplify the expression for the gradient. # ############################################################################ loss, dscores = softmax_loss(scores, y) reg_loss = 0.0 pre_dx = dscores # dgamma = self.params['gamma'] for i in reversed(range(self.num_layers)): i = i + 1 reg_loss = np.sum(np.square(self.params['W' + str(i)])) loss += reg_loss * 0.5 * self.reg # ÊúÄÂêé‰∏ÄÂ±Ç if i == self.num_layers: pre_dx, dw, db = affine_backward( pre_dx, cache['cache' + str(i)]) else: if self.normalization in ["batchnorm", "layernorm"]: pre_dx, dw, db, dgamma, dbeta = self.affine_Normal_relu_dropout_backward( pre_dx, cache['cache' + str(i)], self.normalization) grads['gamma' + str(i)] = dgamma grads['beta' + str(i)] = dbeta else: pre_dx, dw, db, _, _ = self.affine_Normal_relu_dropout_backward( pre_dx, cache['cache' + str(i)], self.normalization) dw += self.reg * self.params['W' + str(i)] db += self.reg * self.params['b' + str(i)] grads['W' + str(i)] = dw grads['b' + str(i)] = db ############################################################################ # END OF YOUR CODE # ############################################################################ return loss, grads def affine_Normal_relu_dropout_forward(self, x, w, b, mode, gamma=None, beta=None, bn_params=None): Normal_cache = None dp_cache = None a, fc_cache = affine_forward(x, w, b) if mode == "batchnorm": mid, Normal_cache = batchnorm_forward(a, gamma, beta, bn_params) elif mode == "layernorm": mid, Normal_cache = layernorm_forward(a, gamma, beta, bn_params) else: mid = a dp, relu_cache = relu_forward(mid) if self.use_dropout: out, dp_cache = dropout_forward(dp, self.dropout_param) else: out = dp cache = (fc_cache, Normal_cache, relu_cache, dp_cache) return out, cache def affine_Normal_relu_dropout_backward(self, dout, cache, mode): fc_cache, Normal_cache, relu_cache, dp_cache = cache dgamma = 0.0 dbeta = 0.0 if self.use_dropout: ddp = dropout_backward(dout, dp_cache) else: ddp = dout da = relu_backward(ddp, relu_cache) if mode == "batchnorm": dmid, dgamma, dbeta = batchnorm_backward_alt(da, Normal_cache) elif mode == "layernorm": dmid, dgamma, dbeta = layernorm_backward(da, Normal_cache) else: dmid = da dx, dw, db = affine_backward(dmid, fc_cache) return dx, dw, db, dgamma, dbeta]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
        <category>CS231n‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>Drop out</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGLÁ¨îËÆ∞]]></title>
    <url>%2F2019%2F04%2F16%2FOpenGL%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Learn OpenGl on Modern OpenGL. -&gt; ‰ªégraphicsÁöÑprogrammingÂºÄÂßãËÆ≤ÁöÑ Getting StartOPENGL ÊòØ‰∏Ä‰∏™ËøõË°åÂõæÂÉèÂ§ÑÁêÜÁöÑÂ∑•ÂÖ∑ ÂèØ‰ª•Ë¢´ËÆ§‰∏∫ÊòØAPIÔºå‰ΩÜÊòØÂÆûÈôÖ‰∏äÊòØspecification ÊòéÁ°ÆËØ¥Êòé‰∫ÜÊØè‰∏™functionÂ∫îËØ•ÁöÑËæìÂÖ•ÂíåËæìÂá∫Ôºå‰ª•ÂèäÂ¶Ç‰Ωïperform Áî®Êà∑Âú®Áî®Ëøô‰∏™ËØ¥ÊòéÊù•Ëß£ÂÜ≥ÈóÆÈ¢òÔºåÂõ†‰∏∫Ê≤°ÊúâÁªôÂá∫ÊòéÁ°ÆÁöÑimplementÁöÑËøáÁ®ãÔºåÊâÄ‰ª•Âè™Ë¶ÅÁªìÊûúÁ¨¶ÂêàËßÑÂàôÔºåÊÄé‰πàimplementÈÉΩÂèØ‰ª• Core-profile vs Immediate mode ‰ª•ÂâçÁöÑÁâàÊú¨Áî®ÁöÑÊòØimmediate mode ÊØîËæÉÂ•ΩÁî®Êù•ÁîªÂõæ ÂÖ∑‰ΩìÁöÑÊòØÂÆûÁé∞ÈÉΩÂú®libÈáåÈù¢Ôºådeveloper‰∏çÊòØÂæàÂ•ΩÁöÑËÉΩÁúãÂà∞Â¶Ç‰ΩïËÆ°ÁÆó ÊïàÁéáË∂äÊù•Ë∂ä‰Ωé Core-profile Âú®3.2ÁâàÊú¨‰πãÂêéÊîπÊàê‰∫ÜËøô‰∏™ Âº∫Âà∂‰ΩøÁî®modern practicesÔºåÂ¶ÇÊûúÊÉ≥Ë¶ÅÁî®Ë¢´ÂàÜÂá∫ÂéªÁöÑfunctionÂ∞±‰ºöÁõ¥Êé•Êä•Èîô ÊïàÁéáÈ´òÔºåÊõ¥ÁÅµÊ¥ªÔºåÊõ¥ÈöæÂ≠¶ extensions ÊîØÊåÅextensionsÔºåÂè™Ë¶ÅÊ£ÄÊü•ÊîØ‰∏çÊîØÊåÅgraphic cardÂ∞±ÂèØ‰ª•Áü•ÈÅìËÉΩ‰∏çËÉΩÁî® ÂèØ‰ª•Áõ¥Êé•Áî®ÊØîËæÉÊñ∞ÁöÑ‰∏úË•øÔºå‰∏çÁî®Á≠âÁùÄOPENGLÊõ¥Êñ∞Êñ∞ÁöÑÂäüËÉΩ ÈúÄË¶ÅÂú®Áî®‰πãÂâçÂà§Êñ≠‰ªñÊòØ‰∏çÊòØavailableÁöÑÔºåÂ¶ÇÊûú‰∏çÊòØÈúÄË¶ÅÁî®ÂéüÊù•ÁöÑÊñπÊ≥ïÊêû State Machine OpenGLËá™Â∑±Â∞±ÊòØ‰∏Ä‰∏™State MachineÔºö‰∏Ä‰∏™varÁöÑÈõÜÂêàÔºåÊù•Âà§Êñ≠‰ªñÁé∞Âú®Â∫îËØ•Â¶Ç‰ΩïÊìç‰Ωú state -&gt; context ÊîπÂèòstateÔºöËÆæÂÆö‰∏Ä‰∫õoptionsÔºåÊìç‰Ωú‰∏Ä‰∫õbufferÔºåÂú®Áé∞Âú®ÁöÑcontextÊù•render ‰æãÂ≠êÔºö Â¶ÇÊûúÊàëÊÉ≥Áîª‰∏âËßíÂΩ¢ÔºåËÄå‰∏çÊòØÁîªÁ∫ø‰∫ÜÔºåÂ∞±ÊîπÂèòdrawÁöÑstate Âè™Ë¶ÅËøô‰∏™ÊîπÂèò‰º†ËææÂà∞‰∫ÜÔºå‰∏ã‰∏ÄÊù°Á∫øÂ∞±ÁîªÁöÑÊòØ‰∏âËßíÂΩ¢‰∫Ü state-changingÁî®Êù•ÊîπÂèòcontextÔºåstate-usingÂú®Áé∞Âú®ÁöÑstate‰∏äÈù¢ÂºÄÂßãËøõË°åÊìç‰Ωú Objects ‰∏Ä‰∏™ÈõÜÂêàÊù•Ë°®Áé∞OpenGLÁöÑsubsetÁöÑstate ÊØîÂ¶ÇÂèØ‰ª•Áî®‰∏Ä‰∏™objectÊù•Ë°®Á§∫ÂØπwindowÁöÑËÆæÂÆöÔºåÂèØ‰ª•ËÆæÁΩÆÂ§ßÂ∞èÔºåËÆæÁΩÆÊîØÊåÅÁöÑÈ¢úËâ≤Á≠âÁ≠â123456// The State of OpenGLstruct OpenGL_Context &#123; ... object_name* object_Window_Target; ... &#125;; 12345678910// create objectunsigned int objectId = 0;glGenObject(1, &amp;objectId);// bind object to contextglBindObject(GL_WINDOW_TARGET, objectId);// set options of object currently bound to GL_WINDOW_TARGETglSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_WIDTH, 800);glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_HEIGHT, 600);// set context target back to defaultglBindObject(GL_WINDOW_TARGET, 0); ÊµÅÁ®ã È¶ñÂÖàÂàõÂª∫‰∫Ü‰∏Ä‰∏™objectÔºåÈáåÈù¢Â≠ò‰∫Ü‰∏Ä‰∏™refÊòØËøô‰∏™objectÁöÑid ÁÑ∂ÂêéÊääËøô‰∏™objectÂíåcontextÁöÑÁõÆÊ†á‰ΩçÁΩÆbindÂú®‰∫Ü‰∏ÄËµ∑ ËÆæÁΩÆ‰∫ÜËøô‰∫õwindowÁöÑÂèÇÊï∞ ÊúÄÂêéun-bindËøô‰∏§‰∏™‰∏úË•øÔºåÊääwindow targetÊîπÂõûÂéüÊù•ÁöÑÂÄº ËøôÊ†∑ÁöÑËØùÊàë‰ª¨ÂèØ‰ª•ÂàõÂª∫ÂæàÂ§öobjectÔºåÊèêÂâçËÆæÁΩÆÂ•ΩÈáåÈù¢ÁöÑÈáèÔºåÁ≠âÂà∞ÈúÄË¶ÅÁî®ÁöÑÊó∂ÂÄôÂ∞±Áõ¥Êé•bindÂ∞±ÂèØ‰ª•Áî®‰∫Ü ÊØîÂ¶ÇÊàë‰ª¨Êúâ‰∏ÄÂ†ÜobjectÂåÖÂê´‰∫ÜÂ∞è‰∫∫ÔºåÂ∞èÈ©¨ÔºåÂ∞èÈπø ÊÉ≥ÁîªÂì™‰∏™Â∞±ÊääÂì™‰∏™ÁªëÂÆöÂà∞drawÈáåÈù¢ÔºåÂ∞±ÂèØ‰ª•Áõ¥Êé•ÁîªÂá∫Êù•‰∫Ü Crateing a windowÂõ†‰∏∫Êìç‰ΩúÁ≥ªÁªüÁöÑÈóÆÈ¢òÔºåÊâÄÊúâÊìç‰ΩúÁ≥ªÁªü‰∏äÈù¢‰∏çÊòØÂæà‰∏ÄÊ†∑„ÄÇ‰ΩÜÊòØÂ∑≤ÁªèÊúâ‰∏Ä‰∫õÊèê‰æõËøô‰∫õÂäüËÉΩÁöÑÂáΩÊï∞‰∫ÜÔºåËøôÈáåÁî®ÁöÑÊòØGLFW GLFW ‰∏Ä‰∏™libÔºåÁî®CÂÜôÁöÑÔºå‰∏ªË¶ÅÁõÆÁöÑÊòØÊèê‰æõÊää‰∏úË•øÊ∏≤ÊüìÂà∞Â±èÂπïÁöÑÂäüËÉΩ ÂèØ‰ª•ÂàõÂª∫‰∏Ä‰∏™contextÔºåÂÆö‰πâÁ™óÂè£ÁöÑparamsÔºåÂ§ÑÁêÜÁî®Êà∑ÁöÑËæìÂÖ• Â∑≤Áªè‰∏ÄÂè£Ê∞îÈÖçÁΩÆÂ•Ω‰∫ÜËøô‰∫õÔºÅhttps://www.jianshu.com/p/25d5fbf792a2ËÆ∞ÂæóÂú®link libÈáåÈù¢ÊääopenGLÁöÑframeworkÂä†ËøõÂéªÔºÅÔºÅÔºÅÔºÅÔºÅ GLAD Âõ†‰∏∫openGLËøòÈúÄË¶Å‰∏çÂêåÁâàÊú¨ÁöÑdriverÁöÑÊîØÊåÅÔºåÈúÄË¶ÅÊúâ‰∏úË•øÊù•Â§ÑÁêÜËøôÈÉ®ÂàÜÁöÑÂÜÖÂÆπ ÂíåÂÖ∂‰ªñÁöÑ‰∏úË•ø‰∏çÂêåÔºåGLADÁî®ÁöÑÊòØweb service Âú®Ëøô‰∏™ÁΩëÈ°µ‰∏äÈÄâÊã©Â•ΩËØ≠Ë®ÄÔºåÁâàÊú¨Âè∑ÔºåÁ°Æ‰øùprofileÊòØcoreÔºåÁÑ∂ÂêéÁîüÊàê Áõ¥Êé•‰∏ãËΩΩ‰∏ãÊù•ÂØπÂ∫îÁöÑzipÔºåÁÑ∂ÂêéÊääincludeÊîæËøõincludeÈáåÈù¢Ôºå.cÊñá‰ª∂ÊîæÂú®projectÈáåÈù¢ Ëé´ÂêçÂÖ∂Â¶ôÂπ∂‰∏çÈúÄË¶ÅËøô‰∏ÄÊ≠•ÔºåÁ•ûÂ•áÔºåÂèØËÉΩÊòØÊàëÂú®includeÈáåÈù¢Â∑≤ÁªèÊêûËøõÊù•‰∫ÜÔºÅÔºÅ Hello WindowÂàùÂßãÂåñ12345678910int main()&#123; glfwInit(); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); //glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); return 0;&#125; È¶ñÂÖàËøõË°å‰∫ÜÂàùÂßãÂåñ ÁÑ∂Âêéconfigure‰∫ÜGLFWÔºåËÆæÁΩÆ‰∫Üa large enum of possible options prefixed with GLFW_. ÔºàÁ¨¨‰∏âË°åÂ∞±ÊòØÊúÄÂ∞èÔºâ -&gt; Â§ßÊ¶ÇÊòØËÆæÁΩÆË¶ÅÁî®GLFWÁöÑÁâàÊú¨Âè∑ ÁÑ∂Âêé‰πüÂëäËØâ‰∫Ü‰ªñÊÉ≥Áî®core ÁÑ∂ÂêéÈúÄË¶Å‰ΩøÁî®glfwCreateWindowËøô‰∏™ÂáΩÊï∞ÔºåÊù•ÂàõÂª∫Ëøô‰∏™GLFWwindow* windowÁöÑÂèòÈáè ÂàõÂª∫ÁöÑÂáΩÊï∞ÈúÄË¶ÅÁ™óÂè£ÁöÑÈïøÂÆΩ Á™óÂè£Âêç ÂàõÂª∫ÂÆå‰πãÂêéÂ∞±ÂèØ‰ª•ÊääËøô‰∏™Á™óÂè£ËÆæÁΩÆÊàêglfwMakeContextCurrent(window);‰πüÂ∞±ÊòØËØ¥ËÆæÁΩÆÊàê‰∫ÜÁé∞Âú®ÁöÑthreadÈáåÈù¢12345678GLFWwindow* window = glfwCreateWindow(800, 600, "LearnOpenGL", NULL, NULL);if (window == NULL)&#123; std::cout &lt;&lt; "Failed to create GLFW window" &lt;&lt; std::endl; glfwTerminate(); return -1;&#125;glfwMakeContextCurrent(window); GLAD GLADÊòØ‰∏∫OpenGLÊù•ÁÆ°ÁêÜËøô‰∫õÂáΩÊï∞ÁöÑÔºåÂú®‰ΩøÁî®Ëøô‰∫õÂáΩÊï∞‰πãÂâçÈúÄË¶ÅÂàùÂßãÂåñGLAD12345if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress))&#123; std::cout &lt;&lt; "Failed to initialize GLAD" &lt;&lt; std::endl; return -1;&#125; viewpoint Âú®ÂºÄÂßãrender‰πãÂâçÊàë‰ª¨ËøòÈúÄË¶ÅÂëäËØâGLÊ∏≤ÊüìÁ™óÂè£ÁöÑÂ§ßÂ∞èÔºåÁî®Âà∞‰∫ÜglViewportËøô‰∏™ÂáΩÊï∞ ÂâçÈù¢‰∏§‰∏™ÂèÇÊï∞ÂÆö‰πâ‰∫ÜËøô‰∏™Á™óÂè£Â∑¶‰∏ãËßíÁöÑÂùêÊ†á ÂêéÈù¢‰∏§‰∏™ÂèÇÊï∞ÂÆö‰πâ‰∫ÜÈúÄË¶ÅrenderÁöÑÁ™óÂè£ÁöÑÂ§ßÂ∞è ÊØèÊ¨°Ë∞ÉÊï¥windowÁöÑÂ§ßÂ∞èÁöÑÊó∂ÂÄôviewport‰πüÈúÄË¶ÅË¢´Ë∞ÉÊï¥ engines Êàë‰ª¨Â∏åÊúõËøô‰∏™engineÂèØ‰ª•‰∏ÄÁõ¥ÊåÅÁª≠ÁîªÂõæÔºåÁõ¥Âà∞ÊúÄÂêéÊàë‰ª¨ÂëäËØâËøô‰∏™Á™óÂè£Ë¶ÅÂÖ≥Èó≠ÔºåÊâÄ‰ª•Ë¶ÅÂª∫Á´ã‰∏Ä‰∏™Âæ™ÁéØ 12345while(!glfwWindowShouldClose(window))&#123; glfwSwapBuffers(window); glfwPollEvents(); &#125; Âú®Ëøô‰∏™Âæ™ÁéØÈáåÈù¢ÔºåpolleventÊòØÊù•Ê£ÄÊü•ÊòØ‰∏çÊòØÊúâtriggerËøõÊù•ÁöÑ‰∫ãÊÉÖÔºàÊØîÂ¶ÇÈîÆÁõòËæìÂÖ•ÔºâÔºåÊõ¥Êñ∞Á™óÂè£ÁöÑÁä∂ÊÄÅÔºåÂπ∂‰∏îcallÁõ∏Â∫îÁöÑÂáΩÊï∞ swapbufferÔºå‰ºö‰∫§Êç¢color bufferÔºàÂåÖÊã¨ÊØè‰∏™ÂÉèÁ¥†ÁÇπÈ¢úËâ≤ÁöÑbufferÔºâÔºåÁÑ∂ÂêéshowÂú®Á™óÂè£ÈáåÈù¢ last thing glfwTerminateÈÄÄÂá∫Ëøô‰∏™Âæ™ÁéØ‰πãÂêéÔºåÈúÄË¶ÅÊ∏ÖÈô§Ëøô‰∫õÁõ∏ÂÖ≥ÁöÑËµÑÊ∫êÔºåÁî®Ëøô‰∏™ÂáΩÊï∞ÊîæÂú®ÊúÄÂ∫ï‰∏ã input ÈúÄË¶Å‰∏Ä‰∫õÈîÆÁõò‰∏äÁöÑÊìç‰ΩúÊù•Ë∞ÉÊï¥ÁöÑÊó∂ÂÄôÔºåÂÜô‰∫Ü‰∏Ä‰∏™processInputÁöÑÂáΩÊï∞ ÊØîÂ¶Ç‰∏ãÈù¢Ëøô‰∏™ÂáΩÊï∞Â∞±ÊòØÊ£ÄÊµã‰∫ÜÊúâÊ≤°ÊúâÊåâ‰∏ãÂéªescÔºåÂ¶ÇÊûúÊåâ‰∫ÜÁöÑËØùÂ∞±ÂÖ≥Èó≠Á™óÂè£ ÂÜôÂÆå‰πãÂêéÊääËøô‰∏™ÂáΩÊï∞Âú®whileÂæ™ÁéØÈáåÈù¢Ë∞ÉÁî®12345void processInput(GLFWwindow *window)&#123; if(glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) glfwSetWindowShouldClose(window, true);&#125; rendering Â∏åÊúõÂú®‰∏Ä‰∏™loopÈáåÈù¢Êîæ‰∏äÂéªÊâÄÊúâÁöÑrenderingÁöÑÂëΩ‰ª§ÔºåÊï¥‰∏™Âæ™ÁéØÁúãËµ∑Êù•Â∫îËØ•ÊòØËøô‰∏™Ê†∑Â≠êÁöÑ12345678910111213// render loopwhile(!glfwWindowShouldClose(window))&#123; // input processInput(window); // rendering commands here ... // check and call events and swap the buffers glfwPollEvents(); glfwSwapBuffers(window);&#125; hello triangleopenglÈáåÈù¢ÊâÄÊúâ‰∏úË•øÈÉΩÊòØÂú®3DÁöÑÁ©∫Èó¥ÈáåÁöÑÔºå‰ΩÜÊòØÂ±èÂπï‰∏äÊòæÁ§∫ÁöÑ‰∏úË•øÊòØ2DÁöÑ„ÄÇÊï¥‰∏™Ëøô‰∏™ËΩ¨Êç¢ÁöÑËøáÁ®ãÂè´ÂÅögraphics pipelineÔºåÂèØ‰ª•ÂàÜÊàê‰∏§‰∏™Ê≠•È™§ÔºöÁ¨¨‰∏Ä‰∏™ÊòØÊääÁâ©‰ΩìÁöÑ3DÂùêÊ†áËΩ¨ÂåñÊàê2DÁöÑÂùêÊ†áÔºåÁ¨¨‰∫å‰∏™ÊòØÊää2DÁöÑÂùêÊ†áËΩ¨ÂåñÊàêpixel‰∏äÈù¢ÁöÑÂÖ∑‰ΩìÂÄº pipeline ÊâÄÊúâÁöÑËΩ¨ÂåñÊ≠•È™§ÈÉΩÂèØ‰ª•parallelÁöÑËøõË°åÔºåÁé∞Âú®ÁöÑÊòæÂç°ÊúâÂæàÂ§öÂ∞èÁöÑcoreÊù•ËøõË°å -&gt; shaders Âú®ÊúÄÂºÄÂßãÁöÑÊó∂ÂÄôpassËøõÂéª‰∫Ü‰∏Ä‰∏™listÁöÑ3DÂùêÊ†á ÔºàVertex DataÔºâ Á¨¨‰∏ÄÊ≠•Ôºövertex shader Êää3DÁöÑÂùêÊ†áËΩ¨ÂåñÊàê‰∏çÂêåÁöÑ3DÂùêÊ†áÔºàÁõ∏ÂΩì‰∫éÊääÊï∞ÊçÆËΩ¨ÂåñÊàêÁÇπÔºüÔºâ primitive assembly ‰ªé‰∏ä‰∏ÄÊ≠•ÂæóÂà∞ÁöÑÂ∑¶Âè≥ÁöÑÁÇπÂæóÂà∞ËæìÂÖ• ÁÑ∂ÂêéÂΩ¢Êàê‰∏Ä‰∏™Âü∫Êú¨ÁöÑÂõæÂΩ¢ geometry shader Ê†πÊçÆÊñ∞ÁªôÁöÑÁÇπÔºåÂΩ¢ÊàêÊñ∞ÁöÑ‰∏çÂêåÁöÑÂΩ¢Áä∂ÔºåÊØîÂ¶ÇÂú®‰æãÂ≠êÈáåÈù¢ÂΩ¢Êàê‰∫ÜÊñ∞ÁöÑ‰∏ÄÊù°Á∫ø rasterization stage Êää‰∏äÈù¢ÂæóÂà∞ÁöÑprimitives mapÂà∞ÊúÄÂêéÁöÑÂ±èÂπï‰∏äÈù¢ÁöÑÁõ∏Â∫îÁöÑpixel‰∏äÈù¢ Clipping Ëøô‰∏ÄÊ≠•‰∏¢Êéâ‰∫ÜÊâÄÊúâÂú®ËßÜÁ∫øÂ§ñÈù¢ÁöÑfragmentsÔºåÊèêÂçáÊÄßËÉΩ fragment shader ËÆ°ÁÆóËøô‰∏™pixelÊúÄÂêéÁöÑÈ¢úËâ≤Ôºå‰ºöÂú®Ëøô‰∏ÄÊ≠•ËÆ°ÁÆóÂÖâÂΩ±Ôºå‰ª•ÂèäÂÖâÁ∫øÁöÑÈ¢úËâ≤Á≠âÁ≠â‰∏úË•ø ÂΩìÊØè‰∏™ÂÉèÁ¥†ÁöÑÈ¢úËâ≤ÂÜ≥ÂÆö‰∫Ü‰ª•ÂêéÔºåËøô‰∏™object‰ºöË¢´ÈÄÅÂà∞alpha testÂíåblending Ëøô‰∏ÄÊ≠•‰ºöÊµãËØïÊ∑±Â∫¶ÂéüÂõ†ÔºåÂà§Êñ≠fragmentÊòØÂú®Áâ©‰ΩìÁöÑÂâçÈù¢ËøòÊòØÂêéÈù¢ Ëøò‰ºöËÄÉËôëÈÄèÊòéÂ∫¶ÁöÑÈóÆÈ¢òËôΩÁÑ∂‰∏äÈù¢ÁöÑ‰∏úË•øÂæàÂ§çÊùÇÔºå‰ΩÜÊòØÂú®ÂÆûÈôÖÂ∫îÁî®ÁöÑÊó∂ÂÄôÂè™ÈúÄË¶ÅË¶ÅËÄÉËôëvertexÂíåfragment shader vertex input openGLÊòØ3DÁöÑ‰∏úË•øÔºåÊâÄÊúâÁöÑÁÇπËÆæÁΩÆinputÁöÑÊó∂ÂÄôÈÉΩÈúÄË¶ÅËÆæÁΩÆ‰∏âÁª¥ÁöÑÂùêÊ†á xyz Âè™ÊúâÂú®ÂùêÊ†áÂú® -1 Âà∞ 1 ‰∏≠Èó¥ÁöÑÊó∂ÂÄôÔºåÊâç‰ºöÂ§ÑÁêÜËøô‰∫õÂùêÊ†áÔºåËøô‰∏™ËåÉÂõ¥ÈáåÈù¢ÁöÑÊï∞Â≠óÊòØÊ†πÊçÆÂ±èÂπïÁöÑÊØî‰æãÂæóÂá∫Êù•ÁöÑnormalized device coordinates ÊØîÂ¶ÇÂú®Ëøô‰∏™‰æãÂ≠êÈáåÈù¢ÔºåÈúÄË¶ÅÁöÑÊ∏≤Êüì‰∏Ä‰∏™‰∏âËßíÂΩ¢ÔºåÈÇ£‰πàÈúÄË¶ÅËøô‰∏™‰∏âËßíÂΩ¢ÁöÑ‰∏â‰∏™ÁÇπÁöÑÂùêÊ†á„ÄÇÊ≥®ÊÑèËøô‰∏™‰æãÂ≠êÈáåÈù¢Ê†πÊú¨Ê≤°ÊúâËÄÉËôëÊ∑±Â∫¶ÔºåËÄåÊòØÁõ¥Êé•ÁîªÂú®‰∫ÜÂπ≥Èù¢‰∏äÈù¢ 12345float vertices[] = &#123; -0.5f, -0.5f, 0.0f, 0.5f, -0.5f, 0.0f, 0.0f, 0.5f, 0.0f&#125;; Âú®ÂÆö‰πâÂ•ΩÂùêÊ†á‰πãÂêéÈúÄË¶ÅÊääËøô‰∏™‰∏úË•øÊîæËøõvertex shaderÈáåÈù¢ÔºåÈúÄË¶ÅÂú®GPUÈáåÈù¢ÂàõÂª∫‰∏ÄÈÉ®ÂàÜÂÜÖÂ≠òÊù•Â≠òÂÇ®Ëøô‰∏™Êï∞ÊçÆÔºåÂπ∂‰∏îÈúÄË¶ÅÂú®GPUÈáåÈù¢Â≠òÂÇ®Â§ßÈáèÁöÑÊï∞ÊçÆÔºàËøôÊ†∑‰∏çÁî®ÊØèÊ¨°ÈÉΩÈÄÅ‰∫ÜÔºâ ÊØè‰∏™ÈÉ®ÂàÜÁöÑobjectÈÉΩ‰ºöÊúâ‰∏Ä‰∏™Ëá™Â∑±ÁöÑbuffer idÔºåÂèØ‰ª•ÈÄöËøá‰∏ãÈù¢ÁöÑÊñπÊ≥ïÁîüÊàê‰∏Ä‰∏™id„ÄÇ‰πüÂèØ‰ª•Êää‰∏Ä‰∏≤arrayÁªëÂà∞Ëøô‰∏™id‰∏äÈù¢12unsigned int VBO;glGenBuffers(1, &amp;VBO);]]></content>
      <categories>
        <category>OpenGl</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment2‰πãBatch Normalization]]></title>
    <url>%2F2019%2F04%2F15%2FCS231Nassignment2BN%2F</url>
    <content type="text"><![CDATA[target ‰πãÂâçÁöÑÂÜÖÂÆπËÆ≤‰∫ÜlrÁöÑ‰ºòÂåñÊñπÊ≥ïÔºåÊØîÂ¶ÇAdamÔºåÂè¶‰∏ÄÁßçÊñπÊ≥ïÊòØÊ†πÊçÆÊîπÂèòÁΩëÁªúÁöÑÁªìÊûÑÔºåmake it easy to train -&gt; batch normalization ÊÉ≥ÂéªÊéâ‰∏Ä‰∫õuncorrelated features(‰∏çÁõ∏ÂÖ≥ÁöÑÁâπÂæÅ)ÔºåÂèØ‰ª•Âú®ËÆ≠ÁªÉÊï∞ÊçÆ‰πãÂâçpreprocessÔºåÂèòÊàê0-centeredÂàÜÂ∏ÉÔºåËøôÊ†∑Á¨¨‰∏ÄÂ±ÇÊòØÊ≤°ÊúâÈóÆÈ¢òÁöÑÔºå‰ΩÜÊòØÂêéÈù¢ÁöÑÂ±ÇÈáåËøòÊòØ‰ºöÂá∫ÈóÆÈ¢ò ÊâÄ‰ª•ÊäänormalizationÁöÑÈÉ®ÂàÜÂä†ÂÖ•‰∫ÜDNÈáåÈù¢ÔºåÂä†ÂÖ•‰∫Ü‰∏Ä‰∏™BNÂ±ÇÔºå‰ºö‰º∞ËÆ°meanÂíåstandard deviation of each featureÔºåËøôÊ†∑ÈáçÊñ∞centreÂíånormalized learnable shift and scale parameters for each feature dimension Ê†∏ÂøÉÊÄùÊÉ≥ÔºöÁ≤óÊö¥ÁöÑÁî®BNÊù•Ëß£ÂÜ≥weightsÂàùÂßãÂåñÁöÑÈóÆÈ¢ò refÔºöhttps://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html Batch normalization: forwardËøô‰∏™‰∏úË•øÁöÑË¶Å‰πâÂ∞±ÊòØNNÈáåÈù¢ÁöÑ‰∏ÄÂ±ÇÔºå‰∏çÂØπÁª¥Â∫¶ÊîπÂèòÔºå‰ΩÜÊòØ‰ºöÊîπÂèòËøô‰∫õÂÄºÁöÑÂàÜÂ∏É È¶ñÂÖàsetupÔºåÂπ∂‰∏îËΩΩÂÖ•Â•Ω‰∫ÜpreprocessÁöÑÊï∞ÊçÆcs231n/layers.py -&gt; batchnorm_forward keep exp decay Êù•ËøêË°åmean &amp; variance of each feature -&gt; Âú®testÁöÑÊó∂ÂÄôÂéªnormalize data test-time: ËÆ°ÁÆósample meanÂíåvarienceÁöÑÊó∂ÂÄôÁî®Â§ßÈáèÁöÑËÆ≠ÁªÉÊï∞ÊçÆËÄå‰∏çÊòØÁî®ÊâÄÊúâÂõæÁâáÁöÑÂπ≥ÂùáÂÄºÔºå‰ΩÜÊòØÂú®‰Ωú‰∏öÈáåÈù¢Áî®ÁöÑÊòØÂπ≥ÂùáÂÄºÔºåÂõ†‰∏∫ÂèØ‰ª•ÁúÅÂéª‰∏ÄÊ≠•estimateÔºàtorch7 ‰πüÁî®ÁöÑÊòØÂπ≥ÂùáÂÄºÔºâ 12running_mean = momentum * running_mean + (1 - momentum) * sample_meanrunning_var = momentum * running_var + (1 - momentum) * sample_var I/O input xÔºådata(N,D) gammaÔºöscale parameter(D,) betaÔºöshift parameter(D,) bn_param: ‰∏Ä‰∏™dict modeÔºö‚Äòtrain‚Äô or ‚Äòtest‚Äô epsÔºö‰∏∫‰∫ÜÊï∞Â≠ó‰∏äÁöÑÁ®≥ÂÆöÊÄßÁöÑ‰∏Ä‰∏™Â∏∏Êï∞ momentumÔºöÂú®ËÆ°ÁÆómeanÂíåvariance‰∏äÈù¢ÁöÑ‰∏Ä‰∏™Â∏∏Êï∞ running meanÔºö(D,)ÔºåÊòØrunning mean running varÔºö(D,) output outÔºö(N,D) cache:Âú®backÁöÑÊó∂ÂÄôÁî® todo Áî®minibatchÁöÑÁªüËÆ°Êù•ËÆ°ÁÆómeanÂíåvarianceÔºåÁî®Ëøô‰∏§‰∏™ÂÄºÊäädata normalizeÔºåÂπ∂‰∏îÁî®gammaÂíåbetaÊãâ‰º∏Ëøô‰∏™ÂÄºÔºå‰ª•ÂèäshiftËøô‰∫õÂÄºÁöÑ‰ΩçÁΩÆ Âú®ÂàÜÂ∏ÉÁöÑ‰∏äÈù¢ÔºåËôΩÁÑ∂Ê±ÇÂæóÊòØrunning varianceÔºå‰ΩÜÊòØÈúÄË¶ÅnormalizeÁöÑÊó∂ÂÄôËÄÉËôëÁöÑÊòØstandardÔºà‰πüÂ∞±ÊòØÂπ≥ÊñπÊ†πÔºâ implement ÂÖ∂ÂÆûÊòØÂíåÂ¶Ç‰ΩïËÆ°ÁÆóÊÅØÊÅØÁõ∏ÂÖ≥ÁöÑÔºåÁü•ÈÅìËæìÂÖ•ÔºåÊ±ÇËøô‰∏™Áé©ÊÑèÁöÑnormalÁöÑÊ≠•È™§Â¶Ç‰∏ãÔºàÂÖ∂‰∏≠ÁöÑxÂ∞±ÊòØËøô‰∏™minibatchÁöÑÂÖ®ÈÉ®Êï∞ÊçÆÔºâ Ê±ÇmuÔºå‰πüÂ∞±ÊòØxÁöÑmeanÔºàÊ≥®ÊÑèËøôÈáåË¶ÅÂØπÂàóÊ±ÇmeanÔºå‰πüÂ∞±ÊòØÊääÊâÄÊúâÂõæÁâáÁöÑÂÉèÁ¥†ÂùáÂåÄÂàÜÂ∏ÉÔºåÊúÄÂêéÂæóÂà∞ÁöÑÁªìÊûúÊòØD‰∏™‰∏çÊòØN‰∏™Ôºâ Ê±ÇvarÔºåÁü•ÈÅìËøô‰∏™‰∏úË•øÔºåÂèØ‰ª•Áõ¥Êé•Áî® np.var(x, axis = 0)Êù•Ê±ÇÊñπÂ∑Æ Ê±ÇnormalizeÔºö x - x.mean / np.sqrt(x.var + eps) ÂÖ∂‰∏≠ÂàöÂºÄÂßãÊ±ÇÂá∫Êù•ÁöÑvarÂ∞±ÊòØÊñπÂ∑ÆÔºå‰πüÂ∞±ÊòØÊ†áÂáÜÂ∑ÆÁöÑÂπ≥Êñπ epsÊòØÂÅèÂ∑ÆÂÄºÔºåËøô‰∏™ÂÄºÂä†‰∏äÊñπÂ∑ÆÂºÄÊñπÊòØÊ†áÂáÜÂ∑Æ scaleÂíåshiftÔºå‰πòscaleÁöÑÁ≥ªÊï∞ÔºåÂä†shiftÁöÑÁ≥ªÊï∞ ÊúÄÂêéÈúÄË¶ÅËÆ°ÁÆó‰ªÄ‰πàcacheÂíåbackÁöÑÊé®ÂØºÊÅØÊÅØÁõ∏ÂÖ≥ Batch normalization: backward ÂèØ‰ª•Áõ¥Êé•ÁîªÂá∫Êù•ËÆ°ÁÆónormalÁöÑË∑ØÂæÑÔºåÁÑ∂ÂêéÊ†πÊçÆËøô‰∏™Ë∑ØÂæÑback Ë¶Å‰πâÂ∞±ÊòØ‰∏ÄÊ≠•‰∏ÄÊ≠•ÁöÑÊ±ÇÂØºÔºÅ‰∏ÄÊ≠•‰∏ÄÊ≠•ÁöÑÈìæÂºèÊ≥ïÂàô Ê≥®ÊÑèÁöÑÂ∞±ÊòØÊ±ÇmeanÂõûÊù•ÁöÑÂØºÊï∞ÔºåÁêÜËß£‰∏äÊù•ËØ¥Â∞±ÊòØËøô‰∏™Áü©ÈòµÂú®Ê±ÇÂØºÁöÑËøáÁ®ã‰∏≠ÂçáÁª¥‰∫ÜÔºå‰ªé(D,)ÂèòÊàê‰∫Ü(N,D)ÔºåËÄåÂú®ÊúÄÂºÄÂßãÊ±ÇÂæóÊó∂ÂÄôÊâÄÊúâÁöÑÊï∞Â≠óÁöÑË¥°ÁåÆÈÉΩÊòØ1ÔºåÊâÄ‰ª•ÂæÄÂõûËµ∞ÁöÑÊó∂ÂÄô‰πò‰∏Ä‰∏™ÔºàNÔºåDÔºâÁöÑÂÖ®ÊòØ1ÁöÑÁü©ÈòµÔºåÂπ∂‰∏î1/NÁöÑÂ∏∏Êï∞ËøòÂú® Batch normalization: alternative backward Âú®sigmoidÁöÑbackÁöÑËøáÁ®ã‰∏≠Êúâ‰∏§Áßç‰∏çÂêåÁöÑÊñπÊ≥ï ‰∏ÄÁßçÊòØÂÜôÂá∫Êù•Êï¥‰ΩìËÆ°ÁÆóÁöÑÂõæÔºàÊãÜÂàÜÊàêÂêÑÁßçÂ∞èÁöÑËÆ°ÁÆóÔºâÔºåÁÑ∂ÂêéÊ†πÊçÆËøôÂº†ÂõæÁöÑÂÜçbackÂõûÂéª Âè¶‰∏ÄÁßçÊòØÂú®Á∫∏‰∏äÂÖàÁÆÄÂåñ‰∫ÜÊï¥‰ΩìÁöÑËÆ°ÁÆóËøáÁ®ãÔºåÁÑ∂ÂêéÂÜçÁõ¥Êé•ÂÆûÁé∞ÔºåËøôÊ†∑‰ª£Á†Å‰ºöÊØîËæÉÁÆÄÂçï ref:https://kevinzakka.github.io/2016/09/14/batch_normalization/ ÊúÄÁªàÁõÆÊ†á f: BN‰πãÂêéÁöÑÊï¥‰ΩìËæìÂá∫ÁªìÊûú yÔºöÂØπnormal‰πãÂêéÁöÑÁ∫øÊÄßÂèòÊç¢Ôºàgamma + betaÔºâ x‚ÄôÔºönormalÁöÑinput muÔºöbatch mean varbatch vatiance ÈúÄË¶ÅÊ±Ç df/dx,df/dgamma,df/dbeta -&gt; ÊúÄÁªàÁªìÊûúÊï¥‰ΩìÈÄüÂ∫¶ÊØî‰ª•ÂâçÂø´‰∫Üx2.5Â∑¶Âè≥ÔºåËøô‰∏ÄÊ≠•ÁöÑ‰∏ªË¶ÅÁõÆÁöÑÂ∞±ÊòØÁî®Êù•ÊèêÈÄüÁöÑ ÂèØ‰ª•ÊääÊï¥‰ΩìÁöÑËÆ°ÁÆóÂàÜ‰∏∫‰ª•‰∏ãÁöÑ‰∏â‰∏™Ê≠•È™§ Ëøô‰∏âÈÉ®ÂàÜÁöÑ‰ª£Á†ÅÂ¶Ç‰∏ã123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208def batchnorm_forward(x, gamma, beta, bn_param): """ Forward pass for batch normalization. During training the sample mean and (uncorrected) sample variance are computed from minibatch statistics and used to normalize the incoming data. During training we also keep an exponentially decaying running mean of the mean and variance of each feature, and these averages are used to normalize data at test-time. At each timestep we update the running averages for mean and variance using an exponential decay based on the momentum parameter: running_mean = momentum * running_mean + (1 - momentum) * sample_mean running_var = momentum * running_var + (1 - momentum) * sample_var Note that the batch normalization paper suggests a different test-time behavior: they compute sample mean and variance for each feature using a large number of training images rather than using a running average. For this implementation we have chosen to use running averages instead since they do not require an additional estimation step; the torch7 implementation of batch normalization also uses running averages. Input: - x: Data of shape (N, D) - gamma: Scale parameter of shape (D,) - beta: Shift paremeter of shape (D,) - bn_param: Dictionary with the following keys: - mode: 'train' or 'test'; required - eps: Constant for numeric stability - momentum: Constant for running mean / variance. - running_mean: Array of shape (D,) giving running mean of features - running_var Array of shape (D,) giving running variance of features Returns a tuple of: - out: of shape (N, D) - cache: A tuple of values needed in the backward pass """ mode = bn_param['mode'] eps = bn_param.get('eps', 1e-5) momentum = bn_param.get('momentum', 0.9) N, D = x.shape running_mean = bn_param.get('running_mean', np.zeros(D, dtype=x.dtype)) running_var = bn_param.get('running_var', np.zeros(D, dtype=x.dtype)) out, cache = None, None if mode == 'train': ####################################################################### # TODO: Implement the training-time forward pass for batch norm. # # Use minibatch statistics to compute the mean and variance, use # # these statistics to normalize the incoming data, and scale and # # shift the normalized data using gamma and beta. # # # # You should store the output in the variable out. Any intermediates # # that you need for the backward pass should be stored in the cache # # variable. # # # # You should also use your computed sample mean and variance together # # with the momentum variable to update the running mean and running # # variance, storing your result in the running_mean and running_var # # variables. # # # # Note that though you should be keeping track of the running # # variance, you should normalize the data based on the standard # # deviation (square root of variance) instead! # # Referencing the original paper (https://arxiv.org/abs/1502.03167) # # might prove to be helpful. # ####################################################################### mean = np.mean(x, axis=0) xmu = x - mean sq = np.square(xmu) var = np.var(x, axis=0) sqrtvar = np.sqrt(var + eps) ivar = 1. / sqrtvar normalize_raw = xmu * ivar normalize_result = gamma * normalize_raw + beta out = normalize_result running_mean = momentum * running_mean + \ (1 - momentum) * mean running_var = momentum * running_var + (1 - momentum) * var cache = (normalize_raw, gamma, xmu, ivar, sqrtvar, var, eps) ####################################################################### # END OF YOUR CODE # ####################################################################### elif mode == 'test': ####################################################################### # TODO: Implement the test-time forward pass for batch normalization. # # Use the running mean and variance to normalize the incoming data, # # then scale and shift the normalized data using gamma and beta. # # Store the result in the out variable. # ####################################################################### x_normalize = (x - running_mean) / (np.sqrt(running_var + eps)) out = x_normalize * gamma + beta ####################################################################### # END OF YOUR CODE # ####################################################################### else: raise ValueError('Invalid forward batchnorm mode "%s"' % mode) # Store the updated running means back into bn_param bn_param['running_mean'] = running_mean bn_param['running_var'] = running_var return out, cachedef batchnorm_backward(dout, cache): """ Backward pass for batch normalization. For this implementation, you should write out a computation graph for batch normalization on paper and propagate gradients backward through intermediate nodes. Inputs: - dout: Upstream derivatives, of shape (N, D) - cache: Variable of intermediates from batchnorm_forward. Returns a tuple of: - dx: Gradient with respect to inputs x, of shape (N, D) - dgamma: Gradient with respect to scale parameter gamma, of shape (D,) - dbeta: Gradient with respect to shift parameter beta, of shape (D,) """ dx, dgamma, dbeta = None, None, None ########################################################################### # TODO: Implement the backward pass for batch normalization. Store the # # results in the dx, dgamma, and dbeta variables. # # Referencing the original paper (https://arxiv.org/abs/1502.03167) # # might prove to be helpful. # ########################################################################### normalize_raw, gamma, xmu, ivar, sqrtvar, var, eps = cache N, D = dout.shape dbeta = np.sum(dout, axis=0) dgammax = dout dgamma = np.sum(dgammax * normalize_raw, axis=0) dnormalize_raw = dgammax * gamma divar = np.sum(dnormalize_raw * xmu, axis=0) dxmu = dnormalize_raw * ivar dsqrtvar = -1. / (sqrtvar ** 2) * divar dvar = 0.5 * 1. / np.sqrt(var + eps) * dsqrtvar dsq = 1. / N * np.ones((N, D)) * dvar dxmu2 = 2 * xmu * dsq dx1 = (dxmu + dxmu2) dmu = -1 * np.sum(dxmu + dxmu2, axis=0) dx2 = 1. / N * np.ones((N, D)) * dmu dx = dx1 + dx2 ########################################################################### # END OF YOUR CODE # ########################################################################### return dx, dgamma, dbetadef batchnorm_backward_alt(dout, cache): """ Alternative backward pass for batch normalization. For this implementation you should work out the derivatives for the batch normalizaton backward pass on paper and simplify as much as possible. You should be able to derive a simple expression for the backward pass. See the jupyter notebook for more hints. Note: This implementation should expect to receive the same cache variable as batchnorm_backward, but might not use all of the values in the cache. Inputs / outputs: Same as batchnorm_backward """ dx, dgamma, dbeta = None, None, None ########################################################################### # TODO: Implement the backward pass for batch normalization. Store the # # results in the dx, dgamma, and dbeta variables. # # # # After computing the gradient with respect to the centered inputs, you # # should be able to compute gradients with respect to the inputs in a # # single statement; our implementation fits on a single 80-character line.# ########################################################################### normalize_raw, gamma, xmu, ivar, sqrtvar, var, eps = cache N, D = dout.shape dbeta = np.sum(dout, axis=0) dgamma = np.sum(dout * normalize_raw, axis=0) # intermediate partial derivatives dxhat = dout * gamma # final partial derivatives dx = (1. / N) * ivar * (N * dxhat - np.sum(dxhat, axis=0) - normalize_raw * np.sum(dxhat * normalize_raw, axis=0)) ########################################################################### # END OF YOUR CODE # ########################################################################### return dx, dgamma, dbeta Fully Connected Nets with Batch Normalizationin cs231n/classifiers/fc_net.py, add the BN layers into the net. Â∫îËØ•Âú®ÊØè‰∏™relu‰πãÂâçÂä†‰∏äBNÔºåÊâÄ‰ª•Âú®ËøôÈáå‰∏çËÉΩÁõ¥Êé•Áî®‰πãÂâçÁöÑaffineÔºåreluÁöÑËøáÁ®ãÔºåÂõ†‰∏∫‰∏≠Èó¥ÂèàÊèí‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑBNÂ±ÇÔºåÊâÄ‰ª•Ë¶ÅÂÜô‰∏Ä‰∏™Êñ∞ÁöÑfunction ÊúÄÂêé‰∏ÄÂ±Ç‰πãÂêéÁöÑËæìÂá∫‰∏çÂ∫îËØ•BN(Â∫îËØ•ÊòØÊ∂âÂèäÂà∞Âæ™ÁéØÁöÑÈóÆÈ¢ò) ÂÆûÁé∞‰∏≠ÈÅáÂà∞ÁöÑÈóÆÈ¢ò self.bn_paramsÁöÑÂèÇÊï∞Á±ªÂûã‰∏çÊòØdictËÄåÊòØlistÔºå‰ª£Ë°®ÁöÑÊòØÊâÄÊúâÂ±ÇÈáåÈù¢ÁöÑÂèÇÊï∞ÁöÑÊâÄÊúâÂíåÔºåÂΩìËøõÂÖ•Âà∞ÊØèÂ±ÇÁöÑÊó∂ÂÄôÂÖ∑‰ΩìÂØπÂ∫îÁöÑÊâçÊòØËøôÈáåÁöÑdict ÂΩìÊääaffine_BN_reluÁªìÂêàÂú®‰∏ÄËµ∑ÁöÑÊó∂ÂÄôÔºåÊ≥®ÊÑèÊúÄÂêé‰∏ÄÂ±ÇËæìÂá∫ÁöÑÂú∞ÊñπÊ≤°ÊúâBNÔºåÊâÄ‰ª•Ê≤°Êúâ‰ªñÁöÑcacheÔºåÈúÄË¶ÅÂàÜÂºÄËÆ®ËÆ∫Ôºå‰∏çÁÑ∂cacheÁöÑÊï∞Èáè‰∏çÂØπ Ê≥®ÊÑèËøô‰∏™fc_netÁöÑclassÂõ†‰∏∫ÈúÄË¶ÅÂÆûÁé∞Â§öÁßç‰∏çÂêåÁöÑÂäüËÉΩÔºåÊâÄ‰ª•ÂØπ‰∫éÊòØ‰∏çÊòØBNË¶ÅÂä†‰∏äÊù°‰ª∂Âà§Êñ≠ Á°ÆÂÆûÈùûÂ∏∏ÂÉèÊê≠‰πêÈ´ò‰∫ÜÔºÅÔºÅ ËøôÈáå‰∏ªË¶ÅÔºåÂÜôÂà∞ËøôÊâçÂèëÁé∞ÊúÄÂêé‰∏ÄÂ±ÇÁöÑÊó∂ÂÄôÂ•ΩÂÉèÊòØ‰∏çÈúÄË¶Årelu‰πü‰∏çÈúÄË¶Åbatchnorm ÂÆö‰πâÂ•ΩÁöÑÂáΩÊï∞Âùó123456789101112131415def affine_BN_relu_forward(self, x, w, b, gamma, beta, bn_params): a, fc_cache = affine_forward(x, w, b) mid, BN_cache = batchnorm_forward(a, gamma, beta, bn_params) out, relu_cache = relu_forward(mid) cache = (fc_cache, BN_cache, relu_cache) return out, cache def affine_BN_relu_backward(self, dout, cache): fc_cache, BN_cache, relu_cache = cache da = relu_backward(dout, relu_cache) dmin, dgamma, dbeta = batchnorm_backward_alt(da, BN_cache) dx, dw, db = affine_backward(dmin, fc_cache) return dx, dw, db, dgamma, dbeta ÁªìËÆ∫ ÂèØËßÜÂåñ‰πãÂêéÂèØ‰ª•ÂèëÁé∞Âä†‰∫ÜnormÁöÑËØùÂ•ΩÂÉè‰ºö‰∏ãÈôçÁöÑÂø´‰∏ÄÁÇπ Batch normalization and initialization ËøõË°åËØïÈ™åÔºå‰∫ÜËß£BNÂíåweight initializationÁöÑÂÖ≥Á≥ª ËÆ≠ÁªÉ‰∏Ä‰∏™ÂÖ´Â±ÇÁöÑÁΩëÁªúÔºåÂåÖÊã¨Âíå‰∏çÂåÖÊã¨BNÔºåÁî®‰∏çÂêåÁöÑweight initialization plotÂá∫Êù•train acc, val_acc,train_lossÂíåweight initializationÁöÑÂÖ≥Á≥ª BNÁöÑ‰ΩúÁî®‰ªéÂõæ‰∏≠ÂèØ‰ª•ÁúãÂá∫Êù•ÔºåÊúâ‰∫ÜBN‰ª•ÂêéÔºåweight initÂØπÊúÄÁªàÁªìÊûúÁöÑÂΩ±ÂìçÊòéÊòæ‰ºöÈôç‰ΩéÔºö weightÁöÑÂàùÂßãÂåñÂØπÊúÄÁªàÁªìÊûúÂΩ±ÂìçÂæà‰∏•ÈáçÔºåÊØîÂ¶ÇÂ¶ÇÊûúÂÖ®ÊòØ0ÁöÑËØùÔºåÂæóÂà∞ÁöÑÊâÄÊúâneuronÁöÑÂäüËÉΩÈÉΩÊòØ‰∏ÄÊ†∑ÁöÑ BNÂÖ∂ÂÆûÂ∞±ÊòØÂú®ÂÆûÈôÖ‰∏≠Ëß£ÂÜ≥weight initÁöÑÂäûÊ≥ïÔºåËøôÊ†∑ÂèØ‰ª•ÂáèÂ∞ëÂàùÂßãÂåñÂèÇÊï∞ÁöÑÂΩ±Âìç Ê†∏ÂøÉÊÄùÊÉ≥Â∞±ÊòØÂ¶ÇÊûú‰Ω†ÈúÄË¶ÅÊõ¥Â•ΩÁöÑÂàÜÂ∏ÉÔºå‰Ω†Â∞±Âä†‰∏ÄÂ±ÇËÆ©‰ªñÂèòÊàêÊõ¥Â•ΩÁöÑÂàÜÂ∏É Âú®ËÆ°ÁÆóÁöÑËøáÁ®ã‰∏≠Ë∂ä‰πòË∂äÂ∞èÔºàÊàñËÄÖË∂äÂ§ßÔºâÔºåÊâÄ‰ª•ËÆ°ÁÆóÂá∫Êù•ÁöÑÁªìÊûúË∂äÊù•Ë∂äÊé•Ëøë0 ÊâÄ‰ª•ËøôÊó∂ÂÄôÂ¶ÇÊûúÊää‰∏Ä‰∫õinputÈáçÊñ∞ÂàÜÂ∏É‰∫ÜÔºåÂ∞±‰ºöÂáèÂ∞ëËøô‰∏™Êé•Ëøë0ÁöÑÂèØËÉΩÊÄß Batch normalization and batch size ËØïÈ™åÈ™åËØÅBNÂíåbatch sizeÁöÑÂÖ≥Á≥ª ËÆ≠ÁªÉ6-layerÁöÑÁΩëÁªúÔºåÂàÜÂà´withÂíåwithout BNÔºå‰ΩøÁî®‰∏çÂêåÁöÑbatch size By increasing batch size your steps can be more accurate because your sampling will be closer to the real population. If you increase the size of batch, your batch normalisation can have better results. The reason is exactly like the input layer. The samples will be closer to the population for inner activations. Layer NormalizationÔºàLNÔºâ ÂâçÈù¢ÁöÑÊâÄÊúâÁöÑBNÂ∑≤ÁªèÂèØ‰ª•ËÆ©NetÊõ¥Â•ΩÁöÑË¢´ËÆ≠ÁªÉ‰∫ÜÔºå‰ΩÜÊòØBNÁöÑÂ§ßÂ∞èÂíåbatchÁöÑÂ§ßÂ∞èÊúâÂÖ≥ÔºåÊâÄ‰ª•Âú®ÂÆûÈôÖÂ∫îÁî®ÁöÑÊó∂ÂÄô‰ºöÂèóÂà∞‰∏Ä‰∫õÈôêÂà∂ Âú®Â§çÊùÇÁöÑÁΩëÁªúÈáåÈù¢ÁöÑÊó∂ÂÄôÔºåbatch_sizeÊòØË¢´Á°¨‰ª∂Êú∫ËÉΩÈôêÂà∂ÁöÑ ÊØè‰∏™minibatchÁöÑÊï∞ÊçÆÂàÜÂ∏ÉÂèØËÉΩ‰ºöÊØîËæÉÊé•ËøëÔºåÊâÄ‰ª•ËÆ≠ÁªÉ‰πãÂâçË¶ÅshuffleÔºåÂê¶ÂàôÁªìÊûú‰ºöÂ∑ÆÂæàÂ§ö ÂÖ∂‰∏≠‰∏ÄÁßçËß£ÂÜ≥ÁöÑÊñπÊ≥ïÂ∞±ÊòØlayer normalization ‰∏çÊòØÂú®batch‰∏äÈù¢normal Âú®layer‰∏äÈù¢normal each feature vector corresponding to a single datapoint is normalized based on the sum of all terms within that feature vector. Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. ‚ÄúLayer Normalization.‚Äù stat 1050 (2016): 21. LN ÁªºÂêà‰∏ÄÂ±ÇÁöÑÊâÄÊúâÁª¥Â∫¶ÁöÑËæìÂÖ•ÔºåËÆ°ÁÆóËØ•Â±ÇÁöÑÂπ≥ÂùáËæìÂÖ•ÂíåÂπ≥ÂùáÊñπÂ∑Æ ÁÑ∂ÂêéÁî®Âêå‰∏Ä‰∏™ËßÑËåÉÂåñÊìç‰ΩúËΩ¨Êç¢ÂêÑ‰∏™Áª¥Â∫¶ÁöÑËæìÂÖ• Áõ∏ÂΩì‰∫é‰ª•ÂâçÊàë‰ª¨Â∏åÊúõÂèØ‰ª•Ê≠£ÂàôÂà∞Ëøô‰∏™minibatchÈáåÈù¢ÁöÑÂ§ßÂÆ∂ÈÉΩÂ∑Æ‰∏çÂ§öÔºåÁé∞Âú®Êàë‰ª¨‰∏çÁÆ°batch‰∫ÜÔºåËÄåÊòØË∞ÉÊï¥Âà∞‰∏ÄÂº†ÂõæÁâáÈáåÈù¢ÁöÑÊâÄÊúâÊï∞ÊçÆÈÉΩÊòØnormalÁöÑ implementcs231n/layers.py -&gt; layernorm_backward forward + back input x, (N,D) gamma, scale beta,shift ln_params: eps output output,(N,D) cache ÂÆûÁé∞ÊñπÊ≥ï -&gt; ÂÆûÈôÖ‰∏äÂ∞±ÊòØ‰ªéÂØπ‰∏ÄÂàóÁöÑÊìç‰ΩúÂèòÊàê‰∫ÜÂØπ‰∏ÄË°åÁöÑÊìç‰Ωú ÊØîÂ¶Ç‰πãÂâçÂØπxÂèñmeanÂ∞±ÊòØÊ±ÇÊØèÂàóÁöÑmeanÔºåÁé∞Âú®ÂèòÊàê‰∫ÜÂèñÊØèË°åÁöÑmean Âú®ÊâÄÊúânormal‰πãÂêéÂπ∂‰∏îscale‰πãÂâçÔºåÊääËøô‰∏™Áü©ÈòµÂú®tranposeÂõûÊù• back ÊääÈúÄË¶ÅÂèÇ‰∏éËÆ°ÁÆóÁöÑ‰∏úË•øÈÉΩtranpose ÁÑ∂ÂêéÊääËÆ°ÁÆóÂÆåÁöÑdx tranposeÂõûÊù• fc_netsÂú®fc_netsÈáåÈù¢Á®çÂä†ÊîπÂä®ÔºåÂú®normalizationÈáåÈù¢Â¢ûÂä†BN_NORMÂíåLayer_NORMÁöÑÈÄâÈ°πÂ∞±ÂèØ‰ª•‰∫ÜÔºåÊï¥‰ΩìÊîπÂä®‰∏çÂ§ß123456789101112131415161718192021def affine_Normal_relu_forward(self, x, w, b, gamma, beta, bn_params, mode): a, fc_cache = affine_forward(x, w, b) if mode == "batchnorm": mid, Normal_cache = batchnorm_forward(a, gamma, beta, bn_params) elif mode == "layernorm": mid, Normal_cache = layernorm_forward(a, gamma, beta, bn_params) out, relu_cache = relu_forward(mid) cache = (fc_cache, Normal_cache, relu_cache) return out, cache def affine_Normal_relu_backward(self, dout, cache, mode): fc_cache, Normal_cache, relu_cache = cache da = relu_backward(dout, relu_cache) if mode == "batchnorm": dmid, dgamma, dbeta = batchnorm_backward_alt(da, Normal_cache) elif mode == "layernorm": dmid, dgamma, dbeta = layernorm_backward(da, Normal_cache) dx, dw, db = affine_backward(dmid, fc_cache) return dx, dw, db, dgamma, dbeta ÂèØ‰ª•‰ªéÂõæÂÉèÁúãÂá∫Êù•Ôºålayernorm‰∏≠ÔºåbatchsizeÁöÑÂΩ±ÂìçÂèòÂ∞è‰∫Ü]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
        <category>CS231n‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>Batch Normalization</tag>
        <tag>Layer Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CppPrimerÁ¨îËÆ∞]]></title>
    <url>%2F2019%2F04%2F15%2FCppPrimer%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Á¨¨‰∏ÄÈÉ®ÂàÜ Basics C++Âú®ÁºñËØëÁöÑÊó∂ÂÄôÂ∞±‰ºöÊ£ÄÊü•Á±ªÂûã allow programmers to define types that include operations as well as data Á¨¨‰∫åÁ´† varibles and basic type2.1 bulid-inÂü∫Á°ÄÁ±ªÂûãÂåÖÊã¨ÁÆóÊï∞Á±ªÂûãÔºàarithmtic typeÔºâÂíåvoidÁ±ªÂûãÔºåvoidÁî®‰∫éÊ≤°ÊúâËøîÂõûÂÄºÁöÑÂáΩÊï∞ 2.1.1 ÁÆóÊï∞Á±ªÂûãincludeÔºöintergalÔºàbool&amp; charÔºâ/ float ‰∏çÂêåÁöÑÈïøÂ∫¶ÁöÑÂè´Ê≥ï‰∏çÂêåÔºö char -&gt; wchar_t, char16_t, char32_t(ÂêéÈù¢‰∏§‰∏™for unicodeÔºåËá™ÁÑ∂ËØ≠Ë®ÄÈáåÈù¢) int -&gt; short, long, long long float -&gt; double, long double Êâ©Â±ïÔºöÂú®ÂÇ®Â≠ò‰ø°ÊÅØÊñπÈù¢ÔºåÂÇ®Â≠òÂú®ÊØè‰∏™byteÈáåÈù¢ÔºåÊòØÊúÄÂ∞èÁöÑËÆ°ÈáèÂçï‰ΩçÔºà8bitsÔºâ„ÄÇÂú®ÂÜÖÂ≠ò‰∏≠ÔºåÊØè‰∏™byteÊã•Êúâ‰∏Ä‰∏™addressÔºåÈúÄË¶ÅÁü•ÈÅìÂú∞ÂùÄÂíåÁ±ªÂûãÊâçÁü•ÈÅìÂà∞Â∫ïÂ≠òÂÇ®ÁöÑÊòØ‰ªÄ‰πà‰∏úË•ø„ÄÇ signed &amp; unsignedÔºàÈô§‰∫ÜboolÔºâÔºö signedÔºöÂåÖÊã¨0ÁöÑÊ≠£Êï∞ÂíåË¥üÊï∞ unsignedÔºöÂ§ß‰∫éÁ≠â‰∫éÈõ∂ Ê≤°ÊúâÂÜôunsignedÁöÑËØùÂ∞±ÊòØsignedÁöÑ ÂØπ‰∫écharÊù•ËØ¥ÔºåsignedÔºåunsiginedÂíåchar‰∏âÁßç charÂà∞Â∫ïÁÆó‰∏çÁÆóunsignedÊòæÁ§∫ÂèñÂÜ≥‰∫éÁºñËØëÂô® unsigned‰ªé0-255 signed‰∏ÄËà¨ÊòØ-128 ÔΩû 127 ÂÖ≥‰∫éÂà∞Â∫ïÊÄé‰πàÁî®Ôºö ÂΩìÁ°ÆÂÆö‰∏çÂèØËÉΩÊòØË¥üÂÄºÁöÑÊó∂ÂÄôÁî®unisgned shortÂ§™Áü≠‰∫ÜÔºålongÂ§™Èïø‰∫ÜÔºåÂπ≥Â∏∏Áî®intÔºåint‰∏çÂ§üÁî®long long Â¶ÇÊûúÁî®charÔºå‰∏∫‰∫ÜËÄÉËôëÂà∞‰∏çÂêåÁºñËØëÁöÑÁªìÊûú‰∏çÂêåÔºåÁ°ÆÂÆöÂ•ΩÁî®signedËøòÊòØunsigned Áî®doubleÔºåfloatÁöÑÁ≤æÂ∫¶‰∏çÂ§üÔºålong doubleÂ∞èÂè∑ÂÜÖÂ≠ò 2.1.2 Á±ªÂûãËΩ¨Êç¢ÔºàconversionsÔºâÂú®Êää‰∏Ä‰∏™‰∏úË•øÂä†Âà∞Âè¶‰∏Ä‰∏™ÁöÑËøáÁ®ã‰∏≠ÔºåÊîØÊåÅËá™Âä®ÁöÑÁ±ªÂûãËΩ¨Êç¢ ÂΩìboolË¢´ËµãÂÄº‰∏∫Èùû0Êó∂Ôºå‰∏∫trueÔºå0Êó∂‰∏∫false ÁªôintËµãÂÄºdoubleÔºåËá™Âä®ÂèòÊàêÊï¥Êï∞ÔºõÁªôdoublËµãÂÄºintÔºåÂèòÊàêÊï¥Êï∞ÂêéÈù¢.0 ÂΩìunsignedË∂ÖÂá∫ÁïåÈôêÊó∂Ôºåthe result is the remainder of the value modulo the number of values the target type can hold. ÂΩìsignedË∂ÖÂá∫ÁïåÈôêÁöÑÊó∂ÂÄôÔºåÁªìÊûúÊòØundefined„ÄÇ‰∏çÁü•ÈÅì‰ºöÂèëÁîü‰ªÄ‰πà‰∫ã„ÄÇ Âú®ÂÜô‰ª£Á†ÅÁöÑÊó∂ÂÄôÂ∞ΩÈáèÈÅøÂÖçÊ≤°ÊúâÂÆö‰πâÁöÑÔºåÊàñËÄÖÂú®implement‰∏≠ÊâçÂÆö‰πâÁöÑË°å‰∏∫ÔºåÂõ†‰∏∫ËøôÊ†∑ÂÆπÊòìÂØºËá¥Âú®Ëøô‰∏™ÁîµËÑë‰∏äË°åÂæóÈÄö‰ΩÜÊòØÊç¢‰∏™Âú∞ÊñπÊ≤°ÂáÜÂ∞±Ë°å‰∏çÈÄö‰∫Ü ‰∏Ä‰∫õÂºïËµ∑ÁöÑÈóÆÈ¢òÔºö intÂíåunsignedÁõ∏Âä†Ôºå‰ºöÂºïËµ∑wrap around ‰∏§‰∏™unsignedÁõ∏ÂáèÂ¶ÇÊûúÂ∞è‰∫éÈõ∂‰ºöÂá∫ÈóÆÈ¢ò Âú®forÂæ™ÁéØÁöÑÊù°‰ª∂ÈáåÔºåunsiged‰Ωú‰∏∫ÂèòÈáèÁöÑËØùÊ∞∏Ëøú‰∏ç‰ºöÂ∞è‰∫éÈõ∂ Ê±ÇÊ±Ç‰Ω†‰∫ÜÂèçÊ≠£‰∏çË¶ÅÊ∑∑ÁùÄÁî® 2.1.3 literalsÊØè‰∏™literalÈÉΩÊúâ‰∏Ä‰∏™typeÔºåËøôÊòØÁî±formÂíåvalueÂÜ≥ÂÆöÁöÑ„ÄÇ Êï¥Êï∞Á±ªÂûãÁöÑ 0ÂºÄÂ§¥ÁöÑÊï¥Êï∞ÊòØÂÖ´ËøõÂà∂Ôºå0xÊòØ16ËøõÂà∂ Ë¥üÂè∑‰∏çÊòØliteralÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÊØîÂ¶Ç -42Ôºå42ÊòØliteralÔºåË¥üÂè∑ÊòØoperator floatÁ±ªÂûãÁöÑ ÂçÅËøõÂà∂Â∏¶Â∞èÊï∞ÁÇπÁöÑÊï∞Â≠ó Áî®exponentÔºåEÊàñËÄÖeÔºåeÂêéÈù¢ÁöÑ‰∏úË•øÂ∞±ÊòØÂçÅÁöÑÂ§öÂ∞ëÊ¨°Êñπ character stringÁöÑÁ±ªÂûãÊòØ‰∏Ä‰∏™charÁöÑarrayÔºåcomplier‰ºöÂú®ÊØè‰∏™string ÂêéÈù¢Âä†‰∏ä‚Äò\0‚ÄôÔºànull characterÔºâ escape -&gt; ‰∏Ä‰∫õÂ∏¶ÊúâÂ•áÊÄ™ÊÑè‰πâÁöÑ\nÔºå\t,\‚ÄôÁ≠âÁ≠â Â¶ÇÊûúÂú®\ÂêéÈù¢Ë∑üÁùÄÂ§ö‰∫é‰∏â‰∏™Êï∞Â≠óÔºåÂè™‰ºöËØªÂèñÂâç‰∏â‰∏™ \x‰ºöËØªÂèñË∑üÂú®Â•πÂêéÈù¢ÁöÑÊâÄÊúâhex digits ÂçïÁã¨ÊîπÂèò‰∏Ä‰∏™literalÔºåÂú®Êï∞Â≠óÂêéÈù¢Âä†ÂêéÁºÄsuffix UÔºöunsigned type LÔºölong ULLÔºöunsigned long long ‰ΩÜÊòØÂ¶ÇÊûú‰Ω†Ë¶ÅÁªô1024ÂêéÈù¢Âä†‰∏™fÂ∞±‰∏çË°åÔºåÂõ†‰∏∫1024ÊòØÊï¥ÂΩ¢ÔºàËøôÊó∂ÂÄôÂèàÂºÄÂßãÊÄÄÂøµpythonÔºâ bool 2.2 ÂèòÈáè VariablesÂèòÈáèÊèê‰æõÁöÑÊòØÔºöÂëΩÂêçÂ•ΩÁöÑÂ≠òÂÇ®Á©∫Èó¥ÔºåÁ®ãÂ∫èÂèØ‰ª•ÂØπ‰ªñÊâßË°åÔºåÊØè‰∏™ÂèòÈáèÈÉΩÊúâtypeÔºàÂÖ∂ÂÆû‰πüÂ∞±ÊòØclassÊàñËÄÖobjectÂêóÔºâ 2.2.1 ÂèòÈáèÁöÑÂÆö‰πâ assignment(ËµãÂÄº)Âíåinitialize(ÂàùÂßãÂåñ)Âú®c++ÈáåÈù¢ÊòØ‰∏ç‰∏ÄÊ†∑ÁöÑÔºåÂàùÂßãÂåñÊòØÂú®ÂàõÂª∫ÁöÑÊó∂ÂÄôËµã‰∫àÁöÑÂÄºÔºåËµãÂÄºÊòØ‰πãÂêéÊîπÂèòËøô‰∏™ÂèòÈáèÁöÑÂÄº listÁöÑÂàùÂßãÂåñÔºöÂ∞ñÊã¨Âè∑„ÄÇ Âú®‰ΩøÁî®bulit-inÁöÑÊó∂ÂÄôÔºåÂèØËÉΩÊó†Ê≥ïlistÂàùÂßãÂåñËøô‰∏™ÂèòÈáèÔºåÂõ†‰∏∫‰ºö‰∏¢Â§±‰∏Ä‰∫õ‰ø°ÊÅØ„ÄÇÊØîÂ¶ÇÊää‰∏Ä‰∏™doubleÊâîÂà∞intÈáåÈù¢ ÊòØÂê¶ÂèØ‰ª•‰∏çÂàùÂßãÂåñÂ∞±‰ΩøÁî®ÂèñÂÜ≥‰∫éclassÁöÑÂÆö‰πâ„ÄÇÊØîÂ¶ÇË¶ÅÊòØintÊ≤°ÊúâÂàùÂßãÂåñÁöÑÊó∂ÂÄôÊòØ0ÔºåstringÊ≤°ÊúâÂàùÂßãÂåñÁöÑÊó∂ÂÄôÊòØÁ©∫Â≠óÁ¨¶‰∏≤ 2.2.2 ÂèòÈáèdeclarationÔºàÂ£∞ÊòéÔºüÔºâÂíåÂÆö‰πâ Âú®ÂàÜÂºÄÁºñÂÜô‰ª£Á†ÅÁöÑÊó∂ÂÄôÔºåÈúÄË¶ÅÁü•ÈÅìË∞ÉÁî®ÁöÑÂáΩÊï∞‰ªéÂì™ÈáåÊù•„ÄÇÊ≥®ÊÑèÔºö‰∏çÂàùÂßãÂåñÂèòÈáèÂÆπÊòìÂá∫ÈóÆÈ¢òÔºåÂª∫ËÆÆÂàùÂßãÂåñÊØè‰∏™bulit-in declarationÔºöËÆ©Á®ãÂ∫èÁü•ÈÅìÂáΩÊï∞ÁöÑÂêçÂ≠ó Âú®ÂâçÈù¢Âä†‰∏äexternÔºåÂ∞±ÂèØ‰ª•declare‰ΩÜÊòØ‰∏çdefine ‰ΩÜÊòØÂ¶ÇÊûúÂ∑≤ÁªèÂàùÂßãÂåñ‰∫ÜÂáΩÊï∞ÔºåÂ∞±‰∏çËÉΩÂä†extern‰∫ÜÔºå‰ºöÂºïËµ∑ÈîôËØØ Âú®ÂÖ∂‰ªñÂáΩÊï∞ÁöÑÂú∞ÊñπË∞ÉÁî®ÁöÑÊó∂ÂÄôÔºàuse a varible in multiple filesÔºâÔºå‰∏çÈúÄË¶ÅÂÜçdefine‰∫ÜÔºå‰ΩÜÊòØÈúÄË¶ÅÂ£∞Êòé definationÔºöÂàõÂª∫Áõ∏Â∫îÁöÑÂÆû‰Ωì Èô§‰∫ÜÂπ≤declarationÁöÑ‰∫ãÊÉÖÔºå‰ªñËøòÂàÜÈÖçÂÜÖÂ≠òÔºåÊàñËÄÖÊèê‰æõÂàùÂßãÂÄº ÂèòÈáèË¢´define‰∏ÄÊ¨°Ôºå‰ΩÜÊòØÂèØ‰ª•Ë¢´declarationÊó†Êï∞Ê¨°„ÄÇ 2.2.3 identifiersÔºàÂÆö‰πâÁöÑÂêçÂ≠óÔºâ Ë¶ÅÊ±Ç Êï∞Â≠óÔºåÂ≠óÊØçÔºå‰∏ãÂàíÁ∫øunderscore ÂØπÂ§ßÂ∞èÂÜôÊúâÂå∫ÂàÜ ‰∏çËÉΩ‰ΩøÁî®C++ÁöÑÂÖ≥ÈîÆËØç ‰∏çËÉΩÂê´Êúâ‰∏§‰∏™Áõ∏ËøûÁöÑ‰∏ãÂàíÁ∫ø 2.2.4 ÂêçÂ≠óÁöÑscope ‰ΩøÁî®ÁöÑÊÑè‰πâÔºöÂêå‰∏Ä‰∏™ÂêçÂ≠óÂèØËÉΩ‰ºöÂú®Á®ãÂ∫èÁöÑÂÖ∂‰ªñÂú∞ÊñπË¢´‰ΩøÁî®ÔºåÊâÄ‰ª•Ë¶ÅÁî®scopeÁ°ÆÂÆöËøô‰∏™ÂêçÂ≠óÂú®Âì™‰∏™ËåÉÂõ¥ÈáåÈù¢ÊúâÊÑè‰πâÔºà‰∏çÊòØnamespaceÂïäÂïäÂïäÂïäÂïäÁ´üÁÑ∂ÊòØÂ§ßÊã¨Âè∑ÊàëÈúáÊÉäÔºâ nested scope Âú®Â§ñÂ±ÇË¢´ÂÆö‰πâÁöÑÂêçÂ≠óÂèØ‰ª•Âú®ÂÜÖÂ±ÇË¢´ÈáçÊñ∞ÂÆö‰πâ Ê∏©ÊÉÖÂª∫ËÆÆÔºöÂ±ÄÈÉ®ÂèòÈáèÂíåÂÖ®Â±ÄÂèòÈáè‰∏çË¶Å‰ΩøÁî®‰∏Ä‰∏™ÂêçÂ≠ó 2.3 compound typesÔºàÊúâËåÉÂõ¥ÁöÑÁ±ªÂûãÔºüÔºâÂ∞±ÊòØÂÆö‰πâÂú®ÂÖ∂‰ªñÁ±ªÂûã‰πã‰∏äÁöÑÁ±ªÂûã„ÄÇÂú®c++ÈáåÈù¢Êúâ‰∏§‰∏™ÔºåpointerÂíåreference 2.3.1 referenceÔºàlvalue referenceÔºâÂú®ÂàõÂª∫ÁöÑÊó∂ÂÄôÔºåcopyÁöÑ‰∏çÊòØÂØπË±°ÁöÑÂÄºÔºåËÄåÊòØÊääreferÂíåÂÄºÁªëÂú®‰∫Ü‰∏ÄËµ∑ÔºåÂú®ÂàõÂª∫‰πãÂêé‰∏çËÉΩÂÜçÂíåÂà´ÁöÑ‰∏úË•øÁªëÂú®‰∏ÄËµ∑„ÄÇreferenceÂøÖÈ°ªÂàùÂßãÂåñ„ÄÇ ‰∏çÊòØÂØπË±°ÔºåÊòØ‰∏Ä‰∏™Â∑≤ÁªèÂ≠òÂú®ÁöÑÂØπË±°ÁöÑÂè¶‰∏Ä‰∏™ÂêçÂ≠ó ÁªôreferËµãÂÄºÁöÑÊó∂ÂÄôÔºåÂÆûÈôÖ‰∏äÊòØËµãÂÄºÁªôreferÊâÄÁªëÂÆöÁöÑÂØπË±° ÂΩìÁªô‰∏Ä‰∏™referËµãÂÄºÂè¶‰∏Ä‰∏™referÁöÑÊó∂ÂÄôÔºåÂÖ∂ÂÆûÊòØÁªëÂà∞‰∫ÜÂêå‰∏Ä‰∏™ÂØπË±°Ôºà‰ΩÜÊòØ‰∏çÂ∫îËØ•Ëøô‰πàÂÆö‰πâÔºâ ÂÆö‰πâ Âú®referÁöÑÂêçÂ≠ó‰πãÂâçÂä†‰∏ä&amp;Ôºå‰ΩÜÊòØÂú®ÂêéÁª≠‰ΩøÁî®ÁöÑÊó∂ÂÄôÂèØ‰ª•‰∏çÂ∏¶‰∫Ü referÂè™ËÉΩÂàùÂßãÂåñÊàê‰∏Ä‰∏™ÂØπË±°Ôºå‰∏çËÉΩÊòØ‰∏Ä‰∏™ÂÖ∑‰ΩìÁöÑÂÄº Á±ªÂûãË¶ÅÊ≠£Á°Æ 2.3.2 pointerÂíårefer‰∏çÂêåÔºåÊåáÈíàÊòØ‰∏Ä‰∏™objectÔºå‰ªñ‰ª¨ÂèØ‰ª•Ë¢´assignÊàñËÄÖcopyÔºåÂú®ÂÆö‰πâÁöÑÊó∂ÂÄô‰∏çÂøÖÈ°ªÂàùÂßãÂåñÔºå‰∏Ä‰∏™ÊåáÈíàÂèØ‰ª•ÊåáÂêë‰∏çÂêåÁöÑ‰∏úË•ø„ÄÇÂú®ÂÆö‰πâÁöÑÊó∂ÂÄôÁî® * Êù•Ë°®Á§∫ ÂèñÂùÄ pointerÂèØ‰ª•ÂæóÂà∞Âè¶‰∏Ä‰∏™ÂØπË±°ÁöÑaddress„ÄÇ&amp;‰πüÂèØ‰ª•‰Ωú‰∏∫ÂèñÂùÄÁ¨¶Âè∑ÂæóÂà∞‰∏Ä‰∏™ÂØπË±°ÁöÑÂú∞ÂùÄÔºàÂíårefer‰∏ç‰∏ÄÊ†∑ÔºÅÔºÅÔºâ Á±ªÂûãÂøÖÈ°ªÂåπÈÖç pointerÁöÑÂÄºÔºàÂèØ‰ª•ÊòØ‰ª•‰∏ãÂõõ‰∏™‰πã‰∏ÄÔºâ ÊåáÂêë‰∏Ä‰∏™ÂØπË±° ÊåáÂêë‰∏Ä‰∏™Âú®ÂØπË±°‰∏≠Êú´Â∞æÁöÑ‰ΩçÁΩÆÔºàÊ≤°Êúâ‰ΩøÁî®ÁöÑÂÆûÈôÖÊÑè‰πâÔºâ nullÊåáÈíàÔºåË°®Á§∫ËøòÊ≤°ÊúâÂíåÂÖ∂‰ªñÁöÑÁªëÂÆö Êó†ÊïàÁöÑÔºüÔºüÂ¶ÇÊûúÊòØÊó†ÊïàÁöÑËØùÊòØ‰∏çËÉΩËÆøÈóÆÁöÑ ËÆøÈóÆÂØπË±° ÂΩì‰∏Ä‰∏™pointerÊåáÂêëÂØπË±°ÁöÑÊó∂ÂÄôÔºå‰ΩøÁî®dereferenceÔºà ÔºâÊù•ÂæóÂà∞Â•πÁöÑÂÄº„ÄÇÔºàpointer pÊòØ‰∏Ä‰∏™Âú∞ÂùÄÔºå pÊòØ‰ªñËøô‰∏™Âú∞ÂùÄ‰∏äÁöÑÂÄº Á©∫ÊåáÈíàNULL ‰ΩøÁî®nullptrÂÆö‰πâ assign‰∏Ä‰∏™intÂèòÈáèÁªôpointerÊòØÈùûÊ≥ïÁöÑÔºåÂç≥‰ΩøËøô‰∏™Êï∞ÊòØ0ÔºàËµãÂÄºÁöÑÊó∂ÂÄôÁªôÁöÑÊòØÂèòÈáèÁöÑÂú∞ÂùÄÔºåÂ∏¶&amp;ÁöÑÔºâ ÁúüËØöÂª∫ËÆÆÔºöÂàùÂßãÂåñÊâÄÊúâÁöÑpointerÔºåÊ≤°ÊúâÂàùÂßãÂåñÁöÑÂæàÈöæÂàÜËæ®Âá∫Êù•Âà∞Â∫ïËøô‰∏™Âú∞ÂùÄÊòØÊúâÊïàËøòÊòØÊó†Êïà assignment ÂÜôÊàê pi = &amp;valÁöÑÊó∂ÂÄôÔºåÊîπÂèòÁöÑÊòØpiÁöÑÂÄºÔºå‰ªñÊåáÂêë‰∫Üval ÂÜôÊàê * pi = 0 ÁöÑÊó∂ÂÄôÔºåÊîπÂèòÁöÑÊòØvalÁöÑÂÄºÔºåvalÂèòÊàê‰∫Ü0 void* Pointers void* ÊòØ‰∏Ä‰∏™ÂæàÁâõÈÄºÁöÑÊåáÈíàÔºåÂèØ‰ª•holdÊâÄÊúâÂØπË±°ÁöÑÂú∞ÂùÄ ‰ΩúÁî®ÔºöÂèØ‰ª•‰º†Âà∞ÂáΩÊï∞ÊàñËÄÖ‰Ωú‰∏∫ÂáΩÊï∞ÁöÑËøîÂõûÂÄºÔºåÂèØ‰ª•ÂíåÂÖ∂‰ªñÊåáÈíàÊØîËæÉÔºåÂèØ‰ª•ËµãÂÄºÁªôÂè¶‰∏Ä‰∏™void* ÊåáÈíàÔºå‰ΩÜÊòØ‰∏çËÉΩÊìçÊéßÂØπË±°ÁöÑÂú∞ÂùÄ 2.3.3 ÁêÜËß£ ÂÆö‰πâÂ§ö‰∏™ÂèòÈáè ËôΩÁÑ∂Âú®ÂÆö‰πâÊåáÈíàÁöÑÊó∂ÂÄôÂèØ‰ª•Âä†Á©∫Ê†ºÔºå‰ΩÜÊòØ int* p1Ôºåp2‰πã‰∏≠Ôºåp1ÊòØÊåáÈíàÔºåp2ÊòØint pointerÂà∞pointer ÂÜôÊàê‰∏Ä‰∏≤ÊòüÂè∑ÂèØ‰ª•Ë°®Á§∫‰ªépointerÂà∞pointer referÂà∞pointer &amp;rÂèØ‰ª•ÂÆö‰πâÊàê‰∏Ä‰∏™pointerÔºàÊåáÈíàÂÜôÂú®=Âè≥ËæπÔºâ 2.4 ‰øÆÈ•∞ËØç const ‰ΩúÁî®ÔºöÂ∏åÊúõÂÆö‰πâ‰∏Ä‰∏™variableÔºåvalue‰∏çÂèØ‰ª•Ë¢´ÊîπÂèòÔºåËøôÊó∂ÂÄôÂ∞±Áî®‰∏ä‰∫Üconst„ÄÇÂú®ÂàõÂª∫ÁöÑÊó∂ÂÄôÂøÖÈ°ªÂàùÂßãÂåñ Âú®ÂÆûÈôÖÊìç‰ΩúÁöÑÊó∂ÂÄôÔºåÂà∞Â∫ïÊòØ‰∏çÊòØconstÂØπÊï∞ÂÄºÊ≤°ÊúâÂΩ±ÂìçÔºåÂèØ‰ª•Áî®ÈùûconstÊù•ÂàùÂßãÂåñconstÊàñËÄÖÁî®constÊù•ÂàùÂßãÂåñÂÖ∂‰ªñÁöÑ Âú®ÂàõÂª∫‰πãÂêéÔºåÁºñËØëÁöÑÊó∂ÂÄôÊâÄÊúâÁöÑÂèòÈáèÂêçÈÉΩ‰ºöÊç¢ÊàêÂèòÈáèÁöÑÂÄº constÂØπÊØè‰∏™fileÊù•ËØ¥ÊòØlocalÁöÑ Â¶ÇÊûúÂ∏åÊúõÂÆö‰πâ‰∏Ä‰∏™Âú®ÊâÄÊúâfileÈáåÈù¢ÈÉΩÂèØ‰ª•Áî®ÁöÑÔºåÁÑ∂ÂêéÂú®ÂÖ∂‰ªñ‰ΩøÁî®ÁöÑÊó∂ÂÄôÂ£∞ÊòéÔºåËøôÊó∂ÂÄôÁî®extern constÔºàÂú®ÂÆö‰πâÂíåÂêéÁª≠Â£∞ÊòéÁöÑÊó∂ÂÄôÈÉΩÈúÄË¶Å‰ΩøÁî®Ôºâ 2.4.1 refer to const ÂèØ‰ª•referÂà∞‰∏Ä‰∏™constÔºå‰ΩÜÊòØ‰πãÂêéÂ∞±‰∏çËÉΩÈÄöËøáreferÊù•ÊîπÂèòÂèòÈáèÁöÑÂÄºÔºå‰πü‰∏çËÉΩÊää‰∏Ä‰∏™constÁöÑÂèòÈáèËµãÂÄºÁªô‰∏Ä‰∏™ÈùûconstÁöÑrefer const referÁöÑÊÑèÊÄùÊòØËøô‰∏™refer‰∏çËÉΩË¢´Áî®Êù•ÊîπÂèòÂèòÈáèÔºå‰ΩÜÊòØË¢´ÁªëÁöÑÂèòÈáèÊú¨Ë∫´ÂèØ‰ª•ÊîπÂèò„ÄÇÊØîÂ¶Çconst int &amp;r2 = iÔºåËøôÊó∂ÂÄôÊîπÂèòiÊòØÂêàÊ≥ïÁöÑ 2.4.2 pointer and const pointer to const‰∏çËÉΩË¢´Áî®‰∫éÊîπÂèòÊåáÂêëÁöÑ‰∏úË•ø ‰ΩÜÊòØpointerÊòØconstÁöÑÂíåÂèòÈáèËá™Â∑±Êîπ‰∏çÊîπÊ≤°ÂÖ≥Á≥ª„ÄÇÂèòÈáèÊòØconstÁöÑËØùÊåáÈíàÂøÖÈ°ªÊòØconstÁöÑ const pointer ÊåáÈíàÊú¨Ë∫´Â∞±ÊòØ‰∏Ä‰∏™ÂØπË±°ÔºåÊâÄ‰ª•ÊåáÈíàËá™Â∑±‰πüÂèØ‰ª•ÊòØconstÁöÑ ÂøÖÈ°ªË¢´ÂàùÂßãÂåñÔºå‰∏ÄÊó¶ÂàùÂßãÂåñ‰∫ÜÔºå‰ªñÁöÑÂÜÖÂÆπÔºàÊâÄÊåáÂêëÁöÑÂú∞ÂùÄÔºâÂ∞±‰∏çËÉΩÊîπÂèò‰∫Ü„ÄÇ ÂÆö‰πâÁöÑÊó∂ÂÄôÁî® int * const cpr = &amp;num ÔºàconstÁöÑ‰ΩçÁΩÆÊîπÂèò‰∫ÜÔºâ ‰ΩÜÊòØÂèØ‰ª•Áî®const pointerÊù•ÊîπÂèòÊâÄÊåáÂêë‰∏úË•øÁöÑÂÄºÔºÅÔºÅÔºÅÂè™ÊòØËøô‰∏§‰∏™‰∏úË•øÁªëÂÆö‰∫Ü‰∏çËÉΩÊîπ‰∫ÜËÄåÂ∑≤ 2.4.3 top-level ÂèØ‰ª•ÂàÜÂºÄËÄÉËôëpointerÂíåÂØπË±° top-levelÔºöpointerËá™Â∑±ÊòØ‰∏Ä‰∏™const -&gt; Êú¨Ë∫´Â∞±ÊòØconstÁöÑÔºåÂèØ‰ª•Âá∫Áé∞Âú®‰ªª‰ΩïÁöÑÂØπË±°ÈáåÈù¢ low-levelÔºöÊåáÂêë‰∏Ä‰∏™const -&gt; Âè™Âá∫Áé∞Âú®referÂíåpointerÈáåÈù¢ ÂΩìcopy‰∏Ä‰∏™ÂØπË±°ÁöÑÊó∂ÂÄôÔºåtop-levelÊòØË¢´ÂøΩÁï•ÁöÑÂ∏∏ÈáèÊåáÈíàÂ∞±ÊòØ‰∏Ä‰∏™Â∏∏ÈáèÔºå‰∏çËÉΩÊääÂ∏∏ÈáèÁªôÊôÆÈÄö‰ΩÜÊòØÂèØ‰ª•ÊääÊôÆÈÄöÁªôÂ∏∏Èáè 2.4.4 constexpr Â∏∏ÈáèË°®ËææÂºèÊòØÁºñËØëÁöÑÊó∂ÂÄô‰∏çËÉΩÊîπÂèòÁöÑÔºåconst objectÊàñËÄÖliteralÈÉΩÊòØÂ∏∏ÈáèË°®ËææÂºè„ÄÇÂè™ÊúâÂú®ÂàùÂßãÂåñÁöÑÊó∂ÂÄôÁü•ÈÅì‰∫ÜÁöÑÂÄºÊâçÊòØÂ∏∏ÈáèË°®ËææÂºè„ÄÇÂ¶ÇÊûúÊòØ‰∏™const int‰ΩÜÊòØ‰∏çÁ°ÆÂÆöÂà∞Â∫ïÊòØ‰ªÄ‰πàÔºåÈÇ£‰πàÂ∞±Ëøò‰∏çÁÆó Âú®ÂâçÈù¢Âä†‰∏ä constexprÔºåËøôÊó∂ÂÄôÂè™ÊúâÂΩìÂêéÈù¢ÁöÑÂèòÈáèÊòØÂ∏∏ÈáèÁöÑÊó∂ÂÄôÊâçËÉΩÁî® ÂèØ‰ª•Âú®compileÁöÑÊó∂ÂÄôÂà§ÂÆö ÂΩìËøô‰∏™Á±ªÂûã‰∏çÊòØliteralÁöÑÊó∂ÂÄôÔºå‰∏çËÉΩÂÆö‰πâÊàêÂ∏∏ÈáèË°®ËææÂºèÔºàliteralÂåÖÊã¨ÁÆóÊï∞ÔºåpointerÂíåreferÔºâ Âú®ÂáΩÊï∞ÂÜÖÂÆö‰πâÁöÑÂèòÈáè‰∏ÄËà¨‰∏ç‰ºöÂÇ®Â≠òÂú®Âõ∫ÂÆöÁöÑÂú∞ÂùÄÔºåÊâÄ‰ª•ËøôÊó∂ÂÄôÊåáÈíà‰∏çËÉΩÊòØconstexprÔºà6.1.1Ôºâ ÂΩì‰ΩøÁî®constexprÁöÑÊó∂ÂÄôÔºå‰ΩúÁî®Âú®ÁöÑÊòØÊåáÈíà‰∏äËÄå‰∏çÊòØÊåáÂêëÁöÑ‰∏úË•ø‰∏ä1const int *p = nullptr; // p is a pointer to a const int constexpr int *q = nullptr; // q is a const pointer to int 2.5 types Á±ªÂûã2.5.1 type aliases Âç≥‰∏∫ÂØπÂè¶‰∏Ä‰∏™typeÁöÑÂåñÂêç -&gt; ÁÆÄÂåñÊØîËæÉÂ§çÊùÇÁöÑtypeÔºåÊõ¥Â•Ω‰ΩøÁî® ÂÆö‰πâÊñπÊ≥ï1Ôºö 12typedef double wages; // wages is a synonym for doubletypedef wages base, *p; // base is a synonym for double, p for double* ÊñπÊ≥ï2: using SI = Sales_itemÔºõ Âíåpointer‰ª•Âèäconst -&gt; Áî®ÁöÑÊó∂ÂÄôÁõ¥Êé•Êõø‰ª£‰ºöÂá∫ÈóÆÈ¢ò123typedef char *pstring;const pstring cstr = 0; // cstr is a constant pointer to charconst pstring *ps; // ps is a pointer to a constant pointer to char 2.5.2 auto ‰ΩúÁî®ÔºöÊúâÁöÑÊó∂ÂÄôÊ≤°Ê≥ïÂÆö‰πâÂèòÈáèÁöÑtypeÔºåËøôÊó∂ÂÄôÂèØ‰ª•Áî®autoÔºåÁºñËØëÁöÑÊó∂ÂÄô‰ºöËá™Âä®ÊåáÂá∫ÂèòÈáèÁöÑÁ±ªÂûãÔºà‰ªéÂàùÂßãÂåñÁöÑÁªìÊûúÊé®Êñ≠Âá∫Êù•ÁöÑÔºâ ÂÜôÊàê‰∏ÄË°åÂÆö‰πâÁöÑÊó∂ÂÄôÔºåauto‰∏çËÉΩÂåÖÊã¨‰∏çÂêåÁöÑÁ±ªÂûãÔºàÂ¶ÇintÂíådoubleÔºâ ÊåáÈíàreferÔºåconstÂíåauto ÂΩìÁî®autoÁÑ∂ÂêéÁî®‰∏Ä‰∏™referÂàùÂßãÂåñÁöÑÊó∂ÂÄôÔºåÂæóÂà∞ÁöÑÁªìÊûúÊòØreferÁªëÂÆöÁöÑobject Â¶ÇÊûúÈúÄË¶Åauto‰πãÂêéÁöÑÁªìÊûúËøòÊòØconstÁöÑÔºåÈúÄË¶ÅÂú®autoÂâçÈù¢Âä†‰∏äconst1234const int ci = i, &amp;cr = ci;auto b = ci; // b is an int (top-level const in ci is dropped)auto c = cr; // c is an int (cr is an alias for ci whose const is top-level) autod=&amp;i; // d isan int*(&amp; ofan int objectis int*)auto e = &amp;ci; // e is const int*(&amp; of a const object is low-level const) 2.5.3 decltype ‰ΩúÁî®Ôºö‰ªéexprÈáåÈù¢Êé®Êñ≠Âá∫Êù•typeÔºå‰ΩÜÊòØ‰∏çÁî®Ëøô‰∏™exprÊù•ÂàùÂßãÂåñÁöÑÊó∂ÂÄô„ÄÇËøôÊó∂ÂÄôÁî®decltype(fun())ÔºåËøôÊó∂ÂÄôfunÁî®Êù•Âà§Êñ≠ÂèòÈáèÁöÑÁ±ªÂûãÔºå‰ΩÜÊòØ‰∏çcall Â¶ÇÊûúÊòØÂøÖÈ°ªÂàùÂßãÂåñÁöÑ‰∏úË•øÔºàÊØîÂ¶ÇpointerÊàñËÄÖreferÔºâÂøÖÈ°ªÂàùÂßãÂåñ decltype(* p) is int&amp;, not plain int decltype((variable))ËÇØÂÆöÊòØ‰∏Ä‰∏™referÔºå‰ΩÜÊòØdecltype(variable)Âè™ÊúâÂΩìvariableÊòØreferÁöÑÊó∂ÂÄôÊâçÊòØ Á¨¨‰∏âÁ´† stringÔºåvectorÔºåarrayÁ¨¨‰∫åÁ´†ËØ¥ÁöÑÊòØc++ÈáåÈù¢ÁöÑbuilt-inÁ±ªÂûãÔºåÈô§Ê≠§‰πãÂ§ñËøòÊúâÂæàÂ§ölibraryÁöÑÁ±ªÂûãÔºàÊ†áÂáÜÂ∫ìÔºâÔºåÂÆö‰πâ‰∫ÜÂæàÂ§öÈ´ò‰∫éËÆ°ÁÆóÊú∫ÂÜÖÈÉ®Áõ¥Êé•ËÆøÈóÆÁöÑÊï∞Â≠óÂíåÂ≠óÊØçÁöÑÁ±ªÂûã„ÄÇ 3.1 namespaceÂ£∞Êòé ÊØèÊ¨°ÈÉΩÂ£∞ÊòéÂáΩÊï∞ÁöÑnamespaceÊØîËæÉÈ∫ªÁÉ¶ÔºåÂèØ‰ª•Âú®ÊâÄÊúâÁöÑÂºÄÂßã‰πãÂâçÁî®using namespace :: nameÊù•Â£∞Êòé‰ΩøÁî®ÁöÑÁâπÂÆöÁöÑÂáΩÊï∞ÁöÑnamespace„ÄÇÊàñËÄÖÁõ¥Êé•Áî®‰ªñ‰ª£Ë°®ÊâÄÊúâÁöÑ„ÄÇ Â§¥Êñá‰ª∂ÈáåÈù¢‰∏çÂ∫îËØ•Áî®usingÔºåÂõ†‰∏∫includeÁöÑÊó∂ÂÄôÂ∞±Âä†Âà∞ÊâÄÊúâÁöÑ‰∏úË•øÈáåÈù¢‰∫ÜÔºåÈÇ£Â∞±Ê≤°ÊúâÊÑè‰πâ‰∫Ü 3.2 stringstringÂÆö‰πâÂú®stdÁöÑnamespaceÈáåÈù¢ 3.2.1 ÂÆö‰πâÂíåÂàùÂßãÂåñ ‰∏Ä‰∏™‰∏çÁü•ÈÅìÁöÑÂàùÂßãÂåñÊñπÊ≥ïÔºö string s(n,‚Äôb‚Äô)ÔºåËæìÂá∫ÁªìÊûúÊòØn‰∏™b ‰ΩøÁî®s(‚Äúhiya‚Äù)Âíås=‚Äùhiya‚Äù‰∏Ä‰∏™ÊòØdirectÁöÑÂàùÂßãÂåñÊñπÊ≥ïÔºåÂè¶‰∏Ä‰∏™ÊòØcopyÁöÑÂàùÂßãÂåñÊñπÊ≥ï„ÄÇÊØîËæÉÂÆπÊòìËØªÁöÑÊñπÊ≥ïÊòØÂàõÂª∫Ôºö string s = string(10,‚Äôb‚Äô) 3.2.2 stringÁöÑÊìç‰Ωú stringÁöÑËØªÂíåÂÜôÔºåcoutÂíåcinÔºàiostreamÂ∫ìÔºâ ÂΩìÈîÆÁõòÊúâËæìÂÖ•ÁöÑÊó∂ÂÄôÔºåwhile(cin &gt;&gt; word)ËøôÁßçÊÑüËßâÁöÑ‰∏úË•øÂΩìÊù°‰ª∂ÔºåcinÊòØ‰ºöËØÜÂà´Á©∫Ê†ºÁÑ∂ÂêéÂàÜÂºÄÁöÑÔºÅÔºÅÔºÅ getline()ÂèØ‰ª•ËØªÂèñ‰∏ÄÊï¥Ë°åÔºåÂ≠òÂú®Á¨¨‰∫å‰∏™ÂèÇÊï∞ÈáåÈù¢ÔºåÂπ∂‰∏îÂ∏ÆÂøôË∑≥Âà∞Êñ∞ÁöÑ‰∏ÄË°å .empty()Âíå.size()ÂèØ‰ª•Âà§ÂÆöÊòØÂê¶‰∏∫Á©∫Ôºå‰ª•ÂèästringÈáåÈù¢ÁöÑcharÁöÑÊï∞Èáè string:: size_type sizeÁöÑËøîÂõûÂÄºÁöÑÁ±ªÂûãÊòØsize_type Ê≥®ÊÑèÔºöÂõ†‰∏∫ËøîÂõûÂÄºÁ±ªÂûã‰∏çÂêåÔºåÊâÄ‰ª•ÂΩìÊØîËæÉsizeÁöÑÊó∂ÂÄôÔºåÂ¶ÇÊûúÂíå‰∏Ä‰∏™intÁöÑË¥üÊï∞ÊØîËæÉÔºåint‰ºöË¢´ËΩ¨Êç¢ÊàêunisgnedÁöÑ‰∏Ä‰∏™Â∑®Â§ßÁöÑÊï∞Â≠óÔºå‰ªéËÄåÂØºËá¥ÊØîËæÉÁöÑÂ§±Ë¥• -&gt; ÊâÄ‰ª•Âú®‰ΩøÁî®sizeÁöÑËØ≠Âè•ÈáåÈù¢Ôºå‰∏çÁî®intÊØîËæÉÂ•ΩÔºà‰∫≤Ë∫´ËØÅÊòéÁ°ÆÂÆûÂ¶ÇÊ≠§ÔºåÊç¢ÊàêdoubleÂ∞±Ê≤°‰∫ã‰∫ÜÔºâ ÊØîËæÉÂ≠óÁ¨¶‰∏≤ == ÊàñËÄÖ ÔºÅ= Êù•ÊØîËæÉ‰∏§‰∏™ÊòØÂê¶Áõ∏Á≠âÔºåÈúÄË¶ÅÊòØÁõ∏ÂêåÁöÑÈïøÂ∫¶‰∏îÂåÖÊã¨Áõ∏ÂêåÁöÑÂ≠óÊØç ÊØîËæÉ‰∏§‰∏™ÁöÑÂ§ßÂ∞èÊó∂ Â¶ÇÊûúÈïøÂ∫¶‰∏çÂêåÔºåÂ¶ÇÊûúÁü≠ÁöÑÊØè‰∏™ÁöÑÂ≠óÊØçÈÉΩÂíåÈïøÁöÑÁõ∏ÂêåÔºåÈÇ£Áü≠ÁöÑÊØîËæÉÂ∞è Â¶ÇÊûú‰ªª‰Ωï‰∏Ä‰Ωç‰∏äÈù¢ÁöÑchar‰∏çÂêåÔºåÈÇ£Â∞±ÊòØÁ¨¨‰∏Ä‰∏™‰∏çÂêåÁöÑcharÊØîËæÉÁöÑÁªìÊûú add Â≠óÁ¨¶‰∏≤ÂèØ‰ª•Áõ¥Êé•Áõ∏Âä†ÔºàÊåás1+s2Ôºâ ÂèØ‰ª•ÊäästringÂíåliteralÊ∑∑ÁùÄÂä†Ôºå‰ΩÜÊòØ‰∏§‰∏™Â∏¶ÂºïÂè∑ÁöÑ‰∏çËÉΩËøûÂú®‰∏ÄËµ∑Áõ¥Êé•Âä†ÔºàËøôÊòØ‰ªÄ‰πàËÑëÊÆãËßÑÂàôÔºâ ÁªÉ‰π† ÂèØ‰ª•Áõ¥Êé•ÈÄöËøáÁ¥¢ÂºïvectorÁöÑÊñπÊ≥ïÁ¥¢ÂºïstringÈáåÈù¢ÁöÑcharÔºà‰ΩÜÊòØ‰∏Ä‰∏™ËØç‰∏Ä‰∏™ËØçËØªÂèñÁõ¥Êé•Áî®cin&gt;&gt; s‰πüÊòØÂèØ‰ª•ÁöÑÔºàÊàëÊòØÂÇªÈÄºÂêóÔºâÔºâ ‰∫åÊã©ÁöÑÂà§Êñ≠Êù°‰ª∂ÂèØ‰ª•ÂÜôÊàê ((str1.size() &gt; str2.size()) ? str1 : str2) 3.2.3 stringÈáåÈù¢ÁöÑchars ÊúâÊó∂ÂÄôÈúÄË¶ÅÂ§ÑÁêÜÊØè‰∏Ä‰∏™Â≠óÊØçÔºåÊúâÁöÑÊó∂ÂÄôÈúÄË¶ÅÂ§ÑÁêÜÁâπÊÆäÁöÑ‰∏Ä‰∫õÂ≠óÊØçÔºåÂÆö‰πâÂú®ÂáΩÊï∞cctypeÈáåÈù¢]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Cpp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫énumpyÈáåÈù¢random.randÂíårandnÁöÑÂå∫Âà´]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%85%B3%E4%BA%8Erandomrand%E5%92%8Crandn%2F</url>
    <content type="text"><![CDATA[pythonÈáåÈù¢Â∏∏Áî®ÁöÑ‰∏§‰∏™‰∫ßÁîüÈöèÊú∫Êï∞ÁöÑÂáΩÊï∞Ôºå‰∏§‰∏™‰∏çÂ§™‰∏ÄÊ†∑ ÂÖ∂‰∏≠ np.random.rand()ÊòØÁî®Êù•‰∫ßÁîü0-1‰πãÈó¥ÁöÑÈöèÊú∫Êï∞ÁöÑÔºåËøô‰∏™ÊúÄËøëÂ∫îÁî®ÊúÄÂ§öÁöÑÂú∞ÊñπÊòØÂú®‰∫ßÁîü‰∏Ä‰∏™‰ªéa-bËåÉÂõ¥ÈáåÈù¢ÁöÑÊï∞Â≠óÔºåËøôÊó∂ÂÄôÂèØ‰ª•ÂÖà‰∫ßÁîü‰∏Ä‰∏™Â∑®Â§ßÁöÑÈöèÊú∫0-1ÁöÑÁü©ÈòµÔºåÁÑ∂ÂêéÂÜç‰πò‰ª•aÂíåb‰πãÈó¥ÁöÑÂ∑Æ np.random.randn()‰∫ßÁîüÁöÑÊòØÈöèÊú∫Ê≠£ÊÄÅÂàÜÂ∏ÉÁöÑÊ†áÂáÜÂÄºÔºåÂ§ñÈù¢ÂèØ‰ª•‰πò‰∏ästdÂ∞±ÊòØÈúÄË¶ÅÁöÑÊ≠£ÊÄÅÂàÜÂ∏ÉÔºåËøôÊ†∑ÂèØ‰ª•Áî®Êù•ÂàùÂßãÂåñÊ∑±Â∫¶ÁΩëÁªúÁöÑweightsÔºåÊã¨Âè∑ÈáåÂ°´ÁöÑÈÉΩÊòØÁîüÊàêÁöÑ‰∏úË•øÁöÑÁª¥Â∫¶ Âè¶Â§ñ‰∏Ä‰∏™ÈóÆÈ¢òÔºårandnÁöÑÂèÇÊï∞ÈúÄË¶ÅÁöÑÊòØinterÔºåÊâÄ‰ª•Âú®ËæìÂÖ•ÁöÑÊó∂ÂÄôË¶Å‰∏çÊòØÈÄâÊã© np.random.randn(x0.shape[0], x0.shape[1]) np.random.randn(*x0.shape)]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>random</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment2‰πãFCnet]]></title>
    <url>%2F2019%2F04%2F11%2FCS231Nassignment2FCnet%2F</url>
    <content type="text"><![CDATA[This part is from the assignment 2018:stanford cs231n assignment2 ÁõÆÊ†á ‰πãÂâçÂ∑≤ÁªèÂÆûÁé∞‰∫Ü‰∏§Â±ÇÁöÑfc netÔºå‰ΩÜÊòØÂú®Ëøô‰∏™ÁΩëÁªúÈáåÈù¢ÁöÑlossÂíågradientÁöÑËÆ°ÁÆóÁî®ÁöÑÊòØÊï∞Â≠¶ÊñπÊ≥ï ËøôÊ†∑ÁöÑËÆ°ÁÆóÂèØ‰ª•Âú®‰∏§Â±ÇÁöÑÁΩëÁªúÈáåÂÆûÁé∞Ôºå‰ΩÜÊòØÂ§öÂ±ÇÁöÑÊÉÖÂÜµ‰∏ãÂÆûÁé∞Ëµ∑Êù•Â§™Âõ∞Èöæ‰∫Ü ÊâÄ‰ª•Âú®ËøôÈáåÊääÁîµËÑëÂàÜÊàê‰∫Üforward passÂíåbackward pass forwardÁöÑËøáÁ®ã‰∏≠ÔºåÊé•ÂèóÊâÄÊúâÁöÑinputÔºåweightsÔºåÂíåÂÖ∂‰ªñÁöÑÂèÇÊï∞ÔºåËøîÂõûoutputÂíåcacheÔºàÂ≠òÂÇ®backÁöÑÊó∂ÂÄôÈúÄË¶ÅÁöÑ‰∏úË•øÔºâ 12345678910def layer_forward(x, w): """ Receive inputs x and weights w """ # Do some computations ... z = # ... some intermediate value # Do some more computations ... out = # the output cache = (x, w, z, out) # Values we need to compute gradients return out, cache backÁöÑÊó∂ÂÄô‰ºöÊé•ÂèóderivativeÂíå‰πãÂâçÂ≠òÂÇ®ÁöÑcacheÔºåÁÑ∂ÂêéËÆ°ÁÆóÊúÄÂêéÁöÑgradient 12345678910111213def layer_backward(dout, cache): """ Receive dout (derivative of loss with respect to outputs) and cache, and compute derivative with respect to inputs. """ # Unpack cache values x, w, z, out = cache # Use values in cache to compute derivatives dx = # Derivative of loss with respect to x dw = # Derivative of loss with respect to w return dx, dw ËøôÊ†∑Â∞±ÂèØ‰ª•ÁªÑÂêàÂêÑ‰∏™ÈÉ®ÂàÜËææÂà∞ÊúÄÁªàÈúÄË¶ÅÁöÑÊïàÊûú‰∫ÜÔºåÊó†ËÆ∫Â§öÊ∑±ÈÉΩÂèØ‰ª•ÂÆûÁé∞‰∫Ü ËøòÈúÄË¶Å‰∏ÄÈÉ®ÂàÜÁöÑ‰ºòÂåñÈÉ®ÂàÜÔºåÂåÖÊã¨DropoutÔºåBatch/LayerÁöÑNormalization Affine layerÔºöforwardinput xÔºöÂ§ßÂ∞èÔºàNÔºåd_1‚Ä¶d_k)Ôºåminibatch of NÔºåÊØèÂº†ÂõæÁâáÁöÑÁª¥Â∫¶ÊòØd_1Âà∞d_kÔºåÊâÄ‰ª•ÊãâÊàê‰∏ÄÈïøÊù°ÁöÑÁª¥Â∫¶ÊòØ d_1 d_2‚Ä¶ d_k wÔºöweightsÔºå(D,M)ÔºåÊääËøô‰∏™ÈïøÂ∫¶ÊòØdÁöÑÂõæÁâáÔºåËæìÂá∫ÁöÑÊó∂ÂÄôÂ∞±ÂèòÊàêM‰∫Ü b:bias,(M,) -&gt; Ëøô‰∏™bias‰ºöË¢´broadcastÂà∞all lines ÔºàbiasÁöÑÂÄºÊòØÊúÄÁªàÂàÜÁ±ªÁöÑclassÁöÑÂÄºÔºåÂú®‰∏çÊòØÊúÄÂêé‰∏ÄÂ±ÇÁöÑÊó∂ÂÄôÂ∞±ÊòØoutputÁöÑÂÄºÔºâÔºåÁõ∏ÂΩì‰∫é‰∏Ä‰∏™classÂàÜ‰∏Ä‰∏™biasÔºà‰∏ÄÂàóÔºâ output output,(N,M) cache:(x,w,b) implement ËøôÈáåÁöÑÂÆûÁé∞Áõ¥Êé•reshapeÂ∞±ÂèØ‰ª•‰∫ÜÔºå-1ÁöÑÊÑèÊÄùÊòØËøô‰∏™Áª¥Â∫¶‰∏ä‰∏çÁü•ÈÅìÊúâÂ§öÂ∞ëÂèçÊ≠£‰Ω†Ëá™Â∑±ÁªôÊàëÁÆóÁÆóÁöÑÊÑèÊÄùÔºå‰ΩÜÊòØÈúÄË¶ÅNË°åÊòØÁ°ÆÂÆö‰∫ÜÁöÑ Ê≥®ÊÑèËøôÈáåÈ™åËØÅÁöÑÊó∂ÂÄôËôΩÁÑ∂inputÁöÑÊòØsizeÔºå‰ΩÜÊòØÂÆûÈôÖ‰∏äÊòØÊääÊï∞Â≠óÂ°´Âà∞Ëøô‰∏™ÈáåÈù¢ÁöÑÔºåÊâÄ‰ª•ÂèñNÁöÑÊó∂ÂÄôÂÆûÈôÖ‰∏äÊòØx.shape[0] Affine layer:backwardinput dout: upstream derivative, shape(N,M) cache: Tuple x w b return dx: (N,d1,d2‚Ä¶,dk) dw:(D,M) db:(M,) implement Ê≥®ÊÑèËøôÈáåÁî®Âà∞ÁöÑÊòØÈìæÂºèÊ≥ïÂàôÔºödf/dx = df/dq * dq/dx ËøôÈáåÁöÑdf/dqÂ∞±ÊòØÂ∑≤ÁªèÊ±ÇÂá∫Êù•ÁöÑdout qÁöÑÂºèÂ≠êÊòØ Wx + bÔºåÂØπËøô‰∏â‰∏™ÂèòÈáèÂàÜÂà´Ê±ÇÂØºÔºåÊ±ÇÂá∫Êù•Â§ßÂÆ∂ÁöÑÔºåÂà´Âøò‰∫ÜÊ±ÇÂØº‰πãÂêéÁöÑ‰∏úË•øÈúÄË¶ÅÂÜç‰πòdout ÁªìÊûúÂà∞Â∫ïÊÄé‰πàÁÆóÂ∫îËØ•ÊåâÊØè‰∏™Áü©ÈòµÁöÑshapeÊù•Êé®Âá∫Êù• ReLU activationforward inputÔºöxÔºåÈöè‰æø‰ªÄ‰πàÂ∞∫ÂØ∏ÈÉΩÂèØ‰ª•ÔºåËøôÈÉ®ÂàÜÂè™ÊòØËÆ°ÁÆóreluËøô‰∏™ÂáΩÊï∞ output outÔºåËÆ°ÁÆóÂá∫Êù•ÁöÑÁªìÊûú cacheÔºåÂÇ®Â≠òxÔºåÁî®Êù•backÁöÑËøêÁÆó implement -&gt; Áõ¥Êé•ÊääÂ∞è‰∫é0ÁöÑÈÉ®ÂàÜËÆæÁΩÆÊàê0Â∞±ÂèØ‰ª•‰∫Ü backward input ËøîÂõûÂõûÊù•ÁöÑdout cache outputÔºö ËÆ°ÁÆóÂá∫Êù•ÁöÑxÁöÑÊ¢ØÂ∫¶ implement: Ê±ÇÂØºÔºåÂΩìÂéüÊù•ÁöÑxÂ§ß‰∫é0ÁöÑÊó∂ÂÄôÔºåÂØºÊï∞ÊòØ1ÔºåÈìæÂºèÊ≥ïÂàôÊòØdout„ÄÇÂ∞è‰∫éÁ≠â‰∫é0ÁöÑÊó∂ÂÄôÊòØdout ÊâÄ‰ª•Áõ¥Êé•ÂØπdoutËøõË°åÊìç‰ΩúÂ∞±ÂèØ‰ª•‰∫Ü 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107def affine_forward(x, w, b): """ Computes the forward pass for an affine (fully-connected) layer. The input x has shape (N, d_1, ..., d_k) and contains a minibatch of N examples, where each example x[i] has shape (d_1, ..., d_k). We will reshape each input into a vector of dimension D = d_1 * ... * d_k, and then transform it to an output vector of dimension M. Inputs: - x: A numpy array containing input data, of shape (N, d_1, ..., d_k) - w: A numpy array of weights, of shape (D, M) - b: A numpy array of biases, of shape (M,) Returns a tuple of: - out: output, of shape (N, M) - cache: (x, w, b) """ out = None ########################################################################### # TODO: Implement the affine forward pass. Store the result in out. You # # will need to reshape the input into rows. # ########################################################################### out = x.reshape(x.shape[0], -1).dot(w) + b ########################################################################### # END OF YOUR CODE # ########################################################################### cache = (x, w, b) return out, cachedef affine_backward(dout, cache): """ Computes the backward pass for an affine layer. Inputs: - dout: Upstream derivative, of shape (N, M) - cache: Tuple of: - x: Input data, of shape (N, d_1, ... d_k) - w: Weights, of shape (D, M) - b: Biases, of shape (M,) Returns a tuple of: - dx: Gradient with respect to x, of shape (N, d1, ..., d_k) - dw: Gradient with respect to w, of shape (D, M) - db: Gradient with respect to b, of shape (M,) """ x, w, b = cache dx, dw, db = None, None, None ########################################################################### # TODO: Implement the affine backward pass. # ########################################################################### dx = dout.dot(w.T).reshape(x.shape) dw = (x.reshape(x.shape[0], -1).T).dot(dout) db = np.sum(dout, axis=0) ########################################################################### # END OF YOUR CODE # ########################################################################### return dx, dw, dbdef relu_forward(x): """ Computes the forward pass for a layer of rectified linear units (ReLUs). Input: - x: Inputs, of any shape Returns a tuple of: - out: Output, of the same shape as x - cache: x """ out = None ########################################################################### # TODO: Implement the ReLU forward pass. # ########################################################################### out = x.copy() out[out &lt;= 0] = 0.0 ########################################################################### # END OF YOUR CODE # ########################################################################### cache = x return out, cachedef relu_backward(dout, cache): """ Computes the backward pass for a layer of rectified linear units (ReLUs). Input: - dout: Upstream derivatives, of any shape - cache: Input x, of same shape as dout Returns: - dx: Gradient with respect to x """ dx, x = None, cache ########################################################################### # TODO: Implement the ReLU backward pass. # ########################################################################### dout[x &lt;= 0] = 0 dx = dout ########################################################################### # END OF YOUR CODE # ########################################################################### return dx sandwich layerÂú®Êñá‰ª∂cs231n/layer_utils.pyÈáåÈù¢ÔºåÊúâ‰∏Ä‰∫õÊØîËæÉÂ∏∏ËßÅÁöÑÁªÑÂêàÔºåÂèØ‰ª•ÈõÜÊàêÊàêÊñ∞ÁöÑÂáΩÊï∞ÔºåËøôÊ†∑Áî®ÁöÑÊó∂ÂÄôÂ∞±ÂèØ‰ª•Áõ¥Êé•Ë∞ÉÁî®‰∏çÁî®Ëá™Â∑±ÂÜô‰∫Ü loss layer -&gt; Âíåassignment1ÈáåÈù¢ÂÜôÁöÑÂÜÖÂÆπÊòØ‰∏ÄÊ†∑ÁöÑtwo-layer networkcs231n/classifiers/fc_net.py TwoLayerNet init__ ÈúÄË¶ÅÂàùÂßãÂåñweightsÂíåbiasÔºåweightsÂ∫îËØ•ÊòØ0.0‰∏≠ÂøÉÁöÑÈ´òÊñØÔºà=weight_scaleÔºâÔºåbiasÂ∫îËØ•ÊòØ0ÔºåÈÉΩÂ≠òÂú®self.paraÁöÑÂ≠óÂÖ∏ÈáåÈù¢ÔºåÁ¨¨Âá†Â±ÇÁöÑÂêçÂ≠óÂ∞±Âè´Á¨¨Âá† input ÂõæÁâáÁöÑsize hiddenÁöÑ‰∏™Êï∞ classÁöÑÊï∞Èáè weight scaleÔºåÁúãÂàùÂßãÁöÑweightsÊÄé‰πàÂàÜÂ∏É regÔºåregularizationÊó∂ÂÄôÁöÑÊùÉÈáç forward Áî®ÂâçÈù¢Â∑≤ÁªèÂÜôÂ•ΩÁöÑ‰∏úË•øËÆ°ÁÆóÂâçÂêë ÊúÄÂêéÂæóÂà∞scores ÂÜçÁî®scoresËÆ°ÁÆólossÔºåÊ≥®ÊÑè ËÆ°ÁÆóloss‰πüÊòØ‰∏ÄÂ±Ç ËÆ°ÁÆólossÁöÑÊó∂ÂÄôÊ≥®ÊÑè‰ªñËøôÈáålossÁöÑÂèÇÊï∞ÊòØscoresÂíålable backward backÁöÑÊó∂ÂÄô‰∏çË¶ÅÂøòËÆ∞‰∫Üloss‰πüÊòØ‰∏ÄÂ±ÇÔºåÊâÄ‰ª•ËæìÂÖ•Á¨¨‰∫å‰∏™sandwichÁöÑÊó∂ÂÄôËæìÂÖ•ÁöÑÂ∫îËØ•ÊòØdscoresËÄå‰∏çÊòØscoresÔºüÔºÅÔºÅÔºÅÔºÅ ËÆ°ÁÆógradientÔºåÊ≥®ÊÑè‰ªñÁöÑfunctionÈáåÈù¢Â∑≤ÁªèÈô§‰∫ÜÊÄªÊï∞ÔºÅ Âà´Âøò‰∫ÜÂä†‰∏äL2ÁöÑregularization SolverÊää‰πãÂâçÈÇ£‰∫õËÆ≠ÁªÉÂïäÔºåÈ™åËØÅÂïäÔºåËÆ°ÁÆóaccuracy‰πãÁ±ªÁöÑÈÉ®ÂàÜÂÖ®ÈÉΩÊâîÂà∞‰∏Ä‰∏™classÈáåÈù¢Âè´ÂÅösolverÔºåÊâìÂºÄcs231n/solver.py ‰ΩúÁî® solverÈÉ®ÂàÜÂåÖÊã¨ÊâÄÊúâËÆ≠ÁªÉÂàÜÁ±ªÊâÄÈúÄË¶ÅÁöÑÈÄªËæëÈÉ®ÂàÜÔºåÂú®optim.pyÈáåÈù¢ËøòÁî®‰∫Ü‰∏çÂêåÁöÑupdateÊñπÊ≥ïÊù•ÂÆûÁé∞SGD Ëøô‰∏™classÊé•ÂèótrainingÂíåvalidationÁöÑÊï∞ÊçÆÂíålabelsÔºåÊâÄ‰ª•ÂèØ‰ª•Ê£ÄÊü•ÂàÜÁ±ªÁöÑÂáÜÁ°ÆÁéáÔºåÊòØÂê¶overfitting ÈúÄË¶ÅÂÖàÊûÑÊàê‰∏Ä‰∏™solverÁöÑinstanceÔºåÊääÈúÄË¶ÅÁöÑmodelÔºådatasetÔºåÂíå‰∏çÂêåÁöÑ‰∏úË•øÔºàlearning rateÔºåbatchÔºåetcÔºâÊîæËøõÂéª ÂÖàÁî®train()Êù•ËÆ≠ÁªÉÔºåÁÑ∂ÂêémodelÁöÑparaÈÉΩÂ≠òÁùÄÊâÄÊúâËÆ≠ÁªÉÂÆåÁöÑÂèÇÊï∞ ËÆ≠ÁªÉÁöÑËøáÁ®ã‰πü‰ºöËÆ∞ÂΩï‰∏ãÊù•ÔºàaccuracyÁöÑÊîπÂèòÂï•ÁöÑÔºâ ÊúÄÂêéËÆ≠ÁªÉÁöÑÁªìÊûúÂ§ßÁ∫¶Âú®50%12345678910111213141516171819model = TwoLayerNet()solver = None############################################################################### TODO: Use a Solver instance to train a TwoLayerNet that achieves at least ## 50% accuracy on the validation set. ###############################################################################solver = Solver(model, data, update_rule = 'sgd', optim_config=&#123;'learning_rate': 1e-3,&#125;, lr_decay=0.95, num_epochs=10, batch_size=100, print_every=100)solver.train()############################################################################### END OF YOUR CODE ######################################################################## ÂèØËßÜÂåñËøô‰∏™ÊúÄÁªàÁöÑÁªìÊûúÔºålossÈöèÁùÄepochÁöÑÂèòÂåñÂíåtraining acc‰ª•Âèäval accÁöÑÂèòÂåñ12345678910111213141516# Run this cell to visualize training loss and train / val accuracyplt.subplot(2, 1, 1)plt.title('Training loss')plt.plot(solver.loss_history, 'o')plt.xlabel('Iteration')plt.subplot(2, 1, 2)plt.title('Accuracy')plt.plot(solver.train_acc_history, '-o', label='train')plt.plot(solver.val_acc_history, '-o', label='val')plt.plot([0.5] * len(solver.val_acc_history), 'k--')plt.xlabel('Epoch')plt.legend(loc='lower right')plt.gcf().set_size_inches(15, 12)plt.show() ËÆ∞‰∏ãÊù•‰∫ÜËøô‰∏™lossÂíåaccÁöÑhistoryÔºåÊâÄ‰ª•Â∞±ÂèØ‰ª•Áõ¥Êé•Áî®Êù•ÂèØËßÜÂåñ‰∫ÜÔºÅ Multilayer networkÁé∞Âú®ÂºÄÂßãÂÆûÁé∞ÊúâÂ§öÂ±ÇÁöÑnet ÈúÄË¶ÅÊ≥®ÊÑèÁöÑÈóÆÈ¢ò‰∏ªË¶ÅÊòØÊï∞Êï∞Êï∞ÂØπ‰∫ÜÔºåÊ≥®ÊÑèÊï∞Â≠óÂíålayerÁöÑÊï∞ÈáèÁöÑÂÖ≥Á≥ª ‰∏∫‰∫Ü‰øùËØÅÈ™åËØÅÁöÑÂáÜÁ°ÆÔºåÈúÄË¶ÅÊäälossÁöÑregularizationÁÆóÂØπÊâçÂèØ‰ª• ÂèçÂêëÂæÄÂõûÊé®ÁöÑÊó∂ÂÄôÔºåÂèØ‰ª•Áî® reversed(range(a))Ëøô‰∏™‰∏úË•øÊù•ËøõË°å ÊÄª‰ΩìÊù•ËØ¥Âíå‰∏§Â±ÇÁöÑÂ∑Æ‰∏çÂ§öÔºåÂ∞±ÊòØÂä†ËøõÊù•‰∫ÜforÂæ™ÁéØ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202class FullyConnectedNet(object): """ A fully-connected neural network with an arbitrary number of hidden layers, ReLU nonlinearities, and a softmax loss function. This will also implement dropout and batch/layer normalization as options. For a network with L layers, the architecture will be &#123;affine - [batch/layer norm] - relu - [dropout]&#125; x (L - 1) - affine - softmax where batch/layer normalization and dropout are optional, and the &#123;...&#125; block is repeated L - 1 times. Similar to the TwoLayerNet above, learnable parameters are stored in the self.params dictionary and will be learned using the Solver class. """ def __init__(self, hidden_dims, input_dim=3 * 32 * 32, num_classes=10, dropout=1, normalization=None, reg=0.0, weight_scale=1e-2, dtype=np.float32, seed=None): """ Initialize a new FullyConnectedNet. Inputs: - hidden_dims: A list of integers giving the size of each hidden layer. - input_dim: An integer giving the size of the input. - num_classes: An integer giving the number of classes to classify. - dropout: Scalar between 0 and 1 giving dropout strength. If dropout=1 then the network should not use dropout at all. - normalization: What type of normalization the network should use. Valid values are "batchnorm", "layernorm", or None for no normalization (the default). - reg: Scalar giving L2 regularization strength. - weight_scale: Scalar giving the standard deviation for random initialization of the weights. - dtype: A numpy datatype object; all computations will be performed using this datatype. float32 is faster but less accurate, so you should use float64 for numeric gradient checking. - seed: If not None, then pass this random seed to the dropout layers. This will make the dropout layers deteriminstic so we can gradient check the model. """ self.normalization = normalization self.use_dropout = dropout != 1 self.reg = reg self.num_layers = 1 + len(hidden_dims) self.dtype = dtype self.params = &#123;&#125; ############################################################################ # TODO: Initialize the parameters of the network, storing all values in # # the self.params dictionary. Store weights and biases for the first layer # # in W1 and b1; for the second layer use W2 and b2, etc. Weights should be # # initialized from a normal distribution centered at 0 with standard # # deviation equal to weight_scale. Biases should be initialized to zero. # # # # When using batch normalization, store scale and shift parameters for the # # first layer in gamma1 and beta1; for the second layer use gamma2 and # # beta2, etc. Scale parameters should be initialized to ones and shift # # parameters should be initialized to zeros. # ############################################################################ pr_num = input_dim # can't use enumerate beacuse I need the number more than the size of hidden_dims for layer in range(self.num_layers): layer += 1 weights = 'W' + str(layer) bias = 'b' + str(layer) # ËøôÊó∂ÂÄôÊòØÊúÄÂêé‰∏ÄÂ±Ç(the last layer) if layer == self.num_layers: self.params[weights] = np.random.randn( hidden_dims[len(hidden_dims) - 1], num_classes) * weight_scale self.params[bias] = np.zeros(num_classes) # other layers else: hidd_num = hidden_dims[layer - 1] self.params[weights] = np.random.randn( pr_num, hidd_num) * weight_scale self.params[bias] = np.zeros(hidd_num) pr_num = hidd_num if self.normalization in ["batchnorm", "layernorm"]: self.params['gamma' + str(layer)] = np.ones(hidd_num) self.params['bata' + str(layer)] = np.zeros(hidd_num) # print(len(self.params)) # print(self.params) ############################################################################ # END OF YOUR CODE # ############################################################################ # When using dropout we need to pass a dropout_param dictionary to each # dropout layer so that the layer knows the dropout probability and the mode # (train / test). You can pass the same dropout_param to each dropout layer. self.dropout_param = &#123;&#125; if self.use_dropout: self.dropout_param = &#123;'mode': 'train', 'p': dropout&#125; if seed is not None: self.dropout_param['seed'] = seed # With batch normalization we need to keep track of running means and # variances, so we need to pass a special bn_param object to each batch # normalization layer. You should pass self.bn_params[0] to the forward pass # of the first batch normalization layer, self.bn_params[1] to the forward # pass of the second batch normalization layer, etc. self.bn_params = [] if self.normalization == 'batchnorm': self.bn_params = [&#123;'mode': 'train'&#125; for i in range(self.num_layers - 1)] if self.normalization == 'layernorm': self.bn_params = [&#123;&#125; for i in range(self.num_layers - 1)] # Cast all parameters to the correct datatype for k, v in self.params.items(): self.params[k] = v.astype(dtype) def loss(self, X, y=None): """ Compute loss and gradient for the fully-connected net. Input / output: Same as TwoLayerNet above. """ X = X.astype(self.dtype) mode = 'test' if y is None else 'train' # Set train/test mode for batchnorm params and dropout param since they # behave differently during training and testing. if self.use_dropout: self.dropout_param['mode'] = mode if self.normalization == 'batchnorm': for bn_param in self.bn_params: bn_param['mode'] = mode scores = None ############################################################################ # TODO: Implement the forward pass for the fully-connected net, computing # # the class scores for X and storing them in the scores variable. # # # # When using dropout, you'll need to pass self.dropout_param to each # # dropout forward pass. # # # # When using batch normalization, you'll need to pass self.bn_params[0] to # # the forward pass for the first batch normalization layer, pass # # self.bn_params[1] to the forward pass for the second batch normalization # # layer, etc. # ############################################################################ cache = &#123;&#125; temp_out = X for i in range(self.num_layers): w = self.params['W' + str(i + 1)] b = self.params['b' + str(i + 1)] if i == self.num_layers - 1: scores, cache['cache' + str(i + 1)] = affine_relu_forward(temp_out, w, b) else: temp_out, cache['cache' + str(i + 1)] = affine_relu_forward(temp_out, w, b) ############################################################################ # END OF YOUR CODE # ############################################################################ # If test mode return early if mode == 'test': return scores loss, grads = 0.0, &#123;&#125; ############################################################################ # TODO: Implement the backward pass for the fully-connected net. Store the # # loss in the loss variable and gradients in the grads dictionary. Compute # # data loss using softmax, and make sure that grads[k] holds the gradients # # for self.params[k]. Don't forget to add L2 regularization! # # # # When using batch/layer normalization, you don't need to regularize the scale # # and shift parameters. # # # # NOTE: To ensure that your implementation matches ours and you pass the # # automated tests, make sure that your L2 regularization includes a factor # # of 0.5 to simplify the expression for the gradient. # ############################################################################ loss, dscores = softmax_loss(scores, y) reg_loss = 0.0 pre_dx = dscores for i in reversed(range(self.num_layers)): i = i + 1 reg_loss = np.sum(np.square(self.params['W' + str(i)])) loss += reg_loss * 0.5 * self.reg pre_dx, dw, db = affine_relu_backward( pre_dx, cache['cache' + str(i)]) dw += self.reg * self.params['W' + str(i)] db += self.reg * self.params['b' + str(i)] grads['W' + str(i)] = dw grads['b' + str(i)] = db ############################################################################ # END OF YOUR CODE # ############################################################################ return loss, grads Ê£ÄÊµãÁΩëÁªúÊòØÂê¶overfitting ÈÄâÊã©‰∫Ü‰∏Ä‰∏™‰∏âÂ±ÇÁöÑÁΩëÁªúÔºåÂ∞èÂπÖÂ∫¶ÊîπÂèòlearning rateÂíåinit scale Â∞ùËØïÂéªoverfittingÂá∫Áé∞‰∫Ü‰∏Ä‰∫õÈóÆÈ¢ò‰∏çÊòØÂ§™ËÉΩoverfittingÊàë‰∏çÁü•ÈÅì‰∏∫‰ªÄ‰πà update rulesÂú®ÂæóÂà∞‰∫ÜbackÂá∫Êù•ÁöÑdw‰πãÂêéÔºåÂ∞±ÈúÄË¶ÅÁî®Ëøô‰∏™dwÂØπwËøõË°åupdateÔºåËøôÈáåÊúâ‰∏Ä‰∫õÊØîËæÉÂ∏∏ËßÅÁöÑupdateÊñπÊ≥ï ÊôÆÈÄöÁöÑupdate ‰ªÖ‰ªÖÊ≤øÁùÄgradientÊîπÂèòÁöÑÂèçÊñπÂêëËøõË°å(ÂèçÊñπÂêëÊòØÂõ†‰∏∫ËÆ°ÁÆóÂá∫Êù•ÁöÑgradientÊòØ‰∏äÂçáÁöÑÊñπÂêë)x += - learning_rate * dx SGD + momentumhttp://cs231n.github.io/neural-networks-3/#sgd ÊòØÂØπËøô‰∏™update‰∏ÄÁÇπÁâ©ÁêÜ‰∏äÊØîËæÉÁõ¥ËßÇÁöÑÁêÜËß£ÔºàÂÖ∂ÂÆûÂêçÂ≠óÂè´ÂÅöÂä®ÈáèÔºâ ÂèØ‰ª•ÁêÜËß£‰∏∫Ëøô‰∏™‰∏úË•øÊòØÂú®‰∏Ä‰∏™Âπ≥Âéü‰∏äË∑ëÁöÑ‰∏Ä‰∏™ÁêÉÔºåÊàë‰ª¨ÈúÄË¶ÅÊ±ÇÁöÑwÊòØËøô‰∏™ÁêÉÁöÑÈÄüÂ∫¶ÔºåÂæóÂà∞ÁöÑdwÊòØËøô‰∏™ÁêÉÁöÑÂä†ÈÄüÂ∫¶ÔºåËÄåËøô‰∏™ÁêÉÁöÑÂàùÈÄüÂ∫¶ÊòØ0 ÂèØ‰ª•ÁêÜËß£‰∏∫Ëøô‰∏™ÁêÉÊâæÊúÄ‰ΩéÁÇπÁöÑÊó∂ÂÄôÔºåÈô§‰∫ÜÊØèÊ≠•Êåâdw updateÔºåËøòÂú®‰∏äÈù¢Âä†‰∏ä‰∫ÜÂâçÈù¢ÈÄüÂ∫¶ÁöÑÂΩ±ÂìçÔºå‰πüÂ∞±ÊòØÂä†‰∏ä‰∫ÜÊÉØÊÄßÔºÅ123# Momentum updatev = mu * v - learning_rate * dx # integrate velocityx += v # integrate position Nesterov Momentum(NAG) Âú®ÂéüÊù•ÁöÑÂü∫Á°Ä‰∏äÔºöÁúüÂÆûÁßªÂä®ÊñπÂêë = ÈÄüÂ∫¶ÁöÑÂΩ±ÂìçÔºàmomentumÔºâ+ Ê¢ØÂ∫¶ÁöÑÂΩ±Âìç ÔºàgradientÔºâ Áé∞Âú®ÔºöÊó¢ÁÑ∂Êàë‰ª¨Â∑≤ÁªèÁü•ÈÅì‰∫ÜË¶ÅÂæÄÂâçËµ∞Âà∞Âä®ÈáèÁöÑÂΩ±ÂìçÁöÑ‰ΩçÁΩÆÔºåÈÇ£‰πàÊàëÊ†πÊçÆÈÇ£‰∏™‰ΩçÁΩÆÁöÑÊ¢ØÂ∫¶ÂÜçËøõË°åupdateÔºåÂ≤Ç‰∏çÊòØË∑ëÁöÑÊõ¥Âø´ÔºÅ ÊÄªÁöÑÊù•ËØ¥Â∞±ÊòØËÄÉËôëÂà∞‰∫ÜÂâçÈù¢ÁöÑÂù°Â∫¶Ôºà‰∫åÈò∂ÂØºÊï∞ÔºâÔºåÂ¶ÇÊûúÂâçÈù¢ÁöÑÂù°Â∫¶ÁºìÁöÑËØùÊàëÂ∞±ÂÜçË∑ëÂø´ÁÇπÔºåÂ¶ÇÊûúÈô°ÁöÑËØùÂ∞±Ë∑ëÊÖ¢ÁÇπ123v_prev = v # back this upv = mu * v - learning_rate * dx # velocity update stays the samex += -mu * v_prev + (1 + mu) * v # position update changes form cs231n/optim.py Âä†ÂÖ•‰∫ÜÊñ∞ÁöÑËÆ°ÁÆóupdateÁöÑÊñπÊ≥ï ÂÖ∑‰ΩìÁöÑÂéüÁêÜËøòÊ≤°ÊúâÁúãÔºå‰ΩÜÊòØËÆ°ÁÆóÂ∞±ÊòØËøôÊ†∑ËÆ°ÁÆóÁöÑ 12345678910111213141516171819202122232425262728293031def sgd_momentum(w, dw, config=None): """ Performs stochastic gradient descent with momentum. config format: - learning_rate: Scalar learning rate. - momentum: Scalar between 0 and 1 giving the momentum value. Setting momentum = 0 reduces to sgd. - velocity: A numpy array of the same shape as w and dw used to store a moving average of the gradients. """ if config is None: config = &#123;&#125; config.setdefault('learning_rate', 1e-2) config.setdefault('momentum', 0.9) v = config.get('velocity', np.zeros_like(w)) next_w = None ########################################################################### # TODO: Implement the momentum update formula. Store the updated value in # # the next_w variable. You should also use and update the velocity v. # ########################################################################### v = config['momentum'] * v - config['learning_rate'] * dw w += v next_w = w ########################################################################### # END OF YOUR CODE # ########################################################################### config['velocity'] = v return next_w, config ÂèØ‰ª•ÁúãÂá∫Êù•ÊúÄÁªàÁöÑÁªìÊûú‰ºöÊØîÊôÆÈÄöÁöÑSGD‰∏äÂçáÁöÑÊõ¥Âø´ ÂàÜÂà´ÂèàÂ∞ùËØï‰∫ÜRMSProp and Adam]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
        <category>CS231n‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>Fully Connected Net</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫éÁ©∫Èó¥ÊäïÂΩ±Â¢ûÂº∫ÔºàSARÔºâÁöÑËÆ∫Êñá]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%85%B3%E4%BA%8E%E7%A9%BA%E9%97%B4%E6%8A%95%E5%BD%B1%E5%A2%9E%E5%BC%BA%E7%9A%84%E8%AE%BA%E6%96%87%2F</url>
    <content type="text"><![CDATA[Áõ∏ÂÖ≥‰ªãÁªçÈìæÊé•koike lab roomAlive ÂÖ≥‰∫éopencvÁöÑfisheye calibrationÔºöhttp://ninghang.blogspot.com/2012/08/fish-eye-camera-calibration.html ÂÖ≥‰∫écalibrationÁöÑËßÜËßíÁöÑÈóÆÈ¢òÔºåmatlabÂèØ‰ª•ÊâæÂà∞ÂÖ®ÈÉ®ËßÜËßíÔºöhttps://www.mathworks.com/help/vision/ug/fisheye-calibration-basics.html DeepCalib: A Deep Learning Approach for Automatic Intrinsic Calibration of Wide Field-of-View CamerasÔºàCVMP ‚Äò18Ôºâ‰ΩøÁî®Ê∑±Â∫¶Â≠¶‰π†ÂØπfish eyeÁõ∏Êú∫ÁöÑËßÜÈáéËøõË°åË°•ÂÖ®„ÄÇ ÊñáÁ´†‰∏≠ÂÖ¨ÂºÄÁöÑcodeÂíåÂÖ∂‰ªñËµÑÊñô Abstract ÂπøËßíÁõ∏Êú∫ÁöÑcalibrationÂú®ÂêÑÁßçÂêÑÊ†∑ÁöÑÂú∞ÊñπÈÉΩÊúâÂ∫îÁî® 3DÈáçÂª∫ image undistortion AR camera motion estimation Áé∞Âú®Â≠òÂú®ÁöÑcalibrationÈÉΩÈúÄË¶ÅÂ§öÂº†ÂõæÁâáËøõË°åÊ†°ÂáÜÔºàchessboardÔºâ ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂÆåÂÖ®Ëá™Âä®ÁöÑÊ†áÂÆöÊñπÊ≥ïÔºåÂü∫‰∫éCNN Âú®ÁΩë‰∏äÊâæ‰∫ÜÈùûÂ∏∏Â§öÁöÑomnidirectionalÁöÑÂõæÁâáËøõË°åËÆ≠ÁªÉÔºåÁîüÊàê‰∫ÜÂÖ∑Êúâ100Â§ö‰∏áÂº†ÂõæÁâáÁöÑdataset Intro ÂπøËßíÁõ∏Êú∫ÁöÑcalibrationÊúÄÈáçË¶ÅÁöÑÊòØÊµãÈáè intrinsic parameters ‰∏§‰∏™wide FOVÁöÑÈáçË¶ÅÂèÇÊï∞Ôºöfocal length &amp; distortion parameter Áé∞Â≠òÁöÑcalibrationÊñπÊ≥ïÊúâÂæàÂ§öÈôêÂà∂Ôºö ÈúÄË¶Å‰∏Ä‰∏™objectÁöÑÂ§ö‰∏™ËßíÂ∫¶ÁöÑËßÇÂØü ÈúÄË¶ÅËßÇÂØü‰∏Ä‰∏™ÁâπÂÆöÁöÑstructures Âú®Â§öÂº†ÂõæÁâá‰∏≠ËßÇÂØüÁõ∏Êú∫ÁöÑÁßªÂä® Áé∞Âú®ÊúÄÊúâÂêçÁöÑÊñπÊ≥ïÊòØchessboard ‰ªñ‰ª¨ÊèêÂá∫ÁöÑÊñπÊ≥ïÂèØ‰ª•Ëß£ÂÜ≥‰∏äËø∞ÁöÑÈóÆÈ¢òÔºåÂπ∂‰∏îÈíàÂØπÁΩë‰∏ä‰∏ã‰∏ãÊù•ÁöÑÁÖßÁâá‰πüÂèØ‰ª•Áî® ‰∏ªË¶ÅÊñπÊ≥ï ‰∏Ä‰∏™CNN with Inception-V3 architecture ÁõÆÊ†á Êî∂ÈõÜÂÖ∑Êúâ‰∏çÂêåintrinsic parametersÁöÑÂõæÁâáÔºåÁÑ∂ÂêéËá™Âä®ÁîüÊàêÂÖ∑Êúâ‰∏çÂêåÁöÑfocal lengthÂíådistortionÁöÑÂõæÁâáÔºàÊ≤°ÊáÇÔºâ ÂØπÊØî‰∏çÂêåÁöÑCNNÁªìÊûÑ related work ‰ª•ÂâçÂ≠òÂú®ÁöÑcalibrationÊñπÊ≥ï‰∏ªË¶ÅÂèØ‰ª•ÂàÜÊàêÂõõ‰∏™‰∏çÂêåÁöÑÈÉ®ÂàÜ ÊúÄÂ∏∏‰ΩøÁî®ÁöÑÂ∞±ÊòØÊ£ãÁõò‰∏ÄÁ±ªÁöÑÔºåÈúÄË¶ÅËßÇÂØü‰∏ÄÂº†ÂõæÁâáÁöÑ‰∏çÂêåÈÉ®ÂàÜÔºå‰ªéËÄåÂæóÂà∞ÁªìÊûú„ÄÇÈóÆÈ¢ò‰∏ªË¶ÅÊòØÂá∫Âú®ÊØî‰ª∑È∫ªÁÉ¶ÔºåËÄå‰∏îÊó†Ê≥ïÂØπÈáéÁîüÁöÑÁÖßÁâáËøõË°åcalibration Âü∫‰∫éÂõæÁâá‰∏äÈù¢ÁöÑgeometric structureÔºålineÔºåÊ∂àÂ§±ÁöÑÁÇπÁ≠â„ÄÇ‰∏çËÉΩÂ§ÑÁêÜgeneral environments self-calibrationÔºàËá™Ë∫´ËøòÊúâ‰∏Ä‰∫õÂÆπÊòìÊî∂Âà∞ÂΩ±ÂìçÁöÑÈóÆÈ¢òÔºâ ÈúÄË¶ÅÂ§öÂº†ÂõæÁâá ÈúÄË¶Åcamera motion estimation Âü∫‰∫éDLÁöÑÔºå‰ΩÜÊòØÈÉΩÊòØËß£ÂÜ≥‰∫ÜÈÉ®ÂàÜÈóÆÈ¢ò Ê≤°ÊúâÊääÂèÇÊï∞ÂÖ®ÈÉΩ‰º∞ËÆ°Âá∫Êù• datasetÊòØ‰ªéprespectiveÁöÑÂõæÁâáÁîüÊàêÂõûÊù•ÁöÑÔºå‰ºöÊúâ‰∏çÂÆåÊï¥ÁöÑÈÉ®ÂàÜÔºà‰ΩÜÊòØ‰ªñ‰ª¨ÁöÑÂæàÂÆåÊï¥ËÄå‰∏î‰ºöÊúâÂæàÂ§öÂ∫îÁî®Ôºâ ApproachÈÄâÊã©model -&gt; Ëá™Âä®ÁîüÊàêlarge-scale dataset -&gt; networkÁöÑstructure Projection &amp; distrotion modelÔºàËÄÉËôëÁîüÊàêdatasetÁöÑÊú∫Âô®Ôºâ ÂπøËßíÁõ∏Êú∫ÈúÄË¶ÅÂÖ∑‰ΩìÁöÑprojection modelÊää3DÁöÑ‰∏ñÁïåmapÂà∞ÂõæÁâáÈáåÈù¢Âéª ËÄÉËôë‰∫ÜÂá†‰∏™model Brown-Conrady‚Äôs model(1971) Âú®ÂÆûÈôÖÂ∫îÁî®ÈáåÈù¢‰∏çÈÄÇÂêàÂπøËßíÁõ∏Êú∫ÁöÑÂ§ßÁöÑdistortion hardly reversible division model [Fitzgibbon 2001] Âè™ÊòØ‰∏∫‰∫ÜfisheyeËÆæËÆ°ÁöÑÔºåÂØπÁõ∏Êú∫Ê≤°ÊúâÊôÆÈÄÇÊÄß impossible to revert ËøôÁØáÊñáÁ´†ÈáåÈù¢ÁöÑmodel unified spherical model [Barreto 2006; Mei and Rives 2007] ÂéüÂõ† fully reversible ÂèØ‰ª•Ëß£ÂÜ≥ÂæàÂ§ßÁöÑdistortion projectionÂíåback-projectionÈÉΩadmit closed-form solution -&gt; ËÆ°ÁÆóÊïàÁéáÈùûÂ∏∏È´òÔºàÊ≤°ÊÄé‰πàÁúãÊáÇÔºâ generation dataset Âõ†‰∏∫Ê†πÊú¨ÂÅö‰∏çÂà∞Âπ∂‰∏îËøòÊ≤°ÊúâÈÇ£‰πàÂ§ßÁöÑdatasetÔºåÊâÄ‰ª•‰ªñ‰ª¨ÊâìÁÆó‰∫∫Â∑•ÂêàÊàê‰∏Ä‰∫õ(synthetically) Ê≤°ÊúâÈÄâÊã©Áî®prspectiveÁöÑÂõæÁâáÁîüÊàê Âú®ÊôÆÈÄöÁöÑÂõæÁâáÈáåÈù¢Âä†‰∏ädistortion‰ºöÊääÂõæÁâáÈáåÂ∫îËØ•Áúã‰∏çÂà∞ÁöÑÂú∞ÊñπÁúãÂà∞ÔºàËæπÁºòÈÉΩ‰ºöÂèòÊàêÈªëËâ≤ÁöÑÔºâ -&gt; ÁîüÊàêÁöÑÂõæÁâá‰∏çÁúüÂÆû ‰ΩøÁî®panoramasÂæóÂà∞ÂõæÁâá Âõ†‰∏∫ÂÖ®ÊôØÂõæÈÉΩÊòØ360Â∫¶ÁöÑÔºåÈÇ£‰πàÂ§öÂ∞ëÂ∫¶ÁöÑÂπøËßíÈÉΩËÉΩÈ©æÈ©≠ ÂèØ‰ª•ÂÅáËÆæÊääÁõ∏Êú∫ÊîæÂú®‰ªª‰ΩïÂú∞Êñπ ÂØπ‰∫éÁªôÁöÑ‰∏ÄÂº†ÂÖ®ÊôØÂõæÔºåÂèØ‰ª•Ëá™Âä®ÁîüÊàê‰∏çÂêåÁÑ¶Ë∑ùÔºå‰∏çÂêådistortionÁöÑÂõæÁâáÔºåËøôÊ†∑Â∞±ÂæóÂà∞‰∫ÜÂæàÂ§ßÁöÑdataset network architecture Inception-V3 structure Âü∫‰∫é‰∏äÈù¢ÁöÑÔºåÂÆûË∑µ‰∫Ü‰∏âÁßç‰∏çÂêåÁöÑÁΩëÁªú ‰∏ÄÂ±ÇÁΩëÁªúÔºåËæìÂá∫‰∏§‰∏™‰∏çÂêåÁöÑÁªìÊûúÔºå‰∏Ä‰∏™ÊòØf‰∏Ä‰∏™ÊòØdistortion DualNetÔºåÁî±‰∏§‰∏™Áã¨Á´ãÁΩëÁªúÁªÑÊàêÔºå‰∏Ä‰∏™ËæìÂá∫fÔºå‰∏Ä‰∏™ËæìÂá∫distortionÔºåËøô‰∏§‰∏™ÂÄºÊòØÁõ∏‰∫íÁã¨Á´ãÁöÑ„ÄÇ SeqNetÔºå‰∏§‰∏™ËøûÂú®‰∏ÄËµ∑ÁöÑÁΩëÁªúÔºåÂÖà‰ªéAÁΩëÁªúÈáåÂæóÂà∞fÔºåÂÜçÊääÂõæÁâáÂíåfÊîæËøõBÂæóÂà∞ÊúÄÁªàÁöÑdistortion Ëß£ÂÜ≥ÈóÆÈ¢òÔºö classification regression resultnetÁöÑÂèÇÊï∞ netÂú®imageNet‰∏äÈù¢pre-train‰∫ÜÔºåÁÑ∂ÂêéÂÜçËøõË°å‰∫ÜËøõ‰∏ÄÊ≠•ÁöÑËÆ≠ÁªÉ evaluationÂØπÊØî‰∏äÈù¢‰∏çÂêå‰∏â‰∏™ÁΩëÁªúÁöÑperformance user study‰º∞ËÆ°Âá∫Êù•ÁöÑÁªìÊûúÂæàÈöæËØ¥ÊòéÂà∞Â∫ïÊòØ‰∏çÊòØÊàêÂäüÁöÑundistort‰∫ÜÔºåÊâÄ‰ª•ËÆæËÆ°‰∫Üuser study Combining Multiple Depth Cameras and Projectors for Interactions On, Above, and Between SurfacesÔºà‚Äò2010ÔºâÊÑüËßâÁÆóÊòØÊØîËæÉÊúÄÊó©ÁöÑSARÁöÑÈÉ®ÂàÜÔºåÈáçÁÇπÂ∞±ÊòØÁî®Â§ö‰∏™ËßÜËßíÁöÑdepth cameraÊù•ÊçïÊçâÁî®Êà∑ÁöÑÂä®‰ΩúÔºåÂÆåÊàêÁõ∏Â∫îÁöÑ‰∫§‰∫íÔºå‰∏çÁü•ÈÅìÂú®Ê°åÂ≠ê‰∏äÁöÑÊäïÂΩ±ÂíåÂú®Â¢ô‰∏äÁöÑÊäïÂΩ±ÊòØÊÄé‰πàÂÆûÁé∞ÁöÑ abstract ÂèØ‰ª•‰∫§‰∫íÁöÑdisplaysÂíåsurface ÂèØ‰ª•ÊäïÂΩ±Âà∞ÈùûÂ∏∏ËßÑÁöÑÊäïÂΩ±Ë°®Èù¢‰∏äÈù¢Âéª ÂèØ‰ª•ÊääËøô‰∫õ‰∏úË•øÊâîÊù•ÊâîÂéªÔºå‰πãÁ±ªÁöÑ Intro the user may touch to manipulate a virtual object projected on an un-instrumented tableÔºàËøô‰∏™Áé∞Âú®Â∑≤Áªè‰∏çÊñ∞È≤ú‰∫ÜÔºâ office size room depth cameraÁöÑÂ¶ôÁî® Ëøô‰∏™Á©∫Èó¥ÁöÑ‰ªª‰ΩïÂú∞ÊñπÈÉΩÊòØsurfaceÔºåÈÉΩÂèØ‰ª•ÊäïÂΩ± Êï¥‰∏™Á©∫Èó¥ÊòØ‰∏Ä‰∏™Â§ßÁöÑÁîµËÑë ÂèØ‰ª•ÊäïÂΩ±Âà∞userËá™Â∑±ÁöÑË∫´‰∏äÂéª-&gt; ÂèØ‰ª•ÊäïÂΩ±Âà∞Áî®Êà∑ÁöÑÊâã‰∏ä 3D mesh data Á°¨‰ª∂ÊûÑÊàêÔºömultiplyÁöÑdepth camera&amp; projector ÊîØÊåÅÁöÑinteraction ÂèØ‰ª•‰∫§‰∫íÁöÑÈùûÊòæÁ§∫Âô®ÈÉ®ÂàÜÔºàÊØîÂ¶ÇÂ¢ôÂ£ÅÊàñËÄÖÊ°åÂ≠êÔºâ ÊâÄÊúâÁöÑÈÉ®ÂàÜÂèØ‰ª•ËøûÊé•Êàê‰∏Ä‰∏™ÂèØ‰∫§‰∫íÁöÑÈÉ®ÂàÜÔºåÂèØ‰ª•ÈÄöËøáËÇ¢‰ΩìÊù•ËøõË°å‰∏§‰∏™Â±èÂπï‰πãÈó¥ÁöÑ‰∫§‰∫íÔºàÂêåÊó∂Êë∏Ëøô‰∏§‰∏™‰∏úË•ø‰ªñÂ∞±‰ºöÊç¢‰ΩçÁΩÆÔºâ ÂèØ‰ª•‰ªédisplay‰∏äÈù¢pick upÂá∫‰∏úË•øÊù• Ê£ÄÊµãÂá∫Áî®Êà∑ÁöÑÂä®‰ΩúÊù•ÔºåÊîØÊåÅÂä®‰ΩúÁöÑ‰∫§‰∫í implement Âú®Â§©Ëä±Êùø‰∏äË£Ö‰∫Ü‰∏â‰∏™depth cameraÂíå‰∏â‰∏™projectorÔºåÂèØ‰ª•ÁúãÂà∞‰∫§‰∫íÁöÑÂú∞ÊñπÔºå‰∏çÈúÄË¶ÅÁâπÂà´Á≤æÂáÜÁöÑcalibration PrimeSense cameraÔºåÊúâIRÂíåRGBcamera depth imageÂèØ‰ª•Áî®Êù•ÂàÜÁ¶ªÈùôÊ≠¢ÁöÑÁâ©‰Ωì calibration both the cameras and the projectors are registered with the real world. camera a fixed grid of retro-reflective dots 3D camera pose estimation de- scribed by Horn[13] interactive space calibration‰πãÂêécameraÂ∞±ÂèØ‰ª•ÊçïÊçâreal timeÁöÑ3D mesh model Âõ†‰∏∫cameraÂíåprojector‰∏ÄËµ∑Ê†°ÂáÜËøá‰∫ÜÔºåÊâÄ‰ª•ÊäïÂΩ±Â∞±ÂèØ‰ª•Ê≠£Á°ÆÁöÑÊäïÂΩ±Âú®Áõ∏Â∫îÁöÑÂú∞Êñπ‰∫Ü Ê†πÊçÆmesh modelÂèØ‰ª•ÂæóÂà∞ÊâãÁöÑ‰∏âÁª¥ÂõæÂΩ¢ÔºåÊ†πÊçÆËøô‰∏™ÂõæÂΩ¢Â∞±ÂèØ‰ª•Áü•ÈÅìÊâãÂú®touchÂì™‰∏™Âú∞Êñπ‰∫Ü Âú®tracking‰∏äÈù¢Áî®‰∫ÜÊõ¥ÁÆÄÂçïÁöÑÁÆóÊ≥ïÔºö[28] [29] Áõ¥Êé•ÂØπ3DÁöÑmeshËøõË°åÊìç‰ΩúÊØîËæÉÂ§çÊùÇÔºåÊâÄ‰ª•ÂØπ2DÁöÑÁîªÈù¢ËøõË°å‰∫ÜÊìç‰Ωú virtual camera first transforming each point in every depth camera image from local camera to world coordinates, and then to virtual camera coordinates by virtual camera view and projection matrices. zÊñπÂêëÁöÑÂùêÊ†áÁî±xyÂÜôÂá∫Êù• -&gt; Êää‰∏ÄÂº†Ê∑±Â∫¶ÂõæÁâáÂéãÊàê‰∫Ü‰∏Ä‰∏™2DÁöÑÂõæÁâá ÁªìÂêàÂ§ö‰∏™ËßíÂ∫¶Âà§Êñ≠Áî®Êà∑ÁöÑÊúÄÁªàÂä®‰Ωú Áî®‰∏äÊñπÁöÑÊëÑÂÉèÊú∫ÁöÑÂõæÁâáÂà§Êñ≠Áî®Êà∑ÊòØ‰∏çÊòØÂêåÊó∂Êé•Ëß¶‰∏§‰∏™‰∏úË•ø‰∫Ü Á©∫Èó¥ÈáåÁöÑmene -&gt; Âú®ÁâπÊÆäÁöÑ‰∏Ä‰∏™Âú∞ÊñπÊúâÊäïÂΩ± RoomAlive: Magical Experiences Enabled by Scalable, Adaptive Projector-Camera Units(UIST ‚Äò14)ÊÑüËßâÊòØ‰∏Ä‰∏™ÊØîËæÉÂÆåÂÖ®ÁöÑÂ±ãÂÜÖÊäïÂΩ±ÁöÑ‰æãÂ≠ê‰∫Ü Abstract ÂèØ‰ª•Âä®ÊÄÅÁöÑÈÄÇÂ∫î‰ªª‰ΩïÁöÑÂ±ãÂ≠ê touch, shoot, stomp, dodge, steerÊäïÂΩ±‰∏äÂéªÁöÑ‰∏úË•øÔºå‰ª•ÂèäÂíåÁâ©ÁêÜÁöÑÁéØÂ¢É‰∫§‰∫í projector-depth camera unit -&gt; ÊâÄ‰ª•Â∞±‰∏çÈúÄË¶ÅÁâπÂà´Â§öÁöÑcalibrationÔºàÂèØ‰ª•ÈáçÁÇπÁúãÁúãËøô‰∏™unitÊòØÊÄé‰πàÂà∂‰ΩúÁöÑÔºâ Intro ÂÅö‰∫Ü‰∏Ä‰∏™Ê∏∏ÊàèÁ≥ªÁªü projectorÂíådepth camera‰∏Ä‰ΩìÁöÑ‰∏úË•ø cover the room‚Äôs walls and furniture with input/output pixels trackÁî®Êà∑ÁöÑÂä®‰ΩúÔºåÂπ∂‰∏îÊ†πÊçÆÂä®‰ΩúÂú®Â±ãÂ≠êÈáåÈù¢ÁîüÊàêÂØπÂ∫îÁöÑ‰∏úË•ø capture &amp; analyzeÂ±ãÂ≠êÈáåÁöÑÁªìÊûÑÔºåÂæóÂà∞ÊàøÈó¥ÈáåÈù¢ÁöÑÂ¢ô‰ª•ÂèäÂú∞Êùø‰πãÁ±ªÁöÑÁâπÂæÅ a distributed framework for tracking body movement and touch detection using optical-flow based particle tracking [4,15], and pointing using an infrared gun [19]. -&gt; ÂÖ∂ÂÆûËøò‰∏çÊòØÊ≤°Êúâ‰æùÊçÆËßÜËßâÊù•ÊçïÊçâËøô‰∏™‰∏úË•ø Â±ÖÁÑ∂Ë£Ö‰∫Ü6‰∏™Áõ∏Êú∫-ÊäïÂΩ±‰ª™ÁöÑunit ÔºàprocamÔºâ related workSpatial Augmented Reality (SAR) use light to change appearance physical objects illumiroom -&gt; ÈùûÂ∏∏ÂñúÊ¨¢Ëøô‰∏™idea projection mappingÂæàÂ§öÈÉΩÈúÄË¶ÅÂú®ÁâπÂÆöÁöÑ‰∏úË•ø‰∏äÈù¢mapping -&gt; ‰ΩÜÊòØËøô‰∏™ÂèØ‰ª•Âú®Êï¥Èó¥Â±ãÂ≠êÁöÑ‰ªªÊÑèÈÉ®ÂàÜmapping System unit -&gt; color camera + IR camera emitter + wide FOV projector + computer in a large living room (ËØ¥ÊòéËøôÁßçÁ†îÁ©∂ÈáåÈù¢Â±ãÂ≠êÁöÑÂ§ßÂ∞è‰πüÈùûÂ∏∏ÁöÑÈáçË¶Å) + 6 units plug-in to the Unity3D commercial game engine ÔºàÊÄ™‰∏çÂæóËÉΩÂÅöÊ∏∏Êàè Á°¨‰ª∂ wide field of view projectors ÊØè‰∏™ÈÉ®ÂàÜconnected to‰ªñËá™Â∑±ÁâπÂÆöÁöÑÁîµËÑë ÊâÄÊúâÁöÑÈÉ®ÂàÜÈÉΩË£ÖÂú®ÊàøÈó¥ÁöÑÂ±ãÈ°∂‰∏ä auto calibration Âπ∂‰∏çÈúÄË¶ÅcalibrationÊâÄÊúâÁöÑÁõ∏Êú∫ Âú®units‰πãÈó¥Êúâ‰∏ÄÈÉ®ÂàÜÁöÑoverlapÔºåÊâÄ‰ª•‰∏úË•øÂú®Ê†°ÂáÜÁöÑÊó∂ÂÄôËßÇÂØüÂêå‰∏Ä‰∏™‰∏úË•øÂ∞±Ë°å‰∫ÜÔºü Áî®opencvÁöÑÊ†°ÂáÜfunction chain togetherÊâÄÊúâÁöÑÈÉ®ÂàÜÁÑ∂ÂêéÂæóÂà∞‰∫ÜÂêÑ‰∏™Áõ∏Êú∫ÁöÑÂÖ≥Á≥ª auto scene analysis ÊâÄÊúâÁöÑunitÂæóÂà∞ÁöÑÊ∑±Â∫¶‰ø°ÊÅØÔºåÁîüÊàê‰πãÂêéÂØªÊâæËøûÁª≠ÁöÑÂπ≥Èù¢ÔºàÂ¢ôÔºåÂú∞ÊùøÁ≠âÁ≠âÔºâ Hough transformÔºàÂπ∂‰∏ç‰ºöËøô‰∏™‰∏úË•øÔºâ Ê∏∏Êàè unity3DÁöÑplug-in Ê∏∏ÊàèËÆæËÆ°ËÄÖÂè™ÈúÄË¶ÅÂú®ËÆæËÆ°ÁïåÈù¢ÈáåÊ∑ªÂä†‰∏úË•øÂ∞±Ë°å‰∫Ü mapping ‰∫ãÂÆûÊ∏≤ÊüìÊï¥‰∏™‰∏úË•øÁöÑ‰ªªÂä°Ê≤°ÊúâÂÆåÂÖ®Ëß£ÂÜ≥ 4‰∏™ÊäÄÊúØ content in a uniformly random way Âìà„ÄÇ„ÄÇ„ÄÇÂ±ÖÁÑ∂ÊòØÈöèÊú∫ÊäïÂΩ±Âá∫Êù•ÁöÑ ÈíàÂØπ‰∏çÂêåÁ±ªÂûãÁöÑË¢´ÊäïÂΩ±ÁöÑ‰∏úË•øÔºå‰ºöÊ†πÊçÆ‰∏çÂêåÁöÑÂéüÁêÜÂá∫Áé∞Âú®‰∏çÂêåÁöÑÂú∞ÊñπÔºàÊØîÂ¶ÇÁü≥Â§¥Âè™‰ºöÂá∫Áé∞Âú®Âú∞Èù¢‰∏äÔºâ ÊäïÂΩ±ÁöÑ‰∏úË•øÈíàÂØπÁî®Êà∑Áé∞Âú®ÁöÑ‰ΩçÁΩÆÔºåÂè™ÊäïÂú®Áî®Êà∑Ëá™Â∑±ÁúãÂæóÂà∞ÁöÑÂú∞Êñπ Âú®ÁßªÂä®Â±ãÂ≠êÈáåÁöÑÁâ©ÁêÜÁâ©ÂìÅÁöÑÊó∂ÂÄôÔºåÊîπÂèòÂ±ãÂ≠êÁöÑÈÉ®ÂàÜ tracking user interface body movement, touching, stomping, pointing/shooting and traditional controller input [4,15]ÊçïÊçâ‰∫Üdepth map -&gt; ‚Äòproxy particles‚Äô,Â∞±ÊòØÂä®‰ΩúÊ∏∏ÊàèÈáåÈù¢ÁöÑ‰ΩìÊÑüÊçïÊçâÁöÑÁÆóÊ≥ï -&gt; tracked by using a depth-aware optical flow algorithm gunÁöÑinputÈÄâÊã©‰∫ÜÁ∫¢Â§ñÊû™ ‰πüÊîØÊåÅÂØªÂ∏∏ÁöÑÊ∏∏ÊàèÊâãÊüÑ rendering RoomAlive tracks the player‚Äôs head position and renders all virtual content with a two-pass view dependent rendering ËøôÈÉ®ÂàÜ‰∏ªË¶ÅËÆ≤Ê∏∏ÊàèÊÄé‰πàËÆæËÆ°ÁöÑlimitation calibration errorsÔºÅËøôÊ†∑Âú®‰∫§Âè†ÁöÑÂú∞Êñπ‰ºöÂá∫Áé∞ÈáçÂΩ± system latency Âª∂ËøüQAQ Âú®overlapÁöÑsensors‰∏äÈù¢Ëß£ÂÜ≥tracking issues Peripheral Expansion of Depth Information via Layout Estimation with Fisheye Camera( ‚Äò16)‰ªéRGBDÈ±ºÁúºÁõ∏Êú∫ÊèêÂèñÊ∑±Â∫¶‰ø°ÊÅØÔºà‰ΩÜÊòØËøô‰∏™Áî®‰∫ÜÂ§ö‰∏™Áõ∏Êú∫ÁöÑsystemÔºâ abstract ‰∏Ä‰∏™ÊôÆÈÄöÁöÑRGBÁõ∏Êú∫Âíå‰∏Ä‰∏™fish eyeÔºåÊääËßÜËßíÊâ©Â±ïÂà∞‰∫Ü180¬∞ developed a new method to generate scaled layout hypotheses from relevant corners, combining the extraction of lines in the fisheye image and the depth information overcome severe occlusions. intro ‰∏ªË¶ÅÂ∞±ÊòØÊääÁé∞ÊúâÁöÑRGB fisheye cameraÂíåDepth cameraÁªìÂêàËµ∑Êù•ÔºåÂæóÂà∞È±ºÁúºÁöÑÊ∑±Â∫¶‰ø°ÊÅØ Pedestrian Detection in Fish-eye Images using Deep Learning: Combine Faster R-CNN with an effective Cutting Method(SPML ‚Äò18)Áî®È±ºÁúºÁõ∏Êú∫ÂíåRCNNÊù•Ê£ÄÊµãË°å‰∫∫ÔºàÊÑüËßâËøô‰∏™Ê£ÄÊµãÁöÑÁõÆÊ†áÊØîËæÉÂ∞èÔºâ -&gt; ÊÄé‰πàÊÑüËßâÊå∫Ê∞¥ÁöÑ abstract È±ºÁúºÁõ∏Êú∫ÁöÑËæπÁºòÊâ≠Êõ≤ÈóÆÈ¢ò -&gt; rotary cutting to solve the problem ÊääÁõ∏Êú∫ÂàÜÊàê‰∫ÜËæπÁºòÈÉ®ÂàÜÂíå‰∏≠Èó¥ÈÉ®ÂàÜ Method Ë£ÅÂâ™ÂõæÁâá ÁªïÁùÄÈ±ºÁúºÁõ∏Êú∫ÁöÑ‰∏≠ÂøÉÊóãËΩ¨Ôºå30Â∫¶Ôºå12Ê¨° ÊØèÊ¨°ÊóãËΩ¨ÂÆåÊà™Âèñ‰∏âÁªÑÂõæÁâáÔºåÂàÜÂà´ÊòØÈù†ËæπÁºòÁöÑÂíåÈù†‰∏≠ÂøÉÁöÑ -&gt; Êõ¥Â•ΩÊ£ÄÊµã‰∫∫Áæ§ÔºàÂûÇÁõ¥ÁöÑÔºâ ‰ΩøÁî®Ëøô‰∫õË£ÅÂâ™ÁöÑÂõæÁâátraining]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>projection mapping</tag>
        <tag>space augumented</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019 1Q ARÁ¨îËÆ∞]]></title>
    <url>%2F2019%2F04%2F09%2F2019Q1AR%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Êï¥‰ΩìÊ≠•È™§ Ê£ÄÊµãmarker ‰∏∫‰ªñËÆ°ÁÆóËÆ°ÁÆó6DOF pose render 3D ÂõæÁâá ÊääÂõæÁâáÂíåmarkerÁªÑÂêàÂú®‰∏ÄËµ∑ slidesÂ≠¶‰π†opengl(Â≠¶‰π†ËÄÅÂ∏àÁöÑcpp‰ª£Á†ÅÈ£éÊ†º) Ex1:Ê£ÄÊµãmarkerÁöÑÂõõ‰∏™Âü∫Á°ÄÁÇπÊâìÂºÄÁõ∏Êú∫ Ê≥®ÊÑèÂàùÂßãÂåñ videocapture Â∫îËØ•ÊòØÂú®whileÁöÑÂæ™ÁéØ‰πãÂâçÁöÑ thresholding ÂáΩÊï∞ cv::threshold(‚Ä¶) src dst thresÁöÑÂÄºÔºå‰πüÂ∞±ÊòØÈòàÂÄºÁöÑËæπÁïåÂÄº double maxvalÔºåÂú®ÊúÄÂêé‰∏Ä‰∏™ÂèÇÊï∞ÊòØbinaryÁöÑÊó∂ÂÄôÔºåÁ°ÆÂÆöbinaryÁöÑÊúÄÂ§ßÂÄº typeÔºå‰∫åÂÄºÂõæÔºåÂèç‰∫åÂÄºÂõæÔºå‰øùÁïôÂéüËâ≤Á≠â‰π±‰∏ÉÂÖ´Á≥üÁöÑ Ê≥®ÊÑèbinary‰πãÂâçË¶ÅÂÖà cvtcolorÂà∞ÁÅ∞Â∫¶ÂõæÔºÅÔºÅÔºÅ cv::adaptiveThreshold &lt;- ËØïËØïËøô‰∏™ÂáΩÊï∞ÁöÑ‰ΩúÁî®Ôºå‰∏çÁî®Ëá™Â∑±ËÆæÁΩÆthreshold‰∫Ü Âπ∂‰∏çÊÉ≥setËøô‰∫õhypers manully Èô§‰∫ÜÂØªÂ∏∏ÈúÄË¶ÅËÆæÁΩÆÁöÑ‰∏úË•ø‰πãÂ§ñÔºåËøòÈúÄË¶Å adaptiveMethod block sizeÔºàÈúÄË¶ÅË¢´Áî®Êù•ËÆ°ÁÆóthresholdÁöÑvalueÔºâ CÔºöÈúÄË¶ÅË¢´‰ªéÊï¥‰Ωì‰∏≠ÂáèÂéªÁöÑ‰∏Ä‰∏™constant Êúâ‰∫õÂèòÈáèÁöÑÂú∞ÊñπÁî®Âà∞‰∫Üconst &lt;- ÊÑüËßâÂ∫îËØ•Â≠¶Â≠¶ËÄÅÂ∏àÁöÑÁºñÁ®ãÈ£éÊ†ºdetect connected componentscv::findContours ÂáΩÊï∞ ÂõæÁâá contours vector&lt;std::vector&lt;cv::Point&gt; &gt; hierarchy vector&lt;cv::Vec4i&gt;ÔºåcontourÁöÑÊãìÊâëÂ≠¶‰ø°ÊÅØ mode ÔºàÊ≥®ÊÑèÂú®ËøôÈáåÈÄâÊã©Ë¶ÅÂ§ñËΩÆÂªìËøòÊòØÂÜÖÂ§ñÈÉΩË¶ÅÔºâ methodÔºö‰º∞ËÆ°contourÁöÑÊñπÊ≥ï offsetÔºàÂΩì‰ªéROIÊèêÂèñËΩÆÂªìÁÑ∂ÂêéÂú®Êï¥Âº†ÂõæÁâáÈáåÈù¢ÂàÜÊûêÁöÑÊÉÖÂÜµÔºâ ÂéªÈô§ËøáÂ∞èÁöÑcontour12345678910vector&lt;vector&lt;Point&gt;&gt; :: iterator itc = contours.begin(); while(itc != contours.end())&#123; if(itc -&gt; size() &lt; 60)&#123; itc = contours.erase(itc); &#125; else&#123; itc++; &#125; &#125; ËÄÅÂ∏àÁöÑ‰ª£Á†ÅÈáåÈù¢ÊòØÂÖàËøõË°å‰∫Ü‰º∞ËÆ°ÔºåËÆ°ÁÆó‰∫ÜboundÁöÑÈù¢ÁßØÔºåÁÑ∂ÂêéÊ†πÊçÆ Èù¢ÁßØÂ§ßÂ∞èÔºåÂç†Êï¥Âº†ÂõæÁâáÁöÑÁôæÂàÜÊØî Âá†‰∏™Ëßí cv::isContourConvex ÔºöÊ£ÄÊü•Ëøô‰∏™markerÁöÑÂá∏ÊÄßÔºåÊØïÁ´üÂΩ¢Áä∂‰∏çËÉΩÊòØÂáπÁöÑÔºåÁõ¥Êé•ËæìÂÖ•Ëøô‰∏™Â§öËæπÂΩ¢ÁöÑarrayÔºåËæìÂá∫ÁöÑÂ∞±ÊòØbool ‰º∞ËÆ°contourÁöÑÂ§öËæπÂΩ¢ approxPolyDP Ë¢´‰º∞ËÆ°ÁöÑcontour ‰º∞ËÆ°Âá∫Êù•ÁöÑÁöÑÂ§öËæπÂΩ¢ ‰º∞ËÆ°ÁöÑÂèÇÊï∞ÔºåÂΩ±Âìç‰º∞ËÆ°ÁöÑÁ≤æÂ∫¶ -&gt; const auto epsilon = 0.05 * cv::arcLength(contour, true); ËÆ°ÁÆó‰∏Ä‰∏™curveÁöÑÈïøÂ∫¶ closedÔºå‰º∞ËÆ°Âá∫Êù•ÁöÑÂ§öËæπÂΩ¢ÊòØ‰∏çÊòØÂ∞ÅÈó≠ÁöÑ ÁîªÂá∫Êù•Âè™ÊúâÂõõ‰∏™ËßíÁöÑÂ§öËæπÂΩ¢ drawContours() ÂõæÁâá ÈúÄË¶ÅÁîªÁöÑËΩÆÂªìs ÔºàÊ≥®ÊÑèËøôÊòØËøôÂº†ÂõæÁâáÈáåÈù¢ÁöÑÊâÄÊúâËΩÆÂªìÔºâ ÈúÄË¶ÅÁîªÁöÑindex thickness Á∫øÁöÑ Á∫øÂæóÁßçÁ±ª Optional information about hierarchy. maxLevel Maximal level for drawn contours. If it is 0, only the specified contour is drawn. If it is 1, the function draws the contour(s) and all the nested contours. If it is 2, the function draws the contours, all the nested contours, all the nested-to-nested contours, and so on. This parameter is only taken into account when there is hierarchy available. offsetÔºöÂèØÈÄâ ËÄÅÂ∏àÁî®ÁöÑÊñπÊ≥ïÊòØËÆ°ÁÆó‰∫ÜÂêÑ‰∏™ÁÇπÂíåËÆ°ÁÆó‰∫ÜÂêÑ‰∏™ËæπÔºåÊâÄ‰ª•ÂèØ‰ª•ÁîªÂá∫Êù•Ëæπ‰∏äËøòÊúâÂ•ΩÂ§öÁÇπÁöÑÁªìÊûú ‰∏ÄÁßçÁ•ûÂ•áÁöÑÂÆö‰πâÈ¢úËâ≤ÁöÑÊñπÂºèÔºåÁõ¥Êé•ÈöèÊú∫Âá∫Êù• const cv::Scalar kEdgeColor(rand() &amp; 255, rand() &amp; 255, rand() &amp; 255); -&gt; ËøôÊ†∑ÁöÑËØùÂá∫Êù•ÁöÑÊØè‰∏ÄÂ∏ßÁöÑÊ°ÜÁöÑÈ¢úËâ≤ÈÉΩ‰ºöÊîπÂèò![] Áî®cv::polylinesÊù•ÁîªÂá∫Êù•polysÁöÑcurveÔºåÂπ∂‰∏îË¶ÅÁîªclosedÁöÑ ÁîªÂá∫Êù•ÂõæÁâáÁöÑdelimiters(‰∏∫‰∏ã‰∏ÄÊ≠•ÂÅöÂáÜÂ§á) ÁõÆÁöÑÔºö‰ªé‰∏Ä‰∏™cornerÂà∞Âè¶‰∏Ä‰∏™cornerÁöÑÊñπÂêëvector Ê≠•È™§ È¶ñÂÖàÂú®corner‰∏äÈù¢Áî®circleÁîªÂá∫Êù• Ê£ÄÊü•ÊØè‰∏™edge ÊØè‰∏™edge‰∏äÊúâ6‰∏™ÁÇπÔºåÁÑ∂ÂêéËÆ°ÁÆó‰∏§‰∏™corner‰πãÈó¥ÁöÑdxÂíådyÁöÑÊñπÂêëÔºåÈô§‰ª•ÈÉ®ÂàÜÁöÑÊï∞ÈáèÔºà7ÔºâÂ∞±ÊòØÊØè‰∏™Â∞èÂùóÁöÑÊñπÂêëÔºåÁÑ∂ÂêéÊääËøô‰∏™Â∞èÂùóÈáçÂ§ç6Ê¨°12const double dx = (double)(contour_approx[(i+1)%kNumOfCorners].x-contour_approx[i].x)/(double)(kNumOfEdgePoints+1);const double dy = (double)(contour_approx[(i+1)%kNumOfCorners].y-contour_approx[i].y)/(double)(kNumOfEdgePoints+1); Á¨¨‰∏ÄÈÉ®ÂàÜÁªìÊùüÂêéÁöÑÂÆåÊï¥‰ª£Á†Å1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#include "ARdetection.hpp"ARDetection::ARDetection(void)&#123; &#125;Mat ARDetection:: SearchMarkers(Mat frame)&#123; Mat img_gray; Mat dst; // threshold‰πãÂâçË¶ÅÂÖàÊîπÊàêÁÅ∞Â∫¶Âõæ cvtColor(frame, img_gray, CV_BGR2GRAY); adaptiveThreshold(img_gray, dst, 255, ADAPTIVE_THRESH_MEAN_C, THRESH_BINARY, 33, 5);// threshold(img_gray, dst, 104, 255, THRESH_BINARY); imshow("lalala", dst); waitKey(1); // ÊØè‰∏™ÁÇπÔºå‰∏ÄÂúàÁÇπ‰∫ãÊòØ‰∏Ä‰∏™contourÔºå‰∏ÄÂ†Ükcontours vector&lt;vector&lt;Point&gt;&gt; contours; vector&lt;Vec4i&gt; hierarchy; findContours(dst, contours, hierarchy, RETR_LIST , CHAIN_APPROX_NONE); // Ê£ÄÊµãÂõæÁâáËøáÂ∞èÈÉ®ÂàÜ// vector&lt;vector&lt;Point&gt;&gt; :: iterator itc = contours.begin();//// while(itc != contours.end())&#123;// if(itc -&gt; size() &lt; 60)&#123;// itc = contours.erase(itc);// &#125;// else&#123;// itc++;// &#125;// &#125; vector&lt;vector&lt;Point&gt;&gt; polys(contours.size()); for(int i=0; i &lt; contours.size(); i++ )&#123; // Ê†πÊçÆÊØè‰∏™ËΩÆÂªìË∞ÉËäÇËøô‰∏™ÂèÇÊï∞ÁöÑÂ§ßÂ∞è const auto epsilon = 0.05*cv::arcLength(contours[i], true); approxPolyDP(contours[i], polys[i], epsilon, true); // if(polys[i].size() == 4)&#123;//// Áî®Ëøô‰∏™ÂáΩÊï∞Áîª‰∏çÂá∫Êù•ÊñúÁöÑ‰∏úË•ø//// rectangle(frame, polys[i][0],polys[i][2], Scalar(0,255,0));// drawContours(frame, polys, i, Scalar(255,0,0), 5, 8, vector&lt;Vec4i&gt;(), 0, Point());// &#125; Rect rect = boundingRect(polys[i]); const int marker_size = rect.area(); const int ImageSize = img_gray.cols * img_gray.rows; const int marker_size_min = int(ImageSize * 0.02); const int marker_size_max = int(ImageSize * 0.95); const int marker_corners_num = 4; const bool is_vaild = (marker_size &gt; marker_size_min) &amp;&amp; (marker_size &lt; marker_size_max) &amp;&amp; (polys[i].size() == marker_corners_num) &amp;&amp; isContourConvex(polys[i]); if (is_vaild == false) continue; // ËøôÊ†∑ÁîªÂá∫Êù•ÁöÑÊòØÈöèÊú∫ÁöÑÈ¢úËâ≤ÁöÑ const Scalar EdgeColor(rand() &amp; 255, rand() &amp; 255, rand() &amp; 255); polylines(frame, polys[i], true, EdgeColor,5); // ‰∏ãÈù¢ÈúÄË¶ÅÊääÊØè‰∏™ËæπÂàÜÊàê6‰∏™ÈÉ®ÂàÜ for(int j = 0; j &lt; marker_corners_num; ++j)&#123; const int edge_point_num = 6; const int circle_size = 5; circle(frame, polys[i][j], circle_size, Scalar(0,255,0),FILLED); const double dx = (double)(polys[i][(j+1)%marker_corners_num].x - polys[i][j].x)/(double)(edge_point_num + 1); const double dy = (double)(polys[i][(j+1)%marker_corners_num].y - polys[i][j].y)/(double)(edge_point_num + 1); for(int k = 0; k&lt; edge_point_num; ++k)&#123; const double edge_point_x = (double)(polys[i][j].x) + (double)(k+1)*dx; const double edge_point_y = (double)(polys[i][j].y) + (double)(k+1)*dy; Point edge_point((int)edge_point_x,(int)edge_point_y); circle(frame, edge_point, circle_size, Scalar(0,0,255),-1); &#125; &#125; &#125; return frame;&#125; Á¨¨‰∏ÄÈÉ®ÂàÜËøêË°å‰πãÂêéÁöÑÁªìÊûú Ex2. find marker precisely Áé∞Âú®ÊúâcornerÔºåcorner‰πãÈó¥ÁöÑlineÔºåËøô‰∏™lineËøòË¢´ÂàÜÊàê6‰∏™ÈÉ®ÂàÜÔºà~Âõ†‰∏∫Â§ßÂ∞èÊòØ6x6ÔºüÁöÑ= ‰∏§‰∏™Ëæπ + ‰∏≠Èó¥Âõõ‰∏™Ê†ºÔºüÔºü~Ôºâ ÂÖâÊ£ÄÊµãËæπÁºòÊòØ‰∏çÂ§üÁöÑÔºåÊÉ≥Áü•ÈÅìËøô‰∏™ËæπÁºòÂÆûÈôÖÊòØ‰ªÄ‰πàÊ†∑Â≠êÁöÑ Áé∞Âú®Âè™Áü•ÈÅìËôöÁ∫øÁöÑÈÉ®ÂàÜÊòØ‰ªÄ‰πàÊ†∑Â≠êÁöÑ Âπ∂‰∏îÁé∞Âú®Â∑≤ÁªèÊääÊØè‰∏™ËæπÈÉΩÂàÜÈÉ®ÂàÜ‰∫Ü -&gt; ÁîªÂá∫Êù•ÂûÇÁõ¥ÁöÑÂàÜÂùóÁöÑÁ∫øÔºåÊâæÂà∞Ëøô‰∏™Á∫øÂíåÈ¢úËâ≤Á™ÅÂèòÁöÑ‰∫§ÁÇπÔºåÈáçÊñ∞ÁîªÂá∫Êù•Êñ∞ÁöÑÁ∫øÔºàÂÆûÁ∫øÔºâ Â∏åÊúõÊâæÂà∞È¢úËâ≤Á™ÅÂèòÁöÑÂú∞Êñπ ‰ΩÜÊòØÂÆûÈôÖ‰∏äÁöÑÈ¢úËâ≤‰∏çÊòØÁ™ÅÂèòÁöÑÔºåÊòØÁôΩ -&gt; ÁÅ∞ -&gt; Èªë Êìç‰ΩúÊ≠•È™§ È¢ÑÂáÜÂ§á Âú®ÊØè‰∏™sideÊâæÂÖ≠‰∏™ÁÇπ Âú®Ëæπ‰∏äÊèêÂèñ‰∏â‰∏™ÂÉèÁ¥†ÂÆΩÂ∫¶ÁöÑstride cv::GetQuadrangleSubPix() -&gt; ‰∏ç‰ºöÁî®ÔºÅ ‰ªéËæìÂÖ•ÁöÑarrayÂæóÂà∞ÂõõËæπÂΩ¢ srcËæìÂÖ•ÂõæÂÉè dstÊèêÂèñÂá∫Êù•ÁöÑÂõõËæπÂΩ¢ ÂèòÊç¢ÁöÑÁü©Èòµ Sober operator ÂõæÂÉèÂ§ÑÁêÜÈáåÈù¢ÁöÑÂ∏∏Áî®ÁÆóÂ≠ê -&gt; ‰∏ªË¶ÅÁî®‰∫éËæπÁºòÊ£ÄÊµãÔºåÁî®Êù•ËøêÁÆó‰∏éÁÅ∞Â∫¶ÁöÑÁõ∏‰ººÂÄº ÂåÖÂê´‰∏§ÁªÑ3x3ÁöÑÁü©ÈòµÔºå‰∏≠Èó¥ÁöÑ3x1ÁöÑ0ÔºåÂàÜÂà´‰∏∫Ê®™ÂêëÂíåÁ∫µÂêëÔºåÂè¶Â§ñ‰∏§Èù¢ÂØπÁß∞ ÁÑ∂Âêé‰∏éÂõæÁâáÂÅöÂç∑ÁßØÔºåÂàÜÂà´ËÆ°ÁÆóxÊñπÂêëÂíåyÊñπÂêëÁöÑÁÅ∞Â∫¶ÂÄº ÁÑ∂ÂêéÊääGxÂíåGyÊ±ÇÂπ≥ÊñπÂíåÁöÑÊ†πÔºåÊúÄÂêéÂæóÂá∫Êù•Ëøô‰∏™ÂÉèÁ¥†ÁÇπÁöÑÁÅ∞Â∫¶ÂÄºÔºàÊàñËÄÖÊúâÁöÑÊó∂ÂÄô‰πüÂèØ‰ª•Áî®ÁªùÂØπÂÄºÊù•ËÆ°ÁÆóÔºåËøôÊ†∑ËÆ°ÁÆóÁöÑÊ∂àËÄóÂ∞è‰∏ÄÁÇπÔºâ Ê≠•È™§ Âú®ÊØè‰∏™stripeÈáåÊâæÂà∞ÊúÄÈ´òÁöÑchange ÂØπËøô‰∏™changeÂíåÂ•πÂë®Âõ¥ÁöÑÁÇπÔºàÂú®ÂéüÊù•ÁöÑÊõ≤Á∫ø‰∏äÔºâÔºåÊâæÂà∞‰∏Ä‰∏™Êñ∞ÁöÑ‰∫åÊ¨°Êõ≤Á∫ø ÊâæÂà∞Ëøô‰∏™Êõ≤Á∫øÁöÑÈ°∂ÁÇπÔºà‰∏ÄÈò∂ÂØºÊï∞Ôºâ Â¶Ç‰ΩïÂæóÂà∞ÂõæÁâáÁöÑsubpixel color‰∏çÊòØÂéüÊù•ÁöÑÊñπÊñπÊ≠£Ê≠£ÁöÑÔºåËÄåÊòØÊ≤øÁùÄÈÇ£‰∏™Áõ¥Á∫øÊñπÂêëÁöÑÊñ∞ÁöÑÊñπÊñπÊ≠£Ê≠£ Â∞±ÊòØÂèñÂêÑ‰∏™È¢úËâ≤Âú®Èù¢ÁßØ‰∏äÁöÑÂπ≥ÂùáÔºå ËÄÅÂ∏àÁöÑ‰ª£Á†Å sublixSampleSafe -&gt; Ëøô‰∏™ÂáΩÊï∞ËæìÂÖ•ÊµãËØïÁöÑÂõæÁâáÔºàgrayÂíåÂ∑≤ÁªèÂæóÂà∞ÁöÑsubpixÁÇπ ÊääËøô‰∏™ÁÇπÊ±ÇfloorÔºåintÔºåÂæóÂà∞Âü∫ÂáÜÁÇπÔºåÁÑ∂ÂêéÊ£ÄÊü•ÊòØ‰∏çÊòØÂú®ÂõæÁâáÈáåÈù¢Ôºà‰∏çÊòØÁöÑËØùËøîÂõûgrayÔºå127Ôºâ Â¶ÇÊûúÂú®ÂõæÁâáÈáåÈù¢ÁöÑËØùËÆ°ÁÆóÂá∫Êù•ÂÆûÈôÖÁöÑÂùêÊ†á Á°ÆÂÆömarkerÁöÑid corner detection exact sides ÊâæÂà∞Ê≤øÁùÄÂàöÊâçËÆ°ÁÆóÂá∫Êù•6‰∏™ÁÇπÁöÑ‰∏ÄÊù°Á∫øfitLine precise corner ‰ªéÂêÑ‰∏™ËæπÁöÑ‰∫§ÁÇπËÆ°ÁÆóÁ≤æÁ°ÆÁöÑcornerÔºàÂõ†‰∏∫ÂêÑ‰∏™ËæπÂ∑≤ÁªèÂæàÁ≤æÁ°Æ‰∫ÜÔºâ Marker Rectification ÂàõÂª∫‰∏Ä‰∏™6x6 pixÁöÑIDÂõæÁâá (-0.5,-0.5) to (5.5,5.5) ‰ªéÂéüÂõæÁâáÁöÑperspective warpÂà∞Id image cv::getPerspectiveTransform or cv::warpPerspective ÈúÄË¶ÅÊâæÂà∞ÁöÑÊòØlinear transformation]]></content>
      <categories>
        <category>AR</category>
        <category>‰∏äËØæÁ¨îËÆ∞</category>
      </categories>
      <tags>
        <tag>AR</tag>
        <tag>OpenCV</tag>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Notes for papers about smart kitchen]]></title>
    <url>%2F2019%2F04%2F08%2Fkitchen%2F</url>
    <content type="text"><![CDATA[Choptop: An Interactive Chopping Board2018 abstract ‰∏Ä‰∏™ÂèØ‰∫§‰∫íÁöÑÊ°àÊùø ÂèØ‰ª•ÁªôÁî®Êà∑ËèúË∞±ÁöÑÊåáÂØºÔºåÊâøÈáçÔºåËÆ°Êó∂ Áî®Êà∑ÂèØ‰ª•ÈÄöËøáÊåâÊ°àÊùøÊù•ËøõË°åÂØπÁîªÈù¢ÁöÑÊìç‰Ωú ‰∏äÈù¢Â∞±ÊòØÈïøÊàê‰∏äÂõæÁöÑÊ†∑Â≠êÔºåÊ°àÊùøÂ∫ï‰∏ãÂÖÖÊª°‰∫ÜÂêÑÁßç‰º†ÊÑüÂô®„ÄÇ Intro ÈíàÂØπÂ≠¶Áîü‰∏ç‰ºöËá™Â∑±ÂÅöÈ•≠Ôºå‰∏çÂêÉÊñ∞È≤úÁöÑÈ•≠ÁöÑÈóÆÈ¢òÔºåÁº∫Êó∂Èó¥ -&gt; ‰∏ÄÊ≠•‰∏ÄÊ≠•ÁöÑÊääÊÄé‰πàÂÅöÈ•≠ÂÜôÂá∫Êù•‰∫ÜÔºåÂåÖÊã¨ÂõæÁâáÂä®ÁîªÁ≠â‰∏úË•ø built-in timerÁî®Êù•ÊØè‰∏ÄÊ≠•ËÆ°Êó∂ ‰ΩøÁî®mobile deviceÊù•ÊèêÈ´òËèúÂçïÁöÑ‰∫§‰∫íÊÄß ËÄÉËôëÂà∞ÊâãÁöÑËÑèÁ≠âÈóÆÈ¢òÔºåÊâÄ‰ª•‰∏çÊòØÊåâÂ±èÂπïËÄåÊòØÊåâÊ°àÊùøÔºàËøôÈáåËÄÉËôëËÉΩ‰∏çËÉΩÂÉèpac pac‰∏ÄÊ†∑ÔºåÁî®ÊâãÂäøÊìç‰ΩúÔºâ load sensorsÔºåÂèØ‰ª•Ëß£ÂÜ≥Áß∞ÈáçÁöÑÈóÆÈ¢ò ÊÄùË∑Ø ‰∏ªË¶ÅÁõÆÁöÑÊòØ‰∏ÄÁßçÊñ∞ÁöÑÂ≠¶‰π†ÂÅöÈ•≠ÁöÑÊñπÊ≥ï Ôºà‰Ωú‰∏∫ÂÅöÈ•≠ÊúâÂ§©ËµãÁöÑ‰∫∫ÔºåÊàëËÆ§‰∏∫ËøôÊ†∑Ê≤°ÊúâÁÅµÈ≠ÇÔºÅÔºâ related work smart kitchen Research has aimed to improve the cook- ing process, promote healthier eating and make it simpler to procure ingredientsÔºåÂ§ßÂÆ∂ÈÉΩ‰ªé‰∏çÂêåÁöÑËßíÂ∫¶ÂÆûÁé∞Êô∫ËÉΩÂé®Êàø ‰ªñËøô‰∏™ËÆ∫ÊñáÁöÑ‰∏úË•øÊàêÊú¨‰∏çÊòØÁâπÂà´È´ò‰πü‰∏çÊòØÁâπÂà´Â§ßÔºàÊòØÂú®Âò≤ËÆΩÊàëÂêóÔºâ load sensing ‰πãÂâçÂ∑≤ÁªèÁî®‰∫ÜÂæàÂ§öforceÁöÑ‰º†ÊÑüÂô® ‰πãÂâç‰πüÊúâÁî®ËøáÂ∏¶ÈáçÈáè‰º†ÊÑüÂô®ÁöÑÊ°àÊùøÔºå‰ª•ÂèäÂ∏¶Êâ≠Áü©‰º†ÊÑüÂô®ÁöÑÂàÄ[9] ‰ªñ‰ª¨ËÆ§‰∏∫cameraÊ≤°Êúâ‰ªÄ‰πàÁî®ÔºåÂπ∂‰∏îÊääÊâÄÊúâÁöÑÁ°¨‰ª∂ÈÉΩËóèËµ∑Êù•‰∫Ü Ë£ÖËøô‰∏™senserÁöÑÊñπÊ≥ïÂèÇËÄÉ‰∫Ü[12] DesignÁ°¨‰ª∂ Êï¥‰∏™Á°¨‰ª∂ÊòØself-containedÁöÑ Â±èÂπïÊòØÂçïÁâáÊú∫ÊéßÂà∂ÁöÑ ÂäõÈáè‰º†ÊÑüÁ≥ªÁî® Ê£ÄÊµãÊåâÂéãÁî®ÁöÑÊòØedge detection -&gt; Èò≤Ê≠¢Ê£ÄÊµãÂà∞ÂÖ∂‰ªñ‰∏úË•øÔºàÂéüÁêÜ‰∏çÊòØÂ§™ÊáÇÔºâ UI The interface updates based on the information delivered from the recognition engine ÊàêÂäü‰πãÂêéËøò‰ºöÊúâÂ£∞Èü≥ ÊåâÊ°àÊùøÁöÑ‰∏çÂêåÈÉ®ÂàÜÂ∞±ÂèØ‰ª•ÂæÄ‰∏çÂêåÁöÑÊñπÂêëÁßªÂä® user study Êâæ‰∫ÜÂçÅ‰∏â‰∏™‰∫∫ÔºåÂáÜÂ§á‰∏ÄÈÅìÊ≤ôÊãâ [3]ÈáåÈù¢ÊâæÂà∞‰∫Ü‰∏Ä‰∏™Ë∞ÉÊü•ÈóÆÂç∑System Usability Scale future SVMËÆ≠ÁªÉ‰∫Ü74%ÁöÑÊµãËØïÁéáÔºàÂ•Ω‰ΩéÔºâÔºåÊèêÈ´òÊ≠£Á°ÆÁéá ÊèêÈ´òËá™Âä®ÁøªÈ°µÔºàÔºü Áî®Áî®Êà∑ÁöÑÊâãÊú∫Êù•ËææÂà∞Â±èÂπïÁöÑ‰ΩúÁî® Ëøõ‰∏ÄÊ≠•ÂàÜuser study CookTab: Smart cutting board for creating recipe with real-time feedback2012 abstract ËÄÉËôëÂà∞ÂæàÂ§öÂé®Â∏àÂÅöÈ•≠ÈöèÂøÉÊâÄÊ¨≤ÔºåËÄå‰∏î‰∏ç‰ºöËÆ∞ÂΩï‰∏ãÊù•Á≤æÂáÜÁöÑÁî®Èáè ‰∏Ä‰∏™ÂèØ‰ª•ËÆ∞ÂΩï‰∏ãÊù•Áî®ÈáèÁöÑÊ°àÊùø intro ‰∏ìÈó®ÈíàÂØπÂàáËèúÈÉ®ÂàÜÁöÑËÆ∞ÂΩïÁöÑËΩØ‰ª∂ ËÆ∞ÂΩïÁî®ÁöÑÊùêÊñôÁöÑÂêçÂ≠óÔºåËèúÈáèÔºåËßÜÈ¢ëÂíåË∞ÉÂë≥ÊñπÊ≥ïÔºåÁÑ∂Âêé‰ºöÊúâreal-timeÁöÑfeedback related work [3]ÂèØ‰ª•ËÆ∞ÂΩïËßÜÈ¢ëÔºåÂ£∞Èü≥ÔºåÁî®ÁöÑcameraÂíåmic Âä†ÈáçÈáèÊÑüÂ∫îÁöÑÔºå [2]Âõõ‰∏™ÊâøÈáçÁöÑÊ®°ÂùóÔºåÂä†ÈÄüÂ∫¶‰º†ÂÆâÁê™ ‰ΩÜÊòØ‰ªñ‰ª¨ÁöÑÁ≥ªÁªü‰ºöÊúâreal-timeÁöÑfeedback ‰∏çÂ•ΩÊÑèÊÄùÂ•ΩÂÉèÂ∞±ÊòØÂú®pad‰∏äÂàáËèú Enabling Nutrition-Aware Cooking in a Smart KitchenCHI 2007ÔºàÂ§ßÊ¶ÇÂè™ËÉΩÁúã‰∏™Ê¶ÇÂøµ‰∫ÜÔºâ abstract ÁõÆÊ†áÔºöhealth cookingÔºàÊòØ‰∏çÊòØÂ§ßÂÆ∂ÁöÑÁõÆÊ†áÈÉΩÊòØÈÇ£‰πà‰ºüÂ§ßÔºâ sensorsÔºådetect cooking activities, and digtail feedback intro ‰∏ªË¶ÅÁõÆÊ†áÂ∞±ÊòØÂ¶ÇÊûú‰∫∫Âä†‰∏úË•øÂÅáÁöÑËøáÈáè‰∫ÜÊàñËÄÖÊÄé‰πàÁùÄÔºåÂ∞±‰ºöÊèêÈÜí Smart Kitchens for People with Cognitive Impairments: A Qualitative Study of Design RequirementsCHI-2018]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>Smart Kitchen</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫émacÊ∂àÂéªÂàÜÂå∫]]></title>
    <url>%2F2019%2F04%2F08%2F%E5%85%B3%E4%BA%8Emac%E6%B6%88%E5%8E%BB%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[ÊúÄËøëÂàöÊé•Êâã‰∫ÜÂà´‰∫∫ÁöÑmbpÔºå‰ªñÂõ†‰∏∫Ë£ÖÂèåÁ≥ªÁªüÂàÜÂå∫‰πãÂêéÔºåwindowsÂàÜÂå∫Êó†Ê≥ïÊ∂àÂéª„ÄÇËØï‰∫Ü‰∏ÄÂúà‰πãÂêéÂèëÁé∞Âè™Ë¶ÅÂÜçÊñ∞Âª∫‰∏Ä‰∏™ÂàÜÂå∫ÔºåÁÑ∂ÂêéÂÜç‰∏ÄËµ∑ÂêàÂπ∂Â∞±ÂèØ‰ª•‰∫Ü„ÄÇ]]></content>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫éPythonÁöÑÂ≠óÂÖ∏Â§ökeyÔºåvalueËøîÂõûkey]]></title>
    <url>%2F2019%2F04%2F05%2F%E5%85%B3%E4%BA%8EPython%E7%9A%84%E5%AD%97%E5%85%B8%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF%2F</url>
    <content type="text"><![CDATA[Â§ö‰∏™keys1dict = &#123;(key11,key12): value&#125; Â§ßÊ¶ÇÂ∞±ÊòØÈïøËøô‰∏™Ê†∑Â≠êÁöÑÔºåkeyÁöÑ‰∏™Êï∞Â§öÂ∞ëÊ≤°ÊúâÈôêÂà∂ÔºåËÆøÈóÆvalueÁöÑÊó∂ÂÄô1dict[(key11,key12)] Â§ö‰∏™value1dict = &#123;key1:(value1, value2)&#125; ËÆøÈóÆÁöÑÊó∂ÂÄôÂ§ßÊ¶ÇÂ∞±ÊòØËøô‰πàÂèñÂÄº12dict[key]dict[key][index] ‰ªévalueÊâæÂà∞key ÂÖàÈÄöËøálist(dict.key())Ëé∑ÂæóÊâÄÊúâÁöÑkeyÔºåÂèòÊàê‰∏Ä‰∏™list list(dict.value())ÂæóÂà∞ÊâÄÊúâÁöÑvalueÁöÑlist ‰∏äÈù¢Ëøô‰∏§‰∏™listÁöÑindexÁõ∏ÂêåÔºåÂÖàËé∑ÂèñvalueÁöÑindexÔºåÁÑ∂ÂêéÂÜç‰Ωú‰∏∫keyÁöÑindexÂéªkeyÈáåÊâæ ‰æãÂ≠êÔºö12dict = &#123;'a': 1, 'b': 2&#125;list(dict.key())[list(dict.value()).index('1')]]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Â≠óÂÖ∏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Human Computer InteractionÁ¨îËÆ∞]]></title>
    <url>%2F2019%2F04%2F04%2FHCI%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Introduction 50% Âá∫Âã§Âíå 50% report koikeÊ£ÆÊ£ÆËøòÊúâassignment History 1945 Vannevar Bush memexÁöÑÊ¶ÇÂøµÔºå‰∫åÊàòÊú´ÊèêÂá∫‰∫Ü‰∏ÄÁßç‰ø°ÊÅØÊú∫Âô®ÁöÑËÆæÊÉ≥Ôºà‰∏™‰∫∫Âõæ‰π¶È¶ÜÔºâ ËøôÁßçÊú∫Âô®ÂÜÖÈÉ®Áî®ÂæÆÁº©ËÉ∂Âç∑ÔºàmicrofilmÔºâÂ≠òÂÇ®‰ø°ÊÅØÔºå‰πüÂ∞±ÊòØËá™Âä®ÁøªÊãçÔºåÂèØ‰ª•‰∏çÊñ≠ÂæÄÈáåÈù¢Ê∑ªÂä†Êñ∞ÁöÑ‰ø°ÊÅØÔºõÊ°åÈù¢‰∏äÊúâÈòÖËØªÂ±èÔºåÁî®Êù•ÊîæÂ§ßÈòÖËØªÂæÆÁº©ËÉ∂Âç∑ÔºõËøòÊúâËÆ∏Â§ö‰∏™ÊåâÈíÆÔºåÊØè‰∏Ä‰∏™ÊåâÈíÆ‰ª£Ë°®‰∏Ä‰∏™‰∏ªÈ¢òÔºåÂè™Ë¶ÅÊåâ‰∏Ä‰∏ãÔºåÁõ∏Â∫îÁöÑÂæÆÁº©ËÉ∂Âç∑Â∞±‰ºöÊòæÁ§∫Âá∫Êù•„ÄÇÊØè‰∏Ä‰∏™ËÉ∂Âç∑ÂÜÖÈÉ®ËøòËÆ∞ÂΩïÁùÄÁõ∏ÂÖ≥ÁöÑÂÖ∂‰ªñËÉ∂Âç∑ÁöÑÁºñÂè∑ÔºåÂèØ‰ª•Êñπ‰æøÂú∞ÂàáÊç¢ÔºåÂΩ¢ÊàêÂêå‰∏ªÈ¢òÈòÖËØª„ÄÇÂú®BushÂçöÂ£´ÁöÑËÆæÊÉ≥‰∏≠ÔºåËøôÁßçÊú∫Âô®ËøòÂèØ‰ª•‰∏éÂõæ‰π¶È¶ÜËÅîÁΩë„ÄÇÈÄöËøáÊüêÁßçÊú∫Âà∂ÔºåÂ∞ÜÂõæ‰π¶È¶ÜÊî∂ËóèÁöÑËÉ∂Âç∑ÔºåËá™Âä®Ë£ÖËΩΩÂà∞Êú¨Âú∞Êú∫Âô®‰∏ä„ÄÇÂõ†Ê≠§ÔºåÂè™ÈÄöËøáËøô‰∏Ä‰∏™Êú∫Âô®ÔºåÂ∞±ÂèØ‰ª•ÂÆûÁé∞Êµ∑ÈáèÁöÑ‰ø°ÊÅØÊ£ÄÁ¥¢„ÄÇfrom ÁôæÂ∫¶ÁôæÁßë as we may thinkÔºöÂêåÊó∂ÊèêÂá∫‰∫ÜwearableÁîµËÑë 1946 Eniac Á¨¨‰∏Ä‰∏™ËÆ°ÁÆóÊú∫ Ê≤°ÊúâkeyboardÂíådisplayÔºåÂè™ËÉΩÊâãÂä® 1951 UNIVAC ÂèØ‰ª•I/O ÂÖàÂú®Á∫∏Êù°‰∏äÊâìÂ≠îÔºåÁÑ∂ÂêéÂÜçÊîæËøõÂéªËØª Ivan Sutherland 1963 SketchPadÔºådisplay‰∏äÈù¢ÊúâÂõæÂÉè‰∫ÜÔºåÂπ∂‰∏îÂèØ‰ª•ÂØπÁîªÈù¢ËøõË°åÊìç‰Ωú ÂèØ‰ª•Áî®ÂÖâÁ¨îÊìç‰ΩúÔºå‰∏çÊòØÁî®ÈîÆÁõòÊìç‰Ωú‰∫Ü CADÈºªÁ•ñ Á¨¨‰∏Ä‰∏™VRËÆæÂ§áÂ±ÖÁÑ∂‰πüÊòØ‰ªñÂÅöÂá∫Êù•ÁöÑ Sword of Damocles(1968) Douglas Engelbart Â±ÖÁÑ∂Âá∫Áé∞‰∫ÜÈº†Ê†áÔºåË£Ö‰∫Ürotatory wheelsÔºàÁ´ñÁùÄÁöÑÈÇ£ÁßçÔºâÔºåÂèØ‰ª•Âú®‰∏§‰∏™ÊñπÂêëÁßªÂä®ÔºàÊâÄ‰ª•Ë£Ö‰∫Ü‰∏§‰∏™ÂêóÔºüÔºâ Alan Kay PC‰πãÁà∂ 1972 DynabookÔºåcard boardÂÅöÁöÑÔºåÂõ†‰∏∫CPUÂíåGPuÂ§™Â§ß‰∫ÜÔºåÂ±èÂπï‰πüÊ≤°ÊúâÔºåÂπ∂‰∏çÊòØÁúüÁöÑ 1996Âπ¥‰∏úËäùÂÅö‰∫Ü‰∏™Âè´Ëøô‰∏™ÂêçÂ≠óÁöÑPC 1973 Xerox Alto real working machine 1981 Xerox Star Âá∫Áé∞‰∫ÜÊ°åÈù¢Á≥ªÁªü GUI Ted Nelson Hypertext Editing System -&gt; pen to jumo to another page Steve Jobs &amp; Bill Atkinson HyperCard 1987ÔºåÂêåÁ±ªÁöÑ‰ø°ÊÅØÈÉΩÂú®Âêå‰∏ÄÂº†Âç°‰∏äÔºåÁÑ∂ÂêéÊâÄ‰ª•ÁöÑÂç°ÈÉΩËøûÂú®‰∏ÄËµ∑ÔºåÂèØ‰ª•Âú®Âç°‰∏≠Èó¥jump„ÄÇ‰∫ãÊÉÖÂ∞±ÂèòÂæóÈùûÂ∏∏ÁÆÄÂçï‰∫Ü Tim Berners-Lee father of WWW ÔºàWorld Wide WebÔºâ Richard Bold put that thereÂèØ‰ª•Áî®ÊâãÂäø‰∫§‰∫íÔºåËØ≠Ë®Ä‰∫§‰∫í ÈùûÂ∏∏Â§ßÁöÑ‰∏Ä‰∏™displayÂíåprojector Mark Weiser father of the concept of Ubiquitous conputing(1991) È¢ÑË®Ä‰∫Ü‰ª•ÂêéÂ§ßÂÆ∂ÂÆ∂ÂÆ∂ÊúâÁîµËÑë Jaron Lanier VPL data glove &amp; HMD 1989ÔºåÊâãÂ•óÈáåÈù¢ÊúâÁ∫§Áª¥ I/OÁöÑÁ°¨‰ª∂Â¶Ç‰ΩïÁªÑÂêà -&gt; Êñ∞ÁöÑHCIÊñπÂºè design &amp; evaluationACM SIGCHI What‚Äôs HCI CS design ÊòØ‰∏Ä‰∏™‰∫§ÂèâÂ≠¶Áßë Â≠¶‰ºö CHI -&gt; Êõ¥Ê≥®ÈáçÊÉ≥Ê≥ïÔºåÂíåËΩ¨ÂåñÊàêÂÆûÁé∞ UIST -&gt; Êõ¥Ê≥®Èáçimplement IEEE/ACM Ubicomp CSCM ÈáçË¶ÅÊÄß ‰øùËØÅÂÆâÂÖ®ÊÄßÔºåÊèêÂçáÁîüÊ¥ªË¥®Èáè Âú®ÂïÜ‰∏ö‰∏äÁöÑ‰∫ßÂìÅÂåñ Êé®Ëçê‰π¶ The Design of Everyday things Ê†∏ÂøÉÊÄùÊÉ≥Affordence: ‰∫∫ÊÉ≥Ë±°ÁöÑËøô‰∏™‰∏úË•øÁöÑÁî®ÈÄîÂíåÂÆûÈôÖÁöÑÁî®ÈÄîÔºåËÆ©Áî®Êà∑ÁúãÂà∞Ëøô‰∏™‰∏úË•øÂ∞±Áü•ÈÅìÊòØÂπ≤‰ªÄ‰πàÁî®ÁöÑ ÊØîÂ¶ÇÂÇªÂ±åÁöÑÁúãËßÅÊåâÈîÆ‰∏çÁü•ÈÅìÊåâÂì™‰∏™ÁöÑÁì¶ÊñØÁÇâ ÊñπÂêë‰∏çÂêåÁöÑËΩ¶Â∫ßÈù†ËÉåË∞ÉËäÇ Ê†πÊú¨‰∏çÁü•ÈÅìÂì™‰∏™ÊòØÂì™‰∏™ÁöÑÁîµÁÅØÂºÄÂÖ≥ ÊÉ≥Ê≥ï mapping ui to real layout design is stupid ‰∏É‰∏™ÂáÜÂàô by Norman 8 golden rules by. Shneiderman consistencyÔºà‰∏ÄËá¥ÊÄßÔºâ -&gt; ÊØîÂ¶ÇmacÁöÑpull downÊúÄ‰∏ãÈù¢ÈÉΩÊòØquitÔºåÂ§ßÂÆ∂ÁöÑ‰ΩçÁΩÆÈÉΩÂ∑Æ‰∏çÂ§ö Short-term memory ÊØîÂ¶ÇËèúÂçïÈáåÈù¢ÁöÑ‰∏™Êï∞ 7+-2 magic number Bringing Design to software T.Winograd GUI &amp; hypermediaGUI CUI -&gt; GUI CUI: I: keyboard O: charracters in display GUI I: keyboard + mouse O: bitmap in display desktop like a real office emvironment (metaphor) document,folder,trash ÂØπ‰∫éÊ≤°ÊúâÁî®ËøáÁîµËÑëÁöÑ‰∫∫Êù•ËØ¥ÈùûÂ∏∏ÂÆπÊòìÁêÜËß£ visualizing to icons operating mouse JobsÂ±ÖÁÑ∂copy‰∫ÜËøô‰∏™‰∏úË•ø Ë∑üÁé∞Âú®ÁöÑ‰πüÊ≤°ÊúâÂ§™Â§öÊ¶ÇÂøµÔºàstandard interface for computer) pros visual by iconÔºåÂõ†‰∏∫ËßÜËßâÁúãÂá∫Êù•ÁöÑ‰∏úË•øÊØîËæÉÂ•ΩÁêÜËß£ direct manipulation interaction abstract by folders cons number of icons make user confused more computing more physical space typing is faster with keyboard ÂÖ∂‰ªñÁöÑ‰∏Ä‰∫õÊÉ≥Ê≥ï room metaphor[henderson86] different romms for different task multiply desk (Â∞±ÂÉèmbpÁöÑÂ§ö‰∏™Ê°åÈù¢‰∏ÄÊ†∑) based on user studys &lt;- how they use each applications Âπ∂Ê≤°ÊúâÂèòÊàê‰∏ªÊµÅÔºåÂì≠Âì≠ Ë∂ÖÊï¥ÁêÜÊ≥ï super-organizing metaphor Â¶Ç‰ΩïÊï¥ÁêÜÁâ©ÁêÜÊñá‰ª∂ organize by time, not name sequentially, not hierarchically implemented by Freeman -&gt; Lifestream GUIÁöÑ‰∏Ä‰∏™ÁâπÂæÅWIMPwindow, icon, menu, pointerÔºàlike mouseÔºâ Êï¥‰ΩìÊù•Áúã ËãπÊûúÊääpull downÂú®Â∑¶‰∏äËßíÔºåÂõ†‰∏∫‰ªéÂ∑¶ÂæÄÂè≥ÊãâÊØîËæÉÂÆπÊòì windows: Âõ†‰∏∫‰∏çÊÉ≥Âíåapple‰∏ÄÊ†∑ÊâÄ‰ª•ÊâîÂà∞Â∫ï‰∏ã‰∫Ü difficult for icon ÊØîÂ¶ÇË∑Ø‰∏äÁöÑÊ†áÂøóËÆæËÆ°ÁöÑÂ∞±ÂæàËø∑ÔºåÂ§ßÂÆ∂ÈÉΩ‰∏çÁü•ÈÅìÊòØÂπ≤Âï•ÁöÑ direct manipulation ÊØîÂ¶ÇÂú®Âà†Èô§‰∏úË•øÁöÑÊó∂ÂÄôCHIÈúÄË¶ÅËá™Â∑±ËæìÂÖ•Ôºå‰ΩÜÊòØGUIÂèØ‰ª•Áõ¥Êé•ÊãñËøõtrashÈáåÈù¢ WYSIWYGwhat you see is what you get PUI?I: recognizationO: large/ small displays PUI(perceptual)GUI -&gt; PUI PUI: using various input(sensors) GUI: mouse&amp; keyboard, not intuitive vision-based HCIwhy? natural &amp; intuitive? not special device, unwired multimodel application recognition detection &amp; recognition object &lt;-(detect) - object detection system(find the thing in the real world) object database &lt;-recognition- objection recognition system(know what it is) detect the hand colorsÔºàshapes?Ôºâ infrared camera near infrared -&gt; vedio cameras(capture near infrared light to the object) far infrared -&gt; capture the heat hand location(ÊâãÊåáÂú®Âì™ÔºåÊâãÂú®Âì™) hand regions find the centre -&gt; morphlogical operation fingers -&gt; pattern matching(ÊúâÂæàÂ§ö‰∏çÂêåÁöÑÊñπÊ≥ï) tracking gesture recognition difficult segmentation of hands/body -&gt; depth camera recognition of 3D pose(occlusion) Â¶ÇÊûúÁî®Êà∑ËΩ¨Ë∫´‰∫ÜÔºåÊâã‰ºöË¢´ÂÖ∂‰ªñÁöÑ‰∏úË•øÊå°‰Ωè detecting begin/end of gestures ‰∏Ä‰∏™ÈùûÂ∏∏ÈáçË¶ÅÁöÑÈóÆÈ¢òÔºÅ high-speed gestures (systems) pacÔºÅpacÔºÅ as many hands as possible advantages robust against light conditions real-time with 40 people with 2 hands No instruction necessary 3D gestures(for navigation in VR) 2 cameras recognise hand shapes pattern classification(NN) object recognition tag-based pre-registration of objects difficult to attached on something(unbralla, glove‚Ä¶) unnartual overlook based on color information(‚Äò1991) 3D histogram(RGB) translation/rotation invariant(Â¶ÇÊûúÂõæÁâáÊîπÂèò‰∫ÜÊñπÂêëÊàñËÄÖÂèò‰∫ÜÔºå‰ΩÜÊòØÈ¢úËâ≤‰ø°ÊÅØËøòÊ≤°Âèò) ‰ΩÜÊòØÈ¢úËâ≤Áõ∏‰ººÁöÑÊó∂ÂÄôÊ≤°Ê≥ïÂàÜËæ® PTAM(‚Äò2007) recgonize feature positions features &amp; markers gaze recognition infrared cameras &amp; LEDs pattern matching corners of eyes,mouse,shaping triangle -&gt; face direction 4/18interactive surface ‰æãÂ≠ê handheld:phone, tablet horizantal: desk vertical: wall digital desk(‚Äò93) overhead projector + camera + desk metaDesk(‚Äò97) -&gt; Áî®‰∏§‰∏™Â•áÊÄ™ÁöÑÊñπÂùóÔºåÂØπËøô‰∏™mapËøõË°åÊìç‰Ωú LCD tabletop LCD -&gt; larger, thinner,lighter,higher resolusion, less expensive before that use projectors(dark) use as window? real glass is expensive then LCD principles of polarization Êª§ÂÖâÂêóÔºå‰∏§‰∏™ÊñπÂêëÁöÑÔºàÂÅèÊåØÁâáÔºâ ËøôÊ†∑ÂèØ‰ª•Áî®Êù•Ê£ÄÊµãÊâãÔºåÊääÊâã‰πãÂêéÁöÑËÉåÊôØÂÖâÊª§Êéâ ÈùûÂ∏∏Â•ΩÁî® ÂèØ‰ª•Áî®Êù•Ê£ÄÊµãÊâã AR markerËøôÊ†∑ÁöÑ‰∏úË•øÂÆûÂú®ÊòØÂ§™‰∏ë‰∫Ü design invisiable markers ÊääÂÅèÊåØÂÖâÁâáÂáèÊàê‰∫Üar markerÁöÑÊ†∑Â≠êÔºå‰∫∫Áúã‰∏çÂà∞‰ΩÜÊòØÊú∫Âô®ÂèØ‰ª•ËØÜÂà´ background &amp; motivation traditional surfaces are planar &amp; regid difficult to make 3D surface photoelasricity -&gt; ÈÄèÊòéÁöÑÊùêÊñôÂØπ‰∏çÂêåËΩΩËç∑‰∏ãÈ¢úËâ≤‰∏çÂêå -&gt; ‰πüÂèØ‰ª•Áî®Êù•‰Ωú‰∏∫ÂΩ±ÂìçÂÅèÊåØÂÖâÁöÑÂõ†Á¥†ÔºåÂèØ‰ª•Áî®Êù•ÊåâÔºåÊåâ‰∏ãÂéªÂÖâÂ∞±ËÉΩËøáÂéªÊÉπ electrical shock ‰∏∫‰ªÄ‰πà‰ºöÊúâËøôÁßçÁîµ‰∫∫ÁöÑdisplayÂïäÔºÅÔºàBIRIBIRIÔºâ beyond 2D surfaceCaytrick surface(‚Äò18)4/22 information visualizationÊõ¥Âø´ÔºåÊõ¥Á≤æÂáÜÁöÑÁêÜËß£info(shape/ colors -&gt; information) SciVis &amp; InfoVis Sci Áî®Êà∑ÊØîËæÉ‰∏ì‰∏ö Áî®Êù•ÁêÜËß£‰∏ì‰∏öÁöÑÁé∞Ë±° physical data, measured data, simulation data Info abstract data Áªô‰∫∫Ê∞ëÁæ§‰ºóÁúãÁöÑÔºåÊÑüËßâÊõ¥Âä†Áõ¥ËßÇ how to layout the data three issues scalability Â¶ÇÊûúÊàë‰ª¨ÊÉ≥Ë¶Åvis infoÔºåÂ¶ÇÊûúdataÁöÑÈáèÂ§™Â§ß‰∫ÜÔºåÊúâ‰∫õ‰∏úË•øÁúãËµ∑Êù•Â∞±ÂæàÂ§çÊùÇ(eg.trees) limited display size human cant understand tech layout scalability filiter layout graph drawing Â•ΩÁúãÔºåeconomicallyÔºàÂ§öÁ∫ßÂåñÁöÑÔºå‰∏≠ÂøÉËæêÂ∞ÑÔºåÂºïÂäõÂûã -&gt; ‰∏çÂêåÂÖ≥Á≥ªÁöÑÁõ∏Êñ•ÔºåÂúÜÁéØÁä∂Ôºâ tree structure TreeMap 5/9 Cognitive processwhy important ÁúãÂà∞ÁöÑ‰∏ç‰∏ÄÂÆöÂ∞±ÊòØÁúüÂÆûÁöÑ ÈÄöËøáÊîπÂèòHCIÔºåÂèØ‰ª•ÊîπÂèòÁúãÂà∞ÁöÑ‰∏úË•øÁöÑ Seven Stage Model]]></content>
      <categories>
        <category>HCI</category>
        <category>‰∏äËØæÁ¨îËÆ∞</category>
      </categories>
      <tags>
        <tag>HCI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XcodeÁöÑbreakpoint1.1ÈóÆÈ¢ò‰ª•ÂèäÊâìÂºÄÊëÑÂÉèÂ§¥]]></title>
    <url>%2F2019%2F04%2F04%2FXcodebreakpoint%2F</url>
    <content type="text"><![CDATA[ÊúÄËøë‰∏äËØæÂèàË¶ÅÊç°Ëµ∑Êù•c++‰∫ÜÔºåÂçäÂπ¥ÂâçÊâçÊç¢ÁöÑmacÁî®xcodeÊ≤°vsÈ°∫ÊâãÔºåÂ•ΩÂá†Ê¨°ÈÅáÂà∞‰∫ÜÊå∫Á•ûÂ•áÁöÑÈîôËØØ„ÄÇ thread 1 breakpoint 1.1Ëøô‰∏™ÈóÆÈ¢òÂÖ∂ÂÆûÂ∞±ÊòØ‰Ω†Âú®‰ª£Á†ÅÈáåÈù¢Ëá™Â∑±Âä†‰∏ä‰∫ÜÊñ≠ÁÇπ(breakpoint)Ôºå‰º∞ËÆ°ÊòØ‰∏çÂ∞èÂøÉÁÇπÂà∞ÁöÑ„ÄÇÂèñÊ∂à‰∫ÜÊñ≠ÁÇπÂ∞±Ë°å ÂÖ≥‰∫éXcodeÂÖÅËÆ∏Áõ∏Êú∫xcodeÁöÑÁõ∏Êú∫ËÆ∏ÂèØÊàë‰πãÂâçÊäòËÖæ‰∫Ü‰∏Ä‰∏™‰∏ãÂçàÊâçÂèëÁé∞ÊÄé‰πàÊêû„ÄÇ È¶ñÂÖàÔºåÈúÄË¶ÅÊúâ‰∏Ä‰∏™ÂÖÅËÆ∏Áõ∏Êú∫ÁöÑInfo.plistÊñá‰ª∂ÔºåÊñá‰ª∂ÂÜÖÂÆπÂ¶Ç‰∏ã 1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;&lt;plist version="1.0"&gt;&lt;dict&gt;&lt;key&gt;NSCameraUsageDescription&lt;/key&gt;&lt;string&gt;Used to capture new image for photo effect&lt;/string&gt;&lt;key&gt;CFBundleName&lt;/key&gt;&lt;string&gt;$&#123;OPENCV_APPLE_BUNDLE_NAME&#125;&lt;/string&gt;&lt;key&gt;CFBundleIdentifier&lt;/key&gt;&lt;string&gt;$&#123;OPENCV_APPLE_BUNDLE_ID&#125;&lt;/string&gt;&lt;key&gt;CFBundleVersion&lt;/key&gt;&lt;string&gt;$&#123;OPENCV_LIBVERSION&#125;&lt;/string&gt;&lt;key&gt;CFBundleShortVersionString&lt;/key&gt;&lt;string&gt;$&#123;OPENCV_LIBVERSION&#125;&lt;/string&gt;&lt;key&gt;CFBundleSignature&lt;/key&gt;&lt;string&gt;????&lt;/string&gt;&lt;key&gt;CFBundlePackageType&lt;/key&gt;&lt;string&gt;FMWK&lt;/string&gt;&lt;/dict&gt;&lt;/plist&gt; ÂÖ∂‰∏≠ÔºåNSCameraUsageDescriptionËøôÈÉ®ÂàÜÂ∞±ÊòØÊâìÂºÄÁõ∏Êú∫ÁöÑËÆ∏ÂèØ„ÄÇ ‰ΩÜÊòØËøô‰∏™Êñá‰ª∂Áõ¥Êé•ÊîæÂú®È°πÁõÆÈáåÊòØ‰∏çË°åÁöÑÔºåÈúÄË¶ÅÂ§çÂà∂‰∏ãÊù•ÔºåÊâìÂºÄproductsÁöÑË∑ØÂæÑÔºåÁÑ∂ÂêéÂ§çÂà∂Âà∞Ëøô‰∏™Ë∑ØÂæÑÈáåÈù¢ÔºåÊâçÂèØ‰ª•ÊàêÂäüÁöÑÊâìÂºÄÁõ∏Êú∫]]></content>
      <categories>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>Xcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫éSVMÁöÑÁêÜËß£]]></title>
    <url>%2F2019%2F04%2F03%2F%E5%85%B3%E4%BA%8ESVM%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Êú¨ÊñáÂèÇËÄÉÊîØÊåÅÂêëÈáèÊú∫ÈÄö‰øóÂØºËÆ∫ÂÜÖÂÆπ SVMÂà∞Â∫ïÊòØÂï•support vecttor machineÔºåÊØîÂ¶ÇÂú®‰∫åÁª¥Âπ≥Èù¢‰∏äÔºåË¶ÅÊää‰∏Ä‰∏™‰∏úË•øÂàÜÊàê‰∏§Á±ªÔºåSVMÂ∞±ÊòØÂπ≥Èù¢‰∏äÁöÑ‰∏ÄÊù°Áõ¥Á∫øÔºåÂπ∂‰∏îÂú®Ëøô‰∏§Á±ªÁöÑÊ≠£‰∏≠Èó¥ÔºåÁ¶ª‰∏§Ëæπ‰∏ÄÊ†∑Ëøú„ÄÇÊç¢Âè•ËØùËØ¥ÔºåÂ≠¶‰π†Á≠ñÁï•ÊòØÊääÈó¥ÈöîÊúÄÂ§ßÂåñÔºå‰ªéËÄåÂæóÂà∞Âá∏‰∫åÊ¨°ËßÑÂàíÈóÆÈ¢òÁöÑËß£ÔºàËôΩÁÑ∂‰∏çÊòØÂæàÁêÜËß£Ôºå‰ΩÜÊòØÂá∏ÈóÆÈ¢òÂ∫îËØ•ÊòØÊØîËæÉÂ•ΩÊ±ÇËß£Ôºâ ÂàÜÁ±ªÊ†áÂáÜ logistic regression Á∫øÊÄßÂàÜÁ±ªÂô®ÔºöxË°®Á§∫Êï∞ÊçÆÔºåyË°®Á§∫Á±ªÂà´ÔºåÂàÜÁ±ªÂô®ÂàôÈúÄË¶ÅÂú®nÁª¥ÊâæÂà∞‰∏Ä‰∏™Ë∂ÖÂπ≥Èù¢hyper planeÔºåË∂ÖÂπ≥Èù¢ÁöÑÊñπÁ®ãÂ∞±ÊòØW.T ‰πüÂ∞±ÊòØ W.T.dot(x) + b = 0 (‰ª§‰∫∫ÈúáÊÉäwÂ±ÖÁÑ∂ÊòØË∂ÖÂπ≥Èù¢ÁöÑÊñπÁ®ã) ÈÄªËæëÂõûÂΩí ÈÄªËæëÂõûÂΩíÂ∞±ÊòØ‰ªéÁâπÂæÅÈáåÈù¢Â≠¶Âà∞‰∏Ä‰∏™0/1ÁöÑÂàÜÁ±ªÊ®°Âûã Ê®°ÂûãÁöÑÁ∫øÊÄßÁªÑÂêà‰Ωú‰∏∫Ëá™ÂèòÈáèÔºåÂèñÂÄºËåÉÂõ¥ÊòØË¥üÊó†Á©∑Âà∞Ê≠£Êó†Á©∑ÔºåÊâÄ‰ª•‰ΩøÁî®logisticÂáΩÊï∞ÔºàÁ´üÁÑ∂Â∞±ÊòØsimoidÂáΩÊï∞Êää‰ªñ‰ª¨ÊäïÂΩ±Âà∞Ôºà0Ôºå1Ôºâ‰∏äÈù¢ÔºåÂæóÂà∞ÁöÑÂÄºÂ∞±ÊòØy = 1ÁöÑÊ¶ÇÁéá Á∫øÊÄßÂàÜÁ±ªÂô®Â¶ÇÊûúÊääÂàÜÁ±ªÁöÑ‰∏§Á±ªÊîπÊàê -1Âíå1ÔºàÂè™ÊòØ‰∏∫‰∫ÜÊñπ‰æøÈÄâ‰∫ÜËøô‰∏™Êï∞Â≠óÔºâÔºåÂÖ∂ÂÆûÂ∞±ÊòØÊääwxÂä†‰∫Üb ËøôÊó∂ÂÄôÁöÑÁÇπÁöÑ‰ΩçÁΩÆÂèØ‰ª•Áî® f(x) = wx + bË°®Á§∫ÔºåÂ¶ÇÊûúf(x)Á≠â‰∫é0ÔºåÈÇ£‰πàËøô‰∏™ÁÇπÂú®Ë∂ÖÂπ≥Èù¢‰∏äÔºåÂ¶ÇÊûúÂ§ß‰∫é0Â∞±ÊòØÂú®1ÁöÑÁ±ªÂûãÈáåÔºåÂ∞è‰∫é0Âú®-1ÁöÑÁ±ªÂûãÈáå ËøôÊó∂ÂÄôÈóÆÈ¢òÂèòÊàê‰∫ÜÂØªÊâæÈó¥ÈöîÊúÄÂ§ßÁöÑË∂ÖÂπ≥Èù¢ function marginÔºågeometrical marginÂáΩÊï∞Ë∑ùÁ¶ª ÂΩìÂπ≥Èù¢‰∏äÁöÑÁÇπÊòØ wx+b = 0 Á°ÆÂÆö‰∫Ü‰ª•ÂêéÔºå wx+bÁöÑÁªùÂØπÂÄºÂ∞±ÊòØÁÇπxÂà∞Ë∂ÖÂπ≥Èù¢ÁöÑË∑ùÁ¶ª ÂêåÊó∂ wx+b ÁöÑÁ¨¶Âè∑Âíå yÔºàÂàÜÁ±ªÊ†áÁ≠æÔºâÁöÑÁ¨¶Âè∑ÂØπÊØîÔºåÂ¶ÇÊûú‰∏ÄËá¥ÁöÑËØùÊòØ‰∏Ä‰∏™Á±ªÂà´Ôºå‰∏ç‰∏ÄËá¥ÁöÑËØùÊòØÂè¶‰∏Ä‰∏™ -&gt; y(wx+ b)ÁöÑÊ≠£Ë¥üÊù•Ë°®Á§∫ÂàÜÁ±ªÁöÑÊ≠£Á°Æ‰∏éÂê¶ Ôºà‰πüÂ∞±ÊòØ‰∏§‰∏™‰∏úË•øÂêåÂè∑ÂæóÊ≠£ÂàÜÁ±ªÊ≠£Á°ÆÔºâ ÂºïÂá∫ÂáΩÊï∞Èó¥ÈöîÁöÑÂÆö‰πâÔºàËøôÈáåÁöÑyÊòØ‰πò‰∏äÂØπÂ∫îÁ±ªÂà´ÁöÑyÔºåÊâÄ‰ª•ËÉΩÂæóÂà∞ÁªùÂØπÂÄºÔºâ Âú®ËÆ≠ÁªÉÈõÜ‰∏≠ÔºåÊâÄÊúâÁÇπÂà∞Ë∂ÖÂπ≥Èù¢ÁöÑË∑ùÁ¶ªÁöÑÊúÄÂ∞èÁÇπÂ∞±ÊòØfunction margin Âá†‰ΩïË∑ùÁ¶ª ‰ΩÜÊòØÂ¶ÇÊûúÂçïÁ∫ØËøô‰πàËØÑÂÆöÔºåÂΩìwÂíåbÊàêÊØî‰æãÊîπÂèòÁöÑÊó∂ÂÄôÔºåÂáΩÊï∞Èó¥Èöî‰πü‰ºöÊîπÂèòÔºåÊâÄ‰ª•ËøòÈúÄË¶ÅÂá†‰ΩïÈó¥Èöî‰∏äÈù¢ÁöÑÂºèÂ≠ê‰πò‰ª•yÔºàÂØπÂ∫îÁ±ªÂà´ÁöÑÊ†áÁ≠æÔºâÂ∞±ÂèØ‰ª•ÂæóÂà∞ÁªùÂØπÂÄº‰∫Ü„ÄÇ ‰πüÂ∞±ÊòØËØ¥Âá†‰ΩïmarginÁöÑ‰∏ªË¶ÅÈÉ®ÂàÜÂ∞±ÊòØÊää‰πãÂâçÁöÑÂÜÖÂÆπÈô§‰∫Ü‰∏Ä‰∏™wÁöÑËåÉÊï∞ÔºåÂèòÊàê‰∫ÜÊ†áÂáÜÂåñ‰πãÂêéÁöÑÈïøÂ∫¶ ÊúÄÂ§ßÈó¥ÈöîÂàÜÁ±ªÂô® max margin classifierÂØπ‰∫é‰∏ÄÁªÑÊï∞ÊçÆÊù•ËØ¥ÔºåË∂ÖÂπ≥Èù¢ÂíåÊï∞ÊçÆÁÇπÁöÑË∑ùÁ¶ªË∂äÂ§ßÔºåËøô‰∏™Êï∞ÊçÆÁöÑÂàÜÁ±ªÁ°Æ‰ø°Â∫¶ÔºàconfidenceÔºâÂ∞±Ë∂äÈ´ò ÊúÄÂ§ßÁöÑÈó¥Ë∑ùÁöÑÁõÆÊ†áÂáΩÊï∞Âç≥Ôºö max\gamaÔºå ÂÖ∂‰∏≠gamaÊòØÊØîÊâÄÊúâÂÖ∂‰ªñÈó¥ÈöîÈÉΩÁü≠ÁöÑÂáΩÊï∞Èó¥Èöî Â¶ÇÊûúËÆ©ÊúÄÂ∞èÁöÑÂáΩÊï∞Èó¥ÈöîÁ≠â‰∫é1Ôºà‰∏∫‰∫ÜÊñπ‰æøËÆ°ÁÆóÔºâÔºåÁÑ∂ÂêéÊ±ÇÂá†‰ΩïÈó¥ÈöîÔºåÂèØ‰ª•ÂæóÁü•ÈúÄË¶ÅÁöÑÁõÆÊ†áÂáΩÊï∞Âèò‰∏∫ÊúÄÂ§ßÂåñ 1/||w||ÔºåÂÖ∂‰∏≠wÊòØË∂ÖÂπ≥Èù¢ Ê∑±ÂÖ•SVMÁ∫øÊÄßÂèØÂàÜÂíå‰∏çÂèØÂàÜÂéüÂßãÈóÆÈ¢òÂíåÂØπÂÅ∂ÈóÆÈ¢òduality ‰πãÂâçÁöÑÁõÆÊ†áÂáΩÊï∞ÊòØ 1/||w||ÔºåÊâÄ‰ª•Ê±ÇËøô‰∏™ÁöÑÊúÄÂ§ßÂÄºÔºåÂ∞±ÊòØÊ±Ç1/2*||w||^2ÁöÑÊúÄÂ∞èÂÄºÔºàËøôÈáåÊ±ÇÊúÄÂ§ßÂÄºÂ∞±ÊòØÊ±ÇÂÄíÊï∞ÁöÑÊúÄÂ∞èÂÄºÔºåÁÑ∂Âêé1/2ÂíåÂπ≥ÊñπÈÉΩÊòØ‰∏∫‰∫ÜÊñπ‰æøÂä†ÁöÑÔºâ ÁõÆÊ†áÂáΩÊï∞ÂèòÊàê‰∫åÊ¨°ÁöÑÔºåÁ∫¶ÊùüÊù°‰ª∂ÊòØÁ∫øÊÄßÁöÑÔºåÂá∏‰∫åÊ¨°ÈóÆÈ¢òÔºåÂèØ‰ª•Áî®QPÔºà‰∏Ä‰∏™ÂÜôÁöÑÂ∑Æ‰∏çÂ§öÁöÑÂåÖÔºâ -&gt; ÁõÆÊ†áÊúÄ‰ºòÁöÑÊó∂ÂÄôloss Áî±‰∫éËøô‰∏™ÈóÆÈ¢òÁöÑÁªìÊûÑÔºåÂèØ‰ª•ËΩ¨Êç¢ÊàêÂØπÂÅ∂ÈóÆÈ¢òÊ±ÇËß£ ÁªôÊØè‰∏Ä‰∏™Á∫¶ÊùüÊù°‰ª∂Âä†‰∏ä‰∏Ä‰∏™ÊãâÊ†ºÊúóÊó•‰πòÂ≠ê alpha ÊääËøô‰∏™ËûçÂêàËøõÂÖ•ÁõÆÊ†áÂáΩÊï∞ÈáåÈù¢ ÂΩìÊâÄÊúâÁöÑÁ∫¶ÊùüÊù°‰ª∂ÈÉΩÊª°Ë∂≥ÁöÑÊó∂ÂÄôÔºåÁõÆÊ†áÂáΩÊï∞ÁöÑÁªìÊûúÂ∞±ÊòØ‰πãÂâçÈúÄË¶ÅÊ±ÇÁöÑÁõÆÊ†áÂáΩÊï∞„ÄÇ ÂÜçÂØπËøô‰∏™ÁõÆÊ†áÂáΩÊï∞ÔºàÊñ∞ÁöÑÔºâÊ±ÇÊúÄÂ∞èÂÄºÔºåÂæóÂà∞ÁöÑÁªìÊûúÂ∞±ÊòØÊú¨Êù•ÈúÄË¶ÅÊ±ÇÁöÑÊúÄÂ∞èÂÄº ÊúÄÂêéÔºåÂõ†‰∏∫‰∏äÈù¢ÁöÑÈóÆÈ¢ò‰∏çÊòØÂæàÂ•ΩÊ±ÇËß£ÔºåÊääÂÆÉÁöÑmaxÂíåmin‰∫§Êç¢‰∫Ü‰∏Ä‰∏ãÔºåÂÖàÊ±ÇÊâÄÊúâÁöÑÈó¥ÈöîÁöÑÊúÄÂ∞èÂÄºÔºåÁÑ∂ÂêéÂÜçÊ±ÇËøôÈáåÈù¢alphaÊù°‰ª∂ÂèØ‰ª•Êª°Ë∂≥ÁöÑÊúÄÂ§ßÂÄºÔºåËøô‰∏§‰∏™ÈóÆÈ¢òÂ∞±ÊòØÂØπÂÅ∂ÈóÆÈ¢ò d &lt;= p ÔºåÂú®Êüê‰∫õÊù°‰ª∂Êª°Ë∂≥ÁöÑÊÉÖÂÜµ‰∏ãËøô‰∏§‰∏™ÂÄºÁõ∏Á≠âÔºåËøôÊó∂ÂÄôÊ±ÇÂá∫Êù•ÂØπÂÅ∂ÈóÆÈ¢òÂ∞±ÂèØ‰ª•Ê±ÇÂá∫Êù•ÂéüÂßãÈóÆÈ¢òÁöÑËß£ ËΩ¨Êç¢ÂØπÂÅ∂ÈóÆÈ¢òÁöÑÂéüÂõ†Ôºö ÂØπÂÅ∂ÈóÆÈ¢òÊõ¥ÂÆπÊòìÊ±ÇËß£ ÂèØ‰ª•ÂºïÂÖ•Ê†∏ÂáΩÊï∞ÔºåËøôÊ†∑ÂèØ‰ª•Áõ¥Êé•ÂºïÂÖ•ÈùûÁ∫øÊÄßÈóÆÈ¢ò K.K.TÊù°‰ª∂ ‰∏ä‰∏ÄÊÆµËØ¥ÁöÑÔºåÊª°Ë∂≥ÂØπÂÅ∂ÈóÆÈ¢òÁöÑËß£Á≠â‰ª∑ÁöÑÊù°‰ª∂Â∞±ÊòØKKTÊù°‰ª∂ KTTÊù°‰ª∂ÁöÑÊÑè‰πâÔºöÈùûÁ∫øÊÄßËßÑÂàíÈóÆÈ¢òÔºànonlinear processingÔºâËÉΩÊúâÊúÄ‰ºòÂåñËß£Ê≥ïÁöÑÂÖÖË¶ÅÊù°‰ª∂ ËøôÈÉ®ÂàÜÊ≤°ÊúâÂÜôËØÅÊòéÔºå‰ΩÜÊòØ‰∏äÈù¢ÁöÑÊ±ÇÊúÄÂÄºÁöÑÈóÆÈ¢òÂèØ‰ª•Ë¢´ËØÅÊòéÊòØÊª°Ë∂≥KKTÊù°‰ª∂ÁöÑÈóÆÈ¢òÔºåÊâÄ‰ª•ÂèØ‰ª•Áî®Ëß£ÂÜ≥ÂØπÂÅ∂ÈóÆÈ¢òÁöÑÊñπÂºèÊù•Ê±ÇËß£„ÄÇ ÂØπÂÅ∂ÈóÆÈ¢òÁöÑÊ±ÇËß£Ê≠•È™§ÂèÇËÄÉÂÜÖÂÆπ https://www.zhihu.com/question/21094489 https://blog.csdn.net/v_JULY_v/article/details/7624837]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Machine Learning</category>
        <category>SVM</category>
      </categories>
      <tags>
        <tag>SVM</tag>
        <tag>ÂàÜÁ±ªÂô®</tag>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment1‰πãImage Features]]></title>
    <url>%2F2019%2F04%2F03%2FCS231Nassignment1Feature%2F</url>
    <content type="text"><![CDATA[ÁõÆÊ†á ‰πãÂâçÂÆûÁé∞ÁöÑÈÉΩÊòØÂÜôÂ•Ω‰∫Ü‰∏Ä‰∏™linear classifierÁÑ∂ÂêéÁõ¥Êé•ÂØπËæìÂÖ•ÂõæÁâáÁöÑraw pixelËøõË°åÂàÜÁ±ª ËøôÈÉ®ÂàÜÊòØÂÖà‰ªéraw dataÂæóÂà∞Áõ∏Â∫îÁöÑÂõæÁâáÁâπÂæÅÔºåÁÑ∂ÂêéÂÜçÂØπÁâπÂæÅËøõË°åÂàÜÁ±ª ÂâçÈù¢ÁöÑÁÆÄÂçïÁöÑsetupÂíåload dataÈÉΩÂíå‰πãÂâçÁöÑ‰∏ÄÊ†∑„ÄÇ Extract Features ÂØπÊØèÂº†ÂõæÁâáËÆ°ÁÆóHOG‰ª•ÂèäÂú®HSVÁöÑcolor space‰∏äÈù¢ÁöÑhue channel„ÄÇÔºàËøôÊòØ‰∏§‰∏™‰∏çÂêåÁöÑÂäüËÉΩÔºâ HOGÂèØ‰ª•ÊèêÂèñÂõæÁâáÁöÑtextureÁöÑÁâπÂæÅÔºåÂøΩÁï•È¢úËâ≤ÁöÑÂΩ±Âìç„ÄÇËÄåÈ¢úËâ≤ÁöÑhistogramË°®Á§∫ÁöÑÊòØÈ¢úËâ≤ËÄåÂøΩÁï•textureÔºåÈ¢úËâ≤ÁöÑÁâπÂæÅ‰ºöÊãâÊàê‰∏Ä‰∏™Êñ∞ÁöÑvectorÁÑ∂ÂêéËøõË°åÂàÜÁ±ª„ÄÇ Â¶ÇÊûúÊàë‰ª¨ÊääËøô‰∏§‰∏™‰∏úË•øÁªìÂêàÂèØËÉΩ‰ºöÊúâÊõ¥Â•ΩÁöÑÁªìÊûú„ÄÇ Âú®ËøôÈÉ®ÂàÜÁöÑ‰ª£Á†ÅÈáåÈù¢ÔºåÁõ¥Êé•ÁªôÂá∫Êù•‰∫ÜÊèêÂèñhog featureÂíåcolor histogramÁöÑ‰∏§‰∏™functionÔºåÁî®Ëøô‰∏§‰∏™Áõ¥Êé•ÊèêÂèñÂá∫‰∫ÜÁâπÂæÅÁÑ∂ÂêéÊûÑÊàê‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑextract_featuresÔºåÁî±ÂõæÁâáÂÜÖÂÆπÂíåÁâπÂæÅÁªÑÊàê„ÄÇ ÁÑ∂ÂêéÈ¢ÑÂ§ÑÁêÜ‰∫ÜÁâπÂæÅÔºåÂáèÂéªÂπ≥ÂùáÂÄºÔºåÈô§‰ª•stdÔºàËøôÊ†∑Â§ßÂÆ∂ÈÉΩÂú®Âêå‰∏Ä‰∏™scaleÈáåÈù¢ÔºâÔºåÊúÄÂêéÂä†‰∏ä‰∫Ü‰∏Ä‰∏™biasÁöÑdim 12345678910111213141516171819202122232425from cs231n.features import *num_color_bins = 10 # Number of bins in the color histogramfeature_fns = [hog_feature, lambda img: color_histogram_hsv(img, nbin=num_color_bins)]X_train_feats = extract_features(X_train, feature_fns, verbose=True)X_val_feats = extract_features(X_val, feature_fns)X_test_feats = extract_features(X_test, feature_fns)# Preprocessing: Subtract the mean featuremean_feat = np.mean(X_train_feats, axis=0, keepdims=True)X_train_feats -= mean_featX_val_feats -= mean_featX_test_feats -= mean_feat# Preprocessing: Divide by standard deviation. This ensures that each feature# has roughly the same scale.std_feat = np.std(X_train_feats, axis=0, keepdims=True)X_train_feats /= std_featX_val_feats /= std_featX_test_feats /= std_feat# Preprocessing: Add a bias dimensionX_train_feats = np.hstack([X_train_feats, np.ones((X_train_feats.shape[0], 1))])X_val_feats = np.hstack([X_val_feats, np.ones((X_val_feats.shape[0], 1))])X_test_feats = np.hstack([X_test_feats, np.ones((X_test_feats.shape[0], 1))]) ËÆ≠ÁªÉSVMÊù•Â§ÑÁêÜfeaturesÁî®Â§ÑÁêÜÂ§ö‰∏™Á±ªÂà´ÁöÑSVMÊù•ÁªôËøô‰∫õÁâπÂæÅÂàÜÁ±ªÔºåÂæóÂà∞ÁöÑÁªìÊûúÂ∫îËØ•ÊØîÁõ¥Êé•ÂàÜÁ±ªÂæóÂà∞ÁöÑÁªìÊûúÂ•Ω„ÄÇÂ§ßÊ¶ÇÁªìÊûú‰∏∫0.44Â∑¶Âè≥ÔºåÊ≥®ÊÑèËøôÈáåÈù¢Áî®ÁöÑÊòØgrid searchËÄå‰∏çÊòØrandom search 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# Use the validation set to tune the learning rate and regularization strengthfrom cs231n.classifiers.linear_classifier import LinearSVMlearning_rates = [1e-9, 1e-8, 1e-7]regularization_strengths = [5e4, 5e5, 5e6]results = &#123;&#125;best_val = -1best_svm = None################################################################################# TODO: ## Use the validation set to set the learning rate and regularization strength. ## This should be identical to the validation that you did for the SVM; save ## the best trained classifer in best_svm. You might also want to play ## with different numbers of bins in the color histogram. If you are careful ## you should be able to get accuracy of near 0.44 on the validation set. #################################################################################for lr in learning_rates: for rs in regularization_strengths: svm = LinearSVM() svm.train(X_train_feats, y_train, learning_rate = lr, reg = rs, num_iters = 1000, verbose = True) y_pred_val = svm.predict(X_val_feats) y_pred_train = svm.predict(X_train_feats) train_acc = np.mean(y_pred_train) val_acc = np.mean(y_pred_val == y_val) results[(lr, rs)] = (train_acc,val_acc) if val_acc &gt; best_val: best_val = val_acc best_svm = svm################################################################################# END OF YOUR CODE ################################################################################## Print out results.for lr, reg in sorted(results): train_accuracy, val_accuracy = results[(lr, reg)] print('lr %e reg %e train accuracy: %f val accuracy: %f' % ( lr, reg, train_accuracy, val_accuracy)) print('best validation accuracy achieved during cross-validation: %f' % best_val) ÂêåÊó∂‰πüÂèØËßÜÂåñ‰∫Ü‰∏çÊòØËøô‰∏™Á±ªÂà´Âç¥Ë¢´ÂàÜÂà∞Ëøô‰∏™Á±ªÂà´ÁöÑÈîôËØØsampleÔºö123456789101112131415161718# An important way to gain intuition about how an algorithm works is to# visualize the mistakes that it makes. In this visualization, we show examples# of images that are misclassified by our current system. The first column# shows images that our system labeled as "plane" but whose true label is# something other than "plane".examples_per_class = 8classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']for cls, cls_name in enumerate(classes): idxs = np.where((y_test != cls) &amp; (y_test_pred == cls))[0] idxs = np.random.choice(idxs, examples_per_class, replace=False) for i, idx in enumerate(idxs): plt.subplot(examples_per_class, len(classes), i * len(classes) + cls + 1) plt.imshow(X_test[idx].astype('uint8')) plt.axis('off') if i == 0: plt.title(cls_name)plt.show() ÔºàÊÑüËßâËá™Â∑±ËÆ≠ÁªÉ‰∫Ü‰∏Ä‰∏™ÂÇªÂ≠êÔºâ Áî®‰∏§Â±ÇÁöÑnerual netËØïËØïÁúã È¶ñÂÖàÂéªÈô§‰∏äÊñá‰∏≠biasÁöÑdim ÁÑ∂Âêé‰∫§ÂèâËÆ≠ÁªÉÔºåÊâæÂà∞ÊúÄÂ•ΩÁöÑÂèÇÊï∞ ËøôÈÉ®ÂàÜÂçäÂ§©loss‰∏ã‰∏çÂéªÁöÑÂéüÂõ†‰∏ªË¶ÅÊòØlrÈÄâÁöÑÂ§™Â∞è‰∫Ü 1234567891011121314151617181920212223242526272829303132333435363738394041424344from cs231n.classifiers.neural_net import TwoLayerNetinput_dim = X_train_feats.shape[1]hidden_dim = 500num_classes = 10hidden_size = [300,400,500,600]learning_rate = [1,1e-1,1e-2]reg = [1e-4,1e-3,1e-2]# net = TwoLayerNet(input_dim, hidden_dim, num_classes)best_net = Nonebest_acc = -1result = &#123;&#125;################################################################################# TODO: Train a two-layer neural network on image features. You may want to ## cross-validate various parameters as in previous sections. Store your best ## model in the best_net variable. #################################################################################for lr in learning_rate: for hidd in hidden_size: for rs in reg: net = TwoLayerNet(input_size, hidden, num_class) status = net.train(X_train_feats, y_train, X_val_feats, y_val, num_iters=1200, batch_size=400, learning_rate=lr, learning_rate_decay=0.95, reg=rs, verbose= True) val_acc = (net.predict(X_val_feats) == y_val).mean() result[(lr, rs, hidd)] = (val_acc) if val_acc &gt; best_acc: best_acc = val_acc best_net = net# print(result)# for lr, rs, hidd in sorted(result):# val_accuracy = result[(lr, rs, hidd)]# print('lr %e reg %e hidden_units %e val accuracy: %f' % (# lr, rs, hidd , val_accuracy))print('best validation accuracy achieved during cross-validation: %f' % best_acc)print('best parameter is :',list (result.keys()) [list (result.values()).index (best_acc)])################################################################################# END OF YOUR CODE ################################################################################# best validation accuracy achieved during cross-validation: 0.605000best parameter is : (1, 0.0001, 500) ‰∏ÄÁÇπÊÑüËßâ ÊÑüËßâË¶ÅÊòØlrÂ§™Â∞èÁöÑËØùÔºåÂç≥‰ΩøÂ¢ûÂä†iterationÁöÑÊ¨°Êï∞ÔºåÂêéÈù¢ÁöÑÊîπÂèò‰πü‰∏çÂ§ß lrÊúÄÂü∫Á°ÄÁöÑËåÉÂõ¥Â∫îËØ•ÂÖàÂÆö‰∏ãÊù• ÊúÄÂêéÊç¢‰∫ÜÊç¢ÂèÇÊï∞Â±ÖÁÑ∂ËÆ≠Âá∫Êù•‰∫Ü60%ÁöÑvalÊ≠£Á°ÆÁéá testÁöÑÊ≠£Á°ÆÁéáÂú®55.8Â∑¶Âè≥]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
        <category>CS231n‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>Image Feature</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231Nassignment1‰πãtwo_layer_net]]></title>
    <url>%2F2019%2F04%2F02%2FCS231Nassignment1twolayernet%2F</url>
    <content type="text"><![CDATA[ÁõÆÊ†á Implement a neural network with fc layers for classifiction Test it on CIFAR-10 dataset ÂàùÂßãÂåñauto-reloading external modules ÂÆö‰πârelative error123def rel_error(x, y): """ returns relative error """ return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y)))) ËøôÈáåÊèíÂÖ•‰∏Ä‰∏ãnp.maxÂíånp.maximumÁöÑÂå∫Âà´ maxÊòØÊ±ÇÂ∫èÂàóÁöÑÊúÄÂÄºÔºåÂèØ‰ª•ËæìÂÖ•‰∏Ä‰∏™ÂèÇÊï∞ÔºåaxisË°®Á§∫ÁöÑÊòØÊ±ÇÊúÄÂÄºÁöÑÊñπÂêë maximumËá≥Â∞ëËæìÂÖ•‰∏§‰∏™ÂèÇÊï∞Ôºå‰ºöÊää‰∏§‰∏™ÂèÇÊï∞ÈÄê‰ΩçÊØîËæÉÔºåÁÑ∂ÂêéËæìÂá∫ÊØîËæÉÂ§ßÁöÑÈÇ£‰∏™ÁªìÊûú ‰ΩÜÊòØÂ•ΩÂÉèÂú®ËøôÈáåÁöÑ‰ΩøÁî®‰∏äÈù¢ÔºåËØ¥ÊòéxÂíåy‰∏çÊòØ‰∏Ä‰∏™ÂçïÁã¨ÁöÑÂÄºÔºåÂ∫îËØ•ÊòØ‰∏§‰∏™Êï∞ÁªÑ 12345&gt;&gt; np.max([-4, -3, 0, 0, 9])9&gt;&gt; np.maximum([-3, -2, 0, 1, 2], 0)array([0, 0, 0, 1, 2]) ‰∏çÊòØÂæàÁêÜËß£ËøôÈáå‰∏∫‰ªÄ‰πàË¶ÅÈô§‰ª•x+y ËÆæÁΩÆÂèÇÊï∞cs231n/classifiers/neural_net.pyself.paramsÂÇ®Â≠ò‰∫ÜÈúÄË¶ÅÁöÑÂèÇÊï∞ÔºåÂèÇÊï∞ÈÉΩË¢´Â≠òÂÇ®Âú®dictÈáåÈù¢Ôºå‰∏Ä‰∏™ÂêçÂ≠óÂØπÂ∫î‰∏Ä‰∏™ÂÜÖÂÆπ ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÁöÑÂèÇÊï∞Â¶Ç‰∏ãÔºö W1ÔºåÁ¨¨‰∏ÄÂ±ÇÁöÑweightsÔºåÔºàDÔºåHÔºâÔºåÂÖ∂‰∏≠HÊòØÁ¨¨‰∫åÂ±ÇÁöÑneruonÁöÑ‰∏™Êï∞„ÄÇÂõ†‰∏∫Âè™Êúâ‰∏ÄÂ±ÇÁöÑÊó∂ÂÄôÔºåD‰∏™ËæìÂÖ•ÂØπÂ∫îC‰∏™ËæìÂá∫ÔºåÁé∞Âú®Êúâ‰∏§Â±ÇÁöÑfcÔºåÂØπÂ∫îÁöÑËæìÂá∫Â∞±ÊòØÁ¨¨‰∫åÂ±ÇÁöÑunits‰∏™Êï∞ b1ÔºåÁ¨¨‰∏ÄÂ±ÇÁöÑbiasÔºåÔºàHÔºåÔºâ W2ÔºåÁ¨¨‰∫åÂ±ÇÁöÑweightsÔºåÔºàHÔºåCÔºâ b2ÔºåÁ¨¨‰∫åÂ±ÇÁöÑbiasbiasÈÉΩÈúÄË¶ÅÂàùÂßãÂåñ‰∏∫Áõ∏Â∫îÂ§ßÂ∞èÁöÑ0ÔºåweightsÂàùÂßãÂåñÊàê0-1‰πãÈó¥ÁöÑÊØîËæÉÂ∞èÁöÑÊï∞Â≠ó Forward pasaËÆ°ÁÆóscores ËøôÈÉ®ÂàÜÈùûÂ∏∏ÁÆÄÂçïÔºå‰∏§Ê¨°Wx+bÔºåÂπ∂‰∏îÂú®Á¨¨‰∏ÄÊ¨°‰πãÂêéËÆ∞ÂæóÊøÄÊ¥ªÂ∞±ÂèØ‰ª•‰∫Ü ÊøÄÊ¥ªÂáΩÊï∞Áî®ÁöÑreluÔºåÂÜÖÂÆπÂ∞±ÊòØscoreÂ∞è‰∫é0ÁöÑÈÉ®ÂàÜËÆ©‰ªñÁõ¥Êé•Á≠â‰∫é0 ËÆ°ÁÆóloss ËøôÈáåÁî®ÁöÑÊòØsoftmaxËÆ°ÁÆólossÔºåÂíåsoftmaxÁöÑ‰Ωú‰∏öÂÜÖÂÆπ‰∏ÄÊ†∑ÔºåÂ∞ÜÊâÄÊúâÁöÑscores expÔºåÊ±ÇÂç†ÁöÑÁôæÂàÜÊØîÔºåÊ±ÇÂá∫Êù•ÁöÑÈÉ®ÂàÜ-logÔºåÁÑ∂ÂêéÊääÊâÄÊúâÁöÑÊ±ÇÂíå ËøôÈáåÁî®Âà∞‰∫ÜboardcastingÁöÑÈóÆÈ¢òÔºåÊ≥®ÊÑèÔºà100Ôºå1ÔºâËøôÊ†∑ÁöÑÊâçÂèØ‰ª•boardcastingÔºåÔºà100ÔºåÔºâÁöÑÊòØ‰∏ÄÁª¥Êï∞ÁªÑÔºåÈúÄË¶ÅÊääÂÆÉreshapeÊàêÂâçÈù¢ÁöÑÊ†∑Â≠êÊâçÂèØ‰ª• ËøôÈáåÊúÄÂêéÁöÑÁªìÊûúËøòÊÄªÊòØÂ∑Æ‰∏ÄÁÇπÔºåÊúÄÂêéÂèëÁé∞ÊòØÂõ†‰∏∫regularzationÁöÑÊó∂ÂÄôÂ§ö‰πò‰∫Ü0.5ÔºåÁúãÈ¢òÂëúÂëúÂëú Backward pass Áî±‰∫ébÊòØÁ∫øÊÄßÊ®°ÂûãÁöÑbiasÔºåÂÅèÂØºÊï∞ÊòØ1ÔºåÁõ¥Êé•ÂØπclassÁöÑÂÜÖÂÆπÊ±ÇÂíåÁÑ∂ÂêéÈô§‰ª•NÂ∞±ÊòØÊúÄÁªàÁªìÊûú ÂØπWÊ±ÇÂØºÁöÑÊó∂ÂÄôÈúÄË¶ÅÁî®Âà∞ÈìæÂºèÊ≥ïÂàôÔºåÁÑ∂ÂêéÁõ¥Êé•‰ª£Á†ÅÂÆûÁé∞‰∏Ä‰∏ãÂ∞±Ë°å‰∫Ü ËøôÈáåÈÅáÂà∞ÁöÑ‰∏ªË¶ÅÈóÆÈ¢òÊòØlossÁöÑÂÄº‰ºöÂΩ±Âìç‰ªñ‰º∞ËÆ°ÁöÑÂÄºÔºåÂõ†‰∏∫lossÁöÑregularzationÊîπ‰∫ÜÔºåÊâÄ‰ª•Á≠îÊ°à‰∏ÄÁõ¥ÂØπ‰∏ç‰∏ä„ÄÇ Training predict ËÆ≠ÁªÉÂíå‰πãÂâçÂÜôÁöÑÂ∑Æ‰∏çÂ§öÔºåËÆ≠ÁªÉÁΩëÁªúÔºå‰∏ªË¶ÅÂåÖÊã¨ÂÜôtrainingÈÉ®ÂàÜÁöÑÈöèÊú∫mini-batchÂíåÊõ¥Êñ∞weightsÔºåËÆ∞ÂæólrÊõ¥Êñ∞ÁöÑÊó∂ÂÄôË¶ÅÂ∏¶Ë¥üÂè∑ È¢ÑÊµã‰πüÂ∑Æ‰∏çÂ§öÔºåÁÆóÂá∫Êù•scoresÔºåÊâæÂà∞ÊúÄÂ§ßÁöÑscoreÂ∞±ÊòØÂàÜÁ±ªÁöÑÁªìÊûú„ÄÇÊ≥®ÊÑèÊâæÊúÄÂ§ßÁöÑÊó∂ÂÄôË¶ÅÁî®argmaxÔºåÊâæÂà∞ÁöÑÊòØÊúÄÂ§ßÁöÑ‰∏úË•øÁöÑindiceÔºå‰∏çÁÑ∂ÂæóÂà∞ÁöÑÊòØÂæóÂàÜ12345678910111213net = init_toy_model()stats = net.train(X, y, X, y, learning_rate=1e-1, reg=5e-6, num_iters=100, verbose=False)print('Final training loss: ', stats['loss_history'][-1])# plot the loss historyplt.plot(stats['loss_history'])plt.xlabel('iteration')plt.ylabel('training loss')plt.title('Training Loss history')plt.show() ‰ΩøÁî®ÂÜôÂ•ΩÁöÑÊù•ËÆ≠ÁªÉCIFAR-101234567891011121314input_size = 32 * 32 * 3hidden_size = 50num_classes = 10net = TwoLayerNet(input_size, hidden_size, num_classes)# Train the networkstats = net.train(X_train, y_train, X_val, y_val, num_iters=1000, batch_size=200, learning_rate=1e-4, learning_rate_decay=0.95, reg=0.25, verbose=True)# Predict on the validation setval_acc = (net.predict(X_val) == y_val).mean()print('Validation accuracy: ', val_acc) ËøôÊó∂ÂÄôÂæóÂà∞ÁöÑÂáÜÁ°ÆÂ∫¶Â∫îËØ•Âú®28%Â∑¶Âè≥ÔºåÂèØ‰ª•‰ºòÂåñ Ëøõ‰∏ÄÊ≠•‰ºòÂåñ ‰∏ÄÁßçÂèØËßÜÂåñÁöÑÊñπÊ≥ïÊòØÂèØËßÜÂåñloss functionÂíåÂáÜÁ°ÆÁéáÁöÑÂÖ≥Á≥ªÔºåÂàÜÂà´Âú®ËÆ≠ÁªÉÂíåvalÈõÜ‰∏äÈù¢ Âè¶ÁßçÊòØÂèØËßÜÂåñÁ¨¨‰∏ÄÂ±ÇÁöÑweights ‰∏§ÁßçÊñπÊ≥ïÁöÑÁªìÊûúÂ¶Ç‰∏ãÔºö debugÊ®°Âûã ÈóÆÈ¢ò lossÂ§ß‰Ωì‰∏äÈÉΩÊòØlinearlyÁöÑ‰∏ãÈôçÁöÑÔºåËØ¥ÊòélrÂèØËÉΩÂ§™‰Ωé‰∫Ü Âú®trainingÂíåvalÁöÑÂáÜÁ°ÆÁéá‰∏äÊ≤°ÊúâgapÔºåËØ¥ÊòémodelÁöÑÂÆπÈáèÂ§™Â∞èÁöÑÔºåÈúÄË¶ÅÂ¢ûÂ§ßsize Â¶ÇÊûúÂÆπÈáèËøáÂ§ßËøò‰ºöÂØºËá¥overfiitingÔºåËøôÊó∂ÂÄôgapÂ∞±‰ºöÂæàÂ§ß tuning hypers È¢òÁõÆÈáåÈù¢ÁöÑÂª∫ËÆÆÊòØtuningÂá†‰∏™hyperÔºåËøòÊòØÂíå‰πãÂâç‰∏ÄÊ†∑ÔºåÁõ¥Êé•randomÔºåsearch ËøôÈáåÈÄâ‰∫Ü‰∏â‰∏™ÂèÇÊï∞ÔºåÂàÜÂà´ÊòØunitsÁöÑÊï∞ÈáèÔºålearning rateÂíåregÁöÑÂº∫Â∫¶ÔºåÈöè‰æøËÆæÁΩÆ‰∫Ü‰∏Ä‰∏ãÁïåÈôê ÊúÄÁªàËÆ°ÁÆóÂá∫Êù•ÁöÑvalÂáÜÁ°ÆÁéáÊòØÔºö49.5% ÁßÄÁßÄÁßÄÔºÅÔºÅ ÂèØËßÜÂåñweigh‰πãÂêéÁöÑÁªìÊûúÊòØ ÈúáÊÉäÔºåÂ±ÖÁÑ∂ÊúÄÂêéÁöÑÊµãËØïÊ≠£Á°ÆÁéá‰πüËææÂà∞‰∫Ü49.4ÔºÅÔºÅÔºÅ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051best_net = None # store the best model into this ################################################################################## TODO: Tune hyperparameters using the validation set. Store your best trained ## model in best_net. ## ## To help debug your network, it may help to use visualizations similar to the ## ones we used above; these visualizations will have significant qualitative ## differences from the ones we saw above for the poorly tuned network. ## ## Tweaking hyperparameters by hand can be fun, but you might find it useful to ## write code to sweep through possible combinations of hyperparameters ## automatically like we did on the previous exercises. ##################################################################################best_acc = -1learning_rates = [1e-3, 1e-2]regularization_strengths = [1e-2, 6e-1]hidden_size = [50, 150]random_search = np.random.rand(30, 3)random_search[:, 0] = random_search[:, 0] * \ (learning_rates[1] - learning_rates[0]) + learning_rates[0]random_search[:, 1] = random_search[:, 1] * \ (regularization_strengths[1] - regularization_strengths[0] ) + regularization_strengths[0]random_search[:, 2] = random_search[:, 2] * \ (hidden_size[1] - hidden_size[0]) + hidden_size[0]for lr, rs, hidd in random_search: input_size = 32 * 32 * 3 hidden = int(hidd) num_class = 10 net = TwoLayerNet(input_size, hidden, num_class) status = net.train(X_train, y_train, X_val, y_val, num_iters=1000, batch_size=200, learning_rate=lr, learning_rate_decay=0.95, reg=rs, verbose=True) val_acc = (net.predict(X_val) == y_val).mean() if val_acc &gt; best_acc: best_acc = val_acc best_net = netprint("best net is with val acc", best_acc)################################################################################## END OF YOUR CODE ################################################################################## ‰ª£Á†ÅÈÉ®ÂàÜnerual_net.pyÈÉ®ÂàÜÁöÑÂÆåÊï¥‰ª£Á†ÅÂ¶Ç‰∏ã 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289from __future__ import print_functionimport numpy as npimport matplotlib.pyplot as pltclass TwoLayerNet(object): """ A two-layer fully-connected neural network. The net has an input dimension of N, a hidden layer dimension of H, and performs classification over C classes. We train the network with a softmax loss function and L2 regularization on the weight matrices. The network uses a ReLU nonlinearity after the first fully connected layer. In other words, the network has the following architecture: input - fully connected layer - ReLU - fully connected layer - softmax The outputs of the second fully-connected layer are the scores for each class. """ def __init__(self, input_size, hidden_size, output_size, std=1e-4): """ Initialize the model. Weights are initialized to small random values and biases are initialized to zero. Weights and biases are stored in the variable self.params, which is a dictionary with the following keys: W1: First layer weights; has shape (D, H) b1: First layer biases; has shape (H,) W2: Second layer weights; has shape (H, C) b2: Second layer biases; has shape (C,) Inputs: - input_size: The dimension D of the input data. - hidden_size: The number of neurons H in the hidden layer. - output_size: The number of classes C. """ self.params = &#123;&#125; self.params['W1'] = std * np.random.randn(input_size, hidden_size) self.params['b1'] = np.zeros(hidden_size) self.params['W2'] = std * np.random.randn(hidden_size, output_size) self.params['b2'] = np.zeros(output_size) def loss(self, X, y=None, reg=0.0): """ Compute the loss and gradients for a two layer fully connected neural network. Inputs: - X: Input data of shape (N, D). Each X[i] is a training sample. - y: Vector of training labels. y[i] is the label for X[i], and each y[i] is an integer in the range 0 &lt;= y[i] &lt; C. This parameter is optional; if it is not passed then we only return scores, and if it is passed then we instead return the loss and gradients. - reg: Regularization strength. Returns: If y is None, return a matrix scores of shape (N, C) where scores[i, c] is the score for class c on input X[i]. If y is not None, instead return a tuple of: - loss: Loss (data loss and regularization loss) for this batch of training samples. - grads: Dictionary mapping parameter names to gradients of those parameters with respect to the loss function; has the same keys as self.params. """ # Unpack variables from the params dictionary W1, b1 = self.params['W1'], self.params['b1'] W2, b2 = self.params['W2'], self.params['b2'] N, D = X.shape # Compute the forward pass scores = None ############################################################################# # TODO: Perform the forward pass, computing the class scores for the input. # # Store the result in the scores variable, which should be an array of # # shape (N, C). # ############################################################################# # first layer, shape(N,H) X1 = X.dot(W1) + b1 # ËøôÈáåÂä†‰∫Ü‰∏Ä‰∏™Á¨¨‰∏ÄÂ±Ç‰πãÂêéÁöÑreluÊøÄÊ¥ª relu = np.maximum(0, X1) # final result, shape(N,C) scores = relu.dot(W2) + b2 ############################################################################# # END OF YOUR CODE # ############################################################################# # If the targets are not given then jump out, we're done if y is None: return scores # Compute the loss loss = None ############################################################################# # TODO: Finish the forward pass, and compute the loss. This should include # # both the data loss and L2 regularization for W1 and W2. Store the result # # in the variable loss, which should be a scalar. Use the Softmax # # classifier loss. # ############################################################################# num_train = N scores = scores - np.reshape(np.max(scores, axis=1), (num_train, -1)) scores = np.exp(scores) scores_sum = np.sum(scores, axis=1).reshape(N, 1) # scores_sum = np.sum(scores, axis=1, keepdims=True) p = scores / scores_sum loss = np.sum(-np.log(p[np.arange(N), y])) loss /= num_train # ËøôÈáå‰∏çË¶Å‰πò0.5ÁöÑÁ≥ªÊï∞ # loss += reg * np.sum(W1 * W1) + reg * np.sum(W2 * W2) loss += 0.5 * reg * np.sum(W1 * W1) + 0.5 * reg * np.sum(W2 * W2) # ############################################################################# # # END OF YOUR CODE # # ############################################################################# # # Backward pass: compute gradients grads = &#123;&#125; # ############################################################################# # # TODO: Compute the backward pass, computing the derivatives of the weights # # # and biases. Store the results in the grads dictionary. For example, # # # grads['W1'] should store the gradient on W1, and be a matrix of same size # # ############################################################################# dscores = p dscores[range(N), y] -= 1.0 # dscores /= N # shape dW2(CxN) x(NxH) -&gt; (CxH) # dW2 = np.dot(relu.T, p) dW2 = np.dot(relu.T, dscores) # print(dW2) # ÊØè‰∏™class‰ºöÊúâ‰∏Ä‰∏™bÔºåÂØπbÊ±ÇÂØºÊòØ1 # shape db2 (C,) db2 = np.sum(p, axis=0) # (NxC) x (HxC).T -&gt; (N,H) dW_relu = np.dot(dscores, W2.T) dW_relu[relu &lt;= 0] = 0 # (NxD).T x (N,H) -&gt; (D,H) dW1 = (X.T).dot(dW_relu) db1 = np.sum(dW_relu, axis=0) dW2 /= N dW1 /= N dW2 += reg * W2 dW1 += reg * W1 db1 /= N db2 /= N grads['W1'] = dW1 grads['b1'] = db1 grads['W2'] = dW2 grads['b2'] = db2 ############################################################################# # END OF YOUR CODE # ############################################################################# return loss, grads def train(self, X, y, X_val, y_val, learning_rate=1e-3, learning_rate_decay=0.95, reg=5e-6, num_iters=100, batch_size=200, verbose=False): """ Train this neural network using stochastic gradient descent. Inputs: - X: A numpy array of shape (N, D) giving training data. - y: A numpy array f shape (N,) giving training labels; y[i] = c means that X[i] has label c, where 0 &lt;= c &lt; C. - X_val: A numpy array of shape (N_val, D) giving validation data. - y_val: A numpy array of shape (N_val,) giving validation labels. - learning_rate: Scalar giving learning rate for optimization. - learning_rate_decay: Scalar giving factor used to decay the learning rate after each epoch. - reg: Scalar giving regularization strength. - num_iters: Number of steps to take when optimizing. - batch_size: Number of training examples to use per step. - verbose: boolean; if true print progress during optimization. """ num_train = X.shape[0] iterations_per_epoch = max(num_train / batch_size, 1) # Use SGD to optimize the parameters in self.model loss_history = [] train_acc_history = [] val_acc_history = [] for it in range(num_iters): X_batch = None y_batch = None ######################################################################### # TODO: Create a random minibatch of training data and labels, storing # # them in X_batch and y_batch respectively. # ######################################################################### rand_mini = np.random.choice(num_train, batch_size, replace=True) X_batch = X[rand_mini] y_batch = y[rand_mini] ######################################################################### # END OF YOUR CODE # ######################################################################### # Compute loss and gradients using the current minibatch loss, grads = self.loss(X_batch, y=y_batch, reg=reg) loss_history.append(loss) ######################################################################### # TODO: Use the gradients in the grads dictionary to update the # # parameters of the network (stored in the dictionary self.params) # # using stochastic gradient descent. You'll need to use the gradients # # stored in the grads dictionary defined above. # ######################################################################### self.params['W1'] -= learning_rate * grads['W1'] self.params['W2'] -= learning_rate * grads['W2'] self.params['b1'] -= learning_rate * grads['b1'] self.params['b2'] -= learning_rate * grads['b2'] ######################################################################### # END OF YOUR CODE # ######################################################################### if verbose and it % 100 == 0: print('iteration %d / %d: loss %f' % (it, num_iters, loss)) # Every epoch, check train and val accuracy and decay learning rate. if it % iterations_per_epoch == 0: # Check accuracy train_acc = (self.predict(X_batch) == y_batch).mean() val_acc = (self.predict(X_val) == y_val).mean() train_acc_history.append(train_acc) val_acc_history.append(val_acc) # Decay learning rate learning_rate *= learning_rate_decay return &#123; 'loss_history': loss_history, 'train_acc_history': train_acc_history, 'val_acc_history': val_acc_history, &#125; def predict(self, X): """ Use the trained weights of this two-layer network to predict labels for data points. For each data point we predict scores for each of the C classes, and assign each data point to the class with the highest score. Inputs: - X: A numpy array of shape (N, D) giving N D-dimensional data points to classify. Returns: - y_pred: A numpy array of shape (N,) giving predicted labels for each of the elements of X. For all i, y_pred[i] = c means that X[i] is predicted to have class c, where 0 &lt;= c &lt; C. """ y_pred = None ########################################################################### # TODO: Implement this function; it should be VERY simple! # ########################################################################### W1 = self.params['W1'] W2 = self.params['W2'] b1 = self.params['b1'] b2 = self.params['b2'] scores = X.dot(W1) + b1 scores[scores &lt; 0] = 0.0 scores = scores.dot(W2) + b2 y_pred = np.argmax(scores, axis=1) ########################################################################### # END OF YOUR CODE # ########################################################################### return y_pred]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
        <category>CS231n‰Ωú‰∏ö</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫éNormalizationÁöÑÊñπÊ≥ï‰ª•ÂèäÂÆûÁé∞]]></title>
    <url>%2F2019%2F04%2F01%2FNormalize%2F</url>
    <content type="text"><![CDATA[Âú®Â§ÑÁêÜÊï∞ÊçÆÁöÑÊó∂ÂÄôÔºåÂõ†‰∏∫Êï∞ÊçÆÁöÑÂ§ßÂ∞èÂ∑ÆÂà´‰ºöÊØîËæÉÂ§ßÔºå‰∏∫‰∫ÜÈÅøÂÖçÊï∞ÊçÆÁöÑÁâπÂæÅË¢´ÂÖ∂‰ªñÁâπÂæÅÂêÉÊéâÔºåÈúÄË¶ÅÂØπÊï∞ÊçÆËøõË°ånormalizationÁöÑÂ§ÑÁêÜ (0,1) Ê†áÂáÜÂåñÊâæÂà∞ÊúÄÂ§ßÂÄºÂíåÊúÄÂ∞èÂÄºÔºå‰ª•ÊúÄÂ§ßÂÄº‰∏∫1ÔºåÊúÄÂ∞èÂÄº‰∏∫0ÔºåËÆ°ÁÆóÂÖ∂‰ªñÊï∞ÊçÆÂú®0Âà∞1‰πãÈó¥ÁöÑÂàÜÂ∏É„ÄÇ 12def normal0_1(x,Max,Min): return (x-Min)/(Max-Min) ‰ΩøÁî®np.max()Ôºånp.minÊù•ÊâæÊúÄÂ§ßÂÄºÂíåÊúÄÂ∞èÂÄº Ê≠£ÊÄÅÂàÜÂ∏ÉËæìÂÖ•ÂéüÂßãÊï∞ÊçÆÁöÑÂùáÂÄºÂíåÊ†áÂáÜÂ∑ÆÔºåÂØπÊï∞ÊçÆÂ§ÑÁêÜÔºåÂ§ÑÁêÜ‰πãÂêéÁöÑÊï∞ÊçÆÊòØÊ†áÂáÜÊ≠£ÊÄÅÂàÜÂ∏ÉÔºàÂùáÂÄºÊòØ0ÔºåÊ†áÂáÜÂ∑ÆÊòØ1Ôºâ 12def Normalization(x, mu, sigma): return (x-mu) / sigma ‰ΩøÁî®np.average()Âíånp.std()ÊâæÂà∞ÂùáÂÄºÂíåÊ†áÂáÜÂ∑Æ SigmoidÂáΩÊï∞sigmoidÂáΩÊï∞ÂÖ≥‰∫éÔºà0Ôºå 0.5Ôºâ‰∏≠ÂøÉÂØπÁß∞ÔºåÂú®‰∏≠ÂøÉÈôÑËøëÊñúÁéáËæÉÂ§ßÔºåÂú®Ë¥üÊó†Á©∑Êé•Ëøë0ÔºåÊ≠£Êó†Á©∑Êé•Ëøë1 12def sigmood(x): return 1.0/(1+np.exp(-float(x)))]]></content>
      <categories>
        <category>Êï∞Â≠¶ÈóÆÈ¢ò</category>
      </categories>
      <tags>
        <tag>Normalize</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231N‰Ωú‰∏öassignment1‰πãsoftmax]]></title>
    <url>%2F2019%2F04%2F01%2FCS231Nassignment1softmax%2F</url>
    <content type="text"><![CDATA[SoftmaxËøôÈÉ®ÂàÜ‰∏ªË¶ÅÊòØsoftmaxÁöÑlossË¶ÅÂ¶Ç‰ΩïËÆ°ÁÆóAssignment From: Assignment1 ÁõÆÊ†á implement a fully-vectorized loss function for the Softmax classifier implement the fully-vectorized expression for its analytic gradient check your implementation with numerical gradient use a validation set to tune the learning rate and regularization strength optimize the loss function with SGD visualize the final learned weights È¢ÑÂ§ÑÁêÜÔºàÂíå‰πãÂâç‰∏ÄÊ†∑Ôºà ËΩΩÂÖ•Êï∞ÊçÆ ÂàùÂßãÂåñÊï∞ÊçÆ ÊãâÈïø normalize ÂàÜÊàêËÆ≠ÁªÉÈõÜÊµãËØïÈõÜvalidationÁ≠âÁ≠â softmax classifiernaive_softmax_loss‰∏≠ÂøÉÊÄùÊÉ≥ÔºöÊääÂæóÂà∞ÁöÑscoreÔºàWx + bÔºâÂÖàexpÔºåÁÑ∂ÂêénormalizeÔºåÊúÄÂêéÊ±Ç-log ËæìÂÖ•Ôºö WÔºöÂ§ßÂ∞è(D,C)Ôºåweights XÔºöÂ§ßÂ∞è(N,D)ÔºåËæìÂÖ•ÁöÑmini-batch yÔºöÂ§ßÂ∞è(N,)ÔºåÊ†áÁ≠æ regÔºöregularizationÁöÑÁ≥ªÊï∞ ËæìÂá∫Ôºö loss dWÔºåÂç≥ÊîπÂèòÁöÑgradient ËÆ°ÁÆóloss ÂÖàÂ∞ÜÊâÄÊúâÁöÑscoresÂÅöexpÔºàËøô‰∏ÄÊ≠•ÂèØ‰ª•ÂÖàËøõË°åÔºâÔºåËøôÊ†∑ÊâÄÊúâÁöÑscoreÈÉΩ‰ºöÂèòÊàêÊ≠£Êï∞ ÁÑ∂ÂêéÂØπ‰∏çÂêåclassÁöÑscoreÂàÜÂà´Ê±ÇnormalizeÔºàËôΩÁÑ∂ËØ¥ÊòØnormalizeÔºåÂÆûÈôÖÊ±ÇÁöÑÊòØËøô‰∏™ÁßçÁ±ªÁöÑscoreÂú®ÊâÄÊúâÁöÑscoreÈáåÈù¢ÊâÄÂç†ÁöÑÊØî‰æãÔºâ ÁÑ∂ÂêéÂ∞ÜÊ≠£Á°ÆÁöÑÁ±ªÂûãÊâÄÂç†ÁöÑÊØî‰æãÊ±ÇlogÔºåÂÜçÊ±ÇË¥üÂè∑ÔºåÂæóÂá∫Êù•ÁöÑÂ∞±ÊòØÊØè‰∏™ÂõæÁâáÁöÑlossÔºàËøôÈáåÊ≥®ÊÑè0ÁöÑlogÊòØÊó†Á©∑ÔºåËÆ°ÁÆó‰∏çÂá∫Êù•Ôºâ ÊâÄÊúâÂõæÁâáÁöÑlossÊ±ÇÂíåÔºåÁÑ∂ÂêéÈô§‰ª•ÂõæÁâáÊÄªÊï∞ÔºåregularzationÔºåÂæóÂá∫Êù•ÁöÑÂ∞±ÊòØÊúÄÁªàÁöÑÁªìÊûú ËÆ°ÁÆódW ÂèØ‰ª•ËøôÊ†∑ÁêÜËß£ WÊòØ‰∏Ä‰∏™ÂèÇÊï∞Áü©ÈòµÔºåËøô‰∏™Áü©ÈòµÁöÑÂèòÂåñÁî±‰∏§‰∏™ÈÉ®ÂàÜÁªÑÊàê Á¨¨‰∏ÄÈÉ®ÂàÜÊòØÂæÄ‰ªÄ‰πàÊñπÂêëÂèòÔºåËøô‰∏™ÂèñÂÜ≥‰∫éÊúÄÂêéÁÆóÂá∫Êù•ÁöÑlossÁöÑÂàÜÂ∏É Á¨¨‰∫åÈÉ®ÂàÜÊòØÂèòÂ§öÂ∞ëÂêàÈÄÇÔºåËøôÊó∂ÂÄôËøòÈúÄË¶Å‰πò‰∏Ä‰∏™Á≥ªÊï∞X[i] ÊâÄ‰ª•ÂΩìÁÆóÂá∫Êù•lossÂπ∂‰∏îy[i] = jÁöÑÊó∂ÂÄôÔºåÂÆûÈôÖ‰∏äÂ∞±ÊòØËøôÂº†ÂõæÊ≠£Á°ÆÂàÜÁ±ªÊÉÖÂÜµ‰∏ãÁöÑÈîôËØØÂàÜÁ±ªÁöÑÊ¶ÇÁéáÔºåÊâÄ‰ª•WÁöÑÊîπÂèòÊñπÂêëÂ∫îËØ•ÊòØËøô‰∏™ÁöÑÂèçÊñπÂêë ËøôÂº†ÂõæÁöÑÂÖ∂‰ªñclassÁöÑlossÂàôÂ∫îËØ•ÊòØÊîπÂèòÁöÑÊñπÂêë ËøôÊ†∑Â∞±ÂèØ‰ª•ÁúãÂá∫Êù• SVMÂíåsoftmaxÁöÑ‰∏çÂêå‰πãÂ§Ñ‰∫Ü ÂØπ‰∫éSVMÊù•ËØ¥Ôºå‰ªÖ‰ªÖÈÄöËøá‰∏é0ÊØîÂ§ßÂ∞èÂæóÂá∫‰∏Ä‰∏™ÂÄºÔºåÁõ∏ÂΩì‰∫é‰∏Ä‰∏™0Ôºå1ÁöÑÂºÄÂÖ≥ÔºåÂè™ËÉΩÊ†πÊçÆÁªìÊûúÂæóÂà∞‰∏Ä‰∏™ÁßªÂä®ÁöÑÊñπÂêë ‰ΩÜÊòØÂØπ‰∫ésoftmaxÊù•ËØ¥Ôºå‰∏ç‰ªÖÂæóÂà∞‰∫ÜÊñπÂêëÔºåËøòÂæóÂà∞‰∫ÜËøô‰∏™ÊñπÂêëÁöÑÂç†ÊØîÔºåÊâÄ‰ª•lossË∂äÂ§ßÁöÑÊï∞ÂΩ±ÂìçÂ∞±‰ºöË∂äÂ§ß 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657def svm_loss_naive(W, X, y, reg): """ Structured SVM loss function, naive implementation (with loops). Inputs have dimension D, there are C classes, and we operate on minibatches of N examples. Inputs: - W: A numpy array of shape (D, C) containing weights. - X: A numpy array of shape (N, D) containing a minibatch of data. - y: A numpy array of shape (N,) containing training labels; y[i] = c means that X[i] has label c, where 0 &lt;= c &lt; C. - reg: (float) regularization strength Returns a tuple of: - loss as single float - gradient with respect to weights W; an array of same shape as W """ dW = np.zeros(W.shape) # initialize the gradient as zero # compute the loss and the gradient num_classes = W.shape[1] # ÊúâÂ§öÂ∞ëÈúÄË¶ÅËÆ≠ÁªÉÁöÑ‰∏™Êï∞ num_train = X.shape[0] loss = 0.0 for i in range(num_train): scores = X[i].dot(W) correct_class_score = scores[y[i]] for j in range(num_classes): # Â¶ÇÊûúËøô‰∏™Á±ªÂûãÊòØÊ≠£Á°ÆÁöÑÔºåÈÇ£Â∞±‰∏çÁî®ÁÆ°‰∫Ü if j == y[i]: continue margin = scores[j] - correct_class_score + 1 # note delta = 1 if margin &gt; 0: loss += margin dW[:, y[i]] += -X[i] dW[:, j] += X[i] # Right now the loss is a sum over all training examples, but we want it # to be an average instead so we divide by num_train. loss /= num_train dW /= num_train # Add regularization to the loss. # regÊòØlanbda loss += reg * np.sum(W * W) dW += 2 * reg * W ############################################################################# # TODO: # # Compute the gradient of the loss function and store it dW. # # Rather that first computing the loss and then computing the derivative, # # it may be simpler to compute the derivative at the same time that the # # loss is being computed. As a result you may need to modify some of the # # code above to compute the gradient. # ############################################################################# return loss, dW softmax_loss_vectorizedÊèêÈ´òËÆ°ÁÆóÈÄüÂ∫¶ Ë∑üsvmÈÉ®ÂàÜÁöÑËÆ°ÁÆóÊÄùË∑Ø‰∏ÄÊ†∑ÔºåÁõ¥Êé•‰ΩøÁî®Áü©ÈòµËøêÁÆó Âú®Ê±ÇÊï¥‰∏™scoreÁü©ÈòµÁöÑÂèòÂåñÁöÑÊó∂ÂÄôÔºåÊ≠£Á°ÆÂàÜÁ±ªÁöÑlossÂ∫îËØ•Ë¢´ÂáèÊéâÔºå‰ΩÜÊòØÁé∞Âú®ÊòØË¢´Âä†‰∏äÁöÑÔºåÊâÄ‰ª•ÈúÄË¶ÅÂú®Ê≠£Á°ÆÂàÜÁ±ªÁöÑÂú∞ÊñπÂä†‰∏Ä‰∏™-1 debug‰∫ÜÂæà‰πÖÁöÑÂú∞ÊñπÊòØÔºöËÆ°ÁÆódWÁöÑÊó∂ÂÄô‰∏çÈúÄË¶ÅËÆ°ÁÆólogÔºåÂõ†‰∏∫Ê≤°Êúâlog‰πãÂâçÂ∑≤ÁªèÊòØËøô‰∏™lossÊâÄÂç†ÁöÑÁôæÂàÜÊØî‰∫ÜÔºöÊ±ÇlogÊòØ‰∏∫‰∫ÜÂèòÊàêÂá∏ÂáΩÊï∞ÔºålossÊ≤°ÊúâÊ±Çlog‰πãÂâçÂπ∂‰∏çÊòØÂá∏ÂáΩÊï∞Ôºå‰ΩÜÊòØÂá∏ÂáΩÊï∞ÂÆπÊòìÊâæÂà∞ÊúÄÂÄºÁöÑ‰ºòÂåñÈóÆÈóÆÈ¢òÔºåÊâÄ‰ª•Ë¶ÅÊ±Çlog„ÄÇ‰ΩÜÊòØÂú®ËÆ°ÁÆódWÁöÑÊó∂ÂÄôÂíålogÊ≤°ÂÖ≥Á≥ª 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def softmax_loss_vectorized(W, X, y, reg): """ Softmax loss function, vectorized version. Inputs and outputs are the same as softmax_loss_naive. """ # Initialize the loss and gradient to zero. loss = 0.0 dW = np.zeros_like(W) num_class = W.shape[1] num_train = X.shape[0] ############################################################################# # TODO: Compute the softmax loss and its gradient using no explicit loops. # # Store the loss in loss and the gradient in dW. If you are not careful # # here, it is easy to run into numeric instability. Don't forget the # # regularization! # ############################################################################# # sizeÔºàNÔºåCÔºâ scores = X.dot(W) scores = np.exp(scores) # ÂØπÊØèË°åÊ±ÇÂíå scores_sum = np.sum(scores, axis=1) scores_sum = np.repeat(scores_sum, num_class) scores_sum = scores_sum.reshape(num_train, num_class) # true_divideËøîÂõûÊµÆÁÇπÊï∞ÔºåÊôÆÈÄöÁöÑËøîÂõûÊ≠£Êï∞ÔºåsizeÔºàNÔºåCÔºâ percent = np.true_divide(scores, scores_sum) # Âè™ÊúâÊ≠£Á°ÆÁßçÁ±ªÈúÄË¶ÅÊ±Çloss Li = -np.log(percent[np.arange(num_train), y]) loss = np.sum(Li) # Ê≥®ÊÑèËøôÈáå‰∏çÈúÄË¶ÅÊ±Çlog dS = percent.copy() dS[np.arange(num_train), y] += -1 dW = (X.T).dot(dS) loss /= num_train loss += reg * np.sum(W * W) dW /= num_train dW += reg * W ############################################################################# # END OF YOUR CODE # ############################################################################# return loss, dW È™åËØÅÔºåÈÄâhyperÂíåSVMÁöÑÈÉ®ÂàÜ‰∏ÄÊ†∑ÔºåÈöèÊú∫ÊêúÁ¥¢hyperÔºåÈ™åËØÅÁªìÊûúÔºåËÆ≠ÁªÉËø≠‰ª£500Ê¨°ÔºåÊúÄÁªàÁöÑÂáÜÁ°ÆÁéáÂú®36%Â∑¶Âè≥1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# Use the validation set to tune hyperparameters (regularization strength and# learning rate). You should experiment with different ranges for the learning# rates and regularization strengths; if you are careful you should be able to# get a classification accuracy of over 0.35 on the validation set.from cs231n.classifiers import Softmaxresults = &#123;&#125;best_val = -1best_softmax = Nonelearning_rates = [1e-7, 5e-7]regularization_strengths = [2.5e4, 5e4]################################################################################# TODO: ## Use the validation set to set the learning rate and regularization strength. ## This should be identical to the validation that you did for the SVM; save ## the best trained softmax classifer in best_softmax. #################################################################################hyper_values = np.random.rand(50,2)hyper_values[:,0] = (learning_rates[1] - learning_rates[0]) * hyper_values[:,0] + learning_rates[0]hyper_values[:,1] = (regularization_strengths[1] - regularization_strengths[0]) * hyper_values[:,1] + regularization_strengths[0]for lr, rs in hyper_values: softmax = Softmax() softmax.train(X_train,y_train,lr,rs,num_iters = 500,verbose = True) train_pred = softmax.predict(X_train) train_acc = np.mean(y_train == train_pred) val_pred = softmax.predict(X_val) val_acc = np.mean(y_val == val_pred) results[(lr,rs)] = (train_acc,val_acc) if val_acc &gt; best_val: best_val = val_acc best_softmax = softmax################################################################################# END OF YOUR CODE ################################################################################# # Print out results.for lr, reg in sorted(results): train_accuracy, val_accuracy = results[(lr, reg)] print('lr %e reg %e train accuracy: %f val accuracy: %f' % ( lr, reg, train_accuracy, val_accuracy)) print('best validation accuracy achieved during cross-validation: %f' % best_val) ÂèØ‰ª•ÁúãÂá∫Êù•ÊÑüËßâsoftmaxÊØîSVMÁöÑÊïàÊûúÂ•Ω‰∏Ä‰∫õÔºüÂèØËßÜÂåñÊúÄÁªàÁöÑ‰ºòÂåñÁöÑweight123456789101112131415# Visualize the learned weights for each classw = best_softmax.W[:-1,:] # strip out the biasw = w.reshape(32, 32, 3, 10)w_min, w_max = np.min(w), np.max(w)classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']for i in range(10): plt.subplot(2, 5, i + 1) # Rescale the weights to be between 0 and 255 wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min) plt.imshow(wimg.astype('uint8')) plt.axis('off') plt.title(classes[i])]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
        <category>CS231n‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>Softmax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫éÊ†áÈáèÔºåÂêëÈáèÔºåÁü©ÈòµÊ±ÇÂØº]]></title>
    <url>%2F2019%2F03%2F30%2F%E5%85%B3%E4%BA%8E%E6%A0%87%E9%87%8F%E5%90%91%E9%87%8F%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[ÂèÇËÄÉÊñáÁ´†Ôºöhttps://blog.csdn.net/u010976453/article/details/54381248 ÂÖ≥‰∫élayoutÂú®Ê±ÇÂØºÁöÑÊó∂ÂÄôÊúâÔºåÂõ†‰∏∫ÂàÜÂ≠êÂíåÂàÜÊØçÂèØËÉΩÁöÑÁª¥Â∫¶‰∏çÂ§™‰∏ÄÊ†∑ÔºåÊâÄ‰ª•‰∏§Áßç‰∏çÂêåÁöÑÂ∏ÉÂ±ÄÔºåÂàÜÂà´ÊòØÂàÜÂ≠êÂ∏ÉÂ±ÄÂíåÂàÜÊØçÂ∏ÉÂ±ÄÂÅáËÆæyÔºàÂêëÈáèÔºâÂØπxÔºàÊ†áÈáèÔºâÊ±ÇÂØºÔºö ÂàÜÂ≠êÂ∏ÉÂ±ÄÔºåÂç≥ÂíåÂéüÊù•ÁöÑyÁõ∏Âêå ÂàÜÊØçÂ∏ÉÂ±ÄÔºå‰∏∫ÂàÜÂ≠êÂ∏ÉÂ±ÄÁöÑtranpose ÂØπÊ†áÈáèÁöÑÂØºÊï∞scalarÂØπscalarÊ±ÇÂØºÂç≥ÊúÄÁÆÄÂçïÁöÑÊ±ÇÂØº vectorÂØπscalarÊ±ÇÂØºÊØîÂ¶Ç‰∏Ä‰∏™ÂàóÂêëÈáèyÔºåÂØπxÊ±ÇÂØºÔºåÁªìÊûúÊòØyÈáåÈù¢ÁöÑÊØè‰∏™ÂÄºÈÉΩÂØπxÊ±ÇÂØº matrixÂØπscalrÊ±ÇÂØºÁü©ÈòµÈáåÈù¢ÁöÑÊØè‰∏™ÂÄºÈÉΩÂØπxÊ±ÇÂØº ÂØπÂêëÈáèÁöÑÂØºÊï∞scalarÂØπvector Ê†áÈáèyÂíåÂêëÈáèxÔºåÊ±ÇÂá∫Êù•ÁöÑÁªìÊûúÊòØyÂØπÊØè‰∏™x(x1,x2 ‚Ä¶.xn)Ê±ÇÂØº ÁªìÊûú‰∏∫Ê¢ØÂ∫¶ÂêëÈáèÔºåÊòØÊ†áÈáèyÂú®Á©∫Èó¥RnÁöÑÊ¢ØÂ∫¶ÔºåÁ©∫Èó¥‰ª•x‰∏∫Âü∫ Ê≥®ÊÑèÔºåxÊòØÂàóÂêëÈáèÁöÑËØùÔºåÊúÄÂêéÊ±ÇÂá∫Êù•ÁöÑÊòØË°åÁöÑÁªìÊûú vectorÂØπvectory = [y1,y2 ‚Ä¶. ym]x = [x1,x2 ‚Ä¶. xn]ÊúÄÂêéÊ±ÇÂá∫Êù•ÁöÑÁªìÊûúÊòØ‰∏Ä‰∏™mË°ånÂàóÁöÑÁü©ÈòµÔºåjacobianÁü©Èòµ matrixÂØπvectorÁü©Èòµy =[[y11,y12‚Ä¶y1n],[y21,y22 ‚Ä¶y2n],‚Ä¶[yn1,yn2 ‚Ä¶ynn]]ÂêëÈáèx = [x1,x2‚Ä¶xn]TÊúÄÁªàÁöÑÁªìÊûúÊòØÊØè‰∏ÄË°åÂàÜÂà´ÂØπËøô‰∏™xÁöÑÂêëÈáèÊ±ÇÂØºÔºåÊâÄ‰ª•Áü©ÈòµÁöÑÂàóÊï∞ÂíåÂêëÈáèÁöÑË°åÊï∞Â∫îËØ•ÂÖàÈÄö ÂØπ‰∫éÁü©Èòµ‰∏ÄËà¨Âè™ËÄÉËôëÊ†áÈáèÂØπÁü©Èòµ(Ââ©‰∏ãÁöÑÊÉÖÂÜµÂíå‰∏äÈù¢Á±ª‰ºº)ÊúÄÁªàÁªìÊûúÊòØËøô‰∏™Ê†áÈáèÂØπÊâÄÊúâÁöÑÁü©ÈòµÂÜÖÂÆπÊ±ÇÂØºÔºåÊ±ÇÂá∫Êù•ÁöÑÊòØÊ¢ØÂ∫¶Áü©Èòµ]]></content>
      <categories>
        <category>Êï∞Â≠¶ÈóÆÈ¢ò</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CS231N‰Ωú‰∏öassignment1‰πãSVMÈÉ®ÂàÜ]]></title>
    <url>%2F2019%2F03%2F29%2FCS231Nassignment1SVM%2F</url>
    <content type="text"><![CDATA[Assignment from: http: // cs231n.github.io / assignments2018 / assignment1/ ÁõÆÊ†áÔºö a fully - vectorized loss function for the SVM fully - vectorized expression for its analytic gradient use a validation set to tune the learning rate and regularization strength optimize the loss function with SGD visualize the final learned weights Set upÈÉ®ÂàÜ1234567891011121314151617181920# Run some setup code for this notebook.from __future__ import print_functionimport randomimport numpy as npfrom cs231n.data_utils import load_CIFAR10import matplotlib.pyplot as plt# This is a bit of magic to make matplotlib figures appear inline in the# notebook rather than in a new window.%matplotlib inlineplt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'# Some more magic so that the notebook will reload external python modules;# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython%load_ext autoreload%autoreload 2 ËØªÂèñCIFAR-10ÁöÑÊï∞ÊçÆÔºåÈ¢ÑÂ§ÑÁêÜ123456789101112131415161718# Load the raw CIFAR-10 data.cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)try: del X_train, y_train del X_test, y_test print('Clear previously loaded data.')except: passX_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)# As a sanity check, we print out the size of the training and test data.print('Training data shape: ', X_train.shape)print('Training labels shape: ', y_train.shape)print('Test data shape: ', X_test.shape)print('Test labels shape: ', y_test.shape) ÁªìÊûúÔºö1234Training data shape: (50000, 32, 32, 3)Training labels shape: (50000,)Test data shape: (10000, 32, 32, 3)Test labels shape: (10000,) ÂèØËßÜÂåñdataset ‰ªéÁ±ªÂûã‰∏≠1234567891011121314151617# Visualize some examples from the dataset.# We show a few examples of training images from each class.classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']num_classes = len(classes)samples_per_class = 7for y, cls in enumerate(classes): idxs = np.flatnonzero(y_train == y) idxs = np.random.choice(idxs, samples_per_class, replace=False) for i, idx in enumerate(idxs): plt_idx = i * num_classes + y + 1 plt.subplot(samples_per_class, num_classes, plt_idx) plt.imshow(X_train[idx].astype('uint8')) plt.axis('off') if i == 0: plt.title(cls)plt.show() 1np.flatnonzero(y_train == y) ËøîÂõûÂÜÖÂÆπÈùû0ÁöÑindex„ÄÇËøôÂè•ÊòØËøîÂõûplaneÁ±ªÂà´ÈáåÈù¢ÁöÑÔºày_train == yÔºâÊâÄÊúâÈùû0ÁöÑÂÜÖÂÆπ„ÄÇÁÑ∂Âêé‰ªéËøô‰∫õÈáåÈù¢ÈöèÊú∫ÈÄâÊã©7‰∏™ÂÜÖÂÆπÔºåÁîªÂá∫Êù•„ÄÇ ÁªìÊûúÂ¶Ç‰∏ãÔºö Ëøõ‰∏ÄÊ≠•ÂàÜ‰∏∫Âá†ÈÉ®ÂàÜ123456789101112131415161718192021222324252627282930313233343536373839# Split the data into train, val, and test sets. In addition we will# create a small development set as a subset of the training data;# we can use this for development so our code runs faster.num_training = 49000num_validation = 1000num_test = 1000# Áî®ËøôÈÉ®ÂàÜÊù•‰ºòÂåñ‰ª£Á†Ånum_dev = 500# Our validation set will be num_validation points from the original# training set.mask = range(num_training, num_training + num_validation)X_val = X_train[mask]y_val = y_train[mask]# Our training set will be the first num_train points from the original# training set.mask = range(num_training)X_train = X_train[mask]y_train = y_train[mask]# We will also make a development set, which is a small subset of# the training set.mask = np.random.choice(num_training, num_dev, replace=False)X_dev = X_train[mask]y_dev = y_train[mask]# We use the first num_test points of the original test set as our# test set.mask = range(num_test)X_test = X_test[mask]y_test = y_test[mask]print('Train data shape: ', X_train.shape)print('Train labels shape: ', y_train.shape)print('Validation data shape: ', X_val.shape)print('Validation labels shape: ', y_val.shape)print('Test data shape: ', X_test.shape)print('Test labels shape: ', y_test.shape) 12mask = range(num_test)X_test = X_test[mask] ÊÑüËßâËøôÊòØ‰∏ÄÁßç‰ªé‰∏Ä‰∏™Êï¥‰Ωì‰∏≠ÈÄâÂèñÂÖ∂‰∏≠‰∏ÄÈÉ®ÂàÜÁöÑ‰ª£Á†Å Â∞ÜimageÊãâÊàêrow1234567891011# Preprocessing: reshape the image data into rowsX_train = np.reshape(X_train, (X_train.shape[0], -1))X_val = np.reshape(X_val, (X_val.shape[0], -1))X_test = np.reshape(X_test, (X_test.shape[0], -1))X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))# As a sanity check, print out the shapes of the dataprint('Training data shape: ', X_train.shape)print('Validation data shape: ', X_val.shape)print('Test data shape: ', X_test.shape)print('dev data shape: ', X_dev.shape) ÂΩìÊÉ≥ÊääÊó†ËÆ∫‰ªª‰ΩïÂ§ßÂ∞èÁöÑ‰∏úË•øÊãâÊàê‰∏ÄÊï¥Ë°åÁöÑÊó∂ÂÄôÔºåÁî®a.reshape(x, -1)„ÄÇ X_train.shape[0]Ë°åÔºåÂàóÊï∞Êú™Áü•Ôºå‰ΩÜÊòØÊãâÂπ≥‰∫Ü Â¶ÇÊûúÊÉ≥ÊãâÊàê‰∏ÄÊï¥ÂàóÁöÑÊó∂ÂÄôÔºåÁî®a.reshape(-1, x)„ÄÇ ÂàóÊï∞‰∏∫xÔºåÊØèÂàóÊúâÂ§öÂ∞ë‰∏úË•øÊú™Áü• È¢ÑÂ§ÑÁêÜÈÉ®ÂàÜÔºöÂáèÂéªmean image Á¨¨‰∏ÄÊ≠•ÔºåÊ±ÇÂá∫ËÆ≠ÁªÉÈõÜÁöÑmeanÂπ∂‰∏îÂèØËßÜÂåñ 12345678# Preprocessing: subtract the mean image# first: compute the image mean based on the training datamean_image = np.mean(X_train, axis=0)print(mean_image[:10]) # print a few of the elementsplt.figure(figsize=(4, 4))plt.imshow(mean_image.reshape((32, 32, 3)).astype( 'uint8')) # visualize the mean imageplt.show() Á¨¨‰∫åÊ≠•Ôºå‰ªétrainÂíåtestÈáåÈù¢ÂáèÂéªÂπ≥ÂùáÊï∞ÊçÆ 12345# second: subtract the mean image from train and test dataX_train -= mean_imageX_val -= mean_imageX_test -= mean_imageX_dev -= mean_image Á¨¨‰∏âÊ≠•ÔºåÊääÈ¢ÑÂ§ÑÁêÜÂ•ΩÁöÑÊâÄÊúâÂõæÁâáÁöÑÊú´Â∞æÔºàÊãâÊàêË°å‰πãÂêéÁöÑÊúÄÂêéÔºâÂä†‰∫Ü‰∏Ä‰∏™1ÔºàbiasÁöÑdimÔºâ 12345678# third: append the bias dimension of ones (i.e. bias trick) so that our SVM# only has to worry about optimizing a single weight matrix W.X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape) np.hstack()ÔºåÊ≤øÁùÄÊ∞¥Âπ≥ÊñπÂêëÊääÊï∞ÁªÑÂè†Ëµ∑Êù•„ÄÇ‰∫éÊ≠§Áõ∏ÂêåÔºånp.vstack()ÔºåÊòØÊ≤øÁùÄÂûÇÁõ¥ÊñπÂêëÊääÊï∞ÁªÑÂè†Ëµ∑Êù•„ÄÇ SVM classifier1cs231n / classifiers / linear_svm.py. svm_loss_naive Êúâ‰∏â‰∏™ËæìÂÖ• XÔºö‰∏Ä‰∏™ÊúâN‰∏™ÂÖÉÁ¥†ÁöÑminibatchÔºåÊØè‰∏™ÂÖÉÁ¥†ÁöÑÂÜÖÂÆπÊòØD(N, D) W: weightsÔºå(D, C), ÂõæÁâáÁöÑÂÜÖÂÆπÊòØDÔºå‰∏ÄÂÖ±C‰∏™classÔºåÊâÄ‰ª•Áî®ÁöÑÊó∂ÂÄôË∑üÊôÆÈÅçÊÉ≥Ê≥ïÁöÑWÊòØtranposeÁöÑ y: Ê†áÁ≠æÔºåÂ§ßÂ∞è(N,) ‰∏ÄÂÖ±NÂº†ÁÖßÁâáÔºåÊØèÂº†ÁÖßÁâáÊúâ‰∏Ä‰∏™Ê†áÁ≠æ ÊúÄÁªàÁªìÊûú ‰∏Ä‰∏™floatÁöÑÁªìÊûúÔºöloss WÁöÑgradient dW Ê≥®ÊÑèÔºåWxÊ±ÇÂá∫Êù•ÁöÑÂ∞±ÊòØ‰∏çÂêåÂàÜÁ±ªÁöÑÁßØÂàÜ dWÁöÑËÆ°ÁÆó(https://blog.csdn.net/zt_1995/article/details/62227201) ÂΩ¢Áä∂ÂæàÂ•áÊÄ™ÁöÑ1(x)ÊåáÁöÑÊòØÔºåÂΩìx‰∏∫ÁúüÁöÑÊó∂ÂÄôÁªìÊûúÊòØ1ÔºåÂΩìx‰∏∫ÂÅáÁöÑÊó∂ÂÄôÁªìÊûúÂèñ0 Á¨¨‰∏Ä‰∏™ÂºèÂ≠êË°®Á§∫Á¨¨i‰∏™Ë¢´Ê≠£Á°ÆÂàÜÁ±ªÁöÑÊ¢ØÂ∫¶ ÊúâÂ§öÂ∞ë‰∏™WjËÆ©Ëøô‰∏™ËæπÁïåÂÄº‰∏çË¢´Êª°Ë∂≥ÔºåÂ∞±ÂØπÊçüÂ§±Ëµ∑‰∫ÜÂ§öÂ∞ëË¥°ÁåÆ ‰πò‰ª•xiÊòØÂõ†‰∏∫xiÂåÖÂê´‰∫ÜÊ†∑Êú¨ÁöÑÂÖ®ÈÉ®ÁâπÂæÅÔºåÊâÄ‰ª•ÂâçÈù¢‰πò‰ª•‰∏Ä‰∏™Á≥ªÊï∞1Â∞±ÂèØ‰ª•‰∫Ü Á¨¶Âè∑ÊòØÂõ†‰∏∫SGDÈááÁî®Ë¥üÊ¢ØÂ∫¶ËøêÁÆó Á¨¨‰∫å‰∏™ÂºèÂ≠êË°®Á§∫‰∏çÊ≠£Á°ÆÂàÜÁ±ªÁöÑÊ¢ØÂ∫¶ÔºåÂè™ÊúâÂú®yi == jÁöÑÊó∂ÂÄôÊâçÊúâË¥°ÁåÆÔºåÊâÄ‰ª•Ê≤°ÊúâÊ±ÇÂíå„ÄÇ‰ΩÜÊòØÊ≥®ÊÑèÔºåÂú®ÊØèÂº†ÂõæÈáåÈù¢ÔºåËøô‰∏™ÈÉΩ‰ºöÂú®j == yiÁöÑÊó∂ÂÄôÂèëÁîü‰∏ÄÊ¨°ÔºåÊâÄ‰ª•ÊØèÂº†ÂõæÁöÑjÈÉ®ÂàÜÈúÄË¶ÅÂä†‰∏äËøô‰∏™ÂÄº ÊúÄÁªàÁöÑÁªìÊûúÈúÄË¶ÅÔºåÈô§‰ª•N Âà´Âøò‰∫ÜÊ≠£ÂàôÂåñÔºÅËÄå‰∏îÁî®2\lanmdaWÊù•Ê≠£ÂàôÂåñÁöÑÊïàÊûúÊõ¥Â•Ω‰∏Ä‰∫õ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051def svm_loss_naive(W, X, y, reg): """ Structured SVM loss function, naive implementation (with loops). Inputs have dimension D, there are C classes, and we operate on minibatches of N examples. Inputs: - W: A numpy array of shape (D, C) containing weights. - X: A numpy array of shape (N, D) containing a minibatch of data. - y: A numpy array of shape (N,) containing training labels; y[i] = c means that X[i] has label c, where 0 &lt;= c &lt; C. - reg: (float) regularization strength Returns a tuple of: - loss as single float - gradient with respect to weights W; an array of same shape as W """ dW = np.zeros(W.shape) # initialize the gradient as zero # compute the loss and the gradient num_classes = W.shape[1] # ÊúâÂ§öÂ∞ëÈúÄË¶ÅËÆ≠ÁªÉÁöÑ‰∏™Êï∞ num_train = X.shape[0] loss = 0.0 for i in range(num_train): scores = X[i].dot(W) correct_class_score = scores[y[i]] for j in range(num_classes): # Â¶ÇÊûúËøô‰∏™Á±ªÂûãÊòØÊ≠£Á°ÆÁöÑÔºåÈÇ£Â∞±‰∏çÁî®ÁÆ°‰∫Ü if j == y[i]: continue margin = scores[j] - correct_class_score + 1 # note delta = 1 if margin &gt; 0: loss += margin dW[:, y[i]] += -X[i] dW[:, j] += X[i] # Right now the loss is a sum over all training examples, but we want it # to be an average instead so we divide by num_train. loss /= num_train dW /= num_train # Add regularization to the loss. # regÊòØlanbda loss += reg * np.sum(W * W) dW += 2 * reg * W return loss, dW svm_loss_vectorizedÈÄöËøáÂêëÈáèÂåñÊù•ÊèêÈ´òËÆ°ÁÆóÈÄüÂ∫¶ ËÆ°ÁÆólossÈÉ®ÂàÜ WÊòØ‰∏Ä‰∏™(D, C)ÁöÑÂêëÈáèÔºåXÊòØ(N, D)ÁöÑÔºåÊâÄ‰ª•‰∏§ËÄÖÁõ∏‰πòÂèØ‰ª•ÂæóÂà∞‰∏Ä‰∏™(N, C)ÁöÑÁü©ÈòµÔºåN‰∏∫ÂõæÁâáÊï∞ÈáèÔºåCÊòØÊØèÂº†ÂõæÁâáÂØπ‰∫é‰∏çÂêåÂàÜÁ±ªÁöÑscore Âú®score‰∏≠ÂèñÊØè‰∏ÄË°åÁöÑy‰∏≠labelÈÉ®ÂàÜÂ∞±ÊòØËøôÂº†ÂõæÊ≠£Á°ÆÁ±ªÂûãÁöÑËØÑÂàÜ ÊääÊï¥‰ΩìÁöÑscoreÁü©ÈòµÁöÑÊâÄÊúâÈ°πÂáèÂéªÊ≠£Á°ÆËØÑÂàÜÁöÑÁü©ÈòµÔºàÂ∫îËØ•ÂèØ‰ª•ÂπøÊí≠‰ΩÜÊòØÊàëÂàöÂºÄÂßãÁî®repeatÂíåreshapeÂ§çÂà∂‰∫Ü‰∏Ä‰∏ãÔºâÔºåÂáèÂéªÁöÑÁªìÊûúÂ∞±ÊòØsvm‰∏≠ÈúÄË¶ÅÂíå0ÊØîÁöÑÂÄºÔºàmarginÔºâ ‰∏∫‰∫ÜÊ±ÇlossÔºåÊääÂ∞è‰∫é0ÁöÑÈ°πÁõÆÂíåÊ≠£Á°ÆÁöÑÈ°πÈô§ÂéªÔºàÈÉΩËÆæÁΩÆÊàê0Ôºâ ÁÑ∂ÂêéË°åÊ±ÇÂíåÔºåÂàóÊ±ÇÂíåÔºåÈô§‰ª•Êï¥‰ΩìÁöÑ‰∏™Êï∞Ôºåregularzation ËÆ°ÁÆódWÈÉ®ÂàÜ X.TÁÇπ‰πòmarginÂæóÂà∞ÁöÑÂ∞±ÊòØÊúÄÁªàÁöÑlossÔºåÊâÄ‰ª•ÈúÄË¶ÅÊääÊØè‰∏™marginÈáåÈù¢Á¨¶ÂêàÊù°‰ª∂ÁöÑÊï∞ÂØπ‰∫Ü ÊâÄÊúâÊØî0Â§ßÁöÑÊó∂ÂÄôÈÉΩÁÆó1ÔºàÊ†πÊçÆÂØºÊï∞ÁöÑËÆ°ÁÆóÁªìÊûúÔºâ ÂΩìÂ∫îËØ•Âà§Êñ≠Ê≠£Á°ÆÁöÑÁ±ªÂûãÊØî0Â§ßÁöÑÊó∂ÂÄôÔºåËøô‰∏™‰∏úË•ø‰ºöÂú®ÊØèÊ¨°ËÆ°ÁÆóÂØºÊï∞ÁöÑÊó∂ÂÄôÈÉΩÁÆó‰∏ä‰∏ÄÊ¨°ÔºåÊâÄ‰ª•ÊòØË°åÁöÑÂêà ÊúÄÂêé‰πòÂÆå‰πãÂêéÈô§‰ª•ÊÄªÁöÑ‰∏™Êï∞ÔºåÂÜçregularzation1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def svm_loss_vectorized(W, X, y, reg): """ Structured SVM loss function, vectorized implementation. Inputs and outputs are the same as svm_loss_naive. """ loss = 0.0 dW = np.zeros(W.shape) # initialize the gradient as zero ############################################################################# # TODO: # # Implement a vectorized version of the structured SVM loss, storing the # # result in loss. # ############################################################################# num_train = X.shape[0] num_classes = W.shape[1] scores = X.dot(W) # ËøôÈáåÊòØÂèñÁ¨¨NË°åÔºàÂõæÁâáË°åÔºâÁöÑÁ¨¨C‰∏™ÔºàclassÂàóÔºâÔºåÂæóÂà∞ÁöÑÊòØÔºà500ÔºåÔºâÁöÑÊ≠£Á°ÆÁ±ªÁöÑscoreÁöÑÁü©Èòµ correct_class_score = scores[np.arange(num_train), y] # correct_class_score = np.repeat(correct_class_score, num_classes) # correct_class_score = correct_class_score.reshape(num_train, num_classes) # DxC margin = scores - correct_class_score + 1.0 margin[np.arange(num_train), y] = 0.0 margin[margin &lt;= 0] = 0.0 loss += np.sum(np.sum(margin, axis=1)) / num_train # loss /= num_train loss += 0.5 * reg * np.sum(W * W) margin[margin &gt; 0] = 1.0 calculate_times = np.sum(margin, axis=1) margin[np.arange(num_train), y] = - calculate_times dW = np.dot(X.T, margin) / num_train dW += 2 * reg * W ############################################################################# # END OF YOUR CODE # ############################################################################# return loss, dW Áé∞Âú®ÂæóÂà∞‰∫ÜdWÂíålossÔºå‰ΩøÁî®SGDÊù•ÂáèÂ∞ëlossËÆ≠ÁªÉ Â∞ÜÊï¥‰ΩìÂàÜÊàê‰∏çÂêåÁöÑminibatchÔºå‰ΩøÁî®np.random.choiceÔºåÊ≥®ÊÑèÂêéÈù¢ÁöÑreplceÂèØ‰ª•ÈÄâTrueÔºåËøôÊ†∑‰ºöÈáçÂ§çÈÄâÊã©ÂÖÉÁ¥†‰ΩÜÊòØÁªìÊûúÈÄüÂ∫¶Â•ΩÂÉèÊòØÊõ¥Âø´‰∫Ü Â∞ÜminibatchÁöÑÁªìÊûúËÆ°ÁÆólossÂíågradientÔºåÁÑ∂Âêégrad * learning rateÊù•updateÊï∞ÊçÆ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100, batch_size=200, verbose=False): """ Train this linear classifier using stochastic gradient descent. Inputs: - X: A numpy array of shape (N, D) containing training data; there are N training samples each of dimension D. - y: A numpy array of shape (N,) containing training labels; y[i] = c means that X[i] has label 0 &lt;= c &lt; C for C classes. - learning_rate: (float) learning rate for optimization. - reg: (float) regularization strength. - num_iters: (integer) number of steps to take when optimizing - batch_size: (integer) number of training examples to use at each step. - verbose: (boolean) If true, print progress during optimization. Outputs: A list containing the value of the loss function at each training iteration. """ num_train, dim = X.shape # assume y takes values 0...K-1 where K is number of classes num_classes = np.max(y) + 1 if self.W is None: # lazily initialize W self.W = 0.001 * np.random.randn(dim, num_classes) # Run stochastic gradient descent to optimize W loss_history = [] for it in range(num_iters): X_batch = None y_batch = None ######################################################################### # TODO: # # Sample batch_size elements from the training data and their # # corresponding labels to use in this round of gradient descent. # # Store the data in X_batch and their corresponding labels in # # y_batch; after sampling X_batch should have shape (dim, batch_size) # # and y_batch should have shape (batch_size,) # # # # Hint: Use np.random.choice to generate indices. Sampling with # # replacement is faster than sampling without replacement. # ######################################################################### indices = np.random.choice(num_train, batch_size, replace=True) X_batch = X[indices] y_batch = y[indices] ######################################################################### # END OF YOUR CODE # ######################################################################### # evaluate loss and gradient loss, grad = self.loss(X_batch, y_batch, reg) loss_history.append(loss) # perform parameter update ######################################################################### # TODO: # # Update the weights using the gradient and the learning rate. # ######################################################################### self.W += - learning_rate * grad ######################################################################### # END OF YOUR CODE # ######################################################################### if verbose and it % 100 == 0: print('iteration %d / %d: loss %f' % (it, num_iters, loss)) return loss_history È¢ÑÊµãÁªìÊûú Â∑≤ÁªèÊúâ‰∫ÜÂâçÈù¢ÁöÑÂà∞ÁöÑËÆ≠ÁªÉËøáÁöÑWÔºàself.WÔºâ WxÁÆóÂá∫Êù•ÁöÑÂ∞±ÊòØÂàÜÊï∞ ‰ªéÊØè‰∏ÄË°åÈáåÈù¢ÈÄâÊã©ÊúÄÂ§ßÁöÑÂàÜÊï∞Â∞±ÊòØÈ¢ÑÊµãÁöÑÁªìÊûú123456789101112131415161718192021222324252627def predict(self, X): """ Use the trained weights of this linear classifier to predict labels for data points. Inputs: - X: A numpy array of shape (N, D) containing training data; there are N training samples each of dimension D. Returns: - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional array of length N, and each element is an integer giving the predicted class. """ y_pred = np.zeros(X.shape[0]) ########################################################################### # TODO: # # Implement this method. Store the predicted labels in y_pred. # ########################################################################### scores = X.dot(self.W) y_pred = np.argmax(scores, axis=1) # print(labels.shape) # print(labels) ########################################################################### # END OF YOUR CODE # ########################################################################### return y_pred ‰∫§ÂèâÈ™åËØÅ Âú®‰Ωú‰∏öÈáåÔºåÈúÄË¶ÅÈÄâÊã©‰∏§‰∏™hyperÁöÑÂÄºÔºåÂàÜÂà´ÊòØÂ≠¶‰π†ÁéáÂíåregularzationÁöÑÂèÇÊï∞ÔºåÊ≤°ÊúâÈááÁî®‰∫§ÂèâÈ™åËØÅÔºå‰ΩÜÊòØÈááÁî®‰∫ÜÈöèÊú∫ÊêúÁ¥¢Ôºå‰ºöÊØîgrid searchÊõ¥ÂáÜÁ°Æ‰∏Ä‰∫õ ÈááÁî®‰∏çÂêåÁöÑÂèÇÊï∞ÁªÑÂêàÂàÜÂà´ËÆ≠ÁªÉËøô‰∏™Ê®°ÂûãÔºåÁÑ∂ÂêéÂæóÂà∞ÂêÑËá™Âú®validation‰∏äÈù¢ÁöÑÂáÜÁ°ÆÁéáÔºåËøô‰∏™ÂæóÂà∞ÂáÜÁ°ÆÁéáÊúÄÂ§ßÁöÑÁªÑÂêàÁöÑÂèÇÊï∞ Ê≥®ÊÑèÔºåÂú®È™åËØÅÁöÑËøáÁ®ã‰∏≠Â∫îËØ•ÈÄâÊã©iterÁöÑÊ¨°Êï∞Â∞ë‰∏ÄÁÇπÔºå‰∏çÁÑ∂ËÆ≠ÁªÉÁöÑÊó∂Èó¥‰ºöÈùûÂ∏∏Èïø Âú®Ëøô‰∏™‰ª£Á†ÅÈáåÁî®‰∫ÜrandÊù•ÂæóÂà∞0Âà∞1‰πãÈó¥ÁöÑÈöèÊú∫Êï∞ÔºåËøô‰∏™Êï∞‰πò‰ª•hyperÁöÑËåÉÂõ¥ÁöÑÂ∑ÆÔºåÁÑ∂ÂêéÂÜçÂä†‰∏ä‰∏ãÈôêÔºåÂ∞±ÊòØÈöèÊú∫ÂæóÂà∞ÁöÑÊúÄÁªàÁªìÊûú 1234567891011121314rand_turple = np.random.rand(50,2)rand_turple[:,0] = rand_turple[:,0]*(learning_rates[1]-learning_rates[0]) + learning_rates[0]rand_turple[:,1] = rand_turple[:,1]*(regularization_strengths[1]-regularization_strengths[0])+regularization_strengths[0]for lr,rs in rand_turple: svm = LinearSVM() svm.train(X_train, y_train, learning_rate=lr, reg=rs,num_iters=1500, verbose=True) y_train_pred = svm.predict(X_train) train_acc = np.mean(y_train == y_train_pred) y_val_pred = svm.predict(X_train) val_acc = np.mean(y_train == y_val_pred) results[(lr,rs)] = (train_acc,val_acc) if (val_acc &gt; best_val): best_val = val_acc best_svm = svm ÁªìÊûúÂèØËßÜÂåñ123456789101112131415# Visualize the learned weights for each class.# Depending on your choice of learning rate and regularization strength, these may# or may not be nice to look at.w = best_svm.W[:-1,:] # strip out the biasw = w.reshape(32, 32, 3, 10)w_min, w_max = np.min(w), np.max(w)classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']for i in range(10): plt.subplot(2, 5, i + 1) # Rescale the weights to be between 0 and 255 wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min) plt.imshow(wimg.astype('uint8')) plt.axis('off') plt.title(classes[i])]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
        <category>CS231n‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>SVM</tag>
        <tag>SGD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TypeError:'method' object is not subscriptable]]></title>
    <url>%2F2019%2F03%2F26%2Fmethod%E4%B8%8D%E6%98%AFsubscripatable%2F</url>
    <content type="text"><![CDATA[ÈÅ≠ÈÅáÈóÆÈ¢òTypeError: ‚Äòmethod‚Äô object is not subscriptableÊòØÂõ†‰∏∫ÊàëÊú¨Êù•ÂÜô‰∫Ü‰∏Ä‰∏™classÁöÑmethod123def get_page(self, num):num = int(num)return self.pages[num] ‰ΩÜÊòØÂú®Ë∞ÉÁî®ÁöÑÊó∂ÂÄôÊàëÁî®‰∫Ü12get_page[i]get_page(i) #ËøôÊ†∑ÊâçÊòØÊ≠£Á°ÆÁöÑ ÊâæÂà∞Êä•ÈîôÊîπÊã¨Âè∑Â∞±Ë°å‰∫ÜÔºÅ]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[enumerateÊûö‰∏æ]]></title>
    <url>%2F2019%2F03%2F25%2Fenumerate%E6%9E%9A%E4%B8%BE%2F</url>
    <content type="text"><![CDATA[enumerate()Êûö‰∏æÂØπÂèØËø≠‰ª£ÁöÑÊï∞ÊçÆËøõË°åÊ†áÂè∑Âπ∂Â∞ÜÂÖ∂ÈáåÈù¢ÁöÑÊï∞ÊçÆÂíåÊ†áÂè∑‰∏ÄÂπ∂ÊâìÂç∞Âá∫Êù•„ÄÇ1enumerate(iterable, start=0) iterable: ÂèØËø≠‰ª£ÁöÑÊï∞ÊçÆÔºåÊØîÂ¶Çlist start: ÊâìÂç∞ÁöÑÂàùÂßãÂÄºÔºåÈªòËÆ§‰ªé0ÂºÄÂßãÊâìÂç∞ 123test = [[11], [21], [31], [41]]for i, cnt in enumerate(test):print(i, cnt) ÁªìÊûú‰∏∫12340 [11]1 [21]2 [31]3 [41]]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PythonÁöÑNoneÂíåifÁöÑÁêÜËß£]]></title>
    <url>%2F2019%2F03%2F25%2FPython%E7%9A%84None%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[pythonÂØπÂèòÈáèNoneÁöÑÂà§Êñ≠NoneÊòØ‰∏ÄÁßçÊï∞ÊçÆÁ±ªÂûãÔºÅÔºÅÔºÅ12&gt;&gt;&gt;type(None)&lt;class 'NoneType'&gt; ËØ¥ÊòéËØ•ÂÄºÊòØ‰∏Ä‰∏™Á©∫ÁöÑÂØπË±°ÔºåÊòØPythonÈáåÈù¢ÁöÑÁâπÊÆäÁöÑÂÄºÔºåË∑üNULL‰∏ç‰∏ÄÊ†∑ÔºåË∑ü0‰πü‰∏ç‰∏ÄÊ†∑ 123456a = Noneb = []if a is None or b is None:print("yahaha")else:print("wocao") ÁªìÊûú‰∏∫‚Äúyahaha‚Äù Ê≥®ÊÑèÔºöÂú®ifÁöÑÊÉÖÂÜµ‰∏ãÔºå‰ΩøÁî®NoneÊúâÊó∂ÂÄôÂèØ‰ª•Ëµ∑Âà∞ÂæàÂ•ΩÁöÑ‰ΩúÁî®1if a is None: ‰∏éËøô‰∏™Â∑Æ‰∏çÂ§öÁöÑÁî®Ê≥ïÊòØ1if not a: Âú®pythonÈáåÈù¢ÔºåNoneÔºåÁ©∫ÂàóË°®[]ÔºåÂ≠óÂÖ∏{},tuple()Ôºå0Á≠âÈÉΩ‰ºöË¢´ËΩ¨ÂåñÊàêfalseÔºåÂâ©‰∏ãÁöÑ‰∏∫trueÊØîÂ¶ÇÔºö12345a = Noneif a:print("yahaha")else:print("wocao") ËøôÊó∂ÂÄôÁöÑËæìÂá∫ÊòØwocaoÔºåÂõ†‰∏∫aË¢´ËÆ§‰∏∫ÊòØfalse]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[np.deleteÂà†Èô§Êï∞ÁªÑÂÜÖÂÆπ]]></title>
    <url>%2F2019%2F03%2F25%2Fnp-delete%E5%88%A0%E9%99%A4%E6%95%B0%E7%BB%84%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[np.deletenumpy.delete(arr, obj, axis=None) ËøîÂõû‰∏Ä‰∏™Êñ∞ÁöÑarrayÔºåÂà†Èô§ÊéâobjÔºåÊ≤øÁùÄaxisÊñπÂêë axis : int, optional The axis along which to delete the subarray defined by obj. If axis is None, obj is applied to the flattened array.(Â¶ÇÊûú‰∏çÂä†‰∏äaxisÁöÑËØù‰ºöËá™Âä®ÊääËøô‰∏™arrayÊãâÂπ≥) axis = 0ÔºöÂà†Èô§Êï∞ÁªÑÁöÑË°å axis = 1: Âà†Èô§Êï∞ÁªÑÁöÑÂàó axis = none: ÊääÊï¥‰∏™Êï∞ÁªÑÂπ≥Èì∫‰πãÂêéÊåâÁ¥¢ÂºïÂà†Èô§ 123456789101112import numpy as npids = [[3], [34], [5]]ids_o = [[3], [31]]remove_list = filter(lambda i: i not in ids, ids_o)# print(np.asarray(ids))for i in remove_list:index = np.where(np.asarray(ids_o) == i)[0]print("index = ", index)ids = np.delete(ids, index, axis = 0)print("new ids = \n", ids) ÁªìÊûúÔºö1234index = [1]new ids = [[3][5]] Â¶ÇÊûúÊää‰∏äÈù¢ÊîπÊàê1ids = np.delete(ids, 0, axis = 1) Âç≥‰∏∫Âà†Èô§Êï∞ÁªÑÁöÑÁ¨¨0ÂàóÔºåÁªìÊûúÊòØ [ ] ÔºàÂõ†‰∏∫Âè™Êúâ‰∏ÄÂàóÔºâ Â¶ÇÊûúÊîπÊàê1ids = np.delete(ids, index, axis = None) ÁªìÊûú‰∏∫Ôºö12new ids = [3 5]]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[np.whereÊü•ÊâæÁ¥¢Âºï]]></title>
    <url>%2F2019%2F03%2F25%2Fnp-where%E6%9F%A5%E6%89%BE%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[np.wherenp.where(condition, x, y)Êª°Ë∂≥Êù°‰ª∂(condition)ÔºåËæìÂá∫xÔºå‰∏çÊª°Ë∂≥ËæìÂá∫y„ÄÇ123np.where([[True,False], [True,True]], # ÂÆòÁΩë‰∏äÁöÑ‰æãÂ≠ê[[1,2], [3,4]],[[9,8], [7,6]]) ËæìÂá∫12array([[1, 8],[3, 4]]) ‰∏äÈù¢Ëøô‰∏™‰æãÂ≠êÁöÑÊù°‰ª∂‰∏∫[[True,False], [True,False]]ÔºåÂàÜÂà´ÂØπÂ∫îÊúÄÂêéËæìÂá∫ÁªìÊûúÁöÑÂõõ‰∏™ÂÄº„ÄÇÁ¨¨‰∏Ä‰∏™ÂÄº‰ªé[1,9]‰∏≠ÈÄâÔºåÂõ†‰∏∫Êù°‰ª∂‰∏∫TrueÔºåÊâÄ‰ª•ÊòØÈÄâ1„ÄÇÁ¨¨‰∫å‰∏™ÂÄº‰ªé[2,8]‰∏≠ÈÄâÔºåÂõ†‰∏∫Êù°‰ª∂‰∏∫FalseÔºåÊâÄ‰ª•ÈÄâ8ÔºåÂêéÈù¢‰ª•Ê≠§Á±ªÊé®ËøôÈáåÁöÑtrueÊåáÁöÑÂ∞±ÊòØÈÄâÂâçÈù¢ÁöÑÔºåfalseÂ∞±ÊòØÊåáÈÄâÂêéÈù¢ÁöÑ 1234567&gt;&gt;&gt; a = 10&gt;&gt;&gt; np.where([[a &gt; 5,a &lt; 5], [a == 10,a == 7]],[["chosen","not chosen"], ["chosen","not chosen"]],[["not chosen","chosen"], ["not chosen","chosen"]])array([['chosen', 'chosen'],['chosen', 'chosen']], dtype='&lt;U10') np.where(condition)Âè™ÊúâÊù°‰ª∂ (condition)ÔºåÊ≤°ÊúâxÂíåyÔºåÂàôËæìÂá∫Êª°Ë∂≥Êù°‰ª∂ (Âç≥Èùû0) ÂÖÉÁ¥†ÁöÑÂùêÊ†áÔºàÊ≥®ÊÑèËøôÈáåËøîÂõûÁöÑÊòØÂùêÊ†áÔºâ12345&gt;&gt;&gt; a = np.array([2,4,6,8,10])&gt;&gt;&gt; np.where(a &gt; 5) # ËøîÂõûÁ¥¢Âºï(array([2, 3, 4]),) &gt;&gt;&gt; a[np.where(a &gt; 5)] # Á≠â‰ª∑‰∫é a[a&gt;5]array([ 6, 8, 10]) 123456789101112131415161718&gt;&gt;&gt; a = np.arange(27).reshape(3,3,3)&gt;&gt;&gt; aarray([[[ 0, 1, 2],[ 3, 4, 5],[ 6, 7, 8]],[[ 9, 10, 11],[12, 13, 14],[15, 16, 17]],[[18, 19, 20],[21, 22, 23],[24, 25, 26]]])&gt;&gt;&gt; np.where(a &gt; 5)(array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]),array([2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2]),array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])) Ê≥®ÊÑèËøôÈáåÁöÑÊúÄÁªàÁªìÊûúÁöÑÂùêÊ†áÊòØË¶ÅÁ´ñÁùÄÁúãÁöÑÔºåÂç≥Ôºà0Ôºå2Ôºå0ÔºâÔºåÔºà0Ôºå2Ôºå1Ôºâ‚Ä¶. Ëøô‰∏™ÊñπÊ≥ïÂè™ËÉΩÁî®Âú®array‰∏äÈù¢ÔºåÂ¶ÇÊûúÈúÄË¶ÅlistÁöÑËØùÈúÄË¶Ånp.asarray 12345678910import numpy as npids = [[3], [34], [5]]ids_o = [[3]]remove_list = filter(lambda i: i not in ids_o, ids)print(np.asarray(ids))for i in remove_list:index = np.where(np.asarray(ids) == i)print(index) ÁªìÊûú123456[[ 3][34][ 5]](array([1]), array([0]))(array([2]), array([0]))[Finished in 0.2s]]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PythonÁöÑfilterÂáΩÊï∞]]></title>
    <url>%2F2019%2F03%2F25%2FPython%E7%9A%84filter%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[python filterfilter() ÂáΩÊï∞Áî®‰∫éËøáÊª§Â∫èÂàóÔºåËøáÊª§Êéâ‰∏çÁ¨¶ÂêàÊù°‰ª∂ÁöÑÂÖÉÁ¥†ÔºåËøîÂõûÁî±Á¨¶ÂêàÊù°‰ª∂ÂÖÉÁ¥†ÁªÑÊàêÁöÑÊñ∞ÂàóË°®„ÄÇ ËØ•Êé•Êî∂‰∏§‰∏™ÂèÇÊï∞ÔºåÁ¨¨‰∏Ä‰∏™‰∏∫ÂáΩÊï∞ÔºåÁ¨¨‰∫å‰∏™‰∏∫Â∫èÂàóÔºåÂ∫èÂàóÁöÑÊØè‰∏™ÂÖÉÁ¥†‰Ωú‰∏∫ÂèÇÊï∞‰º†ÈÄíÁªôÂáΩÊï∞ËøõË°åÂà§ÔºåÁÑ∂ÂêéËøîÂõû True Êàñ FalseÔºåÊúÄÂêéÂ∞ÜËøîÂõû True ÁöÑÂÖÉÁ¥†ÊîæÂà∞Êñ∞ÂàóË°®‰∏≠„ÄÇ ËøîÂõûÂÄºÊòØfliterÁöÑÁ±ªÂûã1remove_list = filter(lambda i: i not in ids_o,ids_u) ÂØπ‰∫é‰∏çÂú®ids_oÈáåÈù¢ÁöÑiÔºåÊòØ‰∏çÊòØÂú®ids_uÈáåÈù¢ÔºåÂ¶ÇÊûúÊòØÁöÑËØùÂ∞±ÈúÄË¶ÅremoveËøôÈÉ®ÂàÜ‰∏úË•ø]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tuple,array,listÁöÑÂ§ßÂ∞èÈóÆÈ¢ò]]></title>
    <url>%2F2019%2F03%2F22%2Ftuple-array-list%E7%9A%84%E5%A4%A7%E5%B0%8F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[ÊØèÊ¨°Âú®‰ΩøÁî®ËøôÁæ§‰π±‰∏ÉÂÖ´Á≥üÁöÑÊï∞ÊçÆÁªìÊûÑÁöÑÊó∂ÂÄôÊàëÈÉΩ‰∏çÊòéÁôΩÂà∞Â∫ïÁî®Âì™‰∏™ÂáΩÊï∞Ê±ÇÈïøÂ∫¶ÔºåËÄå‰∏îÂêÑ‰∏™ÁªìÊûÑÁöÑË°®Á§∫ÊñπÊ≥ïÊØèÊ¨°ÈÉΩËÆ©ÊàëÊÑüËßâÂæàËø∑Ëå´ÔºåÊâÄ‰ª•Êúâ‰∫ÜËøôÁØáÊñáÁ´†„ÄÇ Â•ΩÂÉèÂè™ÊúâarrayÂèØ‰ª•Áî®shapeÊù•Ê±ÇÔºÅÂÖ∂‰ªñÁöÑÈÉΩÊ≤°ÊúâshapeÔºåarrayÁöÑshapeÂèØËÉΩÊòØÂ§öÁª¥ÁöÑ„ÄÇ Êï∞ÁªÑarray Êï∞ÁªÑÁöÑË°®Á§∫ÊñπÊ≥ï‰∏∫ÊúÄÂ§ñÈù¢ÊòØÊã¨Âè∑ÔºåÈáåÈù¢ÊòØÊñπÊã¨Âè∑Ôºå‰∏çÂêåÁöÑÊñπÊã¨Âè∑‰ª£Ë°®‰∏çÂêåÁöÑÁª¥Â∫¶ÔºånpÊìç‰ΩúÁöÑÈÉΩÊòØarrayÁöÑÈÉ®ÂàÜ Â¶ÇÊûúÊòØ‰∏ÄÁª¥Êï∞ÁªÑÔºåÊòæÁ§∫Âá∫Êù•ÁöÑsizeÂ∫îËØ•ÊòØ(1,)Ëøô‰∏™Ê†∑Â≠êÁöÑ sizeÊñπÊ≥ï1a.size 1np.size(a) len‰∏çÂèØ‰ª•ÂæóÂà∞Êï¥‰∏™ÁöÑÂ§ßÂ∞èÔºå‰ΩÜÊòØÂèØ‰ª•ÂæóÂà∞Êï∞ÁªÑÁöÑË°åÊï∞ÔºåÁõ∏ÂΩì‰∫éa.shape[0]1len(a) 1a.shape[ÁúãÁúãÊ±ÇÁöÑÊòØÁ¨¨Âá†Áª¥] ÂàóË°® ÂàóË°®ÊúÄÂ§ñÈù¢ÊòØÊñπÊã¨Âè∑Ôºå‰∏çÊòØÂúÜÊã¨Âè∑ÔºÅ ‰∏çÂèØ‰ª•Áõ¥Êé•Áî® a.size Ê±ÇÔºå‚Äôlist‚Äô object has no attribute ‚Äòsize‚Äô 1np.size(List) 1len(List) ÂÖÉÁªÑ ÂÖÉÁªÑÁöÑÊúÄÂ§ñÈù¢ÊòØÂúÜÊã¨Âè∑ ‰∏çÂèØ‰ª•ÈÄöËøá t.size Êù•ËÆøÈóÆ ÂèØ‰ª•ÈÄöËøá Tuple[]Áõ¥Êé•ËÆøÈóÆÂÖÉÁ¥† 1np.size(Tuple) 1len(Tuple) Â≠óÂÖ∏ Â§ñÈù¢ÊòØÂ§ßÊã¨Âè∑ÔºåÈáåÈù¢ÊòØvalue-keyÁöÑÈÖçÂØπ size‰∏çÂèØ‰ª•Áî®Ôºånp.sizeÊó†Ê≥ïËé∑ÂæóÁúüÂÆûÁöÑÂ§ßÂ∞è 1len(Dict)]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Âú®python‰∏≠Ë∞ÉÁî®Âè¶Â§ñÁöÑÊñá‰ª∂]]></title>
    <url>%2F2019%2F03%2F22%2F%E5%9C%A8python%E4%B8%AD%E8%B0%83%E7%94%A8%E5%8F%A6%E5%A4%96%E7%9A%84%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[ÂÖ≥‰∫éÂ¶Ç‰ΩïÂú®python‰∏≠Ë∞ÉÁî®ÂÖ∂‰ªñÁöÑÊñá‰ª∂Âú®cppÈáåÈù¢ÊòØ‰ΩøÁî®Â§¥Êñá‰ª∂Êù•ÂØºÂÖ•ÁöÑÔºå‰ΩÜÊòØÊèêÂà∞pythonÁ™ÅÁÑ∂Ê≤°ÊÉ≥Ëµ∑Êù•ÊòØÊÄé‰πàÂØºÂÖ•ÁöÑ„ÄÇÂÅáËÆæÊúâÊñá‰ª∂a.pyÂíåb.py Âú®Âêå‰∏ÄÁõÆÂΩï‰∏ã12import aa.func() ÊàñËÄÖÂºïÁî®Ê®°Âùó‰∏≠ÁöÑÂáΩÊï∞123from a import funcfunc() ` Ê≥®ÊÑèÔºöÂâçÈù¢‰∏ÄÁßçÊñπÊ≥ïÂØºÂÖ•ÁöÑÊó∂ÂÄôÈúÄË¶ÅÂä†‰∏äÊ®°ÂùóÁöÑÂêçÁß∞ÈôêÂÆöÔºå‰ΩÜÊòØÂêéÈù¢ÁöÑÂØºÂÖ•Â∞±‰∏çÁî®„ÄÇÂ¶ÇÊûúÊÄïÈ∫ªÁÉ¶ÂèØ‰ª•ÂØºÂÖ•ÁöÑÊó∂ÂÄô‰ΩøÁî®1from a import * Âú®‰∏çÂêåÁõÆÂΩï‰∏ãsys.pathËé∑ÂèñÊåáÂÆöÊ®°ÂùóÊêúÁ¥¢Ë∑ØÂæÑÁöÑÂ≠óÁ¨¶‰∏≤ÈõÜÂêàÔºåÂèØ‰ª•Â∞ÜÂÜôÂ•ΩÁöÑÊ®°ÂùóÊîæÂú®ÂæóÂà∞ÁöÑÊüê‰∏™Ë∑ØÂæÑ‰∏ãÔºåÂ∞±ÂèØ‰ª•Âú®Á®ãÂ∫è‰∏≠importÊó∂Ê≠£Á°ÆÊâæÂà∞1234import syssys.path.append('aÊâÄÂú®ÁöÑË∑ØÂæÑ')import aa.func() sysÊòØ‰ªÄ‰πà sysÊòØpythonÁ®ãÂ∫èÁî®Êù•ËØ∑Ê±ÇËß£ÈáäÂô®Ë°å‰∏∫ÁöÑinterfaceÔºåÊØîÂ¶ÇË∞ÉËØïÔºåÂÆûÊó∂ËøêË°åÁéØÂ¢ÉÁ≠â sys.argv ‰ªéÂ§ñÈÉ®ÂêëÁ®ãÂ∫èÂÜÖÈÉ®‰º†ÈÄíÂèÇÊï∞12345#!/usr/bin/env pythonimport sysprint sys.argv[0]print sys.argv[1] ËøêË°åÔºö123# python sys.py argv1sys.pyargv1 sys.exit() ÈúÄË¶Å‰∏≠ÈÄîÈÄÄÂá∫ÁöÑÊó∂ÂÄôÂèØ‰ª•Ë∞ÉÁî®ÔºåÂèØ‰ª•ËøîÂõûÂèÇÊï∞Ôºà0ÊòØÊ≠£Â∏∏ÈÄÄÂá∫ÔºåÂÖ∂‰ªñÊòØÂºÇÂ∏∏Ôºâ12345678910111213141516#!/usr/bin/env pythonimport sysdef exitfunc(value): print value sys.exit(0)print "hello"try: sys.exit(1)except SystemExit,value: exitfunc(value)print "come?" 123# python exit.pyhello1]]></content>
      <categories>
        <category>ÁºñÁ®ãËØ≠Ë®Ä</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂÖ≥‰∫éhexoÂíågitpageÁöÑÂçöÂÆ¢Êê≠Âª∫‰ª•ÂèäËÆæÁΩÆ]]></title>
    <url>%2F2019%2F03%2F20%2F%E5%85%B3%E4%BA%8Ehexo%E5%92%8Cgitpage%E7%9A%84%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%8F%8A%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Âú®commit‰∫Ü40Â§öÊ¨°‰πãÂêéÁªà‰∫éÊääËá™Â∑±ÁöÑÂçöÂÆ¢Êê≠Â•Ω‰∫ÜÔºå‰∏≠Èó¥ÁîªÈÅáÂà∞‰∫Ü‰∏Ä‰∫õÂ•áÊÄ™ÁöÑÈóÆÈ¢òËÆ∞ÂΩï‰∏Ä‰∏ã githubÈÉ®ÂàÜ Âú®‰∏Ä‰∫õÂú∞ÊñπÁúãÂà∞ÁöÑËØ¥ÁΩëÁ´ôÁöÑÂêçÂ≠óÂøÖÈ°ªÂíågithubÁöÑÂêçÂ≠ó‰∏ÄÊ†∑Ôºå‰∏çÁü•ÈÅìÊòØ‰∏çÊòØÂøÖÈ°ªÁöÑ‰ΩÜÊòØËøòÊòØËøô‰πàËÆæÁΩÆ‰∫Ü ÁΩëÁ´ôÈúÄË¶ÅÈÄâÊã©Âú®master hexoÈÉ®ÂàÜÂü∫Êú¨ÂäüËÉΩÔºöÁîüÊàêÁΩëÈ°µ1hexo g ‰º†Âà∞github‰∏äÈù¢1hexo d ÁîüÊàêÊñ∞ÁöÑmd1hexo new &lt;title&gt; ÈúÄË¶ÅÊääÁîüÊàêÁöÑÂÖ®ÈÉ®Ê∏ÖÈô§1hexo clean Ê∑ªÂä†‰∏ªÈ¢ò ÊääÁõ∏Â∫îÁöÑ‰∏ªÈ¢òclone‰∏ãÊù•ÔºåÁÑ∂Âêé‰øÆÊîπÂçöÂÆ¢Ê†πÁõÆÂΩïÁöÑ _config.yml Êñá‰ª∂ ÈÅáÂà∞404ÊàñËÄÖ‰∏çÊòæÁ§∫Ê®°ÊùøÁöÑÊó∂ÂÄôÂü∫Êú¨Â∞±ÊòØÊ≤°Â•óÂØπ ‰∏ªÈ¢òÂÜÖÂÆπÂú®‰∏ªÈ¢òÁöÑconfig‰øÆÊîπËøôÈÉ®ÂàÜÈÅáÂà∞ÁöÑ‰∏ªË¶ÅÈóÆÈ¢òÊòØ‰∏§‰∏™ÔºöÊ†πÁõÆÂΩïconfigÂøòËÆ∞Ê∑ªÂä†‰∏ÄÈÉ®ÂàÜ123456789101112131415161718jsonContent: meta: false pages: false posts: title: true date: true path: true text: false raw: false content: false slug: false updated: false comments: false link: false permalink: false excerpt: false categories: false tags: true hexoÁöÑurlÂíårootÈÉ®ÂàÜËÆæÁΩÆ‰∏çÂØπ githubÁöÑdeploy Âú∞ÂùÄÂ∫îËØ•ÊòØcloneÊó∂ÂÄôÁöÑÁΩëÂùÄ urlÈÉ®ÂàÜÂ∫îËØ•ÊòØhttps://bigphess.github.io/ÔºårootÈÉ®ÂàÜÊòØ/ mdÊñá‰ª∂Â¢ûÂä†ÂõæÁâáÂú®configÈáåÈù¢ËÆæÁΩÆÔºåÁîüÊàêÊñ∞ÁöÑÊñáÁ´†ÁöÑÊó∂ÂÄôÂ∞±‰ºöÁîüÊàêÂØπÂ∫îÁöÑÊñá‰ª∂Â§π1post_asset_folder: true ÁÑ∂ÂêéÊääÁõ∏Â∫îÁöÑÂõæÁâáÊîæÂú®Êñá‰ª∂Â§πÈáåÔºåÂºïÁî®ÁöÑÊó∂ÂÄôÁõ¥Êé•mdÊ†ºÂºèÂºïÁî®Ôºö1![ÂõæÁâáÁöÑÂêçÂ≠ó](Áõ∏ÂØπË∑ØÂæÑ)]]></content>
      <categories>
        <category>ÂçöÂÆ¢Áõ∏ÂÖ≥</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[StanfordCS231NÁ¨îËÆ∞]]></title>
    <url>%2F2019%2F03%2F20%2FStanfordCS231N%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Introduction Image Classification pipelinechallenges ÂõæÁâáÊòØÁî±Êó†Êï∞Êï∞Â≠óÂùóÁªÑÊàêÁöÑ ËßÜËßíÁöÑËΩ¨ÂèòÔºå‰∫ÆÂ∫¶ÁöÑÂèòÂåñÔºåÂèòÂΩ¢ÈÉΩ‰ºö‰∫ßÁîüÈùûÂ∏∏Â§ßÁöÑÂèòÂåñ viewpoint illumination deformation occlusion background clutter intraclass variation image classifer input:image output: class_label data-driven approach ÂÖ∂‰ªñÊñπÊ≥ï‰∏çË°å attempts: ËæπÁºòÊ£ÄÊµãÔºåÁ∫πÁêÜÁ≠âÁ≠âÔºà‰ΩÜÊòØÂ§™ËøáÂÖ∑‰ΩìÔºâ ‰ª•Êï∞ÊçÆ‰∏∫ÂØºÂêëÁöÑÊñπÊ≥ï def train(image, label) def predict(model, test_image) KNNNN ÂØπ‰∫éÊØè‰∏Ä‰∏™ÊµãËØïÁöÑdataÔºåÂú®Êï∞ÊçÆÂ∫ìÈáåÈù¢ÊâæÂà∞Á¶ª‰ªñÊúÄËøëÁöÑÂõæÁâáÔºàÈÄâÊã©‰∏ÄÂÖ±ÊâæÂ§öÂ∞ëÂº†ÔºåËøô‰πàÂ§öÂº†ÈáåÈù¢ÊäïÁ•®Ôºâ ÂÆö‰πâË∑ùÁ¶ªÔºàhyperparameterÔºâ ÊõºÂìàÈ°øË∑ùÁ¶ª L1: ‰∏§Âº†ÂõæÁõ∏ÂáèÊ±ÇÁªùÂØπÂÄºÔºåÁÑ∂ÂêéÊääÊï¥Âº†ÁÖßÁâáÊ±ÇÂíå Ê¨ßÂá†ÈáåÂæóË∑ùÁ¶ª L2: Ë∑ùÁ¶ªÁöÑÂπ≥ÊñπÂíåÂºÄÊñπ ÂÆûÁé∞ trainingÔºöËÆ∞‰ΩèÊØè‰∏™ÂõæÁâáÁöÑÂÜÖÂÆπÂíålabel imageÔºöN‚úñDÔºåÊØèË°åÊòØ‰∏ÄÂº†ÂõæÁâáÔºàÊãâÊàê‰∏ÄË°åÔºâÔºå‰∏ÄÂÖ±NÂº† labelÔºö1-dÊï∞ÁªÑÔºåsizeN predictÔºöËÆ°ÁÆóË∑ùÁ¶ªÊâæÂà∞ÊúÄÂ∞èÁöÑËßíÊ†áÔºànp.argmin) ÈÄüÂ∫¶Ôºölinearly to size of dataset Áº∫ÁÇπÔºö È¢ÑÊµãÁöÑÊó∂Èó¥Â§™Èïø‰∫ÜÔºàexpensiveÔºâ ‰ΩÜÊòØÊàë‰ª¨Â∏åÊúõËÆ≠ÁªÉÁöÑÊó∂Èó¥Èïø‰ΩÜÊòØÊµãËØïÁöÑÊó∂Èó¥Áü≠ÔºàCNNÔºâ KNN ÊâæÂà∞ÊúÄËøëÁöÑK‰∏™ÔºåÊäïÁ•® ÂΩìKÂ¢ûÂä†ÁöÑÊó∂ÂÄôÔºåÊï¥‰∏™ÂõæÁâáÁöÑËæπÁºòÂèòÂæóÂπ≥Êªë‰∫Ü KÁöÑÊï∞Èáè‰πüÊòØ‰∏Ä‰∏™hyperparameter ÈúÄË¶ÅÈÄâÊã©ÁöÑhyperÔºàÂπ∂‰∏çËÉΩÂæàÂ•ΩÁöÑÊâæÂà∞ÊúÄ‰ºòËß£Ôºâ K Áî®‰ªÄ‰πàdistance Â¶Ç‰ΩïÈÄâÊã©ÊúÄÂ•ΩÁöÑÂèÇÊï∞ ÊÄª‰∏çËÉΩÂ∞ùËØïÊâÄÊúâÁöÑÂèÇÊï∞Âêß2333 ‰∏çËÉΩ‰ΩøÁî®test dataÔºåËØ∑Âú®ËÆ≠ÁªÉÁöÑÊó∂ÂÄôÂøòËÆ∞Ëá™Â∑±Êã•ÊúâÂÆÉ Êäätrain data foldÊàê‰∏çÂêåÁöÑÈÉ®ÂàÜÔºåÊääÂÖ∂‰∏≠ÁöÑ‰∏ÄÈÉ®ÂàÜÂΩìÊàêÊµãËØïÊï∞ÊçÆÔºàvalidation dataÔºâÔºåÁÑ∂ÂêéÊµãËØïËÆ≠ÁªÉÁöÑÁªìÊûúÂØªÊâæhyper ‰∫§ÂèâÈ™åËØÅÔºàcross-validationÔºâÔºåÂæ™ÁéØÂΩìvalidation foldÁÑ∂Âêéaverage result ‰ΩÜÊòØÊ†πÊú¨‰∏çÁî®Âë¢ Âú®test timeÁöÑperformanceÂ§™Â∑Æ‰∫Ü ‰∏§‰∏™ÂõæÁâá‰πãÈó¥ÁöÑË∑ùÁ¶ªÂ§™‰∏çÁõ¥ËßÇ‰∫ÜÔºå‰Ω†Ê†πÊú¨‰∏çÁü•ÈÅìÂõæÁâáÈó¥ÁöÑË∑ùÁ¶ª‰ºöÊÄé‰πàÂèò linear classificationparametric approach ËæìÂÖ•Ôºö32x32x3ÁöÑÂõæÁâáÔºåarray of numbers 0,1,‚Ä¶3072 f(x,W) = Wx + b ÔºàÂú®Á∫øÊÄßÂàÜÁ±ªÁöÑÊÉÖÂÜµ‰∏ãÔºâ Ôºà10x1Ôºâ x: image Ôºà3072x1 -&gt; ÊãâÁõ¥‰∫ÜÔºâ W: parametersÔºåweights Ôºà10x3027Ôºâ bÔºö bias Ôºà10x1ÔºâÔºå‰∏çÊòØËøô‰∏™ÂáΩÊï∞ÁöÑÂèÇÊï∞ÔºåÂè™ÊòØÁî®Êù•ÂÜ≥ÂÆöÊØîÂ¶ÇÁå´ÁöÑÊï∞ÈáèÁâπÂà´Â§öÔºåÂÅèÂêëÁå´ÁöÑbiasÂèØËÉΩÂ∞±ÊØîËæÉÂ§ß ËæìÂá∫Ôºö10‰∏™Êï∞Â≠óÔºåË°®Á§∫ÊØè‰∏™classÁöÑscores Ê≥®ÊÑè WÊòØÊää‰∏çÂêåÂàÜÁ±ªÁöÑclassiferÊãºÂú®‰∫Ü‰∏ÄËµ∑Ôºà‰πêÈ´ò‰∏ÄÊ†∑ÔºâÔºåÊØè‰∏ÄË°åÈÉΩÊòØ‰∏Ä‰∏™‰∏çÂêåÁöÑclassÁöÑÂàÜÁ±ªÂô®ÔºåÁÇπ‰πòËøô‰∏™ÂõæÁâá‰∏äÈù¢ÁöÑÂÉèÁ¥†ÔºåÂä†‰∏äbiasÂ∞±ÊòØËøô‰∏™ÂõæÁâáÊúÄÁªàÁöÑÂæóÂàÜ resizeÊâÄÊúâÁöÑÂõæÁâáÂà∞‰∏Ä‰∏™Â§ßÂ∞èÔºàÁõÆÂâçÔºâ ÂÆûÈôÖ‰∏äÊØè‰∏™classÁöÑscoreÂ∞±ÊòØÂõæÁâáÈáåÈù¢ÊØè‰∏™ÁÇπÁöÑÂä†ÊùÉÊ±ÇÂíåÔºåÂèØ‰ª•ÊÉ≥Ë±°ÊàêÂú®Êï∞ÊØè‰∏™‰∏çÂêåÂú∞ÊñπÁöÑÁÇπÁöÑÈ¢úËâ≤„ÄÇÂ¶ÇÊûúÊääWÁü©ÈòµËøòÂéüÔºåËøòÂéüÂá∫Êù•ÁöÑÂ∞±ÊòØËøô‰∏™classÁöÑÊÑüËßâ‰∏äÁöÑÈ¢úËâ≤ ÂèØ‰ª•ÊÉ≥Ë±°Âú®‰∏Ä‰∏™Â∑®È´òdÁöÑspaceÈáåÈù¢ÔºåÁî®Á∫øÊÄßÂàÜÁ±ª hard part ÈÉΩÁî®ÁÅ∞Â∫¶Âõæ‰ºöÊúâÈóÆÈ¢ò Áõ∏‰ººÁöÑtextureÔºàÔºü loss function optimizationtodoÔºö ÂÆö‰πâ‰∏Ä‰∏™loss functionÊù•ÂÆö‰πâËøô‰∏™scoreÁöÑÂ•ΩÂùè ÊâæÂà∞‰∏Ä‰∏™efficiently wayÂéªÊâæÂà∞minimize Ëøô‰∏™loss SVM lossÂÆö‰πâ ÂÅáËÆæÂ¶ÇÊûúÂè™Êúâ‰∏â‰∏™ÁßçÁ±ªÔºå‰∏ÄÂº†ÂõæÁâáÂØπ‰∏â‰∏™classÂàÜÂà´‰ºöÊúâ‰∏çÂêåÁöÑscore„ÄÇÊØèÂº†ÂõæÁâáÈÉΩÂèØ‰ª•ËÆ°ÁÆóÂá∫‰∏Ä‰∏™ÂØπÂ∫îÁöÑloss SVM loss Li = sum maxÔºà0Ôºåsj - si + 1Ôºâ si: ÊÉ≥Ë¶ÅËÆ°ÁÆóËøô‰∏™ÁöÑloss function ÁöÑclassÁöÑËØÑÂàÜÔºà‰πüÂ∞±ÊòØlabelÊ†áÊ≥®ÁöÑclassÁöÑËØÑÂàÜÔºâ sj: ËøôÂº†ÂõæÂØπ‰∫éÊâÄÊúâÂÖ∂‰ªñÁßçÁ±ªÔºàÈô§‰∫ÜiÔºâÁöÑËØÑÂàÜ Li: ÊúÄÁªàËøôÂº†ÂõæÁâáÁöÑloss 1: ÊòØ‰∏Ä‰∏™safety marginÔºà‰πüÊòØ‰∏Ä‰∏™hyper parameterÔºâ„ÄÇÂèØ‰ª•ÈÄâÊã©ÂÖ∂‰ªñÊ≠£Êï∞Ôºå‰ΩÜÊòØÈÄâ0‰ºöÂá∫ÈóÆÈ¢ò LiÁöÑÊØè‰∏ÄÈ°πÈÉΩÂú®0ÂíåÂ∑ÆÂÄº‰πãÈó¥ÊâæÊúÄÂ§ßÂÄºÔºåÁÑ∂ÂêéÊääÊØè‰∏ÄÈ°πÁöÑÂä†Ëµ∑Êù•Ê±ÇÂíå Â¶Ç‰ΩïÁêÜËß£Ëøô‰∏™ÂºèÂ≠êÔºöÊó¢ÁÑ∂ÂØπ‰∫é‰∏çÂêåclassÁöÑËØÑÂàÜË∂äÈ´òÂ∞±ÊòØË∂äÂèØËÉΩÔºåÈÇ£‰πàËØÑÂàÜÊòØË¥üÊï∞ÁöÑËØùÂ∞±ËØ¥Êòé‰∏çÂèØËÉΩÔºåËøôÊ†∑Â∞±Áõ¥Êé•Áî®0ÊääËøôÁßçÂèØËÉΩÊÄßÊäπÂéª‰∫Ü„ÄÇÂ¶ÇÊûúÂÖ∂‰ªñÁßçÁ±ªÂú®Ê≠£ÁöÑÊñπÈù¢ËØÑÂàÜË∂äÈ´òÔºåËØ¥ÊòéËøô‰∏™ÁßçÁ±ªË∑ëÂÅè‰∫ÜÔºålossË∂äÂ§ß ###Ê≥®ÊÑèÁÇπ Âú®‰∏äÈù¢ËøôÂº†ÂõæÈáåÔºåÂõ†‰∏∫ËΩ¶ÁöÑËØÑÂàÜÂ∑≤ÁªèÊòØÊúÄÈ´ò‰∫ÜÔºåËÆ°ÁÆóÂá∫Êù•ÁöÑlossÂ∞±ÊòØ0 ÊúÄÂêéÂÜçÊääÊâÄÊúâÁ±ªÂûãÁöÑlossÊ±ÇÂíåÔºåÈô§‰ª•ÁßçÁ±ªÂæóÂà∞ÊúÄÁªàÁöÑloss Áî®ÁöÑÊòØÊ±ÇÂíåËÄå‰∏çÊòØmean‰πüÊòØÂèñÂÜ≥‰∫éËá™Â∑±ÁöÑÂÜ≥ÂÆö ‰πüÊúâÁöÑSVMÈáåÈù¢Áî®ÁöÑÊòØmax‰πãÂêéÂπ≥ÊñπÔºå‰ΩÜÊòØ‰∏çÂπ≥ÊñπÁöÑÁî®ÁöÑÊõ¥Â§ö‰∏ÄÁÇπÔºå‰πüÊòØ‰∏Ä‰∏™hyper parameter scale ÊúÄÂ∞èÔºö0 ÊúÄÂ§ßÔºöinfinite bug Âú®ÂÆûÈôÖÂ∫îÁî®ÈáåÈù¢Ê≤°ÊúâÈÇ£‰πàÂ•ΩÁöÑÊïàÊûú W‰∏çÊòØÂîØ‰∏ÄÁöÑÔºåÊØîÂ¶ÇÊääËøô‰∏™WÂä†ÂÄçÔºåÂ¶ÇÊûúlossÊòØ0ÁöÑÊó∂ÂÄôÊòØ‰∏ÄÊ†∑ÁöÑ -&gt; ÈúÄË¶ÅÂæóÂà∞ÂîØ‰∏ÄÁöÑW weight regularizationÔºàËß£ÂÜ≥‰∏äÈù¢Ëøô‰∏™ÈóÆÈ¢òÔºâ Âú®‰πãÂâçÁöÑlossÁöÑÂü∫Á°Ä‰∏äÂä†‰∏ä‰∫Ü \lambda R(W) \lambdaÊòØ‰∏Ä‰∏™hyper parameterÔºåÊòØÂèñÂÜ≥‰∫éËá™Â∑±ÁöÑÈÄâÊã©ÁöÑ RÊòØ‰∏Ä‰∏™regularizationÂáΩÊï∞ÔºåËøô‰∏™ÂáΩÊï∞ÁöÑ‰ΩúÁî®ÊòØÊäµÊäó‰πãÂâçÁöÑloss„ÄÇÂõ†‰∏∫‰πãÂâçÁöÑlossÊòØ‰ªéËÆ≠ÁªÉÈõÜ‰∏äÂæóÂà∞ÁöÑÔºåÊØîËæÉÂêªÂêàËÆ≠ÁªÉÈõÜÔºåÊâÄ‰ª•ÈúÄË¶Å‰∏Ä‰∏™ÊØîËæÉÁâπÂà´ÁöÑWÊù•Âíå‰πãÂâçÁöÑfightÔºåËøôÊ†∑ÁöÑËØùÁªìÊûúÂèØËÉΩ‰ºöÂú®ÂÆûÈôÖ‰ΩøÁî®ÁöÑÊó∂ÂÄôÊõ¥Â•Ω‰∏Ä‰∫õ ‰∏ªË¶ÅÂàÜÁ±ª L2 regularizationÔºöWÈáåÈù¢ÁöÑÊâÄÊúâÈ°πÂπ≥ÊñπÁÑ∂ÂêéÊ±ÇÂíåÔºàÊúÄÂ∏∏ËßÅÔºâ L1 regularizationÔºöWÈáåÈù¢ÊâÄÊúâÈ°πÁªùÂØπÂÄºÁÑ∂ÂêéÊ±ÇÂíå -&gt; Âú®‰∏Ä‰∫õÂÖ∂‰ªñÂú∞Êñπ‰ΩøÁî® elastic netÔºàL1+L2ÔºâÔºöÊâÄÊúâÈ°πÂπ≥Êñπ‰πòÂèÇÊï∞Âä†ÁªùÂØπÂÄºÊ±ÇÂíå max norm regularization -&gt; ÂêéÈù¢ËÆ≤ dropout ÁêÜËß£L2 ÊØîÂ¶ÇXÊòØ[1,1,1,1],‰∏§‰∏™WÂàÜÂà´ÊòØ[1,0,0,0]Âíå[0.25,0.25,0.25,0.25] ËøôÊ†∑‰πòÂá∫Êù•ÁöÑÊúÄÁªàÁªìÊûúÈÉΩÊòØ‰∏ÄÊ†∑ÁöÑÔºåÈÉΩÊòØ1„ÄÇ ‰ΩÜÊòØÂ¶ÇÊûúÂä†‰∏ä‰∫ÜL2ÁöÑregularization‰πãÂêéÂ∞±ÂèëÁé∞Á¨¨‰∫åÁßçÊñπÊ≥ïÁöÑlossÊõ¥Â∞ë‰∏ÄÁÇπ„ÄÇÂõ†‰∏∫‰ªñÁî®Âà∞‰∫ÜÊõ¥Â§öÁöÑÁª¥Êï∞ÔºåÂú®ÂÆûÈôÖÂ∫îÁî®‰πã‰∏≠ÊïàÊûúÊõ¥Â•Ω„ÄÇ softmaxÔºàÁî®Ëµ∑Êù•Êõ¥Â•ΩÔºâÔºàmultinomial logistic regressionÔºâÂÆö‰πâ scoresÔºöunnormalized log probabilities of the class ÈúÄË¶ÅÊääscoreÂÖàexpÂõûÊù•(ËøôÊ†∑ÊâÄÊúâÁöÑÊï∞ÈÉΩÂèòÊàêÊ≠£Êï∞‰∫Ü) ÂÜçnormalizeÔºàÈô§‰ª•ÊâÄÊúâexp‰πãÂêéÁöÑÁöÑÂíåÔºâ ÊúÄÁªàÔºåÂØπ‰∫éÊ≠£Á°ÆclassÁöÑÊúÄÁªàÂ§ÑÁêÜÂÆåÁöÑscoreÊù•ËØ¥ÔºåmaxËøô‰∏™logÊàñËÄÖminÔºàloss functionÔºâ- log‰ºöÂæóÂà∞ÊúÄÁªàÊúÄÂ•ΩÁöÑÁªìÊûú ÊúÄÁªàÂ§ÑÁêÜÂÆåÁöÑscoreÂ∞±ÊòØÊØè‰∏™Á±ªÂûãÊé®ÊµãÂá∫Êù•ÁöÑÂç†ÊØîÂèØËÉΩÊÄßÔºàÂíå‰∏∫1Ôºâ ËøôÈáåÊ±ÇÂÆå-logÔºàpÔºâÂÖ∂ÂÆûÂ∞±ÊòØ‰ø°ÊÅØÁÜµÔºå‰ª£Ë°®ÂØπ‰∏çÁ°ÆÂÆöÂ∫¶ÁöÑÂ∫¶Èáè Áõ¥Êé•ÊØîËæÉÂèØËÉΩÊÄßÂíålog‰πãÂêéÊØîËæÉÂèØËÉΩÊÄßÂú®Êú¨Ë¥®‰∏äÊòØÊ≤°ÊúâÂå∫Âà´ÁöÑ ‰ΩÜÊòØÊï∞Â≠¶‰∏ä‰∏ÄËà¨log‰πãÂêéÁöÑÊï∞ÊçÆ‰ºöÁúãËµ∑Êù•Â•Ω‰∏Ä‰∫õÂÆûÈôÖÊìç‰ΩúÂ¶Ç‰∏ã ‰∏Ä‰∫õÈóÆÈ¢ò ÊûÅÂÄº LiÊúÄÂ∞èÂÄºÔºö0 -&gt; Â¶ÇÊûúÊ≠£Á°ÆÁ±ªÂûãÁöÑÂèØËÉΩÊÄßÊòØ1ÔºåÊ±ÇÂá∫Êù•ÁöÑÊúÄÁªàÂÄºÂ∞±ÊòØ0 LiÊúÄÂ§ßÂÄºÔºöinfiniteÔºåÂèØËÉΩÊÄßÈùûÂ∏∏‰ΩéÈùûÂ∏∏Êé•Ëøë‰∫é0 ÂΩìWÁöÑÂàùÂßãÂåñÂæàÂ∞èÔºåÊâÄÊúâscoreÈÉΩÊé•Ëøë‰∫é0Ôºö scoreÊ±Çexp‰πãÂêéÈÉΩÊòØ1Ôºånormalize‰πãÂêéÊòØ1/numÔºàclassÔºâÔºåÊúÄÂêéÂÜçÊ±Çlog ÂèØ‰ª•Áî®‰∫éÂºÄÂ§¥ÁöÑÊ£ÄÈ™å SVMÂíåsoftmax Â¶ÇÊûúËæìÂÖ•ÊòØ[10,-100,-100]ÔºåÂú®Ëøô‰∏™ËåÉÂõ¥ÈáåÂæÆÂ∞èÂèòÂåñÔºåÁ¨¨‰∏Ä‰∏™ÊòØÊ≠£Á°ÆÁöÑclass ÂØπ‰∫éSVMÊù•ËØ¥ÔºåÂêéÈù¢‰∏§‰∏™Ë¥üÂÄºÈÉΩÈùûÂ∏∏Â∞è‰∫ÜÔºåÊ†πÊú¨‰∏ç‰ºöÂéªÁÆ°ÂêéÈù¢ÁöÑ‰∏§‰∏™‰∏úË•øÔºå-100Âíå-200Ê≤°Âï•Âå∫Âà´ ÂØπ‰∫ésoftmaxÊù•ËØ¥ÔºåÂêéÈù¢ÁöÑ-100ËøòÊòØ-200ËøòÊòØ‰ºöÂØπlossÊúÄÁªàÁöÑÂÄº‰∫ßÁîüÂΩ±ÂìçÔºåsoftmaxÂ∏åÊúõÊâÄÊúâÁöÑÂÄºÈÉΩÂú®Ê≠£Á°ÆÁöÑclass‰∏äÈù¢ÔºåÂêéÈù¢Âï•ÈÉΩÊ≤°Êúâ„ÄÇÊâÄ‰ª•Êõ¥ÂÖ∑Êúârobustness„ÄÇ SVM‰ºöÊúâ‰∏Ä‰∏™‰Ω†ÈúÄË¶ÅÁöÑÂå∫ÂüüÔºåÂâ©‰∏ãÁöÑÊ†πÊú¨‰∏çËÄÉËôëÔºõËÄåsoftmax‰ºöËÄÉËôëÊâÄÊúâÁöÑÂå∫Âüü ‰∏äÊñπÂå∫ÂüüÊÄªÁªì xÔºöËÆ≠ÁªÉÈõÜÈáåÈù¢ÁöÑÊï∞ÊçÆÔºåÊîæÂú®ÂõæÁâáÈáåÂ∞±ÊòØÊää‰∏Ä‰∏™ÂõæÁâáÊãâÊàê‰∏Ä‰∏™1xNÁöÑÂêëÈáè yÔºöËÆ≠ÁªÉÈõÜÁöÑÊ†áÁ≠æÔºåÁî®Êù•ÂíåÊúÄÁªàÁöÑÁªìÊûúÊØîÂØπ W: weightsÔºåÈúÄË¶Å‰ºòÂåñÁöÑÈÉ®ÂàÜ LÔºölossÔºåÁî®Êù•ÊùÉË°°W‰ºòÂåñÁªìÊûúÁöÑÂ•ΩÂùè Âü∫Êú¨ËøáÁ®ã Wx+bÂæóÂà∞ÁõÆÂâçÁöÑÂàÜÁ±ªÂô®ÁöÑscoreÔºàscore functionÔºâ yÊòØÁõÆÂâçÂàÜÁ±ªÂ∫îËØ•ÊúâÁöÑÁªìÊûúÔºàlabelÔºâ RÔºàWÔºâÂæóÂà∞regularzationÁöÑÂÄº ÂàÜÁ±ªÂô®ÂæóÂà∞scoreÔºåyÁü•ÈÅìÊ≠£Á°ÆÁöÑÂàÜÁ±ªÔºåÈÄöËøásoftmaxÊàñËÄÖSVMÂæóÂà∞Ëøô‰∏™ÂàÜÁ±ªÂô®ÁõÆÂâçÁöÑlossÔºåÂÜçÂä†‰∏äRÔºàWÔºâÁöÑÈÉ®ÂàÜÂ¢ûÂä†robustnessÊúÄÁªàÂæóÂà∞Êï¥‰∏™ÂàÜÁ±ªÂô®ÁöÑloss optimization lossfollow the slope ÈÄöËøáËÆ°ÁÆógradientÊù•ÊâæÂà∞ÊúÄ‰ΩéÁÇπ ÊúÄÂü∫Á°ÄÁöÑÊÉ≥Ê≥ïÔºöÔºà‰ªéÊï∞Â≠¶‰∏äÂÖ•ÊâãÔºâ Âõ†‰∏∫Ê¢ØÂ∫¶ÊòØlim f(x+,h)-f(x)/h ÊääW‰∏äÈù¢ÁöÑÊØè‰∏Ä‰∏™ÁÇπÈÉΩÂä†‰∏ä‰∏Ä‰∏™0.00001ÔºàÊé•Ëøë‰∫é0ÔºâÁÑ∂ÂêéÂÜçÊ±Ç‰∏äÈù¢ÁöÑÂºèÂ≠êÔºåÂ∞±ËÉΩÂæóÂà∞Á¨¨‰∏ÄÊ¨°Êìç‰ΩúÁöÑÊ¢ØÂ∫¶ silly ÊØè‰∏ÄÊ≠•ÈÉΩÈúÄË¶ÅÊØè‰∏Ä‰∏™Áª¥Â∫¶ÈÉΩÁÆó‰∏Ä‰∏ãÔºåÂú®CNNÈáåÈù¢ÂèÇÊï∞È´òËææÁôæ‰∏á‰∏™ÔºåËÆ°ÁÆóÂ§™ÊÖ¢‰∫Ü Âõ†‰∏∫Áî®ÁöÑ0.00001ÔºåÂÖ∂ÂÆûÂπ∂‰∏çÂáÜÁ°Æ ÊÑüË∞¢ÁâõÈ°øËé±Â∏ÉÂ∞ºÂÖπÂèëÊòé‰∫ÜÂæÆÁßØÂàÜ -&gt; Â¶Ç‰ΩïÂÖ∑‰ΩìËÆ°ÁÆóÂú®‰∏ã‰∏ÄËäÇËØæ ÊäälossÁöÑgradientÊîπÊàê‰∫Ü‰∏Ä‰∏™ÂºèÂ≠ê Âø´ÈÄüÔºåÂáÜÁ°ÆÔºåÁÑ∂ÊòØÂÆπÊòìÂèëÁîübugÔºàerror-proneÔºâ practiceÈúÄË¶ÅËøõË°ågradient check Âú®ÂÜô‰ª£Á†ÅÁöÑÊó∂ÂÄôÁî®ÁöÑËÇØÂÆöÈÉΩÊòØanalytic gradient ‰ΩÜÊòØÈúÄË¶ÅÂú®Â∫îÁî®‰πãÂâçÁî®numerical gradientÊ£ÄÊü•‰∏Ä‰∏ãÔºåÁ°Æ‰øù‰∏§ËÄÖÁöÑÁªìÊûúÊòØ‰∏ÄÊ†∑ÁöÑÔºå‰∏∫‰∫Ü‰øùËØÅ‰ª£Á†ÅÈáåÈù¢ÂÜôÁöÑÁßØÂàÜÊòØÊ≠£Á°ÆÁöÑ gradient descent mini-batch Âú®ÂÆûÈôÖÂ∫îÁî®ÁöÑÊó∂ÂÄôÔºå‰∏ç‰ºöÊääÊï¥‰∏™ÁöÑËÆ≠ÁªÉÈõÜÈÉΩÊãøÊù•‰ºòÂåñWÔºåËÄåÊòØ‰ºöÊää‰∏ÄÈÉ®ÂàÜÊãøÂá∫Êù•Ôºàsample examplesÔºâ ‰∏ÄÂ∞èÁÇπ‰∏ÄÂ∞èÁÇπÁöÑÊãøÁªìÊûú‰∏ç‰ºöÈùûÂ∏∏ÂáÜÁ°ÆÔºå‰ΩÜÊòØÂèØ‰ª•stepÂæàÂ§öÊ¨°ÔºåÂú®ÂÆûÈôÖÂ∫îÁî®ÈáåÈù¢‰∏ÄËà¨ÈÉΩ‰∏ç‰ºöÁî®Êï¥‰∏™training setÔºå‰∏çÊòØÂæàÁé∞ÂÆûËÄå‰∏îÊïàÊûú‰∏çÊòØÂæàÂ•Ω„ÄÇ ÈÄâÊã©ÁöÑÊï∞Èáè‰∏ä 32/64/256ÔºåËøô‰∏™‰∏çÊòØ‰∏Ä‰∏™ÂæàÈáçË¶ÅÁöÑhyperparameterÔºå‰∏ªË¶ÅÊòØÊ†πÊçÆGPUÁöÑÊÄßËÉΩÊù•ÂÜ≥ÂÆöÁöÑ ÊúÄÁªàÁªìÊûúÁöÑlossÊòØ‰ºö‰∏ãÈôçÁöÑÔºåËôΩÁÑ∂noiseÂæàÂ§ö‰ΩÜÊòØÊúÄÁªà‰ºögo dowm learning rate ÂõæÁâá‰∏≠‰ΩøÁî®linear classifierÂõ†‰∏∫ÂõæÁâáÂÉèÁ¥†Â§™Â§ö‰∫ÜÔºå‰∏çÂèØËÉΩÂØπÊØè‰∏™ÂÉèÁ¥†ÈÉΩÁî®Á∫øÊÄßÂàÜÁ±ªÔºåÊâÄ‰ª•‰∏ÄËà¨‰ºöÂÖàÊèêÂèñ‰∏Ä‰∫õÁâπÂæÅÁÑ∂ÂêéÂæóÂà∞ÊúÄÁªàÁöÑÂàÜÁ±ªÁªìÊûú color histogram ÂÖàÂæóÂà∞‰∏ÄÂº†ÂõæÁâáÁöÑÈ¢úËâ≤ÁâπÂæÅÂàÜÂ∏É ÁÑ∂ÂêéÊääÊï¥‰∏™ÁâπÂæÅÂàÜÂ∏ÉÊãΩÊàê‰∏Ä‰∏™ÈïøÁöÑvectorËøõË°åÂàÜÁ±ª HOG/SIFT ÊâæÂà∞ËæπÁºòÁâπÂæÅÔºåÂú®ÂõæÁâáÁöÑÂì™‰∏™ÈÉ®ÂàÜÊúâÈÇ£ÁßçÊ†∑Â≠êÁöÑedge bag of words ÂÖàÊääÂõæÁâáÈáåÈù¢ÁöÑ‰∏Ä‰∫õÁâπÂæÅÂΩì‰Ωú‰∏Ä‰∏™vocabularyÔºåÁÑ∂ÂêéÊîæËøõ‰∏Ä‰∏™ËØçÂÖ∏ÈáåÈù¢ ÊâæÂà∞ËØçÂÖ∏ÈáåÊØè‰∏™ËØçÂá∫Áé∞ÁöÑÈ¢ëÁéáÁÑ∂ÂêéÊãΩÊàêvector Á∫øÊÄßÂàÜÁ±ª ÊÄªÁªì‰∏ÄËà¨ÈÉΩÊòØÂÖàËøõË°åÁâπÂæÅÊèêÂèñÁÑ∂ÂêéÂÜçËøõË°åÁ∫øÊÄßÂàÜÁ±ª Ê∑±Â∫¶Â≠¶‰π†ÁâπÂæÅÈÉΩÊòØËá™Â∑±ÊèêÂèñ Backpropagation &amp; neural networkÁõÆÁöÑÔºöÊ±ÇÂá∫Êù•loss functionÁöÑgradient backpropagationÊúÄÂè≥ËæπÁöÑÁÇπÂõ†‰∏∫ÊòØdf/dfÊâÄ‰ª•ÁªìÊûúÂ∞±ÊòØ1 forward passÔºöÁü•ÈÅìÂºÄÂßãÁÑ∂Âêé‰∏ÄÁõ¥È°∫Âà∞ÁªìÊùü Âú®‰∏Ä‰∏™node‰∏äÈù¢ÔºåÊî∂Âà∞‰∫ÜxÂíåyÁöÑinputÔºåÂØπ‰ªñ‰ª¨ËøõË°åfÊìç‰ΩúÔºåÂæóÂà∞ÊúÄÁªàÁöÑÁªìÊûúz zÂÜçÂæÄÂêéÊìç‰ΩúÂæóÂà∞ÊúÄÂêéÁöÑlossÔºà‰∏çÁü•ÈÅì‰ªÄ‰πàÊìç‰ΩúÔºâ backward passÔºö‰ªéÂêéÂà∞ÂâçÔºåÈÄöËøáÈìæÂºèÊ≥ïÂàôÂÄíÂõûÊù• ËôΩÁÑ∂‰∏çÁü•ÈÅìlossÂØπxÊàñËÄÖyÁöÑgradientÔºå‰ΩÜÊòØÂèØ‰ª•Ê±ÇÂá∫Êù•dz/dxÂíådz/dyÔºàÂè™ÂíåËøô‰∏™ÁÇπÊúâÂÖ≥Ôºâ ÂèØ‰ª•ÂæóÂà∞dL/dzÔºåÁÑ∂Âêé‰πò‰ª•local gradient local gradient ÊØè‰∏Ä‰∏™node‰∏äÈù¢ÁöÑgradientÂæÄÂâçÊé®ÁöÑÊó∂ÂÄôÔºåÈÉΩÂèØ‰ª•ÈÄöËøáÈìæÂºèÊ≥ïÂàôÔºàchain ruleÔºâÂèòÊàêËøô‰∏™ÁÇπËæìÂÖ•ÁöÑgradientÂíåËøô‰∏™ÁÇπÂà∞‰∏ä‰∏Ä‰∏™ÁÇπÁöÑgradientÁöÑ‰πòÁßØ„ÄÇ ÁÆólocalÁöÑÊó∂ÂÄôÔºå‰πòÁöÑÂèÇÊï∞ÊòØËæìÂÖ•ËøõÂéªÁöÑÂèÇÊï∞Âïä„ÄÇÊØîÂ¶ÇdL/dx = dL/dzÔºàËøô‰∏™Â∏¶Ëøô‰∏™ÁÇπbackÂõûÊù•ÁöÑÊï∞Â≠óÔºâ * dz/dx ÔºàËøô‰∏™ÈáåÈù¢ÁöÑxÂ∏¶Ëøô‰∏™ÁÇπËæìÂÖ•ËøõÊù•xÁöÑÂÄºÔºâ ÊÉ≥‰∏çÊòéÁôΩÁöÑÊó∂ÂÄôÊää‰∏çÂêåÁöÑÁÇπÂÅáËÆæÊàê‰∏çÂêåÂêçÂ≠óÁÑ∂ÂêéÊ±ÇÂØºÔºÅ Âú®Ëøô‰∏™ÁΩëÁªúÈáåÈù¢ÔºåÂ¶ÇÊûúgateÊòØÂä†Ê≥ïÔºàx + yÔºâÁöÑËØù‰∏çÊòØÊ±ÇÂÅèÂØºÔºåÂ¶ÇÊûúÊ±ÇxÁöÑÂØºÊï∞ÁöÑËØùyÂπ∂‰∏çÊòØÂèÇÊï∞ËÄåÊòØÂ∏∏Êï∞ÔºåÊâÄ‰ª•Ê±ÇÂá∫Êù•ÁöÑÁªìÊûúÊòØ1ÔºåÊâÄ‰ª•Âä†Ê≥ïÁöÑgateÂ∞±ÊòØÁõ¥Êé•ÊääËøô‰∏™ÂÄºÁõ∏Á≠âÁöÑÂàÜÂºÄ Âä†gateÊòØ‰∏Ä‰∏™gradient distributorÔºåÂΩì‰∏Ä‰∏™gradientËøõÊù•ÁöÑÊó∂ÂÄô‰ºöË¢´Áõ∏ÂêåÁöÑÂàÜÂºÄÊàê‰∫Ü‰∏§‰ªΩ ‰πüÂèØ‰ª•Êää‰∏Ä‰∫õgateÁªÑÊàê‰∏Ä‰∏™Â§ßÁöÑgateÔºåÊØîÂ¶Çsigmoid Ê≥®ÊÑèÔºåÊ±ÇÂá∫Êù•ÁöÑgradientÂ¶ÇÊûúÊòØÊ≠£ÁöÑÔºåËØ¥ÊòéËøô‰∏™ÁÇπÂØπÊúÄÁªàÁöÑlossÊúâpositiveÁöÑ‰ΩúÁî® patterns addÔºögradient distributor maxÔºörouter ÂÅáËÆæfÊòØmaxÔºàxÔºåyÔºâ local gradientÂØπÊúÄÂ§ßÁöÑÈÇ£‰∏™Â∞±ÊòØ1ÔºåÂØπÂÖ∂‰ªñÁöÑÈÉΩÊòØ0 Âõ†‰∏∫Â¶ÇÊûúÊ≤°ËÉΩÈÄöËøámaxÁöÑgateÁöÑËØùÊ†πÊú¨ÂØπÂêéÈó®ÁöÑlossÊ≤°ÊúâÂΩ±Âìç„ÄÇbackÁöÑÊó∂ÂÄôËµ∞ÊúÄÂ§ßÁöÑÁÇπÂ∞±ÂèØ‰ª•‰∫ÜÔºåÂÖ∂‰ªñÁöÑÈÉΩ‰∏çÁî®ÁÆ°‰∫Ü multiplyÔºöswitcherÔºåÁúüÔºå‰∏§ÊûÅÂèçËΩ¨ ÂΩìÂæÄÂõûÁöÑÊó∂ÂÄôÔºå‰∏§‰∏™ÁÇπÊåáÂêë‰∏Ä‰∏™ÁÇπÔºågradientÈúÄË¶ÅÁõ∏Âä†ÔºàÂ¶Ç‰∏ãÂõæÔºâ Implementationpsuedocode graph or net object forward: Êääinput passËøõËøô‰∏™gateÈáåÈù¢ÔºàÂøÖÈ°ªÂú®‰ª£Á†ÅÈáåÈù¢ËÆ∞‰ΩèinputÔºâ ÊääÊï¥‰∏™computationalÁöÑgarphÂæÄÂâçÊé®Âä® ÊúÄÂêé‰∏Ä‰∏™gate‰ºöreturnËøô‰∏™ÁΩëÁªúÁöÑloss backward ËæìÂÖ•dzÔºåÁÑ∂Âêé‰πò‰∏çÂêåÁöÑxÂíåy ‰∏çÂêåÁöÑgateÂàÜÂà´ÊòØ‰∏çÂêåÁöÑÊñá‰ª∂ÔºàAPIÔºâÔºåÊØè‰∏™Êñá‰ª∂ÈáåÈù¢ÂåÖÊã¨ÂàùÂßãÂåñÔºåforwardÂíåbackward ÊØèÊ¨°updateÁöÑÊó∂ÂÄôÈÉΩÈúÄË¶ÅËøõË°åforwardÂíåbackwardÔºåforwardÂæóÂà∞gradientÔºåbackwardÂÜçÂõûÊù•Ê±ÇÊúÄÁªàÁöÑloss vectorized Âú®ÂÆûÈôÖÁöÑËÆ°ÁÆó‰∏≠xÔºåyÔºåzÈÉΩÊòØÁü©ÈòµÔºådz/dxÊòØjacobianÁü©ÈòµÔºàÂÖ®ÈÉ®ÈÉΩÁî±ÂÅèÂØºÁªÑÊàêÁöÑÁü©ÈòµÔºâ ÊØîÂ¶Ç‰∏Ä‰∏™maxÁöÑÈó®ÔºåÂ¶ÇÊûúËæìÂÖ•ÊòØ1x4096ÔºåËæìÂá∫‰πüÊòØ1x4096Ôºå‰ΩÜÊòØÊ±ÇÂÅèÂØºÂá∫Êù•ÁöÑÁü©ÈòµÊòØ4096x4096ÔºàÂ§™Â§ß‰∫ÜÔºâÔºåÁü©Èòµ‰∏≠Èó¥Âè™ÊúâÂØπËßíÁ∫øÈÉ®ÂàÜÁöÑÊòØÈúÄË¶ÅËÄÉËôëÁöÑÔºàËøò‰ºöÊúâÂæàÂ§ö0Ôºâ ÁÑ∂ÂêéÂ¶ÇÊûúÁî®‰∫ÜminibatchÁöÑ100ÔºåÂæóÂà∞ÁöÑÁªìÊûúÂ∞±ÊòØ409600‰∫ÜÔºåÊõ¥ÂèØÊÄï‰∫Ü ÊâÄ‰ª•Âú®ÊØèÊ¨°APIÁöÑÊó∂ÂÄôÔºåËÇØÂÆö‰∏çËÉΩÂÜôÂá∫Êù•ÊâÄÊúâÁöÑÈìæÂºèÊ≥ïÂàôÔºåÂè™Áî®ÂÖ∂‰∏≠ÁöÑ‰∏ÄÈÉ®ÂàÜ ‰Ωú‰∏öÁöÑÈáçÁÇπÂ∞±ÊòØÂ¶Ç‰ΩïËÆ©Ëøô‰∏™‰∏úË•øËÆ°ÁÆóÂá∫Êù•ÊïàÁéáÈ´ò neural network‰∏§Â±ÇÁöÑNN ËæìÂÖ•ÊòØÂõæÁâá‰∏ÄÂÖ±ÁöÑÂùêÊ†áÊï∞Èáè ÂÖàÈÄöËøáÁ¨¨‰∏ÄÂ±ÇÔºàmaxÔºâÂæóÂà∞100ÁöÑ‰∏≠Èó¥Â±ÇÔºàhidden layerÔºâ-&gt; 100ÊòØhyperparameterÔºåËá™Â∑±ÂÆöÁöÑÔºå‰ΩÜÊòØË∂äÂ§öË∂äÂ•ΩÂêß ÁÑ∂ÂêéÈÄöËøáW2ÂæóÂà∞ÊúÄÁªàÁöÑÂàÜÁ±ªÁªìÊûúÔºàÂàÜ10Á±ªÔºâ ÂÖ∂ÂÆûÂÖ∑‰ΩìÈáåÈù¢ÊòØ‰ªÄ‰πà‰∏úË•øÁúüÁöÑÊòØ‰∏çÁü•ÈÅìÁöÑÔºü Á•ûÁªèÂÖÉ ÊØè‰∏™Á•ûÁªèÂÖÉÁöÑËæìÂÖ•ÊòØWx+bÔºåÁÑ∂ÂêéÁªèËøáÊøÄÊ¥ªÂáΩÊï∞ ËæìÂá∫ ÊøÄÊ¥ªÂáΩÊï∞ activation function sigmoid tanh ReLU Â±ÇÁä∂ -&gt; ÂèØ‰ª•Êõ¥Âä†efficient Neural network 2Ôºàtraining part1ÔºâÂâçÊñπÊèêÁ§∫Ôºö Â∞èÁöÑdataset‰πüÂèØ‰ª•ÊúâÁªìÊûú ÁîµËÑëÁöÑÊÄßËÉΩÊúâÈôê ÂõûÈ°æ‰∏Ä‰∏ãÂéÜÂè≤ perceptron -&gt; ÊøÄÊ¥ªÂáΩÊï∞Ôºö0ÊàñËÄÖ1Ôºå‰∏çËÉΩback madaline¬∑¬∑¬∑ activation functionÔºà‰∏Ä‰∏™hyerparameterÔºâsigmoid ÁâπÁÇπÔºö ÊääÊâÄÊúâÁöÑÊï∞ÂÄºÈÉΩÂéãÂà∞‰∫Ü0Âà∞1‰πãÈó¥ ÊõæÁªèÈùûÂ∏∏ÂèóÊ¨¢ËøéÔºåÂõ†‰∏∫satratingÁöÑÊïàÊûúÊØîËæÉÂ•Ω ÈóÆÈ¢òÔºö Âú®saturateÁöÑÊÉÖÂÜµ‰∏ãÔºàÈùûÂ∏∏Êé•Ëøë0ÊàñËÄÖ1ÔºâÔºå‰ºöÊùÄÊ≠ªgradent -&gt; ÁúãÂáΩÊï∞ÁöÑÂõæÂ∞±ËÉΩÊÑüËßâÂá∫Êù•-10ÂÅöÂìüÁöÑÂØºÊï∞Â∞±ÊòØ0‰∫ÜÔºåbackÂõûÊù•Ê≤°ÊúâÊÑè‰πâ output‰∏çÊòØ‰ª•0‰∏∫‰∏≠ÂøÉÁöÑÔºàÈ¢ÑÂ§ÑÁêÜÁöÑÊó∂ÂÄôÂ∏åÊúõÊòØ0‰∏≠ÂøÉÁöÑÔºâ ‰∏çÊòØ0‰∏≠ÂøÉÁöÑÈóÆÈ¢òÔºöÂ¶ÇÊûúÊâÄÊúâËæìÂÖ•ÁöÑxÈÉΩÊòØpositiveÁöÑËØùÔºåÂæóÂà∞ÁöÑgradientË¶Å‰∏çÈÉΩÊòØpositiveË¶Å‰∏çÈÉΩÊòØnegative ÊúÄÂêéËµ∞Âá∫Êù•ÁöÑË∑ØÂæÑÈÉΩÊòØzig zagÁöÑ expÔºàÔºâÂú®ËÆ°ÁÆó‰∏äÊØîËæÉexpensive tanh ÊääÊï∞Â≠ó‰ªé-1Âà∞1‰πãÈó¥ÂàÜÂ∏ÉÔºåÊòØ‰∏Ä‰∏™‰ª•0‰∏∫‰∏≠ÂøÉÁöÑsigmoidÔºà0-centeredÔºâÔºåÊâÄ‰ª•sigmoidÁöÑÁº∫ÁÇπÔºàsaturatedÁöÑÁÇπ‰ºökill gradientÔºâÁöÑÁº∫ÁÇπËøòÂú® ReLU ËæìÂÖ•ÊòØÊ≠£Êï∞ÁöÑÊó∂ÂÄôÁõ¥Êé•passËøô‰∏™ÂÄºÔºåËæìÂÖ•ÊòØË¥üÊï∞ÁöÑÊó∂ÂÄôÁõ¥Êé•kill ÂèØËÉΩÁöÑ‰ºòÁÇπÔºöÔºàÂÆûÈôÖÂ∫îÁî®ÁöÑÊó∂ÂÄôÊïàÊûúÈùûÂ∏∏Â•Ω‰ΩÜÊòØÂÖ∑‰ΩìËß£ÈáäËµ∑Êù•‰πüÊ≤°ÊúâÈÇ£‰πàÁü•ÈÅì‰∏∫‰ªÄ‰πàÔºâ ‰∏ç‰ºösaturateÔºà‰∏ç‰ºöÊ∂àÂ§±gradientÔºâ ËÆ°ÁÆóÊïàÁéáÈ´ò Êõ¥ÂÆπÊòìÁõ∏‰∫§ ÈóÆÈ¢ò ‰∏çÊòØ0-centered Â¶ÇÊûúxÂ∞è‰∫é0ÔºàÊ≤°ÊúâÊøÄÊ¥ªÔºâ -&gt; kill gradientÔºâ Ê≠ªÁöÑÊó∂ÂÄô‰ºöÊ≠ª‰∏ÄÂ§ßÁâá -&gt; ÊâÄ‰ª•‰∏ÄËà¨ÁöÑÊó∂ÂÄô‰ºöÊääreluÂàùÂßãÂåñÁöÑÊó∂ÂÄôÂä†‰∏ä‰∏Ä‰∏™slightly positive bias Ê≥®ÊÑèlearning rateÔºåÈÄâ‰∏çÂ•ΩÂÆπÊòìÊ≠ª leaky ReLU Âú®Â∞è‰∫é0ÁöÑÊó∂ÂÄô‰ºöÊúâ‰∏Ä‰∏™ÂæÆÂ∞èÁöÑÂÄºÔºåÊâÄ‰ª•‰∏ç‰ºödie Âú®‰ΩøÁî®ÁöÑÊó∂ÂÄôconvergesÁöÑÈÄüÂ∫¶ÊØîsigmoidÂíåtanhÂø´ÂæàÂ§ö Âä†‰∏ä‰∫Ü‰∏Ä‰∏™ÂèÇÊï∞ÔºåÂèØ‰ª•Âú®backÁöÑÊó∂ÂÄôÂ≠¶Âà∞ÔºåËøô‰∏™ÂÄºÂèØ‰ª•Á°ÆÂÆö‰ªñÊòØ‰∏çÊòØReLUÊàñËÄÖÂÖ∂‰ªñÁöÑ Maxout neuron ÊääReLUÂíåleaky ReLUÁªÑÂêà‰∫ÜËµ∑Êù•ÔºåÊúâ‰∏§‰∏™ÂèÇÊï∞„ÄÇÁÆóÂá∫Êù•‰∏§‰∏™ÂàÜÂà´ÁöÑÂÄºÁÑ∂ÂêéÂèñÂÖ∂‰∏≠Â§ßÁöÑÈÇ£‰∏™ ‰∏ç‰ºöÂèëÁîüsaturateÊàñËÄÖdieÁöÑÈóÆÈ¢ò ÈóÆÈ¢òÂú®‰∫éÂèÇÊï∞ÈúÄË¶ÅËÆ°ÁÆó‰∏§Ê¨° Ê≠•È™§Ôºö È¢ÑÂ§ÑÁêÜÊï∞ÊçÆ -&gt; ÈÄâÊã©architecturedata preprocessingML Â§ÑÁêÜÊï∞ÊçÆÁöÑÊó∂ÂÄôÈ¶ñÂÖàÈúÄË¶Å0-center -&gt; ÂáèÂéªÂπ≥ÂùáÂÄºÔºà‰∏çÊòØÁâπÂà´ÈúÄË¶ÅnormalizeÔºåMLÈúÄË¶ÅÔºâ PCAÔºåWhiteningÔºåÂÖ∂ÂÆûÈÉΩÂú®DLÈáå‰∏çÊÄé‰πàÂ∏∏Áî® ÂÆûÈôÖÂ∫îÁî®ÈáåÔºöÂè™ÈúÄË¶Åcenter ÊØîÂ¶Ç‰∏ÄÂº†ÂõæÊòØ32x32x3ÁöÑ ÂáèÂéªmean imageÔºà32x32x3Ôºâ ÂáèÂéªper-channel mean ÔºàÊØè‰∏™channelÁöÑmeanÔºå‰∏ÄÂÖ±ÊòØ‰∏â‰∏™Êï∞Â≠óÔºâ weight initializationÔºàÈáçË¶ÅÔºâËØ∑‰∏çË¶ÅËøô‰πàÂÅöÔºösetÊâÄÊúâwÈÉΩÊòØ0ÔºåÂæóÂà∞ÁöÑÁªìÊûúÂ∞±ÊòØÊØè‰∏™Á•ûÁªèÂÖÉÁöÑÂäüËÉΩÈÉΩÊòØ‰∏ÄÊ†∑ÁöÑ small random numbers 0.01* np.random.randn(D,H) ÈóÆÈ¢òÔºö Âú®ÊØîËæÉÂ∞èÁöÑnetÈáåÂèØ‰ª•‰ΩøÁî® Âú®layer‰πãÈó¥‰ºöÂèëÁîünon-homogeneous distribution of activationÁöÑÈóÆÈ¢ò ÊâÄÊúâÁöÑactivations‰ºöÂèòÊàê0 Âú®backÁöÑÊó∂ÂÄôÊâÄÊúâÁöÑgradientÈÉΩ‰ºöÂèòÊàê0 Â¶ÇÊûúÊää0„ÄÇ01ÂèòÊàê‰∫Ü1ÔºåËøôÊó∂ÂÄôÂèëÁé∞ÊâÄÊúâÁöÑneuronsÂÖ®ÈÉΩÊòØ1ÊàñËÄÖ-1 -&gt; gradient‰πüÂÖ®ÈÉΩÊòØ0ÔºåÊ≠ª‰∫° ÂÖ∂‰ªñÁöÑ‰∏Ä‰∫õËÆ∫Êñá‰πüËÆ®ËÆ∫ËøáÂÖ∂‰ªñÊñπÊ≥ï Xavier 2010 Èô§‰ª•inputÁöÑsqrt ReLUÔºå non-liearÔºå‰ºöbreaking„ÄÇÊØèÂõûreluÈÉΩ‰ºöÊùÄÊéâ‰∏ÄÂçäÁöÑ‰∏úË•øÔºåsetÂà∞0 He 2015 ÊääinputÈô§‰ª•2‰ª•Âêésqrt‰∫Ü Âú®ÂÆûË∑µ‰∏≠ÂæàÊúâÁî® batch normalization -&gt; ÂÆûÈôÖ‰∏≠Ëß£ÂÜ≥wÂàùÂßãÂåñÁöÑÊñπÊ≥ï Ê†∏ÂøÉÊÄùÊÉ≥ÔºöxË∂äÊù•Ë∂äÊé•Ëøë0ÁöÑÂéüÂõ†ÊòØÂõ†‰∏∫Ë∂ä‰πòË∂äÂ∞èÔºàÊàñËÄÖË∂äÂ§ßÔºâÔºåËøô‰∏™Êó∂ÂÄôÊàë‰ª¨Â∞±Â∏åÊúõÂèØ‰ª•normalizeËøô‰∏™xÁöÑinput„ÄÇÂõ†‰∏∫gaussianÁöÑnormaliztionÊòØÂèØ‰ª•ÁßØÂàÜÁöÑÔºåÊâÄ‰ª•ÂèØ‰ª•ÊîæÂõûÂà∞backÈáåÈù¢ÔºåÂú®Êï¥‰∏™ÁöÑÁΩëÁªúÈáåÈù¢ÊèíÂÖ•‰∏Ä‰∫õnormalizeÁöÑÈÉ®ÂàÜÂ∞±ÂèØ‰ª•‰∫Ü ÊèíÂú®FCÊàñËÄÖCNN‰πãÂêéÔºåÁÑ∂ÂêéÊîæÂú®ÊøÄÊ¥ªÂáΩÊï∞‰πãÂâç ‰ºòÁÇπ ÊèêÈ´ònetÈáåÈù¢ÁöÑgradient flow ÂÖÅËÆ∏Êõ¥È´òÁöÑÂ≠¶‰π†Áéá ÂáèÂ∞ëÂØπÂàùÂßãÂåñÂèÇÊï∞ÁöÑÂΩ±Âìç form of regularization -&gt; ÂèØËÉΩÂèØ‰ª•ÂáèÂ∞ëdropoutÁöÑÈúÄÊ±Ç babysitting &amp; learning processÊ£ÄÊü•lossÁÆóÁöÑÂØπ‰∏çÂØπ ÂàùÂßãÂåñËøô‰∏™netÔºåÂéªÊéâregularizationÔºåÊ£ÄÊü•ÊúÄÂêéËøîÂõûÁöÑloss Âõ†‰∏∫‰ªÄ‰πàÈÉΩÊ≤°ÂÅöÂë¢ÔºåÊâÄ‰ª•lossÂ∫îËØ•ÊòØÊúÄÁªàÁü•ÈÅìÁöÑÂÄºÔºà10 classÊòØ2„ÄÇ3Ôºâ ÂÜçÂä†‰∏äregularizationÔºåÁªìÊûúÂ∫îËØ•Â∞èÂ∞èÁöÑÂèòÂåñ Â∞ùËØïËÆ≠ÁªÉ overfit‰∏Ä‰∏™ÈùûÂ∏∏Â∞èÁöÑdatasetÔºåÂÖ≥ÊéâregÔºåÂæóÂà∞ÈùûÂ∏∏Â∞èÁöÑlossÂíåÂæàÈ´òÁöÑaccuracy ‰∏Ä‰∏™ÂèØËÉΩÊÄßÔºöÂª∫ËÆÆ‰ª•‰∏Ä‰∏™Â∞èÁöÑregÂºÄÂßãÔºåÊâæÂà∞ËÆ©lossÂèòÂ∞èÁöÑlearning rateÔºàÂ¶ÇÊûú‰∏çÂèòÂ∞èÂèØËÉΩÊòØrateÂ§™Â∞è‰∫ÜÔºâ costÔºöNaNÔºåÂèØËÉΩÊòØlearning rateÈ´ò‰∫Ü Âª∫ËÆÆËåÉÂõ¥Ôºö 1e-3 ~ 1e-5 hyper optimization‰∫§ÂèâÈ™åËØÅ ÊâæÂà∞ÂáÜÁ°ÆÁéáÈ´òÁöÑÈÉ®ÂàÜÔºå‰ΩøÁî®ÂÖ∂‰∏≠ÁöÑhyper ÊúÄÂ•ΩsetÂà∞logÁöÑspace ÂÜçË∞ÉÊï¥parameterÔºåÊâæÂà∞Êõ¥ÂáÜÁ°ÆÁöÑÂÄº Â¶ÇÊûúÁªìÊûúÁâπÂà´Â•ΩÂèØËÉΩ‰πü‰∏çÂØπÔºåÂèØËÉΩÊòØÂ∑≤ÁªèÂà∞‰∫Üboundary‰∫Ü ÂèÇÊï∞ÁöÑÈÄâÊã©sample randomlyÁöÑÁªìÊûúÊõ¥Â•ΩÔºå‰∏çË¶ÅÂõ∫ÂÆö‰∏Ä‰∏™ÈÄâÂè¶‰∏Ä‰∏™ÔºåÂèØËÉΩ‰∏Ä‰∏™ÂèÇÊï∞ÊØîÂè¶Â§ñ‰∏Ä‰∏™ÈáçË¶ÅÂæàÂ§ö Â¶ÇÊûúËÆ≠ÁªÉÂíåÈ™åËØÅ‰πãÈó¥ÁöÑgapÂ§™Â§ßÔºåËØ¥ÊòéoverfittingÔºåÈúÄË¶ÅÂ¢ûÂä†regÁöÑÂäõÂ∫¶„ÄÇÂ¶ÇÊûúÂ§™Â∞èÂèØËÉΩÈúÄË¶ÅÂ¢ûÂä†modelÁöÑÂÆπÈáè ratio between the values and updates: ~ 0.0002 / 0.02 = 0.01 (about okay) ÈúÄË¶ÅÈÄâÊã©ÁöÑhyper net architecture learning rate. decay schedule and update type regularization(L2/Dropout) ##ÊÄª‰Ωìsummary training Neural Net2parameter updateSGD ‰ª•ÂâçÊòØÁõ¥Êé•Áî®gradientÊù•updateÔºåÁé∞Âú®Â∏åÊúõÂèòÂæóÂ§çÊùÇ‰∏ÄÁÇπ -&gt; SGDÂ§™ÊÖ¢‰∫Ü ‰∏∫‰ªÄ‰πàSGDÂ§™ÊÖ¢Ôºö Â¶ÇÊûúÂú®‰∏Ä‰∏™lossÁöÑÂàÜÂ∏É‰∏äÔºå‰∏Ä‰∏™Áª¥Â∫¶ÁâπÂà´ÂØÜÈõÜÔºåÂè¶‰∏Ä‰∏™Áª¥Â∫¶ÁâπÂà´Á®ÄÁñèÔºåÁõ¥Êé•Áî®gradientÊîπÂèòÂ∞±‰ºöÂú®‰∏Ä‰∏™ÊñπÂêëË∑ëÂ§ß‰∫Ü ÊúÄÂêéÂ∞±‰ºöÂΩ¢ÊàêÈÇ£ÁßçzagÁöÑÂΩ¢Áä∂ momentum update Âú®ËÆ°ÁÆóÁöÑÊó∂ÂÄôÂºïÂÖ•‰∫ÜÈÄüÂ∫¶v = mu v - learning_rate dx ÔºàvÂàùÂßãÂåñ‰∏∫0Ôºâ ÂÅáËÆæË∑ØÁ∫øÂ∞±ÊòØ‰∏Ä‰∏™ÁêÉÂú®lossÁöÑÂúÜÂºßÈáåÈù¢ËøêÂä®ÔºåmuÊòØÔΩû0.5Ôºå0.9Ôºå0.99ÔºàÂè™‰ΩøÁî®‰∏Ä‰∏™ÂÄºÔºåsingle numberÔºåhyperÔºâ ÂΩ¢ÊÄÅÔºå‰ªéÂàùÂßãÁÇπÂºÄÂßãËµ∞‰∏Ä‰∏™Â§ßÁöÑÂúÜÂºßÔºå‰ºöË∑ëËøá‰∫ÜÔºå‰ΩÜÊòØ‰ºöÂÜçÂø´ÈÄüÁöÑconvergeÂõûÂéª ‰ºòÁÇπ ÂºïÂÖ•‰∫ÜÈÄüÂ∫¶ÔºåÂèØ‰ª•Âú®ÊØîËæÉshallowÁöÑÊñπÂêë‰∏äÈÄüÂ∫¶ÈÄêÊ∏êÂ¢ûÂä† Âú®ÊØîËæÉÊ∑±ÁöÑÁª¥Â∫¶‰∏äÈù¢ÔºåÂ∞±ÂÉèÁêÉÂú®ÂúÜÂºßÈáåÈù¢Êù•ÂõûÊªëÂä® ÁêÜËß£ ÊòØÂØπËøô‰∏™update‰∏ÄÁÇπÁâ©ÁêÜ‰∏äÊØîËæÉÁõ¥ËßÇÁöÑÁêÜËß£ÔºàÂÖ∂ÂÆûÂêçÂ≠óÂè´ÂÅöÂä®ÈáèÔºâ ÂèØ‰ª•ÁêÜËß£‰∏∫Ëøô‰∏™‰∏úË•øÊòØÂú®‰∏Ä‰∏™Âπ≥Âéü‰∏äË∑ëÁöÑ‰∏Ä‰∏™ÁêÉÔºåÊàë‰ª¨ÈúÄË¶ÅÊ±ÇÁöÑwÊòØËøô‰∏™ÁêÉÁöÑÈÄüÂ∫¶ÔºåÂæóÂà∞ÁöÑdwÊòØËøô‰∏™ÁêÉÁöÑÂä†ÈÄüÂ∫¶ÔºåËÄåËøô‰∏™ÁêÉÁöÑÂàùÈÄüÂ∫¶ÊòØ0 ÂèØ‰ª•ÁêÜËß£‰∏∫Ëøô‰∏™ÁêÉÊâæÊúÄ‰ΩéÁÇπÁöÑÊó∂ÂÄôÔºåÈô§‰∫ÜÊØèÊ≠•Êåâdw updateÔºåËøòÂú®‰∏äÈù¢Âä†‰∏ä‰∫ÜÂâçÈù¢ÈÄüÂ∫¶ÁöÑÂΩ±ÂìçÔºå‰πüÂ∞±ÊòØÂä†‰∏ä‰∫ÜÊÉØÊÄßÔºÅ123# Momentum updatev = mu * v - learning_rate * dx # integrate velocityx += v # integrate position nesterov momentum update Âú®‰∏äÈù¢ÁöÑÊñπÊ≥ï‰πãÂêé look a head ‰∫Ü‰∏ÄÊ≠•ÔºåÂæóÂà∞ÁöÑÊòØ‰∏§‰∏™ÂêëÈáè‰πãÈó¥ÁöÑÂ∑Æ Âú®ÂÆûÈôÖËµ∞ÁöÑËøáÁ®ãÂΩì‰∏≠ÔºåÂºßÂ∫¶‰ºöÊØîmonnumentÁöÑÊõ¥Â§ß‰∏Ä‰∫õÔºåË∑ëËøáÁöÑ‰ºöÊõ¥Â∞è‰∏Ä‰∫õ ÁêÜËß£ Nesterov Momentum(NAG) Âú®ÂéüÊù•ÁöÑÂü∫Á°Ä‰∏äÔºöÁúüÂÆûÁßªÂä®ÊñπÂêë = ÈÄüÂ∫¶ÁöÑÂΩ±ÂìçÔºàmomentumÔºâ+ Ê¢ØÂ∫¶ÁöÑÂΩ±Âìç ÔºàgradientÔºâ Áé∞Âú®ÔºöÊó¢ÁÑ∂Êàë‰ª¨Â∑≤ÁªèÁü•ÈÅì‰∫ÜË¶ÅÂæÄÂâçËµ∞Âà∞Âä®ÈáèÁöÑÂΩ±ÂìçÁöÑ‰ΩçÁΩÆÔºåÈÇ£‰πàÊàëÊ†πÊçÆÈÇ£‰∏™‰ΩçÁΩÆÁöÑÊ¢ØÂ∫¶ÂÜçËøõË°åupdateÔºåÂ≤Ç‰∏çÊòØË∑ëÁöÑÊõ¥Âø´ÔºÅ ÊÄªÁöÑÊù•ËØ¥Â∞±ÊòØËÄÉËôëÂà∞‰∫ÜÂâçÈù¢ÁöÑÂù°Â∫¶Ôºà‰∫åÈò∂ÂØºÊï∞ÔºâÔºåÂ¶ÇÊûúÂâçÈù¢ÁöÑÂù°Â∫¶ÁºìÁöÑËØùÊàëÂ∞±ÂÜçË∑ëÂø´ÁÇπÔºåÂ¶ÇÊûúÈô°ÁöÑËØùÂ∞±Ë∑ëÊÖ¢ÁÇπ123v_prev = v # back this upv = mu * v - learning_rate * dx # velocity update stays the samex += -mu * v_prev + (1 + mu) * v # position update changes form adaGrad Ôºàparameter-adaptiveÔºâ È¶ñÂÖàÂÆö‰πâ‰∫Ü‰∏Ä‰∏™cacheÔºåËøô‰∏™cacheÊòØgradientÁöÑÂπ≥ÊñπÁöÑÂíåÔºåÂè™ÊòØpositiveÔºåÂíåparameterÁöÑÁª¥Â∫¶ÊòØ‰∏ÄÊ†∑ÁöÑ ÁÑ∂ÂêéÊääSGDÁöÑÂ≠¶‰π†ÁéáÔºàÂÖ®Â±ÄÁöÑlearning rateÔºâscale‰∫Ü‰∏Ä‰∏™Ëøô‰∏™Êï∞ -&gt; ËøôÊ†∑ÂæóÂà∞ÁöÑÊòØ‰∏çÂêåÂèÇÊï∞ÁöÑÂ≠¶‰π†Áéá ‚Äú Added element-wise scaling of the gradient based on the historical sum of squares in each dimension‚Äù ÁªìÊûúÔºöÂú®Ë∂äÂØÜÈõÜÁöÑÁª¥Â∫¶‰∏äÔºåupdateÁöÑÊ≠•‰ºêË∂äÂ∞èÔºåË∂äÁ®ÄÁñèÁöÑ‰∏äÈù¢updateË∂äÂ§ßÔºàÂõ†‰∏∫Âπ≥ÁºìÁöÑÂú∞ÊñπÂéÜÂè≤gradientÁöÑÂπ≥ÊñπÂíåÊõ¥Â∞èÔºåÊâÄ‰ª•update‰ºöÊõ¥Â§ßÔºâ ÈóÆÈ¢ò step sizeÔºöÊó∂Èó¥Ë∂äÈïølearning rate‰ºöÊúÄÁªàÂèòÂà∞0ÔºåÁÑ∂ÂêéÂ∞±ÂÅúÊ≠¢Â≠¶‰π† RMSPropÔºà‰∏äÈù¢‰∏Ä‰∏™ÁöÑÂèòÂΩ¢Ôºâ ÊääcacheÁöÑÂÆö‰πâÊîπÂèò‰∫ÜÔºåÂ¢ûÂä†‰∫Ü‰∏Ä‰∏™decay rateÔºàhyperÔºâ adaGrad‰ºöËÆ°ÁÆóÁöÑÊòØÊâÄÊúâÊ¢ØÂ∫¶ÁöÑÂπ≥ÊñπÁöÑÂíåÔºåËÄåËøô‰∏™ËÆ°ÁÆóÁöÑÊòØgradientÂØπÂ∫îÁöÑÂπ≥ÂùáÂÄºÔºåËøôÊ†∑ÁöÑËØùlearning rateÁöÑ‰∏ãÈôç‰ºöÊõ¥ÊÖ¢ ‰æùÁÑ∂ËÉΩ‰øùÊåÅÂêÑ‰∏™Áª¥Â∫¶‰∏äÈù¢ÁöÑÂπ≥Ë°°Ôºå‰ΩÜÊòØ‰∏ç‰ºöËÆ©learning rateÂèòÂà∞0 adam -&gt; Âè¶‰∏ÄÁßçËá™ÈÄÇÂ∫îÂ≠¶‰π†ÁéáÁöÑÁÆóÊ≥ï betaÈÉΩÊòØhyper ÁªìÂêà‰∫Ü‰∏äÈù¢ÁöÑ‰∏§ÁßçÊñπÊ≥ï Âà©Áî®Ê¢ØÂ∫¶ÁöÑ‰∏ÄÈò∂Áü©Âíå‰∫åÈò∂Áü©‰º∞ËÆ°Âä®ÊÄÅË∞ÉÊï¥ÊØè‰∏™ÂèÇÊï∞ÁöÑÂ≠¶‰π†Áéá -&gt; ÊØèÊ¨°Ëø≠‰ª£Â≠¶‰π†Áéá‰ºöÊúâ‰∏Ä‰∏™ËåÉÂõ¥ÔºåËÆ©ÂèÇÊï∞ÊØîËæÉÂπ≥Á®≥ ÂØπÊ¢ØÂ∫¶ÁöÑ‰∏ÄÈò∂Âíå‰∫åÈò∂‰º∞ËÆ°ÔºàÊúüÊúõÁöÑËøë‰ººÔºâ ÂÆûÈôÖ‰ΩøÁî® ÈªòËÆ§Áî®adam ÂàöÂºÄÂßã‰ΩøÁî®È´òÁöÑlearning rate -&gt; ËøôÊ†∑ËøõÂ±ï‰ºöÈùûÂ∏∏Âø´ decay over time -&gt; Âú®ËøõË°åÂà∞‰∏ÄÂÆöÁ®ãÂ∫¶ÁöÑÊó∂ÂÄô‰ºöÊ≤°ÊúâÂäûÊ≥ïÊõ¥ÁªÜËá¥ÁöÑÈÄºËøëminimum step decay: ÊØîÂ¶ÇËøá‰∏Ä‰∫õepoch‰πãÂêéÂ∞±ÊäälrÂáèÂ∞ëÂà∞‰∏ÄÂçä exponential decay 1/t decay secend order optimization methodÔºàmlÔºâ Âú®ËÆ°ÁÆóÁöÑÊó∂ÂÄô‰∏ç‰ªÖÈúÄË¶ÅgradientÔºåËøòÈúÄË¶ÅhessianÊù•ÂëäËØâ‰Ω†Êõ≤Èù¢ÁöÑcurveÁ®ãÂ∫¶Ôºå‰ª•Ê≠§Êù•Á°ÆÂÆöÂ¶Ç‰ΩïÂâçËøõÔºàÁâõÈ°ømethodÔºâ ÈÄüÂ∫¶Êõ¥Âø´ÔºåhyperÊõ¥Â∞ë ‰ΩÜÊòØÂú®deep netsÈáåÈù¢‰∏çÂ§™ËÉΩ‰ΩøÁî®ÔºåÂõ†‰∏∫ÂèÇÊï∞Â§™Â§öÊÉπ BFGSÔºàapproximate inverse Hessian with rank 1 updates over time (O(n^2) each). L-BFGS work well in full batch mini-batch‰∏çÊòØÂæàÈÄÇÁî® evaluationÔºömodel ensembles ÂèØ‰ª•‰∏çÁî®ËÆ≠ÁªÉÂæàÂ§ö‰∏™modelÔºåËÄåÊòØËÆ≠ÁªÉ‰∏Ä‰∏™ÁÑ∂ÂêéÂú®ÂÖ∂‰∏≠ÈÄâÂèñ‰∏ç‰∏ÄÊ†∑ÁöÑcheck point track‰∏Ä‰∏™ÂèÇÊï∞vectorÁöÑrunning averageÂèØËÉΩ‰ºöÂæóÂà∞Êõ¥Â•ΩÁöÑÊïàÊûú regularizationÔºàDROPOUTÔºâ Âú®forwardÁöÑÊó∂ÂÄôÔºåÈöèÊú∫ÁöÑÊää‰∏Ä‰∫õneruonÁöÑÂÄºËÆæÁΩÆÊàê0ÔºàÊØîÂ¶ÇÊùÄÊéâ‰∏ÄÂçäÔºâ ‰∏∫‰ªÄ‰πàË¶Å‰ΩøÁî®Ôºö ‰∏∫‰∫ÜÊ±ÇÂá∫Êù•ÁöÑÁªìÊûúÊõ¥Âä†ÁöÑÂáÜÁ°ÆÔºåÊØè‰∏™ÁâπÂÆöÁöÑÁâπÂæÅÈÉΩ‰∏çËÉΩÂÆåÂÖ®‰æùËµñÔºåÂõ†‰∏∫Ëøô‰∏™featureÂèØËÉΩÂ∞±Ë¢´dropÊéâ‰∫Ü ËÆ°ÁÆó‰∏Ä‰∏™Â§ßÁöÑnetÁöÑÂÖ∂‰∏≠‰∏ÄÂ∞èÈÉ®ÂàÜÔºåË¢´dropÊéâÁöÑÈÉ®ÂàÜÂú®backÁöÑÊó∂ÂÄô‰πü‰∏ç‰ºöÂÜçËÆ°ÁÆó‰∫ÜÔºåÂ∞±ÂΩªÂ∫ïÂÖ≥Êéâ‰∫Ü„ÄÇÁõ∏ÂΩì‰∫éÂú®netÈáåÈù¢Âèñ‰∫Ü‰∏ÄÈÉ®ÂàÜsample test time Âú®ÊµãËØïÁöÑÊó∂ÂÄôÂ∏åÊúõÂèØ‰ª•ÊääÊâÄÊúâÁöÑneuronÈÉΩÊâìÂºÄÔºàÂ∞±ËøõË°å‰∏ÄÊ¨°Ôºâ scaleÔºÅÔºÅÔºÅÔºÅ ÈúÄË¶ÅÊ≥®ÊÑèÁöÑÈóÆÈ¢òÔºö ËÆ°ÁÆóËÆ≠ÁªÉÊó∂ÂÄôÁöÑÊúüÊúõÔºåÂ∞±ÂèëÁé∞dropout‰πãÂêéÁöÑÊúüÊúõÊòØÊµãËØïÁöÑÂÆûÈôÖÂÄºÁöÑ1/2ÔºàÂõ†‰∏∫drop‰∫Ü‰∏ÄÂçäÔºâ Âõ†‰∏∫‰ª•ÂâçnetÊ≤°ËßÅËøáËøô‰πàÂ§ßÁöÑoutputÔºå‰ºöÁõ¥Êé•Ê≠ªÊéâÔºåÊâÄ‰ª•ÈúÄË¶ÅÊääÊµãËØïÊó∂ÂÄôÁöÑÁªìÊûúÂÜçÁº©Â∞è‰∏ÄÂçäÔºàÊàñËÄÖdropÁöÑÊØî‰æãÔºå* pÔºâ ÊúÄÁªàÁªìÊûúÔºöÊµãËØïÊó∂ÂÄôÁöÑËæìÂá∫ = ËÆ≠ÁªÉÊó∂ÂÄôÁöÑÊúüÊúõËæìÂá∫ Âè¶‰∏ÄÁßçÊñπÊ≥ï inverted dropout Âú®trainÁöÑÊó∂ÂÄô / p Âú®ÊµãËØïÁöÑÊó∂ÂÄôÂ∞±‰∏çÁî®ÊîπÂèò‰∫Ü gradient checkingÔºàÂπ∂Ê≤°ÊúâËÆ≤ÔºâCNNÂºÄÂßãÂï¶Âç∑ÁßØÂ±ÇÔºàÊ†∏ÂøÉÈÉ®ÂàÜÔºâ ÂØπ‰∏ÄÂº†ÂõæÁâáÊìç‰ΩúÔºö Êã•Êúâ‰∏ÄÂº†ÂõæÂÉè32x32x3 Êã•ÊúâÂç∑ÁßØÊ†∏5x5x3ÔºàËøô‰∏§‰∏™‰∏úË•øÂøÖÈ°ªÁª¥Â∫¶‰∏ÄÊ†∑Ôºâ -&gt; Â•áÊï∞Â∞∫ÂØ∏ÁöÑÊïàÊûúÊõ¥Â•Ω kernalÂÅöÂç∑ÁßØÔºàÊâÄÊúâÁöÑchannelÔºâÔºåÂæóÂà∞‰∏Ä‰∏™28x28x1ÁöÑactivaton map ÂÜçÂØπËøôÂº†ÂõæÁâá‰ΩøÁî®‰∏ã‰∏Ä‰∏™‰∏çÂêåÁöÑÂç∑ÁßØÊ†∏ÔºàÂç∑ÁßØÊ†∏ÁöÑÊï∞ÈáèÊòØ‰∏Ä‰∏™hyperÔºâ ËøôÊ†∑‰∏Ä‰∏™32x32x3ÂèòÊàê‰∫Ü‰∏Ä‰∏™28x28x6Ôºà6ÊòØÈÄâÊã©ÁöÑhyperÁöÑÊï∞ÈáèÔºâ ÂΩìÊääËøô‰∫õÂ±ÇÂèØËßÜÂåñ‰∫Ü‰πãÂêéÔºåÂèëÁé∞Ë∂äÊ∑±ÂõæÁâáÁöÑfeatureË∂äÈ´òÁ∫ßÔºà‰ªé‰∏ä‰∏ÄÁ∫ßÁöÑÁâπÂæÅÂæóÂà∞ÁöÑÊñ∞ÁöÑÁâπÂæÅÔºâ Â§ßËá¥Â∏ÉÂ±Ä Âç∑ÁßØÂ±Ç RELUÂ±Ç -&gt; ÈªëÁôΩÂåñ poolingÂ±Ç ÊúÄÂêéÂä†‰∏äfcÂ±Ç ÂÖ∑‰ΩìËÆ°ÁÆóstride ÊØèÊ¨°Âç∑ÁßØÊ†∏ÁßªÂä®ÁöÑÊó∂ÂÄôÁöÑÊ≠•Èïø Ê≥®ÊÑèÂú®‰∏çÂêåÂõæÁâáÂ§ßÂ∞èÔºå‰∏çÂêåÂç∑ÁßØÊ†∏Â§ßÂ∞èÂíå‰∏çÂêåÊ≠•ÈïøÂèØËÉΩ‰∏çÂåπÈÖç ÔºàÂõæÁâá - Âç∑ÁßØÊ†∏Ôºâ/Ê≠•Èïø + 1 ÊòØ‰∏çÊòØÊï¥Êï∞ÔºåÁªìÊûúÊòØËæìÂá∫ÂõæÁâáÁöÑÂ∞∫ÂØ∏ padding ÂèØ‰ª•Âú®ÂõæÁâáÂë®Âõ¥‰∏ÄÂúàÂä†‰∏ä‰∏ÄÂúà0ÔºåËøôÊ†∑ÂõæÁâáÂç∑ÁßØ‰πãÂêéÁöÑÂ§ßÂ∞èÂ∞±‰∏çÂèò‰∫Ü 0-paddingÁöÑÂ§ßÂ∞èÂíåÂç∑ÁßØÊ†∏ÁöÑÂ§ßÂ∞èÊúâÂÖ≥ÔºåÂ§ßÂ∞èÊòØÔºàÂç∑ÁßØÊ†∏ -1Ôºâ/2 Â¶ÇÊûú‰∏çËøõË°åpaddingÔºåÂõæÁâá‰ºöË∂äÊù•Ë∂äÂ∞è ÂèÇÊï∞Êï∞Èáè ÂØπ‰∏Ä‰∏™Âç∑ÁßØÊ†∏ÔºöÂç∑ÁßØÊ†∏ÁöÑÂ§ßÂ∞è * Ê∑±Â∫¶ + 1 ÔºàÂä†‰∏ÄÊòØÂä†‰∫Ü‰∏Ä‰∏™biasÔºâ ‰∏ÄÂ±ÇÁöÑÂèÇÊï∞Ôºö Âç∑ÁßØÊ†∏Êï∞Èáè * ‰∏Ä‰∏™Âç∑ÁßØÊ†∏ Âõõ‰∏™hyperÔºö KÔºöfilterÁöÑÊï∞ÈáèÔºå2ÁöÑÊåáÊï∞ -&gt; ËÆ°ÁÆóÊïàÁéáÈ´ò SÔºöÊ≠•Èïø FÔºöÂç∑ÁßØÊ†∏Â§ßÂ∞è PÔºö0-padding 1x1ÁöÑÂç∑ÁßØ 1x1ÁöÑÂç∑ÁßØÂ±ÇÔºàstride‰πüÊòØ1Ôºâ‰ºöÊúâÊØîËæÉÂ•ΩÁöÑÊïàÊûú ÊØîÂ¶ÇËæìÂÖ•ÊòØ56x56x64ÔºåfilterÊòØ32‰∏™1x1x64„ÄÇÂõ†‰∏∫Êï∞ÊçÆÊòØÊúâÊ∑±Â∫¶ÁöÑÔºå1x1ÁöÑÊó∂ÂÄôÊòØÊúâÊÑè‰πâÁöÑÔºàÂú®‰∫åÁª¥‰∏äÈù¢Ê≤°ÊúâÊÑè‰πâÔºâ Áé∞Âú®Â§ÑÁêÜÁöÑ‰∏úË•øÈÉΩÊòØÊñπÂΩ¢ÁöÑ‰ªéÁ•ûÁªèÂÖÉÁöÑËßíÂ∫¶Êù•ÁúãCNN ÂèØ‰ª•ÊääfilterËÆ§‰∏∫Êàê‰∏Ä‰∏™Âõ∫ÂÆö‰ΩçÁΩÆÁöÑÁ•ûÁªèÂÖÉÔºåËøô‰∏™Á•ûÁªèÂÖÉÂè™ÁúãÂà∞‰∫ÜÂõæÁâá‰∏äÈù¢ÁöÑ‰∏ÄÂ∞èÈÉ®ÂàÜÔºåÊ≤°ÊúâÂíåÂÖ®ÈÉ®ÁöÑÂõæÁâáÁõ∏ËøûÔºåÁÑ∂ÂêéËøõË°å‰∫Üwx+bÁöÑËøêÁÆó ÂΩìslideËøô‰∏™filterÁöÑÊó∂ÂÄôÔºåweightÊòØ‰∏çÂèòÁöÑÔºåÂèØ‰ª•ÂÅáËÆæÊàê‰∏ÄÂúàÂÖ±‰∫´ÂèÇÊï∞ÁöÑÁ•ûÁªèÂÖÉ ÂØπÂêå‰∏ÄÂº†ÂõæÁâáÁöÑ‰∏çÂêåÁöÑfilterÂèØ‰ª•ËÆ§‰∏∫Êàê‰ªñ‰ª¨ÊòØÂú®‰∏âÁª¥‰∏äÈù¢ÊéíÂàóÁöÑ‰∏ÄÁªÑÁ•ûÁªèÂÖÉÔºåÊØè‰∏ÄÂ±ÇÁ•ûÁªèÂÖÉÈÉΩÂíåËøô‰∏ÄÂ±ÇÂÖ±‰∫´ÂèÇÊï∞Ôºà‰∏çÂ∏åÊúõÂÖ®ÈÉ®ÈÉΩÊòØÂÖ®ËÅîÊé•ÔºåÂõ†‰∏∫Êµ™Ë¥π‰∫ÜÂæàÂ§öÂèÇÊï∞Ôºâ pooling Âú®Âç∑ÁßØÁöÑÊó∂ÂÄôÊòØ‰∏ç‰ºöÊîπÂèòÂõæÁâáÁöÑÂ§ßÂ∞èÁöÑ ÊîπÂèòÂõæÁâáÂ§ßÂ∞èÁöÑÊìç‰ΩúÂú®pooling layerÈáåÈù¢ÂÆûÁé∞ ÈïøÂÆΩÁº©Áü≠ÔºåÊ∑±Â∫¶‰∏çÂèò max pooling 2x2poolÔºåstride2 -&gt; ÊØè4‰∏™Ê†ºÂ≠êÈáåÈù¢ÈÄâÊã©‰∏Ä‰∏™ÊúÄÂ§ßÁöÑË°®Á§∫ ‰∏§‰∏™ÂèÇÊï∞ pooling size F 2Ôºå3 stride S 2Ôºå2 ‰∏ç‰ºöÊîπÂèòÂõæÁâáÁöÑÊ∑±Â∫¶ fully connected Â∞±Ë∑üÊôÆÈÄöÁöÑÁ•ûÁªèÁΩëÁªú‰∏ÄÊ†∑ÔºåÊâÄÊúâÁ•ûÁªèÂÖÉ‰πãÈó¥ÈÉΩ‰ºöËøûÊé• ÊääÊúÄÂêéÁöÑÂõæÁâáÂèòÊàê‰∏Ä‰∏™ÂàóÔºåÊîæËøõÂéªÂºÄÂßãËÆ°ÁÆó ÂÆûÈôÖÂ∫îÁî®LeNet-5AlexNet ‰∏§Â§©‰∏çÂêåÁöÑÁ∫øÔºåÂõ†‰∏∫ÂΩìÊó∂ÁöÑGPUÁöÑÊïàÊûú‰∏çÂ§ü ‰ºòÁÇπÔºö Á¨¨‰∏ÄÊ¨°‰ΩøÁî®ReLU Êäädata normalization‰∫ÜÔºå‰ΩÜÊòØÁé∞Âú®ÁúãÂÖ∂ÂÆûÂπ∂‰∏çÈúÄË¶Å data augumenation -&gt; ÊúâÁî®ÔºÅ dropout 0.5ÔºåÊúÄÂêéÂá†Â±Ç ZFNet Âú®Á¨¨‰∏ÄÂ±Ç‰∏äÊØîalexÁöÑstrideÁü≠ÔºåÂõ†‰∏∫alexÁöÑÊ≠•Èïø4Ë∑≥Ëøá‰∫ÜÂ§™Â§öÂõæÁâá‰ø°ÊÅØÔºåËøôÈáåÊîπÊàê‰∫ÜÊ≠•Èïø2 fliterÁöÑÊï∞ÈáèÊõ¥Â§ö VGGNet Âè™Êúâ3x3 s1 p1ÁöÑÂç∑ÁßØÊ†∏ÔºåÂíå2x2 s2ÁöÑmax pooling ÁªìÊûúËøòÁâπÂà´Â•Ω ÂõæÂÉèÁöÑÂ∞∫ÂØ∏Ë∂äÊù•Ë∂äÂ∞èÔºå‰ΩÜÊòØÊ∑±Â∫¶Ë∂äÊù•Ë∂äÈ´ò ÈúÄË¶ÅÁöÑËÆ°ÁÆóÈáèÔºö93MB/imageÔºàforwardÔºâ -&gt; 200m/image(ÊâÄÊúâÁöÑËÆ°ÁÆóÂä†Ëµ∑Êù•) Â§ßÈÉ®ÂàÜÁöÑmemoryÈÉΩÂú®ÂâçÊúüÁöÑÂ±ÇÈáåÔºåÂ§ßÈÉ®ÂàÜÁöÑÂèÇÊï∞ÈÉΩÂú®ÊúÄÂêéÁöÑÂÖ®ÈìæÊé•Â±ÇÈáåÈù¢ÔºàÊúÄÂêéÁöÑËÆ°ÁÆóÈáèÂ§™Â§ßÔºåÂêéÈù¢ÊúâÊõ¥Â•ΩÁöÑÊñπÊ≥ïÔºâ VGG‰πüÊúâ‰ΩçÁΩÆÁ°ÆÂÆöÔºå‰ªñÊØîoverfeatÁöÑÂ±ÇÊï∞Êõ¥Ê∑± GoogLeNet ÊòØ‰∏Ä‰∏™‰∏Ä‰∏™ÁöÑÂ∞èÁªìÊûÑÁªÑÊàêÂá∫Êù•‰∫Ü ÂèÇÊï∞ÁöÑÊï∞ÈáèÈùûÂ∏∏Â∞ë 5millionÔºåÂèñÊ∂à‰∫ÜfcÂ±Ç ‰ΩøÁî®‰∫Üaverage poolÔºåÊää7x7x1024ÂèòÊàê‰∫Ü1x1x1024 :ÊääÊØè‰∏™activate mapÂèñÂπ≥ÂùáÂÄº Áî®VGGÁöÑ‰∫∫Êõ¥Â§öÂõ†‰∏∫VGGÁöÑÁªìÊûÑÊØîËæÉÂ•ΩÊÉ≥2333 ResNet t5 errorÈôçÂà∞‰∫Ü3.Â§ö Âπ≥Â∏∏ÁöÑÂä†Ê∑±Â±ÇÊï∞ËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜ‰∏äËæπÁöÑÂáÜÁ°ÆÁéáÂèòÂåñÁªìÊûú‰∏çÁªü‰∏ÄÔºå‰ΩÜÊòØresÂÅöÂà∞‰∫ÜÁªü‰∏Ä ËôΩÁÑ∂Â±ÇÊï∞ÁâπÊØîÂ§öÔºå‰ΩÜÊòØÈÄüÂ∫¶ËøòÊòØÂø´ -&gt; Âä†ÂÖ•‰∫ÜskipÁöÑÈÉ®ÂàÜÔºåÊääËæìÂÖ•Ë∑≥Ëøá‰∫ÜÂç∑ÁßØÂèàÂä†‰∫ÜÂõûÂéªÔºåËøôÊ†∑backÁöÑÊó∂ÂÄôÂ∞±‰ºöÂàÜÊµÅ top-5 error Âú®ÁúãÁªìÊûúÁöÑÊó∂ÂÄô‰∏çÂÖâÁúãÂáÜÁ°ÆÁéáÔºåËøò‰ºöÁúãÂàÜÁ±ªÂô®ËÆ§‰∏∫ÁöÑÂâç5‰∏™ÂèØËÉΩÊÄßÔºàÂèØËÉΩÊúâÂá†ÂçÉ‰∏™ÂàÜÁ±ªÔºâÔºåÂ¶ÇÊûúËøô5‰∏™ÂèØËÉΩÊÄßÈÉΩ‰∏çÂØπÁöÑËØùÂ∞±ÊòØÊ±ÇÂá∫Êù•ÁöÑÂ∞±ÊòØtop-5 error spatial localization and detectionËøôÁ´†ÁöÑ‰∏ªË¶ÅÂÜÖÂÆπÊòØËØÜÂà´Âá∫Êù•Ëøô‰∏™‰∏úË•ø‰πãÂêéÁî®Ê°ÜÊ°ÜÊ°ÜÂá∫Êù• ÂàÜÁ±ª+ÂÆö‰ΩçÔºöLocalization as Regression ÂÆûÈôÖ‰∏äÂ∞±Ë∑üregressionÂ∑Æ‰∏çÂ§ö neurral netÁöÑËæìÂá∫ÊòØbounding boxÔºà4‰∏™Êï∞Â≠óÔºâÔºåÂ∑¶‰∏äËßíÁöÑÂùêÊ†áÂíåÈïøÂÆΩ ÂÆûÈôÖÁöÑÂõæÁâáÊ†áÊ≥®ÁöÑÂÜÖÂÆπ‰πüÊúâÂ∑¶‰∏äËßíÂùêÊ†áÂíåÈïøÂÆΩÔºåÊ±ÇÂá∫Ëøô‰∏§‰∏™ÈÉ®ÂàÜÁöÑL2 distance‰Ωú‰∏∫loss Ê≠•È™§ ËÆ≠ÁªÉÔºà‰∏ãËΩΩÔºâ‰∏Ä‰∏™ÂàÜÁ±ªÁöÑmodel Âú®netÈáåÈù¢Âä†‰∏äfcÁöÑregression head Áî®SGDÂíåL2lossËÆ≠ÁªÉregression headÈÉ®ÂàÜ testÁöÑÊó∂ÂÄôÂàÜÁ±ªÂíåregressionÈÉΩÁî® Á±ªÂà´ Âπ≥Â∏∏ÁöÑÂàÜÁ±ªÔºöÊúÄÁªàÁöÑÊï∞ÈáèÂíåclassÁöÑÊï∞ÈáèÁõ∏Âêå ‰∏Ä‰∏™boxÈáåÈù¢‰ºöÊúâ4‰∏™Êï∞Â≠óÔºå‰∏ÄÂÖ±Cx4‰∏™Êï∞Â≠ó Âä†Âú®‰ªÄ‰πàÂú∞Êñπ conv layer‰πãÂêé fc‰πãÂêé Â§ö‰∏™ÁõÆÊ†áÁöÑÊ£ÄÊµãÔºàAsideÔºâ Áü•ÈÅìÂáÜÁ°ÆÁöÑÊ£ÄÊµãÁõÆÊ†áÁöÑÊï∞ÈáèkÔºåÈÇ£‰πàÊúÄÁªàÁöÑÂàÜÁ±ªÊï∞ÈáèÂ∞±ÊòØ4 * k Â∫îÁî®Ôºö‰∫∫ÁöÑÂä®‰ΩúÊ£ÄÊµã -&gt; ÂæóÂà∞ÂÖ≥ËäÇÁöÑ‰ΩçÁΩÆ ÂàÜÁ±ª + ÂÆö‰ΩçÔºösliding windowÔºöoverfeat Ê†∏ÂøÉideaÔºöÂú®Ê£ÄÊµãÁöÑÊó∂ÂÄôÁõ¥Êé•processÂõæÁâáÔºå‰ΩÜÊòØÂØπ‰∏ÄÂº†ÂõæÁâáÂú®‰∏çÂêåÁöÑÂú∞ÊñπËøõË°åÂ§öÊ¨°Êìç‰Ωú Êìç‰ΩúÊ≠•È™§Ôºö È¶ñÂÖàÂØπÂõæÁâáËøõË°åconvÂíåpoolingÔºåÁÑ∂ÂêéÂØπÂæóÂà∞ÁöÑÁªìÊûúËøõË°å‰∏§‰∏™‰∏çÂêåÁöÑfcÔºå ÂæóÂà∞ÁöÑÊòØ1000‰∏™ÁöÑÂàÜÁ±ªÁßçÁ±ª Âè¶‰∏Ä‰∏™ÁöÑÂà∞ÁöÑÊòØ1000x4ÁöÑbounding boxÂùêÊ†á Âú®‰∏ÄÂº†Â§ßÁöÑÂõæÁâá‰∏äÔºåÂú®‰∏çÂêåÂå∫ÂüüÊâæÂà∞ÈúÄË¶ÅÂØªÊâæÁöÑ‰∏úË•øÔºàÊØîÂ¶ÇÂàÜÊàêÂõõÈÉ®ÂàÜÔºåËøôÂõõÈÉ®ÂàÜÊòØÊúâÈáçÂè†ÁöÑÔºå‰∏çÊòØpoolingÈÇ£‰∏™Ê†∑Â≠êÔºâ ÂæóÂà∞ÊØè‰∏™ÈÉ®ÂàÜÂØπ‰∫éËøô‰∏™ÂàÜÁ±ªÁöÑÂæóÂàÜÔºå‰ª•ÂèäÁõ∏Â∫îÈÉ®ÂàÜÂØπÂ∫îÁöÑbounding box ÊúÄÂêéÁî®Ê≤°ÊÄé‰πàËÆ≤ÁöÑÂäûÊ≥ïmerge‰∫ÜËøô‰∫õÊ°ÜÔºåÂæóÂà∞‰∫ÜÊúÄÁªàÁªìÊûú Ëøõ‰∏ÄÊ≠•‰ºòÂåñ Âõ†‰∏∫Ë¶ÅÂØπËøô‰∏™ÂõæÁâáÁöÑ‰∏çÂêåcropÂÅöcnnÔºåËÆ°ÁÆóÈáè‰ºöÈùûÂ∏∏Â§ß Âú®fcÂ±ÇÂÖ∂ÂÆûÂè™ÊòØ‰∏Ä‰∏™ÂêëÈáè1x4096ÔºåÊääËøô‰∏™Áé©ÊÑèÊãâÊàê‰∫Ü‰∏Ä‰∏™cnnÔºå4096x1x1ÔºåÁÑ∂ÂêéÁõ¥Êé•conv1x1ÁöÑÂç∑ÁßØÊ†∏ Áé∞Âú®netÈáåÈù¢Â∞±Âè™ÊúâconvÂíåpooling‰∫ÜÔºåÊâÄ‰ª•Â∞±ÂèØ‰ª•Â§ÑÁêÜ‰∏çÂêåÂ∞∫ÂØ∏ÁöÑÂõæÁâá‰∫ÜÔºà‰∏çÂêåÂ∞∫ÂØ∏ÁöÑÊñπÂΩ¢Ôºâ ËÄå‰∏îÂú®Â§ÑÁêÜ‰∏çÂêåÂå∫ÂüüÁöÑÊó∂ÂÄôÊòØÂèÇÊï∞ÊòØshareÁöÑ ÁõÆÊ†áÊ£ÄÊµã ‰∏ªË¶Å‰∏çÂêåÔºö‰∏çËÉΩÁ°ÆÂÆöÂõæÁâáÈáåÈù¢Áâ©‰ΩìÁöÑÊï∞Èáè ÊÄùË∑ØÔºö Â∞ùËØïÊâÄÊúâÂèØËÉΩÁöÑwindowÁÑ∂ÂêéÁî®classifcationÊâæÂà∞ÈúÄË¶ÅÁöÑÈÉ®ÂàÜ ÈóÆÈ¢òÔºöÈúÄË¶ÅÂæàÂ§öÊ¨°ÂàÜÁ±ª ÂéÜÂè≤Ëß£ÂÜ≥ÊñπÊ≥ïÔºöÁî®ÈùûÂ∏∏Âø´ÁöÑÂàÜÁ±ªÂô®ÔºåÂ∞ùËØïÊâÄÊúâÔºàlinear classifierÔºâ Êõ¥ÊÉ≥Áî®ÁöÑÊñπÊ≥ïÔºöÁî®cnnÔºåÂè™ÊµãËØïtiny subsets of possible locations region proposals ËæìÂÖ•‰∏ÄÂº†ÂõæÁâáÔºåËæìÂá∫ÊâÄÊúâÂèØËÉΩÊúâÁâ©‰ΩìÁöÑÂå∫Âüü ‰∏çÂú®ÊÑèÂà∞Â∫ïÊòØ‰ªÄ‰πàÁ±ªÂûã ‰∏çÂú®ÊÑèÁ≤æÁ°ÆÂ∫¶ ‰ΩÜÊòØÈÄüÂ∫¶ÂæàÂø´ selective search ‰ªé‰∏Ä‰∏™pixelÂºÄÂßãÔºåÂ¶ÇÊûúÁõ∏ÈÇªÁöÑpixelÊúâ‰∏ÄÊ†∑ÁöÑÈ¢úËâ≤ÊàñËÄÖtextureÔºåmerge ÂΩ¢ÊàêËøûÊé•Âå∫ÂüüÔºåÂÜçËøûÊé•‰∏çÂêåÂå∫ÂüüÔºåËøô‰∏™Âå∫Âüü‰πüÂèØ‰ª•ÂÜçÊâìÊï£ ËøòÊúâÂæàÂ§öÂÖ∂‰ªñÊñπÊ≥ïÔºöedge boxesÔºàÊé®ËçêÔºâ RCNNÔºàregion based CNNÔºâ ‰ªéËæìÂÖ•ÂõæÁâáÈáåÈù¢Áî®region proposalÁöÑÊñπÊ≥ïÂæóÂà∞‰∏ÄÁ≥ªÂàóÁöÑboundingsÔºà‰∏çÂêåÁöÑ‰ΩçÁΩÆÂíåscaleÔºâ ÂØπÊØè‰∏™Âå∫ÂüücrropÂíåwrapËøô‰∏™Âå∫ÂüüÂà∞fixed size cnnÂàÜÁ±ªÔºåregression head &amp; classifcation head ËøáÁ®ã ‰∏ãËΩΩmodel fine-tune for detectionÔºöÊîπÂèòÂàÜÁ±ªÁöÑÁßçÁ±ªÁ≠â extract features ‰∏∫ÊØè‰∏™classËÆ≠ÁªÉ‰∏Ä‰∏™SVMÔºàÁúãËøô‰∏™Âå∫ÂüüÊòØÂê¶ÂåÖÊã¨ÂØªÊâæÁöÑ‰∏úË•øÔºâ box regressionÔºöÂØπÊØè‰∏™ÁßçÁ±ªÔºåËÆ≠ÁªÉ‰∏Ä‰∏™linear regressionÊù•Á∫†Ê≠£‰ΩçÁΩÆÁöÑÂÅèÂ∑ÆÔºàÂ§™Â∑¶Â§™Âè≥ÔºåÁ©∫ÈöôÂ§™Â§öÔºâÔºàdxÔºådyÔºådwÔºådhÔºâ datast PASCAL VOC ÊØîËæÉÂ∞è ImageNet ‰∏çÊòØ‰∫ãÂæàÂ•ΩÊìç‰ΩúÔºå‰ΩÜÊòØ‰∏ÄÂº†Âõæ‰∏ÄÂçäÂè™Êúâ‰∏Ä‰∏™‰∏úË•ø MS-COCO ‰∏ÄÂº†ÂõæÂ§ö‰∏™ÂÜÖÂÆπ fast RCNN ÔºàÊèêÈÄüÔºâ Âú®ÊµãËØïÊó∂ÁöÑÈÄüÂ∫¶ÊØîËæÉÊÖ¢ -&gt; ‰∏ÄÂº†ÂõæÈáåÔºåÂú®‰∏çÂêåÁöÑproposals‰πãÈó¥share convÁöÑËÆ°ÁÆó ËÆ≠ÁªÉÊó∂‰∏çÊòØ‰∏ÄËµ∑ËÆ≠ÁªÉÁöÑÔºåËÆ≠ÁªÉÁöÑpipeline‰πüÂæàÂ§çÊùÇ -&gt; ÊääÊï¥‰∏™Á≥ªÁªüÁ´ØÂØπÁ´ØÂØπÁöÑËÆ≠ÁªÉ‰∏ÄÊ¨° ROI pooling Âú®Áî®ÁöÑÊó∂ÂÄôÂ∏åÊúõÊÑüÂÖ¥Ë∂£Âå∫ÂüüÁöÑÂàÜËæ®ÁéáÊØîËæÉÈ´òÔºåfcÂ±ÇÂ∏åÊúõÊõ¥‰ΩéÁöÑconv feature Âú®conv feature map‰∏äÈù¢ÊäïÂΩ±È´òÂàÜËæ®ÁéáÁöÑregion proposal ÊääËøô‰∏™Âå∫ÂüüÂàÜÊàêÂ∞èÊ†ºÔºåÁÑ∂ÂêéÂØπÊØè‰∏™Ê†ºÂ≠êËøõË°åmax pooling(backÁöÑÊó∂ÂÄô‰πüÊòØËøô‰πàÂõûÊù•) ËÆ≠ÁªÉ8ÂÄçÔºÅÊµãËØï146ÂÄçÔºÅÁªìÊûúÊõ¥ÂáÜÁ°ÆÔºÅ faster RCNNÔºàÂÜçÊèêÈÄüÔºâ ‰πãÂâçÁöÑÊµãËØïÈÄüÂ∫¶ËÆ°ÁÆóÈÉΩÊ≤°ÊúâÁÆóregion proposalÁöÑÊó∂Èó¥ÔºåÊâÄ‰ª•ÊääËøô‰∏™ÈóÆÈ¢ò‰πü‰∫§ÁªôconvÂéªÂπ≤ Âú®ÊúÄÂêé‰∏ÄÂ±ÇconvÂêéÈù¢Âä†ÂÖ•region proposal net Âú®feature map‰∏äÈù¢ÁöÑÁßªÂä®ÂÆûÈôÖÂ∞±ÊòØÂç∑ÁßØ ËÆ≠ÁªÉ‰∏Ä‰∏™Â∞èÁöÑÁΩëÁªúÂà§Êñ≠ÊòØ‰∏çÊòØ‰∏Ä‰∏™Áâ©‰ΩìÂπ∂ÂàÜÁ±ªÔºå‰ª•ÂèäregressionÊ°ÜÁöÑ‰ΩçÁΩÆ Âú®ÊØè‰∏™‰ΩçÁΩÆ‰ΩøÁî®‰∫ÜN anchor boxesÔºå‰∏çÂêåÁöÑanchorÊúâscoreÊù•Âà§Êñ≠‰ªñÊòØÂê¶Â±û‰∫é‰∏Ä‰∏™objectÔºåÂú®‰∏çÂêåÁöÑÂΩ¢Áä∂‰∏äÊúâ‰∏çÂêåÁöÑÂèØËÉΩÊÄßÔºàÔºü ÂêéÁª≠ÁöÑpaperÈáåÈù¢ÂèØ‰ª•‰∏ÄÂè£Ê∞îtrain‰∫Ü yolo ÊäädetectionÂèòÊàê‰∫ÜregressionÁöÑÈóÆÈ¢ò ÂàÜÊàê‰∏çÂêåÁöÑÂ∞èÂùóÔºåÂú®ÊØè‰∏™ÂùóÈáåÈù¢ÈÉΩÂä†ÂÖ• visualization, deep dream, neural styleÂèØËßÜÂåñÔºöËßÇÂØüÁ•ûÁªèÁΩëÁªúÂ¶Ç‰ΩïÂ∑•‰Ωú ÂèØËßÜÂåñ‰∏çÂêå‰ΩçÁΩÆ ÂèØËßÜÂåñactivationÁöÑÁ•ûÁªèÂÖÉ -&gt; Â§ßÈáèÁöÑÂõæÁâáÊâîËøõÁ•ûÁªèÂÖÉÈáåÈù¢ÔºåÊâæÂá∫Êù•‰∏Ä‰∏™Á•ûÁªèÂÖÉÊúÄÊÑüÂÖ¥Ë∂£ÁöÑÈÉ®ÂàÜ ÂèØËßÜÂåñfliter -&gt; Âè™ËÉΩÂú®Á¨¨‰∏ÄÂ±ÇËøõË°åÔºàÂÖ∂‰ªñÁöÑÂ±ÇÂèØ‰ª•‰ΩÜÊòØÊÑè‰πâ‰∏çÂ§ßÔºâ ‰ΩÜÊòØÂï•ÁÆóÊ≥ïÈÉΩ‰ºöÂæóÂá∫Êù•ÈïøÂæóÂ∑Æ‰∏çÂ§öÁöÑ ÂèØËßÜÂåñÁâπÂæÅÔºàÂÖ®ËÅîÊé•Â±ÇÁöÑÁâπÂæÅÂêëÈáèÔºâ -&gt; t-SNEÔºöEmbed high-dimensional points so that locally, pairwise distances are conservedÔºåÁâπÂæÅÁõ∏‰ººÁöÑ‰∏úË•ø‰ºöËÅöÁ±ª ÂØπÂõæÁâáËøõË°åÈÅÆÁΩ©ÔºåÂèØ‰ª•ÁúãÂá∫Êù•ÈÅÆ‰Ωè‰∏çÂêåÂú∞ÊñπËøôÂº†ÂõæÁâáË¢´ËØÜÂà´Âá∫Êù•ÁöÑÊ¶ÇÁéá deep convÂíåoptimazationÁöÑÂèØËßÜÂåñÂ∑•ÂÖ∑Ôºöhttp://yosinski.com/deepvis deconvÂÆûÁé∞ÈóÆÈ¢ò1:Â¶Ç‰ΩïËÆ°ÁÆó‰ªªÊÑè‰∏Ä‰∏™Á•ûÁªèÂÖÉÁöÑÊ¢ØÂ∫¶Ôºà‰ª£Á†ÅÂÆûÁé∞Ôºâ ÊâæÂà∞ÊÉ≥Ë¶ÅÁöÑÁ•ûÁªèÂÖÉÔºåforwardÁöÑÊó∂ÂÄôÂ∞±ÂÅúÂú®ËøôÈáå ÁÑ∂ÂêéËøõË°åbackÔºåÊääÊâÄÊúâÂÖ∂‰ªñÁöÑÁ•ûÁªèÂÖÉÁöÑÈÉΩËÆæÁΩÆÊàê0ÔºåÂè™ÊääÊÑüÂÖ¥Ë∂£ÁöÑÁ•ûÁªèÂÖÉËÆæÁΩÆÊàê1ÔºåÁÑ∂ÂêéËÆ°ÁÆóbackÂá∫Êù•ÁöÑÁªìÊûú ÊúÄÂêéÁöÑÁªìÊûúÁúãËµ∑Êù•Âπ∂‰∏çÊòØÂæàÂ•ΩÁêÜËß£ÔºåÊâÄ‰ª•ÊîπÂèò‰∫ÜbackÁöÑÊñπÊ≥ïÔºåÂæóÂà∞Êõ¥Â•ΩÁöÑÁªìÊûúÔºà‚Äúguided back‚ÄùÔºâ guided backÁöÑËÆ°ÁÆóÊñπÊ≥ï Âú®ÊôÆÈÄöÁöÑËÆ°ÁÆó‰∏≠ÔºåbackÁöÑÊó∂ÂÄô‰ΩøÁî®reluÔºå‰ºöÊääÊâÄÊúâË¥üÂÄºÈÉΩËΩ¨ÂåñÊàê0 Âú®guideÁöÑËÆ°ÁÆóÈáåÔºåÂú®ÊøÄÊ¥ª‰πãÂêéÁöÑ‰∏úË•øbackÂõûÂéªÁöÑÊó∂ÂÄôÔºåÂ¶ÇÊûúinputÁöÑ‰∏úË•øÊòØË¥üÊï∞ÁöÑËØùÔºå‰πü‰ºöÊääËøô‰∏™‰∏úË•økillÊàê0Ôºå‰πüÂ∞±ÊòØËØ¥‰∏Ä‰∏™ÊòØblock backÁöÑÊó∂ÂÄôÁöÑgradientÁöÑÂÄºÔºåÂè¶‰∏Ä‰∏™Ëøò‰ºöÈôÑÂä†blockËæìÂÖ•ËøõÊù•ÁöÑÂÄº ÂèëÁîü‰∫Ü‰ªÄ‰πàÔºöÊääËæìÂÖ•ËøõÂéªReLUÁöÑË¥üÁöÑÂΩ±Âìç‰πüÂèñÊ∂àÊéâ‰∫Ü„ÄÇÂ¶ÇÊûú‰∏çÂèñÊ∂àÁöÑËØùÔºåËøô‰∫õÊ≠£Ë¥üÂ∞±‰ºö‰∫íÁõ∏fightÔºåÂëàÁé∞Êõ¥Â•áÊÄ™ÁöÑÂõæÁâá„ÄÇ‰ΩÜÊòØÂéªÊéâË¥üÁöÑ‰πãÂêéÂèòÂæóÂ∞±Êõ¥Ê∏ÖÊô∞‰∫Ü„ÄÇ deconvÔºöÁõ¥Êé•Êó†ËßÜÊéâreluÁöÑÂ≠òÂú®‰∫Ü Á¨¨‰∫å‰∏™ÈóÆÈ¢òÔºöÂõæÂÉè‰ºòÂåñ how to find an image maximize some class scoreÔºå‰ΩÜÊòØÊï¥‰∏™ÁΩëÁªú‰∏çÂèò ËæìÂÖ•‰∏ÄÂº†ÂÖ®0ÁöÑÂõæÁâá Âú®backÁöÑÊó∂ÂÄôÊääscoreËÆæÁΩÆÊàê[0,0,0,1,0,0,‚Ä¶]ÔºåÂè™ÊúâÊÑüÂÖ¥Ë∂£ÁöÑÊòØ1 backÂõûÂéªÔºåÊâæÂà∞ÂØπÂõæÁâá‰ºö‰∫ßÁîü‰ªÄ‰πàÂΩ±Âìç ‰∏çÂÅúÁöÑÈáçÂ§çËøô‰∏™Ê≠•È™§ÔºåÊõ¥Êñ∞ÁöÑÊòØÂõæÁâá‰∏çÊòØweight ÊïàÊûú ÊâæÂà∞ÂèØ‰ª•ËÆ©‰∏Ä‰∏™Á±ªÂûãÂàÜÊï∞ÊúÄÈ´òÁöÑÂõæÁâáÔºàÂõæÁâáÊòØÊ†πÊçÆÁΩëÁªúÁîüÊàêÁöÑÔºâ ÂèØËßÜÂåñdataÁöÑÊ¢ØÂ∫¶ -&gt; ÂæóÂà∞‰∫Ü‰∏Ä‰∏™Á±ª‰ººÁÉ≠ÈáèÂõæÁöÑ‰∏úË•øÔºåËøôÊ†∑ÂØπÈªëËâ≤ÁöÑÈÉ®ÂàÜÊîπÂèòÂØπËøô‰∏™‰∏úË•øÁöÑÂàÜÁ±ªÊ≤°ÊúâÂæàÂ§ßÁöÑÂΩ±Âìç ‰∏äÈù¢ÁöÑÊ≠•È™§ÂèØ‰ª•ÂØπ‰ªª‰ΩïÁöÑÁ•ûÁªèÂÖÉËøõË°åÔºàÁîüÊàê‰∏ÄÂº†ÂõæÁâáÔºâ Êõ¥Â•ΩÁöÑregular ÂøΩËßÜ‰∫ÜÊÉ©ÁΩöÔºåÂè™maxÁ•ûÁªèÂÖÉ ‰ΩÜÊòØÊõ¥Êñ∞‰πãÂêéblur‰∫Ü‰∏Ä‰∏ãÂõæÂÉèÔºåËøôÊ†∑ÂèØ‰ª•ÈòªÊ≠¢ÂõæÁâáËøõË°åÈ´òÈ¢ëÁéáÁßØÁ¥Ø Á¨¨‰∏â‰∏™ÈóÆÈ¢òÔºåCNNÁöÑcodeÂåÖÂê´Â§öÂ∞ë‰ø°ÊÅØ ÊòØÂê¶ÂèØ‰ª•ÈÄöËøánetËøòÂéüÂá∫Êù•ÂéüÊù•ÁöÑÂõæÁâáÔºàÊ∂âÂèäÂà∞ÈöêÁßÅÊ≥ÑÈú≤ÁöÑÈóÆÈ¢òÔºâ Ë∂äÂæÄÂêéÁöÑÊó∂ÂÄôÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÂ∫¶Ë∂ä‰Ωé deep dream ‰∏Ä‰∏™ÈùûÂ∏∏ÁÆÄÂçïÁöÑËøáÁ®ãÔºåÂè™ÊúâÂá†ÁôæË°å‰ª£Á†ÅÔºåÂ∞±ÊòØoptimazation image ÊØèÊ¨°Ë∞ÉÁî®make_stepÂõæÁâáÈÉΩ‰ºöÂèëÁîüÂæÆÂ∞èÁöÑÊîπÂèò ÊääÁΩëÁªúforwardÂà∞‰∏Ä‰∏™‰ΩçÁΩÆ ÊäägradientËÆæÁΩÆÊàêactivationËÆæÁΩÆÊàê‰∏ÄÊ†∑ÁöÑ ÂÜçÂæÄÂõû‰º†ÂõûÂéª ÂèØ‰ª•Âº∫Ë∞ÉÂØπÂõæÁâáË¥°ÁåÆÊúÄÂ§öÁöÑÈÉ®ÂàÜÔºå‰∏çÁÆ°ÊøÄÊ¥ª‰∫Ü‰ªÄ‰πàÔºåÈÉΩ‰ºöÊääËøô‰∏™ÊøÄÊ¥ªÂä†Âº∫ deepart ÊääÁõÆÊ†áÁöÑcontent‰º†ËøõCNN Êäästyle contet‰πü‰º†ËøõCNN ÊääÁõÆÊ†áÁöÑlossÂíåstyleÁöÑlossÂåπÈÖçÔºåÁÑ∂ÂêéÂæóÂà∞Áõ∏Â∫îÁöÑopt image ÊòØÂê¶ÂèØ‰ª•Áî®ÁîüÊàêÁöÑÂõæÁâáÂéªfool CNN ÊääÂõæÁâáÁöÑgradientËÆæÁΩÆÊàêÂÖ∂‰ªñÁöÑ‰∏úË•øÔºåÊú¨Êù•Â∏åÊúõÂèØ‰ª•ÂæóÂà∞Ê∑∑ÂêàÁöÑÁªìÊûúÔºå‰ΩÜÊòØÂÆûÈôÖ‰∏äÂõæÁâáÁöÑdistortÊ†πÊú¨ÁúãËµ∑Êù•‰∏çÂèò Êúâ‰∫õÂõæÁâá‰∫∫Á±ªÁúãËµ∑Êù•Â∑Æ‰∏çÂ§öÔºå‰ΩÜÊòØgradientÔºàÊàñËÄÖHOGÔºâ‰πãÁ±ªÁöÑÂèØËÉΩÂΩªÂ∫ïÊòØÂÖ∂‰ªñÁöÑ‰∏úË•ø ÂéüÂõ†Ôºö ÂõæÁâáÊúâÂæàÈ´òÁª¥Â∫¶ÁöÑÁ©∫Èó¥ ÂÆûÈôÖËÆ≠ÁªÉÁöÑÂõæÂÉèÊúâ‰∏ÄÂ∞èÈÉ®ÂàÜË¢´Á∫¶ÊùüÔºåÊîæ‰∫Ü‰∏Ä‰∏™Á∫øÊÄßÂàÜÁ±ª‰πãÁ±ªÂè™Ë∞ÉÊï¥‰∫ÜÂÖ∂‰∏≠ÁöÑ‰∏ÄÂ∞èÈÉ®ÂàÜ Âú®Á∫øÊÄßÂàÜÁ±ªÈáåÔºåÂ¶ÇÊûúÂú®ÊØè‰∏™Áª¥Â∫¶‰∏äÈù¢ÈÉΩÊîπÂèò‰∫Ü‰∏ÄÁÇπÁÇπÔºåÂÆûÈôÖ‰∏äÁöÑÁΩÆ‰ø°Âå∫Èó¥‰ºöÂèëÁîüÁâπÂà´Â§ßÁöÑÊîπÂèòÔºàÂ§ßËßÑÊ®°ÁöÑÁÇπÁßØËøêÁÆóÔºâ.‰∏ãÂõæÂè™Âä†ËøõÂéª‰∫Ü‰∏ÄÁÇπÁÇπÁöÑÈáëÈ±ºÁöÑÂô™Èü≥ÔºåÂàÜÁ±ªÂ∞±ÂèòÊàê‰∫Ü100%ÁöÑÈáëÈ±º Ëøô‰∏™Áé∞Ë±°‰∏ç‰ªÖ‰ªÖÂèëÁîüÂú®ÂõæÁâáÈáåÈù¢Ôºå‰πüÂèëÁîüÂú®ÂÖ∂‰ªñÁöÑÂú∞Êñπ RNNÔºàrecurrent neural networkÔºâÊôÆÈÄöÁöÑnetsÔºöÂ§ßÂ∞èÈÉΩÊòØÂõ∫ÂÆöÁöÑ one to oneRNNÔºöÂèØ‰ª•ÊúâÁÅµÊ¥ªÁöÑÂØπÂ∫îÁªìÊûú ‰∏ÄÁ≥ªÂàóÁöÑËØçÊù•ÊèèËø∞ËøôÂº†Âõæ machine translationÔºöseq of words -&gt; seq of words frame levelÁöÑËßÜÈ¢ëclassification RNNÊòØ‰ªÄ‰πà ÂèØ‰ª•Âú®‰ªª‰ΩïÊó∂Èó¥Êé•Âèó‰∏Ä‰∏™inputÔºàvectorÔºâÔºåÁÑ∂ÂêéÂØπ‰∫é‰∏çÂêåÁöÑstate‰∫ßÁîü‰∏çÂêåÁöÑÈ¢ÑÊµãÁªìÊûúÔºåÁÑ∂ÂêéÈúÄË¶ÅÂú®‰∏Ä‰∫õÊó∂Èó¥‰∏≠È¢ÑÊµãÂá∫Êù•vector„ÄÇÂè™ÈúÄË¶ÅÁâπÂÆöÁöÑÊÉÖÂÜµÔºåÂÖ∂‰ªñÁöÑÊÉÖÂÜµËôΩÁÑ∂Êúâ‰ΩÜÊòØÊ≤°ÊúâËÆ∞ÂΩï‰∏ãÊù• ËøáÂéªÁöÑÁä∂ÊÄÅ + Êñ∞ÁöÑinput + ÂèÇÊï∞w -&gt; È¢ÑÊµãÂá∫Êù•Êñ∞ÁöÑstate Ê≥®ÊÑèÔºöÂêåÊ†∑ÁöÑfunctionÈáåÈù¢ÁöÑweightÊòØÂõ∫ÂÆöÁöÑÔºåÂú®‰∏çÂêåÊó∂Èó¥‰ΩøÁî®‰ΩÜÊòØweightÊòØ‰∏ÄÊ†∑ÁöÑ ÊØîÂ¶Ç‰æãÂ≠êÔºöhttps://gist.github.com/karpathy/d4dee566867f8291f086 ËæìÂÖ•‰∏Ä‰∏™Â≠óÊØçÁöÑÂ∫èÂàóh e l o È¢ÑÊµã‰∏ãÈù¢ÁöÑÂ≠óÊØçÊòØ‰ªÄ‰πàÔºåËÆ≠ÁªÉÁöÑÊ®°ÂûãÊòØhello ÊääÊØè‰∏™Â≠óÊØçÂàÜÂà´feedËøõÂéªÔºåÈ°∫ÁùÄËøô‰∏™Â≠óÊØçÈ°∫Â∫èÊù•‰ºòÂåñÂèÇÊï∞ÁöÑÂ∫èÂàóÔºåÂõ†‰∏∫Áü•ÈÅì‰∏ã‰∏Ä‰∏™ÁöÑÁªìÊûúÊòØ‰ªÄ‰πà‰∫ÜÔºåÂ∞±ÂèØ‰ª•ÊúùÁùÄËøô‰∏™ÁõÆÊ†áÊù•Âä™Âäõ Á´üÁÑ∂ÂèØ‰ª•ÁîüÊàêÂè•Â≠êÊï∞Â≠¶ÂÖ¨ÂºèÁîöËá≥‰ª£Á†Å Âú®ÂõæÁâá‰∏≠ÂºÄÂßã‰ΩøÁî® ‰ªé‰∏ÄÂº†ÂõæÂæóÂà∞‰∏ÄÁ≥ªÂàóÁöÑÊñáÂ≠ó ‰∏§ÈÉ®ÂàÜÁªÑÊàê CNNÔºöÊäätestÂõæÁâáËæìÂÖ•Âà∞CNNÔºå‰∏ÄÁõ¥Âà∞ÊúÄÂêéÁöÑfcÔºå‰ΩÜÊòØÁÑ∂Âêé‰∏çËøõË°åÂàÜÁ±ªÔºåËæìÂÖ•RNN RNNÔºöRNN‰∏ç‰ªÖÊòØÁé∞Âú®ÁöÑËæìÂÖ•ÔºåËøò‰ºöÂä†ÂÖ•‰∫ÜCNNÈáåÈù¢Âá∫Êù•ÁöÑËæìÂá∫„ÄÇÁÑ∂ÂêéÂæóÂà∞ÁöÑÁªìÊûúÔºàÂæóÂà∞‰∫ÜÊ≤°ÂáÜ‰∏Ä‰∏™ËØçÔºâËøõÂÖ•‰∏ã‰∏Ä‰∏™Âæ™ÁéØÔºàÂ∞±Ë∑üÁîüÊàêËØ≠‰πâÁöÑÊó∂ÂÄô‰∏ÄÊ†∑Ôºâ Áõ¥Âà∞Âú®RNNÈáåÈù¢ÊâæÂà∞ÁöÑtokenÔºåÁÑ∂ÂêéÁªìÊùüRNN LSTM long short term memoryÔºàÂ§ßÊ¶ÇÊòØ‰∏™ÁîüÁâ©ÈáåÈù¢ÁöÑ‰∏úË•øÔºâ RNNÊúâÂ•ΩÂ§öÂ±ÇÔºåÊØèÂ±ÇËøòÊúâÂæàÂ§ö‰∏™ÂèÇÊï∞Êù•ÂÜ≥ÂÆöËøôÂ±ÇÂæÄÂì™Ëµ∞ Êúâ‰∏§‰∏™ËæìÂÖ•xÂíåhÔºåÁªÑÂêàÂà∞w‰∏äÈù¢ÔºåÁÑ∂Âêé‰∏çÂêåÁöÑ‰∏úË•ø‰πò‰∏çÂêåÁöÑÊøÄÊ¥ªÂáΩÊï∞ xÊù•Ëá™below hÊòØ‰ªé‰∏ä‰∏ÄÂõûÊù•ÁöÑ Âü∫‰∫égateÂíåfunctionÔºàforget gateÔºâÁöÑÁ±ªÂûãÔºå‰ºöÊõ¥Êñ∞cÁöÑÂÄºÔºàÂèçÊ≠£ÈÉΩÊòØÂèÇÊï∞ÁöÑÔºâ ËøõË°åËøô‰∫õÂ•áÊÄ™ÁöÑÊìç‰ΩúÁöÑÂéüÂõ†Â∞±ÊòØÊâæÂà∞‰∏Ä‰∏™Âπ≥Ë°°ÂíåÊõ¥Â•ΩÁöÑÁªìÊûú ÊØîËæÉ ÊØèÊ¨°ÊôÆÈÄöÁöÑRNNÈÉΩË¶ÅÁªèËøáf gateÔºå‰ºöÂΩªÂ∫ïÊîπÂèò„ÄÇbackÁöÑÊó∂ÂÄôgradient‰ºöÊ∂àÂ§±ÊàñËÄÖÁàÜÁÇ∏ LSTMÈáåÈù¢Áî®Âä†Ê≥ïË∑≥Ëøá‰∫ÜËøô‰∏™Èó®ÔºåÊúâ‰∏ÄÂÆöÁöÑÂΩ±Âìç‰ΩÜÊòØÊ≤°ÊúâÂΩªÂ∫ïÊîπÂèòÔºågradientÁöÑÊ∂àÂ§±ÈóÆÈ¢ò‰ºöË¢´ÊéßÂà∂‰ΩèÔºàÂõ†‰∏∫Âè™Áî®‰∫ÜÂä†Ôºå‰∏ç‰ºödieÔºâ gradient clippingÂèØ‰ª•ÊéßÂà∂‰ΩègradientÁàÜÁÇ∏ ‰Ωú‰∏öÁõ∏ÂÖ≥ÂÜÖÂÆπÂÆâË£ÖanacondaÔºÅÔºÅÔºÅ conda activate cs231npython3 -m IPython notebook ÊâìÂºÄÔºÅÔºÅassignment1knn ‰∏§Ê¨°Âæ™ÁéØËÆ°ÁÆóË∑ùÁ¶ª ‰∏çÈúÄË¶Å‰∏Ä‰∏™ÂÉèÁ¥†‰∏Ä‰∏™ÂÉèÁ¥†ÁöÑËÆ°ÁÆóÔºåÁî®XÁõ¥Êé•Ë°®Á§∫iÂØπÂ∫îÁöÑÈÇ£Ë°åÁöÑÂÉèÁ¥†ÂÄºÁöÑÂíåÔºåÁõ¥Êé•ÂÅöÂ∑ÆÔºàÊØè‰∏ÄÈ°π‰πãÈó¥ÔºåÂπ≥ÊñπÔºàÊØè‰∏Ä‰∏™ÔºåÊ±ÇÂíåÔºàÊâÄÊúâÈ°πÔºâÔºåÂºÄÊñπ„ÄÇ‰ºöÂø´ÂæàÂ§öÔºÅÔºÅÔºÅÔºÅ 12#distsÊòØ‰∏Ä‰∏™500x5000ÁöÑÁü©ÈòµÔºàÊµãËØïÊï∞ÈáèÂíåËÆ≠ÁªÉÊï∞ÈáèÔºâdists[i,j] = np.sqrt(np.sum(np.square(X[i] - self.X_train[j]))) ÂàùÂßãÂåñÊï∞ÁªÑÁöÑÊñπÊ≥ïÊòØ np.array([[],[]]) Â¶ÇÊûú‰∏Ä‰∏™ÂÉèÁ¥†‰∏Ä‰∏™ÂÉèÁ¥†ÁöÑÂæ™ÁéØÁªìÊûúÁÆÄÁõ¥Â§™ÂèØÊÄï‰∫ÜÔºåÂÆ≥ÊÄï]]></content>
      <categories>
        <category>ÂõæÂÉèÂ§ÑÁêÜ</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
</search>
